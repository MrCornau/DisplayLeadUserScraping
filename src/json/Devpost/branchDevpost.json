{"interestingcomments": [{"Unnamed: 0": 124, "autor": "MALWARE DETECTION TECHNIQUES", "date": null, "content": "Inspiration\nalware (e.g. viruses, worms and Trojan horses) has become one of the most significant threats on the Internet. With the help of generation tools, it becomes easy to generate new malware, resulting in a very rapid increase in the number of malware. Test reported that around 81,598,221 new malware samples were obtained in 2017, a 14% increase compared to the previous year. Among all these malware attacks, over 67% targeted Windows systems [1]. It has caused serious threat. For example, the ransomware \u2018\u2018WannaCry\u2019\u2019 spread over 100 countries in the world and caused damage of 8 billion US dollar.\nWhat it does\nwe propose a new method that classifies malware families using malware visualization. The method transforms malware binary files to grayscale images. To obtain discriminative features, we present a new learning framework which is formulated as a multi-layered model to characterize and analyze malware images using bag-ofvisual-words (BoVW).\nAccomplishments that we're proud of\nWith the development of the Internet, malware has become one of the most significant threats. Recognizing specific types of malware is an important step toward effective removal. Malware visualization is an important branch of malware static analysis techniques, where a piece of malware is turned into an image for visualization and classification\nWhat we learned\nExperimental results demonstrate that the obtained descriptors are robust and discriminative, which lead to state-ofthe-art classification performance, outperforming existing methods. Starting from existing local descriptors (LBP or dense SIFT), we group them into blocks and build histograms. The extracted features are more flexible than global features (e.g. GIST) and more robust than local features. We evaluate the proposed method on three datasets, which are all from the Windows platform.", "link": "https://devpost.com/software/malware-detection-techniques", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nalware (e.g. viruses, worms and trojan horses) has become one of the most significant threats on the internet. with the help of generation tools, it becomes easy to generate new malware, resulting in a very rapid increase in the number of malware. test reported that around 81,598,221 new malware samples were obtained in 2017, a 14% increase compared to the previous year. among all these malware attacks, over 67% targeted windows systems [1]. it has caused serious threat. for example, the ransomware \u2018\u2018wannacry\u2019\u2019 spread over 100 countries in the world and caused damage of 8 billion us dollar.\nwhat it does\nwe propose a new method that classifies malware families using malware visualization. the method transforms malware binary files to grayscale images. to obtain discriminative features, we present a new learning framework which is formulated as a multi-layered model to characterize and analyze malware images using bag-ofvisual-words (bovw).\naccomplishments that we're proud of\nwith the development of the internet, malware has become one of the most significant threats. recognizing specific types of malware is an important step toward effective removal. malware visualization is an important -----> branch !!!  of malware static analysis techniques, where a piece of malware is turned into an image for visualization and classification\nwhat we learned\nexperimental results demonstrate that the obtained descriptors are robust and discriminative, which lead to state-ofthe-art classification performance, outperforming existing methods. starting from existing local descriptors (lbp or dense sift), we group them into blocks and build histograms. the extracted features are more flexible than global features (e.g. gist) and more robust than local features. we evaluate the proposed method on three datasets, which are all from the windows platform.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59500124}, {"Unnamed: 0": 169, "autor": "Orthopaedic Doctors in Chennai", "date": null, "content": "Top 10 Orthopaedic doctors in Chennai. Orthopaedics deals with the correction or prevention of disorders or injuries of the skeletal system integrated with muscles, joints, and ligaments in the branch of medicine. A medical doctor who is specialized in diagnosing and treating such disorders is referred as an Orthopaedist (Orthopaedic Doctors). These medical professionals treat conditions like arthritis, sports injuries, back pain, leg and foot pain. For more details, please visit https://bharathorthopaedics.com/top-10-orthopaedic-doctors-in-chennai/. or contact us 96627 36666.", "link": "https://devpost.com/software/orthopaedic-doctors-in-chennai", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "top 10 orthopaedic doctors in chennai. orthopaedics deals with the correction or prevention of disorders or injuries of the skeletal system integrated with muscles, joints, and ligaments in the -----> branch !!!  of medicine. a medical doctor who is specialized in diagnosing and treating such disorders is referred as an orthopaedist (orthopaedic doctors). these medical professionals treat conditions like arthritis, sports injuries, back pain, leg and foot pain. for more details, please visit https://bharathorthopaedics.com/top-10-orthopaedic-doctors-in-chennai/. or contact us 96627 36666.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59500169}, {"Unnamed: 0": 242, "autor": "Customer Support (CRM)", "date": null, "content": "Inspiration\nWell my driving force was the ease of automation. Automation can make everyone life easy. So why not automate customer contact services too? using next level services such as twilio, symbl.ai and alan.ai\nWhat it does\nIt automates web navigation and functionalities for web apps (in this case our DireNet website ) using AlanAi.\nUser can create voice ticket (thanks to twilio) as well as text ticket. If you are lazy even to write, again AlanAi saves the day :)\nAgents can then claim these tickets and thanks to symbl.ai the text and voice analytics (along with recording) are shown to agent . So they can better analyse the issue user is facing.\nAnd if its a end of the world situation for user, he can call directly and if any agent is availabe (logged in system) and is not on any other call, call gets forwarded to the agent. This queue like system was possible with help of twilio and redis.\nHow we built it\nWe have a django app which handles all the logic related to website and database. Fast api handles all the logic related to integration of 3rd party services(twilio/symbl). Redis instance saves all the frequenty used data and free agents queue (which uses a blocking pop call to get a free agent). Alan script handles all the visual and speech of website and was created by Lakshay Tyagi (My teammate).\nChallenges we ran into\nWell there is always problem in integrating 3rd party apis. And above them integrating them with each other and create a workflow and a pipline can wreak havoc. Most of documention of the sponsers were easy to follow but things always breaks in starting.\nOne of the main challenge was to make an agent queue to forward user calls which required some knowledege of redis and queue data structure.\nAlso following best practices of github like making branches for every feature then merging, making sure never to commit sensitive info to repo is not an easy task for a begineer :(\nWhat we learned\nWell I was studying fastapi for a week and this project polished my fastapi skills. and to be honest this was first time i created a project with 3rd party app integration with 3 services (lol). but everything started falling in places after scavinging documentations (after initially breaking stuff offcourse). So, yeah i learned a wide variety of things from best practices of git/github to integrating differnet 3rdparty services with each other and create a workflow Also, this was my first time using redis too (and damn its so useful).", "link": "https://devpost.com/software/customer-support-crm", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nwell my driving force was the ease of automation. automation can make everyone life easy. so why not automate customer contact services too? using next level services such as twilio, symbl.ai and alan.ai\nwhat it does\nit automates web navigation and functionalities for web apps (in this case our direnet website ) using alanai.\nuser can create voice ticket (thanks to twilio) as well as text ticket. if you are lazy even to write, again alanai saves the day :)\nagents can then claim these tickets and thanks to symbl.ai the text and voice analytics (along with recording) are shown to agent . so they can better analyse the issue user is facing.\nand if its a end of the world situation for user, he can call directly and if any agent is availabe (logged in system) and is not on any other call, call gets forwarded to the agent. this queue like system was possible with help of twilio and redis.\nhow we built it\nwe have a django app which handles all the logic related to website and database. fast api handles all the logic related to integration of 3rd party services(twilio/symbl). redis instance saves all the frequenty used data and free agents queue (which uses a blocking pop call to get a free agent). alan script handles all the visual and speech of website and was created by lakshay tyagi (my teammate).\nchallenges we ran into\nwell there is always problem in integrating 3rd party apis. and above them integrating them with each other and create a workflow and a pipline can wreak havoc. most of documention of the sponsers were easy to follow but things always breaks in starting.\none of the main challenge was to make an agent queue to forward user calls which required some knowledege of redis and queue data structure.\nalso following best practices of github like making -----> branches !!!  for every feature then merging, making sure never to commit sensitive info to repo is not an easy task for a begineer :(\nwhat we learned\nwell i was studying fastapi for a week and this project polished my fastapi skills. and to be honest this was first time i created a project with 3rd party app integration with 3 services (lol). but everything started falling in places after scavinging documentations (after initially breaking stuff offcourse). so, yeah i learned a wide variety of things from best practices of git/github to integrating differnet 3rdparty services with each other and create a workflow also, this was my first time using redis too (and damn its so useful).", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 0, "media": null, "medialink": null, "identifyer": 59500242}, {"Unnamed: 0": 632, "autor": "Motherlode.rsk", "date": null, "content": "TECHNICAL DEMO FOR MOTHERLODE: https://youtu.be/dl87mcoUuow\nInspiration\nWith nearly 80 percent of the Salvadoran population unbanked, bitcoin can offer the prospect of financial inclusion to millions. The Bitcoin Law was passed by the Legislative Assembly of El Salvador and President Nayib Bukele on 8 June 2021, giving the cryptocurrency bitcoin the status of legal tender within El Salvador after 7 September 2021.\nMonolithic brick-and-mortars, malfunctioning ATMs and paperwork with third party middlemen like banks, insurance firms, or brokers to perform hedging, speculating, earning interest or collateralizing loans. Banks rely on opaque pricing and and structuring in hopes of widening marigins and face extremely high cost, fees and in-proportionate revenues. Censorship in developing nations can lead to capital controls, poor governance, and corruption costing the global economy $3.6 trillion dollars every year creating a high barrier to entry for small businesses. Female business owners have more difficulty opening bank accounts, loan applications, and insurance. They may not have access to banks, like using banks, or pass credit checks as easily.\nWhat it does\nMotherlode. A bitcoin-enabled NeoBank for small businesses in El Salvador.\nThe world\u2019s first global bank? Bank the unbanked with our open accessible user-friendly Neobank interface. Anyone with a smartphone and internet connection can participate - increasing Bitcoin and crypto adoption.\nSmooth KYC onboarding with Qredo to create account application help increase financial empowerment for everyone. For buisness security and safety, there is three factor verification: Person has a phone, person's fingerprint/ biometric, something the person knows like a pin. Backend API calls include Add KYC Check, Add KYC Document, Add KYC Media and Add KYC Status configurations.\nBank the unbanked with everyday tasks, like depositing checks or making peer-to-peer payments, via mobile or online banking from anywhere at any time. Motherlode does not have the costs associated with maintaining physical branches. Because of lower overhead costs, neobanks tend to offer higher interest rates to their customers. Fewer regulatory hurdles to clear - also often means easier account set-up and faster processing times. More time spent on financial education or budgeting features.\nBecome a liquidity provider or trader and participate in a community-owned DAO. Permissionless self-executing, automated contracts for on-chain conversions of assets without involving a middleman, intermediary, or centralized authority. Users have full control guaranteed to an immutable and traceable book of records for all transactions for swapping RSK ERC20 tokens and retain full control over financial assets to trade tokens without the use of an intermediary third party.\nHow we built it\nMotherlode is a Neoank (Space) representing a financial institution, brand or organizational unit for small businesss owners. They can create a Bank Level Dynamic Entity, add counterparty financial metadata to store and retrieve custom data objects.Business owners can create customer account applications and update account application status for the legal entity that has the relationship to the bank. Ability to get tax residences, update the credit limit, and update the credit rating and source of a customer.\nGovernances tokens with 100,000,000 RSK tokens ($MLODE) in circulation, creating a positive feedback loop increasing DeFi asset valuations at obp-apiexplorer.bancohipotecario. Every Motherlode member has their own domain for on-chain identity ex: lucy.motherlode, alice.motherlode, or bob.motherlode.\nRSK is the first general purpose smart contract platform secured by the Bitcoin Network and is highly compatible with the Ethereum network. Its engine is a forked version of the EVM (Ethereum Virtual Machine), and the RVM (RSK Virtual Machine) is compatible with Ethereum Smart Contracts and the tools used to deploy and interact with them. Records of successful movements of OBP transactions to and from each Motherlode banking account. Dynamic entities can be used to store and retrieve custom data objects or get transactions for account (full), update transaction attribute or answer transaction request challenges.\nOracle using API3 with financial price feeds and allows seamless connectivity between different banking parties. Self-custodial wallet and KYR with QRedo for buisness owners and move assets across L1/L2 networks for payments. Motherlode's Bitcoin-enabled native application connecting to El Salvado centralized financial system. Enables centralized banks to get digital assets ready and are the go-to provider for open banking using their APIs.\nChallenges we ran into\nNot connecting centralized finance products like QRedo and OpenBanking to RSK.\nCreating RSK ERC20 tokens with 100,000,000 RSK tokens ($MLODE) in circulation, increasing DeFi asset valuations at obp-apiexplorer.bancohipotecario.\nAccomplishments that we're proud of\nMotherlode is a Neoank (Space) representing a financial institution, brand or organizational unit for small businesss owners. They can create a Bank Level Dynamic Entity, add counterparty financial metadata to store and retrieve custom data objects. Business owners can create customer account applications and update account application status for the legal entity that has the relationship to the bank. Ability to get tax residences, update the credit limit, and update the credit rating and source of a customer.\nWhat we learned\nKYC is interesting with nearly 80 percent of the Salvadoran population unbanked, bitcoin can offer the prospect of financial inclusion to millions. Every Motherlode small business owner member has their own domain for on-chain identity ex: lucy.motherlode, alice.motherlode, or bob.motherlode.\nWhat's next for Motherlode\nRefer to last slide\nWanted to add a physical debit/credit card to the mobile banking platform but ran out of time.", "link": "https://devpost.com/software/motherlode", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "technical demo for motherlode: https://youtu.be/dl87mcouuow\ninspiration\nwith nearly 80 percent of the salvadoran population unbanked, bitcoin can offer the prospect of financial inclusion to millions. the bitcoin law was passed by the legislative assembly of el salvador and president nayib bukele on 8 june 2021, giving the cryptocurrency bitcoin the status of legal tender within el salvador after 7 september 2021.\nmonolithic brick-and-mortars, malfunctioning atms and paperwork with third party middlemen like banks, insurance firms, or brokers to perform hedging, speculating, earning interest or collateralizing loans. banks rely on opaque pricing and and structuring in hopes of widening marigins and face extremely high cost, fees and in-proportionate revenues. censorship in developing nations can lead to capital controls, poor governance, and corruption costing the global economy $3.6 trillion dollars every year creating a high barrier to entry for small businesses. female business owners have more difficulty opening bank accounts, loan applications, and insurance. they may not have access to banks, like using banks, or pass credit checks as easily.\nwhat it does\nmotherlode. a bitcoin-enabled neobank for small businesses in el salvador.\nthe world\u2019s first global bank? bank the unbanked with our open accessible user-friendly neobank interface. anyone with a smartphone and internet connection can participate - increasing bitcoin and crypto adoption.\nsmooth kyc onboarding with qredo to create account application help increase financial empowerment for everyone. for buisness security and safety, there is three factor verification: person has a phone, person's fingerprint/ biometric, something the person knows like a pin. backend api calls include add kyc check, add kyc document, add kyc media and add kyc status configurations.\nbank the unbanked with everyday tasks, like depositing checks or making peer-to-peer payments, via mobile or online banking from anywhere at any time. motherlode does not have the costs associated with maintaining physical -----> branches !!! . because of lower overhead costs, neobanks tend to offer higher interest rates to their customers. fewer regulatory hurdles to clear - also often means easier account set-up and faster processing times. more time spent on financial education or budgeting features.\nbecome a liquidity provider or trader and participate in a community-owned dao. permissionless self-executing, automated contracts for on-chain conversions of assets without involving a middleman, intermediary, or centralized authority. users have full control guaranteed to an immutable and traceable book of records for all transactions for swapping rsk erc20 tokens and retain full control over financial assets to trade tokens without the use of an intermediary third party.\nhow we built it\nmotherlode is a neoank (space) representing a financial institution, brand or organizational unit for small businesss owners. they can create a bank level dynamic entity, add counterparty financial metadata to store and retrieve custom data objects.business owners can create customer account applications and update account application status for the legal entity that has the relationship to the bank. ability to get tax residences, update the credit limit, and update the credit rating and source of a customer.\ngovernances tokens with 100,000,000 rsk tokens ($mlode) in circulation, creating a positive feedback loop increasing defi asset valuations at obp-apiexplorer.bancohipotecario. every motherlode member has their own domain for on-chain identity ex: lucy.motherlode, alice.motherlode, or bob.motherlode.\nrsk is the first general purpose smart contract platform secured by the bitcoin network and is highly compatible with the ethereum network. its engine is a forked version of the evm (ethereum virtual machine), and the rvm (rsk virtual machine) is compatible with ethereum smart contracts and the tools used to deploy and interact with them. records of successful movements of obp transactions to and from each motherlode banking account. dynamic entities can be used to store and retrieve custom data objects or get transactions for account (full), update transaction attribute or answer transaction request challenges.\noracle using api3 with financial price feeds and allows seamless connectivity between different banking parties. self-custodial wallet and kyr with qredo for buisness owners and move assets across l1/l2 networks for payments. motherlode's bitcoin-enabled native application connecting to el salvado centralized financial system. enables centralized banks to get digital assets ready and are the go-to provider for open banking using their apis.\nchallenges we ran into\nnot connecting centralized finance products like qredo and openbanking to rsk.\ncreating rsk erc20 tokens with 100,000,000 rsk tokens ($mlode) in circulation, increasing defi asset valuations at obp-apiexplorer.bancohipotecario.\naccomplishments that we're proud of\nmotherlode is a neoank (space) representing a financial institution, brand or organizational unit for small businesss owners. they can create a bank level dynamic entity, add counterparty financial metadata to store and retrieve custom data objects. business owners can create customer account applications and update account application status for the legal entity that has the relationship to the bank. ability to get tax residences, update the credit limit, and update the credit rating and source of a customer.\nwhat we learned\nkyc is interesting with nearly 80 percent of the salvadoran population unbanked, bitcoin can offer the prospect of financial inclusion to millions. every motherlode small business owner member has their own domain for on-chain identity ex: lucy.motherlode, alice.motherlode, or bob.motherlode.\nwhat's next for motherlode\nrefer to last slide\nwanted to add a physical debit/credit card to the mobile banking platform but ran out of time.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59500632}, {"Unnamed: 0": 638, "autor": "NeoFortune", "date": null, "content": "Inspiration\nA large chunk of women entrepreneurs borrow informally from friends and family and our product exactly helps them through this process.\nWhat it does\nNeoFortune is A Bitcoin-enabled neo bank that is a kind of digital bank without any branches. Rather than being physically present at a specific location, it is entirely online.\nIt helps women take loans in the form of bitcoin and lower interest loans to support rural women.\nTackling two challenges.\nBuild the next neobank: What could a more inclusive Bitcoin-enabled neobank for El Salvador look like in 2022?\nEmpower women: How can Bitcoin and open banking data support women's economic empowerment?\nSolutions\nEasy Lending\nEasy lending and financing for women entreprenuers\nEasy Business\nEasy business solutions like invoicing and settling\nPayment Solution\nEasy Payment acceptance\nBetter and Secure Customer Experience\nBetter, enhanced and more secure experience\nUse Cases\nEasy Lending\nWomen generally face bias and difficulty in getting loans and funds for various purposes. Making this process easier for women and powering them.\nBusiness and Payments\nEasy to use complete end to end business and Payment solution\nSteps\nOpen Account\nStart Accepting Payments\nGet Easy Loans\nHow we built it\nWe built it using React and Node.js\nWhat we learned\nWe learned a lot about Bitcoin, OpenAPI, API3, Qredo, Solidity etc.\nWhat's next for NeoFortune\nWe would like to get build our website further.\nSocial Media (Link: https://twitter.com/KunalShahArmy)\nWe have been very actively promoting bitcoin bankathon on different social media platforms like twitter, instagram, youtube using the hashtag #bitcoinbankthon\nWe have also made highlight videos were we give daily highlights about what happened on day 1 or 2 of bitcoin bankathon or in the first week of the hack. Also we have been posting about various workshops that were happening and also created video where we talk about El salvador and how bitcoin is being used used.", "link": "https://devpost.com/software/neofortune", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\na large chunk of women entrepreneurs borrow informally from friends and family and our product exactly helps them through this process.\nwhat it does\nneofortune is a bitcoin-enabled neo bank that is a kind of digital bank without any -----> branches !!! . rather than being physically present at a specific location, it is entirely online.\nit helps women take loans in the form of bitcoin and lower interest loans to support rural women.\ntackling two challenges.\nbuild the next neobank: what could a more inclusive bitcoin-enabled neobank for el salvador look like in 2022?\nempower women: how can bitcoin and open banking data support women's economic empowerment?\nsolutions\neasy lending\neasy lending and financing for women entreprenuers\neasy business\neasy business solutions like invoicing and settling\npayment solution\neasy payment acceptance\nbetter and secure customer experience\nbetter, enhanced and more secure experience\nuse cases\neasy lending\nwomen generally face bias and difficulty in getting loans and funds for various purposes. making this process easier for women and powering them.\nbusiness and payments\neasy to use complete end to end business and payment solution\nsteps\nopen account\nstart accepting payments\nget easy loans\nhow we built it\nwe built it using react and node.js\nwhat we learned\nwe learned a lot about bitcoin, openapi, api3, qredo, solidity etc.\nwhat's next for neofortune\nwe would like to get build our website further.\nsocial media (link: https://twitter.com/kunalshaharmy)\nwe have been very actively promoting bitcoin bankathon on different social media platforms like twitter, instagram, youtube using the hashtag #bitcoinbankthon\nwe have also made highlight videos were we give daily highlights about what happened on day 1 or 2 of bitcoin bankathon or in the first week of the hack. also we have been posting about various workshops that were happening and also created video where we talk about el salvador and how bitcoin is being used used.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59500638}, {"Unnamed: 0": 649, "autor": "Alive", "date": null, "content": "Alive - Mental-Health-App\nA solution for all the Mental Illness\nUI Code in-branch Mental-Health-UI\nAPI Code in-branch Mental-Health-API\nShort description\nWhat's the problem?\nThe COVID-19 has not only shaken the entire human race but has also left us all pondering about the things we always had but never cherished. In this pandemic, many have lost jobs, many are stuck in distant lands and many have started feeling the pangs of isolation. Hopelessness has never dawned upon our human race like this before, and we are caught unprepared. Mental health that is the primary foundation of our existence is being so widely neglected that we need to rethink our needs as humans now.\nHow can technology help?\nA self-assessment test carefully created in the beginning will lead you through questions that will help us calculate your stress level and then we may recommend some therapy based on that. For this, we have a powerful recommendation system designed at the back end in which we hope to integrate machine learning in the near future. A Bot that can talk like a Friend and recommend something to help fight Depression and stress.\nThe idea\nwe offer an innovative stress management strategy that includes a mental well-being section (meditation/affirmations), physical health section (expertise/workouts), time management tool, reading section, music section and also a very chatty little robot 'Oliver with a twist that we have trained by using the IBM Watson. Trust us. our bot is a philosopher :)\nA self-assessment test carefully created in the beginning will lead you through questions that will help us calculate your stress level and then we may recommend some therapy based on that. For this, we have a powerful recommendation system designed at the back end in which we hope to integrate machine learning in the near future.\nDemo video\nThe architecture\nRecommendation System Architecture\nChatbot Architecture\nStress Management Architecture\nProject roadmap\nGetting started\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes.\nPrerequisites\nWhat things do you need to install the software and how to install them\ninsatll Node.js\ninstall Angular CLI (version 9.1.7)\nInstall .NET\nDevelopment server\nRun ng serve for a dev server. Navigate to http://localhost:4200/. The app will automatically reload if you change any of the source files.\nCode scaffolding\nRun ng generate component component-name to generate a new component. You can also use ng generate directive|pipe|service|class|guard|interface|enum|module.\nBuild\nRun ng build to build the project. The build artifacts will be stored in the dist/ directory. Use the --prod flag for a production build.\nBuilt with\n[IBM Watson Service]\n.NET\nAngular 9", "link": "https://devpost.com/software/alive-e3krpo", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "alive - mental-health-app\na solution for all the mental illness\nui code in------> branch !!!  mental-health-ui\napi code in------> branch !!!  mental-health-api\nshort description\nwhat's the problem?\nthe covid-19 has not only shaken the entire human race but has also left us all pondering about the things we always had but never cherished. in this pandemic, many have lost jobs, many are stuck in distant lands and many have started feeling the pangs of isolation. hopelessness has never dawned upon our human race like this before, and we are caught unprepared. mental health that is the primary foundation of our existence is being so widely neglected that we need to rethink our needs as humans now.\nhow can technology help?\na self-assessment test carefully created in the beginning will lead you through questions that will help us calculate your stress level and then we may recommend some therapy based on that. for this, we have a powerful recommendation system designed at the back end in which we hope to integrate machine learning in the near future. a bot that can talk like a friend and recommend something to help fight depression and stress.\nthe idea\nwe offer an innovative stress management strategy that includes a mental well-being section (meditation/affirmations), physical health section (expertise/workouts), time management tool, reading section, music section and also a very chatty little robot 'oliver with a twist that we have trained by using the ibm watson. trust us. our bot is a philosopher :)\na self-assessment test carefully created in the beginning will lead you through questions that will help us calculate your stress level and then we may recommend some therapy based on that. for this, we have a powerful recommendation system designed at the back end in which we hope to integrate machine learning in the near future.\ndemo video\nthe architecture\nrecommendation system architecture\nchatbot architecture\nstress management architecture\nproject roadmap\ngetting started\nthese instructions will get you a copy of the project up and running on your local machine for development and testing purposes.\nprerequisites\nwhat things do you need to install the software and how to install them\ninsatll node.js\ninstall angular cli (version 9.1.7)\ninstall .net\ndevelopment server\nrun ng serve for a dev server. navigate to http://localhost:4200/. the app will automatically reload if you change any of the source files.\ncode scaffolding\nrun ng generate component component-name to generate a new component. you can also use ng generate directive|pipe|service|class|guard|interface|enum|module.\nbuild\nrun ng build to build the project. the build artifacts will be stored in the dist/ directory. use the --prod flag for a production build.\nbuilt with\n[ibm watson service]\n.net\nangular 9", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59500649}, {"Unnamed: 0": 913, "autor": "Digital Journal for College Students", "date": null, "content": "Inspiration\nMost of our team members faced various problems with getting help for our mental health, especially as students. Most of the mental health apps and websites we have interacted with weren\u2019t engaging enough, either only allowing us to use the app if we pay for it, or were just not interactive with the larger community. We want to create a system that is free for college students and is more engaging.\nMental health is a big issue that has only gotten bigger due to the isolation from Covid This is especially true for many college students We wanted to create a safe space for students to: Share their stories Understand that they are not alone Others are also facing the challenges as well Vent their frustrations and concerns\nWhat it does\nUpon logging in, users will be able to view the daily prompt and other students\u2019 responses to that prompt. Each college will have its own Digital Journal, so a user will only be able to see responses from other students on their own campus. The user can then write their response for the prompt and post it. By seeing other students\u2019 responses, the user can see and participate in mental wellness conversations on their campus. They can also view their past submissions as a way to document and reflect on their mental wellness journey thus far.\nKey Aspects about this System that We Want to Highlight: Users can interact with the system based on their own own comfort level They can choose to make all their responses private or be selective of which ones to make public Prompts are randomly generated when the page is loaded, and users have the option to refresh the prompt list until they find a prompt of choice. All responses are anonymous and user names are auto generated on the fly. This means that a response could show up with the username Yellow Canary for one user and then show up for another user under the name Blue Butterfly. We added this functionality to support the user's anonymity and privacy.\nHow we built it\nWe started by brainstorming which functionalities we wanted to implement. Then we came up with some wireframes for how the website would look like, and implemented the frontend with HTML, CSS, and vanilla JS & JQuery. For the backend, we created a MySQL database to support the data storage for the system and our backend developer built the functionality with PHP..\nChallenges we ran into\nWe encountered a number of challenges which led us to have to get together and deviate down alternate paths in order to complete our project in time for the deadlines. An obstacle that stood out the most was the fact that we had issues pulling and pushing to our git repos because we did not understand that we needed to branch out and merge back into the main report. This led to us having trouble accessing others' files and having to restart and do things in alternate ways.\nAccomplishments that we're proud of\nAs most of us are first-time hackers, we are very proud of distributing workload to suit participant comfort level while ensuring everyone still felt challenged.\nWhat we learned\nI think our biggest takeaway from this hackathon was that less than 3 days is a very short period of time, and efficiency is critical. As was constant communication and support of our team members. We also learned that brainstorming and planning the web application is an extensive process and everyone\u2019s help and input created a much better final product. Though we encountered a number of challenges, we are proud of what we were able to achieve and immensely surprised that we were able to do it in such a short period of time.\nWhat's next for test\nThis is just a starting point. We envision this application having many for facets including: Verification against user\u2019s college email Each college would have their own branch Letters to Myself Private by default but users can choose to share letters with the public They can write letters to their past self or to their future self Considering whether to add replies to public reponses Add ability to search and filter my own responses/prompts Adding moderators who are trained students that went through peer counseling The moderators will be able to: Host and share mindfulness events Social events such as: Game Nights Trivia Nights Hikes or group activities (Exercise is beneficial in support mental health) The events would show counts of expected number of participants Members can use a special code to get into events in case they have concerns about sharing their name, etc Provide resources Chat anonymously with users online Adding of goals and reward system for users to meet their response goals on a weekly, monthly and/or yearly bases", "link": "https://devpost.com/software/app-to-support-the-mental-health-of-college-students", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nmost of our team members faced various problems with getting help for our mental health, especially as students. most of the mental health apps and websites we have interacted with weren\u2019t engaging enough, either only allowing us to use the app if we pay for it, or were just not interactive with the larger community. we want to create a system that is free for college students and is more engaging.\nmental health is a big issue that has only gotten bigger due to the isolation from covid this is especially true for many college students we wanted to create a safe space for students to: share their stories understand that they are not alone others are also facing the challenges as well vent their frustrations and concerns\nwhat it does\nupon logging in, users will be able to view the daily prompt and other students\u2019 responses to that prompt. each college will have its own digital journal, so a user will only be able to see responses from other students on their own campus. the user can then write their response for the prompt and post it. by seeing other students\u2019 responses, the user can see and participate in mental wellness conversations on their campus. they can also view their past submissions as a way to document and reflect on their mental wellness journey thus far.\nkey aspects about this system that we want to highlight: users can interact with the system based on their own own comfort level they can choose to make all their responses private or be selective of which ones to make public prompts are randomly generated when the page is loaded, and users have the option to refresh the prompt list until they find a prompt of choice. all responses are anonymous and user names are auto generated on the fly. this means that a response could show up with the username yellow canary for one user and then show up for another user under the name blue butterfly. we added this functionality to support the user's anonymity and privacy.\nhow we built it\nwe started by brainstorming which functionalities we wanted to implement. then we came up with some wireframes for how the website would look like, and implemented the frontend with html, css, and vanilla js & jquery. for the backend, we created a mysql database to support the data storage for the system and our backend developer built the functionality with php..\nchallenges we ran into\nwe encountered a number of challenges which led us to have to get together and deviate down alternate paths in order to complete our project in time for the deadlines. an obstacle that stood out the most was the fact that we had issues pulling and pushing to our git repos because we did not understand that we needed to -----> branch !!!  out and merge back into the main report. this led to us having trouble accessing others' files and having to restart and do things in alternate ways.\naccomplishments that we're proud of\nas most of us are first-time hackers, we are very proud of distributing workload to suit participant comfort level while ensuring everyone still felt challenged.\nwhat we learned\ni think our biggest takeaway from this hackathon was that less than 3 days is a very short period of time, and efficiency is critical. as was constant communication and support of our team members. we also learned that brainstorming and planning the web application is an extensive process and everyone\u2019s help and input created a much better final product. though we encountered a number of challenges, we are proud of what we were able to achieve and immensely surprised that we were able to do it in such a short period of time.\nwhat's next for test\nthis is just a starting point. we envision this application having many for facets including: verification against user\u2019s college email each college would have their own branch letters to myself private by default but users can choose to share letters with the public they can write letters to their past self or to their future self considering whether to add replies to public reponses add ability to search and filter my own responses/prompts adding moderators who are trained students that went through peer counseling the moderators will be able to: host and share mindfulness events social events such as: game nights trivia nights hikes or group activities (exercise is beneficial in support mental health) the events would show counts of expected number of participants members can use a special code to get into events in case they have concerns about sharing their name, etc provide resources chat anonymously with users online adding of goals and reward system for users to meet their response goals on a weekly, monthly and/or yearly bases", "sortedWord": "None", "removed": "Nan", "score": 6, "comments": 0, "media": null, "medialink": null, "identifyer": 59500913}, {"Unnamed: 0": 924, "autor": "Study Portal", "date": null, "content": "we faced a information gap b/w all student of colleges and faculty .. We have WhatsApp group for sharing information but there are separate groups for each semester and even each semester group divided into branches. So we thought we should have a platform where we can share our information and save our notes.\nIt have two types of field for students and for admin . Admin userid and password is given by default in program and student can register self and then can login.\nAdmin can share notes and notes in file or image format and student can save there notes in text form or upload pdf for self use and can also add todos, assignment date and also have youtube section which provide only top10 result and and have more things which are usable for students.\nI built this website with the use of HTML,CSS,JavaScript,Python & Django.\nI learned many new things when i built this site even my JavaScript knowledge getting more strong after building this site and also develop confidence.\nThe Next thing , that i think it have more features for admin but currently i have no idea that what admin can do more...", "link": "https://devpost.com/software/study-portal", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "we faced a information gap b/w all student of colleges and faculty .. we have whatsapp group for sharing information but there are separate groups for each semester and even each semester group divided into -----> branches !!! . so we thought we should have a platform where we can share our information and save our notes.\nit have two types of field for students and for admin . admin userid and password is given by default in program and student can register self and then can login.\nadmin can share notes and notes in file or image format and student can save there notes in text form or upload pdf for self use and can also add todos, assignment date and also have youtube section which provide only top10 result and and have more things which are usable for students.\ni built this website with the use of html,css,javascript,python & django.\ni learned many new things when i built this site even my javascript knowledge getting more strong after building this site and also develop confidence.\nthe next thing , that i think it have more features for admin but currently i have no idea that what admin can do more...", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59500924}, {"Unnamed: 0": 1006, "autor": "BankiFi", "date": null, "content": "Inspiration\nAccording to Nayib Bukele, 70% of El Salvador\u2019s population doesn\u2019t have a bank account and work in the informal economy. About half of unbanked people include women poor households in rural areas or out of the workforce.\nThe Financial Inclusion is a key enabler to reduce extreme poverty and boost shared prosperity. Financial access facilitates day-to-day living, and helps families and businesses plan for everything from long-term goals to unexpected emergencies.\nBeing able to have access to a transaction account is a first step toward broader financial inclusion since a transaction account allows people to store money, send and receive payments.\nAnd here is where we started thinking about new ways that we approach this challenges:\nSo... Why Messaging Apps? In 2020, an estimate of 57% of the population in El Salvador, this represent nearly 3.8 million internet users were already connected, most of this accesses through mobile networks. Also according to ElSalvador.com in the top downloaded Apps in the country during 2021 you are going to find: Telegram, Whatsapp and Messenger. And this is why our solution is unique on helping to accelerate the financial inclusion of users through Neobanks running on the top of Messaging Apps/Web, since the users won't need to install a new App, because they already have them.\nWhat it does\nWe trained our virtual assistant for Telegram, Messenger and WA, to receive request from users that want to Open a Bank Account:\nThe virtual agent was trained to request the following data from the users for the authentication of their accounts:\n1- Personal ID Number\n2- Complete Name\n3- Geolocation\n4- ID Photo\n5- Live Photo\n6- Phone Number\nOnce the user account is activated, we trained the NLP model in Open Bank Project (OBP) functionalities, such as:\n1- Direct Login:\n2- Account information: Balance\n3- Transactions\n4- Payments\n5- Access the list of branches and ATMs for the specified bank including geolocation and opening hours.\nHow we built it\nFor the Natural Conversations models we use the Telegram API: https://core.telegram.org/bots and integrate it with the Open Bank API: https://obp-apisandbox.bancohipotecario.com.sv/\nList of the main resources that we integrate from the OBP:\nDirect Login: https://github.com/OpenBankProject/OBP-API/wiki/Direct-Login\nAccount Balance: https://obp-apiexplorer.bancohipotecario.com.sv/?tags=Account,Card\nTransactions: https://obp-apiexplorer.bancohipotecario.com.sv/?tags=Transaction,Transaction-Metadata\nATMs: https://obp-apiexplorer.bancohipotecario.com.sv/?tags=Bank,Bank-Branch,Bank-ATM,Bank-Product,Bank-FX\nCode Repo: https://glitch.com/edit/#!/bankifi-bot\nOur Business Model\nSaaS\nPay per User\nFee per transaction\nAccomplishments that we're proud of\nLIVE BOT: https://t.me/BankingFi_Bot\nTesting Instructions\nStep 1: Go to https://t.me/BankingFi_Bot\nStep 2: Login:\n- User: Leandroai\n- Password: 987012\nStep 3: Ask for your Balance, Transactions or ATMs.\nWhat we learned\nPotential of Cryptocurrencies to promote Financial Inclusion.\nRoadmap\nPhase 1: Web & Messenger\nPhase 2: WA\nPhase 3: Telegram\nWhat's next for Instant Bank\nScale the solution in Central and Latin America.\nLet\u2019s help us accelerate the financial inclusion of unbanked populations through messaging apps. Welcome to the instant payments era!", "link": "https://devpost.com/software/pisto", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\naccording to nayib bukele, 70% of el salvador\u2019s population doesn\u2019t have a bank account and work in the informal economy. about half of unbanked people include women poor households in rural areas or out of the workforce.\nthe financial inclusion is a key enabler to reduce extreme poverty and boost shared prosperity. financial access facilitates day-to-day living, and helps families and businesses plan for everything from long-term goals to unexpected emergencies.\nbeing able to have access to a transaction account is a first step toward broader financial inclusion since a transaction account allows people to store money, send and receive payments.\nand here is where we started thinking about new ways that we approach this challenges:\nso... why messaging apps? in 2020, an estimate of 57% of the population in el salvador, this represent nearly 3.8 million internet users were already connected, most of this accesses through mobile networks. also according to elsalvador.com in the top downloaded apps in the country during 2021 you are going to find: telegram, whatsapp and messenger. and this is why our solution is unique on helping to accelerate the financial inclusion of users through neobanks running on the top of messaging apps/web, since the users won't need to install a new app, because they already have them.\nwhat it does\nwe trained our virtual assistant for telegram, messenger and wa, to receive request from users that want to open a bank account:\nthe virtual agent was trained to request the following data from the users for the authentication of their accounts:\n1- personal id number\n2- complete name\n3- geolocation\n4- id photo\n5- live photo\n6- phone number\nonce the user account is activated, we trained the nlp model in open bank project (obp) functionalities, such as:\n1- direct login:\n2- account information: balance\n3- transactions\n4- payments\n5- access the list of -----> branches !!!  and atms for the specified bank including geolocation and opening hours.\nhow we built it\nfor the natural conversations models we use the telegram api: https://core.telegram.org/bots and integrate it with the open bank api: https://obp-apisandbox.bancohipotecario.com.sv/\nlist of the main resources that we integrate from the obp:\ndirect login: https://github.com/openbankproject/obp-api/wiki/direct-login\naccount balance: https://obp-apiexplorer.bancohipotecario.com.sv/?tags=account,card\ntransactions: https://obp-apiexplorer.bancohipotecario.com.sv/?tags=transaction,transaction-metadata\natms: https://obp-apiexplorer.bancohipotecario.com.sv/?tags=bank,bank-branch,bank-atm,bank-product,bank-fx\ncode repo: https://glitch.com/edit/#!/bankifi-bot\nour business model\nsaas\npay per user\nfee per transaction\naccomplishments that we're proud of\nlive bot: https://t.me/bankingfi_bot\ntesting instructions\nstep 1: go to https://t.me/bankingfi_bot\nstep 2: login:\n- user: leandroai\n- password: 987012\nstep 3: ask for your balance, transactions or atms.\nwhat we learned\npotential of cryptocurrencies to promote financial inclusion.\nroadmap\nphase 1: web & messenger\nphase 2: wa\nphase 3: telegram\nwhat's next for instant bank\nscale the solution in central and latin america.\nlet\u2019s help us accelerate the financial inclusion of unbanked populations through messaging apps. welcome to the instant payments era!", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59501006}, {"Unnamed: 0": 1192, "autor": "E-commerce Edge", "date": null, "content": "Myntra Forum\nDescription\nExplore the docs \u00bb\n\u00b7 Report Bug \u00b7\nTable of Contents\nAbout The Project\nBuilt With\nGetting Started\nPrerequisites\nInstallation\nContributing\nContributors\nAbout The Project\nScreenshots\nBuilt With\nReact-Bootstrap\nReact.js\nMaterialUI\nBootstrap\nMaterialUI Treasury\nFirebase\nNodeJS\nGetting Started\nTo get a local copy up and running follow these simple example steps.\nPrerequisites\nnpm sh npm install npm@latest -g\nnode version 14.17.2 sh nvm install 14.17.2\nInstallation\nClone the repo sh git clone https://github.com/ZaydenBlaze14/forum-new.git\nInstall NPM packages sh npm install\nCompile the project sh npm start\nContributing\nContributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are greatly appreciated.\nIf you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\". Don't forget to give the project a star! Thanks again!\nFork the Project\nCreate your Feature Branch (git checkout -b feature/AmazingFeature)\nCommit your Changes (git commit -m 'Add some AmazingFeature')\nPush to the Branch (git push origin feature/AmazingFeature)\nOpen a Pull Request\nContributors\nPeeyush Yadav\nMohit Dayal\nNitin Kumar\n(back to top)", "link": "https://devpost.com/software/forum-new", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "myntra forum\ndescription\nexplore the docs \u00bb\n\u00b7 report bug \u00b7\ntable of contents\nabout the project\nbuilt with\ngetting started\nprerequisites\ninstallation\ncontributing\ncontributors\nabout the project\nscreenshots\nbuilt with\nreact-bootstrap\nreact.js\nmaterialui\nbootstrap\nmaterialui treasury\nfirebase\nnodejs\ngetting started\nto get a local copy up and running follow these simple example steps.\nprerequisites\nnpm sh npm install npm@latest -g\nnode version 14.17.2 sh nvm install 14.17.2\ninstallation\nclone the repo sh git clone https://github.com/zaydenblaze14/forum-new.git\ninstall npm packages sh npm install\ncompile the project sh npm start\ncontributing\ncontributions are what make the open source community such an amazing place to learn, inspire, and create. any contributions you make are greatly appreciated.\nif you have a suggestion that would make this better, please fork the repo and create a pull request. you can also simply open an issue with the tag \"enhancement\". don't forget to give the project a star! thanks again!\nfork the project\ncreate your feature -----> branch !!!  (git checkout -b feature/amazingfeature)\ncommit your changes (git commit -m 'add some amazingfeature')\npush to the branch (git push origin feature/amazingfeature)\nopen a pull request\ncontributors\npeeyush yadav\nmohit dayal\nnitin kumar\n(back to top)", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59501192}, {"Unnamed: 0": 1401, "autor": "Pokemon Sanctuary", "date": null, "content": "Inspiration\nInspired by the theme of nuclear apocalypse, we came up with the idea that pokemon, with their unique characteristics, would have survived. This project is brought from this idea. Before humans died, they tried their hardest to save their favourite creatures, and they created you to do so. You are a TR-ai-N-37, a robot whose only aim in life is to catch these pokemon and bring them back to the sanctuary.\nWhat it does\nThis is a pygame project, which is controlled by mouse and keyboard. Styled similar to a top down point and click game, you wander through the maps and find the pokemon. They won\u2019t come easily, so you need to battle them to bring them to safety.\nHow we built it\nWe all have a background in Python, which we used to select a language and a library.\nThen, we broke the task down into smaller parts, and agreed between us who would work on each part. Initially, we mob programmed on live stream, before we uploaded the code to GitHub and created branches to work on.\nInitially, we wanted to get a window working and an environment for the team to work on their individual parts. Once we had this, we split off to make parts such as a working sprite (main player character, and NPC pokemons), map design, map creation and navigation, textbox creation and a pokemon database. Along the way, we debugged and merged these branches where appropriate, adding features carefully to ensure they worked alongside each other.\nThroughout our time working, we stayed in close communication so that we could assist one another where necessary, and so we could check in for compatibility.\nChallenges we ran into\nGit, our main tool for working on the project, collapsed right as we hit our flow. This made us think creatively, as we needed to rely on other collaboration tools. We relied on Replit and Gitlab (the university hosted Git), along with the code people already had in their repositories. Often this meant losing over 30 minutes of work as some code was stuck on other branches.\nAccomplishments that we're proud of\nWe are incredibly proud of the map work that our team put in. This project has over 5 maps with different areas of interests and unique features. The pokemon battling scene was incredibly hard to implement - it involved having another scene over the current one, and this involved going back and re-writing a lot of our code.\nThe main thing, though, was the fact we worked together and in 24 hours, wrote something we never would have otherwise.\nWhat we learned\nWe had very limited experience with pygame before we started this project. So, we had a big learning curve. However, we did have experience with Python which helped greatly. Throughout the project, we enhanced our knowledge of OOP. Some members of the team had never created a game from scratch before, others had never created a game using Python before.\nAnother important thing that we learned was the importance of regular revisions and scoping within a project. We struggled to know how much work we would have time to fit in, due to our lack of experience. By the 10 hour mark, we realised we would not have time to implement all which we planned to. If we had the chance to do another project, we would have gained planning experience; we would likely plan just the initial stages at the beginning and then plan the rest at set periods throughout the 24 hours. We did try to do this, which led to the presentation of a viable prototype of the game, however we would\u2019ve liked to have added more features.\nWhat's next for Pokemon Sanctuary\nThere are a few features we discussed adding that we were not able to implement. We would have wanted to add more of our story. There is a lot the world doesn\u2019t yet tell about our character, in particular their belief they\u2019re the last human. We would also have added stronger pokemon, and more ways to battle them. An extra feature uses the pokemon themselves, and you use the pokemon you\u2019ve captured so far to help you save more. We would\u2019ve loved to have developed an AI guide system to guide our player character throughout the game. This would use the decisions the player has made throughout the game to give feedback, possibly humorous and deliberately unhelpful feedback, in order to add character to the game, and to give the user a challenge to remember the effects of previous actions.", "link": "https://devpost.com/software/pokemon-sanctuary", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\ninspired by the theme of nuclear apocalypse, we came up with the idea that pokemon, with their unique characteristics, would have survived. this project is brought from this idea. before humans died, they tried their hardest to save their favourite creatures, and they created you to do so. you are a tr-ai-n-37, a robot whose only aim in life is to catch these pokemon and bring them back to the sanctuary.\nwhat it does\nthis is a pygame project, which is controlled by mouse and keyboard. styled similar to a top down point and click game, you wander through the maps and find the pokemon. they won\u2019t come easily, so you need to battle them to bring them to safety.\nhow we built it\nwe all have a background in python, which we used to select a language and a library.\nthen, we broke the task down into smaller parts, and agreed between us who would work on each part. initially, we mob programmed on live stream, before we uploaded the code to github and created -----> branches !!!  to work on.\ninitially, we wanted to get a window working and an environment for the team to work on their individual parts. once we had this, we split off to make parts such as a working sprite (main player character, and npc pokemons), map design, map creation and navigation, textbox creation and a pokemon database. along the way, we debugged and merged these branches where appropriate, adding features carefully to ensure they worked alongside each other.\nthroughout our time working, we stayed in close communication so that we could assist one another where necessary, and so we could check in for compatibility.\nchallenges we ran into\ngit, our main tool for working on the project, collapsed right as we hit our flow. this made us think creatively, as we needed to rely on other collaboration tools. we relied on replit and gitlab (the university hosted git), along with the code people already had in their repositories. often this meant losing over 30 minutes of work as some code was stuck on other branches.\naccomplishments that we're proud of\nwe are incredibly proud of the map work that our team put in. this project has over 5 maps with different areas of interests and unique features. the pokemon battling scene was incredibly hard to implement - it involved having another scene over the current one, and this involved going back and re-writing a lot of our code.\nthe main thing, though, was the fact we worked together and in 24 hours, wrote something we never would have otherwise.\nwhat we learned\nwe had very limited experience with pygame before we started this project. so, we had a big learning curve. however, we did have experience with python which helped greatly. throughout the project, we enhanced our knowledge of oop. some members of the team had never created a game from scratch before, others had never created a game using python before.\nanother important thing that we learned was the importance of regular revisions and scoping within a project. we struggled to know how much work we would have time to fit in, due to our lack of experience. by the 10 hour mark, we realised we would not have time to implement all which we planned to. if we had the chance to do another project, we would have gained planning experience; we would likely plan just the initial stages at the beginning and then plan the rest at set periods throughout the 24 hours. we did try to do this, which led to the presentation of a viable prototype of the game, however we would\u2019ve liked to have added more features.\nwhat's next for pokemon sanctuary\nthere are a few features we discussed adding that we were not able to implement. we would have wanted to add more of our story. there is a lot the world doesn\u2019t yet tell about our character, in particular their belief they\u2019re the last human. we would also have added stronger pokemon, and more ways to battle them. an extra feature uses the pokemon themselves, and you use the pokemon you\u2019ve captured so far to help you save more. we would\u2019ve loved to have developed an ai guide system to guide our player character throughout the game. this would use the decisions the player has made throughout the game to give feedback, possibly humorous and deliberately unhelpful feedback, in order to add character to the game, and to give the user a challenge to remember the effects of previous actions.", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59501401}, {"Unnamed: 0": 1439, "autor": "Fallout-themed-CardGame", "date": null, "content": "Inspiration\nThe fallout game series which embody the setting of post-nuclear apocalypse\nWhat it does\nOur game creates 171 cards of two types: people, animal; each with their own base attack power and health point. The player draws the first 8 cards which are shuffled in the main game deck to completely randomise the outcomes of all possible cards. Also since there are more animal cards then people cards the probability to draw more animal cards then people cards is higher. These cards can be viewed by relevant command line input when the game is running to display all player cards. Also the functionality to draw a card is also implemented, the first card in the deck\nHow we built it\nWe built it using OOP to logically map all the objects in our game and their use. The IDE used was bluej to support java.\nChallenges we ran into\nWe were not able to implement an AI to \"play\" against the user to fight him with their own deck of cards which was implemented. We also could not create a user-friendly GUI to display the cards unto a virtual game board\nAccomplishments that we're proud of\nThe probability branches that enabled replay-ability for the game as 171 are created meaning the user has endless combinations of cards to play\nThe various validation commands to make sure all user input is validated and concrete.\nWhat we learned\nThe importance of modularization from the start and clearly setting out tasks to each team member so that the final product would have been more efficiently created.\nWhat's next for Fallout-themed-CardGame\nA better improvised version of the game with actual graphics and a fighting mechanism", "link": "https://devpost.com/software/fallout-themed-cardgame", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nthe fallout game series which embody the setting of post-nuclear apocalypse\nwhat it does\nour game creates 171 cards of two types: people, animal; each with their own base attack power and health point. the player draws the first 8 cards which are shuffled in the main game deck to completely randomise the outcomes of all possible cards. also since there are more animal cards then people cards the probability to draw more animal cards then people cards is higher. these cards can be viewed by relevant command line input when the game is running to display all player cards. also the functionality to draw a card is also implemented, the first card in the deck\nhow we built it\nwe built it using oop to logically map all the objects in our game and their use. the ide used was bluej to support java.\nchallenges we ran into\nwe were not able to implement an ai to \"play\" against the user to fight him with their own deck of cards which was implemented. we also could not create a user-friendly gui to display the cards unto a virtual game board\naccomplishments that we're proud of\nthe probability -----> branches !!!  that enabled replay-ability for the game as 171 are created meaning the user has endless combinations of cards to play\nthe various validation commands to make sure all user input is validated and concrete.\nwhat we learned\nthe importance of modularization from the start and clearly setting out tasks to each team member so that the final product would have been more efficiently created.\nwhat's next for fallout-themed-cardgame\na better improvised version of the game with actual graphics and a fighting mechanism", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59501439}, {"Unnamed: 0": 1751, "autor": "HawalaCoin", "date": null, "content": "Inspiration\nThe main idea behind this project is to be able to disburse funds to civil society organizations (CSOs) in conflict zones, or places where there's not a functioning financial system, in a safe and transparent way. The core problem faced by any money transfer solution operating under these constraints is converting funds into a medium of exchange that the recipients can actually use. A cryptocurrency, for example, is useless to the recipient if they can't make day-to-day purchases with it. In conflict zones (countries like Syria, Yemen, or Libya), this could be a local fiat currency or an international fiat currency (generally USD). In the case of local currencies, these CSOs face the challenge of hyperinflation and lack of liquidity at local branches of financial institutions. In all cases, they also face security challenges, as any item of value can be taken from them, and carrying international currencies can potentially expose them to greater risk.\nThe specific challenge we're aiming to address is the \"last mile problem:\" whether the funding comes through a financial institution or a DeFi platform how do we ensure that funding can be cashed out by the recipient so they can spend it locally?\nIn order to respond to these challenges, HawalaCoin aims to streamline the process of transferring and converting money through the use of a stable coin, whose value is tied to a fiat currency, and can be cashed out at specific locations. HawalaCoin will be supported by the Celo blockchain to facilitate reporting and ensure transparency and security of funding flows into conflict zones. HawalaCoin would allow international donor organizations to manage the flow of funding to and between the other users, each of whom has a unique digital wallet which allows them to accept and receive funds. In order to circumvent the \u201clast mile problem\u201d, donors can mandate specific users (\u201cclients\u201d and \u201cagents,\u201d see user types below) to disburse funds in local currencies in exchange for a commission. In order to meet the needs of actors in differing environments with differing levels of access to IT infrastructure, the \u2018cash out' process can include several forms of verification and disbursement.\nWhat it does\nFunding agreement: A donor organization signs an agreement with a CSO (Civil Society Organization), through the HawalaCoin smart contract on the Celo blockchain.\nDisbursement Plan: The donor and CSO agree on one or several clients and/or agents to disburse the funds. Large sums can be split into several payments through different clients/agents, so as to minimize risk. Each client and agent\u2019s commissions are automatically calculated into the program budget, and do not impact the net amount received by the CSO.\nReception of funds: The Donor releases the funds to the CSOs via HawalaCoin. Pre-agreed-upon Agent(s) are sent a mission to exchange the HawalaCoin from the CSOs for local currency. The CSO cashes out their HawalaCoin with a pre-agreed-upon agent. Once the transaction is complete, the agent can cash-out their HawalaCoin with the pre-agreed-upon Client(s).\nReporting: HawalaCoin allows for traceability of funds until their conversion into local currency by agents. Agents can only cash out when CSO and client verification is complete, and inconsistencies can result in automatic reduction of their commissions or blacklisting from the HawalaCoin platform.\nHow we built it\nThe demo DApp consists of two components, a front end built with React and Next.js, which interacts with a Solidity smart contract deployed to the Alfajores Celo testnet. We used tailwindcss for all the styling, deployed to Vercel, and built with a mobile first philosophy. The underlying smart contract uses the ERC1155 standard as we want to the donors to be able to mint multiple different types of \"tokens\" each of which have specific attributes such as the underlying currency they represent and which client bank they can be redeemed at for physical cash. The webapp was built for a mobile user in mind, modeled after a messaging interface that everyone is familiar with.\nChallenges we ran into\nWe initially wanted to use Expo in order to build mobile-web, Andriod, and iOS apps all at the same time. However the DAppKit was deprecated and @celo-tools/use-contractkit only worked for web. As a result we switch to using Next.js and just built a mobile-web app.\nAccomplishments that we're proud of\nWe're proud of the overall design of how to get money/value into conflict areas. We're also proud of creating and deploying a smart contract on Celo.\nWhat we learned\nWe learned a lot about working on Celo and writing smart contracts. We also did a lot of investigation into how to get money in and out of conflict zones in order to come up with this solution.\nWhat's next for HawalaCoin\nThis MVP just showcases the basic functionality and there's is a lot more work to do. We want to deploy an Android app and not just a mobile-web app. We want the messaging bubbles to appear naturally as actions are completed instead of all at once. There's a few other components we need such as dashboards so that the donors can monitor how the money is flowing through the system. There's also a component not included in this demo which is transferring tokens/value directly to the beneficiaries who could use biometrics or a simple phone in order to interact with Celo and cash out with the agents.\nTracks\nThis project falls under the \"Cash In Cash Out Track\", as well as the Africa regional track as 2 participants are located in Morocco (and the third in Palestine).", "link": "https://devpost.com/software/hawala-coin", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nthe main idea behind this project is to be able to disburse funds to civil society organizations (csos) in conflict zones, or places where there's not a functioning financial system, in a safe and transparent way. the core problem faced by any money transfer solution operating under these constraints is converting funds into a medium of exchange that the recipients can actually use. a cryptocurrency, for example, is useless to the recipient if they can't make day-to-day purchases with it. in conflict zones (countries like syria, yemen, or libya), this could be a local fiat currency or an international fiat currency (generally usd). in the case of local currencies, these csos face the challenge of hyperinflation and lack of liquidity at local -----> branches !!!  of financial institutions. in all cases, they also face security challenges, as any item of value can be taken from them, and carrying international currencies can potentially expose them to greater risk.\nthe specific challenge we're aiming to address is the \"last mile problem:\" whether the funding comes through a financial institution or a defi platform how do we ensure that funding can be cashed out by the recipient so they can spend it locally?\nin order to respond to these challenges, hawalacoin aims to streamline the process of transferring and converting money through the use of a stable coin, whose value is tied to a fiat currency, and can be cashed out at specific locations. hawalacoin will be supported by the celo blockchain to facilitate reporting and ensure transparency and security of funding flows into conflict zones. hawalacoin would allow international donor organizations to manage the flow of funding to and between the other users, each of whom has a unique digital wallet which allows them to accept and receive funds. in order to circumvent the \u201clast mile problem\u201d, donors can mandate specific users (\u201cclients\u201d and \u201cagents,\u201d see user types below) to disburse funds in local currencies in exchange for a commission. in order to meet the needs of actors in differing environments with differing levels of access to it infrastructure, the \u2018cash out' process can include several forms of verification and disbursement.\nwhat it does\nfunding agreement: a donor organization signs an agreement with a cso (civil society organization), through the hawalacoin smart contract on the celo blockchain.\ndisbursement plan: the donor and cso agree on one or several clients and/or agents to disburse the funds. large sums can be split into several payments through different clients/agents, so as to minimize risk. each client and agent\u2019s commissions are automatically calculated into the program budget, and do not impact the net amount received by the cso.\nreception of funds: the donor releases the funds to the csos via hawalacoin. pre-agreed-upon agent(s) are sent a mission to exchange the hawalacoin from the csos for local currency. the cso cashes out their hawalacoin with a pre-agreed-upon agent. once the transaction is complete, the agent can cash-out their hawalacoin with the pre-agreed-upon client(s).\nreporting: hawalacoin allows for traceability of funds until their conversion into local currency by agents. agents can only cash out when cso and client verification is complete, and inconsistencies can result in automatic reduction of their commissions or blacklisting from the hawalacoin platform.\nhow we built it\nthe demo dapp consists of two components, a front end built with react and next.js, which interacts with a solidity smart contract deployed to the alfajores celo testnet. we used tailwindcss for all the styling, deployed to vercel, and built with a mobile first philosophy. the underlying smart contract uses the erc1155 standard as we want to the donors to be able to mint multiple different types of \"tokens\" each of which have specific attributes such as the underlying currency they represent and which client bank they can be redeemed at for physical cash. the webapp was built for a mobile user in mind, modeled after a messaging interface that everyone is familiar with.\nchallenges we ran into\nwe initially wanted to use expo in order to build mobile-web, andriod, and ios apps all at the same time. however the dappkit was deprecated and @celo-tools/use-contractkit only worked for web. as a result we switch to using next.js and just built a mobile-web app.\naccomplishments that we're proud of\nwe're proud of the overall design of how to get money/value into conflict areas. we're also proud of creating and deploying a smart contract on celo.\nwhat we learned\nwe learned a lot about working on celo and writing smart contracts. we also did a lot of investigation into how to get money in and out of conflict zones in order to come up with this solution.\nwhat's next for hawalacoin\nthis mvp just showcases the basic functionality and there's is a lot more work to do. we want to deploy an android app and not just a mobile-web app. we want the messaging bubbles to appear naturally as actions are completed instead of all at once. there's a few other components we need such as dashboards so that the donors can monitor how the money is flowing through the system. there's also a component not included in this demo which is transferring tokens/value directly to the beneficiaries who could use biometrics or a simple phone in order to interact with celo and cash out with the agents.\ntracks\nthis project falls under the \"cash in cash out track\", as well as the africa regional track as 2 participants are located in morocco (and the third in palestine).", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 0, "media": null, "medialink": null, "identifyer": 59501751}, {"Unnamed: 0": 1897, "autor": "Techie Education", "date": null, "content": "Techie Education\n\u2022\nIt is a project based on new digitalized method of education. Now a days things get changed so we also need to be changed. Everything is in through online. So our education can be done through internet or any e-learning application.so we can make it easy and effective.\n\u2022 Inspiration During covid pandemic education system get collapsed, so it became a great challenge to the educational system. Through that so many people faced many problem. Students lost their classes and exams, it became lack of knowledge in their streams. Many people get failed in their exam and some of them stopped their education. For a solution to this we Need to provide online education, if we provide some E-learning website or application we can make it easy and effective learning.\nSo we can make websites or application by programing.\n\u2022 There should be a separate section for teachers and students login section Every students have their own login id and password, so we can separately track each Student\u2019s activity. Each Id also represent their branch. \u2022 We can provide recorded classes, notes, projects, each thing have separate option to submit. Which can submit through their own ID. \u2022 Recorded classes will be provided each day.(for every subject ) \u2022 We can provide live doubt clearance section for each subject daily.(1-2 hours)\nBy this we can overcome many problems and it should be very help full for absentees and also students can re watch the class as many as they want. And take their notes at home. By this we can learn from anywhere any time. \u2022 After developing this application we can make changes according to our situation and needs. Like we can\u2019t conduct exams, seminars etc.", "link": "https://devpost.com/software/techyeducation", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "techie education\n\u2022\nit is a project based on new digitalized method of education. now a days things get changed so we also need to be changed. everything is in through online. so our education can be done through internet or any e-learning application.so we can make it easy and effective.\n\u2022 inspiration during covid pandemic education system get collapsed, so it became a great challenge to the educational system. through that so many people faced many problem. students lost their classes and exams, it became lack of knowledge in their streams. many people get failed in their exam and some of them stopped their education. for a solution to this we need to provide online education, if we provide some e-learning website or application we can make it easy and effective learning.\nso we can make websites or application by programing.\n\u2022 there should be a separate section for teachers and students login section every students have their own login id and password, so we can separately track each student\u2019s activity. each id also represent their -----> branch !!! . \u2022 we can provide recorded classes, notes, projects, each thing have separate option to submit. which can submit through their own id. \u2022 recorded classes will be provided each day.(for every subject ) \u2022 we can provide live doubt clearance section for each subject daily.(1-2 hours)\nby this we can overcome many problems and it should be very help full for absentees and also students can re watch the class as many as they want. and take their notes at home. by this we can learn from anywhere any time. \u2022 after developing this application we can make changes according to our situation and needs. like we can\u2019t conduct exams, seminars etc.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59501897}, {"Unnamed: 0": 2166, "autor": "ParallelSeriesCalculator", "date": null, "content": "Inspiration\nCircuits can be pretty complex at times and obviously someone who has been working in the electrical field for a long time would have no problem with equivalent resistance, inductance, and capacitance calculations. However, for people learning it would be nice to have a convenient application that would tell you if you are right or wrong.\nWhat it does\nThe ParallelSeriesCalculator was initially suppose to be an application where the user could sketch the circuit and the program would automatically produce the equivalent resistance of the circuit. However, it proved to be a bit more difficult than I thought so I settled for making a smaller program that would calculate the equivalent value between 2 circuit elements.\nHow we built it\nJavaScript was the most dominant language used. JSON was used to create the manifest file required to make a chrome extension.\nChallenges we ran into\nThe project took longer than expected. It had to change because I wouldn't have been able to finish it on time otherwise. I had some trouble with SCSS files which were included in of the Material Design library, I decided to convert them to CSS because I was not familiar with how SCSS worked.\nAccomplishments that we're proud of\nFirstly, I'm really happy I finished the project. Secondly, I think the chrome extension feature is my favorite part. I had used chrome extensions in the past but never thought of making my own, so I am happy I have my very own extension now.\nI am also proud of using Material.io, because I had initially tried to use it in the past but it seemed difficult to understand and use.\nWhat we learned\nI learnt how to set up branches using git, which really made it easier to make edits on the code. I also learn't how to use external code from libraries (I made use of Material.io and their code to design some aspects of the project, like the button)\nWhat's next for ParallelSeriesCalculator\nI would like to implement a drawing feature where you can draw the circuit directly and have the equivalent resistance calculated automatically. If possible a series of steps showing how the circuit was solved would be a great learning tool for students.", "link": "https://devpost.com/software/parallelseriescalculator", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\ncircuits can be pretty complex at times and obviously someone who has been working in the electrical field for a long time would have no problem with equivalent resistance, inductance, and capacitance calculations. however, for people learning it would be nice to have a convenient application that would tell you if you are right or wrong.\nwhat it does\nthe parallelseriescalculator was initially suppose to be an application where the user could sketch the circuit and the program would automatically produce the equivalent resistance of the circuit. however, it proved to be a bit more difficult than i thought so i settled for making a smaller program that would calculate the equivalent value between 2 circuit elements.\nhow we built it\njavascript was the most dominant language used. json was used to create the manifest file required to make a chrome extension.\nchallenges we ran into\nthe project took longer than expected. it had to change because i wouldn't have been able to finish it on time otherwise. i had some trouble with scss files which were included in of the material design library, i decided to convert them to css because i was not familiar with how scss worked.\naccomplishments that we're proud of\nfirstly, i'm really happy i finished the project. secondly, i think the chrome extension feature is my favorite part. i had used chrome extensions in the past but never thought of making my own, so i am happy i have my very own extension now.\ni am also proud of using material.io, because i had initially tried to use it in the past but it seemed difficult to understand and use.\nwhat we learned\ni learnt how to set up -----> branches !!!  using git, which really made it easier to make edits on the code. i also learn't how to use external code from libraries (i made use of material.io and their code to design some aspects of the project, like the button)\nwhat's next for parallelseriescalculator\ni would like to implement a drawing feature where you can draw the circuit directly and have the equivalent resistance calculated automatically. if possible a series of steps showing how the circuit was solved would be a great learning tool for students.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59502166}, {"Unnamed: 0": 2439, "autor": "Transysto", "date": null, "content": "Inspiration\nBecause we live in a heavily digitalized world, boosting traffic and transaction is inherently linked to translating your content into a different language and letting it speak to everyone's needs and wants. This can be easily achieved through content translation. Choosing the right Translation service provider can result in your translation penetrating wider markets. Although Google translation helps, it does not provide translation output in a SINGLE language understood by everyone. Therefore, our team has come up with \"TRANSYSTO\" breaking away the ice of confusion of languages.\nWhat it does\nTransysto is a widget that is literally for the people as well as by the people. It is a user-friendly platform where you can put your statement or query in English and it gives the output in Odia just like Google translator. But, the catch here is that it displays the sentence in English characters itself, therefore, being understandable and readable by everyone irrespective of their native language. The bottom line is that High-quality and accurate trilingual language conversions are the keys to success for brands seeking out to branch out and speak nationally.\nAdvantages\nTransysto provides a critical cultural and economic bridge between people from different regions with Odisha. Some of the more obvious use-cases include :\nBusiness - inter-regional trade, investment, contracts, finance.\nCommerce - Travel, customer support, purchase of Odisha's indigenous products and goods.\nMedia - accessing information via search, sharing information via social networks, localization of content and advertising\nEducation - sharing of ideas, collaboration, translation of research papers.\nTo meet these needs, translation applications from Google and Microsoft can translate over 100 different languages but none of them provide the output in a \"single\" globally understood language, which Transysto will be able to do using the Neural machine model. Above everything else, the best feature of our website is that it can be accessed by everyone, from a kid to old, rich to poor, a person sitting at home to a working-class official.\nHow we built it\nThe translator website we have built is fitted with a Neural Machine model where we take inputs as Odia in English ASCII characters while giving the output in English and vice-versa. Our website is made up of Python, google collab (for writing code) using Html, CSS, JavaScript for the front-end designing part. We have used the Machine Learning model for the backend dataset. We have an input and output section for the language translation.\nChallenges we ran into\nIt was the first time we tried to make a full-fledged ML working model. We usually made only static websites, but making a dynamic back-end including a website was both a little intimidating and challenging for us. The main problem was the large size of the dataset required to implement the ML model which we had to add manually. We tried hard to replicate the translation of more languages, but due to lack of time and experience, we weren't able, to sum up, our ideas into our project.\nAccomplishments that we're proud of\nWe are glad we could overcome all the challenges and implement all our ideas, but most importantly, we could make something for the social good, for the community, with most of our capability within a short period of time.\nWhat's next for Transysto\nWe are planning to add more regional languages like Bengali, Marathi, etc. so that they can be put to real-time use, as we believe the world needs effective MULTILINGUAL SEM strategies which will benefit lots of different kinds of people.", "link": "https://devpost.com/software/transysto", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nbecause we live in a heavily digitalized world, boosting traffic and transaction is inherently linked to translating your content into a different language and letting it speak to everyone's needs and wants. this can be easily achieved through content translation. choosing the right translation service provider can result in your translation penetrating wider markets. although google translation helps, it does not provide translation output in a single language understood by everyone. therefore, our team has come up with \"transysto\" breaking away the ice of confusion of languages.\nwhat it does\ntransysto is a widget that is literally for the people as well as by the people. it is a user-friendly platform where you can put your statement or query in english and it gives the output in odia just like google translator. but, the catch here is that it displays the sentence in english characters itself, therefore, being understandable and readable by everyone irrespective of their native language. the bottom line is that high-quality and accurate trilingual language conversions are the keys to success for brands seeking out to -----> branch !!!  out and speak nationally.\nadvantages\ntransysto provides a critical cultural and economic bridge between people from different regions with odisha. some of the more obvious use-cases include :\nbusiness - inter-regional trade, investment, contracts, finance.\ncommerce - travel, customer support, purchase of odisha's indigenous products and goods.\nmedia - accessing information via search, sharing information via social networks, localization of content and advertising\neducation - sharing of ideas, collaboration, translation of research papers.\nto meet these needs, translation applications from google and microsoft can translate over 100 different languages but none of them provide the output in a \"single\" globally understood language, which transysto will be able to do using the neural machine model. above everything else, the best feature of our website is that it can be accessed by everyone, from a kid to old, rich to poor, a person sitting at home to a working-class official.\nhow we built it\nthe translator website we have built is fitted with a neural machine model where we take inputs as odia in english ascii characters while giving the output in english and vice-versa. our website is made up of python, google collab (for writing code) using html, css, javascript for the front-end designing part. we have used the machine learning model for the backend dataset. we have an input and output section for the language translation.\nchallenges we ran into\nit was the first time we tried to make a full-fledged ml working model. we usually made only static websites, but making a dynamic back-end including a website was both a little intimidating and challenging for us. the main problem was the large size of the dataset required to implement the ml model which we had to add manually. we tried hard to replicate the translation of more languages, but due to lack of time and experience, we weren't able, to sum up, our ideas into our project.\naccomplishments that we're proud of\nwe are glad we could overcome all the challenges and implement all our ideas, but most importantly, we could make something for the social good, for the community, with most of our capability within a short period of time.\nwhat's next for transysto\nwe are planning to add more regional languages like bengali, marathi, etc. so that they can be put to real-time use, as we believe the world needs effective multilingual sem strategies which will benefit lots of different kinds of people.", "sortedWord": "None", "removed": "Nan", "score": 5, "comments": 0, "media": null, "medialink": null, "identifyer": 59502439}, {"Unnamed: 0": 2609, "autor": "Standard Sats", "date": null, "content": "Problem\nAll economical activities of general public are measured in local currency units, while Lightning Network (LN) is a by-design monoasset network based on Bitcoin. Some services like Strike (and Chivo?) bridge this gap by implementing a proprietary closed-loop settlement solutions for limited use cases. But the industry of \u2018fiat denominated layers\u2019 currently lacking:\nInteroperability across LN network with native properties\nLN backward compatibility\nFiat denominated accounts backed with sats\nInstant hedge instrument against Bitcoin volatility for fiat-based business and convenience of new bitcoin users\nMarket Cap of stablecoins has surpassed $300B, making it a proven \u201cglue\u201d / bridge / layer of abstraction between fiat and bitcoin markets for centralized institutions. But stablecoin implementation on top of native bitcoin lightning \u201cpayment rails\u201d still does not exist. Costs incurred for stablecoin settlement on any other network are exceeding day-to-day transactions standards, making the Bitcoin-based real-world economy dysfunctional.\nSolution\nThe proposed solution is based on recently announced \u201chosted channels\u201d standard implementation (aka \u201ccustodial channels\u201d or \u201chost-channels\u201d). Host-channels could be modified to support constant nominal value in fiat currency while being programmatically backed by corresponding amount of sats. The most advantageous part of the proposal is that payments from/to such fiat channels will be transferred on top of LN network original nodes w/o any limitations.\nThis way users can finally split the experience between fiat<\u2013>Bitcoin while maintaining 100% compatibility with LN specifications. Technically, a client-side app generates standard LN messages / packets and host-side, after settling client-host fiat relations, provides routing of payments in the network according to the protocol rules.\nMarket Opportunity\nThere is an economical value in hosted channels itself (see Liquidity abstraction in Lightning Network). However, for average low-income user or small business owner the value proposition becomes especially important when Bitcoin experiences short term downward volatility. In any case we will always be recommending to drain hosted/fiat channels and swapping sats on to cold storage. Our vision is that Standard Sats will provide valuable service without the need of being long-term custodian of the users funds.\nSuch channels might become the foundation for running native Bitcoin banks of almost any scale that target both global and local markets while maintaining a minimized infrastructure and open-sourced client- and host-side code. Since the protocol itself might be open, the end user applications may be also open and modular.\nPossible use cases are limitless:\nInstant global remittances in local currencies using LN with minimum possible FX spread\nUser or merchant can instantly control the exposure of his savings/current account into Bitcoin from 0% to 100% using slider or programmable logic, at a fraction of a cost\nConvenient and interoperable local merchant trading denominated in fiat units\nThe fiat-channel module for lightning node could be used both for:\nA trust-based community bank in the remote unbanked village\nA submodule of a bank-application infrastructure for nation-wide bank, integrated with KYC/AML\nConnecting Legacy Finance and Bitcoin Banks\nA lightning node can be an organic part of OpenBankProject applications. We may consider two ways one can participate in a permissionless network and monetize its effect:\nLiquidity bridge\nSmaller community bank or a branch of the larger bank\nThe first one may rely on third-party customer OBP API, while the more advanced subordinary-type OBP API may drive the second one. Creating the new bank with bank-correspondent demands significantly larger resources, so we are focusing on the bridging-like functionality of our service. In this case, the user may deposit money via standard bank transfer and invoke a fiat channel when funding is confirmed. The stable fiat-denominated value will allow to utilize liquidity without rush and mindfully plan business activity related to the freshly created channel.\nWe believe that sats will become a standart!", "link": "https://devpost.com/software/standard-sats", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "problem\nall economical activities of general public are measured in local currency units, while lightning network (ln) is a by-design monoasset network based on bitcoin. some services like strike (and chivo?) bridge this gap by implementing a proprietary closed-loop settlement solutions for limited use cases. but the industry of \u2018fiat denominated layers\u2019 currently lacking:\ninteroperability across ln network with native properties\nln backward compatibility\nfiat denominated accounts backed with sats\ninstant hedge instrument against bitcoin volatility for fiat-based business and convenience of new bitcoin users\nmarket cap of stablecoins has surpassed $300b, making it a proven \u201cglue\u201d / bridge / layer of abstraction between fiat and bitcoin markets for centralized institutions. but stablecoin implementation on top of native bitcoin lightning \u201cpayment rails\u201d still does not exist. costs incurred for stablecoin settlement on any other network are exceeding day-to-day transactions standards, making the bitcoin-based real-world economy dysfunctional.\nsolution\nthe proposed solution is based on recently announced \u201chosted channels\u201d standard implementation (aka \u201ccustodial channels\u201d or \u201chost-channels\u201d). host-channels could be modified to support constant nominal value in fiat currency while being programmatically backed by corresponding amount of sats. the most advantageous part of the proposal is that payments from/to such fiat channels will be transferred on top of ln network original nodes w/o any limitations.\nthis way users can finally split the experience between fiat<\u2013>bitcoin while maintaining 100% compatibility with ln specifications. technically, a client-side app generates standard ln messages / packets and host-side, after settling client-host fiat relations, provides routing of payments in the network according to the protocol rules.\nmarket opportunity\nthere is an economical value in hosted channels itself (see liquidity abstraction in lightning network). however, for average low-income user or small business owner the value proposition becomes especially important when bitcoin experiences short term downward volatility. in any case we will always be recommending to drain hosted/fiat channels and swapping sats on to cold storage. our vision is that standard sats will provide valuable service without the need of being long-term custodian of the users funds.\nsuch channels might become the foundation for running native bitcoin banks of almost any scale that target both global and local markets while maintaining a minimized infrastructure and open-sourced client- and host-side code. since the protocol itself might be open, the end user applications may be also open and modular.\npossible use cases are limitless:\ninstant global remittances in local currencies using ln with minimum possible fx spread\nuser or merchant can instantly control the exposure of his savings/current account into bitcoin from 0% to 100% using slider or programmable logic, at a fraction of a cost\nconvenient and interoperable local merchant trading denominated in fiat units\nthe fiat-channel module for lightning node could be used both for:\na trust-based community bank in the remote unbanked village\na submodule of a bank-application infrastructure for nation-wide bank, integrated with kyc/aml\nconnecting legacy finance and bitcoin banks\na lightning node can be an organic part of openbankproject applications. we may consider two ways one can participate in a permissionless network and monetize its effect:\nliquidity bridge\nsmaller community bank or a -----> branch !!!  of the larger bank\nthe first one may rely on third-party customer obp api, while the more advanced subordinary-type obp api may drive the second one. creating the new bank with bank-correspondent demands significantly larger resources, so we are focusing on the bridging-like functionality of our service. in this case, the user may deposit money via standard bank transfer and invoke a fiat channel when funding is confirmed. the stable fiat-denominated value will allow to utilize liquidity without rush and mindfully plan business activity related to the freshly created channel.\nwe believe that sats will become a standart!", "sortedWord": "None", "removed": "Nan", "score": 11, "comments": 3, "media": null, "medialink": null, "identifyer": 59502609}, {"Unnamed: 0": 2789, "autor": "Image 4 - Office & Retail Interior Design Firm", "date": null, "content": "We are a bank branch design company that helps financial institutions create the best possible experience for their customers. Image 4 team of designers, architects, and engineers work with our clients to build spaces that are functional and beautiful. We believe in creating an environment where people feel comfortable doing business with your institution.\n#interiordesigner #graphicdesigner #manchester #manchesternh\nImage 4 - Office & Retail Interior Design Firm - Location\nAddress :- 7 Perimeter Rd Manchester NH 03103 USA\nPhone :- (603) 644-0077\nServices We Offer\nInterior Designer\nImage 4 - Office & Retail Interior Design Firm - Social Profile\nYoutube - https://www.youtube.com/channel/UCXiAjVotA97_QxCVRuJCz6Q/about\nPinterest - https://www.pinterest.com/Image4NH/\nTwitter - https://twitter.com/image4branding\nfacebook.com - https://www.facebook.com/image4/\ninstagram.com - https://www.instagram.com/image4branding/\nlinkedin.com - https://www.linkedin.com/company/image-4", "link": "https://devpost.com/software/image-4-office-retail-interior-design-firm", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "we are a bank -----> branch !!!  design company that helps financial institutions create the best possible experience for their customers. image 4 team of designers, architects, and engineers work with our clients to build spaces that are functional and beautiful. we believe in creating an environment where people feel comfortable doing business with your institution.\n#interiordesigner #graphicdesigner #manchester #manchesternh\nimage 4 - office & retail interior design firm - location\naddress :- 7 perimeter rd manchester nh 03103 usa\nphone :- (603) 644-0077\nservices we offer\ninterior designer\nimage 4 - office & retail interior design firm - social profile\nyoutube - https://www.youtube.com/channel/ucxiajvota97_qxcvrujcz6q/about\npinterest - https://www.pinterest.com/image4nh/\ntwitter - https://twitter.com/image4branding\nfacebook.com - https://www.facebook.com/image4/\ninstagram.com - https://www.instagram.com/image4branding/\nlinkedin.com - https://www.linkedin.com/company/image-4", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59502789}, {"Unnamed: 0": 2884, "autor": "DEEP LEARNING FOR QUANTUM CHEMISTRY", "date": null, "content": "Introduction\nQuantum chemistry is a branch of science that is solely interested in understanding the motion of electrons around atoms and molecules. Knowing with great accuracy the behavior of these particles is the bedrock for understanding modern chemistry, and a necessary ingredient for many applications, including catalysis, drug design, and drug discovery. The physics of these quantum systems was formulated almost a century ago and can be described by a simple differential equation known as the Schrodinger equation. For relatively small systems such as the hydrogen atom, this equation can be solved analytically. However, for larger systems, this problem is analytically intractable due to the exponential scaling of the degrees of freedom of the electrons with system size.\nOver the years, scientists have developed very sophisticated computational methods to tackle the electronic structure problem for many particles. Despite relentless efforts, the task of obtaining a solution to the so-called many-body Schrodinger equation still remains a computational challenge. Even with modern supercomputers, it ab initio electronic structure calculations routinely take days, weeks, or even months to complete. Not only does this impede research from being carried out in a timely manner, but it is also a very costly activity in terms of energy and the potential for CO~2~ emissions into the environment.\nTo deal with the setbacks associated with conventional quantum chemistry methods, researchers have been trying to find faster and cheaper ways to make theoretical predictions. Recently, neural networks have shown significant potential to achieve this. Thanks to the data accumulated over the years from computational chemistry calculations, it is now possible to train machine learning models and make predictions on real chemical systems.\nConvolutional Neural Networks (CNNs) are a powerful utility for deep learning tasks such as computer vision. In these CNN architectures, it is sufficient to use a discrete filter in our CNN architectures since the training is usually done on grid-based data (or at the very least, data that can be represented on a grid). However, due to the dynamic and physical properties of quantum systems, discrete filters are not suitable for such problems. Schutt and co-workers recently developed SchNet: a CNN architecture that uses continuous filters [1]. To our knowledge, this is currently the state-of-the-art when it comes to solving quantum chemistry-related problems.\nIn this work, our goal is to obtain insight into the functionality of SchNet, understand how or why continuous filters work, and finally, make a few modifications to this model and see how that affects the performance of this model. SchNet is a novel CNN approach. We have found very little discussion of this model in the literature although it is widely used in chemistry. Most of the discussions on SchNet simply cite the original paper and move on to applying the model to their architecture. We hope to, in part, remedy that through this work.\nOur motivation for embarking on this project stems from our experience in doing quantum chemistry computations. Often times, we have to suffer long waiting periods of time for our jobs to fully execute. The techniques learned in this course have inspired us to explore a deep learning approach to accelerate quantum chemistry computations. We believe that this experience will be essential for our own future research which involves the application of neural networks in quantum chemistry.\nData\nIn this project, we use the QM9 dataset [2], which is a widely used to benchmark the prediction of properties of molecules in equilibrium. This dataset consists of 133,885 organic molecules with up to 9 heavy atoms of types C=carbon, O=oxygen, N=nitrogen, F=florine. All the geometries in this dataset are in equilibrium, meaning that all the forces acting on each atom are equal to zero. The dataset contains the atomic geometries and charges atoms in each molecule. We use these to train our model and make a prediction of the energy. It is convenient to work with QM9 since all the geometries are in equilibrium. We therefore only need to predict the energies without explicitly computing the forces.\nModel Architecture\nSchNet was introduced in 2017 by Schutt et al. [1]. The authors have provided open-source code for their architecture, which will be our starting point as we attempt to modify their implementation. The architecture of the original SchNet model is presented in the authors' original work [1].\nInput layer The model takes atomic positions and atomic charges as inputs. These inputs are represented in the neural network using a tuple of features.\nEmbedding layer In the embedding layer, atoms are initialized using an embedding that corresponds to the type of atomic charges. The embeddings are initialized randomly and optimized during training. SchNet contains a total of 64 embedding layers.\nInteraction blocks The interaction blocks are responsible for learning and updating the atomic representations of the model based on the input data. Each interaction block is made up of 1) 64 atom-wise layers which contain the weights and biases. This is where the recombination of feature maps is done. 2), 3 sets of 64 continuous filter convolution layers (this is where we attempt to make our modifications), and 3) an activation layer with a shifted softplus activation. Additionally, each interaction block contains a residue connection similar to ResNet models [3].\nContinuous filter convolutional layers This is where the continuous filters are generated. Firstly, a rotational invariance is obtained computing the distances between atoms from the input data. You can think of these interatomic distances as strides for the filter to operate on. The main idea of the concept of a continuous filter rests on this equation. The power of the continuous filter lies on the fact that these \"strides\" are not evenly spaces (i.e., atomic dynamics are not organized or properly confined like pixels on a grid) and can therefore carry more meaningful information as opposed to a discrete filter. Skeptical? Indeed, we were too. This is why in our work we make modifications to the above representation and compare the results to the original architecture. We will note that, in addition to the above equation, the author's of SchNet include radial basis functions (rbf) in order to minimized the correlation between the generated filters. In our work, we try to modify this too and make comparisons with the original SchNet. We leave the rest of the cfconv block unchanged, which contains 2 sets of dense 64 layers, and 2 ssp activations.\nSum Pooling The outputs from the interaction blocks is then passed through atom-wise layers, ssp activation, and finally a pooling layer. Once the model has undergone training, we can now make some predictions of the energy.\nMethodology\nThe original architecture of SchNet [1] can be downloaded and installed from the authors' GitHub page: https://github.com/atomistic-machine-learning/schnetpack. Note that the version we use for this project (latest version) is written in PyTorch. The most important part of the SchNet is the convolution part in the interaction block: cfconv. We will therefore introduce our modifications to this block. In the original SchNet model, the filters in cfconv are designed to be rotationally invariant by using the interatomic distances (i.e., the difference between atoms) as input for the network filter. We attempt two versions of modifications to this block. 1) instead of taking the interlyer distances between the atoms, we simply pass the input unaltered. Everything else stays the same. 2) We replace the rbfs with discrete convolution layers. We explore these modified versions and report the results.\nPreprocessing\nWe start by downloading the dataset using the QM9 class in SchNet. The data is then split into training, validation, and test data using a helper function spk.train_test_split provided in SchNet. The split data is then stored in the split.npz file. Finally, we load the data into the model using the AtomsLoader class, also provided in SchNet helper scripts.\nTraining\nWe take the atomic positions and atomic charges from the QM9 dataset as inputs, and the energies as labels. SchNet provides some statistics about the data, e.g., the mean values, standard deviation, etc. This can give us some idea of what the target property looks like. This is especially helpful in avoiding the non-physical initialization of some parameters in the model. The Trainer class is used to train the model. Although this class comes with the SchNetPack, we still need to define the loss function. In this case, we use the mean squared error of the energy. Here, we set hyperparameters such as learning rate, epoch size, and so on. The output of the training is stored in a log file with the mean absolute errors per epoch, including the training time.\nMetrics\nAs a metric for success, we compare the mean absolute errors between the original SchNet model and our modified SchNet.\nResults\nSee final writeup for results and other details.\nEthics\nAs we implement these deep learning techniques, it is important to be mindful of the potential social implications that these algorithms have. Most of the predictions made in quantum chemistry applications are used by experimentalists to inform their lab techniques, e.g., in drug design and pharmaceuticals. The long-term consequences of entrusting a computer to guide how you design your drugs is still uncharted territory as this science has not yet been fully developed. However, we recommend that even as we develop such kind of applications, they should not be substitute for the guidance and intuition of a human chemist. The goal of these algorithms is to guide humanity, not replace it.\nChallenges\nThe first challenge we ran into was the fact that the original SchNet code used PyTorch instead of tensorflow. Neither of us had used PyTorch before, and knowing that it was infeasible to recode an architecture as large as SchNet in tensorflow, we had quickly adapt and learn a bit about the PyTorch library in a very short period of time. Secondly, we encountered a lot of difficulty understanding how to actually use SchNet once we had it setup on our local machines. The greatest challenge stemmed from how to use database files. The SchNet GitHub repository did not thoroughly explain how to properly pass the database file in the command line when running their model. This led to several installations and uninstallation of the architecture, which ended up being more time-consuming than initially anticipated.\nReflections\nOverall, we can say that our project is a success because, for one, we have achieved the base goal, which was to compare the performance of two kinds of filters. In the project, we have seen that the modified models give the results we expected. By comparing the results, we have gained a better understanding of how SchNet works and why it is better than models, including our modified versions of SchNet. Even while keeping the entire architecture mostly unchanged and alterring only the continuous filter part, we so a significant drop in accuracy in the modified models. We can confidently say that continuous filters are suitable for quantum chemistry problems.\nOn the other hand, we did not achieve our goal of introducing our modified models in a Graph Neural Network platform that compares the performance of various types of convolutional models. This platform, known as MatDeepLearn (https://www.nature.com/articles/s41524-021-00554-0, https://github.com/vxfung/MatDeepLearn) compares the performance of other state-of-the-art networks in quantum chemistry. We found this idea much harder to implement due to the complexity of MatDeepLearn.\nWe would like to explore ideas such as these further and even develop original models in quantum chemistry from scratch. For instance, if time permitted, it would have been interesting to see a totally different deep learning approach such as attention and transformers, for example, being applied to problems in quantum chemistry. If there's anything we have learned from this project, it is this: deep learning is a versatile computational technique and its full potential hasn't been yet explored in other fields. I mean, who knew that CNNs, an approach reserved mainly for image processing, can perform learn chemical space and make accurate predictions? This is only the beginning of what can be done with deep learning! However, due to time constraints, this is where we rest our case for now.\nDivision of labor\nXJ and TK contributed equally to the success of this project. XJ did most of the code modifications to SchNet while TK did most of the writing and poster preparation.\nReferences\n[1] Kristof T Sch \u0308utt, Pieter-Jan Kindermans, Huziel E Sauceda, Stefan Chmiela, Alexandre Tkatchenko, and Klaus-Robert M \u0308uller. Schnet: A continuous-filter convolutional neural network for modeling quantum interactions. arXiv preprint arXiv:1706.08566, 2017.\n[2] Raghunathan Ramakrishnan, Pavlo O Dral, Matthias Rupp, and O Anatole Von Lilienfeld. Quantum chemistry structures and properties of 134 kilo molecules. Scientific data, 1(1):1\u20137, 2014.\n[3] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.", "link": "https://devpost.com/software/deep-learning-for-quantum-chemistry", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "introduction\nquantum chemistry is a -----> branch !!!  of science that is solely interested in understanding the motion of electrons around atoms and molecules. knowing with great accuracy the behavior of these particles is the bedrock for understanding modern chemistry, and a necessary ingredient for many applications, including catalysis, drug design, and drug discovery. the physics of these quantum systems was formulated almost a century ago and can be described by a simple differential equation known as the schrodinger equation. for relatively small systems such as the hydrogen atom, this equation can be solved analytically. however, for larger systems, this problem is analytically intractable due to the exponential scaling of the degrees of freedom of the electrons with system size.\nover the years, scientists have developed very sophisticated computational methods to tackle the electronic structure problem for many particles. despite relentless efforts, the task of obtaining a solution to the so-called many-body schrodinger equation still remains a computational challenge. even with modern supercomputers, it ab initio electronic structure calculations routinely take days, weeks, or even months to complete. not only does this impede research from being carried out in a timely manner, but it is also a very costly activity in terms of energy and the potential for co~2~ emissions into the environment.\nto deal with the setbacks associated with conventional quantum chemistry methods, researchers have been trying to find faster and cheaper ways to make theoretical predictions. recently, neural networks have shown significant potential to achieve this. thanks to the data accumulated over the years from computational chemistry calculations, it is now possible to train machine learning models and make predictions on real chemical systems.\nconvolutional neural networks (cnns) are a powerful utility for deep learning tasks such as computer vision. in these cnn architectures, it is sufficient to use a discrete filter in our cnn architectures since the training is usually done on grid-based data (or at the very least, data that can be represented on a grid). however, due to the dynamic and physical properties of quantum systems, discrete filters are not suitable for such problems. schutt and co-workers recently developed schnet: a cnn architecture that uses continuous filters [1]. to our knowledge, this is currently the state-of-the-art when it comes to solving quantum chemistry-related problems.\nin this work, our goal is to obtain insight into the functionality of schnet, understand how or why continuous filters work, and finally, make a few modifications to this model and see how that affects the performance of this model. schnet is a novel cnn approach. we have found very little discussion of this model in the literature although it is widely used in chemistry. most of the discussions on schnet simply cite the original paper and move on to applying the model to their architecture. we hope to, in part, remedy that through this work.\nour motivation for embarking on this project stems from our experience in doing quantum chemistry computations. often times, we have to suffer long waiting periods of time for our jobs to fully execute. the techniques learned in this course have inspired us to explore a deep learning approach to accelerate quantum chemistry computations. we believe that this experience will be essential for our own future research which involves the application of neural networks in quantum chemistry.\ndata\nin this project, we use the qm9 dataset [2], which is a widely used to benchmark the prediction of properties of molecules in equilibrium. this dataset consists of 133,885 organic molecules with up to 9 heavy atoms of types c=carbon, o=oxygen, n=nitrogen, f=florine. all the geometries in this dataset are in equilibrium, meaning that all the forces acting on each atom are equal to zero. the dataset contains the atomic geometries and charges atoms in each molecule. we use these to train our model and make a prediction of the energy. it is convenient to work with qm9 since all the geometries are in equilibrium. we therefore only need to predict the energies without explicitly computing the forces.\nmodel architecture\nschnet was introduced in 2017 by schutt et al. [1]. the authors have provided open-source code for their architecture, which will be our starting point as we attempt to modify their implementation. the architecture of the original schnet model is presented in the authors' original work [1].\ninput layer the model takes atomic positions and atomic charges as inputs. these inputs are represented in the neural network using a tuple of features.\nembedding layer in the embedding layer, atoms are initialized using an embedding that corresponds to the type of atomic charges. the embeddings are initialized randomly and optimized during training. schnet contains a total of 64 embedding layers.\ninteraction blocks the interaction blocks are responsible for learning and updating the atomic representations of the model based on the input data. each interaction block is made up of 1) 64 atom-wise layers which contain the weights and biases. this is where the recombination of feature maps is done. 2), 3 sets of 64 continuous filter convolution layers (this is where we attempt to make our modifications), and 3) an activation layer with a shifted softplus activation. additionally, each interaction block contains a residue connection similar to resnet models [3].\ncontinuous filter convolutional layers this is where the continuous filters are generated. firstly, a rotational invariance is obtained computing the distances between atoms from the input data. you can think of these interatomic distances as strides for the filter to operate on. the main idea of the concept of a continuous filter rests on this equation. the power of the continuous filter lies on the fact that these \"strides\" are not evenly spaces (i.e., atomic dynamics are not organized or properly confined like pixels on a grid) and can therefore carry more meaningful information as opposed to a discrete filter. skeptical? indeed, we were too. this is why in our work we make modifications to the above representation and compare the results to the original architecture. we will note that, in addition to the above equation, the author's of schnet include radial basis functions (rbf) in order to minimized the correlation between the generated filters. in our work, we try to modify this too and make comparisons with the original schnet. we leave the rest of the cfconv block unchanged, which contains 2 sets of dense 64 layers, and 2 ssp activations.\nsum pooling the outputs from the interaction blocks is then passed through atom-wise layers, ssp activation, and finally a pooling layer. once the model has undergone training, we can now make some predictions of the energy.\nmethodology\nthe original architecture of schnet [1] can be downloaded and installed from the authors' github page: https://github.com/atomistic-machine-learning/schnetpack. note that the version we use for this project (latest version) is written in pytorch. the most important part of the schnet is the convolution part in the interaction block: cfconv. we will therefore introduce our modifications to this block. in the original schnet model, the filters in cfconv are designed to be rotationally invariant by using the interatomic distances (i.e., the difference between atoms) as input for the network filter. we attempt two versions of modifications to this block. 1) instead of taking the interlyer distances between the atoms, we simply pass the input unaltered. everything else stays the same. 2) we replace the rbfs with discrete convolution layers. we explore these modified versions and report the results.\npreprocessing\nwe start by downloading the dataset using the qm9 class in schnet. the data is then split into training, validation, and test data using a helper function spk.train_test_split provided in schnet. the split data is then stored in the split.npz file. finally, we load the data into the model using the atomsloader class, also provided in schnet helper scripts.\ntraining\nwe take the atomic positions and atomic charges from the qm9 dataset as inputs, and the energies as labels. schnet provides some statistics about the data, e.g., the mean values, standard deviation, etc. this can give us some idea of what the target property looks like. this is especially helpful in avoiding the non-physical initialization of some parameters in the model. the trainer class is used to train the model. although this class comes with the schnetpack, we still need to define the loss function. in this case, we use the mean squared error of the energy. here, we set hyperparameters such as learning rate, epoch size, and so on. the output of the training is stored in a log file with the mean absolute errors per epoch, including the training time.\nmetrics\nas a metric for success, we compare the mean absolute errors between the original schnet model and our modified schnet.\nresults\nsee final writeup for results and other details.\nethics\nas we implement these deep learning techniques, it is important to be mindful of the potential social implications that these algorithms have. most of the predictions made in quantum chemistry applications are used by experimentalists to inform their lab techniques, e.g., in drug design and pharmaceuticals. the long-term consequences of entrusting a computer to guide how you design your drugs is still uncharted territory as this science has not yet been fully developed. however, we recommend that even as we develop such kind of applications, they should not be substitute for the guidance and intuition of a human chemist. the goal of these algorithms is to guide humanity, not replace it.\nchallenges\nthe first challenge we ran into was the fact that the original schnet code used pytorch instead of tensorflow. neither of us had used pytorch before, and knowing that it was infeasible to recode an architecture as large as schnet in tensorflow, we had quickly adapt and learn a bit about the pytorch library in a very short period of time. secondly, we encountered a lot of difficulty understanding how to actually use schnet once we had it setup on our local machines. the greatest challenge stemmed from how to use database files. the schnet github repository did not thoroughly explain how to properly pass the database file in the command line when running their model. this led to several installations and uninstallation of the architecture, which ended up being more time-consuming than initially anticipated.\nreflections\noverall, we can say that our project is a success because, for one, we have achieved the base goal, which was to compare the performance of two kinds of filters. in the project, we have seen that the modified models give the results we expected. by comparing the results, we have gained a better understanding of how schnet works and why it is better than models, including our modified versions of schnet. even while keeping the entire architecture mostly unchanged and alterring only the continuous filter part, we so a significant drop in accuracy in the modified models. we can confidently say that continuous filters are suitable for quantum chemistry problems.\non the other hand, we did not achieve our goal of introducing our modified models in a graph neural network platform that compares the performance of various types of convolutional models. this platform, known as matdeeplearn (https://www.nature.com/articles/s41524-021-00554-0, https://github.com/vxfung/matdeeplearn) compares the performance of other state-of-the-art networks in quantum chemistry. we found this idea much harder to implement due to the complexity of matdeeplearn.\nwe would like to explore ideas such as these further and even develop original models in quantum chemistry from scratch. for instance, if time permitted, it would have been interesting to see a totally different deep learning approach such as attention and transformers, for example, being applied to problems in quantum chemistry. if there's anything we have learned from this project, it is this: deep learning is a versatile computational technique and its full potential hasn't been yet explored in other fields. i mean, who knew that cnns, an approach reserved mainly for image processing, can perform learn chemical space and make accurate predictions? this is only the beginning of what can be done with deep learning! however, due to time constraints, this is where we rest our case for now.\ndivision of labor\nxj and tk contributed equally to the success of this project. xj did most of the code modifications to schnet while tk did most of the writing and poster preparation.\nreferences\n[1] kristof t sch \u0308utt, pieter-jan kindermans, huziel e sauceda, stefan chmiela, alexandre tkatchenko, and klaus-robert m \u0308uller. schnet: a continuous-filter convolutional neural network for modeling quantum interactions. arxiv preprint arxiv:1706.08566, 2017.\n[2] raghunathan ramakrishnan, pavlo o dral, matthias rupp, and o anatole von lilienfeld. quantum chemistry structures and properties of 134 kilo molecules. scientific data, 1(1):1\u20137, 2014.\n[3] kaiming he, xiangyu zhang, shaoqing ren, and jian sun. deep residual learning for image recognition. in proceedings of the ieee conference on computer vision and pattern recognition, pages 770\u2013778, 2016.", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 15, "media": null, "medialink": null, "identifyer": 59502884}, {"Unnamed: 0": 2968, "autor": "Studii", "date": null, "content": "Inspiration\nThe idea of our app came to us after some intense brainstorming to address a problem that every student faces. As students ourselves, we recognize that one of the challenges in post-secondary education is the lack of support for student mental health.\nWhat it does\nWith studii, our goals are to create a connection for students who are looking for help on similar questions, to provide a platform for students can reinforce their own understanding through teaching others, and to foster a supportive environment where students can tackle their problems head on\nHow we built it\nBeing our first hackathon, we aren't super well-versed in all the technologies that are available, so we stuck with what we knew. Our project is build in Java, and the GUI is supported by Swing.\nChallenges we ran into\nStaying organized and keeping our branches in order was actually a pretty big challenge. This being the first time we worked simultaneously on the same repo on github, it definitely helped us build some project management skills\nAccomplishments that we're proud of\nAftter a hard day of labour, we're pretty proud of the our product and all the code we wrote to make it work.\nWhat we learned\nHow to finish a project in under 12 hrs? Or that I really hate waking up at 8 in the morning.\nWhat's next for Studii\nWho knows man", "link": "https://devpost.com/software/studii", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nthe idea of our app came to us after some intense brainstorming to address a problem that every student faces. as students ourselves, we recognize that one of the challenges in post-secondary education is the lack of support for student mental health.\nwhat it does\nwith studii, our goals are to create a connection for students who are looking for help on similar questions, to provide a platform for students can reinforce their own understanding through teaching others, and to foster a supportive environment where students can tackle their problems head on\nhow we built it\nbeing our first hackathon, we aren't super well-versed in all the technologies that are available, so we stuck with what we knew. our project is build in java, and the gui is supported by swing.\nchallenges we ran into\nstaying organized and keeping our -----> branches !!!  in order was actually a pretty big challenge. this being the first time we worked simultaneously on the same repo on github, it definitely helped us build some project management skills\naccomplishments that we're proud of\naftter a hard day of labour, we're pretty proud of the our product and all the code we wrote to make it work.\nwhat we learned\nhow to finish a project in under 12 hrs? or that i really hate waking up at 8 in the morning.\nwhat's next for studii\nwho knows man", "sortedWord": "None", "removed": "Nan", "score": 3, "comments": 0, "media": null, "medialink": null, "identifyer": 59502968}, {"Unnamed: 0": 3180, "autor": "Covid-19 Tracker", "date": null, "content": "Covid-19 Tracker\nCoronavirus disease Case Tracker in the World\nExplore the docs \u00bb\nView Demo \u00b7 Report Bug \u00b7 Request Feature\nAbout The Project\nThis Covid19 repo based on Covid-19 Coronavirus disease Case Tracker. You can check detail of coronavirus cases, recovered and death by country and states using Map and data.\nBuilt With\nThis section should list any major frameworks/libraries used to bootstrap your project. Leave any add-ons/plugins for the acknowledgements section. Here are a few examples.\nMapBox\nBootstrap\nJQuery\nContributing\nContributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are greatly appreciated.\nIf you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\". Don't forget to give the project a star! Thanks again!\nFork the Project\nCreate your Feature Branch (git checkout -b feature/AmazingFeature)\nCommit your Changes (git commit -m 'Add some AmazingFeature')\nPush to the Branch (git push origin feature/AmazingFeature)\nOpen a Pull Request\nContact\nVijay Chauhan - @mr_vijaychauhan\nProject Link: https://github.com/mr-vijaychauhan/covid19\nAcknowledgments\nUse this space to list resources you find helpful and would like to give credit to. I've included a few of my favorites to kick things off!\nGitHub Pages\nFont Awesome", "link": "https://devpost.com/software/covid-19-tracker-su15kc", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "covid-19 tracker\ncoronavirus disease case tracker in the world\nexplore the docs \u00bb\nview demo \u00b7 report bug \u00b7 request feature\nabout the project\nthis covid19 repo based on covid-19 coronavirus disease case tracker. you can check detail of coronavirus cases, recovered and death by country and states using map and data.\nbuilt with\nthis section should list any major frameworks/libraries used to bootstrap your project. leave any add-ons/plugins for the acknowledgements section. here are a few examples.\nmapbox\nbootstrap\njquery\ncontributing\ncontributions are what make the open source community such an amazing place to learn, inspire, and create. any contributions you make are greatly appreciated.\nif you have a suggestion that would make this better, please fork the repo and create a pull request. you can also simply open an issue with the tag \"enhancement\". don't forget to give the project a star! thanks again!\nfork the project\ncreate your feature -----> branch !!!  (git checkout -b feature/amazingfeature)\ncommit your changes (git commit -m 'add some amazingfeature')\npush to the branch (git push origin feature/amazingfeature)\nopen a pull request\ncontact\nvijay chauhan - @mr_vijaychauhan\nproject link: https://github.com/mr-vijaychauhan/covid19\nacknowledgments\nuse this space to list resources you find helpful and would like to give credit to. i've included a few of my favorites to kick things off!\ngithub pages\nfont awesome", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59503180}, {"Unnamed: 0": 3283, "autor": "Voice of Zoo", "date": null, "content": "Inspiration \ud83d\udca1\nThe current pandemic is the direct result of our reckless and ruthless mismanagement of nature and our distorted relationship with wildlife. It\u2019s ironic that it also threatens one of the few institutions, zoos, which are dedicated to study and preserve nature and educate us all about a more balanced way of living in peace with it.\nThough zoos across the country are unusually quiet, zookeepers are faced with the challenge of ensuring life goes on as normal for the animals they care for amid a pandemic that has profoundly altered. Zoos have little revenue but still must feed animals, who seem to miss their human audience which impacts their overall morale & impacted their daily routines.\nThis financial crisis has forced many zookeepers to quit their job & many got broke & for whoever stayed has created a massive chaos in the wildcare industry which is currently acting as a catalyst in degrading customer or audience feedback & reviews.\nHard times shall pass. We believe that with the power of AI, this can be solved if we proceed creatively. Thus we made Voice of Zoo with an aim of Resolving global Pandemic Impacts in Zoos! \ud83e\udd93\nSo what\u2019s the app about? \ud83e\udd14\nAs the project is on Zoo World, which goes for the theme Zoo. This application is a Zoo Management System, that goes for managing every aspect about a Zoo. Whether it is Booking and Appointment reservation for customers to visit the Zoo or Reviewing on their experience with the Animals or Restaurant at Zoo visit. The application is designed to provide a priceless experience on using the application pre & post zoo, for both Customers and a Zoo manager for a zoo.\nThe main purpose of this application is about customers sharing their experience about the zoo animals and restaurant. Their reviews on the animals can help the zookeeper's keep check on their animals behavior and emotions, from a customer's review specific to that animal. A Sentiment analysis is used to check whether it is a positive or negative feedback. So that zookeeper can make the animal a good emotions. Happy is a Animal Happier is the Customer's Enjoyment watching the animal!.\nTech Stack \ud83c\udfd7\nIn a recent tech podcast we got to know that nowadays these sort of reviews can be autogenerated by bots for getting edge, but in our case every bit of data is verificable & immutable once it\u2019s registered on the platform!\nAnd this is one of the reasons we are backing up all of these important media on IPFS. Most of the attacks happen on the transport layer, that is the reason we primarily went with IPFS. IPFS uses transport-encryption. This means that your data is secure when being sent from one IPFS node to another.\nChallenges We ran into \ud83e\uddf1\nThere were lots of challenges on our way. First, because we are all online and spread around the globe, it was somewhat difficult for us to be communicating during the process. We also spent a great deal of time discussing ideas for the project. We have reached a final decision on what to include in our project after we had a couple of calls with mentors. After we settled on the idea, we separated the work according to everyone's skills. Rahul was primarily working on the Front-end, and set up integrations & backend. Besides, Pratyay & Dibyaranjan worked on building the ML model. We faced most challenges when we tried to allocate segregated chunks into one project.\nDesign\nWe were heavily inspired by the revised version of Iterative design process, which not only includes visual design, but a full-fledged research cycle in which you must discover and define your problem before tackling your solution & then finally deploy it.\nDiscover: a deep dive into the problem we are trying to solve.\nDefine: synthesizing the information from the discovery phase into a problem definition.\nDevelop: think up solutions to the problem.\nDeliver: pick the best solution and build that.\nThis time went for the minimalist Material UI design. We utilized design tools like Figma, Photoshop & Illustrator to prototype our designs before doing any coding. Through this, we are able to get iterative feedback so that we spend less time re-writing code.\nResearch \ud83d\udcda\nResearch is the key to empathizing with users: we found our specific user group early and that paves the way for our whole project. Here are a few of the resources that were helpful to us \u2014\n\u2663 Datasets :- Recompiled from several Sources.\n\u2663 Articles :-\nZoos struggling in pandemic as group says government hasn't done enough : https://bbc.in/3ouALY0\nARE ZOOS FINANCING CONSERVATION OR FUNDING CAPTIVITY? : https://bit.ly/3Ck6L5L\nWhat is the future of zoos after Covid? We can\u2019t afford them going extinct : https://bit.ly/3nc2VHO\nZoos are closed because of coronavirus, but the animals still need care : https://wapo.st/3qz01yL\nHow much money do zoos make in a year? : https://bit.ly/3DhkNGS\nCREDITS\nDesign Resources : Freepik\nIcons : Icons8, fontawesome\nFont : Roboto / Turret Road / Manrope / Montserrat\nTakeaways\nAccomplishments that we're proud of \ud83d\ude4c\nA fully working prototype! This has been intense yet insightful. We are very proud to have designed and built an application within such a short timeframe.\nLearning how to collaborate on GitHub! Not all of us were familiar with making branches or making a PR and merging. This hackathon has fast-tracked the learning process and we are all now very comfortable in using GitHub!\nLearning new technology (like Tailwind CSS, routing in React, implementing sophisticated design features, Firebase Functions, Firestore), meeting new people, debugging, debugging, and more debugging!\nWhat we learned \ud83d\ude4c\nStaying hydrated was our motto for completing this impactful and complicated project on time. We have learned how great wins are accomplished by working together. For the technical part, we learned much about Azure. Moreover, we have faced some issues when we were merging the front-end and backend. We also gave our level best to make the UI/UX look minimalistic and useful! Not to mention, documentations and help from Google for technologies we used (be it react components libraries, IPFS, API calls) were extremely useful!\nWhat's next for Voice of Zoo \ud83d\udcc3\nWe believe that our App has a great potential. Since all four of us are very passionate about tackling the issue of helping businesses to recover from COVID-19, it's easy to come up with a lot of ideas for new features (like we did at the beginning of this hackathon!). However, we now have learned the importance of focusing on a single feature at a time and making sure that feature works flawlessly before designing a new feature! \u2728\nNote \u2014 API credentials have been revoked. If you want to run the same on your local, use your own credentials.", "link": "https://devpost.com/software/voice-of-zoo", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration \ud83d\udca1\nthe current pandemic is the direct result of our reckless and ruthless mismanagement of nature and our distorted relationship with wildlife. it\u2019s ironic that it also threatens one of the few institutions, zoos, which are dedicated to study and preserve nature and educate us all about a more balanced way of living in peace with it.\nthough zoos across the country are unusually quiet, zookeepers are faced with the challenge of ensuring life goes on as normal for the animals they care for amid a pandemic that has profoundly altered. zoos have little revenue but still must feed animals, who seem to miss their human audience which impacts their overall morale & impacted their daily routines.\nthis financial crisis has forced many zookeepers to quit their job & many got broke & for whoever stayed has created a massive chaos in the wildcare industry which is currently acting as a catalyst in degrading customer or audience feedback & reviews.\nhard times shall pass. we believe that with the power of ai, this can be solved if we proceed creatively. thus we made voice of zoo with an aim of resolving global pandemic impacts in zoos! \ud83e\udd93\nso what\u2019s the app about? \ud83e\udd14\nas the project is on zoo world, which goes for the theme zoo. this application is a zoo management system, that goes for managing every aspect about a zoo. whether it is booking and appointment reservation for customers to visit the zoo or reviewing on their experience with the animals or restaurant at zoo visit. the application is designed to provide a priceless experience on using the application pre & post zoo, for both customers and a zoo manager for a zoo.\nthe main purpose of this application is about customers sharing their experience about the zoo animals and restaurant. their reviews on the animals can help the zookeeper's keep check on their animals behavior and emotions, from a customer's review specific to that animal. a sentiment analysis is used to check whether it is a positive or negative feedback. so that zookeeper can make the animal a good emotions. happy is a animal happier is the customer's enjoyment watching the animal!.\ntech stack \ud83c\udfd7\nin a recent tech podcast we got to know that nowadays these sort of reviews can be autogenerated by bots for getting edge, but in our case every bit of data is verificable & immutable once it\u2019s registered on the platform!\nand this is one of the reasons we are backing up all of these important media on ipfs. most of the attacks happen on the transport layer, that is the reason we primarily went with ipfs. ipfs uses transport-encryption. this means that your data is secure when being sent from one ipfs node to another.\nchallenges we ran into \ud83e\uddf1\nthere were lots of challenges on our way. first, because we are all online and spread around the globe, it was somewhat difficult for us to be communicating during the process. we also spent a great deal of time discussing ideas for the project. we have reached a final decision on what to include in our project after we had a couple of calls with mentors. after we settled on the idea, we separated the work according to everyone's skills. rahul was primarily working on the front-end, and set up integrations & backend. besides, pratyay & dibyaranjan worked on building the ml model. we faced most challenges when we tried to allocate segregated chunks into one project.\ndesign\nwe were heavily inspired by the revised version of iterative design process, which not only includes visual design, but a full-fledged research cycle in which you must discover and define your problem before tackling your solution & then finally deploy it.\ndiscover: a deep dive into the problem we are trying to solve.\ndefine: synthesizing the information from the discovery phase into a problem definition.\ndevelop: think up solutions to the problem.\ndeliver: pick the best solution and build that.\nthis time went for the minimalist material ui design. we utilized design tools like figma, photoshop & illustrator to prototype our designs before doing any coding. through this, we are able to get iterative feedback so that we spend less time re-writing code.\nresearch \ud83d\udcda\nresearch is the key to empathizing with users: we found our specific user group early and that paves the way for our whole project. here are a few of the resources that were helpful to us \u2014\n\u2663 datasets :- recompiled from several sources.\n\u2663 articles :-\nzoos struggling in pandemic as group says government hasn't done enough : https://bbc.in/3oualy0\nare zoos financing conservation or funding captivity? : https://bit.ly/3ck6l5l\nwhat is the future of zoos after covid? we can\u2019t afford them going extinct : https://bit.ly/3nc2vho\nzoos are closed because of coronavirus, but the animals still need care : https://wapo.st/3qz01yl\nhow much money do zoos make in a year? : https://bit.ly/3dhkngs\ncredits\ndesign resources : freepik\nicons : icons8, fontawesome\nfont : roboto / turret road / manrope / montserrat\ntakeaways\naccomplishments that we're proud of \ud83d\ude4c\na fully working prototype! this has been intense yet insightful. we are very proud to have designed and built an application within such a short timeframe.\nlearning how to collaborate on github! not all of us were familiar with making -----> branches !!!  or making a pr and merging. this hackathon has fast-tracked the learning process and we are all now very comfortable in using github!\nlearning new technology (like tailwind css, routing in react, implementing sophisticated design features, firebase functions, firestore), meeting new people, debugging, debugging, and more debugging!\nwhat we learned \ud83d\ude4c\nstaying hydrated was our motto for completing this impactful and complicated project on time. we have learned how great wins are accomplished by working together. for the technical part, we learned much about azure. moreover, we have faced some issues when we were merging the front-end and backend. we also gave our level best to make the ui/ux look minimalistic and useful! not to mention, documentations and help from google for technologies we used (be it react components libraries, ipfs, api calls) were extremely useful!\nwhat's next for voice of zoo \ud83d\udcc3\nwe believe that our app has a great potential. since all four of us are very passionate about tackling the issue of helping businesses to recover from covid-19, it's easy to come up with a lot of ideas for new features (like we did at the beginning of this hackathon!). however, we now have learned the importance of focusing on a single feature at a time and making sure that feature works flawlessly before designing a new feature! \u2728\nnote \u2014 api credentials have been revoked. if you want to run the same on your local, use your own credentials.", "sortedWord": "None", "removed": "Nan", "score": 3, "comments": 0, "media": null, "medialink": null, "identifyer": 59503283}, {"Unnamed: 0": 3405, "autor": "Recipe Finder", "date": null, "content": "Inspiration\nAs college students, we know how difficult it can be to find recipes and create meal plans that can fit into our busy schedule. We wanted to build a website that could take in dietary preferences, dietary restrictions, as well as time restrictions, and generates either a variety of recipes or a meal plan that fits the criteria.\nWhat it does\nBoth the meal planner and recipe generator have a form where the user can input their preferences and information. The website then displays recipe tiles that can be clicked on to display more in-depth information (such as ingredients) and a link to the external source of the recipe.\nHow we built it\nOur website relies on the Spoonacular API. It takes in the form data as inputs and deploys requests to the API with the form data as parameters to filter out the correct recipes.\nChallenges we ran into\nTwo out of three of our group members had no experience with front-end development. We had to utilize online resources and previous programming knowledge to implement a website in languages that were completely unfamiliar to us. Additionally, we had difficulties navigating Github with the different branches, as well as merging branches without conflict. The API we used also had a request limit, so we had to limit the number of recipes that could be displayed for a single search.\nAccomplishments that we're proud of\nClean user interface\nIntegrating an API into our website to filter through recipe information\nOvercoming lack of previous experience\nWhat we learned\nStrengthened our skills in front-end development\nLearned how to make API requests in a React application\nWhat's next for Recipe Finder\nIn the future, we hope to integrate buildable meal plans, so the user can hand-select recipes to be added to their meal plan. We would also like to implement a grocery list generator, which parses the recipes to build a grocery list with all the necessary ingredients for the specified meal plan.", "link": "https://devpost.com/software/recipe-finder-ndqs07", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nas college students, we know how difficult it can be to find recipes and create meal plans that can fit into our busy schedule. we wanted to build a website that could take in dietary preferences, dietary restrictions, as well as time restrictions, and generates either a variety of recipes or a meal plan that fits the criteria.\nwhat it does\nboth the meal planner and recipe generator have a form where the user can input their preferences and information. the website then displays recipe tiles that can be clicked on to display more in-depth information (such as ingredients) and a link to the external source of the recipe.\nhow we built it\nour website relies on the spoonacular api. it takes in the form data as inputs and deploys requests to the api with the form data as parameters to filter out the correct recipes.\nchallenges we ran into\ntwo out of three of our group members had no experience with front-end development. we had to utilize online resources and previous programming knowledge to implement a website in languages that were completely unfamiliar to us. additionally, we had difficulties navigating github with the different -----> branches !!! , as well as merging -----> branches !!!  without conflict. the api we used also had a request limit, so we had to limit the number of recipes that could be displayed for a single search.\naccomplishments that we're proud of\nclean user interface\nintegrating an api into our website to filter through recipe information\novercoming lack of previous experience\nwhat we learned\nstrengthened our skills in front-end development\nlearned how to make api requests in a react application\nwhat's next for recipe finder\nin the future, we hope to integrate buildable meal plans, so the user can hand-select recipes to be added to their meal plan. we would also like to implement a grocery list generator, which parses the recipes to build a grocery list with all the necessary ingredients for the specified meal plan.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59503405}, {"Unnamed: 0": 3409, "autor": "T\u00eate-\u00e0-T\u00eate", "date": null, "content": "Inspiration\nAfter meeting each other for the first time today, we realized how out of touch we all were with social situations. While we were brainstorming ideas, we realized that one of the largest issues plaguing society today is the lack of community between people. So, we decided to develop an app that helps people form connections by providing effective and relevant conversation starters.\nWhat it does\nIt is an android application that utilizes Google Firebase to store the different conversation topics and starters. Depending on your level of intimacy, you can choose different topics that lead to several conversation starters which you can navigate. There is also a topic of the day function and shuffle function for ease of access.\nHow we built it\nOur application was developed in Android Studio using Java and XML for UI. For our back-end database, we used Google Firebase which we connected to our application using their API. We split up tasks and used Git branches to efficiently and effectively implement our code.\nChallenges we ran into\nWe had little experience with Android Studio and using Google Firebase. We struggled with connecting the front-end and back-end of our app, but we were assisted by the mentors and utilized online resources to come up with a successful, finished project.\nAccomplishments that we're proud of\nDespite our lack of experience, we were able to come up with a working final product that utilizes new technologies. We put a lot of effort into our user interface, and we were able to connect it to our back-end.\nWhat we learned\nWe learned how to use new tools such as Google Firebase, Git, and Android Studio. We learned how to effectively work with others in a team, and we were able to have hands-on experience that we would not have been able to obtain from a classroom setting.\nWhat's next for T\u00eate-\u00e0-T\u00eate\nWe plan to implement an SOS system for extremely awkward situations using Twilio, where users may text a number, and T\u00eate-\u00e0-T\u00eate will respond with a random, general conversation starter. We also plan to deploy our application to the Google Play store and develop an iOS version in the near future. Our app also will have an option to favorite different conversation starters and save them, as well as add their own conversation starters.", "link": "https://devpost.com/software/tete-a-tete-386usi", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nafter meeting each other for the first time today, we realized how out of touch we all were with social situations. while we were brainstorming ideas, we realized that one of the largest issues plaguing society today is the lack of community between people. so, we decided to develop an app that helps people form connections by providing effective and relevant conversation starters.\nwhat it does\nit is an android application that utilizes google firebase to store the different conversation topics and starters. depending on your level of intimacy, you can choose different topics that lead to several conversation starters which you can navigate. there is also a topic of the day function and shuffle function for ease of access.\nhow we built it\nour application was developed in android studio using java and xml for ui. for our back-end database, we used google firebase which we connected to our application using their api. we split up tasks and used git -----> branches !!!  to efficiently and effectively implement our code.\nchallenges we ran into\nwe had little experience with android studio and using google firebase. we struggled with connecting the front-end and back-end of our app, but we were assisted by the mentors and utilized online resources to come up with a successful, finished project.\naccomplishments that we're proud of\ndespite our lack of experience, we were able to come up with a working final product that utilizes new technologies. we put a lot of effort into our user interface, and we were able to connect it to our back-end.\nwhat we learned\nwe learned how to use new tools such as google firebase, git, and android studio. we learned how to effectively work with others in a team, and we were able to have hands-on experience that we would not have been able to obtain from a classroom setting.\nwhat's next for t\u00eate-\u00e0-t\u00eate\nwe plan to implement an sos system for extremely awkward situations using twilio, where users may text a number, and t\u00eate-\u00e0-t\u00eate will respond with a random, general conversation starter. we also plan to deploy our application to the google play store and develop an ios version in the near future. our app also will have an option to favorite different conversation starters and save them, as well as add their own conversation starters.", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 0, "media": null, "medialink": null, "identifyer": 59503409}, {"Unnamed: 0": 3450, "autor": "Civo x Pyroscope Continuous Profiling", "date": null, "content": "Inspiration\nMy cousin and I decided to enter this hackathon because both of us wanted to learn more about Kubernetes. Although I've been coding for several years now, the jobs that I've had have been either ruby/rails or python/django so I haven't used Kubernetes very extensively in a professional context. My cousin joined me last week at Rubyconf in Denver and so we wanted to find a way to bring the power of Kubernetes to the world of Ruby!\nWe used the abalone project which is part of Ruby's \"rubyforgood\" organization and was used in a workshop on performance by Jade Dickinson at Rubyconf last week.\nWith that being said, I've also been working on open source performance monitoring tooling for about a year now so I thought it would be a good exercise in combining everything together!\nWhat it does\nThis project does two things:\nIt allows you to preview your application before the PR gets accepted into the main branch\nIt allows you to understand the performance impact of the current commit vs previous commits using continuous profiling\nWhat this project does is allow for you to profile your test suite and use an open-source continuous profiling tool called Pyroscope to inspect the profiles over time and understand which parts of your application are consuming the most resources. We also added the ability to tag profiles based off commit and commit author for easier/further analysis (especially in the profile diff view)\nHow we built it\nWe build this using Github actions fairly extensively. When someone creates a PR the following steps happen:\nChecks out the repo\nCreates a docker image with a tag for the particular commit\nDeploys kubernetes manifests which contain pods for webserver, tests, and pyroscope\nCreates ingress to access webserver (to view the staged changes before merging)\nCreates ingress to access pyroscope server (to view profiles of webserver / tests before merging)\nPosts a comment to the PR with a link to the webserver / pyroscope server\nChallenges we ran into\nOne of the biggest challenges here is that debugging github actions was extremely difficult. Especially when we are trying to create something that fits into the workflow we have to go through that entire workflow ourselves to test that it is functioning correctly.\nAnother issue is that with neither of us being experts in kubernetes there was a lot of trial and error to get things like ingresses to work the way we wanted them to. It seems as though a lot of kubernetes examples and documentation have quickly become outdated so we found ourselves in situations where we were trying to make old code work instead of using the new code.\nAccomplishments that we're proud of\nI ultimately learned a lot about how to effectively debug kuberenetes issues and William became an expert on Git (and is going to make his first open source contribution soon!)\nWhat we learned\nIn trying to follow some tutorials that are purely for kuberentes, we started to understand how much simpler Civo made the process. We spent a good couple of hours trying to understand all TEN of the files needed to create an application with an ingress from this article: https://medium.com/kubernetes-tutorials/deploying-traefik-as-ingress-controller-for-your-kubernetes-cluster-b03a0672ae0c\nOnly to eventually realize that 80% of it was necessary because Civo has abstracted / simplified much of that. All we needed was two file for the Ingresses and it worked great!\nWhat's next for Civo x Pyroscope\nThere's a couple of additions we'd like to add here, but didn't have time:\nCreate a plugin in the https://github.com/civo/kubernetes-marketplace to simplify adding a Pyroscope server to Civo \u2014 Going to be Williams first open source contribution!\nPublish our Github action: This will allow people to create this staging server + profiler combination as long as they've set up a Kubernetes cluster with Civo\nAdd a load testing tool (i.e. K6). The impact of performance issues in flamegraphs become more apparent as the server is under heavier load. It would be cool to add a service that sends fake traffic (or mocks of real traffic) to make the profiles more realistic\nThe web app is a little slow right now so sometimes the link to that will break (ran out of time to fix)", "link": "https://devpost.com/software/civo-x-pyroscope", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nmy cousin and i decided to enter this hackathon because both of us wanted to learn more about kubernetes. although i've been coding for several years now, the jobs that i've had have been either ruby/rails or python/django so i haven't used kubernetes very extensively in a professional context. my cousin joined me last week at rubyconf in denver and so we wanted to find a way to bring the power of kubernetes to the world of ruby!\nwe used the abalone project which is part of ruby's \"rubyforgood\" organization and was used in a workshop on performance by jade dickinson at rubyconf last week.\nwith that being said, i've also been working on open source performance monitoring tooling for about a year now so i thought it would be a good exercise in combining everything together!\nwhat it does\nthis project does two things:\nit allows you to preview your application before the pr gets accepted into the main -----> branch !!! \nit allows you to understand the performance impact of the current commit vs previous commits using continuous profiling\nwhat this project does is allow for you to profile your test suite and use an open-source continuous profiling tool called pyroscope to inspect the profiles over time and understand which parts of your application are consuming the most resources. we also added the ability to tag profiles based off commit and commit author for easier/further analysis (especially in the profile diff view)\nhow we built it\nwe build this using github actions fairly extensively. when someone creates a pr the following steps happen:\nchecks out the repo\ncreates a docker image with a tag for the particular commit\ndeploys kubernetes manifests which contain pods for webserver, tests, and pyroscope\ncreates ingress to access webserver (to view the staged changes before merging)\ncreates ingress to access pyroscope server (to view profiles of webserver / tests before merging)\nposts a comment to the pr with a link to the webserver / pyroscope server\nchallenges we ran into\none of the biggest challenges here is that debugging github actions was extremely difficult. especially when we are trying to create something that fits into the workflow we have to go through that entire workflow ourselves to test that it is functioning correctly.\nanother issue is that with neither of us being experts in kubernetes there was a lot of trial and error to get things like ingresses to work the way we wanted them to. it seems as though a lot of kubernetes examples and documentation have quickly become outdated so we found ourselves in situations where we were trying to make old code work instead of using the new code.\naccomplishments that we're proud of\ni ultimately learned a lot about how to effectively debug kuberenetes issues and william became an expert on git (and is going to make his first open source contribution soon!)\nwhat we learned\nin trying to follow some tutorials that are purely for kuberentes, we started to understand how much simpler civo made the process. we spent a good couple of hours trying to understand all ten of the files needed to create an application with an ingress from this article: https://medium.com/kubernetes-tutorials/deploying-traefik-as-ingress-controller-for-your-kubernetes-cluster-b03a0672ae0c\nonly to eventually realize that 80% of it was necessary because civo has abstracted / simplified much of that. all we needed was two file for the ingresses and it worked great!\nwhat's next for civo x pyroscope\nthere's a couple of additions we'd like to add here, but didn't have time:\ncreate a plugin in the https://github.com/civo/kubernetes-marketplace to simplify adding a pyroscope server to civo \u2014 going to be williams first open source contribution!\npublish our github action: this will allow people to create this staging server + profiler combination as long as they've set up a kubernetes cluster with civo\nadd a load testing tool (i.e. k6). the impact of performance issues in flamegraphs become more apparent as the server is under heavier load. it would be cool to add a service that sends fake traffic (or mocks of real traffic) to make the profiles more realistic\nthe web app is a little slow right now so sometimes the link to that will break (ran out of time to fix)", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59503450}, {"Unnamed: 0": 3533, "autor": "Pawfect", "date": null, "content": "Inspiration\nCats.\nNah, but seriously? Right off the bat, this was going to be a ridiculous hack. When we thought of the 'zen' concept, we thought: what's the best way to relieve stress? Who can we always count on to vent our frustration?\nOur pets. Especially if you force them into the same room.\nWhat it does\npawfect.tech has one function*: to generate you the perfect pet meme. Simply click the \"Generate\" button and be amazed. Unsatisfied? First of all, how dare you? Second of all, it's okay, we got you, homie. Just refresh the page. Boom. New randomly generated meme or your money back, guaranteed.\n*As of now\nHow we built it\non the front end: -created the entire website interface -wrestled with html and css -created a modal popup window and button\nOn the back end: -used python, html, JavaScript to incorporate a working random image generator -expanded upon the generator so it works with gifs too\non the server and web hosting site: -took advantage of the free domain.com deal to create our amazing domain -set up an azure static web app and connected this to our GitHub repository via a TXT-type hostname record, allowing for automatic updates on the workflow -added the DNS record for the domain 'pawfect.tech' onto Azure -waited for it to validate the domain name\nChallenges we ran into\n-lack of javascript knowledge -forgetting everything -lack of sleep\nAccomplishments that we're proud of\nWe are proud of creating a functioning* website, first of all. All three of us are beginners and w entered this event aiming to learn more about programming and collaborating in general. Overall, we learned a lot, and Quan managed to land another LinkedIn connection\n*standby for definition.\nWhat we learned\nWe learned tons of stuff, including but not limited to: -Github functions -Github desktop functions -Javascript -Azure hosting -Github pages -Domain name functionality -HTML, CSS (or rather, reviewed it) -How long we can go without sleep before we go crazy\nWhat's next for Pawfect\nWhat's next for Pawfect? Well, we hope to increase the functionality of our website and become a reliable source of memes. When our DNS server finally validates our domain, pawfect.tech, the website URL will switch over to the actual name, as opposed to the automatically generated one it's hosted on now.\nEventually, we are aiming to branch out and establish PawTinder, where pets are open to forming romantic relationships.\nEDIT THE LINK LATER", "link": "https://devpost.com/software/pawfect-m159hc", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\ncats.\nnah, but seriously? right off the bat, this was going to be a ridiculous hack. when we thought of the 'zen' concept, we thought: what's the best way to relieve stress? who can we always count on to vent our frustration?\nour pets. especially if you force them into the same room.\nwhat it does\npawfect.tech has one function*: to generate you the perfect pet meme. simply click the \"generate\" button and be amazed. unsatisfied? first of all, how dare you? second of all, it's okay, we got you, homie. just refresh the page. boom. new randomly generated meme or your money back, guaranteed.\n*as of now\nhow we built it\non the front end: -created the entire website interface -wrestled with html and css -created a modal popup window and button\non the back end: -used python, html, javascript to incorporate a working random image generator -expanded upon the generator so it works with gifs too\non the server and web hosting site: -took advantage of the free domain.com deal to create our amazing domain -set up an azure static web app and connected this to our github repository via a txt-type hostname record, allowing for automatic updates on the workflow -added the dns record for the domain 'pawfect.tech' onto azure -waited for it to validate the domain name\nchallenges we ran into\n-lack of javascript knowledge -forgetting everything -lack of sleep\naccomplishments that we're proud of\nwe are proud of creating a functioning* website, first of all. all three of us are beginners and w entered this event aiming to learn more about programming and collaborating in general. overall, we learned a lot, and quan managed to land another linkedin connection\n*standby for definition.\nwhat we learned\nwe learned tons of stuff, including but not limited to: -github functions -github desktop functions -javascript -azure hosting -github pages -domain name functionality -html, css (or rather, reviewed it) -how long we can go without sleep before we go crazy\nwhat's next for pawfect\nwhat's next for pawfect? well, we hope to increase the functionality of our website and become a reliable source of memes. when our dns server finally validates our domain, pawfect.tech, the website url will switch over to the actual name, as opposed to the automatically generated one it's hosted on now.\neventually, we are aiming to -----> branch !!!  out and establish pawtinder, where pets are open to forming romantic relationships.\nedit the link later", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59503533}, {"Unnamed: 0": 3545, "autor": "Let's Play", "date": null, "content": "Inspiration\nWe\u2019ve all tried to learn instruments and know how challenging it can be to keep up the regular schedule needed to learn. We realized that it helped when we heard music that we wanted to play, because it reminded us of what the hard work was for. So we decided to create an app that could track our practice to keep us accountable and give us inspiration when we didn\u2019t feel like putting in the work. From looking at other habit tracker reviews we also realized some people wanted the chance to skip habits occasionally. This would make following the routine less stressful, and prevent you from saying \u201cwhy even bother?\u201d. Thus our idea was born.\nWhat it does\nWhat we needed was an app that would do a few things Remind us when to practice Keep track of the days we practiced and how many days in a row we were successful Would give us the option to have a \u201clazy day\u201d by allocating a certain number of tokens which we could use if we didn\u2019t want to practice but wanted to keep our streak Perhaps most importantly, inspire us. We wanted an app that would play music from your library that would remind you of the reason you were practicing in the first place. Unfortunately with our limited time and knowledge of React and APIs, we were unable to complete a few of these goals. We did, however, create a nav bar and a calendar.\nHow we built it\nUsing react, we aimed to construct a web application, with the group members doing a divide and conquer approach.\nChallenges we ran into\nWe ran into the challenge where when 3 of us worked on separate things, merging the 3 git branches together the app would error. Also only one of us had worked with React before, so learning just the right amount of knowledge to make the app was difficult as it was time consuming. One of us tried very hard to work with the Spotify API, which was built well for developers, but she did not have the React knowledge to fulfill this task.\nAccomplishments that we're proud of\nWe created a webapp with several features. We had a hack that we had a vision for and we strived to complete it. Although some of our planned features are missing, we were able to come up with a plan that we all were excited to execute.\nWhat we learned\nWe learned the process of collaborating on github, as well as becoming more familiar with the process of coding React. We also got to use API\u2019s we didn\u2019t previously have experience with, making this experience one more true to the real process of development, and different from the more isolated approach in classrooms.\nWhat's next for Let's Play\nWe\u2019d like to merge the separate branches together, setting up accounts with google oauth, and storing accounts using a database. Implementing lazy tokens would be our next big goal before trying to integrate Spotify again. Perhaps we need to learn more about React to do this.", "link": "https://devpost.com/software/learn-to-play", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nwe\u2019ve all tried to learn instruments and know how challenging it can be to keep up the regular schedule needed to learn. we realized that it helped when we heard music that we wanted to play, because it reminded us of what the hard work was for. so we decided to create an app that could track our practice to keep us accountable and give us inspiration when we didn\u2019t feel like putting in the work. from looking at other habit tracker reviews we also realized some people wanted the chance to skip habits occasionally. this would make following the routine less stressful, and prevent you from saying \u201cwhy even bother?\u201d. thus our idea was born.\nwhat it does\nwhat we needed was an app that would do a few things remind us when to practice keep track of the days we practiced and how many days in a row we were successful would give us the option to have a \u201clazy day\u201d by allocating a certain number of tokens which we could use if we didn\u2019t want to practice but wanted to keep our streak perhaps most importantly, inspire us. we wanted an app that would play music from your library that would remind you of the reason you were practicing in the first place. unfortunately with our limited time and knowledge of react and apis, we were unable to complete a few of these goals. we did, however, create a nav bar and a calendar.\nhow we built it\nusing react, we aimed to construct a web application, with the group members doing a divide and conquer approach.\nchallenges we ran into\nwe ran into the challenge where when 3 of us worked on separate things, merging the 3 git -----> branches !!!  together the app would error. also only one of us had worked with react before, so learning just the right amount of knowledge to make the app was difficult as it was time consuming. one of us tried very hard to work with the spotify api, which was built well for developers, but she did not have the react knowledge to fulfill this task.\naccomplishments that we're proud of\nwe created a webapp with several features. we had a hack that we had a vision for and we strived to complete it. although some of our planned features are missing, we were able to come up with a plan that we all were excited to execute.\nwhat we learned\nwe learned the process of collaborating on github, as well as becoming more familiar with the process of coding react. we also got to use api\u2019s we didn\u2019t previously have experience with, making this experience one more true to the real process of development, and different from the more isolated approach in classrooms.\nwhat's next for let's play\nwe\u2019d like to merge the separate branches together, setting up accounts with google oauth, and storing accounts using a database. implementing lazy tokens would be our next big goal before trying to integrate spotify again. perhaps we need to learn more about react to do this.", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 0, "media": null, "medialink": null, "identifyer": 59503545}, {"Unnamed: 0": 3560, "autor": "Is this my friend?", "date": null, "content": "Inspiration\nWith so many accounts being compromised in data breaches every year within the social media space, its hard to keep track whether a person posting something online is really them.\nOur concept surrounds the question, \"Is there a way I can tell if this person is really the same person based on their past social media and current social media activity?\"\nFor our project we have chosen to analyze user's Hacker News' posts but plan to expand to other social media platforms.\nWhat it does\n\"Is this my friend?\" analyzes a user's hacker news' posts and comments to generate the sentiment displayed in them. In the future, we plan to compare the sentiment from the current month with the user's past statistics and generate a score to check whether user is the same person or chance of anomalous behavior.\nHow we built it\nBrainstorming\nWe spent the first few hours to brainstorm among the different project categories before finalizing on the \"Ever Vigilant\" Hack category.\nDesign\nFollowing deciding the idea we all worked on different aspects of it, the initial figma designs, created by Zi were really helpful to guide our frontend development at a later stage\nCollaboration\nWe used a github repository and features such as branches, pull requests and merged any new features we worked on. When one of the team members was stuck on an aspect, we usually got on a slack call to debug it with them.\nAccessibility First\nWhen designing interfaces, we tried our best to follow some rules from WCAG. For example, all the color we used passed the test from Colour Contrast Analyzer (CCA) and achieved a result of AAA level. Also, when coding the program, we added description for meaningful images as well as leave the description blank for all decorative images.\nChallenges we ran into\nOur initial idea was to analyze user's Twitter tweets, but the Twitter developer API request process was slightly longer and was still under processing, so we decided to choose an alternate API.\nAccomplishments that we're proud of\nBase concept and MVP . When designing interfaces, we tried our best to follow some rules from WCAG. For example, all the color we used passed the test from Colour Contrast Analyzer (CCA) and achieved a result of AAA level. Also, when coding the program, we added description for meaningful images as well as leave the description blank for all decorative images.\nWhat we learned\nWorking with various APIs - Hacker News, Azure Sentiment Analysis API\nAccessibility guidelines for the Web\nLearnt and experimented with React\nWhat's next for Is this my friend?\nIncorporate functionality to analyzing Reddit user's posts\nIncorporate functionality to analyze Twitter user's tweets\nIncorporate code with more semantic elements and look more into how transition animation could probably influence usability", "link": "https://devpost.com/software/is-this-my-friend", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nwith so many accounts being compromised in data breaches every year within the social media space, its hard to keep track whether a person posting something online is really them.\nour concept surrounds the question, \"is there a way i can tell if this person is really the same person based on their past social media and current social media activity?\"\nfor our project we have chosen to analyze user's hacker news' posts but plan to expand to other social media platforms.\nwhat it does\n\"is this my friend?\" analyzes a user's hacker news' posts and comments to generate the sentiment displayed in them. in the future, we plan to compare the sentiment from the current month with the user's past statistics and generate a score to check whether user is the same person or chance of anomalous behavior.\nhow we built it\nbrainstorming\nwe spent the first few hours to brainstorm among the different project categories before finalizing on the \"ever vigilant\" hack category.\ndesign\nfollowing deciding the idea we all worked on different aspects of it, the initial figma designs, created by zi were really helpful to guide our frontend development at a later stage\ncollaboration\nwe used a github repository and features such as -----> branches !!! , pull requests and merged any new features we worked on. when one of the team members was stuck on an aspect, we usually got on a slack call to debug it with them.\naccessibility first\nwhen designing interfaces, we tried our best to follow some rules from wcag. for example, all the color we used passed the test from colour contrast analyzer (cca) and achieved a result of aaa level. also, when coding the program, we added description for meaningful images as well as leave the description blank for all decorative images.\nchallenges we ran into\nour initial idea was to analyze user's twitter tweets, but the twitter developer api request process was slightly longer and was still under processing, so we decided to choose an alternate api.\naccomplishments that we're proud of\nbase concept and mvp . when designing interfaces, we tried our best to follow some rules from wcag. for example, all the color we used passed the test from colour contrast analyzer (cca) and achieved a result of aaa level. also, when coding the program, we added description for meaningful images as well as leave the description blank for all decorative images.\nwhat we learned\nworking with various apis - hacker news, azure sentiment analysis api\naccessibility guidelines for the web\nlearnt and experimented with react\nwhat's next for is this my friend?\nincorporate functionality to analyzing reddit user's posts\nincorporate functionality to analyze twitter user's tweets\nincorporate code with more semantic elements and look more into how transition animation could probably influence usability", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59503560}, {"Unnamed: 0": 3591, "autor": "ParkingOps", "date": null, "content": "Inspiration\nTo brainstorm ideas, our team discussed what we hated the most about driving and a major complaint was parking. Our team is from San Francisco, so we all knew the absolute pain it is to find any parking. So, we decided on a project that would assist us in finding a parking space.\nWhat it does\nOur project calculates the best possible route to your destination like any normal navigation app, but the difference is that it also displays all available parking locations in a user-defined radius around it. Rates and addresses for the parking are given so that users can choose the perfect parking space for them!\nHow we built it\nWe began by creating a GitHub repository where we all made branches from. We would code separate parts of the project, and when we were ready, we all merged the code together.\nWe used the Inrix APIs to gather parking information in a specific radius around the target destination. Once we had this, we could display it on our website in a clean and readable format.\nChallenges we ran into\nWe didn't know each other prior to the Hackathon, so we weren't sure what we were capable of.\nTwo of our members were very experienced in Python, but the other member of our team had zero experience in Python. Getting him used to the syntax of Python took a bit, but we pulled it off.\nWe had some issues formatting our website, one of our members on the team had no experience in HTML so we were not as efficient\nAccomplishments that we're proud of\nDespite not knowing each other before the Hackathon, we all worked extremely well as a team. We collaborated on code, shared ideas, and worked efficiently on our project.\nThis being our first hackathon, we're very proud of the progress we made. Being able to work with an industry-standard API to make something that has real-life application was a very cool change of pace for us.\nWhat we learned\nThis hackathon has been eye-opening for all of us. We learned so much about the real-life application for the things we had been discussing in class, specifically APIs.\nWe all gained experience in hackathons and we're all excited to participate in more!\nWhat's next for ParkingOps\nWhile this was a super cool project to work on, we learned after that it has already been made before (by the company sponsoring this hackathon no less). But that doesn't mean we don't plan on working with each other in the future! We all got along very well so maybe we will work on a different project together.", "link": "https://devpost.com/software/parkingops-5ewoq7", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nto brainstorm ideas, our team discussed what we hated the most about driving and a major complaint was parking. our team is from san francisco, so we all knew the absolute pain it is to find any parking. so, we decided on a project that would assist us in finding a parking space.\nwhat it does\nour project calculates the best possible route to your destination like any normal navigation app, but the difference is that it also displays all available parking locations in a user-defined radius around it. rates and addresses for the parking are given so that users can choose the perfect parking space for them!\nhow we built it\nwe began by creating a github repository where we all made -----> branches !!!  from. we would code separate parts of the project, and when we were ready, we all merged the code together.\nwe used the inrix apis to gather parking information in a specific radius around the target destination. once we had this, we could display it on our website in a clean and readable format.\nchallenges we ran into\nwe didn't know each other prior to the hackathon, so we weren't sure what we were capable of.\ntwo of our members were very experienced in python, but the other member of our team had zero experience in python. getting him used to the syntax of python took a bit, but we pulled it off.\nwe had some issues formatting our website, one of our members on the team had no experience in html so we were not as efficient\naccomplishments that we're proud of\ndespite not knowing each other before the hackathon, we all worked extremely well as a team. we collaborated on code, shared ideas, and worked efficiently on our project.\nthis being our first hackathon, we're very proud of the progress we made. being able to work with an industry-standard api to make something that has real-life application was a very cool change of pace for us.\nwhat we learned\nthis hackathon has been eye-opening for all of us. we learned so much about the real-life application for the things we had been discussing in class, specifically apis.\nwe all gained experience in hackathons and we're all excited to participate in more!\nwhat's next for parkingops\nwhile this was a super cool project to work on, we learned after that it has already been made before (by the company sponsoring this hackathon no less). but that doesn't mean we don't plan on working with each other in the future! we all got along very well so maybe we will work on a different project together.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59503591}, {"Unnamed: 0": 3689, "autor": "Meibomian Glands", "date": null, "content": "Title\nMeibomian Gland Atrophy Evaluation\nThe Written Report's link is as below. The report contains far more concrete information of what we did and many additional trials and results.\nLINK for Written Report\nLINK for Poster\nLINK for Video\nLINK for Github\nTeam\nShixuan Li (sli221), Zhenhao Sun (zsun32), Mingye Zhang (mzhan146)\nMotivation\nDry eye syndrome \u2014 also called dry eye disease (DED) \u2014 is one of the most common eye conditions worldwide. Meibomian gland dysfunction is one of the main factors that cause DED, since the meibomian glands produce an oily component of the tear in the eyelids. The diagnosis of Dry Eye Syndrome usually requires doctors to analyze the images of patients\u2019 meibomian glands inside both upper and lower lids.\nHowever, since the glands are embedded under the skin, it\u2019s hard for doctors to meet a consensus on the shape and locations of each of the glands since the visual information is usually not deterministic. Thus, we hope to develop a solution to achieve instance segmentation on meibomian gland images. We believe it can give a clinic more reference for their diagnosis.\nIntroduction\nIn this project we implemented the proposal-based and proposal-free models for instance segmentation. Then use principle curve + online PCA along with Cubic Spline for feature learning and gland extension. Eventually we implement a generative model to refine the predicted instance masks.\nMethodology\nDataset\nWe are using a dataset released with the paper Associations with Meibomian Gland Atrophy in Daily Contact Lens Wearers. The data is a collection of grayscale images of meibomian glands located in the upper and lower lids of human eyes, with the masks of each gland instance annotated as collections of data points located on the contour of each gland. We have a total of 764 images. 560 of them are in the training set and 204 of them are in the testing set.\nData Processing\nThe first step we do for preliminary processing is to align the ground truth mask with the original images. Since the ground truth masks are labeled as dots on the contour of each gland, we take the enclosed area of the contour as the ground truth mask for each gland. We also added erosion and dilation to the masks to make them better aligned with the raw image.\nSecondly, due to the fixed angle of the camera, we decided to take into account only the 50% area in the middle of each image for our final evaluation. A sample of the ground truth masks and the labeled middle 50% areas is listed above right (between the white lines) Finally, we add the gaussian filtering to our images, augmenting the contrast of our data.\nProposal-Based Segmentation (Mask R-CNN)\nA typical way of starting an instance segmentation task is to implement the classic baseline models. One of the most typical baseline models for image segmentation is Mask R-CNN. An overview of its structure is shown below:\nA proposal-based solution predicts the bounding box of each item, recognizing the class and location for each of them, and then performs segmentation within each bounding box. Thus we see that the number of items and their classes are determined by the bounding box prediction step, and the segmentation step simply segment within the bound step 1 provides.\nProposal-Free Segmentation (PSPNet & DCAN, Contour Elimination Solution)\nFirstly, we implemented the PSPNet model (Pyramid Scene Parsing Network). PSPNet is a proposal-free semantic segmentation model. The advantage of the PSPNet is that it provides perception space of different scales which allows the neural network to capture more information from the neighborhood l. An overview of its structure is as above:\nTo make it work for instance segmentation, we predict two branches: the gland entities and their contours. Then we do a subtraction between the two to get the instance results.\nWe notice that it does a much better job than before in a way that each gland is completely captured and the contours indicate that it knows where each instance is, as contours are indicators of boundaries. However, the downside of this method is that we cannot guarantee that it can separate each gland perfectly at each time. From the connectivity coloring image on the bottom left side, we see that some glands are still partially connected. Indeed such issue exists for most images. The best mIOU we get from this method is 69.92% for mask, and 26.25% for contour.\nProposal-Free Segmentation (Discriminative Loss, End-to-End Solution)\nThus we turn to another solution referring to the paper Semantic Instance Segmentation With A Discriminative Loss Function. The underlying idea is to implement a discriminative loss function after the neural network projects the features of each pixel onto a high-dimensional space, pulling vectors representing pixels from the same gland together while pushing those belong to different glands apart. A 2-D representation of such mechanism is shown below:\nWe can understand the process of segmentation as that we predict the semantic segmentation, with information of each pixel projected on the high-dimensional space known. Then due to the discriminative loss, the distribution of the vectors on the high-dimensional space are clustered by instances. We also have a separate branch predicting the number of instances in the image. Combining all information, we can do a K-Means clustering on the high-dimensional space, each cluster representing pixels that belong to the same gland.\nPost Analysis\nAfterwards, we tried to learn the features of the glands. The features we attempted to collect are the length and the curvature of the glands. To achieve that, we implemented the Principle Curve with Online PCA, and Cubic Spline. Principal Curve captures the shape of each gland via an arbitrary amount of backbone key points. Thus we are able to attain the curvature attribute. However, since the Principle Curve can not measure curve length, we use Cubic Spline to fit the key point in order to attain the curve length.\nWe also tried to extend the gland to fulfill a complete gland structure, since the structure of the eye itself, especially the upper lid, blocks some parts of the gland. We chose to use a linear extension along the growth slope at the end of the gland for the extension. Thus there are three things we need to take care of: the extension key points (where we start the extension), the slope of our extension, and the length of our extension. The slope and the key points for our extension can be calculated via the two-key-point principle curve.\nGenerative Modeling\nObviously, the mask prediction results are not always clean. Thus, in order to get better segmentation results, we build a generative model to make the messy masks neat and clean. The input is the mask for each gland instance, and the output is the cleaned mask. The model we use is Pix2Pix. A sample of the results is shown on the right:\nImpact\nOur work can extend its utility to tasks such as remote diagnosis, as the only data input necessary is an image of the meibomian glands. The model would also be helpful for patients for whom hospital visits may be inconvenient, as they can do a self-check using the model to evaluate their potential of getting a DED. Segmentation could be a tool for doctors to visualize and make decisions, moreover, it can help inexperienced doctors learn. With instance-level segmentation masks, we are also able to collect statistical information to evaluate the severity of the disease or conclude features of typical atrophy/healthy glands.\nReflection\nWe successfully accomplished almost everything we mentioned in our proposal, plus excessive image processing for gland extension. All worked were done by our 2 month + efforts. The target for our work is to help clinics for the diagnosis of dry-eye syndrome by achieving Meibomian Gland Atrophy Evaluation metrics via amodal instance segmentation. Our ideal plan was to ultimately create an end-to-end model, of which the most difficult part is to find out how to output multiple labels for overlapped pixels of multiple glands (traditional instance segmentation only predicts one label for each pixel, thus unable to identify if the pixel is shared by two item). However, we soon found that it is overly hard, since we rarely find resource for guidance as well. Thus, we tried multiple ways to accomplish our goal, and the best solution is to make it two-stage, meaning we firstly to instance segmentation and then add on a generative model to complete all individual glands.\nAs we mentioned in our proposal, the best metric will be the mIOU. The baseline (traditional two-stage instance segmentation method, Mask RCNN) is 23.46%. InstanceCut/DCAN/PSPNet based solutions (predicts the mask, via semantic segmentation, of both the glands and the contour of the glands, then do a subtraction) has best result of mIOU 69.92% for mask, and 26.25% for contour. The End-to-End Discriminative Loss method achieves the best result which is 70.03%. After generative model (pix2pix), the mIOU achieve 72.88%.\nWe added on post processing between our generative model and the instance segmentation model. This part was not planned. We did it because we noticed an information in the dataset's introduction, saying that the gland images of the upper lid was not complete, due to the inevitable hidden areas while photo taking. Thus, we decided to use image processing methods to extend and complete each gland. If we can do it again, we'll do it early and let the completed glands to be the input of our segmentation models, which makes more sense.\nAlthough we did a lot of work on model training, most time was spent on data processing. The initial data cleaning and processing took almost 1 month, due to many unexpected errors and manual corrections. Our greatest breakthrough was not only modified and tuned based on many models, but we developed a original way to accomplish principle curve and combine the method with online PCA for smoothing while doing gland extension. We simplified an NP optimization problem into a P problem.\nDivision of labor\nShixuan Li: Image processing (data cleaning, gland extension), Baseline preparation (Mask R-CNN). End-to-end methods training, testing and fine-tuning (Discriminative Loss).\nZhenhao Sun: Image processing (data cleaning), End-to-end methods training and testing(DCAN), Gland completion generative model (Pix2Pix)\nMingye Zhang: Image processing (data cleaning), End-to-end methods training and testing (InstanceCut). Proof and theory, visualizations (for all result data and intermediate auto-visualization system) and fine-tuning.\nReference\nDeep Residual Learning for Image Recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. CVPR 2015\nMask R-CNN. Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, Ross Girshick. CVPR 2017\nPyramid Scene Parsing Network. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia. CVPR 2017\nSemantic Instance Segmentation with a Discriminative Loss Function. Bert De Brabandere, Davy Neven, Luc Van Gool. CVPR 2017\nImage-to-Image Translation with Conditional Adversarial Networks. Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros. CVPR 2017\nPrinciple Curves. Trevor Hastie, Werner Stuetzle. Stanford University\nInstanceCut: from Edges to Instances with MultiCut. Alexander Kirillov, Evgeny Levinkov, Bjoern Andres, Bogdan Savchynskyy, Carsten Rother. CVPR 2017\nDCAN: Deep contour-aware networks for object instance segmentation from histology images. Hao Chen, Xiaojuan Qi, Lequan Yu, Qi Dou, Jing Qin, Pheng-Ann Heng", "link": "https://devpost.com/software/meibomian-glands", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "title\nmeibomian gland atrophy evaluation\nthe written report's link is as below. the report contains far more concrete information of what we did and many additional trials and results.\nlink for written report\nlink for poster\nlink for video\nlink for github\nteam\nshixuan li (sli221), zhenhao sun (zsun32), mingye zhang (mzhan146)\nmotivation\ndry eye syndrome \u2014 also called dry eye disease (ded) \u2014 is one of the most common eye conditions worldwide. meibomian gland dysfunction is one of the main factors that cause ded, since the meibomian glands produce an oily component of the tear in the eyelids. the diagnosis of dry eye syndrome usually requires doctors to analyze the images of patients\u2019 meibomian glands inside both upper and lower lids.\nhowever, since the glands are embedded under the skin, it\u2019s hard for doctors to meet a consensus on the shape and locations of each of the glands since the visual information is usually not deterministic. thus, we hope to develop a solution to achieve instance segmentation on meibomian gland images. we believe it can give a clinic more reference for their diagnosis.\nintroduction\nin this project we implemented the proposal-based and proposal-free models for instance segmentation. then use principle curve + online pca along with cubic spline for feature learning and gland extension. eventually we implement a generative model to refine the predicted instance masks.\nmethodology\ndataset\nwe are using a dataset released with the paper associations with meibomian gland atrophy in daily contact lens wearers. the data is a collection of grayscale images of meibomian glands located in the upper and lower lids of human eyes, with the masks of each gland instance annotated as collections of data points located on the contour of each gland. we have a total of 764 images. 560 of them are in the training set and 204 of them are in the testing set.\ndata processing\nthe first step we do for preliminary processing is to align the ground truth mask with the original images. since the ground truth masks are labeled as dots on the contour of each gland, we take the enclosed area of the contour as the ground truth mask for each gland. we also added erosion and dilation to the masks to make them better aligned with the raw image.\nsecondly, due to the fixed angle of the camera, we decided to take into account only the 50% area in the middle of each image for our final evaluation. a sample of the ground truth masks and the labeled middle 50% areas is listed above right (between the white lines) finally, we add the gaussian filtering to our images, augmenting the contrast of our data.\nproposal-based segmentation (mask r-cnn)\na typical way of starting an instance segmentation task is to implement the classic baseline models. one of the most typical baseline models for image segmentation is mask r-cnn. an overview of its structure is shown below:\na proposal-based solution predicts the bounding box of each item, recognizing the class and location for each of them, and then performs segmentation within each bounding box. thus we see that the number of items and their classes are determined by the bounding box prediction step, and the segmentation step simply segment within the bound step 1 provides.\nproposal-free segmentation (pspnet & dcan, contour elimination solution)\nfirstly, we implemented the pspnet model (pyramid scene parsing network). pspnet is a proposal-free semantic segmentation model. the advantage of the pspnet is that it provides perception space of different scales which allows the neural network to capture more information from the neighborhood l. an overview of its structure is as above:\nto make it work for instance segmentation, we predict two -----> branches !!! : the gland entities and their contours. then we do a subtraction between the two to get the instance results.\nwe notice that it does a much better job than before in a way that each gland is completely captured and the contours indicate that it knows where each instance is, as contours are indicators of boundaries. however, the downside of this method is that we cannot guarantee that it can separate each gland perfectly at each time. from the connectivity coloring image on the bottom left side, we see that some glands are still partially connected. indeed such issue exists for most images. the best miou we get from this method is 69.92% for mask, and 26.25% for contour.\nproposal-free segmentation (discriminative loss, end-to-end solution)\nthus we turn to another solution referring to the paper semantic instance segmentation with a discriminative loss function. the underlying idea is to implement a discriminative loss function after the neural network projects the features of each pixel onto a high-dimensional space, pulling vectors representing pixels from the same gland together while pushing those belong to different glands apart. a 2-d representation of such mechanism is shown below:\nwe can understand the process of segmentation as that we predict the semantic segmentation, with information of each pixel projected on the high-dimensional space known. then due to the discriminative loss, the distribution of the vectors on the high-dimensional space are clustered by instances. we also have a separate branch predicting the number of instances in the image. combining all information, we can do a k-means clustering on the high-dimensional space, each cluster representing pixels that belong to the same gland.\npost analysis\nafterwards, we tried to learn the features of the glands. the features we attempted to collect are the length and the curvature of the glands. to achieve that, we implemented the principle curve with online pca, and cubic spline. principal curve captures the shape of each gland via an arbitrary amount of backbone key points. thus we are able to attain the curvature attribute. however, since the principle curve can not measure curve length, we use cubic spline to fit the key point in order to attain the curve length.\nwe also tried to extend the gland to fulfill a complete gland structure, since the structure of the eye itself, especially the upper lid, blocks some parts of the gland. we chose to use a linear extension along the growth slope at the end of the gland for the extension. thus there are three things we need to take care of: the extension key points (where we start the extension), the slope of our extension, and the length of our extension. the slope and the key points for our extension can be calculated via the two-key-point principle curve.\ngenerative modeling\nobviously, the mask prediction results are not always clean. thus, in order to get better segmentation results, we build a generative model to make the messy masks neat and clean. the input is the mask for each gland instance, and the output is the cleaned mask. the model we use is pix2pix. a sample of the results is shown on the right:\nimpact\nour work can extend its utility to tasks such as remote diagnosis, as the only data input necessary is an image of the meibomian glands. the model would also be helpful for patients for whom hospital visits may be inconvenient, as they can do a self-check using the model to evaluate their potential of getting a ded. segmentation could be a tool for doctors to visualize and make decisions, moreover, it can help inexperienced doctors learn. with instance-level segmentation masks, we are also able to collect statistical information to evaluate the severity of the disease or conclude features of typical atrophy/healthy glands.\nreflection\nwe successfully accomplished almost everything we mentioned in our proposal, plus excessive image processing for gland extension. all worked were done by our 2 month + efforts. the target for our work is to help clinics for the diagnosis of dry-eye syndrome by achieving meibomian gland atrophy evaluation metrics via amodal instance segmentation. our ideal plan was to ultimately create an end-to-end model, of which the most difficult part is to find out how to output multiple labels for overlapped pixels of multiple glands (traditional instance segmentation only predicts one label for each pixel, thus unable to identify if the pixel is shared by two item). however, we soon found that it is overly hard, since we rarely find resource for guidance as well. thus, we tried multiple ways to accomplish our goal, and the best solution is to make it two-stage, meaning we firstly to instance segmentation and then add on a generative model to complete all individual glands.\nas we mentioned in our proposal, the best metric will be the miou. the baseline (traditional two-stage instance segmentation method, mask rcnn) is 23.46%. instancecut/dcan/pspnet based solutions (predicts the mask, via semantic segmentation, of both the glands and the contour of the glands, then do a subtraction) has best result of miou 69.92% for mask, and 26.25% for contour. the end-to-end discriminative loss method achieves the best result which is 70.03%. after generative model (pix2pix), the miou achieve 72.88%.\nwe added on post processing between our generative model and the instance segmentation model. this part was not planned. we did it because we noticed an information in the dataset's introduction, saying that the gland images of the upper lid was not complete, due to the inevitable hidden areas while photo taking. thus, we decided to use image processing methods to extend and complete each gland. if we can do it again, we'll do it early and let the completed glands to be the input of our segmentation models, which makes more sense.\nalthough we did a lot of work on model training, most time was spent on data processing. the initial data cleaning and processing took almost 1 month, due to many unexpected errors and manual corrections. our greatest breakthrough was not only modified and tuned based on many models, but we developed a original way to accomplish principle curve and combine the method with online pca for smoothing while doing gland extension. we simplified an np optimization problem into a p problem.\ndivision of labor\nshixuan li: image processing (data cleaning, gland extension), baseline preparation (mask r-cnn). end-to-end methods training, testing and fine-tuning (discriminative loss).\nzhenhao sun: image processing (data cleaning), end-to-end methods training and testing(dcan), gland completion generative model (pix2pix)\nmingye zhang: image processing (data cleaning), end-to-end methods training and testing (instancecut). proof and theory, visualizations (for all result data and intermediate auto-visualization system) and fine-tuning.\nreference\ndeep residual learning for image recognition. kaiming he, xiangyu zhang, shaoqing ren, jian sun. cvpr 2015\nmask r-cnn. kaiming he, georgia gkioxari, piotr doll\u00e1r, ross girshick. cvpr 2017\npyramid scene parsing network. hengshuang zhao, jianping shi, xiaojuan qi, xiaogang wang, jiaya jia. cvpr 2017\nsemantic instance segmentation with a discriminative loss function. bert de brabandere, davy neven, luc van gool. cvpr 2017\nimage-to-image translation with conditional adversarial networks. phillip isola, jun-yan zhu, tinghui zhou, alexei a. efros. cvpr 2017\nprinciple curves. trevor hastie, werner stuetzle. stanford university\ninstancecut: from edges to instances with multicut. alexander kirillov, evgeny levinkov, bjoern andres, bogdan savchynskyy, carsten rother. cvpr 2017\ndcan: deep contour-aware networks for object instance segmentation from histology images. hao chen, xiaojuan qi, lequan yu, qi dou, jing qin, pheng-ann heng", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 6, "media": null, "medialink": null, "identifyer": 59503689}, {"Unnamed: 0": 3766, "autor": "Traffic Sign CNN Classifier", "date": null, "content": "Title\nTraffic Sign CNN Classifier\nWho\nSebastian Martino\nCode\nhttps://github.com/SebastianMartino/Traffic-Sign-CNN-Classifier\nIntroduction\nThe problem I am trying to solve with this project is the classification of road signs by making use of CNNs. The research paper I am reimplementing can be found here. The objectives of this paper included both the simultaneous detection and classification of traffic signs, however, this project will limit its scope to only solve the classification of these traffic signs.\nRelated Work\nThere are a number of different works beyond the research paper I am basing this project on that have attempted to solve this problem. One such example can be found in this article here. This example walks through creating a CNN based network for detection and classification of traffic signs using tensorflow and keras using the GTSRB dataset from Kaggle. I also intent to use tensorflow and keras for this project, meaning this related work may serve as a useful reference for my own implementation, however I intend to use a different data set as described in the next section.\nOther Related Works: Building a Road Sign Classifier Traffic Sign Classification\nData\nI intend to use the Chinese Traffic Sign Database which contains 6164 traffic sign images across 58 sign categories with 4170 labeled training images and 1994 testing images. I may look to use other datasets as I work on this project, for example a US traffic sign dataset, but for now this dataset makes sense use due to its free access and pre-labled images.\nUpdate: Pivoted to the German Traffic Sign Recognition Benchmark (GTSRB) dataset which consists of 30,000+ labeled training images and 10,000+ testing images across 43 classes of road signs.\nMethodology\nThe research paper I am reimplementing outlines their network's architecture as a series of 6 convolutional layers which branches after layer 6 into 3 separate convolutional layers, a bounding-box layer, a pixel layer, and a label layer. I intend to take a similar but simpler approach to this architecture; I will likely reduce the number of convolutional layers used, and should not need the branching layers at the end as I am only attempting classification rather than simultaneous detection and classification.\nUpdate: Diverged from architecture outline in research paper, was able to achieve very high accuracy following the modified LeNet Architecture described in this blogpost (with some minor tweaks made myself) which consists of:\n1st Convolution layer, 32 filters, kernel size of 1x1, relu activation\n2nd Convolution layer, 32 filters, kernel size of 5x5, relu activation\nMax pooling, pool size of 2x2\n3rd Convolution layer, 32 filters, kernel size of 5x5, relu activation\nMax pooling, pool size of 2x2\nFlatten layer\n1st Fully connected layer, output size of hidden_dim1 (1024), relu activation\nDropout layer, dropout rate of 0.3\n2nd Fully connected layer, output size of hidden_dim2 (512), relu activation\nDropout layer, dropout rate of 0.3\n3rd and final Fully connected layer, output size of num_classes (43), softmax activation\nMetrics\nIn the research paper I am reimplementing, they were able to achieve an accuracy for simultaneous detection and classification of 88%. My goals for this project will be baseline classification accuracy of 65%, target accuracy of 70%, and a stretch goal accuracy of 85%.\nEthics\nWhy is Deep Learning a good approach to this problem?: With the advent of convolutional neural networks, we have made huge strides in deep learning with image classification. The problem I am approaching in this project, which is purely classification of traffic signs, is therefore a perfect candidate for a deep learning solution with CNNs.\nWho are the major stakeholders in this problem? What are the consequences of mistakes made by your algorithm?: An obvious stakeholder for this problem is the autonomous vehicle industry. In order for a self driving car to operate on the roads, it will certainly need to be able to recognize and interpret road signs in order to follow traffic rules and operate safely on the roads with other vehicles. Because this algorithm is partially responsible for lawful and safe operations of these autonomous vehicles, the consequences of mistakes made by it may have deadly consequences. Imagine if this model being used in a self driving car misinterprets a speed limit sign in a residential neighborhood to read 65mph instead of 25. This would not only put the passengers of at risk with the vehicle driving at unsafe speeds but also endanger other vehicles and pedestrians in the area. For any practical deep learning model to be put to use in an actual self driving car, it is critical that the classifier's accuracy is nearly 100% and that there are other safeguards and redundancies that reduce the chance of these dangerous and deadly mistakes.\nDivision of Labor\nThis is a solo project so I am responsible for every part\nProject Checkin 2 Reflection\nhttps://docs.google.com/document/d/1aEHG3LahXC7Ku-fQdRLr3ng8m6oCknI65Bklm-qSuJA/edit?usp=sharing\nFinal Project Refletion\nSEE UPDATE BELOW", "link": "https://devpost.com/software/traffic-sign-cnn-classifier", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "title\ntraffic sign cnn classifier\nwho\nsebastian martino\ncode\nhttps://github.com/sebastianmartino/traffic-sign-cnn-classifier\nintroduction\nthe problem i am trying to solve with this project is the classification of road signs by making use of cnns. the research paper i am reimplementing can be found here. the objectives of this paper included both the simultaneous detection and classification of traffic signs, however, this project will limit its scope to only solve the classification of these traffic signs.\nrelated work\nthere are a number of different works beyond the research paper i am basing this project on that have attempted to solve this problem. one such example can be found in this article here. this example walks through creating a cnn based network for detection and classification of traffic signs using tensorflow and keras using the gtsrb dataset from kaggle. i also intent to use tensorflow and keras for this project, meaning this related work may serve as a useful reference for my own implementation, however i intend to use a different data set as described in the next section.\nother related works: building a road sign classifier traffic sign classification\ndata\ni intend to use the chinese traffic sign database which contains 6164 traffic sign images across 58 sign categories with 4170 labeled training images and 1994 testing images. i may look to use other datasets as i work on this project, for example a us traffic sign dataset, but for now this dataset makes sense use due to its free access and pre-labled images.\nupdate: pivoted to the german traffic sign recognition benchmark (gtsrb) dataset which consists of 30,000+ labeled training images and 10,000+ testing images across 43 classes of road signs.\nmethodology\nthe research paper i am reimplementing outlines their network's architecture as a series of 6 convolutional layers which -----> branches !!!  after layer 6 into 3 separate convolutional layers, a bounding-box layer, a pixel layer, and a label layer. i intend to take a similar but simpler approach to this architecture; i will likely reduce the number of convolutional layers used, and should not need the branching layers at the end as i am only attempting classification rather than simultaneous detection and classification.\nupdate: diverged from architecture outline in research paper, was able to achieve very high accuracy following the modified lenet architecture described in this blogpost (with some minor tweaks made myself) which consists of:\n1st convolution layer, 32 filters, kernel size of 1x1, relu activation\n2nd convolution layer, 32 filters, kernel size of 5x5, relu activation\nmax pooling, pool size of 2x2\n3rd convolution layer, 32 filters, kernel size of 5x5, relu activation\nmax pooling, pool size of 2x2\nflatten layer\n1st fully connected layer, output size of hidden_dim1 (1024), relu activation\ndropout layer, dropout rate of 0.3\n2nd fully connected layer, output size of hidden_dim2 (512), relu activation\ndropout layer, dropout rate of 0.3\n3rd and final fully connected layer, output size of num_classes (43), softmax activation\nmetrics\nin the research paper i am reimplementing, they were able to achieve an accuracy for simultaneous detection and classification of 88%. my goals for this project will be baseline classification accuracy of 65%, target accuracy of 70%, and a stretch goal accuracy of 85%.\nethics\nwhy is deep learning a good approach to this problem?: with the advent of convolutional neural networks, we have made huge strides in deep learning with image classification. the problem i am approaching in this project, which is purely classification of traffic signs, is therefore a perfect candidate for a deep learning solution with cnns.\nwho are the major stakeholders in this problem? what are the consequences of mistakes made by your algorithm?: an obvious stakeholder for this problem is the autonomous vehicle industry. in order for a self driving car to operate on the roads, it will certainly need to be able to recognize and interpret road signs in order to follow traffic rules and operate safely on the roads with other vehicles. because this algorithm is partially responsible for lawful and safe operations of these autonomous vehicles, the consequences of mistakes made by it may have deadly consequences. imagine if this model being used in a self driving car misinterprets a speed limit sign in a residential neighborhood to read 65mph instead of 25. this would not only put the passengers of at risk with the vehicle driving at unsafe speeds but also endanger other vehicles and pedestrians in the area. for any practical deep learning model to be put to use in an actual self driving car, it is critical that the classifier's accuracy is nearly 100% and that there are other safeguards and redundancies that reduce the chance of these dangerous and deadly mistakes.\ndivision of labor\nthis is a solo project so i am responsible for every part\nproject checkin 2 reflection\nhttps://docs.google.com/document/d/1aehg3lahxc7ku-fqdrlr3ng8m6ockni65bklm-qsuja/edit?usp=sharing\nfinal project refletion\nsee update below", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 8, "media": null, "medialink": null, "identifyer": 59503766}, {"Unnamed: 0": 3857, "autor": "Covid-19 Tracker", "date": null, "content": "Covid-19 Tracker\nCoronavirus disease Case Tracker in the World\nExplore the docs \u00bb\nView Demo \u00b7 Report Bug \u00b7 Request Feature\nAbout The Project\nThis Covid19 repo based on Covid-19 Coronavirus disease Case Tracker. You can check detail of coronavirus cases, recovered and death by country and states using Map and data.\nBuilt With\nMapBox\nBootstrap\nJQuery\nContributing\nContributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are greatly appreciated.\nIf you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag \"enhancement\". Don't forget to give the project a star! Thanks again!\nFork the Project\nCreate your Feature Branch (git checkout -b feature/AmazingFeature)\nCommit your Changes (git commit -m 'Add some AmazingFeature')\nPush to the Branch (git push origin feature/AmazingFeature)\nOpen a Pull Request\nContact\nVijay Chauhan - @mr_vijaychauhan\nProject Link: https://github.com/mr-vijaychauhan/covid19\nAcknowledgments\nUse this space to list resources you find helpful and would like to give credit to. I've included a few of my favorites to kick things off!\nGitHub Pages\nFont Awesome", "link": "https://devpost.com/software/resume-builder-1t4m7r", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "covid-19 tracker\ncoronavirus disease case tracker in the world\nexplore the docs \u00bb\nview demo \u00b7 report bug \u00b7 request feature\nabout the project\nthis covid19 repo based on covid-19 coronavirus disease case tracker. you can check detail of coronavirus cases, recovered and death by country and states using map and data.\nbuilt with\nmapbox\nbootstrap\njquery\ncontributing\ncontributions are what make the open source community such an amazing place to learn, inspire, and create. any contributions you make are greatly appreciated.\nif you have a suggestion that would make this better, please fork the repo and create a pull request. you can also simply open an issue with the tag \"enhancement\". don't forget to give the project a star! thanks again!\nfork the project\ncreate your feature -----> branch !!!  (git checkout -b feature/amazingfeature)\ncommit your changes (git commit -m 'add some amazingfeature')\npush to the branch (git push origin feature/amazingfeature)\nopen a pull request\ncontact\nvijay chauhan - @mr_vijaychauhan\nproject link: https://github.com/mr-vijaychauhan/covid19\nacknowledgments\nuse this space to list resources you find helpful and would like to give credit to. i've included a few of my favorites to kick things off!\ngithub pages\nfont awesome", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59503857}, {"Unnamed: 0": 3860, "autor": "Pet Shop", "date": null, "content": "Inspiration\nIn the world of many ransomware attacks on standard e-commerce platforms. The decentralized approach can remedy this problem. Many instances of the same platform can be dispersed on many nodes which dramatically minimizes potential attack surface. In a standard cloud environment a special protocol should manage specific instances of the frontend and backend part of an e-commerce platform. In a decentralized world it is part of a blockchain protocol. Another aspect in this area is currency transactions. In the standard e-commerce platform special service should be added, in the blockchain we obtain it in a protocol or a smart contract. The pet shop is an example of a decentralized e-commerce platform. It is the only example, our goal is to build an e-commerce decentralized framework dedicated for private and public blockchain networks.\nWhat it does\nIt is a decentralized e-commerce platform dedicated for private and public blockchain networks. It is a shop where potential customers can buy something interesting for pets.\nHow we built it\nWe can partition our solution into three layers. First is the web part. It is written in React. A second layer is blockchain. It is based on solidity smart contracts. The shop contract is the main component. It has a buy and createNewItem function. The buy function is responsible for the buying process. It takes a tuple with a product\u2019s code and an amount of specific product. Second function is responsible for creation of new items and only contarct\u2019s owner can manage this method. The item is ERC20 smart contract interface implementation. Thanks to this all management and change of items amount, transfer, creating are controlled by the smart contract. Last element is delivery smart contract. It allows you to create delivery requests for new items. In the buy function in the shop smart contract is a statement which checks if the balance of an item in a specific smart contract is equal or less than 10 then creates a new delivery request.\nThe webpage of the Pet Shop was deployed on the IPFS protocol (https://still-rice-6959.on.fleek.co).\nThe delivery service is optional. It is dedicated to the automation delivery process for suppliers of goods.\nChallenges we ran into\nThe most challenging for us, was creating a mechanism that allows us to buy many items at one time in a smart contract function.\nAccomplishments that we're proud of\nWe are proud of all parts of the project because we created the proof of concept of a decentralized e-commerce platform.\nWhat we learned\nHardhat and Ethers, what way we can build e-commerce platforms.\nWhat's next for Pet Shop\nWe want to improve web page and add new features e.g:\nadding user profile(i.e displaying orders, displaying and changing user profile),\nadding dashboard for admin (e.g management products, orders, checking history orders, charts with summaries),\ncreating live chat with customers,\nimplementation of pagination,\nadding rating and review products,\nserving e-mails by mailgun,\nadding filters to products,\nadding checkout wizard (with a few steps),\nuploading product images on external services e.g Cloudinary\nERC20 tokens, stable coin payment [in branch]\nzkSync payment [in branch/during test]\nthe graph for transactions history review\nGit\nhttps://github.com/mateuszmaczynski/Pets-Shop", "link": "https://devpost.com/software/pet-shop", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nin the world of many ransomware attacks on standard e-commerce platforms. the decentralized approach can remedy this problem. many instances of the same platform can be dispersed on many nodes which dramatically minimizes potential attack surface. in a standard cloud environment a special protocol should manage specific instances of the frontend and backend part of an e-commerce platform. in a decentralized world it is part of a blockchain protocol. another aspect in this area is currency transactions. in the standard e-commerce platform special service should be added, in the blockchain we obtain it in a protocol or a smart contract. the pet shop is an example of a decentralized e-commerce platform. it is the only example, our goal is to build an e-commerce decentralized framework dedicated for private and public blockchain networks.\nwhat it does\nit is a decentralized e-commerce platform dedicated for private and public blockchain networks. it is a shop where potential customers can buy something interesting for pets.\nhow we built it\nwe can partition our solution into three layers. first is the web part. it is written in react. a second layer is blockchain. it is based on solidity smart contracts. the shop contract is the main component. it has a buy and createnewitem function. the buy function is responsible for the buying process. it takes a tuple with a product\u2019s code and an amount of specific product. second function is responsible for creation of new items and only contarct\u2019s owner can manage this method. the item is erc20 smart contract interface implementation. thanks to this all management and change of items amount, transfer, creating are controlled by the smart contract. last element is delivery smart contract. it allows you to create delivery requests for new items. in the buy function in the shop smart contract is a statement which checks if the balance of an item in a specific smart contract is equal or less than 10 then creates a new delivery request.\nthe webpage of the pet shop was deployed on the ipfs protocol (https://still-rice-6959.on.fleek.co).\nthe delivery service is optional. it is dedicated to the automation delivery process for suppliers of goods.\nchallenges we ran into\nthe most challenging for us, was creating a mechanism that allows us to buy many items at one time in a smart contract function.\naccomplishments that we're proud of\nwe are proud of all parts of the project because we created the proof of concept of a decentralized e-commerce platform.\nwhat we learned\nhardhat and ethers, what way we can build e-commerce platforms.\nwhat's next for pet shop\nwe want to improve web page and add new features e.g:\nadding user profile(i.e displaying orders, displaying and changing user profile),\nadding dashboard for admin (e.g management products, orders, checking history orders, charts with summaries),\ncreating live chat with customers,\nimplementation of pagination,\nadding rating and review products,\nserving e-mails by mailgun,\nadding filters to products,\nadding checkout wizard (with a few steps),\nuploading product images on external services e.g cloudinary\nerc20 tokens, stable coin payment [in -----> branch !!! ]\nzksync payment [in branch/during test]\nthe graph for transactions history review\ngit\nhttps://github.com/mateuszmaczynski/pets-shop", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59503860}, {"Unnamed: 0": 3934, "autor": "Starport plugin system", "date": null, "content": "Inspiration\nBlockchain technology is changing our life very fast and it proves how decentralization is valuable in the future. So, many developers all around the world, try to build their idea and business on the blockchain ecosystem.\nUnfortunately it is not feasible to build everything up from scratch because blockchain technology is so comprehensive. That is a reason why Cosmos SDK and Starport are valuable and it makes developers focus on implementing their idea and business without full knowledge and understanding of blockchain.\nFor developers, flexibility is one of the key important values to realize their idea. Solid and flexible tools will be strong weapons for developers, and that\u2019s why we built a flexible plugin system for Starport.\nWhat it does\nPlugin system for Starport that makes 3rd party code can be imported and executed inside of Starport. Any developers can implement plugins that are based on Golang\u2019s plugin packages and publish them to a public Git repository.\nFor the chain developer side, developers can import and use 3rd party plugins which are published on Git repository.\nIf chain developers import plugins, Starport\u2019s plugin system downloads and builds plugin binaries on their local machine. And then, Starport loads plugins and provides new plugin commands to use them.\nVisit How to test plugins systems to test new plugin system.\nHow we built it\nCore of plugin system is built on reflection of Golang.\nAt the beginning of this project, our team tried to define the protocols that the plugin system should follows. But we realized that predefined protocols make developers be restricted.\nWe think flexibility is one of the most important values for developers especially for extensible systems like plugins. So we decided to minimize these protocols and provide a fully flexible plugin environment by using reflection.\nChallenges we ran into\nMinimizing pre-defined protocol was most hardest part of this project. CLI commands should be loaded dynamically and the developer can run any functions defined on the plugin. Both should be possible at runtime.\nTo solve this challenge, we use reflection to get object's information at runtime. Plugin system loads plugin objects at runtime and inspects inside of this object with reflect package.\nAfter that, the plugin system understands which functions are available and how to call them. So it is possible to provide CLI commands for the plugin dynamically.\nAccomplishments that we're proud of\nIntroducing a fully flexible plugin system to Starport.\nWe minimize predefined protocols which the plugin should follow. That means any features can be implemented on a plugin and imported by the Starport plugin system.\nWhat we learned\nHow to work with the plugin package of Golang.\nHow to use and work on reflection of Golang.\nUnderstanding of Starport's CLI and scaffolding system.\nWhat's next for Starport plugin system\nImplement more commands: Implement more plugin commands to manage plugins like update, delete etc.\nVersion selection of plugin: Current version of plugin system automatically get latest commit of master branch. But the version should be selectable because of management stuff.\nPackage deployment tool: utility command for validating plugin code. It will prevent mistakes for developers.", "link": "https://devpost.com/software/starport-plugin-system", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nblockchain technology is changing our life very fast and it proves how decentralization is valuable in the future. so, many developers all around the world, try to build their idea and business on the blockchain ecosystem.\nunfortunately it is not feasible to build everything up from scratch because blockchain technology is so comprehensive. that is a reason why cosmos sdk and starport are valuable and it makes developers focus on implementing their idea and business without full knowledge and understanding of blockchain.\nfor developers, flexibility is one of the key important values to realize their idea. solid and flexible tools will be strong weapons for developers, and that\u2019s why we built a flexible plugin system for starport.\nwhat it does\nplugin system for starport that makes 3rd party code can be imported and executed inside of starport. any developers can implement plugins that are based on golang\u2019s plugin packages and publish them to a public git repository.\nfor the chain developer side, developers can import and use 3rd party plugins which are published on git repository.\nif chain developers import plugins, starport\u2019s plugin system downloads and builds plugin binaries on their local machine. and then, starport loads plugins and provides new plugin commands to use them.\nvisit how to test plugins systems to test new plugin system.\nhow we built it\ncore of plugin system is built on reflection of golang.\nat the beginning of this project, our team tried to define the protocols that the plugin system should follows. but we realized that predefined protocols make developers be restricted.\nwe think flexibility is one of the most important values for developers especially for extensible systems like plugins. so we decided to minimize these protocols and provide a fully flexible plugin environment by using reflection.\nchallenges we ran into\nminimizing pre-defined protocol was most hardest part of this project. cli commands should be loaded dynamically and the developer can run any functions defined on the plugin. both should be possible at runtime.\nto solve this challenge, we use reflection to get object's information at runtime. plugin system loads plugin objects at runtime and inspects inside of this object with reflect package.\nafter that, the plugin system understands which functions are available and how to call them. so it is possible to provide cli commands for the plugin dynamically.\naccomplishments that we're proud of\nintroducing a fully flexible plugin system to starport.\nwe minimize predefined protocols which the plugin should follow. that means any features can be implemented on a plugin and imported by the starport plugin system.\nwhat we learned\nhow to work with the plugin package of golang.\nhow to use and work on reflection of golang.\nunderstanding of starport's cli and scaffolding system.\nwhat's next for starport plugin system\nimplement more commands: implement more plugin commands to manage plugins like update, delete etc.\nversion selection of plugin: current version of plugin system automatically get latest commit of master -----> branch !!! . but the version should be selectable because of management stuff.\npackage deployment tool: utility command for validating plugin code. it will prevent mistakes for developers.", "sortedWord": "None", "removed": "Nan", "score": 18, "comments": 0, "media": null, "medialink": null, "identifyer": 59503934}, {"Unnamed: 0": 3989, "autor": "MCY-Liquipedia-Bot", "date": null, "content": "Inspiration\nAs a recent graduate in web development and someone who loves perusing various Liquipedia wikis, I wanted to experiment with the Liquipedia API and trying something completely new. Wanting to branch out from full web applications, I dabbled with learning and trying to create a Discord bot but haven't successfully deployed one.\nI was re-inspired to build one after checking out Marvin's workshop at the Liquid Hackathon on how to create a simple Discord bot that queried the Liquipedia API and gave the user relevant information about players.\nWhat it does\nThe bot MCY-bot can be utilized using slash commands from Discord. Its main purpose is to give the inquirer information about a player that they specify by correctly inputting the correct wiki and player in the required fields. What the bot returns is a short biography of the player where the relevant information is filled out by grabbing the appropriate key-values from the JSON object representing the player. Their socials are also listed ranging from their YouTube to their Weibo accounts, if available.\nThere is some user validation when the user inputs the incorrect wiki or player name, or if the player doesn't exist.\nHow I built it\nSome of the code was borrowed or refactored from Marvin's tutorial on how to deploy a Discord bot, mainly the config.py which housed the function on grabbing relevant environment variables from the .env.dev file. There are only four files in the application:\nconfig.py - Contains a function to extrapolate environment variables from the .env.dev file which contains the BOT_TOKEN, GUILD_ID, and API_KEY\nbot.py - Instantiates a bot and runs it. Includes decorators that allows the bot to monitor for any messages and slash commands such as /MCY-getplayer and respond appropriately.\nliquipediaAPI.py - Contains getPlayer and printData functions. getPlayer fetches from the liquipedia API and returns either the player's JSON content, an empty array if there are no results, or a string 'Invalid Wiki' if the wiki doesn't exist. printData formats the JSON content to be displayed appropriately when the bot sends the results in the Discord channel.\ndataCorrection.py - Contains correctedData function which checks the JSON whether key-values exist, and creates the key if it doesn't exist or its value is empty (\"\"), with the value being a string of '<key> unavailable'. For example, if the player did not belong to a team data['team'] == \"\", the key is reassigned a new value of 'no team (free agent)' so that it would display as such in the player's mini-biography MCY-bot sends.\nChallenges I ran into\nOne of the biggest challenges that I ran into was the immensity of the amount of wikis Liquipedia contains. Some of these wikis I never even knew existed! As a consequence, there are inconsistencies when accessing the keys from JSONs of different wikis. For example, a Starcraft player would not specialize in any Dota heroes or League of Legends champions, but rather, they usually specialize in a race. correctedData is supposed to help alleviate some of these issues, but considering the scope of the project, it was better to slightly satisfy everyone utilizing all wikis than having a perfect response to just two or three wikis.\nAnother challenge was not specifically code related, but deploying an application to the cloud. Many errors that I got was version incompatibility between python packages or the python version itself. The process of creating a manifest.yml file and creating dependencies to be utilized by the cloud is something I still don't fully understand, but was definitely an experience full of googling and troubleshooting.\nAccomplishments that I'm proud of\nI deployed a discord bot! And it's not local to my machine! And it works (kind of)! I think having a bot that is able to query the liquipedia API would be very useful in a community, such as if they want to look up certain stats for a player. For example, their most recent tournament placings or what other wikis they're on.\nWhat I learned\nWriting a simple bot is not too bad, especially with guidance from the workshop! I wish I could utilize JSX so that I can more easily program conditionals in case there was data missing, so that I could change the player's biography dynamically. There might be a library or a feature of python I haven't found yet that does this.\nThe Discord documentation for developing applications is not super newbie friendly, but is definitely in-depth and just requires a bit of googling to find answers to reaching a certain endpoint. For example, the application ID refers to the ID of the application that houses the bot we create, not an ID for any general application (so obvious now..).\nWhat's next for MCY-Liquipedia-Bot\nRegurgitation of the README.md from the MCY-bot repo:\nThe bot is optimized mostly for League of Legends, Dota2, and Brood War queries, so querying other wikis will likely make strange contextual mistakes.\nMake it easier for the user to search for players. It requires the user to be very exact with the player's liquipedia page name.\nAdd randomizer\nRemove embeds as the bot response can be very bulky\nAdd a cooldown to reduce frequency of API querying", "link": "https://devpost.com/software/mcy-liquipedia-bot", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nas a recent graduate in web development and someone who loves perusing various liquipedia wikis, i wanted to experiment with the liquipedia api and trying something completely new. wanting to -----> branch !!!  out from full web applications, i dabbled with learning and trying to create a discord bot but haven't successfully deployed one.\ni was re-inspired to build one after checking out marvin's workshop at the liquid hackathon on how to create a simple discord bot that queried the liquipedia api and gave the user relevant information about players.\nwhat it does\nthe bot mcy-bot can be utilized using slash commands from discord. its main purpose is to give the inquirer information about a player that they specify by correctly inputting the correct wiki and player in the required fields. what the bot returns is a short biography of the player where the relevant information is filled out by grabbing the appropriate key-values from the json object representing the player. their socials are also listed ranging from their youtube to their weibo accounts, if available.\nthere is some user validation when the user inputs the incorrect wiki or player name, or if the player doesn't exist.\nhow i built it\nsome of the code was borrowed or refactored from marvin's tutorial on how to deploy a discord bot, mainly the config.py which housed the function on grabbing relevant environment variables from the .env.dev file. there are only four files in the application:\nconfig.py - contains a function to extrapolate environment variables from the .env.dev file which contains the bot_token, guild_id, and api_key\nbot.py - instantiates a bot and runs it. includes decorators that allows the bot to monitor for any messages and slash commands such as /mcy-getplayer and respond appropriately.\nliquipediaapi.py - contains getplayer and printdata functions. getplayer fetches from the liquipedia api and returns either the player's json content, an empty array if there are no results, or a string 'invalid wiki' if the wiki doesn't exist. printdata formats the json content to be displayed appropriately when the bot sends the results in the discord channel.\ndatacorrection.py - contains correcteddata function which checks the json whether key-values exist, and creates the key if it doesn't exist or its value is empty (\"\"), with the value being a string of '<key> unavailable'. for example, if the player did not belong to a team data['team'] == \"\", the key is reassigned a new value of 'no team (free agent)' so that it would display as such in the player's mini-biography mcy-bot sends.\nchallenges i ran into\none of the biggest challenges that i ran into was the immensity of the amount of wikis liquipedia contains. some of these wikis i never even knew existed! as a consequence, there are inconsistencies when accessing the keys from jsons of different wikis. for example, a starcraft player would not specialize in any dota heroes or league of legends champions, but rather, they usually specialize in a race. correcteddata is supposed to help alleviate some of these issues, but considering the scope of the project, it was better to slightly satisfy everyone utilizing all wikis than having a perfect response to just two or three wikis.\nanother challenge was not specifically code related, but deploying an application to the cloud. many errors that i got was version incompatibility between python packages or the python version itself. the process of creating a manifest.yml file and creating dependencies to be utilized by the cloud is something i still don't fully understand, but was definitely an experience full of googling and troubleshooting.\naccomplishments that i'm proud of\ni deployed a discord bot! and it's not local to my machine! and it works (kind of)! i think having a bot that is able to query the liquipedia api would be very useful in a community, such as if they want to look up certain stats for a player. for example, their most recent tournament placings or what other wikis they're on.\nwhat i learned\nwriting a simple bot is not too bad, especially with guidance from the workshop! i wish i could utilize jsx so that i can more easily program conditionals in case there was data missing, so that i could change the player's biography dynamically. there might be a library or a feature of python i haven't found yet that does this.\nthe discord documentation for developing applications is not super newbie friendly, but is definitely in-depth and just requires a bit of googling to find answers to reaching a certain endpoint. for example, the application id refers to the id of the application that houses the bot we create, not an id for any general application (so obvious now..).\nwhat's next for mcy-liquipedia-bot\nregurgitation of the readme.md from the mcy-bot repo:\nthe bot is optimized mostly for league of legends, dota2, and brood war queries, so querying other wikis will likely make strange contextual mistakes.\nmake it easier for the user to search for players. it requires the user to be very exact with the player's liquipedia page name.\nadd randomizer\nremove embeds as the bot response can be very bulky\nadd a cooldown to reduce frequency of api querying", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59503989}, {"Unnamed: 0": 4079, "autor": "Early Access Game NFT", "date": null, "content": "Inspiration\nNew games often are available as early access. In this phase the game finished, but a fan community can be build and the game designer get already an income. NFTs are a good way to finance game development but also give the fans the ability to show up they founded the game.\nWhat it does\nThe marketplace allows game makers deploy contracts and mint NFT Tokens. The fan community can buy the nft tokens then.\nThe game hextris is not part of the hackathon and just embedded into our page.\nHow we built it\nFirst we cloned a marketplace called crypto boys and modified it a little bit. But in the end we decided to develop the smart contract from scratch. The frontend is built with vue framework. The smart contracts are built in solidity. Data which is generated by users like the description of deployed nft contracts are stored on ipfs using https://web3.storage.\nChallenges we ran into\nSometimes there were problems to get tokens from the faucets. We needed the tokens to deploy the contract.\nAccomplishments that we're proud of\nWe are proud that we deployed a erc721 smart contract and hosted a marketplace.\nWhat we learned\nWe learned to deploy smart contracts and how to host web3 software on github pages. We played with ipfs and learned how to integrate it into web pages as the data for the contracts is stored on ipfs while the hash address of the data is stored in the contract.\nWhat's next for the project\nNext we need to give the frontend a redesign. An extra contract should be created to list all games which provide NFTs.\nConnect more chains. Currently connected are:\nhttps://nft-login.github.io/nft-login-marketplace/kovan/\nhttps://nft-login.github.io/nft-login-marketplace/okt/\nhttps://nft-login.github.io/nft-login-marketplace/heco/\nhttps://nft-login.github.io/nft-login-marketplace/celo/\nhttps://nft-login.github.io/nft-login-marketplace/lisk/\nCelo Blockchain\nDemo Game Login if you own a Token: https://nft-login.github.io/nft-login-demo/celo/ Deployed Contract: https://alfajores-blockscout.celo-testnet.org/address/0xBa4e569A5156C00348B89653968c2C294f80E151\nAvalanche Blockchain\nDemo Game Login if you own a Token: https://nft-login.github.io/nft-login-demo/avax/\nTheta Blockchain\nDemo Game Login if you own a Token: https://nft-login.github.io/nft-login-demo/theta/ Deployed Contract: https://testnet-explorer.thetatoken.org/account/0x8fb36197889f23e76e68e3fd57c6063a21dde897\nIt was very hard to get TFuel to deploy the contract as there is no faucet for the testnet. We tried to deploy to the Mainnet by sending myself some Theta from Binance. But truffle told me it needs 0 Theta but X TFuel. We could not find out where to get TFuel. But thanks to the community at discord and the theta team we got enough TFuel on the Testnet to deploy the contract.\nOKEx Blockchain\nVisit https://nft-login.github.io/nft-login-marketplace/okt/, login to your metamask and buy a token.\nYou can test you own this token by visiting https://nft-login.github.io/nft-login-demo/okt/ and login by signing the message with your account that owns the token.\nHeco Blockchain\nVisit https://nft-login.github.io/nft-login-marketplace/heco/, login to your metamask and buy a token. Also hosted on 4everland https://market.nft-login.net/ and https://nft-login-marketplace.4everland.app/ .\nYou can test you own this token by visiting https://nft-login.github.io/nft-login-demo/heco/ and login by signing the message with your account that owns the token. Alternatively you can test it on 4everland https://heco-nft-login-demo.4everland.app.\nLisk Blockchain\nSee the video for the Lisk Blockchain here:\nWe did not finish, as we struggled in the beginning. We planned to host the blockchain in docker container, but we had problems to change the host which allows anyone to connect, not only localhost. Thanks to the community in discord that really helped to find the way to do it. The documentation was good, which helped to understand how the framework works. Nevertheless we could not finish. In the end in this video, you see our frontend hosted on github https://nft-login.github.io/nft-login-marketplace/lisk/?account=lsktrqzuehzhmh4senwdwz3bo2rtqenfuujegjveu&contract=http://localhost:8080/\nand the backend hosted on localhost running in a container. The backend is the nft-demo https://github.com/LiskHQ/lisk-sdk-examples/tree/development/tutorials/nft rewritten in typescript. We did not change much...\nThe frontend is lagging in functions and just shows the available tokens and the addresses that own ist. The functionality for transfer the tokens will be built afterward.\nSources can be found: https://github.com/nft-login/lisk-nft-market\nand here in the lisk branch https://github.com/nft-login/nft-login-marketplace/tree/lisk\nThanks again to the discord community of lisk.\nNotice\nWe also developed the project OIDC NFT Login which is independent but visible in the videos as we use it to demonstrate how nfts can be used.\nBuilt with\nrust, web3, github-pages, react, solidity, heco, okex, metis, lisk-sdk", "link": "https://devpost.com/software/early-access-game-nft", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nnew games often are available as early access. in this phase the game finished, but a fan community can be build and the game designer get already an income. nfts are a good way to finance game development but also give the fans the ability to show up they founded the game.\nwhat it does\nthe marketplace allows game makers deploy contracts and mint nft tokens. the fan community can buy the nft tokens then.\nthe game hextris is not part of the hackathon and just embedded into our page.\nhow we built it\nfirst we cloned a marketplace called crypto boys and modified it a little bit. but in the end we decided to develop the smart contract from scratch. the frontend is built with vue framework. the smart contracts are built in solidity. data which is generated by users like the description of deployed nft contracts are stored on ipfs using https://web3.storage.\nchallenges we ran into\nsometimes there were problems to get tokens from the faucets. we needed the tokens to deploy the contract.\naccomplishments that we're proud of\nwe are proud that we deployed a erc721 smart contract and hosted a marketplace.\nwhat we learned\nwe learned to deploy smart contracts and how to host web3 software on github pages. we played with ipfs and learned how to integrate it into web pages as the data for the contracts is stored on ipfs while the hash address of the data is stored in the contract.\nwhat's next for the project\nnext we need to give the frontend a redesign. an extra contract should be created to list all games which provide nfts.\nconnect more chains. currently connected are:\nhttps://nft-login.github.io/nft-login-marketplace/kovan/\nhttps://nft-login.github.io/nft-login-marketplace/okt/\nhttps://nft-login.github.io/nft-login-marketplace/heco/\nhttps://nft-login.github.io/nft-login-marketplace/celo/\nhttps://nft-login.github.io/nft-login-marketplace/lisk/\ncelo blockchain\ndemo game login if you own a token: https://nft-login.github.io/nft-login-demo/celo/ deployed contract: https://alfajores-blockscout.celo-testnet.org/address/0xba4e569a5156c00348b89653968c2c294f80e151\navalanche blockchain\ndemo game login if you own a token: https://nft-login.github.io/nft-login-demo/avax/\ntheta blockchain\ndemo game login if you own a token: https://nft-login.github.io/nft-login-demo/theta/ deployed contract: https://testnet-explorer.thetatoken.org/account/0x8fb36197889f23e76e68e3fd57c6063a21dde897\nit was very hard to get tfuel to deploy the contract as there is no faucet for the testnet. we tried to deploy to the mainnet by sending myself some theta from binance. but truffle told me it needs 0 theta but x tfuel. we could not find out where to get tfuel. but thanks to the community at discord and the theta team we got enough tfuel on the testnet to deploy the contract.\nokex blockchain\nvisit https://nft-login.github.io/nft-login-marketplace/okt/, login to your metamask and buy a token.\nyou can test you own this token by visiting https://nft-login.github.io/nft-login-demo/okt/ and login by signing the message with your account that owns the token.\nheco blockchain\nvisit https://nft-login.github.io/nft-login-marketplace/heco/, login to your metamask and buy a token. also hosted on 4everland https://market.nft-login.net/ and https://nft-login-marketplace.4everland.app/ .\nyou can test you own this token by visiting https://nft-login.github.io/nft-login-demo/heco/ and login by signing the message with your account that owns the token. alternatively you can test it on 4everland https://heco-nft-login-demo.4everland.app.\nlisk blockchain\nsee the video for the lisk blockchain here:\nwe did not finish, as we struggled in the beginning. we planned to host the blockchain in docker container, but we had problems to change the host which allows anyone to connect, not only localhost. thanks to the community in discord that really helped to find the way to do it. the documentation was good, which helped to understand how the framework works. nevertheless we could not finish. in the end in this video, you see our frontend hosted on github https://nft-login.github.io/nft-login-marketplace/lisk/?account=lsktrqzuehzhmh4senwdwz3bo2rtqenfuujegjveu&contract=http://localhost:8080/\nand the backend hosted on localhost running in a container. the backend is the nft-demo https://github.com/liskhq/lisk-sdk-examples/tree/development/tutorials/nft rewritten in typescript. we did not change much...\nthe frontend is lagging in functions and just shows the available tokens and the addresses that own ist. the functionality for transfer the tokens will be built afterward.\nsources can be found: https://github.com/nft-login/lisk-nft-market\nand here in the lisk -----> branch !!!  https://github.com/nft-login/nft-login-marketplace/tree/lisk\nthanks again to the discord community of lisk.\nnotice\nwe also developed the project oidc nft login which is independent but visible in the videos as we use it to demonstrate how nfts can be used.\nbuilt with\nrust, web3, github-pages, react, solidity, heco, okex, metis, lisk-sdk", "sortedWord": "None", "removed": "Nan", "score": 3, "comments": 0, "media": null, "medialink": null, "identifyer": 59504079}, {"Unnamed: 0": 4204, "autor": "NoteHack", "date": null, "content": "Inspiration\nWith the goal of creating a truly useful product, we met up to reflect on areas of struggle in our own lives.\nWe noticed that our faculty had trouble recruiting student note takers to help students with accommodations.\nWhat it does\nWe decided to create an app that allows students to share their electronic notes with whoever might need them.\nHow we built it\nWe built the web application using React, Firebase and Redux\nThe frontend was created with React\nThe serverless backend was Firebase\nRedux was used to manage the state of all of the components\nChallenges we ran into\nWe faced a steep learning curve since most of us have never used ReactJs nor collaborated on Github.\nMaterial UI uses CSS files to format their objects to specific standards, it took a lot of playing around to format boxes and cards the way we needed them to look.\nCollaborating on GitHub posed challenges since we used many additional packages so the JSON file would be drastically different for each branch.\nAccomplishments that we're proud of\nWe are proud that we were able to learn a bunch of new technologies and skills about web development in such a short amount of time.\nWe are proud that we were effective and efficient as a team in terms of communication and collaboration.\nWhat we learned\nWe learned technologies such as React, Git, Github, Redux, Firebase, and NPM\nWhat's next for NoteHacks\nWe plan on making the product more refined in terms of security, the discussion board, and improving the overall design and functionality.", "link": "https://devpost.com/software/notehacks", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nwith the goal of creating a truly useful product, we met up to reflect on areas of struggle in our own lives.\nwe noticed that our faculty had trouble recruiting student note takers to help students with accommodations.\nwhat it does\nwe decided to create an app that allows students to share their electronic notes with whoever might need them.\nhow we built it\nwe built the web application using react, firebase and redux\nthe frontend was created with react\nthe serverless backend was firebase\nredux was used to manage the state of all of the components\nchallenges we ran into\nwe faced a steep learning curve since most of us have never used reactjs nor collaborated on github.\nmaterial ui uses css files to format their objects to specific standards, it took a lot of playing around to format boxes and cards the way we needed them to look.\ncollaborating on github posed challenges since we used many additional packages so the json file would be drastically different for each -----> branch !!! .\naccomplishments that we're proud of\nwe are proud that we were able to learn a bunch of new technologies and skills about web development in such a short amount of time.\nwe are proud that we were effective and efficient as a team in terms of communication and collaboration.\nwhat we learned\nwe learned technologies such as react, git, github, redux, firebase, and npm\nwhat's next for notehacks\nwe plan on making the product more refined in terms of security, the discussion board, and improving the overall design and functionality.", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59504204}, {"Unnamed: 0": 4447, "autor": "Off-Aura", "date": null, "content": "Inspiration\nI've had the opportunity through my DMS 462 Game Design Seminar class to be introduced to Twine and its usefulness in creating text-based games. I knew that I wanted to make a game for my first hackathon, and this felt like the best way to do it. I have always enjoyed writing and putting fantasy-spins on the world as we know it, so it was a collaboration written in the stars.\nWhat it does\nIt transports you to a world not too unlike the one we live in now. People are blissfully unaware of those that live among them with powers until there isn't a point in denying it anymore. It is up to the player to choose the path they wish to take, but as happens in real life, there are consequences to the decisions they make. To highlight the achievements, there are three stars seen at the beginning screen that will fill once one objective is completed.\nAs I will aim to be true for all of my games, this experience allows for an escape from the world around us into a fictional one. But it doesn't just stop at the end-of-game screen. There are things to think about and messages to be spread- and at face value- it is to choose who you trust wisely. Sometimes it isn't as easy as judging a book by its cover, or even by your first impression. Sometimes it takes more time than that to truly interpret the depths of a person. And all of the times, it takes work to do so.\nHow I built it\nI mainly used Twine for building the game. Since it is text-driven, the other two tools (Audacity and Krita) were more for added sound and art, respectively. I recorded some of my own audio and made the pixel art.\nChallenges I ran into\nAt the start, I had the beginning idea in place, but I wasn't sure how I wanted to end it. I like to make the player's choice genuinely matter, and so trying to foresee how I could have different branches that may relate enough to come back together was a bit tricky. I also needed to decide how many endings I could comfortably do within the time restraint while still ensuring that each of them felt finished.\nAccomplishments that we're proud of\nI'm overall glad that I made it through my first hackathon! I feel like that's a stepping stone for diving into more opportunities that are also similar. I'm also a fan of the concept and being able to stick the landing.", "link": "https://devpost.com/software/off-aura", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\ni've had the opportunity through my dms 462 game design seminar class to be introduced to twine and its usefulness in creating text-based games. i knew that i wanted to make a game for my first hackathon, and this felt like the best way to do it. i have always enjoyed writing and putting fantasy-spins on the world as we know it, so it was a collaboration written in the stars.\nwhat it does\nit transports you to a world not too unlike the one we live in now. people are blissfully unaware of those that live among them with powers until there isn't a point in denying it anymore. it is up to the player to choose the path they wish to take, but as happens in real life, there are consequences to the decisions they make. to highlight the achievements, there are three stars seen at the beginning screen that will fill once one objective is completed.\nas i will aim to be true for all of my games, this experience allows for an escape from the world around us into a fictional one. but it doesn't just stop at the end-of-game screen. there are things to think about and messages to be spread- and at face value- it is to choose who you trust wisely. sometimes it isn't as easy as judging a book by its cover, or even by your first impression. sometimes it takes more time than that to truly interpret the depths of a person. and all of the times, it takes work to do so.\nhow i built it\ni mainly used twine for building the game. since it is text-driven, the other two tools (audacity and krita) were more for added sound and art, respectively. i recorded some of my own audio and made the pixel art.\nchallenges i ran into\nat the start, i had the beginning idea in place, but i wasn't sure how i wanted to end it. i like to make the player's choice genuinely matter, and so trying to foresee how i could have different -----> branches !!!  that may relate enough to come back together was a bit tricky. i also needed to decide how many endings i could comfortably do within the time restraint while still ensuring that each of them felt finished.\naccomplishments that we're proud of\ni'm overall glad that i made it through my first hackathon! i feel like that's a stepping stone for diving into more opportunities that are also similar. i'm also a fan of the concept and being able to stick the landing.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59504447}, {"Unnamed: 0": 4522, "autor": "Cutie Hack Discord Bot: DogFriendBot", "date": null, "content": "Inspiration\nI was inspired to make this Discord bot from two of the workshops I attended today being Intro to Python and Intro to Discord Bots. I felt like this was a decently sized project I could tackle through the day and found it was possible to use python to make a Discord bot through PyCharm as I set it up correctly. As I was making it, I tried to keep the theme of Cutie Hack \"Better Together\" so I wanted to have the Discord bot give you someone's name in the server that you can connect with plus a few extra features. Finally I made it dog themed to make it even more friendly.\nWhat it does\nThe Discord bot has three main functions. The first and most important is that if you type \"NewFriend!\" in the messaging bar, it will provide you with a name from the people in the server that you can start to connect with. The second feature is that if a message has the word \"encouragement\" in it, the bot with give you some words of encouragement, one of three random phrases. Finally, if you type \"Dog!\" in the messaging bar, the bot will post a random image of a dog.\nHow I built it\nI used PyCharm and the language Python in order to construct my Discord bot. I followed what I learned from the workshops today and some online tutorials in order to get the basis for what I wanted to do with the bot. I followed the standard set up but then used my problem solving abilities to create the commands for the bot such as the NewFriend! and Dog! options.\nChallenges I ran into\nSome of the challenges I ran into was that I needed to get a full list of the names from the Discord server into a list but the program wasn't getting them from Discord, only the bot's name. I searched for a solution and learned more about how scripting Discord bots worked and eventually arrived at a solution, changing some parts in order to accommodate the recent changes Discord bots had.\nAccomplishments that we're proud of\nI am proud that in the end, the Discord bot accomplished what I wanted it to do. It can give the names of anyone in the Discord server so you have someone new to connect with. My words of encouragement and dog pictures also worked fantastically!\nWhat we learned\nI learned a lot about the basics of making Discord bots and about coding in Python because this is my first day learning and coding in the language. I am really glad to have both of these in my skill set and am excited to build upon them moving forward!\nWhat's next for Cutie Hack Discord Bot: DogFriendBot\nI will probably try to add more features and message commands to my bot and even try to branch out more with it performing more complex tasks and actions like messaging the person who's name was chosen and asking them if they want to contact the person who initially but in the NewFriend! command.", "link": "https://devpost.com/software/cutie-hack-discord-bot-dogfriendbot", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\ni was inspired to make this discord bot from two of the workshops i attended today being intro to python and intro to discord bots. i felt like this was a decently sized project i could tackle through the day and found it was possible to use python to make a discord bot through pycharm as i set it up correctly. as i was making it, i tried to keep the theme of cutie hack \"better together\" so i wanted to have the discord bot give you someone's name in the server that you can connect with plus a few extra features. finally i made it dog themed to make it even more friendly.\nwhat it does\nthe discord bot has three main functions. the first and most important is that if you type \"newfriend!\" in the messaging bar, it will provide you with a name from the people in the server that you can start to connect with. the second feature is that if a message has the word \"encouragement\" in it, the bot with give you some words of encouragement, one of three random phrases. finally, if you type \"dog!\" in the messaging bar, the bot will post a random image of a dog.\nhow i built it\ni used pycharm and the language python in order to construct my discord bot. i followed what i learned from the workshops today and some online tutorials in order to get the basis for what i wanted to do with the bot. i followed the standard set up but then used my problem solving abilities to create the commands for the bot such as the newfriend! and dog! options.\nchallenges i ran into\nsome of the challenges i ran into was that i needed to get a full list of the names from the discord server into a list but the program wasn't getting them from discord, only the bot's name. i searched for a solution and learned more about how scripting discord bots worked and eventually arrived at a solution, changing some parts in order to accommodate the recent changes discord bots had.\naccomplishments that we're proud of\ni am proud that in the end, the discord bot accomplished what i wanted it to do. it can give the names of anyone in the discord server so you have someone new to connect with. my words of encouragement and dog pictures also worked fantastically!\nwhat we learned\ni learned a lot about the basics of making discord bots and about coding in python because this is my first day learning and coding in the language. i am really glad to have both of these in my skill set and am excited to build upon them moving forward!\nwhat's next for cutie hack discord bot: dogfriendbot\ni will probably try to add more features and message commands to my bot and even try to -----> branch !!!  out more with it performing more complex tasks and actions like messaging the person who's name was chosen and asking them if they want to contact the person who initially but in the newfriend! command.", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59504522}, {"Unnamed: 0": 4544, "autor": "MealMate", "date": null, "content": "\ud83d\udca1 Inspiration \ud83d\udca1\nAs university students, we\u2019re very busy, and we\u2019re often so focused on our work that we end up skipping meals. When we do eat, not only do we waste a lot of time deciding what to eat, but we also don\u2019t know many recipes, and as a result, we usually opt for something quick, cheap, and unhealthy, such as fast food or instant ramen. As this is a common issue within the team, we want to create an app that addresses it. The goal of this app is to organize and decide our meals for us, so we don\u2019t waste time contemplating what to eat. This not only saves time, but it also stops us from resorting to unhealthy foods for the sake of convenience.\n\u2699\ufe0f What it does \u2699\ufe0f\nMealMate lets you choose recipes to make at home. Based on the ingredients you have on hand, MealMate will recommend recipes tailored to your diet. If you want to have a low-calorie, super healthy breakfast, no problem!\nTry it out on here: https://mealmate-flask.herokuapp.com/\n\ud83d\udee0\ufe0f How we built it \ud83d\udee0\ufe0f\nWe found a database of recipes and their respective ingredients on Kaggle. The dataset was approximately 2.2 million rows. We had to take a very small portion of it so that our computers could handle running the recommender systems. We also feature engineered calories and an arbitrary health scale. For calories, each recipe was assigned a random value between 300 and 800 because a person's average homemade meal/snack falls within this boundary. Each recipe was also given a random value between 1 and 10 for the health scale.\nMealMate uses a TF-IDF recommendation system. The recommendation system is measured in cosine similarity and gives recommendations with a score of at least 0.6. The recommender system has two parts. The first part goes through the database and removes any recipes that don't fall within the parameters the user sets (calories and health scale). The TF-IDF system takes into account the different ingredients the user inputs and returns a recommendation of 10 recipes that the user could make.\nFigma was used to create a general UI design template. This helped the project move faster through the next phases because the programmers knew exactly what they were trying to create. Now that the project had a solid foundation in the cosine algorithm and the both the general UI design, we decided to split up and develop multiple deployments in order to run on all major operating systems.\nFlask + Heroku Web app: The Flask app consists of an HTML/Jinja frontend and Python backend. We separated the pages into four main routes: the home page, login, signup, and recommendation page that were built with the help of Flask blueprints which greatly sped up development. The main feature of the web app is in the recommendation algorithm which the user can interact with upon landing on the website. As an aside we also implemented a rudimentary login and signup page which is linked to a SQLite database that was setup using SQLAlchemy. Afterwards, the webpage was deployed on Heroku.\nThe flutter app consisted of 7 different pages: the main intro page, minimum calorie selection page, minimum health scale page, ingredients input page, submit page and recommendation page. It plays the major role in providing maximum User experience. It is powered by flask REST API using POST method helping the app to recommend within a second. Flutter could be designed really fast if we have the blueprint which Figma helped a lot in designing the UI of the app. Without Figma, flutter would take to long to build UI!\n\ud83d\ude23 Challenges we ran into \ud83d\ude23\nWe ran into a lot of challenges with our deployment. One major problem was installing and learning flutter. No one on the team knew how to use flutter, so it was an uphill battle trying to learn it and make a useable UI for iOS/android. We also ran into some troubles with streamlit when we were trying to design a web app. It was a huge hassle trying to understand how to combine the frontend and backend because we needed to grab user input for the recommender system. This was especially the case because we also encountered issues installing scikit-learn which made testing our webpages all the more time consuming. Another major problem came with the deployment of the website and an API that could be used to bridge the user input and recommender output. It was extremely challenging to understand the long-winded and esoteric message thrown up by Heroku. Furthermore, because each deployment consumed plenty of time, the process of debugging became very time consuming. Overall, it was extremely hard to design a UI that focused on usability while getting the user input we needed. In the end, figuring out deployment took up a big chunk of our time.\nWith the recommender system, we ran into memory allocation problems early on. The database we found was amazing, except it had way too much data for us. Our computers were unable to allocate enough memory when running the recommender system. The recommender system also had accuracy problems. The cosine similarity scores were around 0.4 which were quite low. Eventually, after tweaking the hyperparameters, we were achieving scores of 0.6-0.8 consistently.\n\ud83c\udf89 Accomplishments that we're proud of \ud83c\udf89\nOur time management was impeccable, we are all very proud of ourselves since we were able to build and deploy an entire app with a recommender system within 24 hours\nOrganization within the team was perfect, we were all able to contribute and help each other when needed; ex. the figma design helped our webdevs design the UI\nHow our app is able to work on almost all major operating systems\nLearning the basics of flutter and streamlit within a short period of time to deploy our app\nWe are happy to empower people while cooking and make their experience so much more enjoyable\nAble to provide a solution for everyone that will increase productivity and promote healthy living\nThis was a SUPER amazing project! We're all proud to have done it in such a short period of time, everyone is new to the hackathon scene and are still eager to learn new technologies\n\ud83d\udcda What we learned \ud83d\udcda\nMany useful technical skills such as Flutter, Streamlit, Flask and working with API's. A large part of this project was learning how to integrate Flask and Heroku with a Flutter application to allow it upload and retrieve data from an API\nDesign and UI skills such as working with Figma\nHow to work together under pressure and manage tasks effectively within a team\nUsing cosine similarities to compare items within a dataset\nHow to manipulate Github branches via the command window and upload large files using Git LFS\nHow to set up and use a virtual machine using Android Studio\n\u23ed\ufe0fWhat's next for MealMate \u23ed\ufe0f\nMealMate has a lot of work to be done before it is ready to be deployed as a genuine app. It will only be successful if the customer is satisfied and benefits from using it; if it is ugly, slow, or tedious to use, it will be a failure. Our next steps are primarily to increase the usability of the app and fix any shortcomings that were not addressed during this hackathon.\nFor starters, we ran into local memory allocation and speed issues due to the size of the database. As a short time solution, we cut down the size of the database, but to counteract these issues in the future, we aim to move the database, as well as the processing, to the cloud, namely AWS.\nThe recommender system is also very basic as it is now. We hope to create a more intuitive and complex system that generates more relevant recommendations. For example, recommendations can be based on recipes that were clicked on in the past, or the user will be able to indicate taste preferences (spicy, pasta, vegetables, Indian, Italian, etc...). Dietary restrictions will also be taken into account to ensure the apps widespread usability.\nAn important aspect of this app is to allow people to quickly decide on meals; pictures play a big role in this, just look at how advertisements affect consumers. To help the user decide quicker and to increase the attractiveness of the app (so that it's not just a wall of text), we plan to add pictures alongside the recommendations.\nThe current UI is not perfect, and we definitely plan to upgrade it. For now, we plan to add customizable presets so the user does not have to tediously type in the information each time they use the app. On the web app, a more modern multiform input for the ingredients would also be a great addition to the current UI.\n\ud83c\udf81 About the team \ud83c\udf81\nAll 4 of us are 1st or 2nd year university students new to the hackathon scene! Everyone has only 1 or 2 hackathons worth of experience but that hasn't held us back!\nDae is a 2nd year student at Simon Fraser University studying computer science. He's interested in everything computer science related and deeply passionate about data science and cross-platform. You can reach out to him at his LinkedIn ~ https://www.linkedin.com/in/daehyung-kwak-136194223/\nMatthew is a 2nd year student at Simon Fraser University studying computer science. He has formal training in data science. He's interested in learning new and honing his current frontend skills/technologies. Moreover, he's deeply passionate about machine learning, AI and neural networks. You can reach out to him at his LinkedIn ~ https://www.linkedin.com/in/matthew-wong-240837124/\nDaniel is a 1st year student at University of Toronto studying computer science and mathematics. He has an interest in artificial intelligence research and data science. You can reach out to him at his LinkedIn ~ https://www.linkedin.com/in/daniel-s-851b1521a/\nConnor is a 1st year Track One Undeclared engineering student at University of Toronto. He loves both hardware and software and is planning to pursue some sort of mechatronics education in the future. He is especially passionate about computer science and robotics. You can reach out to him at his LinkedIn ~ https://www.linkedin.com/in/connor-sheahan-6a3933223/\n\ud83e\udd73\ud83c\udf89 THANK YOU UOT FOR HOSTING NEWHACKS \ud83e\udd73\ud83c\udf89", "link": "https://devpost.com/software/mealmate-8kupy4", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "\ud83d\udca1 inspiration \ud83d\udca1\nas university students, we\u2019re very busy, and we\u2019re often so focused on our work that we end up skipping meals. when we do eat, not only do we waste a lot of time deciding what to eat, but we also don\u2019t know many recipes, and as a result, we usually opt for something quick, cheap, and unhealthy, such as fast food or instant ramen. as this is a common issue within the team, we want to create an app that addresses it. the goal of this app is to organize and decide our meals for us, so we don\u2019t waste time contemplating what to eat. this not only saves time, but it also stops us from resorting to unhealthy foods for the sake of convenience.\n\u2699\ufe0f what it does \u2699\ufe0f\nmealmate lets you choose recipes to make at home. based on the ingredients you have on hand, mealmate will recommend recipes tailored to your diet. if you want to have a low-calorie, super healthy breakfast, no problem!\ntry it out on here: https://mealmate-flask.herokuapp.com/\n\ud83d\udee0\ufe0f how we built it \ud83d\udee0\ufe0f\nwe found a database of recipes and their respective ingredients on kaggle. the dataset was approximately 2.2 million rows. we had to take a very small portion of it so that our computers could handle running the recommender systems. we also feature engineered calories and an arbitrary health scale. for calories, each recipe was assigned a random value between 300 and 800 because a person's average homemade meal/snack falls within this boundary. each recipe was also given a random value between 1 and 10 for the health scale.\nmealmate uses a tf-idf recommendation system. the recommendation system is measured in cosine similarity and gives recommendations with a score of at least 0.6. the recommender system has two parts. the first part goes through the database and removes any recipes that don't fall within the parameters the user sets (calories and health scale). the tf-idf system takes into account the different ingredients the user inputs and returns a recommendation of 10 recipes that the user could make.\nfigma was used to create a general ui design template. this helped the project move faster through the next phases because the programmers knew exactly what they were trying to create. now that the project had a solid foundation in the cosine algorithm and the both the general ui design, we decided to split up and develop multiple deployments in order to run on all major operating systems.\nflask + heroku web app: the flask app consists of an html/jinja frontend and python backend. we separated the pages into four main routes: the home page, login, signup, and recommendation page that were built with the help of flask blueprints which greatly sped up development. the main feature of the web app is in the recommendation algorithm which the user can interact with upon landing on the website. as an aside we also implemented a rudimentary login and signup page which is linked to a sqlite database that was setup using sqlalchemy. afterwards, the webpage was deployed on heroku.\nthe flutter app consisted of 7 different pages: the main intro page, minimum calorie selection page, minimum health scale page, ingredients input page, submit page and recommendation page. it plays the major role in providing maximum user experience. it is powered by flask rest api using post method helping the app to recommend within a second. flutter could be designed really fast if we have the blueprint which figma helped a lot in designing the ui of the app. without figma, flutter would take to long to build ui!\n\ud83d\ude23 challenges we ran into \ud83d\ude23\nwe ran into a lot of challenges with our deployment. one major problem was installing and learning flutter. no one on the team knew how to use flutter, so it was an uphill battle trying to learn it and make a useable ui for ios/android. we also ran into some troubles with streamlit when we were trying to design a web app. it was a huge hassle trying to understand how to combine the frontend and backend because we needed to grab user input for the recommender system. this was especially the case because we also encountered issues installing scikit-learn which made testing our webpages all the more time consuming. another major problem came with the deployment of the website and an api that could be used to bridge the user input and recommender output. it was extremely challenging to understand the long-winded and esoteric message thrown up by heroku. furthermore, because each deployment consumed plenty of time, the process of debugging became very time consuming. overall, it was extremely hard to design a ui that focused on usability while getting the user input we needed. in the end, figuring out deployment took up a big chunk of our time.\nwith the recommender system, we ran into memory allocation problems early on. the database we found was amazing, except it had way too much data for us. our computers were unable to allocate enough memory when running the recommender system. the recommender system also had accuracy problems. the cosine similarity scores were around 0.4 which were quite low. eventually, after tweaking the hyperparameters, we were achieving scores of 0.6-0.8 consistently.\n\ud83c\udf89 accomplishments that we're proud of \ud83c\udf89\nour time management was impeccable, we are all very proud of ourselves since we were able to build and deploy an entire app with a recommender system within 24 hours\norganization within the team was perfect, we were all able to contribute and help each other when needed; ex. the figma design helped our webdevs design the ui\nhow our app is able to work on almost all major operating systems\nlearning the basics of flutter and streamlit within a short period of time to deploy our app\nwe are happy to empower people while cooking and make their experience so much more enjoyable\nable to provide a solution for everyone that will increase productivity and promote healthy living\nthis was a super amazing project! we're all proud to have done it in such a short period of time, everyone is new to the hackathon scene and are still eager to learn new technologies\n\ud83d\udcda what we learned \ud83d\udcda\nmany useful technical skills such as flutter, streamlit, flask and working with api's. a large part of this project was learning how to integrate flask and heroku with a flutter application to allow it upload and retrieve data from an api\ndesign and ui skills such as working with figma\nhow to work together under pressure and manage tasks effectively within a team\nusing cosine similarities to compare items within a dataset\nhow to manipulate github -----> branches !!!  via the command window and upload large files using git lfs\nhow to set up and use a virtual machine using android studio\n\u23ed\ufe0fwhat's next for mealmate \u23ed\ufe0f\nmealmate has a lot of work to be done before it is ready to be deployed as a genuine app. it will only be successful if the customer is satisfied and benefits from using it; if it is ugly, slow, or tedious to use, it will be a failure. our next steps are primarily to increase the usability of the app and fix any shortcomings that were not addressed during this hackathon.\nfor starters, we ran into local memory allocation and speed issues due to the size of the database. as a short time solution, we cut down the size of the database, but to counteract these issues in the future, we aim to move the database, as well as the processing, to the cloud, namely aws.\nthe recommender system is also very basic as it is now. we hope to create a more intuitive and complex system that generates more relevant recommendations. for example, recommendations can be based on recipes that were clicked on in the past, or the user will be able to indicate taste preferences (spicy, pasta, vegetables, indian, italian, etc...). dietary restrictions will also be taken into account to ensure the apps widespread usability.\nan important aspect of this app is to allow people to quickly decide on meals; pictures play a big role in this, just look at how advertisements affect consumers. to help the user decide quicker and to increase the attractiveness of the app (so that it's not just a wall of text), we plan to add pictures alongside the recommendations.\nthe current ui is not perfect, and we definitely plan to upgrade it. for now, we plan to add customizable presets so the user does not have to tediously type in the information each time they use the app. on the web app, a more modern multiform input for the ingredients would also be a great addition to the current ui.\n\ud83c\udf81 about the team \ud83c\udf81\nall 4 of us are 1st or 2nd year university students new to the hackathon scene! everyone has only 1 or 2 hackathons worth of experience but that hasn't held us back!\ndae is a 2nd year student at simon fraser university studying computer science. he's interested in everything computer science related and deeply passionate about data science and cross-platform. you can reach out to him at his linkedin ~ https://www.linkedin.com/in/daehyung-kwak-136194223/\nmatthew is a 2nd year student at simon fraser university studying computer science. he has formal training in data science. he's interested in learning new and honing his current frontend skills/technologies. moreover, he's deeply passionate about machine learning, ai and neural networks. you can reach out to him at his linkedin ~ https://www.linkedin.com/in/matthew-wong-240837124/\ndaniel is a 1st year student at university of toronto studying computer science and mathematics. he has an interest in artificial intelligence research and data science. you can reach out to him at his linkedin ~ https://www.linkedin.com/in/daniel-s-851b1521a/\nconnor is a 1st year track one undeclared engineering student at university of toronto. he loves both hardware and software and is planning to pursue some sort of mechatronics education in the future. he is especially passionate about computer science and robotics. you can reach out to him at his linkedin ~ https://www.linkedin.com/in/connor-sheahan-6a3933223/\n\ud83e\udd73\ud83c\udf89 thank you uot for hosting newhacks \ud83e\udd73\ud83c\udf89", "sortedWord": "None", "removed": "Nan", "score": 6, "comments": 0, "media": null, "medialink": null, "identifyer": 59504544}, {"Unnamed: 0": 4548, "autor": "Cloudify", "date": null, "content": "Inspiration\nA frustration with the process of local file sharing through current file sharing services\nWhat it does\nAllows users to upload local files and immediately receive a sharable link, all through our downloadable application.\nHow we built it\nBefore we began writing code, we crafted guiding principles that determined our product functionality. We then drew out the user flow on paper. Then, we split off into two different teams, one team would write the backend, and then one team would write the frontend. The frontend team set out to create the Adobe XD wireframe, then straight into building and programming the application. The backend team created a separate branch where they wrote the several API connections. After both teams had finished, we began working on the integration process. We begun manually merging the two branches together; then, we built it, and deployed it.\nChallenges we ran into\nDuring the integration process, we unfortunately were having issues with the bundler bundling more files than intended. In order to quickly work around this issue, we included all the files we didn't want bundled within the configuration file for the bundler. Working within the Electron environment was another considerable time sink, and learning the ins and outs of Electron was a notable challenge.\nAccomplishments that we're proud of\nWith such tight time constraints, we're shocked that we were even able to complete the project. Despite running into some considerable hiccups with integration and Electron, we were able to successfully deploy Cloudify! The whole team is super proud not only of the product, but our dedication and perseverance while learning about Electron and solving the complex problems that arose throughout development.\nWhat we learned\nHow to work with the Electron environment, work under tight time constraints, and (personally) work with React.\nWhat's next for Cloudify\nPlenty. More upload support, more responsive UI, etc. This is only the beginning!", "link": "https://devpost.com/software/cloudify", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\na frustration with the process of local file sharing through current file sharing services\nwhat it does\nallows users to upload local files and immediately receive a sharable link, all through our downloadable application.\nhow we built it\nbefore we began writing code, we crafted guiding principles that determined our product functionality. we then drew out the user flow on paper. then, we split off into two different teams, one team would write the backend, and then one team would write the frontend. the frontend team set out to create the adobe xd wireframe, then straight into building and programming the application. the backend team created a separate -----> branch !!!  where they wrote the several api connections. after both teams had finished, we began working on the integration process. we begun manually merging the two branches together; then, we built it, and deployed it.\nchallenges we ran into\nduring the integration process, we unfortunately were having issues with the bundler bundling more files than intended. in order to quickly work around this issue, we included all the files we didn't want bundled within the configuration file for the bundler. working within the electron environment was another considerable time sink, and learning the ins and outs of electron was a notable challenge.\naccomplishments that we're proud of\nwith such tight time constraints, we're shocked that we were even able to complete the project. despite running into some considerable hiccups with integration and electron, we were able to successfully deploy cloudify! the whole team is super proud not only of the product, but our dedication and perseverance while learning about electron and solving the complex problems that arose throughout development.\nwhat we learned\nhow to work with the electron environment, work under tight time constraints, and (personally) work with react.\nwhat's next for cloudify\nplenty. more upload support, more responsive ui, etc. this is only the beginning!", "sortedWord": "None", "removed": "Nan", "score": 7, "comments": 0, "media": null, "medialink": null, "identifyer": 59504548}, {"Unnamed: 0": 4745, "autor": "GLAsteroids!", "date": null, "content": "Make sure to look at the stuart branch in the github repo for the completed project!\nProject only supports Linux machines with CMake and required libraries(glfw3 and glew) for building!\nInspiration\nWe wanted to learn OpenGL over the weekend and thought making a modern clone of the game asteroids would be a fun project\nWhat it does\nBasically a simple version of the arcade game asteroids. You have a ship that moves around similar to the original game. You can fire laser pulses from the ship. You can destroy asteroids. You can gain points with a binary score display, with an intentional artistic choice of 8 bit integer score variable with rollover like old arcade games. A gameover game state with vectorized text.\nHow we built it\nIt's written from scratch in C++17 using OpenGL 4.6 with the glfw window and input library.\nChallenges we ran into\nLearning the nuances and complexities of OpenGL in a weekend.\nAccomplishments that we're proud of\nMaking it work with correct techniques such as storing vertex data on video memory rather than main computer memory.\nWhat we learned\nThe basics of OpenGL in C++ with glsl shader basics. The core of what we would need to know to begin making a game or game engine from scratch.\nWhat's next for GLAsteroids!\nMore graphics, various features we might think would be fun to add, like 3D graphics or VR support for the heck of it and just for fun.", "link": "https://devpost.com/software/rainbow-js-electric-boogaloo", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "make sure to look at the stuart -----> branch !!!  in the github repo for the completed project!\nproject only supports linux machines with cmake and required libraries(glfw3 and glew) for building!\ninspiration\nwe wanted to learn opengl over the weekend and thought making a modern clone of the game asteroids would be a fun project\nwhat it does\nbasically a simple version of the arcade game asteroids. you have a ship that moves around similar to the original game. you can fire laser pulses from the ship. you can destroy asteroids. you can gain points with a binary score display, with an intentional artistic choice of 8 bit integer score variable with rollover like old arcade games. a gameover game state with vectorized text.\nhow we built it\nit's written from scratch in c++17 using opengl 4.6 with the glfw window and input library.\nchallenges we ran into\nlearning the nuances and complexities of opengl in a weekend.\naccomplishments that we're proud of\nmaking it work with correct techniques such as storing vertex data on video memory rather than main computer memory.\nwhat we learned\nthe basics of opengl in c++ with glsl shader basics. the core of what we would need to know to begin making a game or game engine from scratch.\nwhat's next for glasteroids!\nmore graphics, various features we might think would be fun to add, like 3d graphics or vr support for the heck of it and just for fun.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59504745}, {"Unnamed: 0": 4851, "autor": "Green Deeds", "date": null, "content": "Inspiration\nWe felt Green Deeds fit perfectly with Kiva's mission to expand financial access to underserved individuals.\nWhat it does\nOur app rewards users for recycling and composting with crypto currency that they can convert to fiat. Our app then gives them the option to invest that earned fiat into kiva loans.\nHow we built it\nWe built the app using Expo, React Native, Graph QL and Firebase. We even designed our pages on Figma before integrating into the app.\nChallenges we ran into\nFigma turned out to be a little more complicated than expected, so we ended up just coding the frontend to resemble the Figma designs last minute. The entire team came through in the last five days despite all our prep and excitement over using Figma for an advanced UI experience.\nAccomplishments that we're proud of\nWe're really proud of how well the team worked together considering it was everyone's first time working together. We all have different backgrounds and expertise, but we really all meshed well together and had a fun time making a solid MVP just in time for submission!\nWhat we learned\nWe learned a variety of things, especially about Figma. We learned proper use of github branches while we each worked on different aspects of the app, and how to communicate via discord during the stressful last 24 hours of this hack! We all had such great attitudes and everyone rallied despite the setback with Figma integration.\nWhat's next for Green Deeds\nWe hope to find investors for Green Deeds so that we can really spend time on the UI and the integration of Plaid and Celo's main blockchain (it's currently working on the development chain). Both co-founders are actively working and learning to understand how composting, recycling and the entire food cycle works so that Green Deeds can be an integral part in helping to incentivize the public to help restore the planet.\nThe co-founders, Anthony and Brittany, are so happy to have found a great team for this hackathon. Especially Brittany! She had been the only developer since the outset and she is so grateful to get a chance to work with a team for this hackathon that could contribute their advice and expertise. We all are so excited to submit to the Kiva hackathon and can't wait to continue their work together to bring Green Deeds to the masses!\nThank you Kiva for bringing us together!", "link": "https://devpost.com/software/green-deeds-er02qn", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nwe felt green deeds fit perfectly with kiva's mission to expand financial access to underserved individuals.\nwhat it does\nour app rewards users for recycling and composting with crypto currency that they can convert to fiat. our app then gives them the option to invest that earned fiat into kiva loans.\nhow we built it\nwe built the app using expo, react native, graph ql and firebase. we even designed our pages on figma before integrating into the app.\nchallenges we ran into\nfigma turned out to be a little more complicated than expected, so we ended up just coding the frontend to resemble the figma designs last minute. the entire team came through in the last five days despite all our prep and excitement over using figma for an advanced ui experience.\naccomplishments that we're proud of\nwe're really proud of how well the team worked together considering it was everyone's first time working together. we all have different backgrounds and expertise, but we really all meshed well together and had a fun time making a solid mvp just in time for submission!\nwhat we learned\nwe learned a variety of things, especially about figma. we learned proper use of github -----> branches !!!  while we each worked on different aspects of the app, and how to communicate via discord during the stressful last 24 hours of this hack! we all had such great attitudes and everyone rallied despite the setback with figma integration.\nwhat's next for green deeds\nwe hope to find investors for green deeds so that we can really spend time on the ui and the integration of plaid and celo's main blockchain (it's currently working on the development chain). both co-founders are actively working and learning to understand how composting, recycling and the entire food cycle works so that green deeds can be an integral part in helping to incentivize the public to help restore the planet.\nthe co-founders, anthony and brittany, are so happy to have found a great team for this hackathon. especially brittany! she had been the only developer since the outset and she is so grateful to get a chance to work with a team for this hackathon that could contribute their advice and expertise. we all are so excited to submit to the kiva hackathon and can't wait to continue their work together to bring green deeds to the masses!\nthank you kiva for bringing us together!", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59504851}, {"Unnamed: 0": 5058, "autor": "FamiLead", "date": null, "content": "Inspiration\nWe noticed that household management (dividing up responsibilities and chores, sending grocery lists, communication, and upcoming events, finding places to go, etc.) is divided across several platforms, resulting in information being forgotten, lost, and having to be resent. Our platform combines all aspects of family life so that in this digital age, families are brought together instead of separated across devices. You can think of it as a workflow management platform for the home.\nWhat we learned\nThroughout this hackathon experience, we were able to learn about cool tools and technologies to help support this application with all of its features. We learned how to effectively pitch an idea, by incorporating personal experiences to explain our thinking. On the technical side, we learned how to incorporate Twilio, Firebase, and Google APIs into our React project. Finally, the execution of the web app was a super cool learning process. We learned how to incorporate a Google Maps API into our web app to allow for user interaction.\nHow We Built It\nFamiLead was built upon React as the frontend and Node.js as the backend, with Firebase serving as the database system and the method of hosting the application. TailwindCSS was used to style the application, allowing for smooth, easy-to-use user experience. The embedded map was created using the Google Maps API, and the todo list functionality was built using Firestore Cloud functions.\nChallenges\nWe have faced many problems along our journey. From small things like forgetting to install npm to reinstalling react and firebase and redoing the entire project. Our biggest challenge came up when we were using GitHub to separate the project into different branches and merge partial solutions together. The data had many conflicts and we were forced to start from scratch and take a different path to the problem at hand. This consumed many hours of our work time as we had been working on a solution until mid-afternoon before restarting. Luckily, we learned a great amount about the methods we had to take to create this app, so we were able to take this alternative path much quicker and almost finished by the end of the day.", "link": "https://devpost.com/software/familead", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nwe noticed that household management (dividing up responsibilities and chores, sending grocery lists, communication, and upcoming events, finding places to go, etc.) is divided across several platforms, resulting in information being forgotten, lost, and having to be resent. our platform combines all aspects of family life so that in this digital age, families are brought together instead of separated across devices. you can think of it as a workflow management platform for the home.\nwhat we learned\nthroughout this hackathon experience, we were able to learn about cool tools and technologies to help support this application with all of its features. we learned how to effectively pitch an idea, by incorporating personal experiences to explain our thinking. on the technical side, we learned how to incorporate twilio, firebase, and google apis into our react project. finally, the execution of the web app was a super cool learning process. we learned how to incorporate a google maps api into our web app to allow for user interaction.\nhow we built it\nfamilead was built upon react as the frontend and node.js as the backend, with firebase serving as the database system and the method of hosting the application. tailwindcss was used to style the application, allowing for smooth, easy-to-use user experience. the embedded map was created using the google maps api, and the todo list functionality was built using firestore cloud functions.\nchallenges\nwe have faced many problems along our journey. from small things like forgetting to install npm to reinstalling react and firebase and redoing the entire project. our biggest challenge came up when we were using github to separate the project into different -----> branches !!!  and merge partial solutions together. the data had many conflicts and we were forced to start from scratch and take a different path to the problem at hand. this consumed many hours of our work time as we had been working on a solution until mid-afternoon before restarting. luckily, we learned a great amount about the methods we had to take to create this app, so we were able to take this alternative path much quicker and almost finished by the end of the day.", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 2, "media": null, "medialink": null, "identifyer": 59505058}, {"Unnamed: 0": 5199, "autor": "QuikServe", "date": null, "content": "Inspiration \ud83d\udca1\nThe COVID-19 pandemic imposed severe in-restaurant dining restrictions that deleteriously affected the restaurant industry. According to industry experts, there has been a bloodbath in the industry because of Covid-19 curbs. A Survey estimates that nearly 40% of restaurants have shut shops globally & because of the same many waiters, butlers lost their source of income.\nBut now, things have started changing as people are getting vaccinated, the traffic in restaurants & cafes has started to increase.\nAlthough strict hygienic rules have been foisted, citizens are concerned about catching the Covid-19 infection in restaurants and cafes as they are frequented by a variety of people. And as things begin to move back to normal, because of that traffic it becomes very hectic for the workers such as waiters to provide the necessary priority towards their customers & this is a massive reason why Restaurants lose their customers.\nAs they say, Patience is the key, but not everyone owns it. We believe that with the power of AI, this can be solved if we proceed creatively. Thus we made QuikServe!\nWhat it does \ud83e\udd14\nTranscribing process of order\nSaving the audio files securely\nMeals Identification from Notes\nRecognize the prices from the photo of a bill\nAllows waiter to directly process payment with the option of splitting the bill\nQuikServe is a PWA which has been specially curated for waiters so that customers can spend more time eating their food, rather than eating their time!\nWe simplify the current approaches that are undertaken in most of the restaurants starting from taking the order till the checkout. Different technologies have been leveraged while building the application.\nHow we built it \ud83c\udfd7\nFirst and foremost, it is Crafted with \ud83d\udc99.\nOur fully-working web-app is primarily built with React.js using Tailwind CSS. We used Firebase for OAuth. Inside the app, we have different sections each registered for doing specific operations. For the first instance of the day, the user (i.e. worker) needs to check himself or herself in before using the main features. The check-in only works when the user is in the geo-fence of the restaurant, for which we are using Mapbox for the visualization. Then we have completed & pending orders according to tables, where waiters can visit & can take orders directly using input audio from customers which is processed by AssemblyAI API. We fetch useful information like transcriptions, highlighted keywords/phrases, emotions etc. else can also take notes manually. Once we are done with the order, the same can also be used to scan the barcode of the food item (which comes with the table) & then confirm the order by taking the bills into account. During checkout, that bill is itself processed in the backend using Jina AI running on PaddlePaddle OCR hosted as a Docker image. We then split the bill in terms of the customer count of that table and preview the bill directly. We also have a profile section which is easily customizable!\nWe all know that these datas are very confidential. Recently we got to hear news about the Domino's Pizza data breach, where the Financial data of 180+ million users got exposed.\nAnd this is one of the reasons we are backing up all of these important media on IPFS. Most of the attacks happen on the transport layer, that is the reason we primarily went with IPFS. IPFS uses transport-encryption. This means that your data is secure when being sent from one IPFS node to another.\nRest, we\u2019ve also used Firebase Cloud functions for syncing up with all those custom created API\u2019s that run the show!\nChallenges We ran into \ud83e\uddf1\nThere were lots of challenges on our way. First, because we are all online and spread around the globe, it was somewhat difficult for us to be communicating during the process. We also spent a great deal of time discussing ideas for the project. We have reached a final decision on what to include in our project after we had a couple of calls with mentors. After we settled on the idea, we separated the work according to everyone's skills. Aziz was primarily working on the Front-end, while Jun set up integrations & backend. Besides, Pratyay worked on building the ML model. We faced most challenges when we tried to allocate segregated chunks into one project.\nDesign\nWe were heavily inspired by the revised version of Iterative design process, which not only includes visual design, but a full-fledged research cycle in which you must discover and define your problem before tackling your solution & then finally deploy it.\nDiscover: a deep dive into the problem we are trying to solve.\nDefine: synthesizing the information from the discovery phase into a problem definition.\nDevelop: think up solutions to the problem.\nDeliver: pick the best solution and build that.\nThis time went for the minimalist Material UI design. We utilized design tools like Figma, Photoshop & Illustrator to prototype our designs before doing any coding. Through this, we are able to get iterative feedback so that we spend less time re-writing code.\nResearch \ud83d\udcda\nResearch is the key to empathizing with users: we found our specific user group early and that paves the way for our whole project. Here are a few of the resources that were helpful to us \u2014\nPP-OCR: A Practical Ultra Lightweight OCR System : https://arxiv.org/abs/2009.09941\nOn the Efficiency of Decentralized File Storage for Personal Information Management Systems : https://arxiv.org/pdf/2007.03505.pdf\nCurrency Converter API : https://free.currencyconverterapi.com\nAssembly AI Api Docs : https://bit.ly/3nPQZL4\nJina AI Docs : https://docs.jina.ai\n\u2663 Datasets :- Recompiled from several Sources.\n\u2663 Articles :-\nRestaurant Industry Facts at a Glance : https://bit.ly/3bspl0E\nFood Safety and the Coronavirus Disease, FDA : https://bit.ly/3buiJit\nRestaurants and COVID-19 : https://bit.ly/3msPN0s\n5 Reasons Why Restaurants Lose Customers : https://bit.ly/3nK3FD1\nTop 10 Reasons Why Restaurants Fail Within The First Year Of Operations : https://bit.ly/3CKGgb3\nHow restaurants are adapting to the COVID-19 pandemic : https://bit.ly/2Y3TYqg\nRestaurant sector stares at massive losses as states reimpose strict Covid-19 curbs : https://bit.ly/3jU52hs\nConsumers seek safety and socialization at restaurants in wake of COVID-19 : https://bit.ly/3pQi03x\nDomino\u2019s Pizza data breach, Financial data of 180+ million users are at stake : https://bit.ly/3BpZzVz\nCREDITS\nDesign Resources : Freepik\nIcons : Icons8, fontawesome\nFont : Roboto / Righteous / Turret Road / Manrope / Montserrat\nTakeaways\nAccomplishments that we're proud of \ud83d\ude4c\nA fully working prototype! This has been intense yet insightful. We are very proud to have designed and built an application within such a short timeframe.\nLearning how to collaborate on GitHub! Not all of us were familiar with making branches or making a PR and merging. This hackathon has fast-tracked the learning process and we are all now very comfortable in using GitHub!\nLearning new technology (like Tailwind CSS, routing in React, implementing sophisticated design features, Firebase Functions, Firestore), meeting new people, debugging, debugging, and more debugging!\nThe idea of helping restaurants to survive COVID and making positive changes in our community.\nWhat we learned \ud83d\ude4c\nStaying hydrated was our motto for completing this impactful and complicated project on time. We have learned how great wins are accomplished by working together. For the technical part, we learned how to implement a complete serverless backend using GCP. Moreover, we have faced some issues when we were merging the front-end and backend. We also gave our level best to make the UI/UX look minimalistic and useful! Not to mention, documentations and help from Google for technologies we used (be it react components libraries, IPFS, API calls) were extremely useful!\nWhat's next for QuikServe\ud83d\udcc3\nWe believe that QuikServe is an app with great potential. Since all four of us are very passionate about tackling the issue of helping businesses to recover from COVID-19, it's easy to come up with a lot of ideas for new features (like we did at the beginning of this hackathon!). However, we now have learned the importance of focusing on a single feature at a time and making sure that feature works flawlessly before designing a new feature! \u2728\nThis includes:\nMoving forward and making all the storage systems decentralized\nRefractor our code; because there's so much we can do under 36 hours\nDoing many, many tests (another thing we lack during the past 36 hours). We want to understand all the nitty-gritty details on whether the app flow is intuitive or how the speech-to-text feature behaves on a noisy background, or if there is anything we can do to make the user experience better.\nOverall, we hope that this project can help restaurants to get through pandemics and thrive.\nNote \u2014 API credentials have been revoked. If you want to run the same on your local, use your own credentials.", "link": "https://devpost.com/software/quikserve", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration \ud83d\udca1\nthe covid-19 pandemic imposed severe in-restaurant dining restrictions that deleteriously affected the restaurant industry. according to industry experts, there has been a bloodbath in the industry because of covid-19 curbs. a survey estimates that nearly 40% of restaurants have shut shops globally & because of the same many waiters, butlers lost their source of income.\nbut now, things have started changing as people are getting vaccinated, the traffic in restaurants & cafes has started to increase.\nalthough strict hygienic rules have been foisted, citizens are concerned about catching the covid-19 infection in restaurants and cafes as they are frequented by a variety of people. and as things begin to move back to normal, because of that traffic it becomes very hectic for the workers such as waiters to provide the necessary priority towards their customers & this is a massive reason why restaurants lose their customers.\nas they say, patience is the key, but not everyone owns it. we believe that with the power of ai, this can be solved if we proceed creatively. thus we made quikserve!\nwhat it does \ud83e\udd14\ntranscribing process of order\nsaving the audio files securely\nmeals identification from notes\nrecognize the prices from the photo of a bill\nallows waiter to directly process payment with the option of splitting the bill\nquikserve is a pwa which has been specially curated for waiters so that customers can spend more time eating their food, rather than eating their time!\nwe simplify the current approaches that are undertaken in most of the restaurants starting from taking the order till the checkout. different technologies have been leveraged while building the application.\nhow we built it \ud83c\udfd7\nfirst and foremost, it is crafted with \ud83d\udc99.\nour fully-working web-app is primarily built with react.js using tailwind css. we used firebase for oauth. inside the app, we have different sections each registered for doing specific operations. for the first instance of the day, the user (i.e. worker) needs to check himself or herself in before using the main features. the check-in only works when the user is in the geo-fence of the restaurant, for which we are using mapbox for the visualization. then we have completed & pending orders according to tables, where waiters can visit & can take orders directly using input audio from customers which is processed by assemblyai api. we fetch useful information like transcriptions, highlighted keywords/phrases, emotions etc. else can also take notes manually. once we are done with the order, the same can also be used to scan the barcode of the food item (which comes with the table) & then confirm the order by taking the bills into account. during checkout, that bill is itself processed in the backend using jina ai running on paddlepaddle ocr hosted as a docker image. we then split the bill in terms of the customer count of that table and preview the bill directly. we also have a profile section which is easily customizable!\nwe all know that these datas are very confidential. recently we got to hear news about the domino's pizza data breach, where the financial data of 180+ million users got exposed.\nand this is one of the reasons we are backing up all of these important media on ipfs. most of the attacks happen on the transport layer, that is the reason we primarily went with ipfs. ipfs uses transport-encryption. this means that your data is secure when being sent from one ipfs node to another.\nrest, we\u2019ve also used firebase cloud functions for syncing up with all those custom created api\u2019s that run the show!\nchallenges we ran into \ud83e\uddf1\nthere were lots of challenges on our way. first, because we are all online and spread around the globe, it was somewhat difficult for us to be communicating during the process. we also spent a great deal of time discussing ideas for the project. we have reached a final decision on what to include in our project after we had a couple of calls with mentors. after we settled on the idea, we separated the work according to everyone's skills. aziz was primarily working on the front-end, while jun set up integrations & backend. besides, pratyay worked on building the ml model. we faced most challenges when we tried to allocate segregated chunks into one project.\ndesign\nwe were heavily inspired by the revised version of iterative design process, which not only includes visual design, but a full-fledged research cycle in which you must discover and define your problem before tackling your solution & then finally deploy it.\ndiscover: a deep dive into the problem we are trying to solve.\ndefine: synthesizing the information from the discovery phase into a problem definition.\ndevelop: think up solutions to the problem.\ndeliver: pick the best solution and build that.\nthis time went for the minimalist material ui design. we utilized design tools like figma, photoshop & illustrator to prototype our designs before doing any coding. through this, we are able to get iterative feedback so that we spend less time re-writing code.\nresearch \ud83d\udcda\nresearch is the key to empathizing with users: we found our specific user group early and that paves the way for our whole project. here are a few of the resources that were helpful to us \u2014\npp-ocr: a practical ultra lightweight ocr system : https://arxiv.org/abs/2009.09941\non the efficiency of decentralized file storage for personal information management systems : https://arxiv.org/pdf/2007.03505.pdf\ncurrency converter api : https://free.currencyconverterapi.com\nassembly ai api docs : https://bit.ly/3npqzl4\njina ai docs : https://docs.jina.ai\n\u2663 datasets :- recompiled from several sources.\n\u2663 articles :-\nrestaurant industry facts at a glance : https://bit.ly/3bspl0e\nfood safety and the coronavirus disease, fda : https://bit.ly/3buijit\nrestaurants and covid-19 : https://bit.ly/3mspn0s\n5 reasons why restaurants lose customers : https://bit.ly/3nk3fd1\ntop 10 reasons why restaurants fail within the first year of operations : https://bit.ly/3ckggb3\nhow restaurants are adapting to the covid-19 pandemic : https://bit.ly/2y3tyqg\nrestaurant sector stares at massive losses as states reimpose strict covid-19 curbs : https://bit.ly/3ju52hs\nconsumers seek safety and socialization at restaurants in wake of covid-19 : https://bit.ly/3pqi03x\ndomino\u2019s pizza data breach, financial data of 180+ million users are at stake : https://bit.ly/3bpzzvz\ncredits\ndesign resources : freepik\nicons : icons8, fontawesome\nfont : roboto / righteous / turret road / manrope / montserrat\ntakeaways\naccomplishments that we're proud of \ud83d\ude4c\na fully working prototype! this has been intense yet insightful. we are very proud to have designed and built an application within such a short timeframe.\nlearning how to collaborate on github! not all of us were familiar with making -----> branches !!!  or making a pr and merging. this hackathon has fast-tracked the learning process and we are all now very comfortable in using github!\nlearning new technology (like tailwind css, routing in react, implementing sophisticated design features, firebase functions, firestore), meeting new people, debugging, debugging, and more debugging!\nthe idea of helping restaurants to survive covid and making positive changes in our community.\nwhat we learned \ud83d\ude4c\nstaying hydrated was our motto for completing this impactful and complicated project on time. we have learned how great wins are accomplished by working together. for the technical part, we learned how to implement a complete serverless backend using gcp. moreover, we have faced some issues when we were merging the front-end and backend. we also gave our level best to make the ui/ux look minimalistic and useful! not to mention, documentations and help from google for technologies we used (be it react components libraries, ipfs, api calls) were extremely useful!\nwhat's next for quikserve\ud83d\udcc3\nwe believe that quikserve is an app with great potential. since all four of us are very passionate about tackling the issue of helping businesses to recover from covid-19, it's easy to come up with a lot of ideas for new features (like we did at the beginning of this hackathon!). however, we now have learned the importance of focusing on a single feature at a time and making sure that feature works flawlessly before designing a new feature! \u2728\nthis includes:\nmoving forward and making all the storage systems decentralized\nrefractor our code; because there's so much we can do under 36 hours\ndoing many, many tests (another thing we lack during the past 36 hours). we want to understand all the nitty-gritty details on whether the app flow is intuitive or how the speech-to-text feature behaves on a noisy background, or if there is anything we can do to make the user experience better.\noverall, we hope that this project can help restaurants to get through pandemics and thrive.\nnote \u2014 api credentials have been revoked. if you want to run the same on your local, use your own credentials.", "sortedWord": "None", "removed": "Nan", "score": 6, "comments": 0, "media": null, "medialink": null, "identifyer": 59505199}, {"Unnamed: 0": 5639, "autor": "Mysocialcontract", "date": null, "content": "Inspiration\nI started this project because I myself don't know how to build an audience on Twitter. I looked at the current solutions to get professional marketing advice and wasn't convinced: traditional freelance platforms are intermediaries that offer rigid payment models and take a large cut.\nWhat it does\nMysocialcontract helps businesses and creators who want to boost their social accounts connect with social media marketers. Anyone can make a request for promotion completely free. Marketers can message requesters privately and send them offers for promotion. After negotiating, the requester and the marketer can sign a smart contract with a deadline, promotion conditions i.e. a minimum number of followers for a specific Twitter account, and a deposit as payment.\nBefore the deadline, the contract can be used to verify the conditions using a Chainlink Oracle that requests data from social network APIs. If all the conditions are met, the marketer can withdraw the deposit. If any condition fails, the requester keeps the funds.\nHow we built it\nThis project has the following components:\nReact app: The frontend application that users interact with to create requests, make offers and sign contracts.\nSmart contracts: The solidity contracts that store the conditions, call Chainlink Oracles and handle payments.\nMoralis database: Stores requests, offers, private chats and profiles.\nMoralis cloud functions: Connect with social media providers to get information necessary at the frontend.\nIPFS: An IPFS file keeps a track record of each user's successful contracts and how much ETH, followers, etc. they gained. This increases trust in experienced users and can also be used outside the platform.\nA custom External Adapter to retrieve Youtube and Twitter data. Public repo forked from the official smartcontractkit/external-adapters-js repo (develop branch.)\nA full Chainlink node deployed to AWS.\nChallenges we ran into\nThe most difficult part was setting up my own node and successfully connecting it to both the PostgreSql database and the External Adapter. The Chainlink node's bridge was particularly difficult to debug.\nAccomplishments that we're proud of\nSetting up all the necessary infrastructure and developing a working UI in time.\nWhat we learned\nSolidity (first time using it.)\nSetting up the whole Chainlink stack.\nUsing the Moralis stack.\nWhat's next for Mysocialcontract\nA means to provide feedback after completing a contract with another user.\nBetter error handling at the Bridge/Chainlink node.\nAdd more social networks.\nMainnet release (early 2022).", "link": "https://devpost.com/software/mysocialcontract", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\ni started this project because i myself don't know how to build an audience on twitter. i looked at the current solutions to get professional marketing advice and wasn't convinced: traditional freelance platforms are intermediaries that offer rigid payment models and take a large cut.\nwhat it does\nmysocialcontract helps businesses and creators who want to boost their social accounts connect with social media marketers. anyone can make a request for promotion completely free. marketers can message requesters privately and send them offers for promotion. after negotiating, the requester and the marketer can sign a smart contract with a deadline, promotion conditions i.e. a minimum number of followers for a specific twitter account, and a deposit as payment.\nbefore the deadline, the contract can be used to verify the conditions using a chainlink oracle that requests data from social network apis. if all the conditions are met, the marketer can withdraw the deposit. if any condition fails, the requester keeps the funds.\nhow we built it\nthis project has the following components:\nreact app: the frontend application that users interact with to create requests, make offers and sign contracts.\nsmart contracts: the solidity contracts that store the conditions, call chainlink oracles and handle payments.\nmoralis database: stores requests, offers, private chats and profiles.\nmoralis cloud functions: connect with social media providers to get information necessary at the frontend.\nipfs: an ipfs file keeps a track record of each user's successful contracts and how much eth, followers, etc. they gained. this increases trust in experienced users and can also be used outside the platform.\na custom external adapter to retrieve youtube and twitter data. public repo forked from the official smartcontractkit/external-adapters-js repo (develop -----> branch !!! .)\na full chainlink node deployed to aws.\nchallenges we ran into\nthe most difficult part was setting up my own node and successfully connecting it to both the postgresql database and the external adapter. the chainlink node's bridge was particularly difficult to debug.\naccomplishments that we're proud of\nsetting up all the necessary infrastructure and developing a working ui in time.\nwhat we learned\nsolidity (first time using it.)\nsetting up the whole chainlink stack.\nusing the moralis stack.\nwhat's next for mysocialcontract\na means to provide feedback after completing a contract with another user.\nbetter error handling at the bridge/chainlink node.\nadd more social networks.\nmainnet release (early 2022).", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59505639}, {"Unnamed: 0": 5874, "autor": "HackShop", "date": null, "content": "Inspiration: As college students, we are constantly going to the grocery store with our friends and roommates in need of groceries and supplies for our new homes. One opportunity to improve the experience is through implementing a mini game system that allows for friends to have a friendly competition with each other to gain more points attributed to a specific store. This also allows retailers to gamify the experience, bringing users back through not only their products but entertainment and engagement as well\nWhat it does: The app offers a unique system for a store to organize their enticing game features to attract and retain customers. It has currently implemented two mini games, challenges and hangman, but is designed to implement many more games and features.\nHow we built it: The technologies we used include React (Router, Bootstrap), Firebase, Firestore, Figma, and Nodejs. We also have designed a TicTacToe Game utilizing Pubnub's API.\nChallenges we ran into: Challenges we ran into was interaction with the Firebase and Firestore databases as we attempted to pull and store user information to expand functionality and user experience to many other features. Also, Pubnub's API demonstrated great difficulties when being implemented within our React Framework. Another challenge we faced was various merge conflicts in Github that involved packages that influenced and messed up the overall layout of our project.\nAccomplishments we're proud of: With our project, we were able to implement a login feature, pull and store data into a firebase database that utilizes user attributes, as well as interact with multiple screens and games on the front end to offer an interactive opportunity for users.\nWhat we learned: We all improved upon each of our design, backend, frontend, and full stack skills through this hackathon. We learned how databases work, and how to store and pull data from them, as well as how to query data from databases. We also learned how to work with React, and use GitHub to manage branches and commits.\nWhat's next for HackShop: We hope to create a working group creation feature soon, and fully integrate our backend with the React app, and we would also like to flesh out the cosmetic/customization options available to users. On the non-technical side, we would try to pitch to stores with mostly younger audiences (toy stores, family grocers, school supplies suppliers) to try and connect the app with families, who happen to be a target demographic for us.", "link": "https://devpost.com/software/hackshop-se9um3", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration: as college students, we are constantly going to the grocery store with our friends and roommates in need of groceries and supplies for our new homes. one opportunity to improve the experience is through implementing a mini game system that allows for friends to have a friendly competition with each other to gain more points attributed to a specific store. this also allows retailers to gamify the experience, bringing users back through not only their products but entertainment and engagement as well\nwhat it does: the app offers a unique system for a store to organize their enticing game features to attract and retain customers. it has currently implemented two mini games, challenges and hangman, but is designed to implement many more games and features.\nhow we built it: the technologies we used include react (router, bootstrap), firebase, firestore, figma, and nodejs. we also have designed a tictactoe game utilizing pubnub's api.\nchallenges we ran into: challenges we ran into was interaction with the firebase and firestore databases as we attempted to pull and store user information to expand functionality and user experience to many other features. also, pubnub's api demonstrated great difficulties when being implemented within our react framework. another challenge we faced was various merge conflicts in github that involved packages that influenced and messed up the overall layout of our project.\naccomplishments we're proud of: with our project, we were able to implement a login feature, pull and store data into a firebase database that utilizes user attributes, as well as interact with multiple screens and games on the front end to offer an interactive opportunity for users.\nwhat we learned: we all improved upon each of our design, backend, frontend, and full stack skills through this hackathon. we learned how databases work, and how to store and pull data from them, as well as how to query data from databases. we also learned how to work with react, and use github to manage -----> branches !!!  and commits.\nwhat's next for hackshop: we hope to create a working group creation feature soon, and fully integrate our backend with the react app, and we would also like to flesh out the cosmetic/customization options available to users. on the non-technical side, we would try to pitch to stores with mostly younger audiences (toy stores, family grocers, school supplies suppliers) to try and connect the app with families, who happen to be a target demographic for us.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59505874}, {"Unnamed: 0": 6061, "autor": "Anime Wrapped", "date": null, "content": "Inspiration\nMainstream music, television and cinema all have abundant analytical platforms. However, we noticed that many niche forms of entertainment such as Japanese anime lack these tools. As avid anime watchers ourselves, we know the wide variety of genres out there and are familiar with the anime community's desire to analyze and share anime. We are confident that our project will be embraced by this community.\nWhat it does\nWe decided to leverage the API of the popular anime database MyAnimeList (MAL) to provide users with dynamic, personalized analytics on their viewership. Our platform analyzes user trends to deliver detailed commentary about their anime viewing history and make suggestions for the future.\nHow we built it\nAfter deciding on the idea, we spent a few hours on Figma prototyping our project and discussing what features to add. For the actual implementation, we created a GitHub repository with separate branches and worked on separate components on our own. In terms of the actual technologies, in the backend, we integrated MAL's RESTful API, writing a NodeJS script to implement OAuth authentication. In the frontend, we used AngularJS as our framework, wherein we wrote code in HTML, CSS preprocessors such as SCSS, and JavaScript/TypeScript.\nChallenges we ran into\nOur biggest challenge was definitely a lack of experience. With only one member experienced in web development frameworks, there was a learning curve for a lot of the team. However, the whole team learned on the job and contributed a fair amount to the final product.\nAccomplishments that we're proud of\nDespite the aforementioned lack of experience, we accomplished a great amount in the little time we had to learn. We managed to make a great looking application, using open source themes and a user-friendly scrollable interface. Most importantly, we are very proud of how well we collaborated, treating everyone else with respect and fixing each other's bugs whenever required.\nWhat we learned\nWe learned a great amount in front-end frameworks and languages, API integration including authentication, data analytics, and version control\u2013\u2013skills that we will definitely build on in the future.\nWhat's next for Anime Wrapped\nIn the future we plan to make ML based personalized recommendations, such as using real-time user-generated data in models such as the multi-layered perceptron to supplement our current algorithm.\nWe also strive to connect the anime community by adding social media integration, shareable content, and friend recommendations.", "link": "https://devpost.com/software/anime-wrapped", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nmainstream music, television and cinema all have abundant analytical platforms. however, we noticed that many niche forms of entertainment such as japanese anime lack these tools. as avid anime watchers ourselves, we know the wide variety of genres out there and are familiar with the anime community's desire to analyze and share anime. we are confident that our project will be embraced by this community.\nwhat it does\nwe decided to leverage the api of the popular anime database myanimelist (mal) to provide users with dynamic, personalized analytics on their viewership. our platform analyzes user trends to deliver detailed commentary about their anime viewing history and make suggestions for the future.\nhow we built it\nafter deciding on the idea, we spent a few hours on figma prototyping our project and discussing what features to add. for the actual implementation, we created a github repository with separate -----> branches !!!  and worked on separate components on our own. in terms of the actual technologies, in the backend, we integrated mal's restful api, writing a nodejs script to implement oauth authentication. in the frontend, we used angularjs as our framework, wherein we wrote code in html, css preprocessors such as scss, and javascript/typescript.\nchallenges we ran into\nour biggest challenge was definitely a lack of experience. with only one member experienced in web development frameworks, there was a learning curve for a lot of the team. however, the whole team learned on the job and contributed a fair amount to the final product.\naccomplishments that we're proud of\ndespite the aforementioned lack of experience, we accomplished a great amount in the little time we had to learn. we managed to make a great looking application, using open source themes and a user-friendly scrollable interface. most importantly, we are very proud of how well we collaborated, treating everyone else with respect and fixing each other's bugs whenever required.\nwhat we learned\nwe learned a great amount in front-end frameworks and languages, api integration including authentication, data analytics, and version control\u2013\u2013skills that we will definitely build on in the future.\nwhat's next for anime wrapped\nin the future we plan to make ml based personalized recommendations, such as using real-time user-generated data in models such as the multi-layered perceptron to supplement our current algorithm.\nwe also strive to connect the anime community by adding social media integration, shareable content, and friend recommendations.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59506061}, {"Unnamed: 0": 6196, "autor": "WeDukeCare", "date": null, "content": "Inspiration\nThe one topic we have not always been so open about - mental health.\nGoing off of that, our team had the desire to come up with a companion app to help improve one's mental well-being. From our research, we found out that one way that will help in that sense would be in terms of practicing mindfulness.\nMindfulness is a type of meditation in which you focus on being intensely aware of what you're sensing and feeling in the moment, without interpretation or judgment. Practicing mindfulness involves breathing methods, guided imagery, and other practices to relax the body and mind and help reduce stress. One proven method to encourage the practice of mindfulness is through the habit of journaling (https://www.mayoclinic.org/healthy-lifestyle/consumer-health/in-depth/mindfulness-exercises/art-20046356).\nJournaling is the act of keeping a record of your personal thoughts, feelings, insights, and more. It can be written, drawn, or typed. It can be on paper or on your computer. It\u2019s a simple, low-cost way of improving your mental health.\nThese are some of the benefits of journaling (https://www.webmd.com/mental-health/mental-health-benefits-of-journaling):\nIt can reduce anxiety\nIt helps with brooding\nIt creates awareness\nIt regulates emotions\nIt encourages opening up\nIt can speed up physical healing\nReference https://positivepsychology.com/benefits-of-journaling/\nWhat it does\nUsers are able to sign-up and log in. Once logged in, these are some of the main features:\nUser is able to put in a daily entry: From the daily entry, we included Google's Natural Language API - Sentiment Analysis API to detect the severity of the user's emotions. Should the user lean towards having a risk of harming themselves (low score and high magnitude), a trigger will be sent via Twilio's text messaging API to the user's emergency contact. Should the user lean towards a moderately severe score, it will trigger the function call via Twilio's text messaging API to remind said user of their happier memories that have been recorded on the app\nUser is able to rate their mood on a scale of 1 to 5\nUser is able to key in the date and submit the daily entry\nOther features:\nPlant progress tracker to keep track of user's activity on the app: Say that the user has logged in consecutively, the user is acknowledged for it (the plant looks alive and well). Say that the user has skipped several days, the user is reminded about it (the plant wilts).\nDisclaimer: Not all features have been fully implemented / are still in its prototype stage eg. having hard-coded destination phone numbers.\nHow we built it\nThe tech stacks we used for the frontend are as such:\nReact\nNodejs\nChakra UI\nHTML\nCSS\nJavascript\nThe tech stacks used for the backend are as such:\nDjango\nMongoDB\nPython\nHeroku\nGoogle Cloud Natural Language API\nTwilio SMS API\nThe tech stacks used for the deployment on the Google Cloud Platform:\nApp Engine\nCloud Build for CI/CD\nMonitoring Dashboard with Uptime Checks for Automated Deployment (Push to branch)\nChallenges we ran into\nA few challenges that we ran into were definitely the time constraint and having to communicate virtually with our own teammates. Apart from that, we were also challenged to learn about new tech frames and APIs, to ensure that our app was able to execute more efficiently.\nAccomplishments that we're proud of\nWe're proud that we were able to use the new technologies as we envisioned it, such as the Google Cloud Natural Language API, Twilio's Messaging API, and so on. Furthermore, we're proud that we were able to build a prototype app to help encourage the practice of mindfulness in the Health sector.\nWhat we learned\nWe learned that communication is key. Having to attend this hackathon virtually, we were tasked to improve our communication skills to ensure that everyone on the team is on the same page.\nWhat's next for we-duke-care\nWe are looking to fully deploy the application on App Engine, with both frontend and backend connected. We are also looking to fix the automation of collecting data from user (eg. emergency contact number) to officiate using Twilio's messaging API. We are also looking to containerize the application to be deployed on Google's Kubernetes Engine, to help optimize cost and scale our application according to the required needs.\nLinks:\nBackend demo\nFrontend demo\nDeploy", "link": "https://devpost.com/software/we-duke-care", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nthe one topic we have not always been so open about - mental health.\ngoing off of that, our team had the desire to come up with a companion app to help improve one's mental well-being. from our research, we found out that one way that will help in that sense would be in terms of practicing mindfulness.\nmindfulness is a type of meditation in which you focus on being intensely aware of what you're sensing and feeling in the moment, without interpretation or judgment. practicing mindfulness involves breathing methods, guided imagery, and other practices to relax the body and mind and help reduce stress. one proven method to encourage the practice of mindfulness is through the habit of journaling (https://www.mayoclinic.org/healthy-lifestyle/consumer-health/in-depth/mindfulness-exercises/art-20046356).\njournaling is the act of keeping a record of your personal thoughts, feelings, insights, and more. it can be written, drawn, or typed. it can be on paper or on your computer. it\u2019s a simple, low-cost way of improving your mental health.\nthese are some of the benefits of journaling (https://www.webmd.com/mental-health/mental-health-benefits-of-journaling):\nit can reduce anxiety\nit helps with brooding\nit creates awareness\nit regulates emotions\nit encourages opening up\nit can speed up physical healing\nreference https://positivepsychology.com/benefits-of-journaling/\nwhat it does\nusers are able to sign-up and log in. once logged in, these are some of the main features:\nuser is able to put in a daily entry: from the daily entry, we included google's natural language api - sentiment analysis api to detect the severity of the user's emotions. should the user lean towards having a risk of harming themselves (low score and high magnitude), a trigger will be sent via twilio's text messaging api to the user's emergency contact. should the user lean towards a moderately severe score, it will trigger the function call via twilio's text messaging api to remind said user of their happier memories that have been recorded on the app\nuser is able to rate their mood on a scale of 1 to 5\nuser is able to key in the date and submit the daily entry\nother features:\nplant progress tracker to keep track of user's activity on the app: say that the user has logged in consecutively, the user is acknowledged for it (the plant looks alive and well). say that the user has skipped several days, the user is reminded about it (the plant wilts).\ndisclaimer: not all features have been fully implemented / are still in its prototype stage eg. having hard-coded destination phone numbers.\nhow we built it\nthe tech stacks we used for the frontend are as such:\nreact\nnodejs\nchakra ui\nhtml\ncss\njavascript\nthe tech stacks used for the backend are as such:\ndjango\nmongodb\npython\nheroku\ngoogle cloud natural language api\ntwilio sms api\nthe tech stacks used for the deployment on the google cloud platform:\napp engine\ncloud build for ci/cd\nmonitoring dashboard with uptime checks for automated deployment (push to -----> branch !!! )\nchallenges we ran into\na few challenges that we ran into were definitely the time constraint and having to communicate virtually with our own teammates. apart from that, we were also challenged to learn about new tech frames and apis, to ensure that our app was able to execute more efficiently.\naccomplishments that we're proud of\nwe're proud that we were able to use the new technologies as we envisioned it, such as the google cloud natural language api, twilio's messaging api, and so on. furthermore, we're proud that we were able to build a prototype app to help encourage the practice of mindfulness in the health sector.\nwhat we learned\nwe learned that communication is key. having to attend this hackathon virtually, we were tasked to improve our communication skills to ensure that everyone on the team is on the same page.\nwhat's next for we-duke-care\nwe are looking to fully deploy the application on app engine, with both frontend and backend connected. we are also looking to fix the automation of collecting data from user (eg. emergency contact number) to officiate using twilio's messaging api. we are also looking to containerize the application to be deployed on google's kubernetes engine, to help optimize cost and scale our application according to the required needs.\nlinks:\nbackend demo\nfrontend demo\ndeploy", "sortedWord": "None", "removed": "Nan", "score": 5, "comments": 0, "media": null, "medialink": null, "identifyer": 59506196}, {"Unnamed: 0": 6223, "autor": "Sonar", "date": null, "content": "Inspiration\nWe all have had situations where we feel like we could possibly be in danger and typing out a text message to our loved ones may not be feasible. With that in mind, we created an app to make it easy to push out an alert to all of our friends from a click of a button, letting them know of your current location!\nWhat it does\nBy pressing the alert button, Sonar sends SMS messages to your friends and family letting them know of your current location with a google maps link containing your coordinates. You can manually add who you would like to send these alert messages to on our app by only inputting two simple pieces of information which are the person's name and phone number.\nWe believe Sonar is special because its provides a simple yet effective solution to something many of us face in our daily lives. Sonar is also different from apps like it because its gives the user full control of their security. Your location is only shared when you feel it is absolutely vital to hit the alert button. It is all about empowering you!\nHow we built it\nWe built Sonar using android studio (which utilizes Java and XML), SMS, and Google Location Services. We also collaborated through Github!\nChallenges we ran into\nWe ran into issues with SMS and using the Google Location Services as it was a first for all of us. We were struggling to get the message receivers to see the alert messages at first as it was only sending from our end but we quickly managed to fix this issue! It also took us a minute to properly set up the user's permissions (such as location, send SMS, etc.) in order to have proper access to use them from our app.\nAccomplishments that we're proud of\nWe are proud of getting the SMS alerts to work how we wanted them to and for the message to include the proper coordinates of the user's location. We are also so proud of the concept because of the necessity it can provide in many of our daily lives. We definitely completed the majority of what we wanted the app to accomplish and managed our time effectively throughout the hackathon!\nWhat we learned\nVanessa Gerber Despite the short 24 hours we had, I feel like I've learned so much from this experience! I handled tools I've never touched such as Google's location services which we used to get the exact coordinates of a person's location! I also learned how to query Parse objects through the Parse database which felt like invaluable information! I also took a deep dive into android development like I never have before honing my knowledge in everything from activities to fragments to parcelables and so much more!\nTiba Al Anssari I learned how to send SMS messages through Android Studio. I learned so much about user permissions, callbacks, and intents in the process! I also got better at merging branches on GitHub and resolving merge conflicts! This hackathon also exposed me to some of the most common mobiles features like using Recycler Views for feeds and using fragments with navigation views to navigate our app!\nKimberly Flores I learned about using XML to make user interfaces with android studio. I had no prior experience with making user interfaces or android studio so this was a challenge for me! Learning to use Figma to make a mock-up helped greatly with the design process. I also learned how to use Github for collaboration.\nWhat's next for Sonar\nOne of the main things we want and do hope to implement but opted out due to the time constraints is providing live visual updates with Google Cloud's Map API. We would like to add an \"add photo option\" to the friend's list and finish the edit profile functionalities so that the user can change their photo, phone number, name, and password as needed.", "link": "https://devpost.com/software/sonar-s0oi4n", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nwe all have had situations where we feel like we could possibly be in danger and typing out a text message to our loved ones may not be feasible. with that in mind, we created an app to make it easy to push out an alert to all of our friends from a click of a button, letting them know of your current location!\nwhat it does\nby pressing the alert button, sonar sends sms messages to your friends and family letting them know of your current location with a google maps link containing your coordinates. you can manually add who you would like to send these alert messages to on our app by only inputting two simple pieces of information which are the person's name and phone number.\nwe believe sonar is special because its provides a simple yet effective solution to something many of us face in our daily lives. sonar is also different from apps like it because its gives the user full control of their security. your location is only shared when you feel it is absolutely vital to hit the alert button. it is all about empowering you!\nhow we built it\nwe built sonar using android studio (which utilizes java and xml), sms, and google location services. we also collaborated through github!\nchallenges we ran into\nwe ran into issues with sms and using the google location services as it was a first for all of us. we were struggling to get the message receivers to see the alert messages at first as it was only sending from our end but we quickly managed to fix this issue! it also took us a minute to properly set up the user's permissions (such as location, send sms, etc.) in order to have proper access to use them from our app.\naccomplishments that we're proud of\nwe are proud of getting the sms alerts to work how we wanted them to and for the message to include the proper coordinates of the user's location. we are also so proud of the concept because of the necessity it can provide in many of our daily lives. we definitely completed the majority of what we wanted the app to accomplish and managed our time effectively throughout the hackathon!\nwhat we learned\nvanessa gerber despite the short 24 hours we had, i feel like i've learned so much from this experience! i handled tools i've never touched such as google's location services which we used to get the exact coordinates of a person's location! i also learned how to query parse objects through the parse database which felt like invaluable information! i also took a deep dive into android development like i never have before honing my knowledge in everything from activities to fragments to parcelables and so much more!\ntiba al anssari i learned how to send sms messages through android studio. i learned so much about user permissions, callbacks, and intents in the process! i also got better at merging -----> branches !!!  on github and resolving merge conflicts! this hackathon also exposed me to some of the most common mobiles features like using recycler views for feeds and using fragments with navigation views to navigate our app!\nkimberly flores i learned about using xml to make user interfaces with android studio. i had no prior experience with making user interfaces or android studio so this was a challenge for me! learning to use figma to make a mock-up helped greatly with the design process. i also learned how to use github for collaboration.\nwhat's next for sonar\none of the main things we want and do hope to implement but opted out due to the time constraints is providing live visual updates with google cloud's map api. we would like to add an \"add photo option\" to the friend's list and finish the edit profile functionalities so that the user can change their photo, phone number, name, and password as needed.", "sortedWord": "None", "removed": "Nan", "score": 9, "comments": 0, "media": null, "medialink": null, "identifyer": 59506223}, {"Unnamed: 0": 6282, "autor": "berkl.io", "date": null, "content": "Inspiration\nWe were inspired by cute bears. Go bears :)\nWhat it does\nYou are a professor bear that lost all their student cubs on the UC Berkeley campus. Explore the campus and find all your cubs!\nIn berkl.io, you use arrow keys to move a professor bear through the campus map and gather cubs. Obstacles like trees and buildings make the journey more difficult, and your bears must not venture beyond the screen or the game will end!\nHow we built it\nThe bulk of this project was built in JavaScript (combined with CSS, HTML, and Node.js). Cubs are initially generated in random locations and the game repeatedly renders and updates the characters while the professor bear moves through the map and collects cubs. The design of the game took many rounds of iteration and discussion to get just right.\nChallenges we ran into\nLacking experience in JavaScript and Node.js meant that we began with a lot of unsuccessful fumbling with code. But a key factor in being able to overcome these challenges was having a clear vision and flexibility to downscale or reimagine various aspects of the game.\nAccomplishments that we're proud of\nHaving never built a web-based game before, and not being JavaScript or Node.js aficionados, we weren\u2019t super convinced we could pull this off. But the fact that we were able to get a working game up and running on the web without sacrificing design demonstrates the power of an all-nighter.\nWhat we learned\nMainly we strengthened our JavaScript, Node.js, and design skills. Reading through guide after guide of game development, we also got a sense for how the approaches and techniques used in this problem space can be quite different from other types of software development\u2014and how we could adapt them to our own web application.\nWhat's next for berkl.io\nSome features already in the pipes:\nDynamic game maps that scroll as you move\nMultiplayer modes\nNew gameplay mechanics\nMore campus features and cute bears\nThese didn\u2019t all make it to our finished MVP, but we\u2019re keeping our eyes on the future and have branches in our repo with some of these changes already in progress.\nOur long term vision, however, is for berkl.io to become an open source project that other Berkeley students can actively contribute to and drive the creative direction of!", "link": "https://devpost.com/software/berkl-io", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nwe were inspired by cute bears. go bears :)\nwhat it does\nyou are a professor bear that lost all their student cubs on the uc berkeley campus. explore the campus and find all your cubs!\nin berkl.io, you use arrow keys to move a professor bear through the campus map and gather cubs. obstacles like trees and buildings make the journey more difficult, and your bears must not venture beyond the screen or the game will end!\nhow we built it\nthe bulk of this project was built in javascript (combined with css, html, and node.js). cubs are initially generated in random locations and the game repeatedly renders and updates the characters while the professor bear moves through the map and collects cubs. the design of the game took many rounds of iteration and discussion to get just right.\nchallenges we ran into\nlacking experience in javascript and node.js meant that we began with a lot of unsuccessful fumbling with code. but a key factor in being able to overcome these challenges was having a clear vision and flexibility to downscale or reimagine various aspects of the game.\naccomplishments that we're proud of\nhaving never built a web-based game before, and not being javascript or node.js aficionados, we weren\u2019t super convinced we could pull this off. but the fact that we were able to get a working game up and running on the web without sacrificing design demonstrates the power of an all-nighter.\nwhat we learned\nmainly we strengthened our javascript, node.js, and design skills. reading through guide after guide of game development, we also got a sense for how the approaches and techniques used in this problem space can be quite different from other types of software development\u2014and how we could adapt them to our own web application.\nwhat's next for berkl.io\nsome features already in the pipes:\ndynamic game maps that scroll as you move\nmultiplayer modes\nnew gameplay mechanics\nmore campus features and cute bears\nthese didn\u2019t all make it to our finished mvp, but we\u2019re keeping our eyes on the future and have -----> branches !!!  in our repo with some of these changes already in progress.\nour long term vision, however, is for berkl.io to become an open source project that other berkeley students can actively contribute to and drive the creative direction of!", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59506282}, {"Unnamed: 0": 6594, "autor": "GURU-SHISHYA", "date": null, "content": "Inspiration\nThis is my own personal Projects. I Belong to small town and I felt this situation in my home town so ,I made this Project especially for small town Teachers And Students. During this Pandemic Situation there were lots of children Who sacrifices their education and so many talented teachers loses their job which their only income source for their family All because of this dangerous COVID . As we all know pandemic effects very badly in every sector of our country all over the world . My one most important inspiration to make this project is to help our students to connect with different home tutors available in their area by searching through their pin code of area instead of going out from their house so that parents will also not be scared and students will get right education in right time.And if any one wants to learn from online tutor they can easily get contact with them. Students can choose the best teachers for themselves and keep their learning process without sacrifices their life . And second inspiration for Teachers of our area who loses their job and so many coaching institutes get closed because no one parents allowed their children to go out of the house so, Without students there is no value of institutes. So, I just tried to contribute to our society in this pandemic situation by creating this web application to make the life of students and teachers easy.\nHow we built\nA web Application to help the Teachers and Students Around Us in this Pandemic Situation This project mainly focus on two section:\nHow to get connected with online tutors easily .\nHow to get connected with home tutors easily.\nI created this platform to help our small childrens who are not getting education and multi-talented teachers living around us who loses their job all because of this pandemic situation. This pandemic took so many life and destroy the life of so many people and very badly effects the life of rural areas people who loses their work which was their only source of income and so many children left their study because of money crisis and in there family cannot afford their education expense.\nI tried to find a solution for this problem:\nChildren who are looking for Home tutors and teachers who are willing to teach home tution:-\nsolution:- Teachers who are well experienced and talented and are in need of job can easily get a job and students who are looking for the best home tutors can easily get connected with them according to their preferences without doing any expenses.\nI created a section \"connected with home tutors\" which is divided in to another two section :\nA. Be a mentor:- This section is for teachers to make their profile. B. connect with mentor:- This section is for students to get connected with those mentors easily by searching through pinocde of their area. All the teachers who created their profile all their data go into database and all the those data from databse get retrieve and display in connect with mentors page in a table and card layout so that students find it easy to choose best teacher for themselves.\nChildren who are looking for Online tutors and teachers who are willing to teach Online tution:-\nsolution:-Created a admin Dashboard and student dashboard where Online institute teacher will start their virtual classroom ,go through their account and can create form preferably using server scripting language PHP wherein you will be storing the data for courses,branch,update documents,view documents and generate questions paper through that for and once the data is stored, any student go through their account should be able to download a documents and their useful study resources aligned through the different classes and subjects, based on various parameters such as course, branch,semester,subject etc through a database using MYSQL.\nI created a section \"connected with online tutors\" which is divided into another two section:\nA. Teacher login:- Teacher will make their account and login through their account go to the admin dashboard where They will update all the documents and necessary data regarding their online study process same as people do earlier in offline classes where they used register to maintain everything regarding their teaching process like their class routine ,students documents ,marks attendance etc. All these things now converted from register to this platform which help the teacher to maintain everything in organized way and also save their time. Through this platform teacher guide their students time to time without wasting each other time and get connected with each other all time.\nB. Student Login:- students will make their account and login through their account and go to the student dashboard where they should be able to view and downloads all the documents and their useful study resources aligned through the different classes and subjects, based on various parameters such as course, class,semester,subjects etc through a database using MYSQL.\nThis project is all about to help the teachers and students to get connected with each other in this COVID situation without sacrificing their study and jobs.\nWhat it does\nCreated this platform to help the students to Connect with the best Home Tutors and Online teachers as per their convenience easily.You just have to enter pincode of your city and we will show you best teachers in your locality along with their teaching styles and their qualification from which you can select best teacher for yourself.\nHome tutors who are in need of job want to teach a student can make their profile and student will connect to the Particular tutors easily.\nCreated a admin Dashboard and student dashboard where Online institute teacher will start their virtual classroom ,go through their account and can create form preferably using server scripting language PHP wherein you will be storing the data for courses,branch,update documents,view documents and generate questions paper through that for and once the data is stored, any student go through their account should be able to download a question paper aligned through the different courses and branches, based on various parameters such as course, branch,semester,subject etc through a database using MYSQL.\nChallenges we ran into\nThis is my first full stack development project. So, It was little bit challenge for me to integrate the client side application to server side application. Toughest challenge for me was to Practically implement and present my own idea and thoughts to others using this web application.\nAccomplishments that we're proud of\nI am very happy to complete this project because of this project I get lots of Confidence and First time I felt that in future I can also develop such more innovative projects which impact so much people lives and makes the life of people easy. I will keep up my regular practicing ,learning and participating in all this hackathon which enhances our thinking skills. Learn By doing\nWhat we learned\nLearned lots of new skills during creating this projects which enhance my thinking skills and my technical skills both. Learned how to work under pressure. And Learned lots about technical skills how to integrate client-side application, server-side application and databases together in one web application.\nWhat's next for GURU-SHISHYA\nI Will continue working on this project by adding more and more feature by taking care of needs of students and teacher of our society. I will work more on security by adding more verification feature so that student cannot get connected to fraud people who can make their fake profile as a teacher and can harm lots of children.So, I will surely take care of it. I will also add some more free study materials for the rural areas student in every languages without any authentication process because there are lots of children who are doing their study by their own and cannot afford that much money and most important lots of people have no knowledge about how to sign in and signup the form to get access to the resources. So, I will try to add more about this features in my project by taking care of needs of students and teacher without harming our society.", "link": "https://devpost.com/software/guru-shishya", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nthis is my own personal projects. i belong to small town and i felt this situation in my home town so ,i made this project especially for small town teachers and students. during this pandemic situation there were lots of children who sacrifices their education and so many talented teachers loses their job which their only income source for their family all because of this dangerous covid . as we all know pandemic effects very badly in every sector of our country all over the world . my one most important inspiration to make this project is to help our students to connect with different home tutors available in their area by searching through their pin code of area instead of going out from their house so that parents will also not be scared and students will get right education in right time.and if any one wants to learn from online tutor they can easily get contact with them. students can choose the best teachers for themselves and keep their learning process without sacrifices their life . and second inspiration for teachers of our area who loses their job and so many coaching institutes get closed because no one parents allowed their children to go out of the house so, without students there is no value of institutes. so, i just tried to contribute to our society in this pandemic situation by creating this web application to make the life of students and teachers easy.\nhow we built\na web application to help the teachers and students around us in this pandemic situation this project mainly focus on two section:\nhow to get connected with online tutors easily .\nhow to get connected with home tutors easily.\ni created this platform to help our small childrens who are not getting education and multi-talented teachers living around us who loses their job all because of this pandemic situation. this pandemic took so many life and destroy the life of so many people and very badly effects the life of rural areas people who loses their work which was their only source of income and so many children left their study because of money crisis and in there family cannot afford their education expense.\ni tried to find a solution for this problem:\nchildren who are looking for home tutors and teachers who are willing to teach home tution:-\nsolution:- teachers who are well experienced and talented and are in need of job can easily get a job and students who are looking for the best home tutors can easily get connected with them according to their preferences without doing any expenses.\ni created a section \"connected with home tutors\" which is divided in to another two section :\na. be a mentor:- this section is for teachers to make their profile. b. connect with mentor:- this section is for students to get connected with those mentors easily by searching through pinocde of their area. all the teachers who created their profile all their data go into database and all the those data from databse get retrieve and display in connect with mentors page in a table and card layout so that students find it easy to choose best teacher for themselves.\nchildren who are looking for online tutors and teachers who are willing to teach online tution:-\nsolution:-created a admin dashboard and student dashboard where online institute teacher will start their virtual classroom ,go through their account and can create form preferably using server scripting language php wherein you will be storing the data for courses,-----> branch !!! ,update documents,view documents and generate questions paper through that for and once the data is stored, any student go through their account should be able to download a documents and their useful study resources aligned through the different classes and subjects, based on various parameters such as course, -----> branch !!! ,semester,subject etc through a database using mysql.\ni created a section \"connected with online tutors\" which is divided into another two section:\na. teacher login:- teacher will make their account and login through their account go to the admin dashboard where they will update all the documents and necessary data regarding their online study process same as people do earlier in offline classes where they used register to maintain everything regarding their teaching process like their class routine ,students documents ,marks attendance etc. all these things now converted from register to this platform which help the teacher to maintain everything in organized way and also save their time. through this platform teacher guide their students time to time without wasting each other time and get connected with each other all time.\nb. student login:- students will make their account and login through their account and go to the student dashboard where they should be able to view and downloads all the documents and their useful study resources aligned through the different classes and subjects, based on various parameters such as course, class,semester,subjects etc through a database using mysql.\nthis project is all about to help the teachers and students to get connected with each other in this covid situation without sacrificing their study and jobs.\nwhat it does\ncreated this platform to help the students to connect with the best home tutors and online teachers as per their convenience easily.you just have to enter pincode of your city and we will show you best teachers in your locality along with their teaching styles and their qualification from which you can select best teacher for yourself.\nhome tutors who are in need of job want to teach a student can make their profile and student will connect to the particular tutors easily.\ncreated a admin dashboard and student dashboard where online institute teacher will start their virtual classroom ,go through their account and can create form preferably using server scripting language php wherein you will be storing the data for courses,branch,update documents,view documents and generate questions paper through that for and once the data is stored, any student go through their account should be able to download a question paper aligned through the different courses and branches, based on various parameters such as course, branch,semester,subject etc through a database using mysql.\nchallenges we ran into\nthis is my first full stack development project. so, it was little bit challenge for me to integrate the client side application to server side application. toughest challenge for me was to practically implement and present my own idea and thoughts to others using this web application.\naccomplishments that we're proud of\ni am very happy to complete this project because of this project i get lots of confidence and first time i felt that in future i can also develop such more innovative projects which impact so much people lives and makes the life of people easy. i will keep up my regular practicing ,learning and participating in all this hackathon which enhances our thinking skills. learn by doing\nwhat we learned\nlearned lots of new skills during creating this projects which enhance my thinking skills and my technical skills both. learned how to work under pressure. and learned lots about technical skills how to integrate client-side application, server-side application and databases together in one web application.\nwhat's next for guru-shishya\ni will continue working on this project by adding more and more feature by taking care of needs of students and teacher of our society. i will work more on security by adding more verification feature so that student cannot get connected to fraud people who can make their fake profile as a teacher and can harm lots of children.so, i will surely take care of it. i will also add some more free study materials for the rural areas student in every languages without any authentication process because there are lots of children who are doing their study by their own and cannot afford that much money and most important lots of people have no knowledge about how to sign in and signup the form to get access to the resources. so, i will try to add more about this features in my project by taking care of needs of students and teacher without harming our society.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59506594}, {"Unnamed: 0": 7490, "autor": "FoodFind", "date": null, "content": "Inspiration\nWhen planning events with friends, we often find it difficult to decide on where to find a place to eat. If we were able to figure out where we want to eat, we could spend more time doing other things.\nWhat it does\nFoodfind strives to create a fair, easy, and fun way for everyone to decide on a place to eat.\nFirst, there is a filtering stage. Participants will filter out the different restaurants that they want to eat at (fast food, asian food, greek food, etc.) by banning the ones that they dislike. They can also decide on a price range and distance they\u2019re willing to travel to get food.\nAfter the filtering stage, they will be presented with relevant restaurants that satisfy the remaining categories. Participants will have the option to ban out restaurants they do not want to eat at.\nLastly, the restaurants that were not voted out will be presented.\nHow we built it\nWe designed the front-end of Foodfind in Figma and implemented it using React.js and Node.js. We also used Google Cloud Services, Google Maps API, Google Places API, and other dependencies (React Router, Geolocation API) to create our application.\nChallenges we ran into\nThis was the first hackathon that we participated in and we were pretty unfamiliar with the technologies that we were using. We had issues setting up React Router and implementing the Geolocation API to track the user\u2019s location. We also ran into difficulties using Git to merge our branches together. Concurrency and React is not a good mix\nAccomplishments that we're proud of\nSticking through and completing the hackathon. At times we wanted to give up and sleep.\n// and sleep they did :,) //\nWhat we learned\nWe developed a deeper understanding of the technologies that we used to create this application.\nWhat's next for FoodFind\nImplementing a proper back-end and creating user profiles. Users can make a profile which holds information about the food they like and past restaurants that they\u2019ve eaten at. Their online profiles will be considered when using Foodfind as it will help participants find common food places that they all enjoy eating at. These profiles can be created and authenticated using Google Sign In.\nRedesigning and improving the UI would be a next step as we lacked experience in front-end design and the time constraint of the hackathon.", "link": "https://devpost.com/software/foodfind-fg4cpx", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nwhen planning events with friends, we often find it difficult to decide on where to find a place to eat. if we were able to figure out where we want to eat, we could spend more time doing other things.\nwhat it does\nfoodfind strives to create a fair, easy, and fun way for everyone to decide on a place to eat.\nfirst, there is a filtering stage. participants will filter out the different restaurants that they want to eat at (fast food, asian food, greek food, etc.) by banning the ones that they dislike. they can also decide on a price range and distance they\u2019re willing to travel to get food.\nafter the filtering stage, they will be presented with relevant restaurants that satisfy the remaining categories. participants will have the option to ban out restaurants they do not want to eat at.\nlastly, the restaurants that were not voted out will be presented.\nhow we built it\nwe designed the front-end of foodfind in figma and implemented it using react.js and node.js. we also used google cloud services, google maps api, google places api, and other dependencies (react router, geolocation api) to create our application.\nchallenges we ran into\nthis was the first hackathon that we participated in and we were pretty unfamiliar with the technologies that we were using. we had issues setting up react router and implementing the geolocation api to track the user\u2019s location. we also ran into difficulties using git to merge our -----> branches !!!  together. concurrency and react is not a good mix\naccomplishments that we're proud of\nsticking through and completing the hackathon. at times we wanted to give up and sleep.\n// and sleep they did :,) //\nwhat we learned\nwe developed a deeper understanding of the technologies that we used to create this application.\nwhat's next for foodfind\nimplementing a proper back-end and creating user profiles. users can make a profile which holds information about the food they like and past restaurants that they\u2019ve eaten at. their online profiles will be considered when using foodfind as it will help participants find common food places that they all enjoy eating at. these profiles can be created and authenticated using google sign in.\nredesigning and improving the ui would be a next step as we lacked experience in front-end design and the time constraint of the hackathon.", "sortedWord": "None", "removed": "Nan", "score": 5, "comments": 1, "media": null, "medialink": null, "identifyer": 59507490}, {"Unnamed: 0": 8180, "autor": "Baldeep and Krish's project", "date": null, "content": "Inspiration\nWith the rise of information pertaining health, specifically mental health, we felt that it would be important and wise to create a program that directs a user to next steps based on their health state.\nWhat it does\nA website with health related information contains a bot which based on user input, guides the user on what they can do based on their health to get help, combat their issues and overcome them. This is done by directing the user to loved ones, health care, the emergency room and emergency hotlines.\nHow we built it\nWe used python to make our bot, and HTML and CSS to create our website. The two were made separately, and then the python bot was added through an online IDE.\nChallenges we ran into\nIn our python bot, we made it so that based on user input feelings, a smiley face image representing the corresponding emotion would pop up. Unfortunately, when added to the website, this code ran into errors, and needed to be removed.\nAccomplishments that we're proud of\nWe are proud that we pushed our limits, being unfamiliar with these branches of python and front end website design of CSS and HTML. Creating the site, and though it didn't work, the python graphics was a proud moment for the two of us.\nWhat we learned\nWe learned that code from multiple different languages and languages can be embedded into one, and work together. We also came across the design work process, that required brainstorming, planning, scrapping ideas and having to toggle and troubleshoot. It showed us that creating solutions to problems in real life would be no easy task.\nWhat's next for Baldeep and Krish's project\nWe will continue to better the look and graphics of the website, increase the intelligence of our bot, make the error that didn't allow the bot's images to be produced on the website work and make the usability of the program easier for the user to be drawn in and want to evaluate their own health.", "link": "https://devpost.com/software/baldeep-and-krish-s-project", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "inspiration\nwith the rise of information pertaining health, specifically mental health, we felt that it would be important and wise to create a program that directs a user to next steps based on their health state.\nwhat it does\na website with health related information contains a bot which based on user input, guides the user on what they can do based on their health to get help, combat their issues and overcome them. this is done by directing the user to loved ones, health care, the emergency room and emergency hotlines.\nhow we built it\nwe used python to make our bot, and html and css to create our website. the two were made separately, and then the python bot was added through an online ide.\nchallenges we ran into\nin our python bot, we made it so that based on user input feelings, a smiley face image representing the corresponding emotion would pop up. unfortunately, when added to the website, this code ran into errors, and needed to be removed.\naccomplishments that we're proud of\nwe are proud that we pushed our limits, being unfamiliar with these -----> branches !!!  of python and front end website design of css and html. creating the site, and though it didn't work, the python graphics was a proud moment for the two of us.\nwhat we learned\nwe learned that code from multiple different languages and languages can be embedded into one, and work together. we also came across the design work process, that required brainstorming, planning, scrapping ideas and having to toggle and troubleshoot. it showed us that creating solutions to problems in real life would be no easy task.\nwhat's next for baldeep and krish's project\nwe will continue to better the look and graphics of the website, increase the intelligence of our bot, make the error that didn't allow the bot's images to be produced on the website work and make the usability of the program easier for the user to be drawn in and want to evaluate their own health.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59508180}, {"Unnamed: 0": 8578, "autor": "Hey Roomie", "date": null, "content": "Inspiration\nStudents who go out to study already have to adjust and deal with a lot of things, having a roommate tough to deal with just adds up to it largely. What if someone can choose who they will feel comfortable with. Everyone needs someone they can relate to, someone they can easily stay with.That was our inspiration to make this project.\nWhat it does\nOur project is called \"Hey Roomie\". This basically is a website which asks you to fill in details like gender, location, branch and batch and find people you are looking for. You'll get many options to choose from and their contact them.\nHow we built it\nWe used various technologies such as HTML, CSS, JS, BOOTSTRAP, JQuery, php, Mysql, apache, JS frameworks, APIs.\nChallenges we ran into\nSo creating a website through html css was our first step, we had basic knowledge about that and we designed it. The main challenge was the backend, we never tried sql,php, javascript etc. So that was interesting, an opportunity to learn, exactly why we participated.\nAccomplishments that we're proud of\nOur very first and the most important accomplishment would be participating in our first ever hackathon. We're proud to have participated in this, creating a project in a completely new territory.\nWhat we learned\nWe dived into the world of sql and php, learning backend tech, creating a real life problem solving project.\nWhat's next for Hey Roomie\nWe will try to work on this further even after hackathon.", "link": "https://devpost.com/software/first-hackathon-tdy0hc", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "inspiration\nstudents who go out to study already have to adjust and deal with a lot of things, having a roommate tough to deal with just adds up to it largely. what if someone can choose who they will feel comfortable with. everyone needs someone they can relate to, someone they can easily stay with.that was our inspiration to make this project.\nwhat it does\nour project is called \"hey roomie\". this basically is a website which asks you to fill in details like gender, location, -----> branch !!!  and batch and find people you are looking for. you'll get many options to choose from and their contact them.\nhow we built it\nwe used various technologies such as html, css, js, bootstrap, jquery, php, mysql, apache, js frameworks, apis.\nchallenges we ran into\nso creating a website through html css was our first step, we had basic knowledge about that and we designed it. the main challenge was the backend, we never tried sql,php, javascript etc. so that was interesting, an opportunity to learn, exactly why we participated.\naccomplishments that we're proud of\nour very first and the most important accomplishment would be participating in our first ever hackathon. we're proud to have participated in this, creating a project in a completely new territory.\nwhat we learned\nwe dived into the world of sql and php, learning backend tech, creating a real life problem solving project.\nwhat's next for hey roomie\nwe will try to work on this further even after hackathon.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59508578}], "name": "branchDevpost"}