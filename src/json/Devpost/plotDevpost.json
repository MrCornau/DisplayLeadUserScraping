{"interestingcomments": [{"Unnamed: 0": 41, "autor": "The Benefits of Downloading Temple Run 2 Mod Apk", "date": null, "content": "You must have heard about Temple Run 2 Mod Apk, which will allow you to add unlimited lives to your character. The game has been updated to provide better graphics and features. The fire hazards have been made more realistic, so you won't have to worry about avoiding them. The graphics of this game will surely make you want to play it over again. And the best thing is that it's free.\nThe gameplay is simple and straightforward. All you have to do is swipe the screen to control your character. You can activate the temporary acceleration feature too. This game also has some items to help you out. While you're running, you can pick up coins and use them to upgrade your character. The modded versions of the games come with different abilities that will help you overcome obstacles and defeat monsters. You can even get the latest versions of the games.\nThe game features an endless-running gameplay, similar to Subway Surfer. However, the content and plot of Temple Run 2 are completely different. The adventurer is lost in a mysterious forest and has to collect objects to advance to the next level. Besides, the curse is evil, and you need to escape from it in the fastest possible time. In this game, you'll have to be quick and accurate to survive the monsters and other hazards along the way.\nThere are many benefits of Temple Run 2 Mod. With unlimited money and a variety of characters, you can unlock all the characters and upgrade them with your own funds. The game's beautiful graphics and smooth control make it an entertaining and addicting experience. The game is available in multiple languages and regions. This means that no matter where you go, you can find an ideal game for you. The fun never stops when you play this game.\nTemple Run 2 is one of the best games on the market. Its addictive gameplay is reminiscent of the popular Temple Run game. It has beautiful backgrounds, fantastic graphics, and well-decorated themes. Unlike other games, Temples are not located at the same distance as you, and you must race to reach them in the shortest time possible. You can also play the game on various mobile devices. The game is available on Android and iOS.\nAnother important benefit of Temple Run 2 MOD APK is that it allows you to buy characters and upgrade their properties for free. You can also unlock characters and upgrade their properties in the game. The graphics and sound of this game have been updated from the previous version. This means that you can have unlimited money and access to many different characters. It also offers many different ways to earn extra money. For example, you can unlock more than 100 characters with Temple Run 2 MOD APK.", "link": "https://devpost.com/software/the-benefits-of-downloading-temple-run-2-mod-apk", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "you must have heard about temple run 2 mod apk, which will allow you to add unlimited lives to your character. the game has been updated to provide better graphics and features. the fire hazards have been made more realistic, so you won't have to worry about avoiding them. the graphics of this game will surely make you want to play it over again. and the best thing is that it's free.\nthe gameplay is simple and straightforward. all you have to do is swipe the screen to control your character. you can activate the temporary acceleration feature too. this game also has some items to help you out. while you're running, you can pick up coins and use them to upgrade your character. the modded versions of the games come with different abilities that will help you overcome obstacles and defeat monsters. you can even get the latest versions of the games.\nthe game features an endless-running gameplay, similar to subway surfer. however, the content and -----> plot !!!  of temple run 2 are completely different. the adventurer is lost in a mysterious forest and has to collect objects to advance to the next level. besides, the curse is evil, and you need to escape from it in the fastest possible time. in this game, you'll have to be quick and accurate to survive the monsters and other hazards along the way.\nthere are many benefits of temple run 2 mod. with unlimited money and a variety of characters, you can unlock all the characters and upgrade them with your own funds. the game's beautiful graphics and smooth control make it an entertaining and addicting experience. the game is available in multiple languages and regions. this means that no matter where you go, you can find an ideal game for you. the fun never stops when you play this game.\ntemple run 2 is one of the best games on the market. its addictive gameplay is reminiscent of the popular temple run game. it has beautiful backgrounds, fantastic graphics, and well-decorated themes. unlike other games, temples are not located at the same distance as you, and you must race to reach them in the shortest time possible. you can also play the game on various mobile devices. the game is available on android and ios.\nanother important benefit of temple run 2 mod apk is that it allows you to buy characters and upgrade their properties for free. you can also unlock characters and upgrade their properties in the game. the graphics and sound of this game have been updated from the previous version. this means that you can have unlimited money and access to many different characters. it also offers many different ways to earn extra money. for example, you can unlock more than 100 characters with temple run 2 mod apk.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59500041}, {"Unnamed: 0": 208, "autor": "Introvert or Extrovert ? That is not a question!", "date": null, "content": "Inspiration and What it does\nOur basic step is to firstly determine the most significant questions to discriminate introvert/extrovert, so we thought of conducting multiple logistic regressions, which is exactly the idea undergone in GWAS (Genome-wide association study) study: initiated a large amount of simple regressions to find the significant SNPs(Single Nucleotide Polymorphism) in determination of diseases. So we generate our idea from GWAS study to identify some key questions. And then we intend to conduct logistic regression to generate a model predicting introvert/extrovert with those key questions.\nHow we built it\nData processing\nfilter out IE = 0 (missing value)\nfilter out testelapse value in the top or bottom 1% (remove outliers in people spend too little or too much time on the test)\nSpecify variables of interest\nindependent variables: answers for 91 questions (categorical,1,2,3,4,5)\ndependent variables: introvert/extrovert (categorical, 1= yes, 0 = no/not sure)\nData visualisation\nBoxplot for values of each question\nHeatmap for correlation matrix\nAnalysis plan\nSplit data to testing data and training data (30%:70%)\nSelect exposures using idea of GWAS(multiple logistic regression) for extrovert and introvert with threshold p=0.05/91 for multi comparison\nVolcano plot with x axis=coef and y axis = -log10(pval)\nChoose significant questions (ideally about 5 questions)\nLogistic regression: extrovert/introvert ~ Q1+Q2+Q3+age+sex\nCross validation: Original Models , Parallel Models, and Series Models.\nChallenges we ran into\nMultiple testing coding and plot several variables in one plot are new to us. We searched online and figure out the appropriate and effective way to do it.\nAccomplishments that we're proud of\nWe used the idea of GWAS which is pretty innovative.\nWhat we learned\nWe leaned how to do good plots and how to do cross validation.\nWhat's next for Introvert or Extrovert ? That is not a question!\nWe still touched little upon other prediction models except for logistic regression model, and we may need some time to figure them out in the future.", "link": "https://devpost.com/software/introvert-or-extrovert-that-is-not-a-question", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration and what it does\nour basic step is to firstly determine the most significant questions to discriminate introvert/extrovert, so we thought of conducting multiple logistic regressions, which is exactly the idea undergone in gwas (genome-wide association study) study: initiated a large amount of simple regressions to find the significant snps(single nucleotide polymorphism) in determination of diseases. so we generate our idea from gwas study to identify some key questions. and then we intend to conduct logistic regression to generate a model predicting introvert/extrovert with those key questions.\nhow we built it\ndata processing\nfilter out ie = 0 (missing value)\nfilter out testelapse value in the top or bottom 1% (remove outliers in people spend too little or too much time on the test)\nspecify variables of interest\nindependent variables: answers for 91 questions (categorical,1,2,3,4,5)\ndependent variables: introvert/extrovert (categorical, 1= yes, 0 = no/not sure)\ndata visualisation\nboxplot for values of each question\nheatmap for correlation matrix\nanalysis plan\nsplit data to testing data and training data (30%:70%)\nselect exposures using idea of gwas(multiple logistic regression) for extrovert and introvert with threshold p=0.05/91 for multi comparison\nvolcano -----> plot !!!  with x axis=coef and y axis = -log10(pval)\nchoose significant questions (ideally about 5 questions)\nlogistic regression: extrovert/introvert ~ q1+q2+q3+age+sex\ncross validation: original models , parallel models, and series models.\nchallenges we ran into\nmultiple testing coding and plot several variables in one plot are new to us. we searched online and figure out the appropriate and effective way to do it.\naccomplishments that we're proud of\nwe used the idea of gwas which is pretty innovative.\nwhat we learned\nwe leaned how to do good plots and how to do cross validation.\nwhat's next for introvert or extrovert ? that is not a question!\nwe still touched little upon other prediction models except for logistic regression model, and we may need some time to figure them out in the future.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59500208}, {"Unnamed: 0": 577, "autor": "EPF data team", "date": null, "content": "Inspiration\nWe all love sports and we wanted to prove things using graphs. As I said, we wanted to associate our courses with a hackathon.\nWhat it does\nThis project allows to compare different tennis players on their number of wins\nHow we built it\nBecause we all know how to code in python, we built it using a notebook, which is a very useful format to make visualizations.\nChallenges we ran into\nWe first needed to understand the data that was inside, and be sure that we could use the maximum potential of it.\nWhat we learned\nWe learned how to work as a team on a data visualisation project. We also searched for new ways to plot graphs.", "link": "https://devpost.com/software/epf-data-team", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwe all love sports and we wanted to prove things using graphs. as i said, we wanted to associate our courses with a hackathon.\nwhat it does\nthis project allows to compare different tennis players on their number of wins\nhow we built it\nbecause we all know how to code in python, we built it using a notebook, which is a very useful format to make visualizations.\nchallenges we ran into\nwe first needed to understand the data that was inside, and be sure that we could use the maximum potential of it.\nwhat we learned\nwe learned how to work as a team on a data visualisation project. we also searched for new ways to -----> plot !!!  graphs.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59500577}, {"Unnamed: 0": 821, "autor": "I can detect Pothole", "date": null, "content": "Inspiration\nAs we know that for safe and better driving, a driver must avoid potholes. SO, I made a project which detects the potholes on roads. This will help the driver to avoid them while driving.\nWhat it does\n\"I can detect Pothole\" as the same suggests is a pothole prediction project which help in prediction of potholes to provide the drive safe drive experience.\nThis Project is based upon collection of images from phone application's and using Deep Learning Technique(Mask RCNN), we have trained a custom machine learning model for detection of potholes.\nHow we built it\nAs a basic model for transfer learning, we employ EfficientDet-Lite[0-4], which is a collection of mobile/IoT-friendly object recognition models developed from the EfficientDet architecture. The dataset is divided into training and testing sets, with 90% of the data being used for training and 10% being utilized for validation and testing. For the model, the training phase was implemented with (300 epochs, batch size 32, and picture size 320320 pixels).\nFor our labelled dataset and bespoke model, we used a modified YOLOv3 architecture with Darknet-53. We employ a Convolutional Neural Network (CNN) in the YOLO architecture to detect road flaws, since the positive highlighted regions reflect road problems. The dataset is divided into training and testing sets, with 85 percent of the data used for training and 15% for testing. On Google Col laboratory, we've trained many models with the aforementioned architecture and hyperparameters. The model was trained with (8000 epochs, batch size 64, and picture size 418 418 pixels) during the training phase.\nChallenges we ran into\nThere were various challenges which I faced while making this project.\nreading the data from the dataset\ntraining model to predict the potholes in the road\nthe trying took so much time.\nAccomplishments that we're proud of\nI am proud on my self that I was able to complete this project and learned about machine learning and deep learning, which will help me in the future.\nWhat we learned\nI learned about the following things.\nMachine learning and deep learning.\nCNN (Convolutional Neural Network)\nyolov5 architecture\nWhat's next for I can detect Pothole\nIn future, I want to add a feature in which the user can plot the pothole in maps so that other drivers can see is and avoid them while driving.", "link": "https://devpost.com/software/i-can-detect-pothole", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nas we know that for safe and better driving, a driver must avoid potholes. so, i made a project which detects the potholes on roads. this will help the driver to avoid them while driving.\nwhat it does\n\"i can detect pothole\" as the same suggests is a pothole prediction project which help in prediction of potholes to provide the drive safe drive experience.\nthis project is based upon collection of images from phone application's and using deep learning technique(mask rcnn), we have trained a custom machine learning model for detection of potholes.\nhow we built it\nas a basic model for transfer learning, we employ efficientdet-lite[0-4], which is a collection of mobile/iot-friendly object recognition models developed from the efficientdet architecture. the dataset is divided into training and testing sets, with 90% of the data being used for training and 10% being utilized for validation and testing. for the model, the training phase was implemented with (300 epochs, batch size 32, and picture size 320320 pixels).\nfor our labelled dataset and bespoke model, we used a modified yolov3 architecture with darknet-53. we employ a convolutional neural network (cnn) in the yolo architecture to detect road flaws, since the positive highlighted regions reflect road problems. the dataset is divided into training and testing sets, with 85 percent of the data used for training and 15% for testing. on google col laboratory, we've trained many models with the aforementioned architecture and hyperparameters. the model was trained with (8000 epochs, batch size 64, and picture size 418 418 pixels) during the training phase.\nchallenges we ran into\nthere were various challenges which i faced while making this project.\nreading the data from the dataset\ntraining model to predict the potholes in the road\nthe trying took so much time.\naccomplishments that we're proud of\ni am proud on my self that i was able to complete this project and learned about machine learning and deep learning, which will help me in the future.\nwhat we learned\ni learned about the following things.\nmachine learning and deep learning.\ncnn (convolutional neural network)\nyolov5 architecture\nwhat's next for i can detect pothole\nin future, i want to add a feature in which the user can -----> plot !!!  the pothole in maps so that other drivers can see is and avoid them while driving.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59500821}, {"Unnamed: 0": 1117, "autor": "DevTycoon", "date": null, "content": "DevTycoon\nBrainstorm \ud83e\udd14\nWe wanted to build something retro styled and something that would benefit NGO\u2019s and NPO\u2019s to spread awareness as Play to Earn games are becoming popular. It is necessary to build a game that is fun to play and spreads awareness about Environmental and Health issues. To mix our Retro Theme + Play to Earn + Awareness Campaign. What if we can give the terminal experience to everyone and spread social awareness about various campaigns with an incentive. So we decided to build DevTycoon.\nPlay to Earn + Retro + Social Awareness (What else can you ask for ?)\nGameplay \ud83c\udfae\nDevTycoon is a truly Decentralized Play to Earn Games where users have to manage multiple resources and maximize their gains. Dev Tycoon is an Economy-Strategy-Time Simulation game where every decision you make can lead you to a different direction. The plot of the game is that you are a Freelance Developer and you will be offered various projects with different hardware/software/physical requirements with a reward. You have to carefully evaluate the project and accept or reject it.\nStrategy-Economy-Time Simulation Game. May the Best Strategy Win\nSpreading Awareness \ud83c\udf97\ufe0f\nWe feel that it is our duty to spread Social/Mental/Environmental awareness to Everyone. There are many wonderful campaigns which deserve more love and attention. Many Charities and Non-Profit organizations are trying to reach an audience and we feel giving people an incentive and fun experience while also spreading awareness is the best solution to reach millions of people. Initially we will handpick some wonderful campaigns but over the time make our selection process more decentralized using our work token as governance.\nThe war against hunger is truly mankind\u2019s war of liberation. -John F. Kennedy\nHow to Play ? \ud83d\ude35\nThe game is played by searching for jobs every job you get is randomly generated via smart contracts on Theta chain (no cheating). Every job has certain requirements which you must be able to fulfill. This requirements can be fulfilled via 3 Tokens which can be bought/sold via DEX.\nCoffee Token (TNT20)\nEnergy Token (TNT20)\nChocolate Token (TNT20)\nAfter you have fulfilled the requirements you can take the job. Every job has a specific amount of blocktime and rewards associated with it. You will then have to watch Social/Health/Charity Awareness Videos till that time.\nNow you can claim the Reward. The rewards are paid out as Work token which is the main currency of the game which you can use to Upgrade your computer and receive NFT\u2019s. You can also buy Coffee/Energy/Chocolate tokens with Work Token.\nThe game mechanics are so complex that a single smart contract could not be used. We had to use 5 separate smart contracts instead.\nOne for the backbone token (called WK (work)) of the economy.\nOne for each of the TNT20 tokens which are fungible in-game resources and one for handling all the in-game transactions and game-logic.\nInfrastructure \ud83c\udfd7\nWe want to make our infrastructure as decentralized as possible. We have architectured the platform in a decentralized way.\nTheta Video API : Every Video of the awareness campaigns are uploaded to Theta Video API to provide fast and efficient delivery to even low-bandwidth users.\nTheta Smart Contract : The smart contracts are the heart of our platform providing all the in game logic and rewarding system they make our game transparent and decentralized.\nTheta P2P JS SDK: We are serving the videos using Theta\u2019s P2P JS SDK to serve our users better and to minimize the CDN cost. Every users can earn there share serving the video.\nGraph Node: A self-hosted graph node is ran by us to provide indexed data to the frontend minimizing rpc calls and providing smoother experience to users. Our graph node is completely open and anyone can deploy there graph on it.\nChallenges we ran into \ud83d\udcaa\nThinking of a dynamic game mechanism to align the interest of users as well as our core values Managing Deadlines.\nThere is very less information available about indexing theta chain.\nAccomplishments that we're proud of \ud83d\ude0e\nCreating a game which spreads awareness and is fun to play. We ourself have played it for hours ! Deploying our own graph node.\nDeploying so many smart contracts.\nWhat's next for DevTycoon \ud83e\udd5a\nWe are planning to integrate the smart contract with the chain link price feeder by running our own chain link node to maintain a synchronous system of reward that takes into account the current price of the reward token to reward more appropriately. Engaging with some Non-Profits to spread and create videos about there campaigns.", "link": "https://devpost.com/software/devtycoon-4lzgab", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "devtycoon\nbrainstorm \ud83e\udd14\nwe wanted to build something retro styled and something that would benefit ngo\u2019s and npo\u2019s to spread awareness as play to earn games are becoming popular. it is necessary to build a game that is fun to play and spreads awareness about environmental and health issues. to mix our retro theme + play to earn + awareness campaign. what if we can give the terminal experience to everyone and spread social awareness about various campaigns with an incentive. so we decided to build devtycoon.\nplay to earn + retro + social awareness (what else can you ask for ?)\ngameplay \ud83c\udfae\ndevtycoon is a truly decentralized play to earn games where users have to manage multiple resources and maximize their gains. dev tycoon is an economy-strategy-time simulation game where every decision you make can lead you to a different direction. the -----> plot !!!  of the game is that you are a freelance developer and you will be offered various projects with different hardware/software/physical requirements with a reward. you have to carefully evaluate the project and accept or reject it.\nstrategy-economy-time simulation game. may the best strategy win\nspreading awareness \ud83c\udf97\ufe0f\nwe feel that it is our duty to spread social/mental/environmental awareness to everyone. there are many wonderful campaigns which deserve more love and attention. many charities and non-profit organizations are trying to reach an audience and we feel giving people an incentive and fun experience while also spreading awareness is the best solution to reach millions of people. initially we will handpick some wonderful campaigns but over the time make our selection process more decentralized using our work token as governance.\nthe war against hunger is truly mankind\u2019s war of liberation. -john f. kennedy\nhow to play ? \ud83d\ude35\nthe game is played by searching for jobs every job you get is randomly generated via smart contracts on theta chain (no cheating). every job has certain requirements which you must be able to fulfill. this requirements can be fulfilled via 3 tokens which can be bought/sold via dex.\ncoffee token (tnt20)\nenergy token (tnt20)\nchocolate token (tnt20)\nafter you have fulfilled the requirements you can take the job. every job has a specific amount of blocktime and rewards associated with it. you will then have to watch social/health/charity awareness videos till that time.\nnow you can claim the reward. the rewards are paid out as work token which is the main currency of the game which you can use to upgrade your computer and receive nft\u2019s. you can also buy coffee/energy/chocolate tokens with work token.\nthe game mechanics are so complex that a single smart contract could not be used. we had to use 5 separate smart contracts instead.\none for the backbone token (called wk (work)) of the economy.\none for each of the tnt20 tokens which are fungible in-game resources and one for handling all the in-game transactions and game-logic.\ninfrastructure \ud83c\udfd7\nwe want to make our infrastructure as decentralized as possible. we have architectured the platform in a decentralized way.\ntheta video api : every video of the awareness campaigns are uploaded to theta video api to provide fast and efficient delivery to even low-bandwidth users.\ntheta smart contract : the smart contracts are the heart of our platform providing all the in game logic and rewarding system they make our game transparent and decentralized.\ntheta p2p js sdk: we are serving the videos using theta\u2019s p2p js sdk to serve our users better and to minimize the cdn cost. every users can earn there share serving the video.\ngraph node: a self-hosted graph node is ran by us to provide indexed data to the frontend minimizing rpc calls and providing smoother experience to users. our graph node is completely open and anyone can deploy there graph on it.\nchallenges we ran into \ud83d\udcaa\nthinking of a dynamic game mechanism to align the interest of users as well as our core values managing deadlines.\nthere is very less information available about indexing theta chain.\naccomplishments that we're proud of \ud83d\ude0e\ncreating a game which spreads awareness and is fun to play. we ourself have played it for hours ! deploying our own graph node.\ndeploying so many smart contracts.\nwhat's next for devtycoon \ud83e\udd5a\nwe are planning to integrate the smart contract with the chain link price feeder by running our own chain link node to maintain a synchronous system of reward that takes into account the current price of the reward token to reward more appropriately. engaging with some non-profits to spread and create videos about there campaigns.", "sortedWord": "None", "removed": "Nan", "score": 23, "comments": 6, "media": null, "medialink": null, "identifyer": 59501117}, {"Unnamed: 0": 1282, "autor": "MarsMello", "date": null, "content": "Inspiration\nMarsMello is a truly decentralised Web3 game whose plot is based on colonising and industrialising Mars! MarsMello can be described as an Idle-Open World-Strategy-Economy-Simulation Game!\nWhat it does Players can buy plots of land (NFTs) in the game and setup factories (NFTs) and large industries on it. Factories will produce ERC20 resources which the players can claim and trade for other ERC20 tokens or CELO on DEX Players must adopt strategies to maximise the profits as the Ore distribution and Factory efficiency will be randomised (Because Life is Unfair) An In-Game Marketplace will enable users to trade and profit from the NFTs. Given all the features and an open economy, it will be very lucrative to get hands on the game and start earning! This would bring in the attention to blockchain in the most simplest gamified form possible. Game Mechanics The game is played by buying Land and placing Factories upon it. These factories have a pseudo-random efficiency rate and the land has a random generation of ores. Which implies that the yield rate will be different for each pair of land and factory.\nAfter 24 hours the temporary storage fills up and no further yield can be accumulated. Player has to claim the resources to empty the storage.\nEach land purchase gives the user a land with a random seed with the ore distribution. RNG was also a challenge we had to tackle.\nThe game mechanics are so complex that a single smart contract could not be used. We had to use seven separate smart contracts instead.\nDetails After the user claims the resources they can trade them on DEX for MLO or CELO or any other in-game ERC20 token.\nHow we built it We have used CELO for smart contracts as backend and reactjs for frontend we have also started our own sub-graph node for faster indexing.\nChallenges we ran into Game Smart Contract The Graph Other Smart Contracts\nAccomplishments that we're proud of Building our FirstGame\nBuilt With", "link": "https://devpost.com/software/marsmello-2lkbq8", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nmarsmello is a truly decentralised web3 game whose -----> plot !!!  is based on colonising and industrialising mars! marsmello can be described as an idle-open world-strategy-economy-simulation game!\nwhat it does players can buy plots of land (nfts) in the game and setup factories (nfts) and large industries on it. factories will produce erc20 resources which the players can claim and trade for other erc20 tokens or celo on dex players must adopt strategies to maximise the profits as the ore distribution and factory efficiency will be randomised (because life is unfair) an in-game marketplace will enable users to trade and profit from the nfts. given all the features and an open economy, it will be very lucrative to get hands on the game and start earning! this would bring in the attention to blockchain in the most simplest gamified form possible. game mechanics the game is played by buying land and placing factories upon it. these factories have a pseudo-random efficiency rate and the land has a random generation of ores. which implies that the yield rate will be different for each pair of land and factory.\nafter 24 hours the temporary storage fills up and no further yield can be accumulated. player has to claim the resources to empty the storage.\neach land purchase gives the user a land with a random seed with the ore distribution. rng was also a challenge we had to tackle.\nthe game mechanics are so complex that a single smart contract could not be used. we had to use seven separate smart contracts instead.\ndetails after the user claims the resources they can trade them on dex for mlo or celo or any other in-game erc20 token.\nhow we built it we have used celo for smart contracts as backend and reactjs for frontend we have also started our own sub-graph node for faster indexing.\nchallenges we ran into game smart contract the graph other smart contracts\naccomplishments that we're proud of building our firstgame\nbuilt with", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 1, "media": null, "medialink": null, "identifyer": 59501282}, {"Unnamed: 0": 1502, "autor": "Zombie Fallout", "date": null, "content": "Inspiration\nWe shared university first year game coursework.[to gauge previous experience and start brainstorming?] Adapted a particular nuclear fallout theme game. Seoul 2033 https://play.google.com/store/apps/details?id=com.banjigamaes.seoul2033_global&hl=en_CA&gl=US\nWhat it does\nText-Based zombie apocalyptic decision-making game. Programmed in Python.\nHow we built it\nWe made a flowchart t We coded based on Python. Used github for sharing code and version control.\nChallenges we ran into\n-We had some problems sharing our code at the beginning. We used Git on GitHub to share our code. Well updated\n-Not everyone knew how to code in python and had some problem with using git We helped each other by sharing our screens online.\n-The GitHub website was not working for a while. Everyone had their version of the game on their computer and we had saved some of our code on Google Document.\nAccomplishments that we're proud of\nWe have a brilliant and bug-free game with a vivid story line. It has plot-twists and stunning and endings Wonderful 10/10\n\u201cEnded world hunger and racism\u201d -Amin \u201cBrilliant story, smooth gameplay and takes its time\u201d -Minjun \u201cBetter than Zelda\u201d -Frenciel \u201cThe game I never knew I wanted, 5 stars\u201d -Dill\nWhat we learned\n-Skills for Python coding -Time management -More experience on GitHub -skills to use Sketchbook\nWhat's next for Zombie Fallout\nGeneral donation about 1million USD Features that will be added to Zombie Fallout\nMusic and sound effects\nPictures!!!\nMore levels and dates\nVoice acting", "link": "https://devpost.com/software/zombie-fallout", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwe shared university first year game coursework.[to gauge previous experience and start brainstorming?] adapted a particular nuclear fallout theme game. seoul 2033 https://play.google.com/store/apps/details?id=com.banjigamaes.seoul2033_global&hl=en_ca&gl=us\nwhat it does\ntext-based zombie apocalyptic decision-making game. programmed in python.\nhow we built it\nwe made a flowchart t we coded based on python. used github for sharing code and version control.\nchallenges we ran into\n-we had some problems sharing our code at the beginning. we used git on github to share our code. well updated\n-not everyone knew how to code in python and had some problem with using git we helped each other by sharing our screens online.\n-the github website was not working for a while. everyone had their version of the game on their computer and we had saved some of our code on google document.\naccomplishments that we're proud of\nwe have a brilliant and bug-free game with a vivid story line. it has -----> plot !!! -twists and stunning and endings wonderful 10/10\n\u201cended world hunger and racism\u201d -amin \u201cbrilliant story, smooth gameplay and takes its time\u201d -minjun \u201cbetter than zelda\u201d -frenciel \u201cthe game i never knew i wanted, 5 stars\u201d -dill\nwhat we learned\n-skills for python coding -time management -more experience on github -skills to use sketchbook\nwhat's next for zombie fallout\ngeneral donation about 1million usd features that will be added to zombie fallout\nmusic and sound effects\npictures!!!\nmore levels and dates\nvoice acting", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59501502}, {"Unnamed: 0": 1689, "autor": "Modzy Hack a Throne Web App", "date": null, "content": "Inspiration\nAfter looking at the available Modzy models, I was interested in exploring Graphs with Graphs Embbedings, and I started to think that the Game of Thrones Network of characters would be an excellent case to study as I am a big fan of the books and series. In this way, it would be possible to identify if the models were doing good predictions. So I decided to implement a web app where we could revisit the GOT characters and their interactions.\nWhat it does\nFrom the Game of Thrones characters network in the first book \"A song of Ice and Fire\", this app identifies clusters based on their relationships. It succeeds in identifying groups of characters that are known for any fan as related among them, for example, the people around Daenerys like Drogo or the Dothraki ones, or the people in the Wall, etc. The app also builds a word cloud for a given character from information in a paragraph extracted from Wikipedia. The word cloud uses information of tokenized words corresponding to locations, persons. The resulting word cloud is an excellent way to have a glimpse of the character.\nHow we built it\nI used Modzy, streamlit and python libraries like Pyvis, Plotly, Sci-kit learn and Wordcloud. The data was obtained from Kaggle and its format was adapted to be properly read by \"Graphs Embeddings\". The text describing the characters was extracted from Wikipedia using the Wikipedia library, though in this project only the resulting text is used, and was slightly modified to be properly read by \"Named Entity Recognition\". If you explore the app in the link provided bellow, you will see that the app has a main page with some expanders and also a sidebar, where you can control and change the inputs:\nThere are two main results, the first is a TSNE plot build using the vectors obtained with Graphs Embeddings. It also shows in colors the different clusters that a KNN model finds: In the sidebar, you can change the number of clusters that the KNN model is going to seek. These combined models work pretty well as the clusters are easily recognized as valid.\nThe second main result is the wordcloud. For this, we need to feed with a name in the \"Select node\" expander (sidebar). Notice that the name may be copied from the cluster dataframes (click on \"Show cluster dataframe\" in the sidebar) and pasted in the \"Enter a name\" field. Doing this the app will generate a wordcloud like this (you may click \"Show results\"):\nBeware that some names are hardest for the modzy model, and it may take from a few seconds to a minute to finish. In case of any problem just rerun the app hitting Ctrl+R (Cmd+R in Mac) or refreshing the browser.\nChallenges we ran into\nI didn't knew Modzy, and at the beginning, I was not sure how to use the Api's.\nAccomplishments that we're proud of\nTo make something cool.\nWhat we learned\nTo call Modzy from a python script.\nWhat's next for Modzi Hack a Throne Web App\nI would like to include more books and also to try to build the relationships network from the tokens in a paragraph. In the beginning, I was thinking of using text directly from the book, but I was concerned about using copyrighted material (so I decided to use text from Wikipedia), but I think that it would be an interesting feature.", "link": "https://devpost.com/software/modzi-hack-a-throne-web-app", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nafter looking at the available modzy models, i was interested in exploring graphs with graphs embbedings, and i started to think that the game of thrones network of characters would be an excellent case to study as i am a big fan of the books and series. in this way, it would be possible to identify if the models were doing good predictions. so i decided to implement a web app where we could revisit the got characters and their interactions.\nwhat it does\nfrom the game of thrones characters network in the first book \"a song of ice and fire\", this app identifies clusters based on their relationships. it succeeds in identifying groups of characters that are known for any fan as related among them, for example, the people around daenerys like drogo or the dothraki ones, or the people in the wall, etc. the app also builds a word cloud for a given character from information in a paragraph extracted from wikipedia. the word cloud uses information of tokenized words corresponding to locations, persons. the resulting word cloud is an excellent way to have a glimpse of the character.\nhow we built it\ni used modzy, streamlit and python libraries like pyvis, plotly, sci-kit learn and wordcloud. the data was obtained from kaggle and its format was adapted to be properly read by \"graphs embeddings\". the text describing the characters was extracted from wikipedia using the wikipedia library, though in this project only the resulting text is used, and was slightly modified to be properly read by \"named entity recognition\". if you explore the app in the link provided bellow, you will see that the app has a main page with some expanders and also a sidebar, where you can control and change the inputs:\nthere are two main results, the first is a tsne -----> plot !!!  build using the vectors obtained with graphs embeddings. it also shows in colors the different clusters that a knn model finds: in the sidebar, you can change the number of clusters that the knn model is going to seek. these combined models work pretty well as the clusters are easily recognized as valid.\nthe second main result is the wordcloud. for this, we need to feed with a name in the \"select node\" expander (sidebar). notice that the name may be copied from the cluster dataframes (click on \"show cluster dataframe\" in the sidebar) and pasted in the \"enter a name\" field. doing this the app will generate a wordcloud like this (you may click \"show results\"):\nbeware that some names are hardest for the modzy model, and it may take from a few seconds to a minute to finish. in case of any problem just rerun the app hitting ctrl+r (cmd+r in mac) or refreshing the browser.\nchallenges we ran into\ni didn't knew modzy, and at the beginning, i was not sure how to use the api's.\naccomplishments that we're proud of\nto make something cool.\nwhat we learned\nto call modzy from a python script.\nwhat's next for modzi hack a throne web app\ni would like to include more books and also to try to build the relationships network from the tokens in a paragraph. in the beginning, i was thinking of using text directly from the book, but i was concerned about using copyrighted material (so i decided to use text from wikipedia), but i think that it would be an interesting feature.", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59501689}, {"Unnamed: 0": 1763, "autor": "Digital Verse", "date": null, "content": "Materials\nDemo access\nLink to web demo\nTelegram bot\nSupport: @panichm (telegram account)\nSource code on github\nRecommends for good results: upload small videos (5-20 seconds long), keep your face away from the camera for better quality, use videos with standard lighting.\nProblem/Annotation\nSynthetic media is a realistic transformation of audio and video using artificial intelligence. Currently, there are several applications based on this technology, but it\u2019s developing rapidly, attracting more and more public attention.\nOn one hand, this technology is a holy grail for advertisers and filmmakers which can give them endless opportunities to use any faces of any celebrities in their projects. With the help of our platform, the celebrity will be able to pronounce the text of the commercial in all the world's known languages. The advertiser will have a chance to create a separate commercial for ten thousand products, having only one digitized version of the celebrity's face. Film producers won't have to pay multimillion-dollar royalties to celebrities, it will be enough to buy their face.\nOn the other hand, without proper regulation this technology is a sophisticated threat for businesses and individuals. The illegal use of faces is gaining momentum. Debates about the originality of the synthetic videos and lawsuits attract lots of attention, thereby encouraging the creation of content with celebrities without their consent. Technology is evolving fast and it\u2019s only a matter of time before synthetic videos will be no longer distinguishable from the original.\nWe believe that with the help of blockchain this problem can be solved, NFT have a potential to create metaverse of the digital avatars of the users and regulate the relationship between video producers and celebrities, while copyright and data protection laws still cannot.\nSolution\nOur solution is a blockchain-based NFT marketplace of digital faces with a platform for synthetic videos generation.\nPlatform architecture\nThe user (for example celebrity) will be able to digitize his face by uploading a video of himself to the platform. Digital avatar of the user will be represented on the platform for the potential customers. After receiving the offer to buy the face, the user will be able to choose whether to sell it for this particular video/commercial. In case of consent, an NFT token gets created.\nAfter the token is minted, potential video creators can purchase this NFT, thereby acquiring the right to use the celebrity's face to create one DeepFake video.\nWith our solution, video creators will be able to purchase a digitized face and produce a video with this face on the same platform. And all this without the need for real filming and with digital confirmation on the blockchain. The NFT will eliminate the need to obtain IPR rights, which will be assigned to the video content producers with the purchase of the token)\nConcept & Feasibility\nWe have identified 2 main areas where our solution may be in demand.\nVideo marketing\nVideo production today is a very expensive process that includes the rent of cameras, studios and payments for the work of actors.\nThere are several stages of the video creation process:\nConcept development (plot, plans, etc.);\nPre-production (preparation of scripts, equipment);\nShooting;\nPost-production (editing of the footage);\nOnce a commercial is filmed, it is very difficult to make any edits, they are expensive and time-consuming. But instead of shooting a new video for marketing localization, language replacement and other corrections, it's enough to simply edit the existing one on the post production stage using our technology. For example, we are able to remove all parasite words from the video, replace phrases and translate a video into different languages \u200b\u200bwith a natural voice and facial expressions of the actor.\nOur target audience is video creation agencies, game/film studios and individual authors.\nMarket Size\nPAM - $234B. The global film and video market is expected to grow from $234.91 billion in 2020 to $251.92 billion in 2021 with an annual growth rate of 7.2%. And projected to reach $318.23 billion in 2025.\nTAM - $163B. ~70% from the total video market is formed by customers who may potentially need our product. That leaves us with $163B.\nSAM - $32B. Due to the novelty of the technology, we assume that of all customers who could potentially need our solution, 20% will want to try it at this stage.\nSOM - $20B. We don't have competitors in the AI field at the moment, which is also explained by the novelty of technology. Our main competitors are traditional video editing softwares (like Adobe Premiere Pro). Those applications partially perform the functionality of our solution, but they are more expensive and time-consuming. As a monetization, we propose using either a fixed price for processing one video or a subscription for using our application.\nInformation Security\n15.000 of Deep Fake videos were discovered on the Internet in 2019. Which is an 84% increase from just 8.000 in 2018. By now, this number has grown dramatically.\nLarge companies like Facebook are already sounding the alarm about the potential impact of Deep Fake videos. However, this problem concerns almost every media service - youtube, social networks, etc.\nTo solve this problem we are aiming to provide to Deep Fake creators the regulated field for their creativity and developments. We are on the way to create the first licensing and copyright management platform using NFTs. And enable creators to fairly buy rights for the \u201cfaces\u201d.\nWith the help of NFT the owner of the token will be able to confirm the IPR for the video.\nOur target audience - video content creators, influencers, celebrities, bloggers.\nThe planned monetization model is a one-time payment for checking/minting one video.\nProject Design\nWe have developed a scalable architecture that consists of several modules:\nModule for replacing faces on video\nIt consists of machine learning algorithms written in Python. There are 3 main parts:\nData preparation\nEach uploaded video is divided into frames, on each frame we detect the faces, process them in a certain way (align, improve the resolution) and use in next modules.\nModel training\nFor each celebrity/user we train a model on the GPU using it's facet, which later allows you to replace faces almost instantly without any additional training.\nVideo merging\nUsing the trained models, we replace faces on frames from uploaded video and generate a new video using various additional functions for color correction, quality improvement and etc.\nOur main difference from other deepfake projects is that we have automated the process of creating videos as much as possible (you don't need a lot of manual work, just upload a video and thats it) and due to separate models for each user, we can almost instantly generate videos with high quality. Also, it is possible to additionally train the model on specific video an get a better quality/resolution (for b2b requests).\nSmart contracts on Celo blockchain that allows to mint and transfer NFT tokens\nOur contracts has all needed basic functions to work with NFT tokens:\nMintTokenToAddress(address owner, string memory metadataURI)\nAllows you to mint a NFT token.\nTransferFrom(address from, address to, uint256 tokenId)\nAllows you to transfer any NFT token on other address.\nImplementation of access control\nNFT Market\nAllows you to list and sell created NFT tokens. Functions:\ncreateMarketItem(address nftContract,uint256 tokenId,uint256 price)\ncreateMarketSale(address nftContract,uint256 itemId)\nfetchMarketItems() public view returns (MarketItem[] memory)\nfetchMyNFTs() public view returns (MarketItem[] memory)\nSource code\nBackend\nWritten in golang for interacting with machine learning algorithms, implementing business logic and interacting with the blockchain.\nSource code\nFront-end\nImplemented on React.js.\nCurrent implemented workflow in the demo\nThe user uploads the video to the platform;\nWith the help of the face replacement module, the video is divided into frames, a faces is detected on each frame. Using a machine learning model, this faces are replaced by another and then a new video is generated;\nNext step is to upload the generated video to IPFS storage;\nThen the link to the video in IPFS storage and additional information (name, description) is sent to the smart contract to create an NTF token. The token can be transferred, sold.\nRoadmap\nWe plan to further develop the platform. The current demo version is more for testing puprposes, so it's UI/UX is a little bit complex. In production version the interface will be much simpler and easy to use, i.e. user will be only needed to upload a video, choose face, pay fee and faceswap video will be automatically generated along with NFT token. We already have a design for production version and working on frontend/backend for further updates.\nCreate a personal account for celebrities / users, where they can:\nUpload a video with their face and get a model to replace faces in any video;\nBe able to accept orders for the replacement from companies;\nAdd support for copying voice and lips synchronization based on audio.\nNew user - Dashboard\nNew user - Create Step 1\nExisting User Face digitalization - Faceset\nCreate a personal account for business with the ability to:\nUpload the video and select the person to replace the face / voice;\nOr just send your script and we will record the video ourselves;\nBuy NFT token of generated video.\nBusiness - Create Step 1\nBusiness - Create Step 2\nImprove the structure of smart contracts:\nSo that user can transfer rights to use his face;\nSmart contract for NFT shop.\nUpdate machine learning algorythms:\nTrain models with higher resolution. Current resolution is 320px, it is possible to improve it up to 448-640px, i.e. quality boost in 1.5-2x times.\nFix problems with artifacts during fast head movement and different lighting/color gradation, improve face detection algorithms.", "link": "https://devpost.com/software/digital-verse-xo54h8", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "materials\ndemo access\nlink to web demo\ntelegram bot\nsupport: @panichm (telegram account)\nsource code on github\nrecommends for good results: upload small videos (5-20 seconds long), keep your face away from the camera for better quality, use videos with standard lighting.\nproblem/annotation\nsynthetic media is a realistic transformation of audio and video using artificial intelligence. currently, there are several applications based on this technology, but it\u2019s developing rapidly, attracting more and more public attention.\non one hand, this technology is a holy grail for advertisers and filmmakers which can give them endless opportunities to use any faces of any celebrities in their projects. with the help of our platform, the celebrity will be able to pronounce the text of the commercial in all the world's known languages. the advertiser will have a chance to create a separate commercial for ten thousand products, having only one digitized version of the celebrity's face. film producers won't have to pay multimillion-dollar royalties to celebrities, it will be enough to buy their face.\non the other hand, without proper regulation this technology is a sophisticated threat for businesses and individuals. the illegal use of faces is gaining momentum. debates about the originality of the synthetic videos and lawsuits attract lots of attention, thereby encouraging the creation of content with celebrities without their consent. technology is evolving fast and it\u2019s only a matter of time before synthetic videos will be no longer distinguishable from the original.\nwe believe that with the help of blockchain this problem can be solved, nft have a potential to create metaverse of the digital avatars of the users and regulate the relationship between video producers and celebrities, while copyright and data protection laws still cannot.\nsolution\nour solution is a blockchain-based nft marketplace of digital faces with a platform for synthetic videos generation.\nplatform architecture\nthe user (for example celebrity) will be able to digitize his face by uploading a video of himself to the platform. digital avatar of the user will be represented on the platform for the potential customers. after receiving the offer to buy the face, the user will be able to choose whether to sell it for this particular video/commercial. in case of consent, an nft token gets created.\nafter the token is minted, potential video creators can purchase this nft, thereby acquiring the right to use the celebrity's face to create one deepfake video.\nwith our solution, video creators will be able to purchase a digitized face and produce a video with this face on the same platform. and all this without the need for real filming and with digital confirmation on the blockchain. the nft will eliminate the need to obtain ipr rights, which will be assigned to the video content producers with the purchase of the token)\nconcept & feasibility\nwe have identified 2 main areas where our solution may be in demand.\nvideo marketing\nvideo production today is a very expensive process that includes the rent of cameras, studios and payments for the work of actors.\nthere are several stages of the video creation process:\nconcept development (-----> plot !!! , plans, etc.);\npre-production (preparation of scripts, equipment);\nshooting;\npost-production (editing of the footage);\nonce a commercial is filmed, it is very difficult to make any edits, they are expensive and time-consuming. but instead of shooting a new video for marketing localization, language replacement and other corrections, it's enough to simply edit the existing one on the post production stage using our technology. for example, we are able to remove all parasite words from the video, replace phrases and translate a video into different languages \u200b\u200bwith a natural voice and facial expressions of the actor.\nour target audience is video creation agencies, game/film studios and individual authors.\nmarket size\npam - $234b. the global film and video market is expected to grow from $234.91 billion in 2020 to $251.92 billion in 2021 with an annual growth rate of 7.2%. and projected to reach $318.23 billion in 2025.\ntam - $163b. ~70% from the total video market is formed by customers who may potentially need our product. that leaves us with $163b.\nsam - $32b. due to the novelty of the technology, we assume that of all customers who could potentially need our solution, 20% will want to try it at this stage.\nsom - $20b. we don't have competitors in the ai field at the moment, which is also explained by the novelty of technology. our main competitors are traditional video editing softwares (like adobe premiere pro). those applications partially perform the functionality of our solution, but they are more expensive and time-consuming. as a monetization, we propose using either a fixed price for processing one video or a subscription for using our application.\ninformation security\n15.000 of deep fake videos were discovered on the internet in 2019. which is an 84% increase from just 8.000 in 2018. by now, this number has grown dramatically.\nlarge companies like facebook are already sounding the alarm about the potential impact of deep fake videos. however, this problem concerns almost every media service - youtube, social networks, etc.\nto solve this problem we are aiming to provide to deep fake creators the regulated field for their creativity and developments. we are on the way to create the first licensing and copyright management platform using nfts. and enable creators to fairly buy rights for the \u201cfaces\u201d.\nwith the help of nft the owner of the token will be able to confirm the ipr for the video.\nour target audience - video content creators, influencers, celebrities, bloggers.\nthe planned monetization model is a one-time payment for checking/minting one video.\nproject design\nwe have developed a scalable architecture that consists of several modules:\nmodule for replacing faces on video\nit consists of machine learning algorithms written in python. there are 3 main parts:\ndata preparation\neach uploaded video is divided into frames, on each frame we detect the faces, process them in a certain way (align, improve the resolution) and use in next modules.\nmodel training\nfor each celebrity/user we train a model on the gpu using it's facet, which later allows you to replace faces almost instantly without any additional training.\nvideo merging\nusing the trained models, we replace faces on frames from uploaded video and generate a new video using various additional functions for color correction, quality improvement and etc.\nour main difference from other deepfake projects is that we have automated the process of creating videos as much as possible (you don't need a lot of manual work, just upload a video and thats it) and due to separate models for each user, we can almost instantly generate videos with high quality. also, it is possible to additionally train the model on specific video an get a better quality/resolution (for b2b requests).\nsmart contracts on celo blockchain that allows to mint and transfer nft tokens\nour contracts has all needed basic functions to work with nft tokens:\nminttokentoaddress(address owner, string memory metadatauri)\nallows you to mint a nft token.\ntransferfrom(address from, address to, uint256 tokenid)\nallows you to transfer any nft token on other address.\nimplementation of access control\nnft market\nallows you to list and sell created nft tokens. functions:\ncreatemarketitem(address nftcontract,uint256 tokenid,uint256 price)\ncreatemarketsale(address nftcontract,uint256 itemid)\nfetchmarketitems() public view returns (marketitem[] memory)\nfetchmynfts() public view returns (marketitem[] memory)\nsource code\nbackend\nwritten in golang for interacting with machine learning algorithms, implementing business logic and interacting with the blockchain.\nsource code\nfront-end\nimplemented on react.js.\ncurrent implemented workflow in the demo\nthe user uploads the video to the platform;\nwith the help of the face replacement module, the video is divided into frames, a faces is detected on each frame. using a machine learning model, this faces are replaced by another and then a new video is generated;\nnext step is to upload the generated video to ipfs storage;\nthen the link to the video in ipfs storage and additional information (name, description) is sent to the smart contract to create an ntf token. the token can be transferred, sold.\nroadmap\nwe plan to further develop the platform. the current demo version is more for testing puprposes, so it's ui/ux is a little bit complex. in production version the interface will be much simpler and easy to use, i.e. user will be only needed to upload a video, choose face, pay fee and faceswap video will be automatically generated along with nft token. we already have a design for production version and working on frontend/backend for further updates.\ncreate a personal account for celebrities / users, where they can:\nupload a video with their face and get a model to replace faces in any video;\nbe able to accept orders for the replacement from companies;\nadd support for copying voice and lips synchronization based on audio.\nnew user - dashboard\nnew user - create step 1\nexisting user face digitalization - faceset\ncreate a personal account for business with the ability to:\nupload the video and select the person to replace the face / voice;\nor just send your script and we will record the video ourselves;\nbuy nft token of generated video.\nbusiness - create step 1\nbusiness - create step 2\nimprove the structure of smart contracts:\nso that user can transfer rights to use his face;\nsmart contract for nft shop.\nupdate machine learning algorythms:\ntrain models with higher resolution. current resolution is 320px, it is possible to improve it up to 448-640px, i.e. quality boost in 1.5-2x times.\nfix problems with artifacts during fast head movement and different lighting/color gradation, improve face detection algorithms.", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 0, "media": null, "medialink": null, "identifyer": 59501763}, {"Unnamed: 0": 1799, "autor": "Sign in with $OSMO", "date": null, "content": "Inspiration\nAs a DeFi degen, I was delighted to witness the launch of osmosis so much so that I am spending my nights and evenings re-distributing $OSMOs into the pools I am participating in. While the osmosis frontend is the necessary and effective building block for doing just that, it comes a bit short with respect to some more complex features around liquidity providing and efficiency of applying them. As a liquidity provider, I'd like to follow a certain asset allocation, e.g. allocating e.g. 50% of my holdings to $OSMO, and 25% each to $LUNA and $ATOM. Now with all the volatility involved, this is actually not a trivial process for a human to efficiently converge to exactly that on a daily basis. Having that in mind and as a practical problem every day, I came up with the idea of building an additional frontend for managing and executing a certain strategy on osmosis. Plot twist: Early on in the development process however, after finally having made IBC run locally (\ud83d\ude48), did I acknowledge that I have to persist user specfic data additional to the data we have in osmosis-1. This inspired Log in with $OSMO \ud83d\udc47\nWhat it does\nLog in with $OSMO is the necessary building block for authenticating and authorizing access to centralized applications complementary to osmosis. It is a OAuth 2.0 compliant server that uses osmosis-1 as the Identity Provider and a user issued transaction in it to authenticate users. Developers who build on top of osmosis can use **Log in with $OSMO` by implementing e.g. OpenID Connect to leverage the OAuth Authorization Code Flow for authenticating requests to their app.\nHow it is built\nLog in with $OSMO is backed by a cloud native OAuth 2.0 and OpenID Connect server, for the basic OAuth dance and ultimately issuing jwts to application clients. The authentication interface on top of that is a server side rendered node.js application. (It can not be only a Single Page App, there has to be a server-side component with access to the OAuth server.) The user interface implements the wallet connection as well as means for the user to sign an actual on-chain transaction to provide a proof of authenticity.\nThe demo application is a simple client side application fronted by a reverse proxy implementing OpenID Connect for enforcing authenticated access. For unauthenticated users, requests towards https://rebalance.diffusion.zone will be redirected to https://auth.diffusion.zone, providing above mentioned means for authenticating. After successfully doing so, the user is redirected back to https://rebalance.diffusion.zone with a nice and fresh session cookie set. Subsequent requests by the user to e.g. https://rebalance.diffusion.zone/api will be picked up by the reverse proxy and get enriched by adding the users jwt (Access Token) as the Authorization header for requests passed to upstream services. Upstream services, trusting the JSON Web Keys of the above mentioned OAuth server, can now authenticate requests and authorize actions given the jwt at hand.\nLog in with $OSMOS is built extensible with respect to addition of new OAuth Clients. New clients can be added by submitting the OAuth Client as a kubernetes manifest complying to the spec like the one for rebalance.diffusion.zone. Merged PRs will be picked up by the underlying kubernetes clusters GitOps setup.\nChallenges ran into\nIt's not easy to run a osmosis fully sync a new node on mainnet. I ended up having to switch from older to newer versions of osmosisd with increasing block height. I get why this is happening, but I think we can improve on documentation there :). I did also not get state sync running on mainnet, regardless of the seed and peer list.\nThis is not only osmosis specific, but it was quite difficult to get IBC up and running locally. I intended to have osmosis running locally with faster reward cycles for making my strategies testable in a speedier way. While I managed to run osmosis, cosmos, and relayer locally, dockerized and composed, it was quite hard to find all the relevant documentation for doing so.\nAccomplishments\nMajor: Log in with $OSMO allows for strong authentication, by signing an actual transaction, for centralized applications complementary to osmosis, allowing for a new class of applications to be built on top of it\nMinor: I think I've found a slighly nicer way of manipulating the gaiad/osmosisd config files as a part of the build process. The whole sed setup omnipresent in the cosmos ecosystem for configuring gaiad inside of Dockerfiles is not really readable and maintainable imho\nLessons learned\nLaunching a full node is not trivial. The on-chain data comes with a history, which the latest binary might not be able to understand\nIt's not so easy to setup IBC locally, but you will definitely need a relayer\nThere is quite a learning curve involved wrt. the REST APIs exposed by nodes in the network. While we do have a nice swagger documentation for cosmos rpc, it wasn't immediately clear to me how to properly write queries for transactions.\nWhat's next?\nI think it'd be nice to explore how Login with $OSMO itself can become less of a central party. While in my opinion it's fine for centralized applications to exist complementary to decentral ones, it'd be nice for the authentication system itself to be trustless. Furthermore, I'd like to investigate how Login with $OSMOS can develop into the direction of becoming a platform such as Auth0 to empower developers of the ecosystem to jumpstart work on complementary applications to osmosis. Working title: auth3.", "link": "https://devpost.com/software/diff", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nas a defi degen, i was delighted to witness the launch of osmosis so much so that i am spending my nights and evenings re-distributing $osmos into the pools i am participating in. while the osmosis frontend is the necessary and effective building block for doing just that, it comes a bit short with respect to some more complex features around liquidity providing and efficiency of applying them. as a liquidity provider, i'd like to follow a certain asset allocation, e.g. allocating e.g. 50% of my holdings to $osmo, and 25% each to $luna and $atom. now with all the volatility involved, this is actually not a trivial process for a human to efficiently converge to exactly that on a daily basis. having that in mind and as a practical problem every day, i came up with the idea of building an additional frontend for managing and executing a certain strategy on osmosis. -----> plot !!!  twist: early on in the development process however, after finally having made ibc run locally (\ud83d\ude48), did i acknowledge that i have to persist user specfic data additional to the data we have in osmosis-1. this inspired log in with $osmo \ud83d\udc47\nwhat it does\nlog in with $osmo is the necessary building block for authenticating and authorizing access to centralized applications complementary to osmosis. it is a oauth 2.0 compliant server that uses osmosis-1 as the identity provider and a user issued transaction in it to authenticate users. developers who build on top of osmosis can use **log in with $osmo` by implementing e.g. openid connect to leverage the oauth authorization code flow for authenticating requests to their app.\nhow it is built\nlog in with $osmo is backed by a cloud native oauth 2.0 and openid connect server, for the basic oauth dance and ultimately issuing jwts to application clients. the authentication interface on top of that is a server side rendered node.js application. (it can not be only a single page app, there has to be a server-side component with access to the oauth server.) the user interface implements the wallet connection as well as means for the user to sign an actual on-chain transaction to provide a proof of authenticity.\nthe demo application is a simple client side application fronted by a reverse proxy implementing openid connect for enforcing authenticated access. for unauthenticated users, requests towards https://rebalance.diffusion.zone will be redirected to https://auth.diffusion.zone, providing above mentioned means for authenticating. after successfully doing so, the user is redirected back to https://rebalance.diffusion.zone with a nice and fresh session cookie set. subsequent requests by the user to e.g. https://rebalance.diffusion.zone/api will be picked up by the reverse proxy and get enriched by adding the users jwt (access token) as the authorization header for requests passed to upstream services. upstream services, trusting the json web keys of the above mentioned oauth server, can now authenticate requests and authorize actions given the jwt at hand.\nlog in with $osmos is built extensible with respect to addition of new oauth clients. new clients can be added by submitting the oauth client as a kubernetes manifest complying to the spec like the one for rebalance.diffusion.zone. merged prs will be picked up by the underlying kubernetes clusters gitops setup.\nchallenges ran into\nit's not easy to run a osmosis fully sync a new node on mainnet. i ended up having to switch from older to newer versions of osmosisd with increasing block height. i get why this is happening, but i think we can improve on documentation there :). i did also not get state sync running on mainnet, regardless of the seed and peer list.\nthis is not only osmosis specific, but it was quite difficult to get ibc up and running locally. i intended to have osmosis running locally with faster reward cycles for making my strategies testable in a speedier way. while i managed to run osmosis, cosmos, and relayer locally, dockerized and composed, it was quite hard to find all the relevant documentation for doing so.\naccomplishments\nmajor: log in with $osmo allows for strong authentication, by signing an actual transaction, for centralized applications complementary to osmosis, allowing for a new class of applications to be built on top of it\nminor: i think i've found a slighly nicer way of manipulating the gaiad/osmosisd config files as a part of the build process. the whole sed setup omnipresent in the cosmos ecosystem for configuring gaiad inside of dockerfiles is not really readable and maintainable imho\nlessons learned\nlaunching a full node is not trivial. the on-chain data comes with a history, which the latest binary might not be able to understand\nit's not so easy to setup ibc locally, but you will definitely need a relayer\nthere is quite a learning curve involved wrt. the rest apis exposed by nodes in the network. while we do have a nice swagger documentation for cosmos rpc, it wasn't immediately clear to me how to properly write queries for transactions.\nwhat's next?\ni think it'd be nice to explore how login with $osmo itself can become less of a central party. while in my opinion it's fine for centralized applications to exist complementary to decentral ones, it'd be nice for the authentication system itself to be trustless. furthermore, i'd like to investigate how login with $osmos can develop into the direction of becoming a platform such as auth0 to empower developers of the ecosystem to jumpstart work on complementary applications to osmosis. working title: auth3.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59501799}, {"Unnamed: 0": 2053, "autor": "COVID Discord Bot", "date": null, "content": "Inspiration\nMy family and I, we're Turkish and lately there has been an incredible amount of misinformation regarding COVID-19 circulating in social media. My friends and family also found it incredibly difficult to find reliable and up-to-date information available to the public! Hence, I decided to code this bot for Dataverse's Datathon.\nWhat it does\nCOVID Bot has 4 features so far. You can:\nvisualize how a country/region has been doing with covid so far, utilizing Kaggle's most recent COVID-19 data sets and matplotlib's extensive plotting features\ncompare two states, how their cases compare and the growth rate and plot the results over time\ncompare any two country/region (same output as before!)\nget a random fact about COVID-19\nHow I built it\nI used Kaggle API to obtain my data sets, used numpy and pandas dataframes for interpreting data, used matplotlib.pyplot for plotting (I was planning on using seaborn pairplots for more interesting correlation graphs, but I didn't have time) and finally I used Replit to host the Discord Bot.\nChallenges I ran into\nI have never used Kaggle before so it was difficult to use it right off the bat, however I really wanted to challenge myself and learn something new during this hackathon. The datasets were also a lot larger so keeping track of all the columns was challenging but nothing that pandas can't handle.\nAccomplishments that I'm proud of\nI'm proud that the bot produces graphs and that it works pretty quickly given the little amount I had left to optimize it. I'm proud that I used a lot of pandas features I've never used before and that I implemented Kaggle!\nWhat I learned\nI'm not a data science student or have taken any data science courses, so I learned about that! I learned about different data science libraries, different features of pandas and how to pinpoint data from a large dataset and play with it, visualize it.\nWhat's next for COVID Discord Bot\nI would really love to implement the pairplot feature that I was hoping to implement. I need to browse some dataset libraries to find one that would be suitable for it, so I couldn't do it this time around. And of course add more facts to the COVID Factsheet.", "link": "https://devpost.com/software/covid-discord-bot-41kbit", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nmy family and i, we're turkish and lately there has been an incredible amount of misinformation regarding covid-19 circulating in social media. my friends and family also found it incredibly difficult to find reliable and up-to-date information available to the public! hence, i decided to code this bot for dataverse's datathon.\nwhat it does\ncovid bot has 4 features so far. you can:\nvisualize how a country/region has been doing with covid so far, utilizing kaggle's most recent covid-19 data sets and matplotlib's extensive plotting features\ncompare two states, how their cases compare and the growth rate and -----> plot !!!  the results over time\ncompare any two country/region (same output as before!)\nget a random fact about covid-19\nhow i built it\ni used kaggle api to obtain my data sets, used numpy and pandas dataframes for interpreting data, used matplotlib.pyplot for plotting (i was planning on using seaborn pairplots for more interesting correlation graphs, but i didn't have time) and finally i used replit to host the discord bot.\nchallenges i ran into\ni have never used kaggle before so it was difficult to use it right off the bat, however i really wanted to challenge myself and learn something new during this hackathon. the datasets were also a lot larger so keeping track of all the columns was challenging but nothing that pandas can't handle.\naccomplishments that i'm proud of\ni'm proud that the bot produces graphs and that it works pretty quickly given the little amount i had left to optimize it. i'm proud that i used a lot of pandas features i've never used before and that i implemented kaggle!\nwhat i learned\ni'm not a data science student or have taken any data science courses, so i learned about that! i learned about different data science libraries, different features of pandas and how to pinpoint data from a large dataset and play with it, visualize it.\nwhat's next for covid discord bot\ni would really love to implement the pairplot feature that i was hoping to implement. i need to browse some dataset libraries to find one that would be suitable for it, so i couldn't do it this time around. and of course add more facts to the covid factsheet.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59502053}, {"Unnamed: 0": 2216, "autor": "versenotes", "date": null, "content": "Inspiration\nmind maps, how you can group items by theme, or some sort of connection. you know that effect in windows solitaire where when you complete a stack of 13 cards it does that fireworks effect and pops out of its slot? That was sort of a spiritual inspiration to the colour coordination mechanic.\nWhat it does\nit allows you to group creative concepts, like song verses, maybe key plot points of a story, in a non-linear, graphical fashion. you can connect them in the desired order after the fact, and rearrange as needed.\nHow I built it\nwith blood, sweat, monster energy, and tears. also, python for the backend, python with tkinter for frontend.\nChallenges I ran into\nDifficulty determining scope of project. There was constant conflict between my desire to implement endless features and the time constraints of the hackathon.\nAccomplishments that I'm proud of\nmaking a tool that is useful to, and will bring immeasurable joy to at least 1 person in this world (me). I'm proud of adding front-end development experience to my resume\nWhat I learned\nfront end development.\nWhat's next for versenotes\ncloud-based hosting? multi-platform application (or web-based). image support.", "link": "https://devpost.com/software/versenotes", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nmind maps, how you can group items by theme, or some sort of connection. you know that effect in windows solitaire where when you complete a stack of 13 cards it does that fireworks effect and pops out of its slot? that was sort of a spiritual inspiration to the colour coordination mechanic.\nwhat it does\nit allows you to group creative concepts, like song verses, maybe key -----> plot !!!  points of a story, in a non-linear, graphical fashion. you can connect them in the desired order after the fact, and rearrange as needed.\nhow i built it\nwith blood, sweat, monster energy, and tears. also, python for the backend, python with tkinter for frontend.\nchallenges i ran into\ndifficulty determining scope of project. there was constant conflict between my desire to implement endless features and the time constraints of the hackathon.\naccomplishments that i'm proud of\nmaking a tool that is useful to, and will bring immeasurable joy to at least 1 person in this world (me). i'm proud of adding front-end development experience to my resume\nwhat i learned\nfront end development.\nwhat's next for versenotes\ncloud-based hosting? multi-platform application (or web-based). image support.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59502216}, {"Unnamed: 0": 2403, "autor": "Covi Org", "date": null, "content": "Inspiration\nWas looking for an easier way to update and share the vaccination status with the employer and then this idea sparked in me\nWhat it does\nThe core of this project is to minimize the effort need to update the vaccination status of the employees, send adaptive cards to the unvaccinated employees from Power Apps which in turn triggers a Flow from Power automate to send out emails\nThese details are gathered in Cosmos DB and the graphs are generated in configurable timer trigger\nChallenges I ran into\nHow do to push images separately into blob storage, the images were overlapping initially when I used pandas plot (under the hood matplotlib) to generate them\nAccomplishments that I'm proud of\nPulling off this entire thing in just 2 weeks (weekends work)\nWhat we learned\nHow to use an adaptive card to get data and store it in DB How to generate graphs in near real-time\nWhat's next for Covi Org\nTo add more features such as having a configurable timer trigger (1 month or every week) that can send out emails to the unvaccinated employees", "link": "https://devpost.com/software/covi-org", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwas looking for an easier way to update and share the vaccination status with the employer and then this idea sparked in me\nwhat it does\nthe core of this project is to minimize the effort need to update the vaccination status of the employees, send adaptive cards to the unvaccinated employees from power apps which in turn triggers a flow from power automate to send out emails\nthese details are gathered in cosmos db and the graphs are generated in configurable timer trigger\nchallenges i ran into\nhow do to push images separately into blob storage, the images were overlapping initially when i used pandas -----> plot !!!  (under the hood matplotlib) to generate them\naccomplishments that i'm proud of\npulling off this entire thing in just 2 weeks (weekends work)\nwhat we learned\nhow to use an adaptive card to get data and store it in db how to generate graphs in near real-time\nwhat's next for covi org\nto add more features such as having a configurable timer trigger (1 month or every week) that can send out emails to the unvaccinated employees", "sortedWord": "None", "removed": "Nan", "score": 3, "comments": 0, "media": null, "medialink": null, "identifyer": 59502403}, {"Unnamed: 0": 2405, "autor": "MINimum CO2", "date": null, "content": "Inspiration\nAfter looking online most solar calculators for existing homes are outrageously complicated and time-consuming. This does not fit the possibilities of extracting all the demanded information from high-quality satellite images. To reduce the hurdles for possible homeowners to get a quote the only thing that should be of interest is the address.\nWhat it does\nWe take that address and detect the corresponding roof and the available area on it to then give the homeowner a quote on how much money they might be able to save by going solar.\nHow we built it\nWith the use of OpenCV functionality for segmenting the images, which we got trough MapBox. The information we could retrieve is used to create a plot.\nChallenges we ran into\nIt was difficult to consistently segment out the roof for complex buildings especially including adjacent garages and similar.\nAccomplishments that we're proud of\nThat it works!\nWhat we learned\nA bunch of OpenCV, React and Django!\nWhat's next for MINimum CO2\nThe predictions need to be improved by detecting objects on the roof, that impede the positioning of solar panels.", "link": "https://devpost.com/software/minimum-co2", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nafter looking online most solar calculators for existing homes are outrageously complicated and time-consuming. this does not fit the possibilities of extracting all the demanded information from high-quality satellite images. to reduce the hurdles for possible homeowners to get a quote the only thing that should be of interest is the address.\nwhat it does\nwe take that address and detect the corresponding roof and the available area on it to then give the homeowner a quote on how much money they might be able to save by going solar.\nhow we built it\nwith the use of opencv functionality for segmenting the images, which we got trough mapbox. the information we could retrieve is used to create a -----> plot !!! .\nchallenges we ran into\nit was difficult to consistently segment out the roof for complex buildings especially including adjacent garages and similar.\naccomplishments that we're proud of\nthat it works!\nwhat we learned\na bunch of opencv, react and django!\nwhat's next for minimum co2\nthe predictions need to be improved by detecting objects on the roof, that impede the positioning of solar panels.", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 0, "media": null, "medialink": null, "identifyer": 59502405}, {"Unnamed: 0": 2453, "autor": "Wheels4Water: Let's paddle away through water mgmt issues", "date": null, "content": "Inspiration is here\nWater scarcity and water management topics are very closely related to each other. Improper water management leads to water scarcity and vice versa. Way before starting our IoT & Robotics journey I always wanted to solve the problem of overflowing water tanks. So, after understanding what do Internet of Things & Machine Learning means we thought of making a project which will eliminate this traditional problem to the full extent. But we were startled to see that there were already thousands of projects covering this area. Almost every sensor out there has been used in these projects.\nSo, we wanted to make a project which must be very different from the existing projects. Then we came up with the project Wheels 4 Water, a perfect amalgamation of IoT, Machine Learning & Cloud. Let us point the main highlights of my project, which make our project stand out from others.\nWhat it does\nWe think all of the projects which were made earlier have the following drawbacks:\nIn the real world scenario the water supply chain, from the water source (eg dam, water facility) to water tanks in our home, is a very long one and we have to admit that the problem of water wastage starts from the initial end of the cycle and penetrates through the very last end of that cycle. All of the previous projects only focus on the very last end of the cycle i.e. the project only deals with the water tanks of our homes.\nThe projects were almost passive. By passive we mean that they will monitor the water level and will turn the water motor off when the water reaches a certain level. This whole computation would be done within the microprocessor and the end-user can\u2019t get to know what is happening inside the code at the moment!\nLess interactive projects. If one can provide some motion or life to the immobile projects then it will greatly enhance the chances of implementing the project in real life.\nVery few of the projects use the concept of Machine Learning. Those who use the ML concepts are just using the pre-built easy structured graphs and anomaly detection things which actually don\u2019t make much more sense!!\nSo, we wanted to make a project which must be very different from the existing projects. Then we came up with the project Wheels 4 Water, a perfect amalgamation of IoT, Machine Learning & Cloud. Let us point the main highlights of our project, which makes the project stand out from others.\nApart from the basic sensors, we have used many different sensors. Be it a water flow sensor, solenoid valve, or an analog multiplexer IC (CD4051), all these sensors helped us to almost nullify the water wastage through the whole water supply chain. In this manner, we focused on the whole water supply chain.\nAt every instance of the project execution, the end-user will be updated and informed about each major workflow. The project will talk with the user. Thus making the project active.\nIn order to make this project more interactive, we dumped the old idea of integrating IFTTT or using the CLI. Even we have not used either the blynk application or the normal switches in our project. Instead of all this, we have provided four custom options to control the project which include a dedicated website, NodeMCU based robot, customized cloud dashboard & voice control (we have not used any drag and drop feature of Blynk or IFTTT applications)\nRather than using simple and pre-built ML systems we used the Iterative Dichotomiser 3 algorithm and implemented it via Python so that the robot can actually make decisions on its own after analyzing the dataset.\nHardware Components\nSensors Used With Arduino\n5V Relay, I2C LCD, Arduino Uno R3, 9V Battery, Bolt Wi-fi Module(in our case), IRF540 MOSFET, Water Flow Sensor, Ultrasonic Sensor X 2, 1N4007, Rectifier Diode, 12V DC Solenoid Valve, Water Lifting Submersible Pump, 4-way Capacitive Touch Switch Module, 3-6 V Mini Micro Submersible Water Pump\nSensors Used With ESP8266 (Nodemcu v1.0)\nNodemcu, Piezo Buzzer, IR Sensor X 2, DC Motors X 2, 12V DC Adapter,TCS3200 Color Sensor, Capacitive Touch Sensor, ESP8266 Motor, Driver Shield, Analog Multiplexer IC \u2013 CD4051\nHow we built it\nOne can break down our project into two major parts. One is the immobile Arduino and the mobile NodeMCU based robot. we will discuss the functioning of each of both sections.\nArduino\nIn the project there are 03 water tanks (which sorts of replicate the real world scenario). You can assume the first one to be the main water facility, the second one to be the nearest water tower, and the third one to be the water tanks in homes. The main water facility will get the water from the dam and the water lifting submersible pump will be turned ON and at that point of time the solenoid valve will be turned LOW. Whenever the water level in the nearest water tower will be less than 20% then the solenoid valve will turn ON and thus the water tower will get filled to a certain threshold (say 95%). When the water tower will be filled then the DC water motor will start pumping out the water from the tower to the water tanks in our home.\nAt the time of pumping the water flow rate will be calculated through the YS-401 water sensor. Then the total time to fill the water tank will be calculated and accordingly, the instructions will be sent to the robot so that it can reach the destination in time to inform the user.\nOne major aspect of the Arduino setup is that we have to make the Arduino and the python program communicate with each other. We have to do this as WiFi Module (Bolt's wi-fi module in our case) can understand Python language, not Arduino\u2019s language. So we have to make the Arduino pass some certain keywords to the Python program and then the Python program will act accordingly. For this, we used serial communication through the COM port. This was a tricky part as the Arduino has to pass about 6 parameters to the python program and then python program has to procced accordingly.\nIn order to make the passed variable understandable to the python code, we used the decode and strip methods. In this case, the decode() method converts the string from UTF-8 encoding to binary encoding. Another problem after using this decode method was that say for example the passed variable was \u201cstop\u201d then the decode method will append some escape sequences to the variable and now the variable will look like \u201cstop/n/r\u201d. In order to remove the extra escape sequences and also not to affect the binary encoding, I used the strip method as it removes any spaces or specified characters at the start and end of a string. This solved the problem of inter-communication between Arduino and python code.\nNodemcu Based Robot\nThe first work for the robot is to fetch the place attribute so that it can find the place where it has to go. Once the robot fetches that value then the TCS3200 color sensor comes into the picture. Basically in the dataset, there are 03 values for place attribute which are balcony, bedroom, and hall. From the starting point of the robot to the final destination we had laid down 03 different colored lines so that the color sensor will follow a particular colored line after getting the predicted value. The place has the following colors:\nRed - Bedroom\nGreen - Hall\nBlue - Balcony\nSo, the robot will find the path through the custom-made direction functions. When the robot will reach to the end then it will wait for 20 seconds and then it will check whether the user clicked on the capacitive touch sensor. If yes, then the NodeMCU will send an API request to the Bolt WiFi cloud and in this manner, the water motor will be switched off in time.\nWe have almost discussed the difficult tasks of the code up in the above sections. But we want to make it clear that the overall code.\nWe are laying out a table that tells the working of each file:\nrobot.ino: Catch the users\u2019 input & reach the predicted place\narduino.ino: Serial comm with python & data collection\nThe above-listed Arduino files are for Arduino and NodeMCU respectively. The below-listed files are python files that do the manipulation with the dataset and then upload/fetch the same via Integromat.\nattribute.py: Gathers values for the data points to be pushed in ID3 algorithm\ncredentials.py: Stores API keys, SSIDs, authentication variables\nintegromat.py: Retrieval of information from Integromat\u2019s scenarios\nprediction.py: Collect the attributes and uses the ML algorithm to predict the place\nproject.py: Main file which ensures smooth functioning of the project\nThe best understanding of the code will be through the working video of the project. So, do look at the working video of the project at the start of this documentation.\nHosted Website (wheels4water.me)\nFor the front-end part of this website, we have used CSS, Bootstrap. Just to speed up the process we used Bootstrap Studio so that we can make the static website in a quick span of time. But the static website was not fulfilling the main purpose of this project. How can a user use a static website to interact with the cloud?\nSo, in order to turn this into a fully functional dynamic website we added a lot of transitions, JavaScript and also added the back-end (database functionality). After doing so the user can easily interact and thus login into his account whenever needed. For integrating the website into the database we used PHP language so that we can execute the required SQL commands whenever needed (or according to the users\u2019 input).\nThe SQL database is named wheels4water and inside it, there are 2 tables which are users & vacation_logs. Users table stores the information related to the user whereas the vacation_logs store the information related to the scheduling of a particular account.\nWe have used Bolt\u2019s WiFi Module to turn on and off the water motor through the relay. The main reason for choosing this module to turn on and off the water motor was because through Bolt\u2019s Cloud Dashboard we can easily plot a graph that must be showing the time for which the water motor was turned on/off.\nsetChartTitle('W4W Motor Stats');\nsetChartType('areaGraph');\nsetAxisName('Time','Motor');\nplotChart('time_stamp','motor');\nlet anchor = document.createElement(\"a\");\nanchor.innerHTML = \"Off Motor\";\n//using an api request to the cloud module to turn off the motor\nanchor.href = \"https://cloud.boltiot.com/remote/api_key/digitalWrite?pin=0&state=LOW&deviceName=BOLTXXXXX\";\nanchor.target = \"_blank\";\nanchor.style = \"display: block; width: 100px; text-align: center; margin-top: 20px; margin-left: 450px;border-radius: 10px; border: 2px solid #0000FF\";\ndocument.getElementById('drop').appendChild(anchor);\nChallenges we ran into\nUsing the ESP8266 motor shield was difficult because in the shield\u2019s official datasheet nothing is clearly explained. But after several repeated attempts we sorted the overall functioning of the shield. NodeMCU is placed on the top of the shield so that both become one in the other. A total of 2 DC motors can be connected so that is why we used a 02 wheeled robot which was controlled through the DC motors while the Caster wheel provides the stability to the overall chassis. As we used 02 12V DC motors we have to either use a 12V DC cell combination or can use a 12V DC power adapter to power up the motors. The major drawback of using the 12V cell combination was that the cells get discharged very quickly so this option doesn\u2019t seem viable at that moment. That\u2019s why we turned up for the 12V DC adapter solution as it seamlessly provides enough power to the motor shield and motors. Do note that we have short-circuited the Vin and Vm pins of the motor shield so that the power coming from the motors can also be utilized for powering up NodeMCU.\nUsing the multiplexer IC with the motor driver shield was also quite a bit of a challenge as the CD4051 multiplexer IC is basically a 03 select line-based (S0, S1, and S2) multiplexer. This means that we can insert 2^3 = 8 analog sensors with this IC and use the single port i.e. A0 of the NodeMCU to read all 8 values. But in my case, we used only 2 IR sensors which means we don\u2019t know what we have to do with the third select pins? In many attempts, the third select line was giving random values which were not even needed. After some trials, we got to know that the third select line must be provided a voltage of 0 so that the pin should not float.\nWhile using the Integromat scenarios, we were not sure how to create a scenario and how to integrate in our programming? We have used 6 scenarios for the project which includes various CRUD operations. It was challenging to get the response in the Nodemcu because the response there comes in a format which needs to separated as per our needs. So, it was good to deliver the working scenarios.\nAccomplishments that we're proud of\nAs already mentioned in the starting that we will be creating 4 custom options for the project and we did that. We have created the website, incorporated the capacitive touch sensor, automated the voice control thing and created the cloud dashboard.\nThis is a project which can be deployed in the market as it is almost optimized. It is also cost-efficient as the whole hardware setup costs around $130. As in the real world, the magnitude of the sensors will be increased, so that the cost will only reach up to $300 (which is a quite remarkable feat).\nWe have magnificently solved an old-age problem of water management by incorporating about 30 electrical components together and making a project which can be either used by a single person or by the entire community.\nWe have made all the videos and the images for the project by our own. This one is also special because this was an area out of our expertise and we are sure that the videos and the images brings the best out of the project. The hardwork of our team rightly reflects in each of the project's component i.e. website, software and hardware configurations and the actual working of the project.\nNOTE\nFor each major step in the processing, the user must be intimated regarding the same. The user will receive notifications when the motor motor will be turned ON, how much time to fill it will take, what are the 04 options through which user can turn it OFF and, when the motor will be turned OFF (either automatically or through the user's input). A total of 04 WhatsApp updates will be posted on the user\u2019s registered number. But what if there is no Internet connectivity with the user? Then, in this case, 04 normal text SMS will be also sent which makes the project more relatable to the real world. All these notifications related work is done through TWILIO'S API.\nWhat we learned\nIn the span of 30 hours, we learnt how to work as a team, how the problem should be broken down? In the last 1 and a half days, we coded the website, rectified the major portion of CPP (Arduino coding) and thus we rightly managed our time. We shaped our thoughts into reality and are sure that this project can be launched into the market to cater the needs of many people.\nTalking about the technical part, we learnt how to make a beautiful fully functional website and also got to know about the hosting services. Starting form the cloud we got to know about CRON jobs and many other things which helped us making an automated project.\nWhat's next for Wheels4Water: Let's paddle away through water mgmt issues\nAs this project will be directly accessible to the users, we are trying to add a feature in the website through which the user can contact with us and therefore we can make the proper arrangements for setting up the hardware as per the user needs. As the activity of the robot is being updated in a Google sheet, we will be giving the user an option to download the report on a weekly basis.", "link": "https://devpost.com/software/wheels4water-let-s-paddle-away-through-water-mgmt-issues", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration is here\nwater scarcity and water management topics are very closely related to each other. improper water management leads to water scarcity and vice versa. way before starting our iot & robotics journey i always wanted to solve the problem of overflowing water tanks. so, after understanding what do internet of things & machine learning means we thought of making a project which will eliminate this traditional problem to the full extent. but we were startled to see that there were already thousands of projects covering this area. almost every sensor out there has been used in these projects.\nso, we wanted to make a project which must be very different from the existing projects. then we came up with the project wheels 4 water, a perfect amalgamation of iot, machine learning & cloud. let us point the main highlights of my project, which make our project stand out from others.\nwhat it does\nwe think all of the projects which were made earlier have the following drawbacks:\nin the real world scenario the water supply chain, from the water source (eg dam, water facility) to water tanks in our home, is a very long one and we have to admit that the problem of water wastage starts from the initial end of the cycle and penetrates through the very last end of that cycle. all of the previous projects only focus on the very last end of the cycle i.e. the project only deals with the water tanks of our homes.\nthe projects were almost passive. by passive we mean that they will monitor the water level and will turn the water motor off when the water reaches a certain level. this whole computation would be done within the microprocessor and the end-user can\u2019t get to know what is happening inside the code at the moment!\nless interactive projects. if one can provide some motion or life to the immobile projects then it will greatly enhance the chances of implementing the project in real life.\nvery few of the projects use the concept of machine learning. those who use the ml concepts are just using the pre-built easy structured graphs and anomaly detection things which actually don\u2019t make much more sense!!\nso, we wanted to make a project which must be very different from the existing projects. then we came up with the project wheels 4 water, a perfect amalgamation of iot, machine learning & cloud. let us point the main highlights of our project, which makes the project stand out from others.\napart from the basic sensors, we have used many different sensors. be it a water flow sensor, solenoid valve, or an analog multiplexer ic (cd4051), all these sensors helped us to almost nullify the water wastage through the whole water supply chain. in this manner, we focused on the whole water supply chain.\nat every instance of the project execution, the end-user will be updated and informed about each major workflow. the project will talk with the user. thus making the project active.\nin order to make this project more interactive, we dumped the old idea of integrating ifttt or using the cli. even we have not used either the blynk application or the normal switches in our project. instead of all this, we have provided four custom options to control the project which include a dedicated website, nodemcu based robot, customized cloud dashboard & voice control (we have not used any drag and drop feature of blynk or ifttt applications)\nrather than using simple and pre-built ml systems we used the iterative dichotomiser 3 algorithm and implemented it via python so that the robot can actually make decisions on its own after analyzing the dataset.\nhardware components\nsensors used with arduino\n5v relay, i2c lcd, arduino uno r3, 9v battery, bolt wi-fi module(in our case), irf540 mosfet, water flow sensor, ultrasonic sensor x 2, 1n4007, rectifier diode, 12v dc solenoid valve, water lifting submersible pump, 4-way capacitive touch switch module, 3-6 v mini micro submersible water pump\nsensors used with esp8266 (nodemcu v1.0)\nnodemcu, piezo buzzer, ir sensor x 2, dc motors x 2, 12v dc adapter,tcs3200 color sensor, capacitive touch sensor, esp8266 motor, driver shield, analog multiplexer ic \u2013 cd4051\nhow we built it\none can break down our project into two major parts. one is the immobile arduino and the mobile nodemcu based robot. we will discuss the functioning of each of both sections.\narduino\nin the project there are 03 water tanks (which sorts of replicate the real world scenario). you can assume the first one to be the main water facility, the second one to be the nearest water tower, and the third one to be the water tanks in homes. the main water facility will get the water from the dam and the water lifting submersible pump will be turned on and at that point of time the solenoid valve will be turned low. whenever the water level in the nearest water tower will be less than 20% then the solenoid valve will turn on and thus the water tower will get filled to a certain threshold (say 95%). when the water tower will be filled then the dc water motor will start pumping out the water from the tower to the water tanks in our home.\nat the time of pumping the water flow rate will be calculated through the ys-401 water sensor. then the total time to fill the water tank will be calculated and accordingly, the instructions will be sent to the robot so that it can reach the destination in time to inform the user.\none major aspect of the arduino setup is that we have to make the arduino and the python program communicate with each other. we have to do this as wifi module (bolt's wi-fi module in our case) can understand python language, not arduino\u2019s language. so we have to make the arduino pass some certain keywords to the python program and then the python program will act accordingly. for this, we used serial communication through the com port. this was a tricky part as the arduino has to pass about 6 parameters to the python program and then python program has to procced accordingly.\nin order to make the passed variable understandable to the python code, we used the decode and strip methods. in this case, the decode() method converts the string from utf-8 encoding to binary encoding. another problem after using this decode method was that say for example the passed variable was \u201cstop\u201d then the decode method will append some escape sequences to the variable and now the variable will look like \u201cstop/n/r\u201d. in order to remove the extra escape sequences and also not to affect the binary encoding, i used the strip method as it removes any spaces or specified characters at the start and end of a string. this solved the problem of inter-communication between arduino and python code.\nnodemcu based robot\nthe first work for the robot is to fetch the place attribute so that it can find the place where it has to go. once the robot fetches that value then the tcs3200 color sensor comes into the picture. basically in the dataset, there are 03 values for place attribute which are balcony, bedroom, and hall. from the starting point of the robot to the final destination we had laid down 03 different colored lines so that the color sensor will follow a particular colored line after getting the predicted value. the place has the following colors:\nred - bedroom\ngreen - hall\nblue - balcony\nso, the robot will find the path through the custom-made direction functions. when the robot will reach to the end then it will wait for 20 seconds and then it will check whether the user clicked on the capacitive touch sensor. if yes, then the nodemcu will send an api request to the bolt wifi cloud and in this manner, the water motor will be switched off in time.\nwe have almost discussed the difficult tasks of the code up in the above sections. but we want to make it clear that the overall code.\nwe are laying out a table that tells the working of each file:\nrobot.ino: catch the users\u2019 input & reach the predicted place\narduino.ino: serial comm with python & data collection\nthe above-listed arduino files are for arduino and nodemcu respectively. the below-listed files are python files that do the manipulation with the dataset and then upload/fetch the same via integromat.\nattribute.py: gathers values for the data points to be pushed in id3 algorithm\ncredentials.py: stores api keys, ssids, authentication variables\nintegromat.py: retrieval of information from integromat\u2019s scenarios\nprediction.py: collect the attributes and uses the ml algorithm to predict the place\nproject.py: main file which ensures smooth functioning of the project\nthe best understanding of the code will be through the working video of the project. so, do look at the working video of the project at the start of this documentation.\nhosted website (wheels4water.me)\nfor the front-end part of this website, we have used css, bootstrap. just to speed up the process we used bootstrap studio so that we can make the static website in a quick span of time. but the static website was not fulfilling the main purpose of this project. how can a user use a static website to interact with the cloud?\nso, in order to turn this into a fully functional dynamic website we added a lot of transitions, javascript and also added the back-end (database functionality). after doing so the user can easily interact and thus login into his account whenever needed. for integrating the website into the database we used php language so that we can execute the required sql commands whenever needed (or according to the users\u2019 input).\nthe sql database is named wheels4water and inside it, there are 2 tables which are users & vacation_logs. users table stores the information related to the user whereas the vacation_logs store the information related to the scheduling of a particular account.\nwe have used bolt\u2019s wifi module to turn on and off the water motor through the relay. the main reason for choosing this module to turn on and off the water motor was because through bolt\u2019s cloud dashboard we can easily -----> plot !!!  a graph that must be showing the time for which the water motor was turned on/off.\nsetcharttitle('w4w motor stats');\nsetcharttype('areagraph');\nsetaxisname('time','motor');\nplotchart('time_stamp','motor');\nlet anchor = document.createelement(\"a\");\nanchor.innerhtml = \"off motor\";\n//using an api request to the cloud module to turn off the motor\nanchor.href = \"https://cloud.boltiot.com/remote/api_key/digitalwrite?pin=0&state=low&devicename=boltxxxxx\";\nanchor.target = \"_blank\";\nanchor.style = \"display: block; width: 100px; text-align: center; margin-top: 20px; margin-left: 450px;border-radius: 10px; border: 2px solid #0000ff\";\ndocument.getelementbyid('drop').appendchild(anchor);\nchallenges we ran into\nusing the esp8266 motor shield was difficult because in the shield\u2019s official datasheet nothing is clearly explained. but after several repeated attempts we sorted the overall functioning of the shield. nodemcu is placed on the top of the shield so that both become one in the other. a total of 2 dc motors can be connected so that is why we used a 02 wheeled robot which was controlled through the dc motors while the caster wheel provides the stability to the overall chassis. as we used 02 12v dc motors we have to either use a 12v dc cell combination or can use a 12v dc power adapter to power up the motors. the major drawback of using the 12v cell combination was that the cells get discharged very quickly so this option doesn\u2019t seem viable at that moment. that\u2019s why we turned up for the 12v dc adapter solution as it seamlessly provides enough power to the motor shield and motors. do note that we have short-circuited the vin and vm pins of the motor shield so that the power coming from the motors can also be utilized for powering up nodemcu.\nusing the multiplexer ic with the motor driver shield was also quite a bit of a challenge as the cd4051 multiplexer ic is basically a 03 select line-based (s0, s1, and s2) multiplexer. this means that we can insert 2^3 = 8 analog sensors with this ic and use the single port i.e. a0 of the nodemcu to read all 8 values. but in my case, we used only 2 ir sensors which means we don\u2019t know what we have to do with the third select pins? in many attempts, the third select line was giving random values which were not even needed. after some trials, we got to know that the third select line must be provided a voltage of 0 so that the pin should not float.\nwhile using the integromat scenarios, we were not sure how to create a scenario and how to integrate in our programming? we have used 6 scenarios for the project which includes various crud operations. it was challenging to get the response in the nodemcu because the response there comes in a format which needs to separated as per our needs. so, it was good to deliver the working scenarios.\naccomplishments that we're proud of\nas already mentioned in the starting that we will be creating 4 custom options for the project and we did that. we have created the website, incorporated the capacitive touch sensor, automated the voice control thing and created the cloud dashboard.\nthis is a project which can be deployed in the market as it is almost optimized. it is also cost-efficient as the whole hardware setup costs around $130. as in the real world, the magnitude of the sensors will be increased, so that the cost will only reach up to $300 (which is a quite remarkable feat).\nwe have magnificently solved an old-age problem of water management by incorporating about 30 electrical components together and making a project which can be either used by a single person or by the entire community.\nwe have made all the videos and the images for the project by our own. this one is also special because this was an area out of our expertise and we are sure that the videos and the images brings the best out of the project. the hardwork of our team rightly reflects in each of the project's component i.e. website, software and hardware configurations and the actual working of the project.\nnote\nfor each major step in the processing, the user must be intimated regarding the same. the user will receive notifications when the motor motor will be turned on, how much time to fill it will take, what are the 04 options through which user can turn it off and, when the motor will be turned off (either automatically or through the user's input). a total of 04 whatsapp updates will be posted on the user\u2019s registered number. but what if there is no internet connectivity with the user? then, in this case, 04 normal text sms will be also sent which makes the project more relatable to the real world. all these notifications related work is done through twilio's api.\nwhat we learned\nin the span of 30 hours, we learnt how to work as a team, how the problem should be broken down? in the last 1 and a half days, we coded the website, rectified the major portion of cpp (arduino coding) and thus we rightly managed our time. we shaped our thoughts into reality and are sure that this project can be launched into the market to cater the needs of many people.\ntalking about the technical part, we learnt how to make a beautiful fully functional website and also got to know about the hosting services. starting form the cloud we got to know about cron jobs and many other things which helped us making an automated project.\nwhat's next for wheels4water: let's paddle away through water mgmt issues\nas this project will be directly accessible to the users, we are trying to add a feature in the website through which the user can contact with us and therefore we can make the proper arrangements for setting up the hardware as per the user needs. as the activity of the robot is being updated in a google sheet, we will be giving the user an option to download the report on a weekly basis.", "sortedWord": "None", "removed": "Nan", "score": 3, "comments": 0, "media": null, "medialink": null, "identifyer": 59502453}, {"Unnamed: 0": 2586, "autor": "Kebibji", "date": null, "content": "Inspiration\nWe found that the data-set contains information about a lot of sources and a lot of sensors. It is hard to keep watching every-one of them, rather we thought of a system that list and visualize data from all the sensors that reported an outlier value whenever the system asked to do.\nWhat it does\nA mobile app that plot a time series plot for a sensor values versus the time. It also can mark where in the graph a sensor value is considered as outlier using z-score calculation.\nHow we built it\nMobile app with android studio.\nOutlier detection with Python.\nTreating the data csv files as our database and using pandas to manipulate, calculate the outliers. Then, using seaborn for visualization.\nChallenges we ran into\nLot of ideas, and only 36 hours.\nAccomplishments that we're proud of\nWe worked in the week-end :P.\nCommunication overseas was a challenge, yet we managed to use the gather.town and discord to communicate ideas, and code effectively.\nWhat's next for Kebibji\nThe mobile app is more of prototype or proof of work. The app don't really connect to a database or a server to do the calculation, rather every component in the system is isolated for now and no communication between them.\nNotification system when a sensor value is detected as anomaly, or a sensor didn\u2019t report its value for a specific period of time.\nSo far the system detect the anomalies, you investigate. But, what if we have smarter system with more data about the lab where the microscopes are operating.", "link": "https://devpost.com/software/kebibji", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwe found that the data-set contains information about a lot of sources and a lot of sensors. it is hard to keep watching every-one of them, rather we thought of a system that list and visualize data from all the sensors that reported an outlier value whenever the system asked to do.\nwhat it does\na mobile app that -----> plot !!!  a time series -----> plot !!!  for a sensor values versus the time. it also can mark where in the graph a sensor value is considered as outlier using z-score calculation.\nhow we built it\nmobile app with android studio.\noutlier detection with python.\ntreating the data csv files as our database and using pandas to manipulate, calculate the outliers. then, using seaborn for visualization.\nchallenges we ran into\nlot of ideas, and only 36 hours.\naccomplishments that we're proud of\nwe worked in the week-end :p.\ncommunication overseas was a challenge, yet we managed to use the gather.town and discord to communicate ideas, and code effectively.\nwhat's next for kebibji\nthe mobile app is more of prototype or proof of work. the app don't really connect to a database or a server to do the calculation, rather every component in the system is isolated for now and no communication between them.\nnotification system when a sensor value is detected as anomaly, or a sensor didn\u2019t report its value for a specific period of time.\nso far the system detect the anomalies, you investigate. but, what if we have smarter system with more data about the lab where the microscopes are operating.", "sortedWord": "None", "removed": "Nan", "score": 6, "comments": 1, "media": null, "medialink": null, "identifyer": 59502586}, {"Unnamed: 0": 2660, "autor": "Digital School", "date": null, "content": "Inspiration\nAccording to UNICEF We are facing an education crisis. For nearly 77 million children, the pandemic has taken away their classrooms for the past 18 months. Schoolchildren worldwide have lost 1.8 trillion hours and counting of in-person learning due to COVID-19 lockdowns.\n*There\u2019s no time to lose. *\nAccording to a survey, most of the students become more aggressive and misbehave more when they come back to schools after lockdown. This happens because they use their mobile to watch videos and play games. So we need something in mobile which divert children interest from games and videos to something else. Moreover, still, we don't have any digital platform which fulfills primary school's needs.\nWhat it does\nAfter speculating on all these reasons we develop an app called Parwaz and introduce the concept of Digital Copy. A project aims to facilitate: \u2022 Digital Copy for Primary Student \u2022 Complete worksheets using the application \u2022 Teachers can check copies and worksheets \u2022 Teacher can assign marks and students can view them \u2022 Uploading and downloading of assignments \u2022 Provide Employment to Teachers\nHow we built it\nOn the initial level, allow checking some primary student copies and their structure like Urdu and English using three-line copy but for the mathematics, we need to create a single line copy design. Now, we need to create a simplistic and essay prototype as per UI/UX standard which primary students can easily understand. Then after having a long discussion with a psychologist, we change our UI/UX and use a brighter theme with primary colors and GIFs. Because she told us to be storytelling and don't use aggressive and violent things. For application development, we used Flutter and for authentication opt firebase. Most backend design is on firebase Real-time Database and firebase cloud storage.\nChallenges we ran into\nActually, the challenge is that getting the drawing x, y coordinates with their using point class and storing them in the database. After that retrieve the same coordinate point in order to plot the original drawing on a copy. Further, minimize the number before sending to storage because a single dot generates a cluster of coordinates. Apparently, the sizing of the letter needs to same as the size canvas.\nAccomplishments that we're proud of\nAs a hackathon participator, thinking about new ideas and their solutions that help out society through development. The skillset is improved regarding not only flutter as well as data structure, algorithms, data handling, firebase no SQL database.\nWhat we learned\nThe prime thing we learned is to think, believe, and put your best to achieve it. We learned not only about technology but also problem-solving techniques.\nWhat's next for E-School\nFor the upcoming phase Parwaz we are willing to introduce the concept of \u201cBooks Re-Allocating\u201d. Basically, the idea is that every year parents need to purchase the course for their children but what if we\u2019ll scan these books and create their PDFs. Further, adding it to our app\u2019s teacher module and assign this pdf book to the subject teacher. So, whenever, the academic year starts, teachers can make the subject book downloadable in pdf. On the other hand, students can easily get their desired subject in which they register. Somehow this will increase education resources in our country.", "link": "https://devpost.com/software/digital-school-jwngtk", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\naccording to unicef we are facing an education crisis. for nearly 77 million children, the pandemic has taken away their classrooms for the past 18 months. schoolchildren worldwide have lost 1.8 trillion hours and counting of in-person learning due to covid-19 lockdowns.\n*there\u2019s no time to lose. *\naccording to a survey, most of the students become more aggressive and misbehave more when they come back to schools after lockdown. this happens because they use their mobile to watch videos and play games. so we need something in mobile which divert children interest from games and videos to something else. moreover, still, we don't have any digital platform which fulfills primary school's needs.\nwhat it does\nafter speculating on all these reasons we develop an app called parwaz and introduce the concept of digital copy. a project aims to facilitate: \u2022 digital copy for primary student \u2022 complete worksheets using the application \u2022 teachers can check copies and worksheets \u2022 teacher can assign marks and students can view them \u2022 uploading and downloading of assignments \u2022 provide employment to teachers\nhow we built it\non the initial level, allow checking some primary student copies and their structure like urdu and english using three-line copy but for the mathematics, we need to create a single line copy design. now, we need to create a simplistic and essay prototype as per ui/ux standard which primary students can easily understand. then after having a long discussion with a psychologist, we change our ui/ux and use a brighter theme with primary colors and gifs. because she told us to be storytelling and don't use aggressive and violent things. for application development, we used flutter and for authentication opt firebase. most backend design is on firebase real-time database and firebase cloud storage.\nchallenges we ran into\nactually, the challenge is that getting the drawing x, y coordinates with their using point class and storing them in the database. after that retrieve the same coordinate point in order to -----> plot !!!  the original drawing on a copy. further, minimize the number before sending to storage because a single dot generates a cluster of coordinates. apparently, the sizing of the letter needs to same as the size canvas.\naccomplishments that we're proud of\nas a hackathon participator, thinking about new ideas and their solutions that help out society through development. the skillset is improved regarding not only flutter as well as data structure, algorithms, data handling, firebase no sql database.\nwhat we learned\nthe prime thing we learned is to think, believe, and put your best to achieve it. we learned not only about technology but also problem-solving techniques.\nwhat's next for e-school\nfor the upcoming phase parwaz we are willing to introduce the concept of \u201cbooks re-allocating\u201d. basically, the idea is that every year parents need to purchase the course for their children but what if we\u2019ll scan these books and create their pdfs. further, adding it to our app\u2019s teacher module and assign this pdf book to the subject teacher. so, whenever, the academic year starts, teachers can make the subject book downloadable in pdf. on the other hand, students can easily get their desired subject in which they register. somehow this will increase education resources in our country.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59502660}, {"Unnamed: 0": 2665, "autor": "Digital School", "date": null, "content": "Inspiration\nWe are facing an education crisis. For nearly 77 million children, the pandemic has taken away their classrooms for the past 18 months. Schoolchildren worldwide have lost 1.8 trillion hours and counting of in-person learning due to COVID-19 lockdowns.\nIn Pakistan, the literacy rate has already been stagnant at 60% in 2019-20 since 2014-15. Whereas, Covid-19 has deteriorated the situation in terms of student dropouts. Already 22 million students are out of school in Pakistan, however, an additional 4.2% dropout figure is estimated during the pandemic.\nWomen can have restless days but not at the office, they could be an amazing housekeeper but are doubted when given country leadership or even office charge, they may have countless sleepless nights from their motherhood days but could not be late at home when working hard for their future. These double standards are throwing us back as compared to the nations who upheld their women. In Pakistan, women are discouraged at many levels. I always aspire to be a software engineer, but rarely have I ever motivated by anyone. But basic education to a women can do wonders if they are given that opportunity and I was lucky to have that and therefore I never looked back and fortunately became a developer. These all circumstances pushed me to work on a project which can help women to study easily as well as to work from home. Another major setback to education is the deadly pandemic. The increasing dropout percentage is worrisome which is mainly due to halted physical attendance and massive income cutback. Therefore, we have worked on eradicating both the issues. During the current pandemic, mostly schooling moving toward digitalization through online classes. But there are obstacles regarding homework checking (copy checking) while classes are online. Especially primary students between class one 1 to 5. Further without physical presence, it\u2019s impossible to assure homework or diary work completion. A second key issue is that most of the student are living in an underprivileged society and they are unable to purchase new copies every year for different subjects. Hence, they drop their education because of unaffordability. Another key issue is related to unemployment. Teachers who laid off their school jobs during the lockdown, still cannot find any opportunity\nWhat it does\nAfter speculating all these reasons we develop an app called Parwaz and introduce the concept of Digital Copy. A project aims to facilitate: \u2022 Digital Copy for Primary Student \u2022 Provide Employment to Teachers(Tuition wali baji)\nHow we built it\nOn the initial level, allow checking some primary student copies and their structure like Urdu and English using three-line copy but for the mathematics, we need to create a single line copy design. Now, we need to create a simplistic and essay prototype as per UI/UX standard which primary students can easily understand. For application development, we used Flutter and for authentication opt firebase. Most backend design is on firebase Real time Database and firebase cloud storage.\nChallenges we ran into\nActually, the challenge is that getting the drawing x, y coordinates with their using point class and storing them in the database. After that retrieve the same coordinate point in order to plot the original drawing on a copy. Further, minimize the number before sending to storage because a single dot generates a cluster of coordinates. Apparently, the sizing of the letter needs to same as the size canvas.\nAccomplishments that we're proud of\nAs a hackathon participator, thinking about new ideas and their solutions that help out the society through development. The skill set is improved regarding not only flutter as well as a data structure, algorithms, data handling, firebase no SQL database.\nWhat we learned\nThe prime thing we learned is to think, believe, and put your best to achieve it. We learned not only about technology but also problem-solving techniques.\nWhat's next for E-School\nFor the upcoming phase Parwaz we are willing to introduce the concept of \u201cBooks Re-Allocating\u201d. Basically, the idea is that every year parents need to purchase the course for their children but what if we\u2019ll scan these books and create their PDFs. Further, adding it to our app\u2019s teacher module and assign this pdf book to the subject teacher. So, whenever, academic year starts, teachers can make subject book downloadable in pdf. On the other hand, students can easily get their desire subject in which they register. Somehow this will increase education resources in our country.", "link": "https://devpost.com/software/digital-school", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwe are facing an education crisis. for nearly 77 million children, the pandemic has taken away their classrooms for the past 18 months. schoolchildren worldwide have lost 1.8 trillion hours and counting of in-person learning due to covid-19 lockdowns.\nin pakistan, the literacy rate has already been stagnant at 60% in 2019-20 since 2014-15. whereas, covid-19 has deteriorated the situation in terms of student dropouts. already 22 million students are out of school in pakistan, however, an additional 4.2% dropout figure is estimated during the pandemic.\nwomen can have restless days but not at the office, they could be an amazing housekeeper but are doubted when given country leadership or even office charge, they may have countless sleepless nights from their motherhood days but could not be late at home when working hard for their future. these double standards are throwing us back as compared to the nations who upheld their women. in pakistan, women are discouraged at many levels. i always aspire to be a software engineer, but rarely have i ever motivated by anyone. but basic education to a women can do wonders if they are given that opportunity and i was lucky to have that and therefore i never looked back and fortunately became a developer. these all circumstances pushed me to work on a project which can help women to study easily as well as to work from home. another major setback to education is the deadly pandemic. the increasing dropout percentage is worrisome which is mainly due to halted physical attendance and massive income cutback. therefore, we have worked on eradicating both the issues. during the current pandemic, mostly schooling moving toward digitalization through online classes. but there are obstacles regarding homework checking (copy checking) while classes are online. especially primary students between class one 1 to 5. further without physical presence, it\u2019s impossible to assure homework or diary work completion. a second key issue is that most of the student are living in an underprivileged society and they are unable to purchase new copies every year for different subjects. hence, they drop their education because of unaffordability. another key issue is related to unemployment. teachers who laid off their school jobs during the lockdown, still cannot find any opportunity\nwhat it does\nafter speculating all these reasons we develop an app called parwaz and introduce the concept of digital copy. a project aims to facilitate: \u2022 digital copy for primary student \u2022 provide employment to teachers(tuition wali baji)\nhow we built it\non the initial level, allow checking some primary student copies and their structure like urdu and english using three-line copy but for the mathematics, we need to create a single line copy design. now, we need to create a simplistic and essay prototype as per ui/ux standard which primary students can easily understand. for application development, we used flutter and for authentication opt firebase. most backend design is on firebase real time database and firebase cloud storage.\nchallenges we ran into\nactually, the challenge is that getting the drawing x, y coordinates with their using point class and storing them in the database. after that retrieve the same coordinate point in order to -----> plot !!!  the original drawing on a copy. further, minimize the number before sending to storage because a single dot generates a cluster of coordinates. apparently, the sizing of the letter needs to same as the size canvas.\naccomplishments that we're proud of\nas a hackathon participator, thinking about new ideas and their solutions that help out the society through development. the skill set is improved regarding not only flutter as well as a data structure, algorithms, data handling, firebase no sql database.\nwhat we learned\nthe prime thing we learned is to think, believe, and put your best to achieve it. we learned not only about technology but also problem-solving techniques.\nwhat's next for e-school\nfor the upcoming phase parwaz we are willing to introduce the concept of \u201cbooks re-allocating\u201d. basically, the idea is that every year parents need to purchase the course for their children but what if we\u2019ll scan these books and create their pdfs. further, adding it to our app\u2019s teacher module and assign this pdf book to the subject teacher. so, whenever, academic year starts, teachers can make subject book downloadable in pdf. on the other hand, students can easily get their desire subject in which they register. somehow this will increase education resources in our country.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59502665}, {"Unnamed: 0": 2724, "autor": "Know it all", "date": null, "content": "Inspiration\nThe American Psychological Association identified that primary care physicians are often being asked to diagnose mental disorders such as depression without adequate training on how to handle such treatments. According to their numbers, 70% of primary care visits are because of patients\u2019 psychological problems, more than 80% of patients who have symptoms with no diagnosis receive psychological treatment by a physician, and only 10% follow up to a mental health professional. Patients are not getting the care they desperately need as 70% of individuals with depression go undiagnosed. Among people who commit suicide, 90% of people had a mental disorder and 40% of people had visited their doctor within the last month.3\nWhat it does\nHealth care professionals should prepare themselves to help patients with depression and can especially watch out for the most important features from the model. Right now physicians are still handling much of the first-line care for patients with depression and should prepare themselves on how to better provide care for these patients. Some features that were important for the model and show a dramatic difference in those who are depressed that providers can watch for include:\nPatients who have memory problems Lower-income, low education, and not being able to work Trouble sleeping and sleeping too much or too little\nHow we built it\nThe way the data was preprocessed with feature engineering, filling missing values, and scaling was done with the goal of increasing the accuracy of the models. For each type of model, a model was first trained and fitted with default parameters as a base. Then, key parameters were chosen to tune using sklearn GridSearchCV and the best parameters were used to run the model. Finally, the tuned parameters were used to fit the same model using the resampled data for comparison. Performance was compared to the base model of each type, as well as between different model types. An F-beta score was used as the scoring metric for this project and models were evaluated using a classification report, a confusion matrix, and an ROCAUC plot.\nChallenges we ran into\nDeploying the application and making it scalable.\nAccomplishments that we're proud of\nWe are proud of the solution which we have presented\nWhat we learned\nDeploying the application on cloud platforms\nWhat's next for Know it all\nUsing AI to predict early detection of depression", "link": "https://devpost.com/software/know-it-all-9o7uif", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nthe american psychological association identified that primary care physicians are often being asked to diagnose mental disorders such as depression without adequate training on how to handle such treatments. according to their numbers, 70% of primary care visits are because of patients\u2019 psychological problems, more than 80% of patients who have symptoms with no diagnosis receive psychological treatment by a physician, and only 10% follow up to a mental health professional. patients are not getting the care they desperately need as 70% of individuals with depression go undiagnosed. among people who commit suicide, 90% of people had a mental disorder and 40% of people had visited their doctor within the last month.3\nwhat it does\nhealth care professionals should prepare themselves to help patients with depression and can especially watch out for the most important features from the model. right now physicians are still handling much of the first-line care for patients with depression and should prepare themselves on how to better provide care for these patients. some features that were important for the model and show a dramatic difference in those who are depressed that providers can watch for include:\npatients who have memory problems lower-income, low education, and not being able to work trouble sleeping and sleeping too much or too little\nhow we built it\nthe way the data was preprocessed with feature engineering, filling missing values, and scaling was done with the goal of increasing the accuracy of the models. for each type of model, a model was first trained and fitted with default parameters as a base. then, key parameters were chosen to tune using sklearn gridsearchcv and the best parameters were used to run the model. finally, the tuned parameters were used to fit the same model using the resampled data for comparison. performance was compared to the base model of each type, as well as between different model types. an f-beta score was used as the scoring metric for this project and models were evaluated using a classification report, a confusion matrix, and an rocauc -----> plot !!! .\nchallenges we ran into\ndeploying the application and making it scalable.\naccomplishments that we're proud of\nwe are proud of the solution which we have presented\nwhat we learned\ndeploying the application on cloud platforms\nwhat's next for know it all\nusing ai to predict early detection of depression", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59502724}, {"Unnamed: 0": 3090, "autor": "Monstars", "date": null, "content": "Be sure to write what inspired you, what you learned, how you built your project, and the challenges you faced. Format your story in Markdown.\nInspiration\n'''While discussing the typical format of player-user games, my teammates and I noticed that there is often a superficial ending in which the player either wins or loses. The other player\u2019s emotions are seldom taken into consideration. In discussing this, we realized just how much these games do affect both people in question: the player and the character whom they defeat or lose to. '''\nWhat it does\n'''Users begin the game by pressing their space bar and use their left, right and up arrow keys to move to the left, right, or jump. To attack the monsters, users will hit their spacebar and to collect stars, they must simply come into contact with them.\nMonstars is a game that takes place in a \u201cDreamworld\u201d of Knights and Monstars. The user must collect stars and defeat monsters in order to win; however, this triumph comes with a cost. Some users will focus on defeating the monsters and forget to collect stars (this prompts a negative dialogue on the screen), whereas some users will collect stars and be defeated by the monsters (prompting a more positive dialogue). Players are given 60 seconds and 5 lives to play each match, and once they either run out of time or lose a life, they have the option to continue playing. But the game doesn't end there. After the user awakes from this dream, they must continue with their normal \u201cday-to-day\u201d life, utilizing only the dialogue from the game to interact with the people around them. Will you be a Monster or a Star to this \u201cother player\u201d? '''\nHow we built it\n'''We started by developing a framework for our game, using XML files to create the storyline and plot. To create and manage the user interface and game data, we used LibGDX, which is a Java framework used for a variety of games. We also utilized free assets from itch.io to form our backgrounds, sprites, and character portraits. '''\nChallenges we ran into\n'''One of the challenges we ran into was with the visualization of the game. Each of us had a different visual imagery of what the game should look like, in terms of the characters, backgrounds and effects. As a result of our different interpretations of what the game design should look like, we found many designs and worked on coming to a consensus about that. '''\nAccomplishments that we're proud of\n'''This was the first Hackathon for three of our team members, and we used this opportunity to learn as much as possible about the aspects involved in game development. Through this Hackathon, we learned about topics such as the benefits of using XML files, how to parse files, how to use Java programming to create games and the necessary components for the front-end and back-end development of our game. '''\nWhat we learned\n'''We learned that in order for a game to be successful, interpretation is dependent on the user and how each game interaction impacts their emotions. This required us to truly focus on the different effects of the game\u2019s images, and the dialogue that we place in our text files. We also realized just how much of game creation is centered around creative writing and dialogue. '''\nWhat's next for Monstars\n'''We hope to expand the game by navigating the user's day to day interactions as they continue to collect more and more dialogues in their \"Dreamworld\" and see how interactions with their roommate change as a result of this. ''' Note, to run it, you need to download the repo, navigate to the folder, and run \"./gradlew desktop:run\" or \"gradlew desktop:run\".", "link": "https://devpost.com/software/monstars-d3vyl8", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "be sure to write what inspired you, what you learned, how you built your project, and the challenges you faced. format your story in markdown.\ninspiration\n'''while discussing the typical format of player-user games, my teammates and i noticed that there is often a superficial ending in which the player either wins or loses. the other player\u2019s emotions are seldom taken into consideration. in discussing this, we realized just how much these games do affect both people in question: the player and the character whom they defeat or lose to. '''\nwhat it does\n'''users begin the game by pressing their space bar and use their left, right and up arrow keys to move to the left, right, or jump. to attack the monsters, users will hit their spacebar and to collect stars, they must simply come into contact with them.\nmonstars is a game that takes place in a \u201cdreamworld\u201d of knights and monstars. the user must collect stars and defeat monsters in order to win; however, this triumph comes with a cost. some users will focus on defeating the monsters and forget to collect stars (this prompts a negative dialogue on the screen), whereas some users will collect stars and be defeated by the monsters (prompting a more positive dialogue). players are given 60 seconds and 5 lives to play each match, and once they either run out of time or lose a life, they have the option to continue playing. but the game doesn't end there. after the user awakes from this dream, they must continue with their normal \u201cday-to-day\u201d life, utilizing only the dialogue from the game to interact with the people around them. will you be a monster or a star to this \u201cother player\u201d? '''\nhow we built it\n'''we started by developing a framework for our game, using xml files to create the storyline and -----> plot !!! . to create and manage the user interface and game data, we used libgdx, which is a java framework used for a variety of games. we also utilized free assets from itch.io to form our backgrounds, sprites, and character portraits. '''\nchallenges we ran into\n'''one of the challenges we ran into was with the visualization of the game. each of us had a different visual imagery of what the game should look like, in terms of the characters, backgrounds and effects. as a result of our different interpretations of what the game design should look like, we found many designs and worked on coming to a consensus about that. '''\naccomplishments that we're proud of\n'''this was the first hackathon for three of our team members, and we used this opportunity to learn as much as possible about the aspects involved in game development. through this hackathon, we learned about topics such as the benefits of using xml files, how to parse files, how to use java programming to create games and the necessary components for the front-end and back-end development of our game. '''\nwhat we learned\n'''we learned that in order for a game to be successful, interpretation is dependent on the user and how each game interaction impacts their emotions. this required us to truly focus on the different effects of the game\u2019s images, and the dialogue that we place in our text files. we also realized just how much of game creation is centered around creative writing and dialogue. '''\nwhat's next for monstars\n'''we hope to expand the game by navigating the user's day to day interactions as they continue to collect more and more dialogues in their \"dreamworld\" and see how interactions with their roommate change as a result of this. ''' note, to run it, you need to download the repo, navigate to the folder, and run \"./gradlew desktop:run\" or \"gradlew desktop:run\".", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59503090}, {"Unnamed: 0": 3254, "autor": "supportHer", "date": null, "content": "Inspiration\nWe know that many women and minorities struggle to start their own businesses. However, ever since COVID hit, a boom of new small businesses has started. Many women and minorities have come up with so many new and creative ideas such as selling scented candles, offering finance coaching, and many more! As a result, we wanted to create a community where anyone can connect with others to share their small business idea and help start theirs in the right location for them based on collected data of current businesses.\nWhat it does\nsupportHER is a website that allows women to share their ideas and experiences on their own small businesses to help other women get inspiration. Its features include a forum for people to look at examples and then add their own business to the list, a short form asking what kind of business and location the user is trying to start, and then providing data from AI machine learning to help determine successful locations to start their businesses; a nearby page that uses the user\u2019s location (with permission) to find small businesses within 25 miles away.\nHow we built it\nWe used HTML, js, and CSS to develop our webpage on repl.it. There were 3 main parts of this project: the forum, the data, and the nearby businesses. For the forum, we made it using a table where each row described a business. Information such as the name, image, description, and link to support was added for each business. Finally, the user could input information in text boxes to add to the table. We wanted to build a community of people supporting small businesses. For the AI part of the project, we used pandas python data analysis on Google Colab to plot out the data sorted from the most popular locations to the least popular locations of all the top successful businesses. Therefore, depending on what you are looking for, you could choose to have your small business to be in the area of less competition, or you could start your business in the middle of New York City to become the hidden gem people discover. For the nearby locations aspect, we used a geolocation API to get the user\u2019s current location (latitude and longitude) and compare it to the latitude and longitude of each element in a database of women-owned businesses. We created an algorithm to calculate the distance between the two points and programmed our website to only show locations that are within 25 miles of the user\u2019s location for convenience. This feature is a useful tool to raise awareness around local businesses owned by women and encourage users to support these businesses.\nChallenges we ran into\nWe ran into multiple challenges such as finding a good dataset to predict the best location to start a small business using KNN Classifiers as machine learning along with determining the accuracy of our model. Since we are not too familiar with Javascript, we encountered many issues with the formatting of tables and increasing the textbox size for the user inputs. We also had trouble putting in pictures of our own data because they did not have image addresses, but we were able to upload them at the end. It was extremely difficult to find a comprehensive database of businesses owned by women, so we used a sample dataset for the purposes of this demo.\nAccomplishments that we're proud of\nOne thing we are proud of as a team is building our own webpage from scratch. We were able to design the webpage, using CSS, and customize it to what we wanted. We are also proud of making use of Google Colab and using the Pandas data analysis because it is something new we just learned about this year.\nWhat we learned\nWe learned a lot about web design using Javascript and HTML, such as background color, pages, including a small survey, and more. But most importantly, as a team, we learned to communicate and check-in frequently. We also learned a lot from the mentors who helped us along the way!\nWhat's next for supportHER\nNext time, we would like to learn more about the AI model training to be able to predict the exact locations that would best meet the needs of our users. Rather than generating a plot graph to let users determine the best business location for them, we would love to be able to generate specific locations for them along with generating the accuracy of our suggestions based on their needs. Similarly, there are also a few issues with making the site user-friendly. When we improve our knowledge with databases, we want to connect the forum to one so that it is constantly saving. We could expand the database of women owned businesses in the location finder by working with local organizations to advertise this opportunity. Another cool idea would be to be able to add a chat function where people can talk and support each other.", "link": "https://devpost.com/software/name-tascjz", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwe know that many women and minorities struggle to start their own businesses. however, ever since covid hit, a boom of new small businesses has started. many women and minorities have come up with so many new and creative ideas such as selling scented candles, offering finance coaching, and many more! as a result, we wanted to create a community where anyone can connect with others to share their small business idea and help start theirs in the right location for them based on collected data of current businesses.\nwhat it does\nsupporther is a website that allows women to share their ideas and experiences on their own small businesses to help other women get inspiration. its features include a forum for people to look at examples and then add their own business to the list, a short form asking what kind of business and location the user is trying to start, and then providing data from ai machine learning to help determine successful locations to start their businesses; a nearby page that uses the user\u2019s location (with permission) to find small businesses within 25 miles away.\nhow we built it\nwe used html, js, and css to develop our webpage on repl.it. there were 3 main parts of this project: the forum, the data, and the nearby businesses. for the forum, we made it using a table where each row described a business. information such as the name, image, description, and link to support was added for each business. finally, the user could input information in text boxes to add to the table. we wanted to build a community of people supporting small businesses. for the ai part of the project, we used pandas python data analysis on google colab to -----> plot !!!  out the data sorted from the most popular locations to the least popular locations of all the top successful businesses. therefore, depending on what you are looking for, you could choose to have your small business to be in the area of less competition, or you could start your business in the middle of new york city to become the hidden gem people discover. for the nearby locations aspect, we used a geolocation api to get the user\u2019s current location (latitude and longitude) and compare it to the latitude and longitude of each element in a database of women-owned businesses. we created an algorithm to calculate the distance between the two points and programmed our website to only show locations that are within 25 miles of the user\u2019s location for convenience. this feature is a useful tool to raise awareness around local businesses owned by women and encourage users to support these businesses.\nchallenges we ran into\nwe ran into multiple challenges such as finding a good dataset to predict the best location to start a small business using knn classifiers as machine learning along with determining the accuracy of our model. since we are not too familiar with javascript, we encountered many issues with the formatting of tables and increasing the textbox size for the user inputs. we also had trouble putting in pictures of our own data because they did not have image addresses, but we were able to upload them at the end. it was extremely difficult to find a comprehensive database of businesses owned by women, so we used a sample dataset for the purposes of this demo.\naccomplishments that we're proud of\none thing we are proud of as a team is building our own webpage from scratch. we were able to design the webpage, using css, and customize it to what we wanted. we are also proud of making use of google colab and using the pandas data analysis because it is something new we just learned about this year.\nwhat we learned\nwe learned a lot about web design using javascript and html, such as background color, pages, including a small survey, and more. but most importantly, as a team, we learned to communicate and check-in frequently. we also learned a lot from the mentors who helped us along the way!\nwhat's next for supporther\nnext time, we would like to learn more about the ai model training to be able to predict the exact locations that would best meet the needs of our users. rather than generating a plot graph to let users determine the best business location for them, we would love to be able to generate specific locations for them along with generating the accuracy of our suggestions based on their needs. similarly, there are also a few issues with making the site user-friendly. when we improve our knowledge with databases, we want to connect the forum to one so that it is constantly saving. we could expand the database of women owned businesses in the location finder by working with local organizations to advertise this opportunity. another cool idea would be to be able to add a chat function where people can talk and support each other.", "sortedWord": "None", "removed": "Nan", "score": 3, "comments": 0, "media": null, "medialink": null, "identifyer": 59503254}, {"Unnamed: 0": 3368, "autor": "MarsMello", "date": null, "content": "MarsMello is a truly decentralised Web3 game whose plot is based on colonising and industrialising Mars! MarsMello can be described as an Idle-Open World-Strategy-Economy-Simulation Game\nPlayers can buy plots of land (NFTs) in the game and setup factories (NFTs) and large industries on it. Factories will produce HRC20 resources which the players can claim and trade for other OKT tokens or OKT on DEX. Players must adopt strategies to maximise the profits as the Ore distribution and Factory efficiency will be randomised (Because Life is Unfair) An In-Game Marketplace will enable users to trade and profit from the NFTs. Given all the features and an open economy, it will be very lucrative to get hands on the game and start earning! This would bring in the attention to blockchain in the most simplest gamified form possible.\nGame Mechanics\nThe game is played by buying Land and placing Factories upon it. These factories have a pseudo-random efficiency rate and the land has a random generation of ores. Which implies that the yield rate will be different for each pair of land and factory.\nAfter 24 hours the temporary storage fills up and no further yield can be accumulated. Player has to claim the resources to empty the storage.\nEach land purchase gives the user a land with a random seed with the ore distribution. RNG was also a challenge we had to tackle.\nThe game mechanics are so complex that a single smart contract could not be used. We had to use seven separate smart contracts instead.\nAfter the user claims the resources they can trade them on any ERC20 DEX for MLO or OKT or any other in-game ERC20 token.", "link": "https://devpost.com/software/marsmello-dja1yv", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "marsmello is a truly decentralised web3 game whose -----> plot !!!  is based on colonising and industrialising mars! marsmello can be described as an idle-open world-strategy-economy-simulation game\nplayers can buy plots of land (nfts) in the game and setup factories (nfts) and large industries on it. factories will produce hrc20 resources which the players can claim and trade for other okt tokens or okt on dex. players must adopt strategies to maximise the profits as the ore distribution and factory efficiency will be randomised (because life is unfair) an in-game marketplace will enable users to trade and profit from the nfts. given all the features and an open economy, it will be very lucrative to get hands on the game and start earning! this would bring in the attention to blockchain in the most simplest gamified form possible.\ngame mechanics\nthe game is played by buying land and placing factories upon it. these factories have a pseudo-random efficiency rate and the land has a random generation of ores. which implies that the yield rate will be different for each pair of land and factory.\nafter 24 hours the temporary storage fills up and no further yield can be accumulated. player has to claim the resources to empty the storage.\neach land purchase gives the user a land with a random seed with the ore distribution. rng was also a challenge we had to tackle.\nthe game mechanics are so complex that a single smart contract could not be used. we had to use seven separate smart contracts instead.\nafter the user claims the resources they can trade them on any erc20 dex for mlo or okt or any other in-game erc20 token.", "sortedWord": "None", "removed": "Nan", "score": 5, "comments": 0, "media": null, "medialink": null, "identifyer": 59503368}, {"Unnamed: 0": 3408, "autor": "Data Visualization", "date": null, "content": "It feels surreal to imagine how the COVID-19 virus began to spread from one person that is patient zero to four million today. In this project we are going to use COVID-19 dataset to represent the number of confirmed cases and deaths with respect to Date reported on the Graph\nData visualization is an interdisciplinary field that deals with the graphic representation of data. Data visualization is a particularly efficient way of communicating when the data is numerous as for example a time series.\nTo get started with the project, I needed to set up a Jupyter notebook After getting my Jupyter notebook ready, I had to import some important Python libraries like Pandas, Numpy and Matplot to visualize the required set of data on the graph. Next, I opened my csv file which contains all of the data for different countries in the world Now to see the data of a specific country (in this case India) \u2014 I searched for \u2018India\u2019 in the \u2018Country\u2019 column of my data frame To display this data in the form of a line chart I used the Plotly module again having entries which included: Name of the data frame (df_india); X-axis will show the \u2018Date Reported\u2019; Y-axis will show the \u2018New cases\u2019 along with the \u2018New Deaths\u2019.\nFrom the graph we can clearly see that during the lockdown period in India\u2014 the \u2018New cases\u2019 increases during the middle of the lockdown and the \u2018Deaths\u2019 increases slightly\nThis Project helped me understand the spread of COVID-19 in a single country, it was important to be able to compare the data of different countries\nAs my future work, I decided to create a new data frame with 2 columns showing the name of the country along with the maximum deaths. With this I will plot a bar chart to show the comparison between the different countries as to identify which country had the highest number of confirmed COVID cases in a single day.", "link": "https://devpost.com/software/data-visualization-c8l6yo", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "it feels surreal to imagine how the covid-19 virus began to spread from one person that is patient zero to four million today. in this project we are going to use covid-19 dataset to represent the number of confirmed cases and deaths with respect to date reported on the graph\ndata visualization is an interdisciplinary field that deals with the graphic representation of data. data visualization is a particularly efficient way of communicating when the data is numerous as for example a time series.\nto get started with the project, i needed to set up a jupyter notebook after getting my jupyter notebook ready, i had to import some important python libraries like pandas, numpy and matplot to visualize the required set of data on the graph. next, i opened my csv file which contains all of the data for different countries in the world now to see the data of a specific country (in this case india) \u2014 i searched for \u2018india\u2019 in the \u2018country\u2019 column of my data frame to display this data in the form of a line chart i used the plotly module again having entries which included: name of the data frame (df_india); x-axis will show the \u2018date reported\u2019; y-axis will show the \u2018new cases\u2019 along with the \u2018new deaths\u2019.\nfrom the graph we can clearly see that during the lockdown period in india\u2014 the \u2018new cases\u2019 increases during the middle of the lockdown and the \u2018deaths\u2019 increases slightly\nthis project helped me understand the spread of covid-19 in a single country, it was important to be able to compare the data of different countries\nas my future work, i decided to create a new data frame with 2 columns showing the name of the country along with the maximum deaths. with this i will -----> plot !!!  a bar chart to show the comparison between the different countries as to identify which country had the highest number of confirmed covid cases in a single day.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59503408}, {"Unnamed: 0": 3461, "autor": "Analyzing Social Media from a Diversity Perspective", "date": null, "content": "Inspiration\nI was interested in the questions about diversity and social media engagement, especially because I have worked as a social media intern for several non-profit organizations. I also wanted to make the final deliverable as accessible as possible, so I considered aspects of the ADA framework when designing it and choosing the software to create the final page with.\nWhat it does\nThis storymap takes a step by step dive into the dataset provided by TwoSixTech. Accessible elements include compatibility with text-to-speech readers, descriptive captions, responsive UX design to use on different devices, auto-scroll, and the ability to scroll down with the down arrow. We start out with a birds-eye view of the data using pie charts and end with a scatter plot with insights about diversity and inclusion in tech. I also wrote a reflection building on thoughts I had about the data.\nHow we built it\nI analyzed the data using Microsoft Excel, and stylized the charts in Adobe Illustrator. Some analysis was coded in Python, but I used 3rd party code for that component. I then imported the files to ArcGIS to create the final deliverable.\nChallenges we ran into\nIt took me 2.5 hours to figure out how to make the 3D effects on the pie charts, but I had a very specific vision that I wanted to make work.\nAccomplishments that we're proud of\nI'm proud that I completed all graphics and charts from scratch in Adobe Illustrator and Microsoft Excel. I did not use any software that would combine the two functionalities, because I wanted to have a lot of control over the final look.\nWhat we learned\nI learned how to create and publish an ArcGIS StoryMap. I also learned how to do some new functions in Excel to count occurrences of keywords.", "link": "https://devpost.com/software/analyzing-social-media-from-a-diversity-perspective", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\ni was interested in the questions about diversity and social media engagement, especially because i have worked as a social media intern for several non-profit organizations. i also wanted to make the final deliverable as accessible as possible, so i considered aspects of the ada framework when designing it and choosing the software to create the final page with.\nwhat it does\nthis storymap takes a step by step dive into the dataset provided by twosixtech. accessible elements include compatibility with text-to-speech readers, descriptive captions, responsive ux design to use on different devices, auto-scroll, and the ability to scroll down with the down arrow. we start out with a birds-eye view of the data using pie charts and end with a scatter -----> plot !!!  with insights about diversity and inclusion in tech. i also wrote a reflection building on thoughts i had about the data.\nhow we built it\ni analyzed the data using microsoft excel, and stylized the charts in adobe illustrator. some analysis was coded in python, but i used 3rd party code for that component. i then imported the files to arcgis to create the final deliverable.\nchallenges we ran into\nit took me 2.5 hours to figure out how to make the 3d effects on the pie charts, but i had a very specific vision that i wanted to make work.\naccomplishments that we're proud of\ni'm proud that i completed all graphics and charts from scratch in adobe illustrator and microsoft excel. i did not use any software that would combine the two functionalities, because i wanted to have a lot of control over the final look.\nwhat we learned\ni learned how to create and publish an arcgis storymap. i also learned how to do some new functions in excel to count occurrences of keywords.", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 0, "media": null, "medialink": null, "identifyer": 59503461}, {"Unnamed: 0": 3509, "autor": "Save Wildlife", "date": null, "content": "Members:\nTrang Dang, Truong Dang, Anand Patel, Leon Gao\nInspiration\nBased on the zoo theme provided to us and underfunding of animal welfare around the world during the COVID-19 pandemic, we decided to build a website that provides both non-profit organizations and users with essential statistics, predicting data about animal populations. So, they can raise awareness about nature then pay attention to natural activities.\nWhat it does\nWe built a website made for welfare NGOs to consider the prediction of animal species populations. Therefore, they can have a clear view of nature at the moment in order to raise suitable campaigns that ask for people\u2019s support and donation. Users also can access this website so as to view the information of NGOs, their campaigns, the statistics, from which make their decisions to participate in certain campaigns.\nHow we built it\nPython for the back-end. We applied a linear regression model so as to predict the animal species population decrease in the near future (2022 - 2030). Moreover, we compared the rate of change in these species and made a comparison of animal categories\u2019 emergencies. HTML, CSS, and JavaScript for the front-end. Flask for integrating both Python and HTML. Microsoft-Azure Wix Logo Maker\nChallenges we ran into\nUnfamiliar with displaying a graph using Python. implementing an image onto an HTML webpage. Formatting and styling the website into the way we wanted it to look.\nAccomplishments that we're proud of\nFigure out how to build a linear regression model by Python. Figure out how to plot a bar chart with a color bar based on the quantities\u2019 values. Learned to edit a large template to the way we wanted Deploy code to get an image file in HTML. Add image and text into one section onto an HTML webpage.\nWhat we learned\nTeamworking Task management Using Flask to integrate Python and HTML Collect data and deal with raw data. How to relocate files using HTML and display them onto a webpage.", "link": "https://devpost.com/software/help-us-save-the-animals", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "members:\ntrang dang, truong dang, anand patel, leon gao\ninspiration\nbased on the zoo theme provided to us and underfunding of animal welfare around the world during the covid-19 pandemic, we decided to build a website that provides both non-profit organizations and users with essential statistics, predicting data about animal populations. so, they can raise awareness about nature then pay attention to natural activities.\nwhat it does\nwe built a website made for welfare ngos to consider the prediction of animal species populations. therefore, they can have a clear view of nature at the moment in order to raise suitable campaigns that ask for people\u2019s support and donation. users also can access this website so as to view the information of ngos, their campaigns, the statistics, from which make their decisions to participate in certain campaigns.\nhow we built it\npython for the back-end. we applied a linear regression model so as to predict the animal species population decrease in the near future (2022 - 2030). moreover, we compared the rate of change in these species and made a comparison of animal categories\u2019 emergencies. html, css, and javascript for the front-end. flask for integrating both python and html. microsoft-azure wix logo maker\nchallenges we ran into\nunfamiliar with displaying a graph using python. implementing an image onto an html webpage. formatting and styling the website into the way we wanted it to look.\naccomplishments that we're proud of\nfigure out how to build a linear regression model by python. figure out how to -----> plot !!!  a bar chart with a color bar based on the quantities\u2019 values. learned to edit a large template to the way we wanted deploy code to get an image file in html. add image and text into one section onto an html webpage.\nwhat we learned\nteamworking task management using flask to integrate python and html collect data and deal with raw data. how to relocate files using html and display them onto a webpage.", "sortedWord": "None", "removed": "Nan", "score": 3, "comments": 0, "media": null, "medialink": null, "identifyer": 59503509}, {"Unnamed: 0": 3927, "autor": "Xtructure", "date": null, "content": "Final Write-up: https://drive.google.com/file/d/1NJPnyHREM6UJE9t2ZFBo4TdbT-0uYdKO/view?usp=sharing\nPresentation video: https://youtu.be/9eqbZ0elbQw\nPoster: https://drive.google.com/file/d/1v7I_3t9kcNBcig73Hvn8_P-f_v6y80_v/view?usp=sharing\nCode: https://github.com/sunoru/Xtructure\nProject Check-in #2: We've directly added/updated it in the following post.\nXstructure\nDawei Si (dsi1), Lingyu Ma (lma21)\nIntroduction\nX-ray scattering is one of the state-of-art materials characterization techniques that measure materials' structural and dynamical properties with high precision. Based on the scattering patterns, it is possible to retrieve the geometric structure of gas-phase molecules with sub-\u00c5ngstrom spatial and femtosecond temporal resolution. However, structural retrieval becomes progressively difficult with increasing structural complexity, given that a global extremum must be found in multi-dimensional solution space. Even worse, pre-calculating many thousands of molecular configurations for all orientations becomes simply intractable. The strong predictive power and capacity for representation learning enable machine learning models to perform comparably to more expensive numerical models, like first-principles calculations, at a much lower computational cost. Machine learning models can distill complex structural information and be trained to acquire interatomic force field and potential energy surface.\nThe scattering intensity can be represented as a high dimensional array (I), indexed by momentum k, energy \u03c9, and polarization \u03b5. Such data structures are naturally compatible with convolutional neural networks (CNNs), which are widely applied in image processing. Atomic structures can also be interpreted as images by regarding them as density fields based on atomic species and positions on 3D real-space grid, which enable them to work with convolutional filters. After radial averaging of the scattering intensity, we can obtain the isotropic scattering signal which can be represented as a 1-D vector, considering the time-sequence of the experimental signals, Recurrent Neural networks like LSTMs, GRUs, are also suitable to solve this problem. Our goal is to interpret X-ray scattering signals and figure out their corresponding molecular structures. The problem we want to solve is regression.\nRelated Work\nIn recent years, X-ray, electron, and neutron scattering have received a significant boost due to the development and increased application of machine learning to materials problems. With the integration of machine learning methods into the typical workflow of scattering experiments, problems that challenge traditional analysis approaches can be addressable, including leveraging the knowledge of simple materials to model more complicated systems, learning with limited data or incomplete labels, identifying meaningful spectra and materials, mitigating spectral noise, and others.\nList of the related work:\nMachine learning on neutron and x-ray scattering and spectroscopies\nMachine learning for laser-induced electron diffraction imaging of molecular structures\nTransferable Machine-Learning Model of the Electron Density\nData\nWe need a number of X-ray scattering patterns from various different structures and different molecules. Based on previous theoretical work, we can create structure pools of million trial structures and generate their corresponding theoretical scattering patterns used as our training and test dataset. There're three different ways to create structure pools, molecular dynamics simulations (MD), a Monte Carlo (MC) based approach, sampling from a quantum Wigner distribution. In terms of the model/theory, we'd like to simulate the scattering pattern, Independent Atom Model (IAM) would work well for our purpose.\nThe structure pool would contain more than one million geometries of several different molecules, with the corresponding scattering pattern for each geometry. It would need to do significant preprocessing.\nMethodology\nThe basic architecture of the procedure in this work is as the following figure:\nX-ray scaterring results from experiments or theoretical simulations are fed into neural networks, and the structures of their corresponding molecules are predicted. For example, the X-ray scattering pattern (the plot on the left) can be recognized to has the structure of N-Methylmorpholine (that on the right).\nData Representation\nThere are two types of representation for the input patterns. One is directly using the 2D images like we can measure in experiments, as shown in the green plot in the above figure. Algorithms working well on images might be also applied well to the data, but the information might be more redundant.\nThe other one is taking the average of the scattering intensity and plotting it with respect to the radius, (like the curve plot in the figure), so each 2D pattern is represented in an one-dimensional vector. Thus, the information is like time sequence and it is more suitable for the algorithms designed for 1D signals.\nSince the output is molecular structures, there are also two ways to describe them. Each atom in the molecule can be located by their cartesian coordinates in the space, or the electron density of the whole molecule can be calculated. The first method has a limit number of atoms, while with the second method the space is more limited. Note that atomic numbers should also be included with the 3D coordinates to distinguish different elements.\nThe root-mean-square deviation (RMSD) of atomic positions between predicted and labelled structures can be used as loss function, as it is a measurement of how similar two molecular structures are to each other.\nConvolutional Neural Networks\nCNNs are widely used to extract information and do classification tasks for image data. They are very suited for tasks like recognizing subtle features in an image that are difficult for human brains to identify. In this project, we will attempt several types of CNNs for the 2D patterns.\nRecurrent Neural Networks\nRNNs like LSTMs and GRUs might also be helpful for our project, since the input can also be represented as 1D signals. RNNs are useful to identify the dynamics of physical systems.\nMetrics\nThe accuracy in this project is defined as the average number of succeeded recognization of molecules.\nBy the final due date, we should finish preparing and preprocessing the data for both training and testing, understanding how other researchers are studying similar problems, and setting up a procedure to test different kinds of models. At least one CNN and one RNN-based neural networks are tested to see their ability for this task.\nWe also plan to design and test more models. Hopefully, a working model that has an accuracy > 50% could be found. We may also provide this tool to experimentalist for realtime fast data analysis in their labs.\nEthics\nGiven the current repetition rate of the state-of-art experimental techniques, 120 Hz for X-ray scattering and 50000 Hz for keV-UED, it's very hard for experimentalist to analyze these scattering patterns on the fly by using traditional methods during experiments. With the help of deep learning, it makes possible to do real-time fast data-analysis for experimentalists. The obtained information would guide the experiment and offer valuable insights.\nSince this project is designed as a tool for experimentalists instead of taking over all jobs of a human, we plan to quantify the success by how much more efficiency it helps improve in the labs. And depending on how experimentalists are relying on the tool, it might also cause mistakes.\nDivision of labor\nLingyu: Generate data, preprocessing, investigate suitable Neural Networks (NN), training\nDawei: Preprocessing, Investigate suitable NNs, training\nChallenges\nWhen we explore suitable Neural Networks for our project, we've encountered the following challenges:\nCurrently, we can not come up with a suitable neural network that can be used as a general molecular scattering pattern interpreter. To be more specific, our input data is simulated scattering pattern + atomic numbers of the corresponding molecule, and the output is the 3D cartesian coordinates for each atom within the molecules. No matter we use GNN, RNN, Transformer, or just CNN, its trained weights or embeddings are just for one specific molecular since different molecules might have a different number of atoms (e.g. N-methlymorpholine C5H11NO has 18 atoms while 1,2-Dithiane C4S2H8 has only 14 atoms), different connections between atoms (e.g. C-N, C-O bonds in N-methylmorphine and C-S, S-S bonds in 1,2-Dithiane), and etc. Furthermore, the input size and output size are not fixed for different molecules, because of the different number of atoms within different molecules, the size of the output is changing with respect to the input size. Because of these constrictions, we can only build one NN for one molecule and haven't found a general molecular scattering pattern interpreter yet.\nThe molecular structures in our structure pool are close to each other, for example, we've estimated the maximum relative percent difference between two scattering patterns is around 7% for the corresponding two molecular structures of NMM. Given the architecture of NN we've built now, i.e. use several layers of CNN as an encoder to encode the information in the scattering pattern, and the output of the CNN as the initial state for the following RNN which is used to recover the 3D cartesian coordinates for the molecule, it seems that every time we trained the NN, it finds some local/artificial structures which sit around in the middle of the structure pool. It would give a small loss but always the same structure, kind of like the model collapse in GAN. Therefore, we have some trouble finding or tuning the architecture of NN to suitably solve our problem.\nInsights\nWe've built our neural network, trained, and tested on it. But we found the problem as mentioned in the second bullet point in the Challenges section. Therefore, we haven't had concrete results at this point.\nActually, we originally expected that our model should work and give us some kind of reasonably predicted structures. In reality, our current model can not tell those subtle structural differences in the structure pool and have some issues with correct prediction.\nPlan\nFirst, we would like to resolve the issues we've met in the current model, i.e. letting one molecular interpreter NN normally function. We will try to re-process our data to magnify the differences between the scattering patterns w.r.t different molecular structures, tune the architecture of the current model to strengthen the recognization ability. (Dedicate more time to this task)\nThen, we will build such one molecular scattering pattern interpreter for each kind of molecule we have, and probably compare the quality of their predictions. We have one million structures for N-methylmorpholine (NMM), half-million structures for 1,3-cyclohexadiene (CHD), and around half-million structures for 1,2-Dithiane (DT).\nFinally, we hope that with the help/insights from TA, we could construct a general molecular scattering pattern interpreter, which could predict different molecular structures given different kinds of scattering patterns. (If it is possible, we'll try for it)", "link": "https://devpost.com/software/xtructure", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "final write-up: https://drive.google.com/file/d/1njpnyhrem6uje9t2zfbo4tdbt-0uydko/view?usp=sharing\npresentation video: https://youtu.be/9eqbz0elbqw\nposter: https://drive.google.com/file/d/1v7i_3t9kcnbcig73hvn8_p-f_v6y80_v/view?usp=sharing\ncode: https://github.com/sunoru/xtructure\nproject check-in #2: we've directly added/updated it in the following post.\nxstructure\ndawei si (dsi1), lingyu ma (lma21)\nintroduction\nx-ray scattering is one of the state-of-art materials characterization techniques that measure materials' structural and dynamical properties with high precision. based on the scattering patterns, it is possible to retrieve the geometric structure of gas-phase molecules with sub-\u00e5ngstrom spatial and femtosecond temporal resolution. however, structural retrieval becomes progressively difficult with increasing structural complexity, given that a global extremum must be found in multi-dimensional solution space. even worse, pre-calculating many thousands of molecular configurations for all orientations becomes simply intractable. the strong predictive power and capacity for representation learning enable machine learning models to perform comparably to more expensive numerical models, like first-principles calculations, at a much lower computational cost. machine learning models can distill complex structural information and be trained to acquire interatomic force field and potential energy surface.\nthe scattering intensity can be represented as a high dimensional array (i), indexed by momentum k, energy \u03c9, and polarization \u03b5. such data structures are naturally compatible with convolutional neural networks (cnns), which are widely applied in image processing. atomic structures can also be interpreted as images by regarding them as density fields based on atomic species and positions on 3d real-space grid, which enable them to work with convolutional filters. after radial averaging of the scattering intensity, we can obtain the isotropic scattering signal which can be represented as a 1-d vector, considering the time-sequence of the experimental signals, recurrent neural networks like lstms, grus, are also suitable to solve this problem. our goal is to interpret x-ray scattering signals and figure out their corresponding molecular structures. the problem we want to solve is regression.\nrelated work\nin recent years, x-ray, electron, and neutron scattering have received a significant boost due to the development and increased application of machine learning to materials problems. with the integration of machine learning methods into the typical workflow of scattering experiments, problems that challenge traditional analysis approaches can be addressable, including leveraging the knowledge of simple materials to model more complicated systems, learning with limited data or incomplete labels, identifying meaningful spectra and materials, mitigating spectral noise, and others.\nlist of the related work:\nmachine learning on neutron and x-ray scattering and spectroscopies\nmachine learning for laser-induced electron diffraction imaging of molecular structures\ntransferable machine-learning model of the electron density\ndata\nwe need a number of x-ray scattering patterns from various different structures and different molecules. based on previous theoretical work, we can create structure pools of million trial structures and generate their corresponding theoretical scattering patterns used as our training and test dataset. there're three different ways to create structure pools, molecular dynamics simulations (md), a monte carlo (mc) based approach, sampling from a quantum wigner distribution. in terms of the model/theory, we'd like to simulate the scattering pattern, independent atom model (iam) would work well for our purpose.\nthe structure pool would contain more than one million geometries of several different molecules, with the corresponding scattering pattern for each geometry. it would need to do significant preprocessing.\nmethodology\nthe basic architecture of the procedure in this work is as the following figure:\nx-ray scaterring results from experiments or theoretical simulations are fed into neural networks, and the structures of their corresponding molecules are predicted. for example, the x-ray scattering pattern (the -----> plot !!!  on the left) can be recognized to has the structure of n-methylmorpholine (that on the right).\ndata representation\nthere are two types of representation for the input patterns. one is directly using the 2d images like we can measure in experiments, as shown in the green plot in the above figure. algorithms working well on images might be also applied well to the data, but the information might be more redundant.\nthe other one is taking the average of the scattering intensity and plotting it with respect to the radius, (like the curve plot in the figure), so each 2d pattern is represented in an one-dimensional vector. thus, the information is like time sequence and it is more suitable for the algorithms designed for 1d signals.\nsince the output is molecular structures, there are also two ways to describe them. each atom in the molecule can be located by their cartesian coordinates in the space, or the electron density of the whole molecule can be calculated. the first method has a limit number of atoms, while with the second method the space is more limited. note that atomic numbers should also be included with the 3d coordinates to distinguish different elements.\nthe root-mean-square deviation (rmsd) of atomic positions between predicted and labelled structures can be used as loss function, as it is a measurement of how similar two molecular structures are to each other.\nconvolutional neural networks\ncnns are widely used to extract information and do classification tasks for image data. they are very suited for tasks like recognizing subtle features in an image that are difficult for human brains to identify. in this project, we will attempt several types of cnns for the 2d patterns.\nrecurrent neural networks\nrnns like lstms and grus might also be helpful for our project, since the input can also be represented as 1d signals. rnns are useful to identify the dynamics of physical systems.\nmetrics\nthe accuracy in this project is defined as the average number of succeeded recognization of molecules.\nby the final due date, we should finish preparing and preprocessing the data for both training and testing, understanding how other researchers are studying similar problems, and setting up a procedure to test different kinds of models. at least one cnn and one rnn-based neural networks are tested to see their ability for this task.\nwe also plan to design and test more models. hopefully, a working model that has an accuracy > 50% could be found. we may also provide this tool to experimentalist for realtime fast data analysis in their labs.\nethics\ngiven the current repetition rate of the state-of-art experimental techniques, 120 hz for x-ray scattering and 50000 hz for kev-ued, it's very hard for experimentalist to analyze these scattering patterns on the fly by using traditional methods during experiments. with the help of deep learning, it makes possible to do real-time fast data-analysis for experimentalists. the obtained information would guide the experiment and offer valuable insights.\nsince this project is designed as a tool for experimentalists instead of taking over all jobs of a human, we plan to quantify the success by how much more efficiency it helps improve in the labs. and depending on how experimentalists are relying on the tool, it might also cause mistakes.\ndivision of labor\nlingyu: generate data, preprocessing, investigate suitable neural networks (nn), training\ndawei: preprocessing, investigate suitable nns, training\nchallenges\nwhen we explore suitable neural networks for our project, we've encountered the following challenges:\ncurrently, we can not come up with a suitable neural network that can be used as a general molecular scattering pattern interpreter. to be more specific, our input data is simulated scattering pattern + atomic numbers of the corresponding molecule, and the output is the 3d cartesian coordinates for each atom within the molecules. no matter we use gnn, rnn, transformer, or just cnn, its trained weights or embeddings are just for one specific molecular since different molecules might have a different number of atoms (e.g. n-methlymorpholine c5h11no has 18 atoms while 1,2-dithiane c4s2h8 has only 14 atoms), different connections between atoms (e.g. c-n, c-o bonds in n-methylmorphine and c-s, s-s bonds in 1,2-dithiane), and etc. furthermore, the input size and output size are not fixed for different molecules, because of the different number of atoms within different molecules, the size of the output is changing with respect to the input size. because of these constrictions, we can only build one nn for one molecule and haven't found a general molecular scattering pattern interpreter yet.\nthe molecular structures in our structure pool are close to each other, for example, we've estimated the maximum relative percent difference between two scattering patterns is around 7% for the corresponding two molecular structures of nmm. given the architecture of nn we've built now, i.e. use several layers of cnn as an encoder to encode the information in the scattering pattern, and the output of the cnn as the initial state for the following rnn which is used to recover the 3d cartesian coordinates for the molecule, it seems that every time we trained the nn, it finds some local/artificial structures which sit around in the middle of the structure pool. it would give a small loss but always the same structure, kind of like the model collapse in gan. therefore, we have some trouble finding or tuning the architecture of nn to suitably solve our problem.\ninsights\nwe've built our neural network, trained, and tested on it. but we found the problem as mentioned in the second bullet point in the challenges section. therefore, we haven't had concrete results at this point.\nactually, we originally expected that our model should work and give us some kind of reasonably predicted structures. in reality, our current model can not tell those subtle structural differences in the structure pool and have some issues with correct prediction.\nplan\nfirst, we would like to resolve the issues we've met in the current model, i.e. letting one molecular interpreter nn normally function. we will try to re-process our data to magnify the differences between the scattering patterns w.r.t different molecular structures, tune the architecture of the current model to strengthen the recognization ability. (dedicate more time to this task)\nthen, we will build such one molecular scattering pattern interpreter for each kind of molecule we have, and probably compare the quality of their predictions. we have one million structures for n-methylmorpholine (nmm), half-million structures for 1,3-cyclohexadiene (chd), and around half-million structures for 1,2-dithiane (dt).\nfinally, we hope that with the help/insights from ta, we could construct a general molecular scattering pattern interpreter, which could predict different molecular structures given different kinds of scattering patterns. (if it is possible, we'll try for it)", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 2, "media": null, "medialink": null, "identifyer": 59503927}, {"Unnamed: 0": 3957, "autor": "Realm Hunter (Not Boring Company)", "date": null, "content": "We are about to launch the project! If you want to get ahead, be sure to follow our twitter page we just made recently Official NBC Twitter\nWe Want To Pioneer A New Form Of Entertainment For The Metaverse\nOur day-to-day lives can be mundane. So, we often imagine what life could have been. We fantasize and we dream. However, because the physical world limits what we can do, our wild ideas often gets materialized into lesser forms - movies, video games, comics, theme parks and so on. We believe that there are better medium that our dream can materialize into. We call this a hyper second reality - a fantasy digital reality where people can live, work and play. Although the actual technology to build it still requires time to develop, we believe that the value of of creating it will be tremendous, both intrinsically and financially to our society, and that's why we're building this.\nAbout Realm Hunter\nRealm Hunter is the first upcoming blockchain game NBC will release. It's a high quality GameFi project which will serve as means establishing NBC as a strong contender for the Metaverse!\nThe Plot - Mysterious dungeons (realms) started appearing around our world. Rumor dictates that each realm contains riches and treasures called Artifacts, a mysterious object that yields power beyond imagination to the person who finds it. On one hand, these realms are too dangerous for humans to venture alone. On the other hand, this phenomenon gave birth to a mythical, powerful yet cute creature called NBMons. They possess the power and ability that allow ordinary humans to explore the realms safely. For reasons unknown, NBMons have an appetite for shards produced within these realms but can't enter them without a human, so they try to seek their worthy partner. When an NBMon and a human form a bonding contract, the person becomes known as a \"Hunter\". Together with their NBMon, Hunters explore these realms to hunt treasure and riches as they undergo a phenomenal journey of a lifetime while uncovering the secrets behind the occurrences of these realms.\nHow we built it\nThe main game is being built with Unity. We plan to use cloud service provider AWS Lamda + Dynamo DB + Smartfox (Networking) that will communicated with a backend server that will handle the blockchain side of things!\nFor our Dapp (which is basically the marketplace where you will be able to buy and sell NFTs), the main frontend framework we are using is React + Node with Solidity and a few JS blockchain libraries (web3, ethers...) as the blockchain/backend framework respectively. To iterate fast, we are using bubble.io to temporarily.\nWhat's next for Not Boring Company\nWe've barely touched the surface of the potential of Realm Hunter, but we're very excited to continue developing the game and launching it. Follow our project in Twitter for more updates!\nWhat we learned\nThe main things we've learned and deepened our knowledge during this Hackathon:\nWriting Smart Contract\nWorking With OEC,\nGame Development With Unity (Developing games, Shaders, etc)\nMultiplayer architecture (and networking architecture) for Unity\n3d Arts (making NBmons, rigging, animating and texturing, etc)\nWhat we're proud of\nAnd at the end, we're proud that in the short period of time (we decided to enter our project to hackathon midway), we've coded most of our smart contracts with some adjustments to be made (along with more new creative ideas, of course), adding a varying gameplay mechanic and improved our graphics and shader quality which basically went from zero to hero (or at least halfway).\nNotes\nPlease don't be confused that we mention we are using BSC in our landing page. We started the project with that but now we are evaluating multiple different options for our blockchain.", "link": "https://devpost.com/software/not-boring-company", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "we are about to launch the project! if you want to get ahead, be sure to follow our twitter page we just made recently official nbc twitter\nwe want to pioneer a new form of entertainment for the metaverse\nour day-to-day lives can be mundane. so, we often imagine what life could have been. we fantasize and we dream. however, because the physical world limits what we can do, our wild ideas often gets materialized into lesser forms - movies, video games, comics, theme parks and so on. we believe that there are better medium that our dream can materialize into. we call this a hyper second reality - a fantasy digital reality where people can live, work and play. although the actual technology to build it still requires time to develop, we believe that the value of of creating it will be tremendous, both intrinsically and financially to our society, and that's why we're building this.\nabout realm hunter\nrealm hunter is the first upcoming blockchain game nbc will release. it's a high quality gamefi project which will serve as means establishing nbc as a strong contender for the metaverse!\nthe -----> plot !!!  - mysterious dungeons (realms) started appearing around our world. rumor dictates that each realm contains riches and treasures called artifacts, a mysterious object that yields power beyond imagination to the person who finds it. on one hand, these realms are too dangerous for humans to venture alone. on the other hand, this phenomenon gave birth to a mythical, powerful yet cute creature called nbmons. they possess the power and ability that allow ordinary humans to explore the realms safely. for reasons unknown, nbmons have an appetite for shards produced within these realms but can't enter them without a human, so they try to seek their worthy partner. when an nbmon and a human form a bonding contract, the person becomes known as a \"hunter\". together with their nbmon, hunters explore these realms to hunt treasure and riches as they undergo a phenomenal journey of a lifetime while uncovering the secrets behind the occurrences of these realms.\nhow we built it\nthe main game is being built with unity. we plan to use cloud service provider aws lamda + dynamo db + smartfox (networking) that will communicated with a backend server that will handle the blockchain side of things!\nfor our dapp (which is basically the marketplace where you will be able to buy and sell nfts), the main frontend framework we are using is react + node with solidity and a few js blockchain libraries (web3, ethers...) as the blockchain/backend framework respectively. to iterate fast, we are using bubble.io to temporarily.\nwhat's next for not boring company\nwe've barely touched the surface of the potential of realm hunter, but we're very excited to continue developing the game and launching it. follow our project in twitter for more updates!\nwhat we learned\nthe main things we've learned and deepened our knowledge during this hackathon:\nwriting smart contract\nworking with oec,\ngame development with unity (developing games, shaders, etc)\nmultiplayer architecture (and networking architecture) for unity\n3d arts (making nbmons, rigging, animating and texturing, etc)\nwhat we're proud of\nand at the end, we're proud that in the short period of time (we decided to enter our project to hackathon midway), we've coded most of our smart contracts with some adjustments to be made (along with more new creative ideas, of course), adding a varying gameplay mechanic and improved our graphics and shader quality which basically went from zero to hero (or at least halfway).\nnotes\nplease don't be confused that we mention we are using bsc in our landing page. we started the project with that but now we are evaluating multiple different options for our blockchain.", "sortedWord": "None", "removed": "Nan", "score": 42, "comments": 3, "media": null, "medialink": null, "identifyer": 59503957}, {"Unnamed: 0": 4016, "autor": "Digital Verse", "date": null, "content": "Materials\nDemo access\nLink to web demo\nTelegram bot\nSupport: @panichm (telegram account)\nSource code on github\nRecommends for good results: upload small videos (5-20 seconds long), keep your face away from the camera for better quality, use videos with standard lighting.\nProblem/Annotation\nSynthetic media is a realistic transformation of audio and video using artificial intelligence. Currently, there are several applications based on this technology, but it\u2019s developing rapidly, attracting more and more public attention.\nOn one hand, this technology is a holy grail for advertisers and filmmakers which can give them endless opportunities to use any faces of any celebrities in their projects. With the help of our platform, the celebrity will be able to pronounce the text of the commercial in all the world's known languages. The advertiser will have a chance to create a separate commercial for ten thousand products, having only one digitized version of the celebrity's face. Film producers won't have to pay multimillion-dollar royalties to celebrities, it will be enough to buy their face.\nOn the other hand, without proper regulation this technology is a sophisticated threat for businesses and individuals. The illegal use of faces is gaining momentum. Debates about the originality of the synthetic videos and lawsuits attract lots of attention, thereby encouraging the creation of content with celebrities without their consent. Technology is evolving fast and it\u2019s only a matter of time before synthetic videos will be no longer distinguishable from the original.\nWe believe that with the help of blockchain this problem can be solved, NFT have a potential to create metaverse of the digital avatars of the users and regulate the relationship between video producers and celebrities, while copyright and data protection laws still cannot.\nSolution\nOur solution is a blockchain-based NFT marketplace of digital faces with a platform for synthetic videos generation.\nPlatform architecture\nThe user (for example celebrity) will be able to digitize his face by uploading a video of himself to the platform. Digital avatar of the user will be represented on the platform for the potential customers. After receiving the offer to buy the face, the user will be able to choose whether to sell it for this particular video/commercial. In case of consent, an NFT token gets created.\nAfter the token is minted, potential video creators can purchase this NFT, thereby acquiring the right to use the celebrity's face to create one DeepFake video.\nWith our solution, video creators will be able to purchase a digitized face and produce a video with this face on the same platform. And all this without the need for real filming and with digital confirmation on the blockchain. The NFT will eliminate the need to obtain IPR rights, which will be assigned to the video content producers with the purchase of the token)\nConcept & Feasibility\nWe have identified 2 main areas where our solution may be in demand.\nVideo marketing\nVideo production today is a very expensive process that includes the rent of cameras, studios and payments for the work of actors.\nThere are several stages of the video creation process:\nConcept development (plot, plans, etc.);\nPre-production (preparation of scripts, equipment);\nShooting;\nPost-production (editing of the footage);\nOnce a commercial is filmed, it is very difficult to make any edits, they are expensive and time-consuming. But instead of shooting a new video for marketing localization, language replacement and other corrections, it's enough to simply edit the existing one on the post production stage using our technology. For example, we are able to remove all parasite words from the video, replace phrases and translate a video into different languages \u200b\u200bwith a natural voice and facial expressions of the actor.\nOur target audience is video creation agencies, game/film studios and individual authors.\nMarket Size\nPAM - $234B. The global film and video market is expected to grow from $234.91 billion in 2020 to $251.92 billion in 2021 with an annual growth rate of 7.2%. And projected to reach $318.23 billion in 2025.\nTAM - $163B. ~70% from the total video market is formed by customers who may potentially need our product. That leaves us with $163B.\nSAM - $32B. Due to the novelty of the technology, we assume that of all customers who could potentially need our solution, 20% will want to try it at this stage.\nSOM - $20B. We don't have competitors in the AI field at the moment, which is also explained by the novelty of technology. Our main competitors are traditional video editing softwares (like Adobe Premiere Pro). Those applications partially perform the functionality of our solution, but they are more expensive and time-consuming. As a monetization, we propose using either a fixed price for processing one video or a subscription for using our application.\nInformation Security\n15.000 of Deep Fake videos were discovered on the Internet in 2019. Which is an 84% increase from just 8.000 in 2018. By now, this number has grown dramatically.\nLarge companies like Facebook are already sounding the alarm about the potential impact of Deep Fake videos. However, this problem concerns almost every media service - youtube, social networks, etc.\nTo solve this problem we are aiming to provide to Deep Fake creators the regulated field for their creativity and developments. We are on the way to create the first licensing and copyright management platform using NFTs. And enable creators to fairly buy rights for the \u201cfaces\u201d.\nWith the help of NFT the owner of the token will be able to confirm the IPR for the video.\nOur target audience - video content creators, influencers, celebrities, bloggers.\nThe planned monetization model is a one-time payment for checking/minting one video.\nProject Design\nWe have developed a scalable architecture that consists of several modules:\nModule for replacing faces on video\nIt consists of machine learning algorithms written in Python. There are 3 main parts:\nData preparation\nEach uploaded video is divided into frames, on each frame we detect the faces, process them in a certain way (align, improve the resolution) and use in next modules.\nModel training\nFor each celebrity/user we train a model on the GPU using it's facet, which later allows you to replace faces almost instantly without any additional training.\nVideo merging\nUsing the trained models, we replace faces on frames from uploaded video and generate a new video using various additional functions for color correction, quality improvement and etc.\nOur main difference from other deepfake projects is that we have automated the process of creating videos as much as possible (you don't need a lot of manual work, just upload a video and thats it) and due to separate models for each user, we can almost instantly generate videos with high quality. Also, it is possible to additionally train the model on specific video an get a better quality/resolution (for b2b requests).\nSmart contracts on Okex blockchain that allows to mint and transfer NFT tokens\nOur contracts has all needed basic functions to work with NFT tokens:\nMintTokenToAddress(address owner, string memory metadataURI)\nAllows you to mint a NFT token.\nTransferFrom(address from, address to, uint256 tokenId)\nAllows you to transfer any NFT token on other address.\nImplementation of access control\nNFT Market\nAllows you to list and sell created NFT tokens. Functions:\ncreateMarketItem(address nftContract,uint256 tokenId,uint256 price)\ncreateMarketSale(address nftContract,uint256 itemId)\nfetchMarketItems() public view returns (MarketItem[] memory)\nfetchMyNFTs() public view returns (MarketItem[] memory)\nSource code\nBackend\nWritten in golang for interacting with machine learning algorithms, implementing business logic and interacting with the blockchain.\nSource code\nFront-end\nImplemented on React.js.\nCurrent implemented workflow in the demo\nThe user uploads the video to the platform;\nWith the help of the face replacement module, the video is divided into frames, a faces is detected on each frame. Using a machine learning model, this faces are replaced by another and then a new video is generated;\nNext step is to upload the generated video to IPFS storage;\nThen the link to the video in IPFS storage and additional information (name, description) is sent to the smart contract to create an NTF token. The token can be transferred, sold.\nRoadmap\nWe plan to further develop the platform. The current demo version is more for testing puprposes, so it's UI/UX is a little bit complex. In production version the interface will be much simpler and easy to use, i.e. user will be only needed to upload a video, choose face, pay fee and faceswap video will be automatically generated along with NFT token. We already have a design for production version and working on frontend/backend for further updates.\nCreate a personal account for celebrities / users, where they can:\nUpload a video with their face and get a model to replace faces in any video;\nBe able to accept orders for the replacement from companies;\nAdd support for copying voice and lips synchronization based on audio.\nNew user - Dashboard\nNew user - Create Step 1\nExisting User Face digitalization - Faceset\nCreate a personal account for business with the ability to:\nUpload the video and select the person to replace the face / voice;\nOr just send your script and we will record the video ourselves;\nBuy NFT token of generated video.\nBusiness - Create Step 1\nBusiness - Create Step 2\nImprove the structure of smart contracts:\nSo that user can transfer rights to use his face;\nSmart contract for NFT shop.\nUpdate machine learning algorythms:\nTrain models with higher resolution. Current resolution is 320px, it is possible to improve it up to 448-640px, i.e. quality boost in 1.5-2x times.\nFix problems with artifacts during fast head movement and different lighting/color gradation, improve face detection algorithms.", "link": "https://devpost.com/software/nft-platform-for-digital-faces", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "materials\ndemo access\nlink to web demo\ntelegram bot\nsupport: @panichm (telegram account)\nsource code on github\nrecommends for good results: upload small videos (5-20 seconds long), keep your face away from the camera for better quality, use videos with standard lighting.\nproblem/annotation\nsynthetic media is a realistic transformation of audio and video using artificial intelligence. currently, there are several applications based on this technology, but it\u2019s developing rapidly, attracting more and more public attention.\non one hand, this technology is a holy grail for advertisers and filmmakers which can give them endless opportunities to use any faces of any celebrities in their projects. with the help of our platform, the celebrity will be able to pronounce the text of the commercial in all the world's known languages. the advertiser will have a chance to create a separate commercial for ten thousand products, having only one digitized version of the celebrity's face. film producers won't have to pay multimillion-dollar royalties to celebrities, it will be enough to buy their face.\non the other hand, without proper regulation this technology is a sophisticated threat for businesses and individuals. the illegal use of faces is gaining momentum. debates about the originality of the synthetic videos and lawsuits attract lots of attention, thereby encouraging the creation of content with celebrities without their consent. technology is evolving fast and it\u2019s only a matter of time before synthetic videos will be no longer distinguishable from the original.\nwe believe that with the help of blockchain this problem can be solved, nft have a potential to create metaverse of the digital avatars of the users and regulate the relationship between video producers and celebrities, while copyright and data protection laws still cannot.\nsolution\nour solution is a blockchain-based nft marketplace of digital faces with a platform for synthetic videos generation.\nplatform architecture\nthe user (for example celebrity) will be able to digitize his face by uploading a video of himself to the platform. digital avatar of the user will be represented on the platform for the potential customers. after receiving the offer to buy the face, the user will be able to choose whether to sell it for this particular video/commercial. in case of consent, an nft token gets created.\nafter the token is minted, potential video creators can purchase this nft, thereby acquiring the right to use the celebrity's face to create one deepfake video.\nwith our solution, video creators will be able to purchase a digitized face and produce a video with this face on the same platform. and all this without the need for real filming and with digital confirmation on the blockchain. the nft will eliminate the need to obtain ipr rights, which will be assigned to the video content producers with the purchase of the token)\nconcept & feasibility\nwe have identified 2 main areas where our solution may be in demand.\nvideo marketing\nvideo production today is a very expensive process that includes the rent of cameras, studios and payments for the work of actors.\nthere are several stages of the video creation process:\nconcept development (-----> plot !!! , plans, etc.);\npre-production (preparation of scripts, equipment);\nshooting;\npost-production (editing of the footage);\nonce a commercial is filmed, it is very difficult to make any edits, they are expensive and time-consuming. but instead of shooting a new video for marketing localization, language replacement and other corrections, it's enough to simply edit the existing one on the post production stage using our technology. for example, we are able to remove all parasite words from the video, replace phrases and translate a video into different languages \u200b\u200bwith a natural voice and facial expressions of the actor.\nour target audience is video creation agencies, game/film studios and individual authors.\nmarket size\npam - $234b. the global film and video market is expected to grow from $234.91 billion in 2020 to $251.92 billion in 2021 with an annual growth rate of 7.2%. and projected to reach $318.23 billion in 2025.\ntam - $163b. ~70% from the total video market is formed by customers who may potentially need our product. that leaves us with $163b.\nsam - $32b. due to the novelty of the technology, we assume that of all customers who could potentially need our solution, 20% will want to try it at this stage.\nsom - $20b. we don't have competitors in the ai field at the moment, which is also explained by the novelty of technology. our main competitors are traditional video editing softwares (like adobe premiere pro). those applications partially perform the functionality of our solution, but they are more expensive and time-consuming. as a monetization, we propose using either a fixed price for processing one video or a subscription for using our application.\ninformation security\n15.000 of deep fake videos were discovered on the internet in 2019. which is an 84% increase from just 8.000 in 2018. by now, this number has grown dramatically.\nlarge companies like facebook are already sounding the alarm about the potential impact of deep fake videos. however, this problem concerns almost every media service - youtube, social networks, etc.\nto solve this problem we are aiming to provide to deep fake creators the regulated field for their creativity and developments. we are on the way to create the first licensing and copyright management platform using nfts. and enable creators to fairly buy rights for the \u201cfaces\u201d.\nwith the help of nft the owner of the token will be able to confirm the ipr for the video.\nour target audience - video content creators, influencers, celebrities, bloggers.\nthe planned monetization model is a one-time payment for checking/minting one video.\nproject design\nwe have developed a scalable architecture that consists of several modules:\nmodule for replacing faces on video\nit consists of machine learning algorithms written in python. there are 3 main parts:\ndata preparation\neach uploaded video is divided into frames, on each frame we detect the faces, process them in a certain way (align, improve the resolution) and use in next modules.\nmodel training\nfor each celebrity/user we train a model on the gpu using it's facet, which later allows you to replace faces almost instantly without any additional training.\nvideo merging\nusing the trained models, we replace faces on frames from uploaded video and generate a new video using various additional functions for color correction, quality improvement and etc.\nour main difference from other deepfake projects is that we have automated the process of creating videos as much as possible (you don't need a lot of manual work, just upload a video and thats it) and due to separate models for each user, we can almost instantly generate videos with high quality. also, it is possible to additionally train the model on specific video an get a better quality/resolution (for b2b requests).\nsmart contracts on okex blockchain that allows to mint and transfer nft tokens\nour contracts has all needed basic functions to work with nft tokens:\nminttokentoaddress(address owner, string memory metadatauri)\nallows you to mint a nft token.\ntransferfrom(address from, address to, uint256 tokenid)\nallows you to transfer any nft token on other address.\nimplementation of access control\nnft market\nallows you to list and sell created nft tokens. functions:\ncreatemarketitem(address nftcontract,uint256 tokenid,uint256 price)\ncreatemarketsale(address nftcontract,uint256 itemid)\nfetchmarketitems() public view returns (marketitem[] memory)\nfetchmynfts() public view returns (marketitem[] memory)\nsource code\nbackend\nwritten in golang for interacting with machine learning algorithms, implementing business logic and interacting with the blockchain.\nsource code\nfront-end\nimplemented on react.js.\ncurrent implemented workflow in the demo\nthe user uploads the video to the platform;\nwith the help of the face replacement module, the video is divided into frames, a faces is detected on each frame. using a machine learning model, this faces are replaced by another and then a new video is generated;\nnext step is to upload the generated video to ipfs storage;\nthen the link to the video in ipfs storage and additional information (name, description) is sent to the smart contract to create an ntf token. the token can be transferred, sold.\nroadmap\nwe plan to further develop the platform. the current demo version is more for testing puprposes, so it's ui/ux is a little bit complex. in production version the interface will be much simpler and easy to use, i.e. user will be only needed to upload a video, choose face, pay fee and faceswap video will be automatically generated along with nft token. we already have a design for production version and working on frontend/backend for further updates.\ncreate a personal account for celebrities / users, where they can:\nupload a video with their face and get a model to replace faces in any video;\nbe able to accept orders for the replacement from companies;\nadd support for copying voice and lips synchronization based on audio.\nnew user - dashboard\nnew user - create step 1\nexisting user face digitalization - faceset\ncreate a personal account for business with the ability to:\nupload the video and select the person to replace the face / voice;\nor just send your script and we will record the video ourselves;\nbuy nft token of generated video.\nbusiness - create step 1\nbusiness - create step 2\nimprove the structure of smart contracts:\nso that user can transfer rights to use his face;\nsmart contract for nft shop.\nupdate machine learning algorythms:\ntrain models with higher resolution. current resolution is 320px, it is possible to improve it up to 448-640px, i.e. quality boost in 1.5-2x times.\nfix problems with artifacts during fast head movement and different lighting/color gradation, improve face detection algorithms.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59504016}, {"Unnamed: 0": 4097, "autor": "Trail Buddies", "date": null, "content": "Inspiration\nUse cell phone data to manage, monitor, and analyze visitor activity in the parks. We are going to use R to plot cell-phone ping data as provided by the dlnr to show visitor traffic within park boundaries.\nWhat it does\nOur app shows traffic along Hawaii hiking trails using location data from mobile phones.\nHow we built it\nWe looked for open source utilities that could plot geodata, and found that R was well suited for our needs. We used the state of Hawaii's ARCGIS data, that is publicly available to render maps of hawaii, trails, and park boundaries. Lastly, we plotted the cell phone ping data that was provided by the DLNR.\nChallenges we ran into\nSome major challenges we ran into were time, handling geodata, and shape files. Another challenge that we faced was plotting kml data.\nAccomplishments that we're proud of\nLearning to code in R and creating professional looking maps was certainly something to be proud of, seeing all of that raw code turned to images and maps was an amazing accomplishment.\nWhat we learned\nWe learned that Hawaii has tons of geographical data for parks, that we can transfer easily to polygon python code, and build layers of code over it to display the data and maps together.\nWhat's next for w-h-s bulldogs 2021\nIf we make it to the next round, we plan to increase our capability, and add a new function that is built on the R.", "link": "https://devpost.com/software/w-h-s-bulldogs-2021", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nuse cell phone data to manage, monitor, and analyze visitor activity in the parks. we are going to use r to -----> plot !!!  cell-phone ping data as provided by the dlnr to show visitor traffic within park boundaries.\nwhat it does\nour app shows traffic along hawaii hiking trails using location data from mobile phones.\nhow we built it\nwe looked for open source utilities that could plot geodata, and found that r was well suited for our needs. we used the state of hawaii's arcgis data, that is publicly available to render maps of hawaii, trails, and park boundaries. lastly, we plotted the cell phone ping data that was provided by the dlnr.\nchallenges we ran into\nsome major challenges we ran into were time, handling geodata, and shape files. another challenge that we faced was plotting kml data.\naccomplishments that we're proud of\nlearning to code in r and creating professional looking maps was certainly something to be proud of, seeing all of that raw code turned to images and maps was an amazing accomplishment.\nwhat we learned\nwe learned that hawaii has tons of geographical data for parks, that we can transfer easily to polygon python code, and build layers of code over it to display the data and maps together.\nwhat's next for w-h-s bulldogs 2021\nif we make it to the next round, we plan to increase our capability, and add a new function that is built on the r.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 1, "media": null, "medialink": null, "identifyer": 59504097}, {"Unnamed: 0": 4181, "autor": "GEANT4 Particle Identification using ML Algorithms", "date": null, "content": "Background\nGEANT4\nGEANT4 (Geometry and Tracking) is a platform for the simulation of the passage of particles through matter using Monte Carlo methods.\nMore information: https://en.wikipedia.org/wiki/Geant4\nPreparing the Dataset\nThe following dataset is from a simplified GEANT4 based simulation of electron-proton inelastic scattering measured by a particle detector system.\nExploring the Dataset\nThere are a total of 7 columns. The id column identifies the particle (e.g., positron (-11), pion (211), kaon (321) and proton (2212)). The p column is momentum in GeV/c. The theta and beta columns are angles in radians. The nphe column is the number of photoelectrons. The ein column is the inner energy (GeV). The eout column is the outer energy (GeV).\nBeta vs. Momentum\nThe Beta vs. Momentum plot shows the relationship between the \u03b2 measured by the ToF system and the momentum, p obtained from TPC. The visible bands are from e+ (positron), \u03c0+ (pion), K- (kaon), and p (proton).\nk-Nearest Neighbors (k-NN)\nThe k-nearest neighbors algorithm (k-NN) is a non-parametric classification method. For a classification problem, the input consists of the k closest training examples in a data set. The output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors. If k=1, then the object is simply assigned to the class of that single nearest neighbor.\nMore information: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\nRandom Forests\nRandom forests or random decision forests are an ensemble learning method for tasks that operate by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. Random forests correct for decision trees' habit of overfitting to their training set.\nMore information: https://en.wikipedia.org/wiki/Random_forest\nMultilayer Perceptron (MLP)\nA multilayer perceptron (MLP) is a class of feedforward artifical neural network (ANN). An MLP consists of at least three layers of nodes, an input layer, a hidden layer, and an output layer. Except for the input nodes, each node is a neuron that uses nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. The ReLU activation function was used in this project.\nMore information: https://en.wikipedia.org/wiki/Multilayer_perceptron", "link": "https://devpost.com/software/geant4-particle-identification-using-ml-algorithms", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "background\ngeant4\ngeant4 (geometry and tracking) is a platform for the simulation of the passage of particles through matter using monte carlo methods.\nmore information: https://en.wikipedia.org/wiki/geant4\npreparing the dataset\nthe following dataset is from a simplified geant4 based simulation of electron-proton inelastic scattering measured by a particle detector system.\nexploring the dataset\nthere are a total of 7 columns. the id column identifies the particle (e.g., positron (-11), pion (211), kaon (321) and proton (2212)). the p column is momentum in gev/c. the theta and beta columns are angles in radians. the nphe column is the number of photoelectrons. the ein column is the inner energy (gev). the eout column is the outer energy (gev).\nbeta vs. momentum\nthe beta vs. momentum -----> plot !!!  shows the relationship between the \u03b2 measured by the tof system and the momentum, p obtained from tpc. the visible bands are from e+ (positron), \u03c0+ (pion), k- (kaon), and p (proton).\nk-nearest neighbors (k-nn)\nthe k-nearest neighbors algorithm (k-nn) is a non-parametric classification method. for a classification problem, the input consists of the k closest training examples in a data set. the output is a class membership. an object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors. if k=1, then the object is simply assigned to the class of that single nearest neighbor.\nmore information: https://en.wikipedia.org/wiki/k-nearest_neighbors_algorithm\nrandom forests\nrandom forests or random decision forests are an ensemble learning method for tasks that operate by constructing a multitude of decision trees at training time. for classification tasks, the output of the random forest is the class selected by most trees. random forests correct for decision trees' habit of overfitting to their training set.\nmore information: https://en.wikipedia.org/wiki/random_forest\nmultilayer perceptron (mlp)\na multilayer perceptron (mlp) is a class of feedforward artifical neural network (ann). an mlp consists of at least three layers of nodes, an input layer, a hidden layer, and an output layer. except for the input nodes, each node is a neuron that uses nonlinear activation function. mlp utilizes a supervised learning technique called backpropagation for training. the relu activation function was used in this project.\nmore information: https://en.wikipedia.org/wiki/multilayer_perceptron", "sortedWord": "None", "removed": "Nan", "score": 5, "comments": 1, "media": null, "medialink": null, "identifyer": 59504181}, {"Unnamed: 0": 4200, "autor": "Meteorite Plotting Project", "date": null, "content": "Inspiration\nNASA has a lot of astronomical data available to the public online, and while looking at it, we found a very interesting data set relating to meteorite data from all over the world. We decided we wanted to try and find a good way to visualize it, with an interactive globe and plotted points representing each individual meteorite landing.\nWhat it does\nIt gives a visual representation of the NASA meteorite landing data, so you can better understand the distribution of meteor landings on Earth.\nHow we built it\nWe created a Google Colab notebook and used Python's plotly libraries to create a 3D surface model of the Earth with plotted points atop it.\nChallenges we ran into\nThe data set was quite large, and one of the issues was that the geolocation data (latitude/longitude) was in one column together. To solve this, we found a way to split the column in two, to make it easier for data processing.\nAccomplishments that we're proud of\nOnce we got the basic globe down and plotted a few test points, bringing together all of the data from the data set and actually getting it plotted was quite the accomplishment. It is quite cool being able to look at all these individual bits of data and imagine that each was a meteorite landing.\nWhat we learned\nWe all learned a very interesting way to plot this kind of location data. Instead of just looking at numbers in a spreadsheet, we have the opportunity to really look at how the landings are distributed around the globe and how this sort of visual representation can be very valuable in examining these kinds of data sets.\nWhat's next for Meteorite Plotting Project\nWe have all the data plotted, but one addition we could make would be to also keep the landing data alongside the coordinates. With some tweaks, that would mean that while looking at all these data points, you could hover over them individually to perhaps examine some of them in closer detail (date of landing, name of meteorite, etc). It would mean just another way to interact with the data in a meaningful manner.", "link": "https://devpost.com/software/meteorite-plotting-project", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nnasa has a lot of astronomical data available to the public online, and while looking at it, we found a very interesting data set relating to meteorite data from all over the world. we decided we wanted to try and find a good way to visualize it, with an interactive globe and plotted points representing each individual meteorite landing.\nwhat it does\nit gives a visual representation of the nasa meteorite landing data, so you can better understand the distribution of meteor landings on earth.\nhow we built it\nwe created a google colab notebook and used python's plotly libraries to create a 3d surface model of the earth with plotted points atop it.\nchallenges we ran into\nthe data set was quite large, and one of the issues was that the geolocation data (latitude/longitude) was in one column together. to solve this, we found a way to split the column in two, to make it easier for data processing.\naccomplishments that we're proud of\nonce we got the basic globe down and plotted a few test points, bringing together all of the data from the data set and actually getting it plotted was quite the accomplishment. it is quite cool being able to look at all these individual bits of data and imagine that each was a meteorite landing.\nwhat we learned\nwe all learned a very interesting way to -----> plot !!!  this kind of location data. instead of just looking at numbers in a spreadsheet, we have the opportunity to really look at how the landings are distributed around the globe and how this sort of visual representation can be very valuable in examining these kinds of data sets.\nwhat's next for meteorite plotting project\nwe have all the data plotted, but one addition we could make would be to also keep the landing data alongside the coordinates. with some tweaks, that would mean that while looking at all these data points, you could hover over them individually to perhaps examine some of them in closer detail (date of landing, name of meteorite, etc). it would mean just another way to interact with the data in a meaningful manner.", "sortedWord": "None", "removed": "Nan", "score": 5, "comments": 0, "media": null, "medialink": null, "identifyer": 59504200}, {"Unnamed: 0": 4233, "autor": "Farming Simulator", "date": null, "content": "Inspiration\nWe were inspired to teach kids about the complexities of agriculture, specifically because of its large impact on the society of North Carolina\nWhat it does\nOur game lets you simulate being a small farmer. You are faced with some real-life decisions like choosing which crop to plant, and whether or not to use GMO's. You can move your character around to work the land and eventually grow crops.\nHow we built it\nWe used pygame library and python to build this project. We also imported some images and sounds.\nChallenges we ran into\nOne of our largest roadblocks was after making the grid that represents plots of land, we were unable to store the \"state\" of each plot. For example, we could till a specific plot, but we could not till multiple plots. We were able to surpass this problem by using a 2d array. It was also difficult in general because some of our team members were new to python and pygame.\nAccomplishments that we're proud of\nWe are very proud of the artwork created by our team member Celina Chung.\nWhat we learned\nWe learned how to use some python-specific operations and concepts by using mu editor and the pygame zero libary.\nWhat's next for Farming Simulator\nThere\u2019s a weather icon at the top. When it\u2019s raining, we want to make it so that it automatically waters all of the crops. Multiple different crops worth different points Gather crops in inventory. Sell them later in a market. Add animals to feed.T In the future, we hope to implement minigames such as fighting invasive pests that pop up in your crops.", "link": "https://devpost.com/software/farming-simulator", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwe were inspired to teach kids about the complexities of agriculture, specifically because of its large impact on the society of north carolina\nwhat it does\nour game lets you simulate being a small farmer. you are faced with some real-life decisions like choosing which crop to plant, and whether or not to use gmo's. you can move your character around to work the land and eventually grow crops.\nhow we built it\nwe used pygame library and python to build this project. we also imported some images and sounds.\nchallenges we ran into\none of our largest roadblocks was after making the grid that represents plots of land, we were unable to store the \"state\" of each -----> plot !!! . for example, we could till a specific plot, but we could not till multiple plots. we were able to surpass this problem by using a 2d array. it was also difficult in general because some of our team members were new to python and pygame.\naccomplishments that we're proud of\nwe are very proud of the artwork created by our team member celina chung.\nwhat we learned\nwe learned how to use some python-specific operations and concepts by using mu editor and the pygame zero libary.\nwhat's next for farming simulator\nthere\u2019s a weather icon at the top. when it\u2019s raining, we want to make it so that it automatically waters all of the crops. multiple different crops worth different points gather crops in inventory. sell them later in a market. add animals to feed.t in the future, we hope to implement minigames such as fighting invasive pests that pop up in your crops.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59504233}, {"Unnamed: 0": 4283, "autor": "General Relativistic Three-Body Simulator", "date": null, "content": "Inspiration\nFelipe Fontinele was the main person responsible for motivating us to participate on the McGill Physics Hackathon and for giving and developing the main physical ideas for the project. He's our inspiration :)\nWhat it does\nSOURCE CODE AT link\nWelcome to our relativistic interactive three body problem simulation project for McGill Physics Hackathon 2021! Here, we implement Post-Newtonian general relativistic corrections to the orbits of each body. In addition, we also obtain gravitational waves for some orbit configurations in an intuitive interface built with PyQT5.\nWe've made one interactive window so that you can focus primarily on the physics. You can select one of our preconfigured orbits (from stable and famous configurations such as the figure 8 to marginally stable (M) and unstable orbits (U)) in the first box of our panel. The code takes about 10-30 seconds to solve the differential equations and plot it on the main panel. You can then watch the simulation until the end, or select \"Stop simulation\" to test other configurations.\nIn the main panel, you'll be able to see the famous classical orbits obtained only from Newton's equations of gravity side-by-side with the orbits obtained with the relativistic corrections via the Einstein\u2013Infeld\u2013Hoffmann equations. The orbit plots aren't fixed in order to encourage exploring different points of view from the orbits: just click and drag the mouse around the orbits in each plot.\nFor more information about the theoretical background, take a look at our website.\nHow we built it\nThe program was developed using python3. The main structure is based on solving both the Newtonian and Post-Newtonian equations of motion for planet's orbits using the scipy solve_ivp built-in function. All the user interface was developed via a mixture of matplotlib and PyQT5.\nChallenges we ran into\nObtaining the gravitational waves were quite challenging and Felipe was the main person responsible for all analytical/numerical derivations of the physics involved!\nThe implementation of the Einstein\u2013Infeld\u2013Hoffmann were also difficult to implement, but Felipe, Vitor and Igor managed to do an excellent job in the time that we had.\nSometimes the force in the simulation diverges when two bodies come very close to each other, effectively occupying the same space. We did implement a softening term to prevent the force from diverging, however the post newtonian correction terms still make the force explode quickly, sometimes (some newtonian orbits quickly diverge in the relativistic correction in these cases).\nAccomplishments that we're proud of\nThe implementation of the Post-Newtonian physics was quite challenging, and we did a pretty good job obtaining meaningful results in the 24-hour period. We are also quite proud of the user interface/website developed using PyQT5 by Jo\u00e3o Augusto and Pedro Cintra.\nWhat we learned\nWe learned a lot about solving differential equations and data visualization, and some of us (who did not have a gravitational background) had a lot of fun generating the new orbits and learning more about gravitational aspects of the problem :)\nJo\u00e3o and Pedro worked for the first time developing a user interface via PyQT5;\nWhat's next for General Relativistic Three-Body Simulator\nIntegration of the gravitational waves emission to the main interface;\nInvestigation of different methods for solving coupled differential equations of second order. In particular, we want to investigate the problem of convergence when planets are closer to each other in the Post-Newtonian implementation.\nWe'll probably continue exploring different facets of this problem in the following months. It was quite fun to work together once again after graduation on this hackathon :)", "link": "https://devpost.com/software/general-relativistic-three-body-simulator", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nfelipe fontinele was the main person responsible for motivating us to participate on the mcgill physics hackathon and for giving and developing the main physical ideas for the project. he's our inspiration :)\nwhat it does\nsource code at link\nwelcome to our relativistic interactive three body problem simulation project for mcgill physics hackathon 2021! here, we implement post-newtonian general relativistic corrections to the orbits of each body. in addition, we also obtain gravitational waves for some orbit configurations in an intuitive interface built with pyqt5.\nwe've made one interactive window so that you can focus primarily on the physics. you can select one of our preconfigured orbits (from stable and famous configurations such as the figure 8 to marginally stable (m) and unstable orbits (u)) in the first box of our panel. the code takes about 10-30 seconds to solve the differential equations and -----> plot !!!  it on the main panel. you can then watch the simulation until the end, or select \"stop simulation\" to test other configurations.\nin the main panel, you'll be able to see the famous classical orbits obtained only from newton's equations of gravity side-by-side with the orbits obtained with the relativistic corrections via the einstein\u2013infeld\u2013hoffmann equations. the orbit plots aren't fixed in order to encourage exploring different points of view from the orbits: just click and drag the mouse around the orbits in each plot.\nfor more information about the theoretical background, take a look at our website.\nhow we built it\nthe program was developed using python3. the main structure is based on solving both the newtonian and post-newtonian equations of motion for planet's orbits using the scipy solve_ivp built-in function. all the user interface was developed via a mixture of matplotlib and pyqt5.\nchallenges we ran into\nobtaining the gravitational waves were quite challenging and felipe was the main person responsible for all analytical/numerical derivations of the physics involved!\nthe implementation of the einstein\u2013infeld\u2013hoffmann were also difficult to implement, but felipe, vitor and igor managed to do an excellent job in the time that we had.\nsometimes the force in the simulation diverges when two bodies come very close to each other, effectively occupying the same space. we did implement a softening term to prevent the force from diverging, however the post newtonian correction terms still make the force explode quickly, sometimes (some newtonian orbits quickly diverge in the relativistic correction in these cases).\naccomplishments that we're proud of\nthe implementation of the post-newtonian physics was quite challenging, and we did a pretty good job obtaining meaningful results in the 24-hour period. we are also quite proud of the user interface/website developed using pyqt5 by jo\u00e3o augusto and pedro cintra.\nwhat we learned\nwe learned a lot about solving differential equations and data visualization, and some of us (who did not have a gravitational background) had a lot of fun generating the new orbits and learning more about gravitational aspects of the problem :)\njo\u00e3o and pedro worked for the first time developing a user interface via pyqt5;\nwhat's next for general relativistic three-body simulator\nintegration of the gravitational waves emission to the main interface;\ninvestigation of different methods for solving coupled differential equations of second order. in particular, we want to investigate the problem of convergence when planets are closer to each other in the post-newtonian implementation.\nwe'll probably continue exploring different facets of this problem in the following months. it was quite fun to work together once again after graduation on this hackathon :)", "sortedWord": "None", "removed": "Nan", "score": 66, "comments": 6, "media": null, "medialink": null, "identifyer": 59504283}, {"Unnamed: 0": 4335, "autor": "Is social distancing effective?", "date": null, "content": "By: Team Z&W\nTeam members: Jessica Zhu and Eve Wang\nInspiration\nInspired by current pandemic situations, we wanted to test the effectiveness of 2m social distancing in preventing COVID19 transmission.\nWhat it does\nUsing random walk, we modelled and simulated the 3D Brownian motion of airborne viruses and estimated the probability of a person 2m away from an infected individual coming into contact with airborne viral molecules.\nHow we built it\nThe program was written in Python using libraries such as NumPy and Matplotlib. Nested loops were used to run the simulation for 1000 viral molecules for a 2hr duration.\nChallenges we ran into\nOne challenge was generating the data necessary to create a 3D plot. We solved this problem by generating a random integers from a range of 3 possible choice with each integer representing the direction of movement for the random motion of the virus. The steps were continuously added to a position variable. A NumPy array was used to store the position of the virus at every step for each of the x, y, and z axes.\nAccomplishments that we're proud of\nWe're very proud of the program that had successfully simulated the airborne viral motion and generated the necessary plots. We're also really happy to say that our estimation for the probability of infection of an individual 2m away is about 2-8% and is in line with what other researches have found which goes to show the accuracy of our model.\nWhat we learned\nWe've learned a great deal about generating 3D simulation and using NumPy arrays.\nWhat's next?\nNext steps would be to make the program more efficient and to simulate it under a more realistic conditions (i.e. what happens when ventilation is introduced, or if masks are worn etc.)\nImplementation\nWe were able to implement the probabilities calculated for individuals wearing masks as well. For example, a person wearing a N95 mask (filters at least 95% of aerosols) standing 1m away from an infected individual, reduces their chances of being contracting COVID from 52% to 3%.", "link": "https://devpost.com/software/is-social-distancing-effective", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "by: team z&w\nteam members: jessica zhu and eve wang\ninspiration\ninspired by current pandemic situations, we wanted to test the effectiveness of 2m social distancing in preventing covid19 transmission.\nwhat it does\nusing random walk, we modelled and simulated the 3d brownian motion of airborne viruses and estimated the probability of a person 2m away from an infected individual coming into contact with airborne viral molecules.\nhow we built it\nthe program was written in python using libraries such as numpy and matplotlib. nested loops were used to run the simulation for 1000 viral molecules for a 2hr duration.\nchallenges we ran into\none challenge was generating the data necessary to create a 3d -----> plot !!! . we solved this problem by generating a random integers from a range of 3 possible choice with each integer representing the direction of movement for the random motion of the virus. the steps were continuously added to a position variable. a numpy array was used to store the position of the virus at every step for each of the x, y, and z axes.\naccomplishments that we're proud of\nwe're very proud of the program that had successfully simulated the airborne viral motion and generated the necessary plots. we're also really happy to say that our estimation for the probability of infection of an individual 2m away is about 2-8% and is in line with what other researches have found which goes to show the accuracy of our model.\nwhat we learned\nwe've learned a great deal about generating 3d simulation and using numpy arrays.\nwhat's next?\nnext steps would be to make the program more efficient and to simulate it under a more realistic conditions (i.e. what happens when ventilation is introduced, or if masks are worn etc.)\nimplementation\nwe were able to implement the probabilities calculated for individuals wearing masks as well. for example, a person wearing a n95 mask (filters at least 95% of aerosols) standing 1m away from an infected individual, reduces their chances of being contracting covid from 52% to 3%.", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 0, "media": null, "medialink": null, "identifyer": 59504335}, {"Unnamed: 0": 4351, "autor": "Cars.com Web Scraper", "date": null, "content": "Inspiration\nVisualization is key to attack the market. It helps focus our valuable resources in the right direction. I wanted to create a product that will help provide more clarity about the market.\nWhat it does\nIt plots car listings on a map obtained from scraping cars.com\nHow I built it\nI first started building the scraper with beautifulsoup. I also used geocoding to gather lat and long co-ordinates for each listing. Then, I accumulated the data in a CSV file. After that, I started to look for map plotting libraries and found leaflet. I extracted data from CSV using PapaParse and used it to plot the markers. To package everything neatly, I uploaded all the changes to git and implemented html templates for finishing touches.\nChallenges we ran into\nJs doesn't come with a CSV parser so I had to spend some time looking for Papaparse. One of the mentors Tristan suggested me to use it. I also tried hosting the project on digital ocean but couldn't do it.\nAccomplishments that we're proud of\nI am very proud about implementing the scraper using bs4. My scraper was so powerful that cars.com banned my IP :P which is why I had to use proxysite in my demo video.\nWhat's next for Cars.com Web Scraper\nCreating unique graphs and a nice dashboard. Adding more used car websites.", "link": "https://devpost.com/software/cars-com-web-scraper", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nvisualization is key to attack the market. it helps focus our valuable resources in the right direction. i wanted to create a product that will help provide more clarity about the market.\nwhat it does\nit plots car listings on a map obtained from scraping cars.com\nhow i built it\ni first started building the scraper with beautifulsoup. i also used geocoding to gather lat and long co-ordinates for each listing. then, i accumulated the data in a csv file. after that, i started to look for map plotting libraries and found leaflet. i extracted data from csv using papaparse and used it to -----> plot !!!  the markers. to package everything neatly, i uploaded all the changes to git and implemented html templates for finishing touches.\nchallenges we ran into\njs doesn't come with a csv parser so i had to spend some time looking for papaparse. one of the mentors tristan suggested me to use it. i also tried hosting the project on digital ocean but couldn't do it.\naccomplishments that we're proud of\ni am very proud about implementing the scraper using bs4. my scraper was so powerful that cars.com banned my ip :p which is why i had to use proxysite in my demo video.\nwhat's next for cars.com web scraper\ncreating unique graphs and a nice dashboard. adding more used car websites.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59504351}, {"Unnamed: 0": 4420, "autor": "Space Casino", "date": null, "content": "Inspiration\nThe theme was space and we got a pack of cards in out TigerHacks merchandise that said casino quality cards.\nWhat it does\nIt lets you play casino games with an intriguing plot thrown in.\nHow we built it\nWe tried using java script initially, but only one of us knew how to use it. We then thought pygames might be the route, but again, only one of us could use python. So we ended up just coding it entirely in C.\nChallenges we ran into\nAs previously mentioned, there was a language barrier as only one of us could use java script and only one could use python. After that, the main problem we ran into is that C is a hard language to use.\nAccomplishments that we're proud of\nThe poker opponents respond well to player input in a unique and intelligent way. The ASCII art cards are also pretty.\nWhat we learned\nBetter ways of dealing with C's antiquity.\nWhat's next for Space Casino\nThe recycle bin.", "link": "https://devpost.com/software/space-casino", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nthe theme was space and we got a pack of cards in out tigerhacks merchandise that said casino quality cards.\nwhat it does\nit lets you play casino games with an intriguing -----> plot !!!  thrown in.\nhow we built it\nwe tried using java script initially, but only one of us knew how to use it. we then thought pygames might be the route, but again, only one of us could use python. so we ended up just coding it entirely in c.\nchallenges we ran into\nas previously mentioned, there was a language barrier as only one of us could use java script and only one could use python. after that, the main problem we ran into is that c is a hard language to use.\naccomplishments that we're proud of\nthe poker opponents respond well to player input in a unique and intelligent way. the ascii art cards are also pretty.\nwhat we learned\nbetter ways of dealing with c's antiquity.\nwhat's next for space casino\nthe recycle bin.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59504420}, {"Unnamed: 0": 4493, "autor": "Spotify Query", "date": null, "content": "Project Details\nWe created a user interface to generate visualizations describing the music of Spotify artists. The user inputs an artist and is then able to easily plot parameters of the music. Some of the parameters include:\nSong duration Publication date Tempo (beats per minute) Energy (perceptual measure of intensity/activity) Valence (how positive/negative a song is)\nWhat We Learned\nAfter struggling to get things deployed, we spent a majority of our time trying to style things so that they looked half decent. There is still quite a bit of work to do in this area:\nWorking with API\u2019s Working with keys and tokens HTML, CSS, web development Working with Git Deploying products Managing websites Working with data frames A little bit of music theory\nChallenges We Ran Into\nThe majority of the day went surprisingly smoothly until it came to styling the webpage. After much frustration, we got something that our team is proud of. Challenges: Styling the website Figuring out what services are needed to deploy the web app and website Our lack of understanding of Git came back to haunt us Parsing messy data Edge cases when using the API\nAccomplishments\nWe got a web app off of the ground in less than a day and got a pretty good application tacked onto. The tool used here is something that we can definitely see ourselves using in the future, not only to compare songs by an artist but also to find similar songs by other artists.\nWe also learned an absolute ton about web development as well as a bunch of other useful technologies. Interfacing with an API and being able to use the Dash framework will definitely come in useful in the future.", "link": "https://devpost.com/software/spotify-query", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "project details\nwe created a user interface to generate visualizations describing the music of spotify artists. the user inputs an artist and is then able to easily -----> plot !!!  parameters of the music. some of the parameters include:\nsong duration publication date tempo (beats per minute) energy (perceptual measure of intensity/activity) valence (how positive/negative a song is)\nwhat we learned\nafter struggling to get things deployed, we spent a majority of our time trying to style things so that they looked half decent. there is still quite a bit of work to do in this area:\nworking with api\u2019s working with keys and tokens html, css, web development working with git deploying products managing websites working with data frames a little bit of music theory\nchallenges we ran into\nthe majority of the day went surprisingly smoothly until it came to styling the webpage. after much frustration, we got something that our team is proud of. challenges: styling the website figuring out what services are needed to deploy the web app and website our lack of understanding of git came back to haunt us parsing messy data edge cases when using the api\naccomplishments\nwe got a web app off of the ground in less than a day and got a pretty good application tacked onto. the tool used here is something that we can definitely see ourselves using in the future, not only to compare songs by an artist but also to find similar songs by other artists.\nwe also learned an absolute ton about web development as well as a bunch of other useful technologies. interfacing with an api and being able to use the dash framework will definitely come in useful in the future.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59504493}, {"Unnamed: 0": 4615, "autor": "Text Based RPG", "date": null, "content": "Inspiration\nOur project was inspired by text based RPGs of old like Colossal Cave Adventures and the overarching theme of \u201cBetter Together\u201d as we felt that it would be a simple but effective design to fulfill our purposes.\nWhat it does\nIt serves as entertainment as the player must make choices in order to progress the story or meet their untimely demise. There are multiple endings, some more satisfying than others and some that are clearly better than others in terms of character development for our protagonist. The true ending has a not so subtle moral to it.\nHow we built it\nWe used the C++ language and Rep.lit to collaborate. First, we wrote up a script for most of the decisions, then we had our coders implement decision making gameplay and combat.\nChallenges we ran into\nInitially we had to decide on a story for our project to even begin the development, we couldn\u2019t pick a difficult or long winded storyline despite the fact that it would make it far more interesting to follow. We had to decide on a plot that was simple and easy to understand. So why not the daily adventures of a hunter living out in the wilds alone?\nAccomplishments that we're proud of\nWe switched project ideas halfway when we realized it was really difficult to learn a new coding language in such a short amount of time, so a lot of us are proud of the fact that we adapted quickly to make up for the lost time.\nWhat we learned\nWe learned to adapt quickly and communicate with one another in order to reliably and quickly finish the project despite our earlier hiccups. At some point some of us thought we wouldn\u2019t be able to finish in time and that was a scary thought so we\u2019re not gonna talk about it. But we\u2019re glad we did in time.\nWhat's next for Text Based RPG\nFor any updates, we would likely expand on the story and go more in depth with each character\u2019s personality. Also, our dear protagonist will be voiced by Chris Pratt. As well as the story, we\u2019d likely make the combat system more diverse and strategic. Finally, we\u2019d like to add more unique gameplay mechanics to break up the monotony of simply making simple decisions/", "link": "https://devpost.com/software/hackathon-team-matchmaking-software", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nour project was inspired by text based rpgs of old like colossal cave adventures and the overarching theme of \u201cbetter together\u201d as we felt that it would be a simple but effective design to fulfill our purposes.\nwhat it does\nit serves as entertainment as the player must make choices in order to progress the story or meet their untimely demise. there are multiple endings, some more satisfying than others and some that are clearly better than others in terms of character development for our protagonist. the true ending has a not so subtle moral to it.\nhow we built it\nwe used the c++ language and rep.lit to collaborate. first, we wrote up a script for most of the decisions, then we had our coders implement decision making gameplay and combat.\nchallenges we ran into\ninitially we had to decide on a story for our project to even begin the development, we couldn\u2019t pick a difficult or long winded storyline despite the fact that it would make it far more interesting to follow. we had to decide on a -----> plot !!!  that was simple and easy to understand. so why not the daily adventures of a hunter living out in the wilds alone?\naccomplishments that we're proud of\nwe switched project ideas halfway when we realized it was really difficult to learn a new coding language in such a short amount of time, so a lot of us are proud of the fact that we adapted quickly to make up for the lost time.\nwhat we learned\nwe learned to adapt quickly and communicate with one another in order to reliably and quickly finish the project despite our earlier hiccups. at some point some of us thought we wouldn\u2019t be able to finish in time and that was a scary thought so we\u2019re not gonna talk about it. but we\u2019re glad we did in time.\nwhat's next for text based rpg\nfor any updates, we would likely expand on the story and go more in depth with each character\u2019s personality. also, our dear protagonist will be voiced by chris pratt. as well as the story, we\u2019d likely make the combat system more diverse and strategic. finally, we\u2019d like to add more unique gameplay mechanics to break up the monotony of simply making simple decisions/", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59504615}, {"Unnamed: 0": 4688, "autor": "Is The Coffee Pot Full?", "date": null, "content": "Inspiration\nGraduate Students in Computer Science are very busy and are constantly on the lookout for means of increased efficiency in their daily lives. This project aims to increase efficiency by saving the up to 3 minutes of effort required to walk down the hallway to the break room to see if there's coffee available. Our project pays homage to the University of Cambridge's Trojan Room coffee pot (https://en.wikipedia.org/wiki/Trojan_Room_coffee_pot), but is implemented to view a much cooler Computer Science department's coffee dispensing apparatus.\nWhat it does\nInstead of exerting the effort of walking all the way down the hall, we may simply check a website with a livestream of the coffee pot along with some built-in image processing to let us know that yes, The Coffee Pot Is Full. The webserver also uses image processing to estimate the amount of coffee left and plots a time history of the most recent coffee pot levels. Furthermore, we have text notifications enabled to alert users when certain conditions are met.\nHow we built it\nOur domain name of ksucscoffeepot.tech was registered using Domain.com and we have a webserver running on a Linode instance. Our Raspberry Pi is using the PiCamera library to continually capture images via its serial camera. Our Raspberry Pi is connecting to our webserver using a Python socket and streaming the camera feed to our webserver. The webserver is running code which crops the image to focus on the coffee pot, turns the image to grayscale, and then computes a threshold filter on the image effectively counting the number of dark pixels over light pixels. The more dark pixels in the processed image, the more full the coffee pot is. Our webserver is populating a MySQL database with time stamped data to allow a \"coffee quantity over time\" graph to be generated in real time and displayed on our website. Our website automatically refreshes every 5 seconds so you can always get an accurate, up-to-date status of the Computer Science department's coffeepot without having to leave the comfort of your own desk! Most importantly, due to integration with Twilio, the webserver will text the nearest PhD student to the CS coffeepot (Scott) when it needs some attention (aka refilling).\nChallenges we ran into\nNetworking: It was tough to get all the parts talking, especially at the start to get the image off the Pi and onto the webserver (though none of us have strong web dev skills).\nImage Processing: The method relies on a calibration routine which must be redone if the camera view or ambient lighting changes.\nDatabase: Getting the MySQL database running and populated wasn't too bad, but it was done with no prior knowledge of such a task.\nAccomplishments that we're proud of\nIt works! Do a lot of work now to save a tiny amount of work later!\nWhat we learned\nGeneral topics we gained experience with: Twilio, Networking, Webservers, Databases\nWhat's next for Is The Coffee Pot Full?\nThere probably isn't much more work we will do, but here is our current wishlist of unimplemented features:\nImprove image processing calibration to account for irregular carafe profile, glares, and lighting levels\nMake the webpage look nice\nContinue to tweak the plot for readability", "link": "https://devpost.com/software/is-the-coffee-pot-full", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\ngraduate students in computer science are very busy and are constantly on the lookout for means of increased efficiency in their daily lives. this project aims to increase efficiency by saving the up to 3 minutes of effort required to walk down the hallway to the break room to see if there's coffee available. our project pays homage to the university of cambridge's trojan room coffee pot (https://en.wikipedia.org/wiki/trojan_room_coffee_pot), but is implemented to view a much cooler computer science department's coffee dispensing apparatus.\nwhat it does\ninstead of exerting the effort of walking all the way down the hall, we may simply check a website with a livestream of the coffee pot along with some built-in image processing to let us know that yes, the coffee pot is full. the webserver also uses image processing to estimate the amount of coffee left and plots a time history of the most recent coffee pot levels. furthermore, we have text notifications enabled to alert users when certain conditions are met.\nhow we built it\nour domain name of ksucscoffeepot.tech was registered using domain.com and we have a webserver running on a linode instance. our raspberry pi is using the picamera library to continually capture images via its serial camera. our raspberry pi is connecting to our webserver using a python socket and streaming the camera feed to our webserver. the webserver is running code which crops the image to focus on the coffee pot, turns the image to grayscale, and then computes a threshold filter on the image effectively counting the number of dark pixels over light pixels. the more dark pixels in the processed image, the more full the coffee pot is. our webserver is populating a mysql database with time stamped data to allow a \"coffee quantity over time\" graph to be generated in real time and displayed on our website. our website automatically refreshes every 5 seconds so you can always get an accurate, up-to-date status of the computer science department's coffeepot without having to leave the comfort of your own desk! most importantly, due to integration with twilio, the webserver will text the nearest phd student to the cs coffeepot (scott) when it needs some attention (aka refilling).\nchallenges we ran into\nnetworking: it was tough to get all the parts talking, especially at the start to get the image off the pi and onto the webserver (though none of us have strong web dev skills).\nimage processing: the method relies on a calibration routine which must be redone if the camera view or ambient lighting changes.\ndatabase: getting the mysql database running and populated wasn't too bad, but it was done with no prior knowledge of such a task.\naccomplishments that we're proud of\nit works! do a lot of work now to save a tiny amount of work later!\nwhat we learned\ngeneral topics we gained experience with: twilio, networking, webservers, databases\nwhat's next for is the coffee pot full?\nthere probably isn't much more work we will do, but here is our current wishlist of unimplemented features:\nimprove image processing calibration to account for irregular carafe profile, glares, and lighting levels\nmake the webpage look nice\ncontinue to tweak the -----> plot !!!  for readability", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59504688}, {"Unnamed: 0": 4877, "autor": "Matic Mike", "date": null, "content": "A Quick Note\nThe project is now fully in production with almost 660 unique wallets holding NFTs. I listed staging environment links on the mumbai testnet, however for full user experience some updates have been pushed directly to production. If judges need a production Matic Mike and don't want to buy one on the opensea aftermarket, please let me know so I can send one of mine.\nLink to Production Site\nLink to Staging\n$HGH ERC20 Testnet, Use #15 openFaucet for test $HGH\nInspiration\nMatic Mike was inspired by other high utility NFT projects in the space that are 100% on chain. I wanted to make something special that is fully on chain with no api, but also have a full functioning and easy to use interface for everyone to enjoy. The goal here is not only to release a fun, free project, but also to show how dynamic the NFT space can be, ranging from pure artwork to a full-scale collectibles game with it's own ecosystem.\nYou can read a full rundown and guide of the current release here.\nWhat it does\nFull 25 minute detailed overview video\nMatic Mike is a free, 100% on-chain generative ERC721 NFT game on the Polygon network with a Polygon <-> Ethereum bridge, and is accompanied by a fully compliant ERC20 Token, Matic Mike Juice ($HGH) with a Polygon <-> Ethereum bridge as well.\nAs stated, Matic Mike is a 100% on chain generated NFT. When I say 100%, I mean 100% as each Mike's traits are chosen on mint, and drawn out pixel by pixel on chain. Every trait has a power level associated with it, with each Mike having their own power level associated with them. Power levels are used in all the gaming functionality which I'll explain further down the line.\nProblems it Solves\nThere's a few problems in the NFT space this project provides a resolution to. The first and most obvious is being fully on-chain. Having all metadata, including image, being stored fully on chain is basically a guarantee you will forever have access to the NFT.\nThe second is being able to dynamically modify metadata based on future project releases. In the data contract (which we can change the address of in the ERC721 contract if we need to make changes) I have an extension contract that queries and loops through for future contract additions. Things like fighting boss NFTs and receiving loot can be done totally on chain, and pull new data and graphics into the genesis NFT.\nAnother problem with high utility projects on L1 Ethereum is transaction fees. Being on Polygon with the ability to bridge over to Ethereum for certain aftermarket compatibility allows users the luxury of participating in the high utility of staking, withdrawing, token injections, minting and burn rerolls, as well as PvP battle royales without having to worry about spending more than a few pennies.\nThe Dance Royale specifically displays a system in which blockchain can be utilized in a fortnite style queueing system, with new queues opening as soon as the previous queue fills or is triggered via a time trigger. The actual functionality of the Dance Royale makes extreme use of Chainlink VRF.\nThe $HGH contract provides a new way to earn tokens by staking ERC721 tokens, with the ability to add any ERC721 Token into the ERC20 contract at different emission rates. This is something quite unique as I can add in other developers contracts for promotions or collaborations.\nFinally, the major thing this project shows is the ability to integrate a full-scale collectibles game without the need for any external / centralized API. Although chainlink provides a useful resource for communicating with centralized data, being fully decentralized was the goal of this project. Utilizing Chainlink VRF for the heavy use of random number generation was a necessity in the success of this project. Chainlink VRF in the upgrade & dance royale completion also prevents against potential flashbot misuse to revert calls if desired result is not met (just learned this today).\nThe Minting Process\nMatic Mike is now fully minted on the Polygon chain. To onboard interested users, I airdropped $1000 in MATIC to users who signed up for our whitelist for gas on the Polygon network. The mint price was as follows...\n1-2500: Free Mint (1 per whitelist, and once public sale was activated, up to 10 per wallet)\n2500-4000: 1 $HGH\n4000-6000: 2 $HGH\n6000-8000: 3 $HGH\n8000-10000: 4 $HGH\nAfter 2500, free \"Burn Rerolls\" were activated, allowing users to burn their mint and generate a new mint.\n$HGH and It's Uses\nLet's talk a little bit about $HGH and what it is used for in-game in Matic Mike NFT's present state. Before we get into the functions of $HGH, we should talk about how to earn $HGH. As stated, Matic Mike was a 100% free mint, and after 2500 used our new ERC20 token $HGH. To earn $HGH, you must have a Mike, and he is staked \"in the gym,\" also known as the $HGH contract, with an emissions rate of 1 $HGH over 24 hours per Matic Mike staked in the $HGH contract. The first feature was obviously the tokenized minting process, now let's take a look at the \"token injections.\"\nERC20 -> ERC721 Token Injection\nOne of the unique features about the Matic Mike NFT is the ability to dynamically modify traits all on-chain at the cost of $HGH. I call this \"Token Injection\" and it is the process of burning off $HGH for a small chance to upgrade the tier of rarity of a random trait. This was a feature included in our initial release 2 weeks ago. The cost to inject Matic Mike for a chance to upgrade started at 1 $HGH and increases on a global scale by 3 $HGH for every successful injection. Token injections have about a 5.5% success rate, and the $HGH used per attempt is burned from the circulating supply. I'll explain how this is built in the next section.\nThe PvP Battle Royale\nThe other current use of $HGH is our player vs player battle royale contract, also known as the \"Dance Royale.\" This is a rolling 50 man queue system done completely on-chain that costs 1 $HGH to enter, with the option of adding 0-5 additional $HGH for adding 1-10 power level per additional $HGH injected. The optional injection $HGH is burned from the circulating supply, while the entry fee is added to the pot for the current royale. Upon completion, the winner receives 70% of the royale pot, 2nd place receives 20%, and 3rd 10%.\nA complete log of analytics are stored in the PvP Dance Royale contract, and our Web Interface gives a nice look at individual token stats. Analytics for wallet address data is also stored on-chain, with plans to integrate a future contract with a \"name your wallet\" function and a custom uri slug on the website. This will give complete analytical history for addresses even if you sell or trade your Mike in the future.\nHow I built it\nThe short answer is solidity, html, javascript, web3, jquery, select2, bootstrap 5, discordjs, and nodejs for the ethereum bridge.\nThe chains include Polygon, Ethereum, as well as utilizing tons of Chainlink VRF functionality specifically in the utility features of ERC20->ERC721 token injection and Battle Royale contract.\nThe Long Answer\nThe Matic Mike NFT and Matic Mike Juice ($HGH) initial release was a total of 5 smart contracts.\nERC721: Matic Mike NFT\nERC20: $HGH Contract\nIntermediate Data Contract\nERC721 Bridge: Matic Mike NFT\nERC20 Bridge: $HGH Contract\nAnd the PvP Battle Royale Contract is one single contract, but 2 more contracts are planned in the near future for a more in-depth analytical look as well as the \"Name your Club\" contract.\nDance Royale Contract\nThe Matic Mike NFT Minting Process\nSimulate Minting Here\nLet's first start by getting into the minting process of the Matic Mike NFT. Every mint generates new unique metadata by looping through and generating 8 random numbers (this part does not utilize chainlink VRF so I could quickly return to the user) which are used to determine the rarity of each trait. Depending on where the number falls, it selects a number (0-9) of the trait and pieces together a \"hash\" or \"dna code\" for the token id. That DNA code and token ID is sent to the data contract when pulling the tokenURI or other read calls and the metadata is generated on demand.\nI also integrated the free \"burn rerolls\" which essentially sent the token id being burned to a dead address, and ran the same minting process over again. This is what pushed the mint to fully mint out very quickly. There are examples of all these functions in the 5 minute overview video.\nThe Data & Reading From the Data Contract\nLet's first start with how I populated the data. I store the data for each trait in a struct as follows...\nstruct Trait{\nstring traitName;\nstring traitType;\nstring pixels;\nuint256 pixelCount;\nuint8 powerLevel;\n}\nThis is pretty straight forward, but I should get into what the pixel string looks like, and how it works. Every \"pixels\" string is composed of each pixel by 4 characters, let's use the example ab23. The first 2 characters represent the x and y coordinates, encoded as a letter. so a = 0, and b = 1. This mean's I am plotting a pixel at 0,1. The last 2 characters represent a css class associated with the color. So I am plotting a pixel at 0,1 with a css class of \"c23\". I loop through each trait and plot these pixel strings during our calls. Because I do have such a large mapping of pixels, I also loaded full XML of pre-plotted data for the body and outfits.\nIt is worth noting, for further expansion I include this bit of code...\nif(xxlAddress != nullAddress){\nIMikeExtended.Traits[] memory XxlTraits = IMikeExtended(xxlAddress).getAllPlayerLoot(_tokenId);\nfor(uint256 i=0; i < XxlTraits.length; i++){\nif(XxlTraits[i].valid && XxlTraits[i].pixelCount > 0){\nsvgString = string(\nabi.encodePacked(\nsvgString,\nXxlTraits[i].pixels\n)\n);\n}\n}\n}\nThis is for our expansion projects, in which I'll be able to pull new graphics directly into the SVG string. Each additional trait will be plotted in 1 long string.\nThe ERC721 contract will call the data contract for tokenURI (which grabs the attributes and SVG, and base64 encodes for return) and power level inqueries.\nIt's worth noting, I drew everything out in photoshop, then mapped everything out pixel by pixel in a 24x24 SVG and wrote the style sheet that is stored on the data contract, this took over 30 hours.\nThe ERC20 Contract and Staking\nSimulate Staking Here\nThe \"gym\" as I call it is a pretty simple mechanic. You stake your MIKE into the ERC20 contract ($HGH) and record the timestamp sent. You can claim the accumulated $HGH at any time, at an emissions rate of 1 per day per MIKE staked, with a max of 10 MIKEs per wallet staking.\nIncluded in this is the same set of functionality, but mapped by contract addresses. This gives us the ability to add multiple contracts that can stake at different emissions rates for future projects. I plan on allowing our \"Evil Club Owner\" NFT to stake at an emissions rate of .25 $HGH per 24 hours.\nERC20 -> ERC721 Token Injection\nSimulate Token Injection Here You must have a MIKE minted and unstaked, you can open $HGH faucet from #15 \"openFaucet\" on $HGH polygon mumbai contract\nOur Matic Mike NFT contract allows for \"injecting\" Mike with the $HGH token for a chance to upgrade a random trait. I determine all randomization in this method by working off of a random number provided by a Chainlink VRF call. Let's dig in.\nFirst, I take payment in $HGH for the injection attempt. This is burned from the total supply, and a Chainlink VRF function is called, storing the request ID to the token being attempted at upgrade.\nIn our fulfillRandomness call I first check to see if the modulo equation result falls in the 5.5% range required to proceed with the upgrade. If not, nothing happens, but if true, it will move onto the next call, which is determining which trait to try and upgrade. I do this by a simple modulo call to determine a 1-9 range.\nOnce the trait the algorithm is going to upgrade is selected, it will try to increase it's rarity by 1 or 2 rarities by subtracting from the number (if > 0), recreating the \"dna code\" hash with the new number, and making sure it does not exist in the hash map (all MIKEs must remain unique). If it doesn't exist, it saves the hash to the token and it is now upgraded, otherwise, it continues to move rarity positions over by 1 to until it hits a successful upgrade which the hash doesn't exist. If it steps through every combination and all hashes exist, the upgrade will also be unsuccessful.\nUpon completion of a successful upgrade, the contract increases the global price of $HGH for upgrade attempts by 3. This is to preserve rarities and deflate $HGH supply.\nThe PvP Dance Royale Contract\nFirst, let's list the links involved with this contract interface so you can easily jump from page to page. Make sure you have your Mike minted if you plan on sampling the queue system. Please note, if you do want to test on live environment, please send \"Mike Dev\" a message in discord and I'll send you some $HGH. $HGH has no max supply, and no faucet on mainnet, so I earn at the same rate as everyone else.\nThe Staging Environment Queue\nYour \"My Stats\" Page\nWatch a Dance Replay\nView a Dance Results\nView Individual Token Stats\nAs mentioned in the previous section. The dance royale has a rolling 50 man queue system, which lowers to 15 man after 30 minutes if the queue hasn't filled in an effort to keep queues rolling (all numbers and times are adjustable). Lets go through a few of the requirements to enter.\nI have an active flag in case I ever need to freeze entries for whatever reason.\nThe optional $HGH added to your MIKE entering battle must be a non decimal integer\nThe optional $HGH added must be less than the maximum allowed juice (adjustable, currently 5).\nYou must be owner of the MIKE, however the MIKE can be staked in the $HGH contract.\nThe current Royale Rumble id does not exceed the rumble size, and the battle is not already in progress.\nYou can only enter a unique MIKE once per content.\nIt is also worth noting, if you are the first in queue, you populate the analytics for the last royale. This is not done during the actual royale call due to gas limitations and ensuring Chainlink doesn't run out of gas during the callback.\nOptional $HGH added is tracked and burned, before calling the Chainlink VRF function.\nHere is the code for the enter royale function, it is pretty self explanatory. I make use of a lot of mappings to quickly handle all requests.\n// enter battle royale\nfunction enterRoyale(uint256 _tokenId, uint8 _hghJuice) public returns (uint256){\nrequire(active, \"Dance Royale not currently active\");\nrequire((_hghJuice * wagerMulti) % wagerMulti == 0, \"HGH Amount cannot be a decimal\");\nrequire(_hghJuice <= maxJuice, \"Over the maximum juice amount\");\nrequire(IHgh(hghAddress).balanceOf(msg.sender) >= (_hghJuice * wagerMulti) + currentPrice, \"Not enough HGH in wallet balance\");\n// check in gym as well\nrequire(IMaticMike(mmAddress).ownerOf(_tokenId) == msg.sender || IHgh(hghAddress).getStaker(_tokenId) == msg.sender, \"Not the owner of token\");\nrequire(royaleParticipants[_rumbleId.current()] < rumbleSize && !battleIsComplete[_rumbleId.current()], \"Royale trigger currently in progress. Try again in a minute\");\n// require that they are not already entered in the competition...\nrequire(!tokenToRumble[_tokenId][_rumbleId.current()], \"Already entered in competition\");\n// if new rumble populate analytics from previous rumble\nif(_rumbleId.current() != 0 && royaleParticipants[_rumbleId.current()] == 0){\npopulateWinners(_rumbleId.current() - 1);\n}\n// burn the juiced up amount\nIHgh(hghAddress).burnFrom(msg.sender, _hghJuice * wagerMulti);\n// transfer 1 HGH to contract\nIHgh(hghAddress).transferFrom(msg.sender, address(this), currentPrice);\n// begin royale entry\nroyaleParticipants[_rumbleId.current()]++;\nroyalePot[_rumbleId.current()] = royalePot[_rumbleId.current()] + wagerMulti;\ntokenToRumble[_tokenId][_rumbleId.current()] = true;\n// Chainlink VRF\nbytes32 requestId = requestRandomness(keyHash, fee);\nresponseIdToBattle[requestId] = BattleType(\n1,\n_rumbleId.current(),\n_tokenId,\n_hghJuice,\nwagerMulti\n);\nrumbleIdParticipants[_rumbleId.current()].push(_tokenId);\ntokenToRumblesEntered[_tokenId].push(_rumbleId.current());\naddressToRumblesEntered[msg.sender].push(_rumbleId.current());\nreturn _rumbleId.current();\n}\nOnce a user has entered into the competition, I need to determine their roll. This is done by first calculating their power level. The function assign a random additional powerlevel (up to the optional $HGH, multiplied by 9, plus the optional $HGH).\nif(responseIdToBattle[requestId].juicedUp > 0){\npowerup = (randomness % (responseIdToBattle[requestId].juicedUp * 9)) + responseIdToBattle[requestId].juicedUp;\n}\nI then query the Matic Mike contract for power level, add it to the previous calculation, and determine the roll...\nuint powerlevel = IMaticMike(mmAddress).getPowerLevel(responseIdToBattle[requestId].tokenId) + powerup;\naddress tokenHolder;\n// check if in gym and assign accordingly\nif(IMaticMike(mmAddress).ownerOf(responseIdToBattle[requestId].tokenId) != hghAddress){\ntokenHolder = IMaticMike(mmAddress).ownerOf(responseIdToBattle[requestId].tokenId);\n}\nelse{\ntokenHolder = IHgh(hghAddress).getStaker(responseIdToBattle[requestId].tokenId);\n}\nuint256 roll = randomness % powerlevel;\nrumbleIdToRolls[rumbleId].push(\nRollInfo(\nresponseIdToBattle[requestId].tokenId,\ntokenHolder,\nroll\n)\n);\nOnce all the entries are in for the current royale, I calculate the winner by looping through all the roles, coin flipping on ties, and saving 1st, 2nd, and 3rd place. Payouts are done instantly sending the $HGH pot as follows...\n70% to First Place\n20% to Second Place\n10% to Third Place\nThe next Royale queue begins immediately, and as previously state, the analytics are stored on the first person who queues the into the next royale.\nIt is worth noting, I am saving wins by Token ID as well as wins by Address. This is for the future \"Name Your Club\" project in which I'll have full details on club wins and analytics whether they still hold the token which they won or lost with.\nDiscordJS and Additional Functionality with Ethereum Bridge\nI run a discord bot using discordjs running on our server using foreverjs. Some of the functionality I have implemented include...\n/supply\nreturns circulating supply of $HGH, Matic Mikes, Unique Wallets Staking, Total Burned, and other useful info\n/powerlevel {id}\nReturns Powerlevel of the Token ID\n/peek {address}\nReturns all OpenSea links of the address, both staked and unstaked tokens\n/snapshot {id}\nReturns a snapshot of all the traits and an opensea link of the Token ID\nThe Ethereum Bridge TokenURI points to our website which runs a simple NodeJS script to query and return the polygon Matic Mike contract MetaData. For speed, we save a cached copy of the json on the server, and it is overwritten periodically with new data in case any upgrades occur or additional traits are pulled in in the future with our PvE contract.\nChallenges I ran into\nI had some hickups along the way as this was my first major blockchain project. I'll go over each issue individually and how it was resolved.\nGas Limit Issues on Read Functions\nI ran into the problem when calling the TokenURI where if a combination of traits led to a very large amount of pixels, it would run out of gas. This is because the body and clothing portion of the SVG uses a good amount of pixels. To resolve this, instead of drawing out these attributes pixel by pixel, I loaded in the entire section of the SVG and append it to the result in one loop. I still draw out most of the smaller traits pixel by pixel, but after realizing how low cost it is to populate something like this on Polygon, I could just load more data into the contract without having to worry about a pixel by pixel drawing.\nIn future contracts, I'll be implementing a new algorithm for drawing out graphics in chunk in a larger map, but for the sake of time and getting multiple phases of this project out within the hackathon deadline, I did not implement this in the current data contract.\nOnboarding Users to Polygon Chain\nIt was very hard with our whitelist explaining how to get Matic on Polygon, as well as just getting users onboarded in general. I put a guide together prior to minting that helped with this, and automatically added the polygon network to their web3 wallet.\nA Small Error in the Contract Code\nWhen a MIKE was burn rerolled, the contract modifies the \"dna\" hash to reflect that it has been burned, and a pitchfork type of drawing is placed on the MIKE signifying it has been sent to the dead wallet. I forgot to run this function when sending the hash to the data contract, so I had to replace the data contract mid mint to call back to the ERC721 contract to see if the token belongs to the DEAD address, and modify the hash on the data contract.\nIf I could go back and change it, I would probably integrate an upgradable contract to fix the error in the main contract.\nOpenSea Not Refreshing MetaData and Not Having Polygon API\nInstead of being able to force refresh metadata like you are able to on OpenSea with ethereum contracts, I needed to create a browser automation script that constantly runs to refresh metadata to reflect potential user upgrades from token injections, and in the future, loot from the boss contract NFTs.\nChainlink on Polygon\nThis was kind of a scary moment, but I had loaded some LINK onto the contract for Chainlink VRF functionality yet was getting an insufficient LINK balance. I quickly realized after re-reading the documentation that I needed to convert to the official LINK token on Polygon using the PegSwap service. This was a relief, however there is now some LINK stuck in the contract forever!\nMarketing, Marketing, Marketing\nI am in desperate need of marketing help for this project to gain attention and actually bring in more active users. Unfortunately due to the quick \"flip\" mentality on a lot of NFT projects, I have a good amount of users listing for a very low price on OpenSea and not participating in the PvP Dance Royale contract, and I'm afraid will not participate in my future PvE Evil Club Owners NFT contract I plan on releasing in December.\nAn update as of 11/23 - we have began to see some movement in getting a lot of the inactive users out, and I launched an update to the data contract to pull in stats to the metadata to show things like Power Level, Dance Royales entered, and Placement Percentage in those royales (top 3) for each Matic Mike. This helps potential buyers narrow down options for when they plan to buy.\nMy goal with this hackathon is to hopefully place, and potentially draw some attention to the work I've been putting in on really expanding what NFTs can do.\nAccomplishments that I'm proud of\n10,000 Matic Mikes were minted over the course of 12 hours\n7363 of those Mikes were burn rerolled, leaving a total supply of 2637\nOf those 2637, Matic Mike sees an average over 2200 staked (in the gym). That signifies the project has a lot of long-term holders\nMy ethereum bridge worked, although I am the only one who has used it\nAlmost 18,000 $HGH has been generated through staking over the course of this project\nOver 648 unique wallets own a Matic Mike, which I am happy with that number\nI was told by almost everyone on the night of minting that it was the most fun minting experience they ever had\nThe launch was relatively smooth for both the minting, and the PvP Battle Royale contract.\nAs of 11/23 we have over 70 dance royales with a minimum of 15 Matic Mikes per royale completed.\nWhat I learned\nSolidity, and working with blockchain in general\nThis was the first blockchain project I've worked on. I've been a big fan of Ethereum and Polygon in general but never got around to actually working with it. I now consider myself pretty up to speed with the core concepts.\nChainlink VRF - I had no idea until I started writing out the code I whiteboarded that true random numbers weren't technically possible on chain. Chainlink VRF was a true asset with this. I am also very excited to expand my use of Chainlink in the future, and I've got some CRAZY ideas brewing.\nDiscordJS and Web3\nI was very happy to find DiscordJS and it was a pleasure to work with. You can do some really cool things with it and I think it is especially useful for web3 functionality\nReignited my passion for coding\nI've been a full stack developer for 12 years, but this brought me back to college and not having the robust amount of documentation I am used to today. Although a lot of documentation exists, because blockchain is still relatively \"new\" you can't just Google every problem and come up with a solution.\nLearned just how much one can get done if TRULY motivated. This is the most amount of work I've done in the least amount of time I think in my entire career.\nWhat's next for Matic Mike NFT Game\nThe unreleased phase of our project is our PvE Evil Club Owners NFT contract. Although I won't have time to complete this prior to the chainlink hackathon deadline, I should give a rundown so you can see more ways $HGH and the genesis Matic Mike NFT will play a role in the future of this project.\nThe idea is that Matic Mike will need to summon the Evil Club Owner NFT by staking in the Club contract, which will assign a randomized time period, between 1 week and 1 month, to summon out the Club Owner. You will also need to burn off 100 $HGH to start summoning the owner, and will be able to send more $HGH on a daily basis to reduce the amount of time it takes to summon the boss. My initial thought is 10 $HGH will reduce the amount of time Mike needs to be staked in the club by 1 hour.\nOnce the Evil Club Owner is spawned, not only will they be able to stake inside the gym and earn $HGH (at a lower emissions rate than Mike), they will also have a power level associated with themselves as well as a piece of loot. Matic Mike will be able to go into battle with his Evil Club Owner and if Mike is successful in defeating them, Mike will pull the trait and new graphic directly onto his original Matic Mike NFT. The club owner will only be able to be looted once, but will be used in future player vs player concepts. Each Matic Mike will be able to summon 2 club owners and a total of 2 new trait types with 9 different trait values will be randomly generated in the loot of the club owners.\nThe future of this project will be released in seasons, where the club owner and \"name your club\" contracts will finish up season 1, and season 2 will begin with Mike training a new apprentice, and the next chapter of PvP and PvE will revolve around Mike helping his apprentice through all walks of life in this crazy NFT space.\nUpdates to submission 11/23/2021 I've updated the github repository with the discordjs bot, as well as the website source code for the production site. If judges need a Matic Mike NFT on production, as well as some $HGH to use the utility functions, please reach out via discord to myself, \"Mike Dev\" in our discord.\nI have also updated some of this documentation and replaced \"we\" with \"I\" as I developed this project solo from a code and innovation perspective. It, however, is not my intention to take away from the community help I received in promoting the project to get the amount of unique holders I currently have.\nBecause this is a continuously evolving product, the staging environment may not be kept as up to date as the production environment. Due to the fast-moving space I will frequently push updates directly to production.", "link": "https://devpost.com/software/matic-mike-nft-game", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "a quick note\nthe project is now fully in production with almost 660 unique wallets holding nfts. i listed staging environment links on the mumbai testnet, however for full user experience some updates have been pushed directly to production. if judges need a production matic mike and don't want to buy one on the opensea aftermarket, please let me know so i can send one of mine.\nlink to production site\nlink to staging\n$hgh erc20 testnet, use #15 openfaucet for test $hgh\ninspiration\nmatic mike was inspired by other high utility nft projects in the space that are 100% on chain. i wanted to make something special that is fully on chain with no api, but also have a full functioning and easy to use interface for everyone to enjoy. the goal here is not only to release a fun, free project, but also to show how dynamic the nft space can be, ranging from pure artwork to a full-scale collectibles game with it's own ecosystem.\nyou can read a full rundown and guide of the current release here.\nwhat it does\nfull 25 minute detailed overview video\nmatic mike is a free, 100% on-chain generative erc721 nft game on the polygon network with a polygon <-> ethereum bridge, and is accompanied by a fully compliant erc20 token, matic mike juice ($hgh) with a polygon <-> ethereum bridge as well.\nas stated, matic mike is a 100% on chain generated nft. when i say 100%, i mean 100% as each mike's traits are chosen on mint, and drawn out pixel by pixel on chain. every trait has a power level associated with it, with each mike having their own power level associated with them. power levels are used in all the gaming functionality which i'll explain further down the line.\nproblems it solves\nthere's a few problems in the nft space this project provides a resolution to. the first and most obvious is being fully on-chain. having all metadata, including image, being stored fully on chain is basically a guarantee you will forever have access to the nft.\nthe second is being able to dynamically modify metadata based on future project releases. in the data contract (which we can change the address of in the erc721 contract if we need to make changes) i have an extension contract that queries and loops through for future contract additions. things like fighting boss nfts and receiving loot can be done totally on chain, and pull new data and graphics into the genesis nft.\nanother problem with high utility projects on l1 ethereum is transaction fees. being on polygon with the ability to bridge over to ethereum for certain aftermarket compatibility allows users the luxury of participating in the high utility of staking, withdrawing, token injections, minting and burn rerolls, as well as pvp battle royales without having to worry about spending more than a few pennies.\nthe dance royale specifically displays a system in which blockchain can be utilized in a fortnite style queueing system, with new queues opening as soon as the previous queue fills or is triggered via a time trigger. the actual functionality of the dance royale makes extreme use of chainlink vrf.\nthe $hgh contract provides a new way to earn tokens by staking erc721 tokens, with the ability to add any erc721 token into the erc20 contract at different emission rates. this is something quite unique as i can add in other developers contracts for promotions or collaborations.\nfinally, the major thing this project shows is the ability to integrate a full-scale collectibles game without the need for any external / centralized api. although chainlink provides a useful resource for communicating with centralized data, being fully decentralized was the goal of this project. utilizing chainlink vrf for the heavy use of random number generation was a necessity in the success of this project. chainlink vrf in the upgrade & dance royale completion also prevents against potential flashbot misuse to revert calls if desired result is not met (just learned this today).\nthe minting process\nmatic mike is now fully minted on the polygon chain. to onboard interested users, i airdropped $1000 in matic to users who signed up for our whitelist for gas on the polygon network. the mint price was as follows...\n1-2500: free mint (1 per whitelist, and once public sale was activated, up to 10 per wallet)\n2500-4000: 1 $hgh\n4000-6000: 2 $hgh\n6000-8000: 3 $hgh\n8000-10000: 4 $hgh\nafter 2500, free \"burn rerolls\" were activated, allowing users to burn their mint and generate a new mint.\n$hgh and it's uses\nlet's talk a little bit about $hgh and what it is used for in-game in matic mike nft's present state. before we get into the functions of $hgh, we should talk about how to earn $hgh. as stated, matic mike was a 100% free mint, and after 2500 used our new erc20 token $hgh. to earn $hgh, you must have a mike, and he is staked \"in the gym,\" also known as the $hgh contract, with an emissions rate of 1 $hgh over 24 hours per matic mike staked in the $hgh contract. the first feature was obviously the tokenized minting process, now let's take a look at the \"token injections.\"\nerc20 -> erc721 token injection\none of the unique features about the matic mike nft is the ability to dynamically modify traits all on-chain at the cost of $hgh. i call this \"token injection\" and it is the process of burning off $hgh for a small chance to upgrade the tier of rarity of a random trait. this was a feature included in our initial release 2 weeks ago. the cost to inject matic mike for a chance to upgrade started at 1 $hgh and increases on a global scale by 3 $hgh for every successful injection. token injections have about a 5.5% success rate, and the $hgh used per attempt is burned from the circulating supply. i'll explain how this is built in the next section.\nthe pvp battle royale\nthe other current use of $hgh is our player vs player battle royale contract, also known as the \"dance royale.\" this is a rolling 50 man queue system done completely on-chain that costs 1 $hgh to enter, with the option of adding 0-5 additional $hgh for adding 1-10 power level per additional $hgh injected. the optional injection $hgh is burned from the circulating supply, while the entry fee is added to the pot for the current royale. upon completion, the winner receives 70% of the royale pot, 2nd place receives 20%, and 3rd 10%.\na complete log of analytics are stored in the pvp dance royale contract, and our web interface gives a nice look at individual token stats. analytics for wallet address data is also stored on-chain, with plans to integrate a future contract with a \"name your wallet\" function and a custom uri slug on the website. this will give complete analytical history for addresses even if you sell or trade your mike in the future.\nhow i built it\nthe short answer is solidity, html, javascript, web3, jquery, select2, bootstrap 5, discordjs, and nodejs for the ethereum bridge.\nthe chains include polygon, ethereum, as well as utilizing tons of chainlink vrf functionality specifically in the utility features of erc20->erc721 token injection and battle royale contract.\nthe long answer\nthe matic mike nft and matic mike juice ($hgh) initial release was a total of 5 smart contracts.\nerc721: matic mike nft\nerc20: $hgh contract\nintermediate data contract\nerc721 bridge: matic mike nft\nerc20 bridge: $hgh contract\nand the pvp battle royale contract is one single contract, but 2 more contracts are planned in the near future for a more in-depth analytical look as well as the \"name your club\" contract.\ndance royale contract\nthe matic mike nft minting process\nsimulate minting here\nlet's first start by getting into the minting process of the matic mike nft. every mint generates new unique metadata by looping through and generating 8 random numbers (this part does not utilize chainlink vrf so i could quickly return to the user) which are used to determine the rarity of each trait. depending on where the number falls, it selects a number (0-9) of the trait and pieces together a \"hash\" or \"dna code\" for the token id. that dna code and token id is sent to the data contract when pulling the tokenuri or other read calls and the metadata is generated on demand.\ni also integrated the free \"burn rerolls\" which essentially sent the token id being burned to a dead address, and ran the same minting process over again. this is what pushed the mint to fully mint out very quickly. there are examples of all these functions in the 5 minute overview video.\nthe data & reading from the data contract\nlet's first start with how i populated the data. i store the data for each trait in a struct as follows...\nstruct trait{\nstring traitname;\nstring traittype;\nstring pixels;\nuint256 pixelcount;\nuint8 powerlevel;\n}\nthis is pretty straight forward, but i should get into what the pixel string looks like, and how it works. every \"pixels\" string is composed of each pixel by 4 characters, let's use the example ab23. the first 2 characters represent the x and y coordinates, encoded as a letter. so a = 0, and b = 1. this mean's i am plotting a pixel at 0,1. the last 2 characters represent a css class associated with the color. so i am plotting a pixel at 0,1 with a css class of \"c23\". i loop through each trait and -----> plot !!!  these pixel strings during our calls. because i do have such a large mapping of pixels, i also loaded full xml of pre-plotted data for the body and outfits.\nit is worth noting, for further expansion i include this bit of code...\nif(xxladdress != nulladdress){\nimikeextended.traits[] memory xxltraits = imikeextended(xxladdress).getallplayerloot(_tokenid);\nfor(uint256 i=0; i < xxltraits.length; i++){\nif(xxltraits[i].valid && xxltraits[i].pixelcount > 0){\nsvgstring = string(\nabi.encodepacked(\nsvgstring,\nxxltraits[i].pixels\n)\n);\n}\n}\n}\nthis is for our expansion projects, in which i'll be able to pull new graphics directly into the svg string. each additional trait will be plotted in 1 long string.\nthe erc721 contract will call the data contract for tokenuri (which grabs the attributes and svg, and base64 encodes for return) and power level inqueries.\nit's worth noting, i drew everything out in photoshop, then mapped everything out pixel by pixel in a 24x24 svg and wrote the style sheet that is stored on the data contract, this took over 30 hours.\nthe erc20 contract and staking\nsimulate staking here\nthe \"gym\" as i call it is a pretty simple mechanic. you stake your mike into the erc20 contract ($hgh) and record the timestamp sent. you can claim the accumulated $hgh at any time, at an emissions rate of 1 per day per mike staked, with a max of 10 mikes per wallet staking.\nincluded in this is the same set of functionality, but mapped by contract addresses. this gives us the ability to add multiple contracts that can stake at different emissions rates for future projects. i plan on allowing our \"evil club owner\" nft to stake at an emissions rate of .25 $hgh per 24 hours.\nerc20 -> erc721 token injection\nsimulate token injection here you must have a mike minted and unstaked, you can open $hgh faucet from #15 \"openfaucet\" on $hgh polygon mumbai contract\nour matic mike nft contract allows for \"injecting\" mike with the $hgh token for a chance to upgrade a random trait. i determine all randomization in this method by working off of a random number provided by a chainlink vrf call. let's dig in.\nfirst, i take payment in $hgh for the injection attempt. this is burned from the total supply, and a chainlink vrf function is called, storing the request id to the token being attempted at upgrade.\nin our fulfillrandomness call i first check to see if the modulo equation result falls in the 5.5% range required to proceed with the upgrade. if not, nothing happens, but if true, it will move onto the next call, which is determining which trait to try and upgrade. i do this by a simple modulo call to determine a 1-9 range.\nonce the trait the algorithm is going to upgrade is selected, it will try to increase it's rarity by 1 or 2 rarities by subtracting from the number (if > 0), recreating the \"dna code\" hash with the new number, and making sure it does not exist in the hash map (all mikes must remain unique). if it doesn't exist, it saves the hash to the token and it is now upgraded, otherwise, it continues to move rarity positions over by 1 to until it hits a successful upgrade which the hash doesn't exist. if it steps through every combination and all hashes exist, the upgrade will also be unsuccessful.\nupon completion of a successful upgrade, the contract increases the global price of $hgh for upgrade attempts by 3. this is to preserve rarities and deflate $hgh supply.\nthe pvp dance royale contract\nfirst, let's list the links involved with this contract interface so you can easily jump from page to page. make sure you have your mike minted if you plan on sampling the queue system. please note, if you do want to test on live environment, please send \"mike dev\" a message in discord and i'll send you some $hgh. $hgh has no max supply, and no faucet on mainnet, so i earn at the same rate as everyone else.\nthe staging environment queue\nyour \"my stats\" page\nwatch a dance replay\nview a dance results\nview individual token stats\nas mentioned in the previous section. the dance royale has a rolling 50 man queue system, which lowers to 15 man after 30 minutes if the queue hasn't filled in an effort to keep queues rolling (all numbers and times are adjustable). lets go through a few of the requirements to enter.\ni have an active flag in case i ever need to freeze entries for whatever reason.\nthe optional $hgh added to your mike entering battle must be a non decimal integer\nthe optional $hgh added must be less than the maximum allowed juice (adjustable, currently 5).\nyou must be owner of the mike, however the mike can be staked in the $hgh contract.\nthe current royale rumble id does not exceed the rumble size, and the battle is not already in progress.\nyou can only enter a unique mike once per content.\nit is also worth noting, if you are the first in queue, you populate the analytics for the last royale. this is not done during the actual royale call due to gas limitations and ensuring chainlink doesn't run out of gas during the callback.\noptional $hgh added is tracked and burned, before calling the chainlink vrf function.\nhere is the code for the enter royale function, it is pretty self explanatory. i make use of a lot of mappings to quickly handle all requests.\n// enter battle royale\nfunction enterroyale(uint256 _tokenid, uint8 _hghjuice) public returns (uint256){\nrequire(active, \"dance royale not currently active\");\nrequire((_hghjuice * wagermulti) % wagermulti == 0, \"hgh amount cannot be a decimal\");\nrequire(_hghjuice <= maxjuice, \"over the maximum juice amount\");\nrequire(ihgh(hghaddress).balanceof(msg.sender) >= (_hghjuice * wagermulti) + currentprice, \"not enough hgh in wallet balance\");\n// check in gym as well\nrequire(imaticmike(mmaddress).ownerof(_tokenid) == msg.sender || ihgh(hghaddress).getstaker(_tokenid) == msg.sender, \"not the owner of token\");\nrequire(royaleparticipants[_rumbleid.current()] < rumblesize && !battleiscomplete[_rumbleid.current()], \"royale trigger currently in progress. try again in a minute\");\n// require that they are not already entered in the competition...\nrequire(!tokentorumble[_tokenid][_rumbleid.current()], \"already entered in competition\");\n// if new rumble populate analytics from previous rumble\nif(_rumbleid.current() != 0 && royaleparticipants[_rumbleid.current()] == 0){\npopulatewinners(_rumbleid.current() - 1);\n}\n// burn the juiced up amount\nihgh(hghaddress).burnfrom(msg.sender, _hghjuice * wagermulti);\n// transfer 1 hgh to contract\nihgh(hghaddress).transferfrom(msg.sender, address(this), currentprice);\n// begin royale entry\nroyaleparticipants[_rumbleid.current()]++;\nroyalepot[_rumbleid.current()] = royalepot[_rumbleid.current()] + wagermulti;\ntokentorumble[_tokenid][_rumbleid.current()] = true;\n// chainlink vrf\nbytes32 requestid = requestrandomness(keyhash, fee);\nresponseidtobattle[requestid] = battletype(\n1,\n_rumbleid.current(),\n_tokenid,\n_hghjuice,\nwagermulti\n);\nrumbleidparticipants[_rumbleid.current()].push(_tokenid);\ntokentorumblesentered[_tokenid].push(_rumbleid.current());\naddresstorumblesentered[msg.sender].push(_rumbleid.current());\nreturn _rumbleid.current();\n}\nonce a user has entered into the competition, i need to determine their roll. this is done by first calculating their power level. the function assign a random additional powerlevel (up to the optional $hgh, multiplied by 9, plus the optional $hgh).\nif(responseidtobattle[requestid].juicedup > 0){\npowerup = (randomness % (responseidtobattle[requestid].juicedup * 9)) + responseidtobattle[requestid].juicedup;\n}\ni then query the matic mike contract for power level, add it to the previous calculation, and determine the roll...\nuint powerlevel = imaticmike(mmaddress).getpowerlevel(responseidtobattle[requestid].tokenid) + powerup;\naddress tokenholder;\n// check if in gym and assign accordingly\nif(imaticmike(mmaddress).ownerof(responseidtobattle[requestid].tokenid) != hghaddress){\ntokenholder = imaticmike(mmaddress).ownerof(responseidtobattle[requestid].tokenid);\n}\nelse{\ntokenholder = ihgh(hghaddress).getstaker(responseidtobattle[requestid].tokenid);\n}\nuint256 roll = randomness % powerlevel;\nrumbleidtorolls[rumbleid].push(\nrollinfo(\nresponseidtobattle[requestid].tokenid,\ntokenholder,\nroll\n)\n);\nonce all the entries are in for the current royale, i calculate the winner by looping through all the roles, coin flipping on ties, and saving 1st, 2nd, and 3rd place. payouts are done instantly sending the $hgh pot as follows...\n70% to first place\n20% to second place\n10% to third place\nthe next royale queue begins immediately, and as previously state, the analytics are stored on the first person who queues the into the next royale.\nit is worth noting, i am saving wins by token id as well as wins by address. this is for the future \"name your club\" project in which i'll have full details on club wins and analytics whether they still hold the token which they won or lost with.\ndiscordjs and additional functionality with ethereum bridge\ni run a discord bot using discordjs running on our server using foreverjs. some of the functionality i have implemented include...\n/supply\nreturns circulating supply of $hgh, matic mikes, unique wallets staking, total burned, and other useful info\n/powerlevel {id}\nreturns powerlevel of the token id\n/peek {address}\nreturns all opensea links of the address, both staked and unstaked tokens\n/snapshot {id}\nreturns a snapshot of all the traits and an opensea link of the token id\nthe ethereum bridge tokenuri points to our website which runs a simple nodejs script to query and return the polygon matic mike contract metadata. for speed, we save a cached copy of the json on the server, and it is overwritten periodically with new data in case any upgrades occur or additional traits are pulled in in the future with our pve contract.\nchallenges i ran into\ni had some hickups along the way as this was my first major blockchain project. i'll go over each issue individually and how it was resolved.\ngas limit issues on read functions\ni ran into the problem when calling the tokenuri where if a combination of traits led to a very large amount of pixels, it would run out of gas. this is because the body and clothing portion of the svg uses a good amount of pixels. to resolve this, instead of drawing out these attributes pixel by pixel, i loaded in the entire section of the svg and append it to the result in one loop. i still draw out most of the smaller traits pixel by pixel, but after realizing how low cost it is to populate something like this on polygon, i could just load more data into the contract without having to worry about a pixel by pixel drawing.\nin future contracts, i'll be implementing a new algorithm for drawing out graphics in chunk in a larger map, but for the sake of time and getting multiple phases of this project out within the hackathon deadline, i did not implement this in the current data contract.\nonboarding users to polygon chain\nit was very hard with our whitelist explaining how to get matic on polygon, as well as just getting users onboarded in general. i put a guide together prior to minting that helped with this, and automatically added the polygon network to their web3 wallet.\na small error in the contract code\nwhen a mike was burn rerolled, the contract modifies the \"dna\" hash to reflect that it has been burned, and a pitchfork type of drawing is placed on the mike signifying it has been sent to the dead wallet. i forgot to run this function when sending the hash to the data contract, so i had to replace the data contract mid mint to call back to the erc721 contract to see if the token belongs to the dead address, and modify the hash on the data contract.\nif i could go back and change it, i would probably integrate an upgradable contract to fix the error in the main contract.\nopensea not refreshing metadata and not having polygon api\ninstead of being able to force refresh metadata like you are able to on opensea with ethereum contracts, i needed to create a browser automation script that constantly runs to refresh metadata to reflect potential user upgrades from token injections, and in the future, loot from the boss contract nfts.\nchainlink on polygon\nthis was kind of a scary moment, but i had loaded some link onto the contract for chainlink vrf functionality yet was getting an insufficient link balance. i quickly realized after re-reading the documentation that i needed to convert to the official link token on polygon using the pegswap service. this was a relief, however there is now some link stuck in the contract forever!\nmarketing, marketing, marketing\ni am in desperate need of marketing help for this project to gain attention and actually bring in more active users. unfortunately due to the quick \"flip\" mentality on a lot of nft projects, i have a good amount of users listing for a very low price on opensea and not participating in the pvp dance royale contract, and i'm afraid will not participate in my future pve evil club owners nft contract i plan on releasing in december.\nan update as of 11/23 - we have began to see some movement in getting a lot of the inactive users out, and i launched an update to the data contract to pull in stats to the metadata to show things like power level, dance royales entered, and placement percentage in those royales (top 3) for each matic mike. this helps potential buyers narrow down options for when they plan to buy.\nmy goal with this hackathon is to hopefully place, and potentially draw some attention to the work i've been putting in on really expanding what nfts can do.\naccomplishments that i'm proud of\n10,000 matic mikes were minted over the course of 12 hours\n7363 of those mikes were burn rerolled, leaving a total supply of 2637\nof those 2637, matic mike sees an average over 2200 staked (in the gym). that signifies the project has a lot of long-term holders\nmy ethereum bridge worked, although i am the only one who has used it\nalmost 18,000 $hgh has been generated through staking over the course of this project\nover 648 unique wallets own a matic mike, which i am happy with that number\ni was told by almost everyone on the night of minting that it was the most fun minting experience they ever had\nthe launch was relatively smooth for both the minting, and the pvp battle royale contract.\nas of 11/23 we have over 70 dance royales with a minimum of 15 matic mikes per royale completed.\nwhat i learned\nsolidity, and working with blockchain in general\nthis was the first blockchain project i've worked on. i've been a big fan of ethereum and polygon in general but never got around to actually working with it. i now consider myself pretty up to speed with the core concepts.\nchainlink vrf - i had no idea until i started writing out the code i whiteboarded that true random numbers weren't technically possible on chain. chainlink vrf was a true asset with this. i am also very excited to expand my use of chainlink in the future, and i've got some crazy ideas brewing.\ndiscordjs and web3\ni was very happy to find discordjs and it was a pleasure to work with. you can do some really cool things with it and i think it is especially useful for web3 functionality\nreignited my passion for coding\ni've been a full stack developer for 12 years, but this brought me back to college and not having the robust amount of documentation i am used to today. although a lot of documentation exists, because blockchain is still relatively \"new\" you can't just google every problem and come up with a solution.\nlearned just how much one can get done if truly motivated. this is the most amount of work i've done in the least amount of time i think in my entire career.\nwhat's next for matic mike nft game\nthe unreleased phase of our project is our pve evil club owners nft contract. although i won't have time to complete this prior to the chainlink hackathon deadline, i should give a rundown so you can see more ways $hgh and the genesis matic mike nft will play a role in the future of this project.\nthe idea is that matic mike will need to summon the evil club owner nft by staking in the club contract, which will assign a randomized time period, between 1 week and 1 month, to summon out the club owner. you will also need to burn off 100 $hgh to start summoning the owner, and will be able to send more $hgh on a daily basis to reduce the amount of time it takes to summon the boss. my initial thought is 10 $hgh will reduce the amount of time mike needs to be staked in the club by 1 hour.\nonce the evil club owner is spawned, not only will they be able to stake inside the gym and earn $hgh (at a lower emissions rate than mike), they will also have a power level associated with themselves as well as a piece of loot. matic mike will be able to go into battle with his evil club owner and if mike is successful in defeating them, mike will pull the trait and new graphic directly onto his original matic mike nft. the club owner will only be able to be looted once, but will be used in future player vs player concepts. each matic mike will be able to summon 2 club owners and a total of 2 new trait types with 9 different trait values will be randomly generated in the loot of the club owners.\nthe future of this project will be released in seasons, where the club owner and \"name your club\" contracts will finish up season 1, and season 2 will begin with mike training a new apprentice, and the next chapter of pvp and pve will revolve around mike helping his apprentice through all walks of life in this crazy nft space.\nupdates to submission 11/23/2021 i've updated the github repository with the discordjs bot, as well as the website source code for the production site. if judges need a matic mike nft on production, as well as some $hgh to use the utility functions, please reach out via discord to myself, \"mike dev\" in our discord.\ni have also updated some of this documentation and replaced \"we\" with \"i\" as i developed this project solo from a code and innovation perspective. it, however, is not my intention to take away from the community help i received in promoting the project to get the amount of unique holders i currently have.\nbecause this is a continuously evolving product, the staging environment may not be kept as up to date as the production environment. due to the fast-moving space i will frequently push updates directly to production.", "sortedWord": "None", "removed": "Nan", "score": 9, "comments": 6, "media": null, "medialink": null, "identifyer": 59504877}, {"Unnamed: 0": 4976, "autor": "COVID-19 visualization", "date": null, "content": "Inspiration - the task of Global Pandemic COVID 19 Analysis with Python. COVID-19 does not need to be introduced, it is the latest infectious disease to take hold of the whole world.\nWhat it does-It shows vizualizations of number of peoples vaccinated, active cases, death cases and total cases by state.\nHow we built it-We have used PowerBI for doing various vizualizations.\nChallenges we ran into-\nWhat we learned-We learnt how to plot different graphs and charts of covid-19 data using PowerBI.\nWhat's next for COVID-19 visualization-We have made vizualizations using India's Covid-19 data ,In future we will try to analyze and make vizualizations of whole world's Covid -19 data.", "link": "https://devpost.com/software/covid-19-visualization", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration - the task of global pandemic covid 19 analysis with python. covid-19 does not need to be introduced, it is the latest infectious disease to take hold of the whole world.\nwhat it does-it shows vizualizations of number of peoples vaccinated, active cases, death cases and total cases by state.\nhow we built it-we have used powerbi for doing various vizualizations.\nchallenges we ran into-\nwhat we learned-we learnt how to -----> plot !!!  different graphs and charts of covid-19 data using powerbi.\nwhat's next for covid-19 visualization-we have made vizualizations using india's covid-19 data ,in future we will try to analyze and make vizualizations of whole world's covid -19 data.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59504976}, {"Unnamed: 0": 5187, "autor": "Garbage Maps", "date": null, "content": "What it does\nThe application generates a map of the UTK campus and can plot a path between a user's start and end goal; however don't expect the path to be convenient whatsoever.\nThis project requires Python 3.9+ and PyQt6. PyQt6 installation scripts for Windows and Linux have been provided.\nYou are presented with a map of UTK's main campus\nThere are 2 boxes for you to select your current location, and your desired destination\nOnce you've made your selection, press the Yeet button to get a unique path around campus to eventually reach your destination\nHow we built it\nWe divided the overall project into different field and assigned members to them according to past experience and skillset. 2 members chose to work together and develop the Python integration of a UTK campus map, application UI, and path routing logic. Another member focused on all tasks related to digital art, including custom logo designs, website formatting, and path \u201cstickers\u201d that are used to display the generated path to the user. The last member was dedicated to maintaining uptime of website/databases services (the free tier webhosting subscription making such an especially annoying challenge) as well creating marketable, out of the box deployment ideas for the application.\nChallenges we ran into\nAt first, we wanted to work with either Google Maps and their APIs, or maybe Amazon's APIs, but both required payment depending on how much they were used, and we don't quite have the funding for that. Our goal was to avoid spending even a single penny on subscriptions or services and make do with whatever free services we could find.\nWithout a real maps API, we ended up working with a single image of UTK's campus, and had to draw out the paths for all the streets and their connections so we could highlight the route we provided, we had to do a lot of data entry by hand for this\nOur aforementioned stubbornness about paid subscriptions especially proved challenging when attempting to create sustainable website/databases. Our free .tech domain could not be hosted on Domain.com (the original registrar) as no free web hosting plan was available to us; the one service we did find (000hostweb), however had significant limitations that encouraged free users to upgrade. Some of those disadvantages included very limited storage space, a max of 2 SQL databases (with one of them automatically used by Wordpress), a database query limit, and little access to advanced Wordpress website features.\nThe initial idea was to have a market ready product, with a website providing potential customers with ample information, and a server sided database for client sided software to activate, authenticate, and renew their license subscriptions. Unfortunately, communicating with the SQL databases from external sources like that requires a paid subscription, forcing us to adapt and formulate alternative solutions.\nWe wanted to have a market ready product, with a website that provided a client with their very own license, which would be put into an online database so they didn't share their copy around as their own, but database access was also an issue without funding\nAccomplishments that we're proud of\nIn the end, we do have a map that gives you a really inconvenient path to your destination\nWe have a functional website you can visit, at link\nWhat we learned\nWhat's next for Garbage Maps\nIf this became a large scale project, we would start using a maps API from Google or Amazon ** With this API, we could expand beyond just UTK to give you inconvenient routes all over the world ** This would also help with the user experience, as they would just tap their destination rather than the selection boxes in use now\nWith more time and funding, we would polish the website and the download process ** Users need python3 and PyQt6 to run the program, but with more time we could set up config files to get all of that at once so the user wouldn't need a lot of time to set up ** A paid subscription to a webhost would allow bigger downloads from our website, which would be needed to include those config files", "link": "https://devpost.com/software/garbage-maps", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "what it does\nthe application generates a map of the utk campus and can -----> plot !!!  a path between a user's start and end goal; however don't expect the path to be convenient whatsoever.\nthis project requires python 3.9+ and pyqt6. pyqt6 installation scripts for windows and linux have been provided.\nyou are presented with a map of utk's main campus\nthere are 2 boxes for you to select your current location, and your desired destination\nonce you've made your selection, press the yeet button to get a unique path around campus to eventually reach your destination\nhow we built it\nwe divided the overall project into different field and assigned members to them according to past experience and skillset. 2 members chose to work together and develop the python integration of a utk campus map, application ui, and path routing logic. another member focused on all tasks related to digital art, including custom logo designs, website formatting, and path \u201cstickers\u201d that are used to display the generated path to the user. the last member was dedicated to maintaining uptime of website/databases services (the free tier webhosting subscription making such an especially annoying challenge) as well creating marketable, out of the box deployment ideas for the application.\nchallenges we ran into\nat first, we wanted to work with either google maps and their apis, or maybe amazon's apis, but both required payment depending on how much they were used, and we don't quite have the funding for that. our goal was to avoid spending even a single penny on subscriptions or services and make do with whatever free services we could find.\nwithout a real maps api, we ended up working with a single image of utk's campus, and had to draw out the paths for all the streets and their connections so we could highlight the route we provided, we had to do a lot of data entry by hand for this\nour aforementioned stubbornness about paid subscriptions especially proved challenging when attempting to create sustainable website/databases. our free .tech domain could not be hosted on domain.com (the original registrar) as no free web hosting plan was available to us; the one service we did find (000hostweb), however had significant limitations that encouraged free users to upgrade. some of those disadvantages included very limited storage space, a max of 2 sql databases (with one of them automatically used by wordpress), a database query limit, and little access to advanced wordpress website features.\nthe initial idea was to have a market ready product, with a website providing potential customers with ample information, and a server sided database for client sided software to activate, authenticate, and renew their license subscriptions. unfortunately, communicating with the sql databases from external sources like that requires a paid subscription, forcing us to adapt and formulate alternative solutions.\nwe wanted to have a market ready product, with a website that provided a client with their very own license, which would be put into an online database so they didn't share their copy around as their own, but database access was also an issue without funding\naccomplishments that we're proud of\nin the end, we do have a map that gives you a really inconvenient path to your destination\nwe have a functional website you can visit, at link\nwhat we learned\nwhat's next for garbage maps\nif this became a large scale project, we would start using a maps api from google or amazon ** with this api, we could expand beyond just utk to give you inconvenient routes all over the world ** this would also help with the user experience, as they would just tap their destination rather than the selection boxes in use now\nwith more time and funding, we would polish the website and the download process ** users need python3 and pyqt6 to run the program, but with more time we could set up config files to get all of that at once so the user wouldn't need a lot of time to set up ** a paid subscription to a webhost would allow bigger downloads from our website, which would be needed to include those config files", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59505187}, {"Unnamed: 0": 5969, "autor": "Mowin! Mobility Wins", "date": null, "content": "Inspiration\nPeople with low mobility needs information to move from point A to point B in a City, and in most of the cases, this information is out of reach for them. People with no mobility issues can provide the information. Mowin comes from intersecting the 2, a platform where everyone can add information that helps the mobile impaired navigate in the city safe and easy.\nWhat it does\nMowin is a platform where mobile impaired can plot routes from point A to point B taking into consideration their needs (ramps, elevator, large sidewalks, railings). The information is supplied by everyone - either mobile impaired or not.\nHow we built it\nStarted with the needs from the people with mobile impairment, then exchanged and debated ideas within the team. We haven't built a PoC or a demonstration of the idea as yet, it is at \"concept\" stage.\nChallenges we ran into\nFinding the right coder.\nAccomplishments that we're proud of\nGreat feedback from family and friends when we presented the idea.\nWhat we learned\nPutting ourselves in the shoes of people with mobile impairments and seeing mobility from their perspective and their challenges.\nWhat's next for Mowin! Mobility Wins\nGetting the right sponsor", "link": "https://devpost.com/software/mowin-mobility-wins", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\npeople with low mobility needs information to move from point a to point b in a city, and in most of the cases, this information is out of reach for them. people with no mobility issues can provide the information. mowin comes from intersecting the 2, a platform where everyone can add information that helps the mobile impaired navigate in the city safe and easy.\nwhat it does\nmowin is a platform where mobile impaired can -----> plot !!!  routes from point a to point b taking into consideration their needs (ramps, elevator, large sidewalks, railings). the information is supplied by everyone - either mobile impaired or not.\nhow we built it\nstarted with the needs from the people with mobile impairment, then exchanged and debated ideas within the team. we haven't built a poc or a demonstration of the idea as yet, it is at \"concept\" stage.\nchallenges we ran into\nfinding the right coder.\naccomplishments that we're proud of\ngreat feedback from family and friends when we presented the idea.\nwhat we learned\nputting ourselves in the shoes of people with mobile impairments and seeing mobility from their perspective and their challenges.\nwhat's next for mowin! mobility wins\ngetting the right sponsor", "sortedWord": "None", "removed": "Nan", "score": 10, "comments": 0, "media": null, "medialink": null, "identifyer": 59505969}, {"Unnamed: 0": 5981, "autor": "Whitestone", "date": null, "content": "Inspiration\nOne teammate is quite knowledgeable in finance and stocks, but the rest of the team had very little background in stocks, so our group as a whole thought it would be really nice to create something that made learning about stocks easier.\nWhat it does\nWhitestone has two main functionalities. The first is that it takes in a stock and budget, and outputs a graph of the stock price over time (based on the 100 most recent days), the linear approximation, and the number of stocks you could buy with the budget. The second is a \"glossary\" functionality that takes in a company name and outputs its abbreviation.\nHow we built it\nWe started with a simple react app and installed the necessary packages using npm. We then used the Alpha Vantage API to fetch stock data, which we could use to plot on a graph. The layout was done in styled components in React (essentially just CSS).\nChallenges we ran into\nOne of the main challenges was just getting started on the project. This was each member's first hackathon ever, and it took a while to just learn and get the hang of basic web development and using APIs. After that, there were some repetitive tasks that went by faster.\nAccomplishments that we're proud of\nWe're all proud of our contribution and growth. Each member contributed a significant amount towards the project, and we all learn a ton of new skills regarding web development.\nWhat we learned\nWe learned how to create a web app using React and JavaScript syntax, how to use the Alpha Vantage API, and how to read documentation in general. We also learned and used a lot more CSS.\nWhat's next for Whitestone\nWhitestone is still far from complete. We'd like to expand on our database of company abbreviations, as well as provide more information and analytics on stocks. Another possibility is to display information about the frequency of mentions of stocks (such as on Twitter), which could help users gain more intuition about which stocks are/were popular and how that correlates with the stock price.", "link": "https://devpost.com/software/whitestone", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\none teammate is quite knowledgeable in finance and stocks, but the rest of the team had very little background in stocks, so our group as a whole thought it would be really nice to create something that made learning about stocks easier.\nwhat it does\nwhitestone has two main functionalities. the first is that it takes in a stock and budget, and outputs a graph of the stock price over time (based on the 100 most recent days), the linear approximation, and the number of stocks you could buy with the budget. the second is a \"glossary\" functionality that takes in a company name and outputs its abbreviation.\nhow we built it\nwe started with a simple react app and installed the necessary packages using npm. we then used the alpha vantage api to fetch stock data, which we could use to -----> plot !!!  on a graph. the layout was done in styled components in react (essentially just css).\nchallenges we ran into\none of the main challenges was just getting started on the project. this was each member's first hackathon ever, and it took a while to just learn and get the hang of basic web development and using apis. after that, there were some repetitive tasks that went by faster.\naccomplishments that we're proud of\nwe're all proud of our contribution and growth. each member contributed a significant amount towards the project, and we all learn a ton of new skills regarding web development.\nwhat we learned\nwe learned how to create a web app using react and javascript syntax, how to use the alpha vantage api, and how to read documentation in general. we also learned and used a lot more css.\nwhat's next for whitestone\nwhitestone is still far from complete. we'd like to expand on our database of company abbreviations, as well as provide more information and analytics on stocks. another possibility is to display information about the frequency of mentions of stocks (such as on twitter), which could help users gain more intuition about which stocks are/were popular and how that correlates with the stock price.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59505981}, {"Unnamed: 0": 6098, "autor": "BunnyMatrix", "date": null, "content": "Bunny Matrix\nWhat Inspired Us\nBunny Matrix was created while discussing our interests, experiences, and goals. Initially, we felt lost as we were having a hard time coming up with an idea. All four of us agreed that we want to gain experience, learn new implementations, make connections, and have fun hacking. We communicated our ideas to each other and changed our plans to reflect new additions. We believed our project should not only be possible to create with the time restriction but also be practical and impactful. Some ideas we had included making a leaderboard of professors on Course Critique, using the Google Maps API to plot a heat map of forest fires in the country, and creating a calendar for GT Engage events. Ultimately, we proceeded with a project that allows businesses to take advantage of modern machine learning algorithms to predict future business opportunities. After hours of discussion, we decided to create a tool that not only visualizes a generic time-dependent business key performance indicator (KPI), e.g., weekly sales, but also predicts future KPI movement utilizing machine learning on past performance.\nWhat We Learned and How We Built This\nThroughout this hackathon, we learned a lot from new libraries to new languages. We found a number of libraries that simplified the implementation of several complex functions. One of the first libraries we attempted to implement was the D3.js as one of the team members had some experience using it. This library was used to parse the hundreds of rows of data in the CSV file, to produce the dataset in a JS array, and to construct a preliminary scatterplot visualization of the dataset. However, D3 was relatively complicated for beginners and required a server to operate in. We decided to utilize Chart.js as it provides more intuitive functions and has a bigger user base to get support. Overall, the most important library we used is Regression-js. This library enabled us to conduct numerous regression analyses and plot the regression line under multiple modes including linear, exponential, and polynomial with an order of an integer. Regression-js only provided us with a mathematical model that takes in an input X (time in our dataset) and gives an output Y (Walmart weekly sales).\nThe real question was how we could take the data regression-js provides and implement it in Chart.js. The library provided us with a regression equation but not an actual line graph which we need. We came up with a quick solution to instead take an arbitrarily large number of equidistant X points and calculate the respective Y values for each through the regression equation. The points are plotted and connected with straight lines. As the number of points approaches infinity, the regression line becomes more representative to the extent of the accuracy of the mathematical equation. The resulting regression equation was also used to predict current and future values of the KPI metric, the first step in machine learning models. In addition, we added complementary functions that improved the functionality of the regression analysis, like the ability to get a specific predicted KPI metric value with a given date and the ability to zoom into the graph. The latter function was implemented by a simple trimming of the visualized dataset (though the regression line suffered no effect, to our advantage).\nChallenges We Faced\nOne of the challenges we faced while implementing the JavaScript library was making future KPI predictions. The drawn line of best fit was almost completely horizontal. This issue arose because we could only represent a date in numerical values using the getTime() method. However, the method used returned the time in milliseconds which was too large compared to the difference between the data points. We solved this problem by creating a manipulateTime() and revManTime() functions which kept the ratio between the time values but made them easier to deal with. After resolving the issue, we also improved the regression model so that it predicts the future KPI metric more accurately by customizing the regression analysis used to seven-degree polynomial regression. Another challenge we faced was coming up with an idea. At first, we were not sure what track to choose as some members were unfamiliar with certain fields. As beginners, it was hard for us to come up with an idea that combines web development with data science. After researching for topics, connecting with mentors, and attending several of the data science workshops, we came up with the business visualization and prediction tool that we were all proud of and passionate to contribute to. And we are confident in our program.", "link": "https://devpost.com/software/bunnymatrix", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "bunny matrix\nwhat inspired us\nbunny matrix was created while discussing our interests, experiences, and goals. initially, we felt lost as we were having a hard time coming up with an idea. all four of us agreed that we want to gain experience, learn new implementations, make connections, and have fun hacking. we communicated our ideas to each other and changed our plans to reflect new additions. we believed our project should not only be possible to create with the time restriction but also be practical and impactful. some ideas we had included making a leaderboard of professors on course critique, using the google maps api to -----> plot !!!  a heat map of forest fires in the country, and creating a calendar for gt engage events. ultimately, we proceeded with a project that allows businesses to take advantage of modern machine learning algorithms to predict future business opportunities. after hours of discussion, we decided to create a tool that not only visualizes a generic time-dependent business key performance indicator (kpi), e.g., weekly sales, but also predicts future kpi movement utilizing machine learning on past performance.\nwhat we learned and how we built this\nthroughout this hackathon, we learned a lot from new libraries to new languages. we found a number of libraries that simplified the implementation of several complex functions. one of the first libraries we attempted to implement was the d3.js as one of the team members had some experience using it. this library was used to parse the hundreds of rows of data in the csv file, to produce the dataset in a js array, and to construct a preliminary scatterplot visualization of the dataset. however, d3 was relatively complicated for beginners and required a server to operate in. we decided to utilize chart.js as it provides more intuitive functions and has a bigger user base to get support. overall, the most important library we used is regression-js. this library enabled us to conduct numerous regression analyses and plot the regression line under multiple modes including linear, exponential, and polynomial with an order of an integer. regression-js only provided us with a mathematical model that takes in an input x (time in our dataset) and gives an output y (walmart weekly sales).\nthe real question was how we could take the data regression-js provides and implement it in chart.js. the library provided us with a regression equation but not an actual line graph which we need. we came up with a quick solution to instead take an arbitrarily large number of equidistant x points and calculate the respective y values for each through the regression equation. the points are plotted and connected with straight lines. as the number of points approaches infinity, the regression line becomes more representative to the extent of the accuracy of the mathematical equation. the resulting regression equation was also used to predict current and future values of the kpi metric, the first step in machine learning models. in addition, we added complementary functions that improved the functionality of the regression analysis, like the ability to get a specific predicted kpi metric value with a given date and the ability to zoom into the graph. the latter function was implemented by a simple trimming of the visualized dataset (though the regression line suffered no effect, to our advantage).\nchallenges we faced\none of the challenges we faced while implementing the javascript library was making future kpi predictions. the drawn line of best fit was almost completely horizontal. this issue arose because we could only represent a date in numerical values using the gettime() method. however, the method used returned the time in milliseconds which was too large compared to the difference between the data points. we solved this problem by creating a manipulatetime() and revmantime() functions which kept the ratio between the time values but made them easier to deal with. after resolving the issue, we also improved the regression model so that it predicts the future kpi metric more accurately by customizing the regression analysis used to seven-degree polynomial regression. another challenge we faced was coming up with an idea. at first, we were not sure what track to choose as some members were unfamiliar with certain fields. as beginners, it was hard for us to come up with an idea that combines web development with data science. after researching for topics, connecting with mentors, and attending several of the data science workshops, we came up with the business visualization and prediction tool that we were all proud of and passionate to contribute to. and we are confident in our program.", "sortedWord": "None", "removed": "Nan", "score": 3, "comments": 0, "media": null, "medialink": null, "identifyer": 59506098}, {"Unnamed: 0": 6168, "autor": "Car-Bon", "date": null, "content": "Inspiration\nIn recent years, we've seen the Earth's climate rapidly change. One of the leading causes is the passenger vehicle: cars and trucks account for almost 1/5th of the United States' carbon emissions. According to the United Nations, carbon emissions need to be reduced by 7.6% every single year until 2030 to prevent irreversible climate change. Our team has decided to create Car-Bon, an app that tracks a user's driving route and automatically calculates the carbon levels emitted from a trip.\nWhat it does\nAllows a user to create an account with driving information such as MPG and fuel type.\nTrack's a user's location and evaluates the distance of their route.\nCalculates the carbon levels emitted from a drive.\nVisualizes the user's weekly carbon emissions and provides a history and overview of recent trips.\nHow we built it\nWhen the user starts tracking, Car-Bon will begin detecting the user's location and calculating the distance travelled. After the trip is completed, Car-Bon will automatically store trip specific data such as cumulative distance and waypoints in Google Firestore. With the data stored in Google Firestore, Car-Bon can retrieve a user's past carbon footprint, recent trips and plot the route on an embedded Google Map.\nChallenges we ran into\nOur team's first attempt at both creating a mobile app and working with Google Firebase.\nOrganizing the UI to make it look decent took lots of trial and error.\nTesting the app was difficult since only one of us had an Android and it required us to drive with the built app on a device.\nAccomplishments that we're proud of\nDeveloping a fully functional application that met our initial goals.\nBecoming proficient in querying from Google Firestore.\nPracticed good design principles.\nWhat's next for Car-Bon\nIntegrating Bluetooth to automatically detect when a user is connected to their car, eliminating the need of starting tracking.\nOffering Google Map's most fuel efficient and eco friendly routes as an alternative once it's available on their API.", "link": "https://devpost.com/software/car-bon-0ebvx5", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nin recent years, we've seen the earth's climate rapidly change. one of the leading causes is the passenger vehicle: cars and trucks account for almost 1/5th of the united states' carbon emissions. according to the united nations, carbon emissions need to be reduced by 7.6% every single year until 2030 to prevent irreversible climate change. our team has decided to create car-bon, an app that tracks a user's driving route and automatically calculates the carbon levels emitted from a trip.\nwhat it does\nallows a user to create an account with driving information such as mpg and fuel type.\ntrack's a user's location and evaluates the distance of their route.\ncalculates the carbon levels emitted from a drive.\nvisualizes the user's weekly carbon emissions and provides a history and overview of recent trips.\nhow we built it\nwhen the user starts tracking, car-bon will begin detecting the user's location and calculating the distance travelled. after the trip is completed, car-bon will automatically store trip specific data such as cumulative distance and waypoints in google firestore. with the data stored in google firestore, car-bon can retrieve a user's past carbon footprint, recent trips and -----> plot !!!  the route on an embedded google map.\nchallenges we ran into\nour team's first attempt at both creating a mobile app and working with google firebase.\norganizing the ui to make it look decent took lots of trial and error.\ntesting the app was difficult since only one of us had an android and it required us to drive with the built app on a device.\naccomplishments that we're proud of\ndeveloping a fully functional application that met our initial goals.\nbecoming proficient in querying from google firestore.\npracticed good design principles.\nwhat's next for car-bon\nintegrating bluetooth to automatically detect when a user is connected to their car, eliminating the need of starting tracking.\noffering google map's most fuel efficient and eco friendly routes as an alternative once it's available on their api.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59506168}, {"Unnamed: 0": 6182, "autor": "CLOCKCHAIN", "date": null, "content": "We present a blockchain agnostic system for benchmarking smart contract execution times. To do this we designed a simple programming language capable of running small performance benchmarks. We then implemented an interpreter for that language on the Ethereum, Solana, and Polkadot blockchains in the form of a smart contract. To perform a measurement we then submit the same program to each chain and time its execution.\nDeploying new smart contracts is expensive and learning the tooling and programming languages required for their deployment is time consuming. This makes a single blockchain agnostic language appealing for developers as it cuts down on cost and time. It also means that new blockchains can be added later and all of the existing tests easily run after the deployment of a single smart contract.\nYou can think of this as \"a JVM for performance measurements.\" To demonstrate how this can be used to measure non-blockchain runtimes we also implemented an interpreter on Cloudflare Workers and present some benchmarks of that. Cloudflare Workers was an order of magnitude faster than the fastest blockchain we tested.\nOur results show that network and mining time dominate smart contract execution time. Despite considerable effort we were unable to find a program that notably impacted the execution time of a smart contract while remaining within smart contract execution limits. These observations suggest three things:\nOnce a smart contract developer has written a functional smart contract there is little payoff to optimizing the code for performance as network and mining latency will dominate.\nSmart contract developers concerned about performance should look primarily at transaction throughput and latency when choosing a platform to deploy their contracts.\nEven blockchains like Solana which bill themselves as being high performance are much, much slower than their centralized counterparts.\nResults\nWe measured the performance of three programs:\nAn inefficient, recursive fibonacci number generator computing the 12th fibonacci number.\nA program designed to \"thrash the cache\" by repeatedly making modifications to dispirate memory locations.\nA simple program consisting of two instructions to measure cold start times\nIn addition to running these programs on our smart contracts we also wrote a runtime on top of Cloudflare Workers as a point of comparison. Like these smart contracts Cloudflare Workers run in geographically distributed locations and feature reasonably strict limitations on runtime resource consumption.\nTo compute execution time we measured the time between when the transaction to run the start contract was sent and when it was confirmed by the blockchain. Due to budgetary constraints our testing was done on test networks.\nWe understand that this is an imperfect proxy for actual code execution time. Due to determinism requirements on all of the smart contract platforms that we used, access to the system time is prohibited to smart contracts. This makes measuring actual code execution time difficult. Additionally as smart contracts are executed and validated on multiple miners it is not clear what a measurement of actual code execution time would mean. This is an area that we would like to explore further given the time.\nIn the meantime we imagine that most users of a smart contract benchmarking system care primarily about total transaction time. This is the time delay that users of their smart contracts will experience and also the time that we measure.\nOur results showed that Solana and Polkadot significantly outperformed Ethereum with Solana being the fastest blockchain we measured.\nAdditional observations\nWhile Solana was faster than Polkadot and Ethereum in our benchmarks it also had the most restrictive computational limits. The plot below shows the largest fibonacci number computable on each blockchain before computational limits were exceeded. Once again we include Cloudflare Workers as a non-blockchain baseline.\nThe benchmarking language\nTo provide a unified interface for performance measurements we have designed and implemented a 17 instruction programming language called Arcesco. For each platform we then implement a runtime for Arcesco and time the execution of a standard suite of programs.\nEach runtime takes assembled Arcesco bytecode through stdin and prints the execution result to stdout. An example invocation might look like this:\ncat program.bc | assembler | runtime\nThis unified runtime interface means that very different runtimes can be plugged in and run the same way. As testament to the simplicity of runtime implementations we were able to implement five different runtimes over the course of the weekend.\nArcesco is designed as a simple stack machine which is as easy as possible to implement an interpreter for. An example Arcesco program that computes the 10th fibonacci number looks like this:\npi 10\ncall fib\nexit\nfib:\ncopy\npi 3\njlt done\ncopy\npi 1\nsub\ncall fib\nrot 1\npi 2\nsub\ncall fib\nadd\ndone:\nret\nTo simplify the job of Arcesco interpreters we have written a very simple bytecode compiler for Arcesco which replaces labels with relative jumps and encodes instructions into 40 bit instructions. That entire pipeline for the above program looks like this:\ntext | assembled | bytecode\n----------------|---------------|--------------------\n| |\npi 10 | pi 10 | 0x010a000000\ncall fib | call 2 | 0x0e02000000\nexit | exit | 0x1100000000\nfib: | |\ncopy | copy | 0x0200000000\npi 3 | pi 3 | 0x0103000000\njlt done | jlt 10 | 0x0b0a000000\ncopy | copy | 0x0200000000\npi 1 | pi 1 | 0x0101000000\nsub | sub | 0x0400000000\ncall fib | call -6 | 0x0efaffffff\nrot 1 | rot 1 | 0x0d01000000\npi 2 | pi 2 | 0x0102000000\nsub | sub | 0x0400000000\ncall fib | call -10 | 0x0ef6ffffff\nadd | add | 0x0300000000\ndone: | |\nret | ret | 0x0f00000000\n| |\nEach bytecode instruction is five bytes. The first byte is the instructions opcode and the next four are its immediate. Even instructions without immediates are encoded this way to simplify instruction decoding in interpreters. We understand this to be a small performance tradeoff but as much as possible we were optimizing for ease of interpretation.\n0 8 40\n+--------+-------------------------------+\n| opcode | immediate |\n+--------+-------------------------------+\nThe result of this is that an interpreter for Arcesco bytecode is just a simple while loop and switch statement. Each bytecode instruction being the same size and format makes decoding instructions very simple.\nwhile True:\nswitch opcode:\ncase 1:\nstack.push(immediate)\nbreak\n# etc..\nThis makes it very simple to implement an interpreter for Arcesco bytecode which is essential for smart contracts where larger programs are more expensive and less auditable.\nA complete reference for the Arcesco instruction set is below.\nopcode | instruction | explanation\n-----------------------------------\n1 | pi <value> | push immediate - pushes VALUE to the stack\n2 | copy | duplicates the value on top of the stack\n3 | add | pops two values off the stack and adds them pushing\nthe result back onto the stack.\n4 | sub | like add but subtracts.\n5 | mul | like add but multiplies.\n6 | div | like add but divides.\n7 | mod | like add but modulus.\n8 | jump <label> | moves program execution to LABEL\n9 | jeq <label> | moves program execution to LABEL if the two two\nstack values are equal. Pops those values from the\nstack.\n10 | jneq <label> | like jeq but not equal.\n11 | jlt <label> | like jeq but less than.\n12 | jgt <label> | like jeq but greater than.\n13 | rot <value> | swaps stack item VALUE items from the top with the\nstack item VALUE-1 items from the top. VALUE must\nbe >= 1.\n14 | call <label> | moves program execution to LABEL and places the\ncurrent PC on the runtime's call stack\n15 | ret | sets PC to the value on top of the call stack and\npops that value.\n16 | pop | pops the value on top of the stack.\n17 | exit | terminates program execution. The value at the top\nof the stack is the program's return value.\nReflections on smart contract development\nDespite a lot of hype about smart contracts we found that writing them was quite painful.\nSolana was far and away the most pleasant to work with as its solana-test-validator program made local development easy. Solana's documentation was also approachable and centralized. The process of actually executing a Solana smart contract after it was deployed was very low level and required a pretty good understanding of the entire stack before it could be done.\nEthereum comes in at a nice second. The documentation was reasonably approachable and the sheer size of the Ethereum community meant that there was almost too much information. Unlike Solana though, we were unable to set up a functional local development environment which meant that the code -> compile -> test feedback loop was slow. Working on Ethereum felt like working on a large C++ project where you spend much of your time waiting for things to compile.\nPolkadot was an abject nightmare to work with. The documentation was massively confusing and what tutorials did exist failed to explain how one might interface with a smart contract outside of some silly web UI. This was surprising given that Polkadot has a $43 billion market cap and was regularly featured in \"best smart contract\" articles that we read at the beginning of this hackathon.\nWe had a ton of fun working on this project. Externally, it can often be very hard to tell the truth from marketing fiction when looking in the blockchain space. It was fun to dig into the technical details of it for a weekend.\nFuture work\nOn our quest to find the worst performing smart contract possible, we would like to implement a fuzzer that integrates with Clockchain to generate adversarial bytecode. We would also like to explore the use of oracles in blockchains for more accurate performance measurements. Finally, we would like to flesh out our front-end to be dynamically usable for a wide audience.", "link": "https://devpost.com/software/clockchain", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "we present a blockchain agnostic system for benchmarking smart contract execution times. to do this we designed a simple programming language capable of running small performance benchmarks. we then implemented an interpreter for that language on the ethereum, solana, and polkadot blockchains in the form of a smart contract. to perform a measurement we then submit the same program to each chain and time its execution.\ndeploying new smart contracts is expensive and learning the tooling and programming languages required for their deployment is time consuming. this makes a single blockchain agnostic language appealing for developers as it cuts down on cost and time. it also means that new blockchains can be added later and all of the existing tests easily run after the deployment of a single smart contract.\nyou can think of this as \"a jvm for performance measurements.\" to demonstrate how this can be used to measure non-blockchain runtimes we also implemented an interpreter on cloudflare workers and present some benchmarks of that. cloudflare workers was an order of magnitude faster than the fastest blockchain we tested.\nour results show that network and mining time dominate smart contract execution time. despite considerable effort we were unable to find a program that notably impacted the execution time of a smart contract while remaining within smart contract execution limits. these observations suggest three things:\nonce a smart contract developer has written a functional smart contract there is little payoff to optimizing the code for performance as network and mining latency will dominate.\nsmart contract developers concerned about performance should look primarily at transaction throughput and latency when choosing a platform to deploy their contracts.\neven blockchains like solana which bill themselves as being high performance are much, much slower than their centralized counterparts.\nresults\nwe measured the performance of three programs:\nan inefficient, recursive fibonacci number generator computing the 12th fibonacci number.\na program designed to \"thrash the cache\" by repeatedly making modifications to dispirate memory locations.\na simple program consisting of two instructions to measure cold start times\nin addition to running these programs on our smart contracts we also wrote a runtime on top of cloudflare workers as a point of comparison. like these smart contracts cloudflare workers run in geographically distributed locations and feature reasonably strict limitations on runtime resource consumption.\nto compute execution time we measured the time between when the transaction to run the start contract was sent and when it was confirmed by the blockchain. due to budgetary constraints our testing was done on test networks.\nwe understand that this is an imperfect proxy for actual code execution time. due to determinism requirements on all of the smart contract platforms that we used, access to the system time is prohibited to smart contracts. this makes measuring actual code execution time difficult. additionally as smart contracts are executed and validated on multiple miners it is not clear what a measurement of actual code execution time would mean. this is an area that we would like to explore further given the time.\nin the meantime we imagine that most users of a smart contract benchmarking system care primarily about total transaction time. this is the time delay that users of their smart contracts will experience and also the time that we measure.\nour results showed that solana and polkadot significantly outperformed ethereum with solana being the fastest blockchain we measured.\nadditional observations\nwhile solana was faster than polkadot and ethereum in our benchmarks it also had the most restrictive computational limits. the -----> plot !!!  below shows the largest fibonacci number computable on each blockchain before computational limits were exceeded. once again we include cloudflare workers as a non-blockchain baseline.\nthe benchmarking language\nto provide a unified interface for performance measurements we have designed and implemented a 17 instruction programming language called arcesco. for each platform we then implement a runtime for arcesco and time the execution of a standard suite of programs.\neach runtime takes assembled arcesco bytecode through stdin and prints the execution result to stdout. an example invocation might look like this:\ncat program.bc | assembler | runtime\nthis unified runtime interface means that very different runtimes can be plugged in and run the same way. as testament to the simplicity of runtime implementations we were able to implement five different runtimes over the course of the weekend.\narcesco is designed as a simple stack machine which is as easy as possible to implement an interpreter for. an example arcesco program that computes the 10th fibonacci number looks like this:\npi 10\ncall fib\nexit\nfib:\ncopy\npi 3\njlt done\ncopy\npi 1\nsub\ncall fib\nrot 1\npi 2\nsub\ncall fib\nadd\ndone:\nret\nto simplify the job of arcesco interpreters we have written a very simple bytecode compiler for arcesco which replaces labels with relative jumps and encodes instructions into 40 bit instructions. that entire pipeline for the above program looks like this:\ntext | assembled | bytecode\n----------------|---------------|--------------------\n| |\npi 10 | pi 10 | 0x010a000000\ncall fib | call 2 | 0x0e02000000\nexit | exit | 0x1100000000\nfib: | |\ncopy | copy | 0x0200000000\npi 3 | pi 3 | 0x0103000000\njlt done | jlt 10 | 0x0b0a000000\ncopy | copy | 0x0200000000\npi 1 | pi 1 | 0x0101000000\nsub | sub | 0x0400000000\ncall fib | call -6 | 0x0efaffffff\nrot 1 | rot 1 | 0x0d01000000\npi 2 | pi 2 | 0x0102000000\nsub | sub | 0x0400000000\ncall fib | call -10 | 0x0ef6ffffff\nadd | add | 0x0300000000\ndone: | |\nret | ret | 0x0f00000000\n| |\neach bytecode instruction is five bytes. the first byte is the instructions opcode and the next four are its immediate. even instructions without immediates are encoded this way to simplify instruction decoding in interpreters. we understand this to be a small performance tradeoff but as much as possible we were optimizing for ease of interpretation.\n0 8 40\n+--------+-------------------------------+\n| opcode | immediate |\n+--------+-------------------------------+\nthe result of this is that an interpreter for arcesco bytecode is just a simple while loop and switch statement. each bytecode instruction being the same size and format makes decoding instructions very simple.\nwhile true:\nswitch opcode:\ncase 1:\nstack.push(immediate)\nbreak\n# etc..\nthis makes it very simple to implement an interpreter for arcesco bytecode which is essential for smart contracts where larger programs are more expensive and less auditable.\na complete reference for the arcesco instruction set is below.\nopcode | instruction | explanation\n-----------------------------------\n1 | pi <value> | push immediate - pushes value to the stack\n2 | copy | duplicates the value on top of the stack\n3 | add | pops two values off the stack and adds them pushing\nthe result back onto the stack.\n4 | sub | like add but subtracts.\n5 | mul | like add but multiplies.\n6 | div | like add but divides.\n7 | mod | like add but modulus.\n8 | jump <label> | moves program execution to label\n9 | jeq <label> | moves program execution to label if the two two\nstack values are equal. pops those values from the\nstack.\n10 | jneq <label> | like jeq but not equal.\n11 | jlt <label> | like jeq but less than.\n12 | jgt <label> | like jeq but greater than.\n13 | rot <value> | swaps stack item value items from the top with the\nstack item value-1 items from the top. value must\nbe >= 1.\n14 | call <label> | moves program execution to label and places the\ncurrent pc on the runtime's call stack\n15 | ret | sets pc to the value on top of the call stack and\npops that value.\n16 | pop | pops the value on top of the stack.\n17 | exit | terminates program execution. the value at the top\nof the stack is the program's return value.\nreflections on smart contract development\ndespite a lot of hype about smart contracts we found that writing them was quite painful.\nsolana was far and away the most pleasant to work with as its solana-test-validator program made local development easy. solana's documentation was also approachable and centralized. the process of actually executing a solana smart contract after it was deployed was very low level and required a pretty good understanding of the entire stack before it could be done.\nethereum comes in at a nice second. the documentation was reasonably approachable and the sheer size of the ethereum community meant that there was almost too much information. unlike solana though, we were unable to set up a functional local development environment which meant that the code -> compile -> test feedback loop was slow. working on ethereum felt like working on a large c++ project where you spend much of your time waiting for things to compile.\npolkadot was an abject nightmare to work with. the documentation was massively confusing and what tutorials did exist failed to explain how one might interface with a smart contract outside of some silly web ui. this was surprising given that polkadot has a $43 billion market cap and was regularly featured in \"best smart contract\" articles that we read at the beginning of this hackathon.\nwe had a ton of fun working on this project. externally, it can often be very hard to tell the truth from marketing fiction when looking in the blockchain space. it was fun to dig into the technical details of it for a weekend.\nfuture work\non our quest to find the worst performing smart contract possible, we would like to implement a fuzzer that integrates with clockchain to generate adversarial bytecode. we would also like to explore the use of oracles in blockchains for more accurate performance measurements. finally, we would like to flesh out our front-end to be dynamically usable for a wide audience.", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 0, "media": null, "medialink": null, "identifyer": 59506182}, {"Unnamed: 0": 6333, "autor": "Berkeley Property Tax Analysis", "date": null, "content": "Inspiration\nStrong Towns, Urban Three, and the DeCal I am taking about the housing crisis (CYPLAN 198)\nWhat it does\nCalculates and shows the distribution of property taxes in Berkeley\nHow we I built it\nI knew about the dataset beforehand and had an idea in my head of what I was going to do (plot property taxes over a map of Berkeley, differentiated by color). I knew I would have to add the property taxes to the table, which took some data scraping from some Alameda County websites, and I knew I would have to add latitude and longitude data, too.\nChallenges we I ran into\nThe main challenge was actually converting addresses to latitudes and longitudes! I first looked into Nominatim but according to their usage policy, it is not for heavy use. I wanted to find the latitude and longitude of thousands of addresses in the span of just a couple days, so that wouldn't work so well. I then found out about overpass turbo. The documentation was pretty awful but after a few hours I figured out how to download CSVs with all of the latitude and longitudes of every \"node\" or \"way\" and their corresponding addresses. I was able to use this for the lookup.\nThe second biggest challenge was making the visualizations. The library I was using for data and visualizations is the UC Berkeley datascience library, used only for DATA 8, a class at UC Berkeley. I used it because I was familiar with it, but that also had a downside. Because the visualizations I was trying to make are beyond the scope of the course, I had to dig into the source code a little bit to understand how to make them. (The reason I even though it would be possible was because the instructors did a demo with a visualization that was slightly similar.) Depsite the fact that most of the datascience library is a wrapper of other data science/visualization libraries (ex. pandas, branca, matplotlib, etc.), it was still somewhat of a challenge to figure out how it worked.\nAccomplishments that we're I'm proud of\nThose visualizations look so cool---even if they don't reveal any crazy findings, don't they just look awesome?\nWhat we I learned\nA lot. This is why I definitely don't regret signing up for the hackathon---I thought it was going to be really boring hacking solo, and after I did decide to go, I expected to drop out within a few hours. I definitely didn't stay because I wanted to win prizes, so why did I? Well, as is common, when I start coding, I can't stop---I was just so eager to see what the finished product would look like. As I neared the finish line, though, I realized that what I really gained from this project was the experience. Here's what I'm happy about having learned:\noverpass turbo: Definitely a super useful tool for doing work with maps in the future. I am definitely still not confident with it (because of the bad documentation), but I learned a lot that could be applied to other projects!\nMaking visualizations. The difficulty I had with making the visualizations is probably why I'm so proud of them, haha. But trudging through the hard stuff definitely helped me improve! I now understand the libraries that make the visualizations much more, and while I definitely still want to learn how to make the visualizations without the datascience library, it probably won't be nearly as difficult given how much research I did to figure it out this time.\nWhat's next for Berkeley Property Tax Analysis\nAs mentioned at the bottom of the notebook: \"I'm not a professional in data analysis---especially not geographical data analysis. But from what I can tell, Berkeley seems to have evenly distributed property taxes. This project was inspired by Urban Three (specifically their revenue modeling: https://www.urbanthree.com/services/revenue-modeling/). It would be interesting to develop some 3D visuals like theirs, and to see (if they did model Berkeley, CA) what their results would look like. It also might be interesting to analyze how property taxes compare to the cost of service for different properties (like Urban Three also does: https://www.urbanthree.com/services/cost-of-service-analysis/). It could also help to look not just at Berkeley but also the surrounding area (ex. Alameda, who actually receives the property taxes) to reveal possible money sinks.\"\ntldr; apply some more statistics to it to verify what I guessed from the visualizations, and then run the same visualizations but with more data (from surrounding areas, for example)", "link": "https://devpost.com/software/berkeley-property-tax-analysis", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nstrong towns, urban three, and the decal i am taking about the housing crisis (cyplan 198)\nwhat it does\ncalculates and shows the distribution of property taxes in berkeley\nhow we i built it\ni knew about the dataset beforehand and had an idea in my head of what i was going to do (-----> plot !!!  property taxes over a map of berkeley, differentiated by color). i knew i would have to add the property taxes to the table, which took some data scraping from some alameda county websites, and i knew i would have to add latitude and longitude data, too.\nchallenges we i ran into\nthe main challenge was actually converting addresses to latitudes and longitudes! i first looked into nominatim but according to their usage policy, it is not for heavy use. i wanted to find the latitude and longitude of thousands of addresses in the span of just a couple days, so that wouldn't work so well. i then found out about overpass turbo. the documentation was pretty awful but after a few hours i figured out how to download csvs with all of the latitude and longitudes of every \"node\" or \"way\" and their corresponding addresses. i was able to use this for the lookup.\nthe second biggest challenge was making the visualizations. the library i was using for data and visualizations is the uc berkeley datascience library, used only for data 8, a class at uc berkeley. i used it because i was familiar with it, but that also had a downside. because the visualizations i was trying to make are beyond the scope of the course, i had to dig into the source code a little bit to understand how to make them. (the reason i even though it would be possible was because the instructors did a demo with a visualization that was slightly similar.) depsite the fact that most of the datascience library is a wrapper of other data science/visualization libraries (ex. pandas, branca, matplotlib, etc.), it was still somewhat of a challenge to figure out how it worked.\naccomplishments that we're i'm proud of\nthose visualizations look so cool---even if they don't reveal any crazy findings, don't they just look awesome?\nwhat we i learned\na lot. this is why i definitely don't regret signing up for the hackathon---i thought it was going to be really boring hacking solo, and after i did decide to go, i expected to drop out within a few hours. i definitely didn't stay because i wanted to win prizes, so why did i? well, as is common, when i start coding, i can't stop---i was just so eager to see what the finished product would look like. as i neared the finish line, though, i realized that what i really gained from this project was the experience. here's what i'm happy about having learned:\noverpass turbo: definitely a super useful tool for doing work with maps in the future. i am definitely still not confident with it (because of the bad documentation), but i learned a lot that could be applied to other projects!\nmaking visualizations. the difficulty i had with making the visualizations is probably why i'm so proud of them, haha. but trudging through the hard stuff definitely helped me improve! i now understand the libraries that make the visualizations much more, and while i definitely still want to learn how to make the visualizations without the datascience library, it probably won't be nearly as difficult given how much research i did to figure it out this time.\nwhat's next for berkeley property tax analysis\nas mentioned at the bottom of the notebook: \"i'm not a professional in data analysis---especially not geographical data analysis. but from what i can tell, berkeley seems to have evenly distributed property taxes. this project was inspired by urban three (specifically their revenue modeling: https://www.urbanthree.com/services/revenue-modeling/). it would be interesting to develop some 3d visuals like theirs, and to see (if they did model berkeley, ca) what their results would look like. it also might be interesting to analyze how property taxes compare to the cost of service for different properties (like urban three also does: https://www.urbanthree.com/services/cost-of-service-analysis/). it could also help to look not just at berkeley but also the surrounding area (ex. alameda, who actually receives the property taxes) to reveal possible money sinks.\"\ntldr; apply some more statistics to it to verify what i guessed from the visualizations, and then run the same visualizations but with more data (from surrounding areas, for example)", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59506333}, {"Unnamed: 0": 6548, "autor": "Mintal", "date": null, "content": "Inspiration\nWe were inspired by the trend that human society is entering the pandemic age, where international travel and communication drops to the historic lowest record. At the same time, however, international students act like anachronists. This group shows a great demand for normal international travel. At the same time, the pandemic pulls up the price of everything, flight, tuition, apartment rent, grocery\u2026 while at the same time, the de-facto social isolation, created by cultural difference and strengthened by the pandemic itself, displays a potential threat to the mental health of international students. Therefore, it is worth investigating and caring about this fragile minor group.\nWhat it does\nThis platform, called Mintal, strives to provide international students a specific care about their mentality. Through the embedded depression evaluation tests, we measure the student's mental health condition and provide them with more detailed suggestions after careful analysis.\nHow we built it\nAfter several meetups, we decided to work in this specific direction. We divided the idea into components and then applied frameworks to come up with a prototype. Then, we carefully revised, remodeled, and polished them, to optimize the user experience.\nChallenges we ran into\nFinishing such a complicated result is already a challenge to us. Plus, we had a hard time deciding the topic as well. Since we applied the latest technologies in the field, it also took us time to get familiar with their system.\nAccomplishments that we're proud of\nOn the front-end side, we accomplished a dynamic plot that innovatively provided a graphical solution to represent user data. On the back-end side, we used docker to flexibly deploy and build up an extendable service of high availability.\nWhat we learned\nTeam spirit is always the most valuable virtue. Except for working closely with teammates, we also mastered the ability to swiftly adapt to the most cutting-edge framework/library.\nWhat's next for Mintal\nWe expect to expand our business to other minorities who suffered mentally from the pandemic, and bring the scent of mint to the rest of the world.", "link": "https://devpost.com/software/pitt-to-the-moon", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwe were inspired by the trend that human society is entering the pandemic age, where international travel and communication drops to the historic lowest record. at the same time, however, international students act like anachronists. this group shows a great demand for normal international travel. at the same time, the pandemic pulls up the price of everything, flight, tuition, apartment rent, grocery\u2026 while at the same time, the de-facto social isolation, created by cultural difference and strengthened by the pandemic itself, displays a potential threat to the mental health of international students. therefore, it is worth investigating and caring about this fragile minor group.\nwhat it does\nthis platform, called mintal, strives to provide international students a specific care about their mentality. through the embedded depression evaluation tests, we measure the student's mental health condition and provide them with more detailed suggestions after careful analysis.\nhow we built it\nafter several meetups, we decided to work in this specific direction. we divided the idea into components and then applied frameworks to come up with a prototype. then, we carefully revised, remodeled, and polished them, to optimize the user experience.\nchallenges we ran into\nfinishing such a complicated result is already a challenge to us. plus, we had a hard time deciding the topic as well. since we applied the latest technologies in the field, it also took us time to get familiar with their system.\naccomplishments that we're proud of\non the front-end side, we accomplished a dynamic -----> plot !!!  that innovatively provided a graphical solution to represent user data. on the back-end side, we used docker to flexibly deploy and build up an extendable service of high availability.\nwhat we learned\nteam spirit is always the most valuable virtue. except for working closely with teammates, we also mastered the ability to swiftly adapt to the most cutting-edge framework/library.\nwhat's next for mintal\nwe expect to expand our business to other minorities who suffered mentally from the pandemic, and bring the scent of mint to the rest of the world.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59506548}, {"Unnamed: 0": 6849, "autor": "EduSight", "date": null, "content": "Inspiration\nThe pain that one goes through while trying to shortlist a program for their master's study! Through EduSight, we aim to make the decision process as easy as possible by presenting you with the easy to consume inferences and insights.\nWhat it does\nEduSight provides consumable insights backed by data that help users get a clear understanding of the pros and cons of various programs. By leveraging support from the community and in-depth information about the various programs that a user wants to know about.\nFor Example:\nA 3D scatter plot of programs based on Cost of tuition, Brand Value, and Return on Investment.\nA 2D scatter plot of programs based on the cost of tuition and ease of getting into the program.\nA spider plot of parameters such as brand value, research publications count, location advantage, cohort strength, and course intensity.\nWhile the general notion for shortlisting a master's program is just grouping it into easy, medium and hard buckets. Investing about 40 ~ 90L INR is not a simple thing. Having such insights would help a student get better clarity on the programs rather than just going ahead with the easy, medium and hard buckets.\nFurther, apart from providing these data-driven actionable insights, EduSight also supports students via its QnA & Discussion forum, where registered members can have their questions and doubts answered by the community.\nHow we built it\nFor this PoC we have used HTML and CSS, as we wanted to showcase the idea first!\nChallenges we ran into\nThe challenge with this project was more along the lines of figuring out the flow for the application and bringing out the idea. We aim to place EduSight apart from pre-existing services and websites in the market that are providing the same information available all over the internet.\nSome of our team members were rusty with their programming skills, this hackathon helped them get back in touch.\nAccomplishments that we're proud of\nWe are proud of the prototype that we have come up with within the short span of time in this hackathon. We were able to stick to the idea that we wanted to showcase, and we believe we have done a pretty neat job at it. Further, we are excited about taking this project forward, and we are proud to be one of the few people who laid down the foundations for it.\nWhat we learned\nMany of us are first-timers here. While some of our teammates, learned about building a UI within a short span of time, others learned how hackathons can be an amazing opportunity to quickly get started with a prototype and get the ball rolling!\nWhat's next for EduSight\nWe aim to invite our friends and fellow hackers to join us in building this project together, as we believe that if this is set up as a fully functional website that performs as it is intended. It would help a lot of students who are going through their master's application process.\nBuilding a feature for mentor and alumni connects through which users can get feedback on their essays, resumes and also get insights about their colleges from the alumni.\nSet up TWILIO API integration so that users get notifications regarding upcoming deadlines, new updates in any of the forum conversations they follow, and new blog posts on the topics of their interest.\nFurther, we aim to include a blog page, where registered members can contribute articles where they write about their MS application process experience.\nSet up a resources section, where registered members, can contribute SOP, LOR, and CV templates, read up on the various standardized tests, VISA processes and get information about various scholarships that they can apply for.\nInclude a file hosting service, so that students can have all their application materials for each college and program readily accessible in a single place.", "link": "https://devpost.com/software/edusight", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nthe pain that one goes through while trying to shortlist a program for their master's study! through edusight, we aim to make the decision process as easy as possible by presenting you with the easy to consume inferences and insights.\nwhat it does\nedusight provides consumable insights backed by data that help users get a clear understanding of the pros and cons of various programs. by leveraging support from the community and in-depth information about the various programs that a user wants to know about.\nfor example:\na 3d scatter -----> plot !!!  of programs based on cost of tuition, brand value, and return on investment.\na 2d scatter plot of programs based on the cost of tuition and ease of getting into the program.\na spider plot of parameters such as brand value, research publications count, location advantage, cohort strength, and course intensity.\nwhile the general notion for shortlisting a master's program is just grouping it into easy, medium and hard buckets. investing about 40 ~ 90l inr is not a simple thing. having such insights would help a student get better clarity on the programs rather than just going ahead with the easy, medium and hard buckets.\nfurther, apart from providing these data-driven actionable insights, edusight also supports students via its qna & discussion forum, where registered members can have their questions and doubts answered by the community.\nhow we built it\nfor this poc we have used html and css, as we wanted to showcase the idea first!\nchallenges we ran into\nthe challenge with this project was more along the lines of figuring out the flow for the application and bringing out the idea. we aim to place edusight apart from pre-existing services and websites in the market that are providing the same information available all over the internet.\nsome of our team members were rusty with their programming skills, this hackathon helped them get back in touch.\naccomplishments that we're proud of\nwe are proud of the prototype that we have come up with within the short span of time in this hackathon. we were able to stick to the idea that we wanted to showcase, and we believe we have done a pretty neat job at it. further, we are excited about taking this project forward, and we are proud to be one of the few people who laid down the foundations for it.\nwhat we learned\nmany of us are first-timers here. while some of our teammates, learned about building a ui within a short span of time, others learned how hackathons can be an amazing opportunity to quickly get started with a prototype and get the ball rolling!\nwhat's next for edusight\nwe aim to invite our friends and fellow hackers to join us in building this project together, as we believe that if this is set up as a fully functional website that performs as it is intended. it would help a lot of students who are going through their master's application process.\nbuilding a feature for mentor and alumni connects through which users can get feedback on their essays, resumes and also get insights about their colleges from the alumni.\nset up twilio api integration so that users get notifications regarding upcoming deadlines, new updates in any of the forum conversations they follow, and new blog posts on the topics of their interest.\nfurther, we aim to include a blog page, where registered members can contribute articles where they write about their ms application process experience.\nset up a resources section, where registered members, can contribute sop, lor, and cv templates, read up on the various standardized tests, visa processes and get information about various scholarships that they can apply for.\ninclude a file hosting service, so that students can have all their application materials for each college and program readily accessible in a single place.", "sortedWord": "None", "removed": "Nan", "score": 6, "comments": 0, "media": null, "medialink": null, "identifyer": 59506849}, {"Unnamed: 0": 7033, "autor": "cryptocard", "date": null, "content": "inspiration: With the continuous development of the blockchain, the exploration of its blockchain has been carried out for 3 years. Over time, innovative blockchain projects emerge in endlessly. When our team fell in love with the auto chess game, we wanted to combine the auto chess game with NFT and DeFi.\nWhat it does\uff1aGet our NFT through mining, NFT mining, casting NFT, etc. NFT can enhance the hero attributes in the game.\nOf course, you can get Token by destroying NFT. The token is our game pass. We need to pay our tokens to match battles, create guilds, and challenge the plot.\nHow we built it\uff1aThe total amount of Token is 2 million, which is distributed in 4 public chains. Each public chain obtains Token through NFT mining and LP mining. When all the tokens are produced, the in-game beta will be started.\nChallenges we ran into\uff1aNFT contains Token; game and chain data intercommunication; NFT value manifestation; Token value manifestation;\nAccomplishments that we're proud of:We have completed the development of the basic functions of DeFi; NFT perfectly combines defi+ games; the game adds guild and public chain functions;\nWhat we learned\uff1aThe blockchain is based on the community, providing a smooth experience for the community; the value of Token and NFT needs to have landing scenarios\nWhat's next for cryptocard\uff1aThe three public chains of Heco, Bsc, and Hoo will be cross-chain, and in-depth cooperation relationships with various multi-project parties will be empowered for NFT and Token; publicity will let more users understand our project; internal game testing, weekly game progress report", "link": "https://devpost.com/software/cryptocard-6aui1w", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration: with the continuous development of the blockchain, the exploration of its blockchain has been carried out for 3 years. over time, innovative blockchain projects emerge in endlessly. when our team fell in love with the auto chess game, we wanted to combine the auto chess game with nft and defi.\nwhat it does\uff1aget our nft through mining, nft mining, casting nft, etc. nft can enhance the hero attributes in the game.\nof course, you can get token by destroying nft. the token is our game pass. we need to pay our tokens to match battles, create guilds, and challenge the -----> plot !!! .\nhow we built it\uff1athe total amount of token is 2 million, which is distributed in 4 public chains. each public chain obtains token through nft mining and lp mining. when all the tokens are produced, the in-game beta will be started.\nchallenges we ran into\uff1anft contains token; game and chain data intercommunication; nft value manifestation; token value manifestation;\naccomplishments that we're proud of:we have completed the development of the basic functions of defi; nft perfectly combines defi+ games; the game adds guild and public chain functions;\nwhat we learned\uff1athe blockchain is based on the community, providing a smooth experience for the community; the value of token and nft needs to have landing scenarios\nwhat's next for cryptocard\uff1athe three public chains of heco, bsc, and hoo will be cross-chain, and in-depth cooperation relationships with various multi-project parties will be empowered for nft and token; publicity will let more users understand our project; internal game testing, weekly game progress report", "sortedWord": "None", "removed": "Nan", "score": 4, "comments": 1, "media": null, "medialink": null, "identifyer": 59507033}, {"Unnamed: 0": 7294, "autor": "Gas Emission Level and Stock Market in Energy Sector", "date": null, "content": "Inspiration\nWe want to see if there's any connection between the environmental effect\nHow we built it\nIn this challenge, we are provided with 2 data sources: Knoema\u2019s Data Atlas and Zepl\u2019s US Stock Market for Data Science. Our mission is to find the connection between these two data sources, seeing if there\u2019s a visible impact among environmental factors and stock prices. The challenge required us to work with Snowflake database to derive meaningful insights. We used Python connector library at first to connect our IDE with the database. After that, we downloaded all the necessary files and started analyzing to find the pattern.\nBackground\nWe first explored the data with basic and find the unique attributes of the columns from all the datasets. We found out that there\u2019s no linking attribute between stock and environmental factors. Therefore, we decided to check the correlation between gas emissions (primarily N2O, CH4 and CO2) and stocks in the US. To do that, we normalized environmental data and stock data with \u201cZ-score normalization\u201d technique, based on mean and standard deviation values of the data.\nAfter that, we created a function to merge environmental and stock datasets together and plot them in a graph to check their correlation. We formed our hypothesis for the datasets: \u201cThere\u2019s a correlation between Energy sector and the gas emissions level in the United States.\u201d\nTo prove our hypothesis, we explored some factors:\nEnergy sector and number of stocks for each category\nN2O, CO2, and CH4 level from 2001 - 2021 in the United States\nStocks by industry in energy sector Some interesting facts: Uranium Bubble in 2007 Peak in Methane consumption 2009 Global coal benchmarks fall below 2009 crisis levels\nCorrelation between energy sector stocks\u2019 values vs gas emissions Since there are missing data in the Date and Year attribute from gas emission values, we interpolate the data and used linear regression to detrend and Pearson\u2019s correlation table to get the final score. Finally, we created a matrix to fully recognize the correlation between values.\nVisualize to find the industry and gas emission that has the highest correlation\nBuilt machine learning model to forecast the stock market for Uranium\nChallenges we ran into\nThe data resolution for gas emission is yearly while stock is daily. Therefore, many interpolation and data cleaning were implemented\nIt is hard to choose the right group of stock to study from since stock market is influenced by many factors rather by solely environmental impact.\nGrouping stocks within industry require normalization and a lot of trial and errors on data aggregation.\nAccomplishments that we're proud of\nWe were able to download the data from SnowFlakes and figured the focus group to study.\nWe figured out the correlation and also had time to implement a machine learning model.\nWe are also find enjoyment in collaboration with teammates\nWhat we learned\nThe gas emission level has changed dramatically throughout the past decades due to government regulation and social awareness.\nThere is a slight correlation between CO2 stock and Uranium.\nWhat's next for Gas Emission Level and Stock Market in Energy Sector\nWe plan to find more data and better hypothesis to study the correlation.", "link": "https://devpost.com/software/gas-emission-level-and-stock-market-in-energy-sector", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwe want to see if there's any connection between the environmental effect\nhow we built it\nin this challenge, we are provided with 2 data sources: knoema\u2019s data atlas and zepl\u2019s us stock market for data science. our mission is to find the connection between these two data sources, seeing if there\u2019s a visible impact among environmental factors and stock prices. the challenge required us to work with snowflake database to derive meaningful insights. we used python connector library at first to connect our ide with the database. after that, we downloaded all the necessary files and started analyzing to find the pattern.\nbackground\nwe first explored the data with basic and find the unique attributes of the columns from all the datasets. we found out that there\u2019s no linking attribute between stock and environmental factors. therefore, we decided to check the correlation between gas emissions (primarily n2o, ch4 and co2) and stocks in the us. to do that, we normalized environmental data and stock data with \u201cz-score normalization\u201d technique, based on mean and standard deviation values of the data.\nafter that, we created a function to merge environmental and stock datasets together and -----> plot !!!  them in a graph to check their correlation. we formed our hypothesis for the datasets: \u201cthere\u2019s a correlation between energy sector and the gas emissions level in the united states.\u201d\nto prove our hypothesis, we explored some factors:\nenergy sector and number of stocks for each category\nn2o, co2, and ch4 level from 2001 - 2021 in the united states\nstocks by industry in energy sector some interesting facts: uranium bubble in 2007 peak in methane consumption 2009 global coal benchmarks fall below 2009 crisis levels\ncorrelation between energy sector stocks\u2019 values vs gas emissions since there are missing data in the date and year attribute from gas emission values, we interpolate the data and used linear regression to detrend and pearson\u2019s correlation table to get the final score. finally, we created a matrix to fully recognize the correlation between values.\nvisualize to find the industry and gas emission that has the highest correlation\nbuilt machine learning model to forecast the stock market for uranium\nchallenges we ran into\nthe data resolution for gas emission is yearly while stock is daily. therefore, many interpolation and data cleaning were implemented\nit is hard to choose the right group of stock to study from since stock market is influenced by many factors rather by solely environmental impact.\ngrouping stocks within industry require normalization and a lot of trial and errors on data aggregation.\naccomplishments that we're proud of\nwe were able to download the data from snowflakes and figured the focus group to study.\nwe figured out the correlation and also had time to implement a machine learning model.\nwe are also find enjoyment in collaboration with teammates\nwhat we learned\nthe gas emission level has changed dramatically throughout the past decades due to government regulation and social awareness.\nthere is a slight correlation between co2 stock and uranium.\nwhat's next for gas emission level and stock market in energy sector\nwe plan to find more data and better hypothesis to study the correlation.", "sortedWord": "None", "removed": "Nan", "score": 2, "comments": 0, "media": null, "medialink": null, "identifyer": 59507294}, {"Unnamed: 0": 7354, "autor": "Pyparazzi", "date": null, "content": "What is Pyparazzi?\nA python package aimed at answering the question: how do we gather meaningful data? With this library, we present to researchers and data scientists a modularized and pipelined methodology of data acquisition, processing, and visualization.\nWeb scraping is made so much easier!.\nPyparazzi allows developers, data-scientist and researchers fetch data from different sources and make visualizations by using a high level api.\nHow to install it\npip install pyparazzi\nSearch Rooms\nBy defining the rooms Pyparazzi knows where it should go to grab the data.\nTwitter\nTo generate the api key go to : https://developer.twitter.com/en/portal/dashboard\nfrom pyparazzi.scrapy.rooms import TwitterRoom\nAPI_KEY = \"<TWITTER_API_KEY>\"\nAPI_KEY_SECRET = \"<TWITTER_API_KEY_SECRET>\"\nACCESS_TOKEN = \"<TWITTER_ACCESS_TOKEN>\"\nACCESS_TOKEN_SECRET = \"<TWITTER_ACCESS_TOKEN_SECRET>\"\nif __name__ == '__main__':\nroom = TwitterRoom(\napi_key=API_KEY,\napi_key_secret=API_KEY_SECRET,\naccess_token=ACCESS_TOKEN,\naccess_token_secret=ACCESS_TOKEN_SECRET,\n)\nentities = room.fetch(\nq=[\"Covid\"], num_results=10\n) # fetching tweets where topic is COVID19\nfor entity in entities:\nprint(entity.text)\nFlicker\nTo generate the api key go to : https://www.flickr.com/services/api/\nfrom pyparazzi.scrapy.rooms import FlickrRoom\nFLICKR_API_KEY = \"<FLICKER_API_KEY>\"\nif __name__ == '__main__':\nroom = FlickrRoom(api_key=FLICKR_API_KEY)\nentities = room.fetch(q=[\"covid\", \"Dog\"], num_results=50)\nfor img in entities:\nprint(img.url)\nBing\nTo generate the api key go to : https://www.microsoft.com/en-us/bing/apis/bing-web-search-api\nfrom pyparazzi.scrapy.rooms import BingRoom\nBING_API_KEY = \"<BING_SEARCH_API_KEY\"\nif __name__ == \"__main__\":\nroom = BingRoom(api_key=BING_API_KEY)\nentities = room.fetch(q=[\"mouse\", \"covid\"], num_results=50)\nfor img in entities:\nprint(img.url)\nWikipedia\nNo API key is needed for Wikipedia. Only install the Python package.\nfrom pyparazzi.scrapy.rooms import WikipediaRoom\nif __name__ == \"__main__\":\nroom = WikipediaRoom()\nresults = room.fetch(q=[\"crypto\"], num_results=10)\nfor result in results:\nprint(result.text)\nCreate a custom Room\nfrom pyparazzi.scrapy.rooms import SearchRoom, DataEntity\nclass MyRoom(SearchRoom):\ndef fetch(self, q, num_results = 100) -> [DataEntity]:\n#TODO: do something cool here to fetch your data\nreturn []\nif __name__ == '__main__':\nroom = MyRoom()\nentities = room.fetch(q=\"covid\", num_results=200)\nfor e in entities:\nprint(e)\nScrapping Data\n# import libraries\nfrom pyparazzi.core import Dataset\nfrom pyparazzi.scrapy.rooms import BingRoom, FlickrRoom, TwitterRoom\nfrom pyparazzi import Paparazzi\nBING_API_KEY = \"<BIN_API_KEY>\"\nFLICKR_API_KEY = \"<FLICKER_API>\"\nTWITTER_API_KEY = \"<TWITTER_API\"\nTWITTER_API_KEY_SECRET = \"<TWITTER_API_SECRET>\"\nTWITTER_ACCESS_TOKEN = \"<TWITTER_ACCESS_TOKEN>\"\nTWITTER_ACCESS_TOKEN_SECRET = \"<TWITTER_ACCESS_TOKEN_SECRET>\"\nif __name__ == \"__main__\":\n# create search rooms\nbing_room = BingRoom(api_key=BING_API_KEY)\nflickr_room = FlickrRoom(api_key=FLICKR_API_KEY)\ntwitter_room = TwitterRoom(\napi_key=TWITTER_API_KEY,\napi_key_secret=TWITTER_API_KEY_SECRET,\naccess_token=TWITTER_ACCESS_TOKEN,\naccess_token_secret=TWITTER_ACCESS_TOKEN_SECRET,\n)\n# search parameters\nquery = [\"mouse\", \"covid\"]\nn = 200\n# create paparazzi\nme = Paparazzi(\nrooms=[\nbing_room,\nflickr_room,\ntwitter_room\n]\n)\n# fetch data from the multiple sources, and create dataset\ndataset = me.scrape(q=query, num_results = n)\n# export dataset to disk\ndataset.save(\"data.pkl\")\n# load dataset from disk\ndataset = Dataset.from_file(\"data.pkl\")\nfor entry in dataset:\nprint(f\"{type(entry)}, {entry.content}\") # print entity content\nUtils\nFilter only image entities\nfrom pyparazzi.core import Dataset\nfrom pyparazzi.scrapy.rooms import TextEntity, ImageEntity\ndataset = Dataset.from_file(\"data.pkl\")\ndataset = dataset.select(mime_type = ImageEntity)\nfor entry in dataset:\nprint(f\"{type(entry)}, {entry.url}\")\nFilter only text entities\nfrom pyparazzi.core import Dataset\nfrom pyparazzi.scrapy.rooms import TextEntity, ImageEntity\ndataset = Dataset.from_file(\"data.pkl\")\ndataset = dataset.select(mime_type = TextEntity)\nfor entry in dataset:\nprint(f\"{type(entry)}, {entry.text}\")\nVisualize data\nText\nGet Text Entities:\nfrom pyparazzi.core import Dataset\nfrom pyparazzi.scrapy.rooms import TextEntity\nif __name__ == '__main__':\ndataset = Dataset.from_file(\"data.pkl\")\ndataset = dataset.select(mime_type = TextEntity)\nplot worldcloud\ndataset.plot(kind=\"wordcloud\")\nplot scatter plot\ndataset.plot(kind=\"scatterplot\")\nother util functions\nprint(dataset.to_list())\nprint(dataset.to_numpy())\nImages\nComing soon\nHow we built it\nPyparazzi is built on the top of python packages such as dask, numpy, sklearn, matplotlib, pandas, seaborn, opencv-python etc.\nChallenges we ran into\nHow to merge and organize data from different sources Flickr, Bing, Twitter, Wikipedia.\nWhat we learned\nWe learn about web-scrapping, how to process heterogeneous datasets(images, text, etc.) and plot multidimensional data using the TSNE(t-distributed stochastic neighbor embedding) algorithm\nWhat's next for Pyparazzi\nIncorporate more visualization and data interpretability tools.", "link": "https://devpost.com/software/pyparazzi", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "what is pyparazzi?\na python package aimed at answering the question: how do we gather meaningful data? with this library, we present to researchers and data scientists a modularized and pipelined methodology of data acquisition, processing, and visualization.\nweb scraping is made so much easier!.\npyparazzi allows developers, data-scientist and researchers fetch data from different sources and make visualizations by using a high level api.\nhow to install it\npip install pyparazzi\nsearch rooms\nby defining the rooms pyparazzi knows where it should go to grab the data.\ntwitter\nto generate the api key go to : https://developer.twitter.com/en/portal/dashboard\nfrom pyparazzi.scrapy.rooms import twitterroom\napi_key = \"<twitter_api_key>\"\napi_key_secret = \"<twitter_api_key_secret>\"\naccess_token = \"<twitter_access_token>\"\naccess_token_secret = \"<twitter_access_token_secret>\"\nif __name__ == '__main__':\nroom = twitterroom(\napi_key=api_key,\napi_key_secret=api_key_secret,\naccess_token=access_token,\naccess_token_secret=access_token_secret,\n)\nentities = room.fetch(\nq=[\"covid\"], num_results=10\n) # fetching tweets where topic is covid19\nfor entity in entities:\nprint(entity.text)\nflicker\nto generate the api key go to : https://www.flickr.com/services/api/\nfrom pyparazzi.scrapy.rooms import flickrroom\nflickr_api_key = \"<flicker_api_key>\"\nif __name__ == '__main__':\nroom = flickrroom(api_key=flickr_api_key)\nentities = room.fetch(q=[\"covid\", \"dog\"], num_results=50)\nfor img in entities:\nprint(img.url)\nbing\nto generate the api key go to : https://www.microsoft.com/en-us/bing/apis/bing-web-search-api\nfrom pyparazzi.scrapy.rooms import bingroom\nbing_api_key = \"<bing_search_api_key\"\nif __name__ == \"__main__\":\nroom = bingroom(api_key=bing_api_key)\nentities = room.fetch(q=[\"mouse\", \"covid\"], num_results=50)\nfor img in entities:\nprint(img.url)\nwikipedia\nno api key is needed for wikipedia. only install the python package.\nfrom pyparazzi.scrapy.rooms import wikipediaroom\nif __name__ == \"__main__\":\nroom = wikipediaroom()\nresults = room.fetch(q=[\"crypto\"], num_results=10)\nfor result in results:\nprint(result.text)\ncreate a custom room\nfrom pyparazzi.scrapy.rooms import searchroom, dataentity\nclass myroom(searchroom):\ndef fetch(self, q, num_results = 100) -> [dataentity]:\n#todo: do something cool here to fetch your data\nreturn []\nif __name__ == '__main__':\nroom = myroom()\nentities = room.fetch(q=\"covid\", num_results=200)\nfor e in entities:\nprint(e)\nscrapping data\n# import libraries\nfrom pyparazzi.core import dataset\nfrom pyparazzi.scrapy.rooms import bingroom, flickrroom, twitterroom\nfrom pyparazzi import paparazzi\nbing_api_key = \"<bin_api_key>\"\nflickr_api_key = \"<flicker_api>\"\ntwitter_api_key = \"<twitter_api\"\ntwitter_api_key_secret = \"<twitter_api_secret>\"\ntwitter_access_token = \"<twitter_access_token>\"\ntwitter_access_token_secret = \"<twitter_access_token_secret>\"\nif __name__ == \"__main__\":\n# create search rooms\nbing_room = bingroom(api_key=bing_api_key)\nflickr_room = flickrroom(api_key=flickr_api_key)\ntwitter_room = twitterroom(\napi_key=twitter_api_key,\napi_key_secret=twitter_api_key_secret,\naccess_token=twitter_access_token,\naccess_token_secret=twitter_access_token_secret,\n)\n# search parameters\nquery = [\"mouse\", \"covid\"]\nn = 200\n# create paparazzi\nme = paparazzi(\nrooms=[\nbing_room,\nflickr_room,\ntwitter_room\n]\n)\n# fetch data from the multiple sources, and create dataset\ndataset = me.scrape(q=query, num_results = n)\n# export dataset to disk\ndataset.save(\"data.pkl\")\n# load dataset from disk\ndataset = dataset.from_file(\"data.pkl\")\nfor entry in dataset:\nprint(f\"{type(entry)}, {entry.content}\") # print entity content\nutils\nfilter only image entities\nfrom pyparazzi.core import dataset\nfrom pyparazzi.scrapy.rooms import textentity, imageentity\ndataset = dataset.from_file(\"data.pkl\")\ndataset = dataset.select(mime_type = imageentity)\nfor entry in dataset:\nprint(f\"{type(entry)}, {entry.url}\")\nfilter only text entities\nfrom pyparazzi.core import dataset\nfrom pyparazzi.scrapy.rooms import textentity, imageentity\ndataset = dataset.from_file(\"data.pkl\")\ndataset = dataset.select(mime_type = textentity)\nfor entry in dataset:\nprint(f\"{type(entry)}, {entry.text}\")\nvisualize data\ntext\nget text entities:\nfrom pyparazzi.core import dataset\nfrom pyparazzi.scrapy.rooms import textentity\nif __name__ == '__main__':\ndataset = dataset.from_file(\"data.pkl\")\ndataset = dataset.select(mime_type = textentity)\n-----> plot !!!  worldcloud\ndataset.plot(kind=\"wordcloud\")\n-----> plot !!!  scatter -----> plot !!! \ndataset.plot(kind=\"scatterplot\")\nother util functions\nprint(dataset.to_list())\nprint(dataset.to_numpy())\nimages\ncoming soon\nhow we built it\npyparazzi is built on the top of python packages such as dask, numpy, sklearn, matplotlib, pandas, seaborn, opencv-python etc.\nchallenges we ran into\nhow to merge and organize data from different sources flickr, bing, twitter, wikipedia.\nwhat we learned\nwe learn about web-scrapping, how to process heterogeneous datasets(images, text, etc.) and plot multidimensional data using the tsne(t-distributed stochastic neighbor embedding) algorithm\nwhat's next for pyparazzi\nincorporate more visualization and data interpretability tools.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59507354}, {"Unnamed: 0": 7644, "autor": "Amazon Scraper", "date": null, "content": "Inspiration\nMy inspiration for the Amazon Scraper was that sometimes when shopping on Amazon, I'm unsure if I'm getting a good deal or not. The Amazon Scraper allows me to nearly instantaneously generate the average cost of hundreds of similar listings so I can make better decisions when I shop.\nWhat it does\nThe Amazon Scraper, based on input given by the user, generates a .csv with the price, star rating, review count, and title of a set of Amazon listings, pulled from the website in real-time. It also generates the average cost of those listings, as well as produces a bar chart showcasing the price distribution of those listings.\nHow we built it/Process\nMy approach in creating the Amazon Scraper was first to recognize what tools I needed in order to do so; those tools ended up being Python, BeautifulSoup for its HTML parsing, and matplotlib for its plotting functionalities. Next, I had to find a way to adapt the url based on the search term given by user input, eventually accomplished by doing some string formatting - also important to keep in mind in this string formatting was how the URL is affected by incrementing the page, so the Scraper could collect data from more than one page.\nI then needed to create an array of all of the search results of each page, page by page, accomplished by finding the unique \u2018s-search-result\u2019 in the HTML code for the Amazon webpage. From there, I added another function in order to create individual records with the relevant information instead of a bunch of nonsense HTML from each element of the search results array. Parsing using unique features found in the HTML for each item such as the h2 header for the title, \u2018a-offscreen\u2019 for the price, \u2018i\u2019 for the rating, and the \u2018a-size-base\u2019 class for the number of reviews, I could create a record for each of the elements in the search results array with only the information I deemed useful.\nFrom there, I simply had to iterate through the array of records in order to calculate average price, and in order to plot the price distribution.\nVisualization Interpretability\nThe example chart uploaded alongside this project was produced from the user input of \u201cintel i7\u201d for the search term, \u201c10\u201d for the number of ratings per listing, \u201c4.5\u201d for the minimum star rating, \"5\" for the pages, and not \"n\" for the sponsored listings. The graph portrays the price distribution for elements found with that search term, so in this case, the graph shows the price distribution of the first 45 Intel i7 processors on Amazon with at least 10 reviews and a star rating of 4.5. This could be used to give someone an idea of how much they should be spending on an Intel i7 processor and give them information about how much variability there is in their prices.\nChallenges we ran into\nThis is my first time working with any sort of web scraping, so there were really challenges at every step of the way. Figuring out how to pick through the HTML to get what I really wanted without getting empty strings or the wrong data was challenging, what with all of the encased in each other. Congregating all of the data in order to produce plots and spreadsheets, all with Python code, was also challenging.\nAccomplishments that we're proud of\nI'm proud of the dynamic user interface I've given the program. Instead of finding only one specific set of data from the Amazon website, I've given users the ability to search with whatever query they want, complete with filtering options (# of stars, # of reviews, etc.). It's become something I can actually use practically, rather than an interesting experiment.\nWhat we learned\nI learned the very basics of how HTML is structured, and I gained a solid understanding of how to parse HTML to get the information I want. I also gained a bit of experience using Selenium, BeautifulSoup, and matplotlib.\nWhat's next for Amazon Scraper\nIn the future, I think more useful functionalities could be added to the Amazon Scraper, such as accumulating price data over time for listings in order to generate price over time plots. Perhaps more search options could be added as well, or even the option to choose a set page range rather than just the first x amount of pages.", "link": "https://devpost.com/software/amazon-scraper", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nmy inspiration for the amazon scraper was that sometimes when shopping on amazon, i'm unsure if i'm getting a good deal or not. the amazon scraper allows me to nearly instantaneously generate the average cost of hundreds of similar listings so i can make better decisions when i shop.\nwhat it does\nthe amazon scraper, based on input given by the user, generates a .csv with the price, star rating, review count, and title of a set of amazon listings, pulled from the website in real-time. it also generates the average cost of those listings, as well as produces a bar chart showcasing the price distribution of those listings.\nhow we built it/process\nmy approach in creating the amazon scraper was first to recognize what tools i needed in order to do so; those tools ended up being python, beautifulsoup for its html parsing, and matplotlib for its plotting functionalities. next, i had to find a way to adapt the url based on the search term given by user input, eventually accomplished by doing some string formatting - also important to keep in mind in this string formatting was how the url is affected by incrementing the page, so the scraper could collect data from more than one page.\ni then needed to create an array of all of the search results of each page, page by page, accomplished by finding the unique \u2018s-search-result\u2019 in the html code for the amazon webpage. from there, i added another function in order to create individual records with the relevant information instead of a bunch of nonsense html from each element of the search results array. parsing using unique features found in the html for each item such as the h2 header for the title, \u2018a-offscreen\u2019 for the price, \u2018i\u2019 for the rating, and the \u2018a-size-base\u2019 class for the number of reviews, i could create a record for each of the elements in the search results array with only the information i deemed useful.\nfrom there, i simply had to iterate through the array of records in order to calculate average price, and in order to -----> plot !!!  the price distribution.\nvisualization interpretability\nthe example chart uploaded alongside this project was produced from the user input of \u201cintel i7\u201d for the search term, \u201c10\u201d for the number of ratings per listing, \u201c4.5\u201d for the minimum star rating, \"5\" for the pages, and not \"n\" for the sponsored listings. the graph portrays the price distribution for elements found with that search term, so in this case, the graph shows the price distribution of the first 45 intel i7 processors on amazon with at least 10 reviews and a star rating of 4.5. this could be used to give someone an idea of how much they should be spending on an intel i7 processor and give them information about how much variability there is in their prices.\nchallenges we ran into\nthis is my first time working with any sort of web scraping, so there were really challenges at every step of the way. figuring out how to pick through the html to get what i really wanted without getting empty strings or the wrong data was challenging, what with all of the encased in each other. congregating all of the data in order to produce plots and spreadsheets, all with python code, was also challenging.\naccomplishments that we're proud of\ni'm proud of the dynamic user interface i've given the program. instead of finding only one specific set of data from the amazon website, i've given users the ability to search with whatever query they want, complete with filtering options (# of stars, # of reviews, etc.). it's become something i can actually use practically, rather than an interesting experiment.\nwhat we learned\ni learned the very basics of how html is structured, and i gained a solid understanding of how to parse html to get the information i want. i also gained a bit of experience using selenium, beautifulsoup, and matplotlib.\nwhat's next for amazon scraper\nin the future, i think more useful functionalities could be added to the amazon scraper, such as accumulating price data over time for listings in order to generate price over time plots. perhaps more search options could be added as well, or even the option to choose a set page range rather than just the first x amount of pages.", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59507644}, {"Unnamed: 0": 7648, "autor": "Celonis_answer", "date": null, "content": "Inspiration\nWhat it does\nThe attached model and EDA notebook provides deep insight into the data provided. Using advanced visualization like scatterplot, pairplot, correlation matrix, heatmaps, subplots, etc, the model provides an holistic view of the data. The EDA firstly replaces cost , revenue with net profit, which is more clear and robust metrics towards calculating our result. Then we plot several pairplots, which are excellent visualization method for comparing 2 features on basis of a third one.{like comparing cusomer satisfaction and cost on baseline of cost factors}.\nFeature Importance\nAn important part of our analysis was the feature importance. We used CatBoost Algorithm to find the highest and the least important features towards our net profit. After 699 iterations, we finally reached the optimal learning point and assigned feature importance to different given features in our dataset. According to result, Weekday is the most influential feature towards predicting our net profit, which is followed by Customer Type, Event Time, Customer Location, Cost factor and so on. Overfitting was prevented and optimal learning rate was taken while calculating our metrics.\nExcellent Visualization\nExcellent visualizations and comparisons are done to extrapolate hidden patterns and correlations between the features like Comparison of pizza type and size on basis of customer satisfaction, comparing performance of automation on our profit, identifying weak working hours which are leading to low customer satisfaction, comparing impact of different Customer type on revenue taking into consideration their different pizza tastes{multi-valued pairplots}.\nChallenges we faced\nThe ACTIVITY_EN column was a bit-challenging as the actions were repeating after uneven instances, thus normal splicing the dataset{at every 7th instance} was not beneficial. Thus, leading to difficulty in calculating time difference in placing of a order and its delivery.\nInsights from your analyses\n=>Feature importance : Weekday, Customer Type, Event Time, Customer Location, Cost factor, ... => Wedneday is weakest performing day, and highest profit is earned at Tuesday => Medium Paparika is the most liked pizza, Large Paparika is the least => People are least satisfied at 17th hour, thus improvement should be done there. => 18th,12th and 19th hour are the busiest period in the whole day.{Sale of Funghi and Salami is the highest} =>Teenagers make the biggest portion of revenue(and they like Funghi pizza the most), followed by Student(Calzone), Senior(Speciale),Adult. => Distribution channel companies performance is variable in different at different places, eg-> Orderly performs great in Munich district 3 but fails miserably in district 2, same goes for the others => Automation is the least important feature amongst all, thus no more money should be spent on that.\nbusiness recommendations for process improvement\n=> Less spending on more automation => Focus more on busy hours(18th,12th and 19th ) => During busy hours, more focus should be provided towards early preparation of highly ordered dishes like Funghi and Salami =>Distribution channels should be given their stronghold area and they should work there only. {Orderly performs great in Munich district 3, Town Express in District 5, etc} => Offers should be given on low-sale days like Wednesday and at low-foothold hours. => Teenagers provide highest revenue, so more student discounts can be given to increase their numbers. =>Lowest costumer satisfaction pizzas like Small Veg Pizza, Large Paparika should be removed from the menu, .\nAnalysis questions:\n1) 207 (c) 2) 347(b) 3) 533 (c) 4)1998 (b) 5) 39 (c) 6) 42 ((a) 7) 33% (b) 8) Adult (c)", "link": "https://devpost.com/software/celonis_answer", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\nwhat it does\nthe attached model and eda notebook provides deep insight into the data provided. using advanced visualization like scatterplot, pairplot, correlation matrix, heatmaps, subplots, etc, the model provides an holistic view of the data. the eda firstly replaces cost , revenue with net profit, which is more clear and robust metrics towards calculating our result. then we -----> plot !!!  several pairplots, which are excellent visualization method for comparing 2 features on basis of a third one.{like comparing cusomer satisfaction and cost on baseline of cost factors}.\nfeature importance\nan important part of our analysis was the feature importance. we used catboost algorithm to find the highest and the least important features towards our net profit. after 699 iterations, we finally reached the optimal learning point and assigned feature importance to different given features in our dataset. according to result, weekday is the most influential feature towards predicting our net profit, which is followed by customer type, event time, customer location, cost factor and so on. overfitting was prevented and optimal learning rate was taken while calculating our metrics.\nexcellent visualization\nexcellent visualizations and comparisons are done to extrapolate hidden patterns and correlations between the features like comparison of pizza type and size on basis of customer satisfaction, comparing performance of automation on our profit, identifying weak working hours which are leading to low customer satisfaction, comparing impact of different customer type on revenue taking into consideration their different pizza tastes{multi-valued pairplots}.\nchallenges we faced\nthe activity_en column was a bit-challenging as the actions were repeating after uneven instances, thus normal splicing the dataset{at every 7th instance} was not beneficial. thus, leading to difficulty in calculating time difference in placing of a order and its delivery.\ninsights from your analyses\n=>feature importance : weekday, customer type, event time, customer location, cost factor, ... => wedneday is weakest performing day, and highest profit is earned at tuesday => medium paparika is the most liked pizza, large paparika is the least => people are least satisfied at 17th hour, thus improvement should be done there. => 18th,12th and 19th hour are the busiest period in the whole day.{sale of funghi and salami is the highest} =>teenagers make the biggest portion of revenue(and they like funghi pizza the most), followed by student(calzone), senior(speciale),adult. => distribution channel companies performance is variable in different at different places, eg-> orderly performs great in munich district 3 but fails miserably in district 2, same goes for the others => automation is the least important feature amongst all, thus no more money should be spent on that.\nbusiness recommendations for process improvement\n=> less spending on more automation => focus more on busy hours(18th,12th and 19th ) => during busy hours, more focus should be provided towards early preparation of highly ordered dishes like funghi and salami =>distribution channels should be given their stronghold area and they should work there only. {orderly performs great in munich district 3, town express in district 5, etc} => offers should be given on low-sale days like wednesday and at low-foothold hours. => teenagers provide highest revenue, so more student discounts can be given to increase their numbers. =>lowest costumer satisfaction pizzas like small veg pizza, large paparika should be removed from the menu, .\nanalysis questions:\n1) 207 (c) 2) 347(b) 3) 533 (c) 4)1998 (b) 5) 39 (c) 6) 42 ((a) 7) 33% (b) 8) adult (c)", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59507648}, {"Unnamed: 0": 7656, "autor": "A Simple Stock Price Prediction model", "date": null, "content": "Inspiration\nAccording to Joseph E.Granville's Theory, there is a relationship between stock price and stock trade volume. Stock trade volume trends can be used to predict future stock price. The ZEPL on Snowflakes provides a brilliant database of US stock daily Market Data which includes prices (OPEN, CLOSE, HIGH, LOW) and trade volume. Therefore, I build a simple stock price prediction model to provide suggestions and validation based on historical data.\nWhat it does\nThe model can plot the OHLC (open, high, low, and closing) charts together with volume of specific stock in recent days (can be modified), and provide suggestions based on Joseph E.Granville's Theory according to the today's performance. In addition, it also provide validation based on recent performance of the stock.\nHow we built it\nUsing Python to access the database, modify the data, make the plot and doing further analysis.\nChallenges we ran into\nAccess the snowflake database,\nModify the data,\nPlot OHLC charts,\nand doing analysis and validation. ## Accomplishments that we're proud of I completed the code. Some checks are done in some stocks and looks working well. ## What we learned\nJoseph E.Granville's Theory.\nHow to access snowflake database.\nPlot OHLC charts.\nThe Validation test based on historical data shows that Joseph E.Granville's Theory works well in most cases and when there are more confident days, the prediction is more reliable. ## What's next for A Simple Stock Price Prediction model Try to practice in the real-time stock trading. I am new to stocks and therefore there may be some setting problems. For example, how to define a steady price or volume, so I use a long-term average value to be the threshold of steady for volume and price.", "link": "https://devpost.com/software/a-simple-stock-price-prediction-model", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\naccording to joseph e.granville's theory, there is a relationship between stock price and stock trade volume. stock trade volume trends can be used to predict future stock price. the zepl on snowflakes provides a brilliant database of us stock daily market data which includes prices (open, close, high, low) and trade volume. therefore, i build a simple stock price prediction model to provide suggestions and validation based on historical data.\nwhat it does\nthe model can -----> plot !!!  the ohlc (open, high, low, and closing) charts together with volume of specific stock in recent days (can be modified), and provide suggestions based on joseph e.granville's theory according to the today's performance. in addition, it also provide validation based on recent performance of the stock.\nhow we built it\nusing python to access the database, modify the data, make the plot and doing further analysis.\nchallenges we ran into\naccess the snowflake database,\nmodify the data,\nplot ohlc charts,\nand doing analysis and validation. ## accomplishments that we're proud of i completed the code. some checks are done in some stocks and looks working well. ## what we learned\njoseph e.granville's theory.\nhow to access snowflake database.\nplot ohlc charts.\nthe validation test based on historical data shows that joseph e.granville's theory works well in most cases and when there are more confident days, the prediction is more reliable. ## what's next for a simple stock price prediction model try to practice in the real-time stock trading. i am new to stocks and therefore there may be some setting problems. for example, how to define a steady price or volume, so i use a long-term average value to be the threshold of steady for volume and price.", "sortedWord": "None", "removed": "Nan", "score": 1, "comments": 0, "media": null, "medialink": null, "identifyer": 59507656}, {"Unnamed: 0": 7753, "autor": "Predicting the price of Electric Transportation", "date": null, "content": "Inspiration\nI was inspired to do this project and further explore it due to one of my professor's transportation lectures. I learned that The Government of India launched the National Electric Mobility Mission Plan in 2013, intending to boost demand for electric vehicles (EVs) in India and create a self-sustaining ecosystem. A slew of schemes and programmes aimed at increasing demand and establishing a supply chain in India was implemented. Even though India's electric vehicle programme has been in place for eight years, electric vehicles still account for only about 1% of total vehicle sales.\nWhat it does\nThis project uses data from Germany and the United Kingdom, where electric cars have already been established, as a case study to show how customers in India could benefit from adopting the same behaviour.\nHow we built it\nData Cleaning Data Visualization\nCorrelation plot using the heatmap\nScatter Plots to find the relation between various parameters\nJoint plot to analyse the relationship between two different variables\nBar graph was used to analyse each parameter more carefully.\nRandom forest was used as the machine learning model to predict the price\nThe accuracy metrics of the predicted value was done using MAE, MSE, RMSE and R-squared.\nChallenges we ran into\nI was also looking for real-time India data but couldn't find it.\nAccomplishments that we're proud of\nThe accuracy of the predictions was reasonably good, achieved an R-Squared value of 0.815 which shows a high level of correlation.\nWhat we learned\nPrice in Germany and Price in the UK have a higher correlation. Top Speed has a higher correlation with Price in Germany and Price in the UK. A car with a higher speed has a higher price. KWH and range have a higher correlation.\nWhat's next for Predicting the price of Electric Transportation\nI'll be using India's data to create a more efficient supply chain in order to increase profits and electric vehicle penetration in the Indian market!", "link": "https://devpost.com/software/predicting-the-price-of-electric-transportation", "origin": "Devpost", "suborigin": "Devpost", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "inspiration\ni was inspired to do this project and further explore it due to one of my professor's transportation lectures. i learned that the government of india launched the national electric mobility mission plan in 2013, intending to boost demand for electric vehicles (evs) in india and create a self-sustaining ecosystem. a slew of schemes and programmes aimed at increasing demand and establishing a supply chain in india was implemented. even though india's electric vehicle programme has been in place for eight years, electric vehicles still account for only about 1% of total vehicle sales.\nwhat it does\nthis project uses data from germany and the united kingdom, where electric cars have already been established, as a case study to show how customers in india could benefit from adopting the same behaviour.\nhow we built it\ndata cleaning data visualization\ncorrelation -----> plot !!!  using the heatmap\nscatter plots to find the relation between various parameters\njoint -----> plot !!!  to analyse the relationship between two different variables\nbar graph was used to analyse each parameter more carefully.\nrandom forest was used as the machine learning model to predict the price\nthe accuracy metrics of the predicted value was done using mae, mse, rmse and r-squared.\nchallenges we ran into\ni was also looking for real-time india data but couldn't find it.\naccomplishments that we're proud of\nthe accuracy of the predictions was reasonably good, achieved an r-squared value of 0.815 which shows a high level of correlation.\nwhat we learned\nprice in germany and price in the uk have a higher correlation. top speed has a higher correlation with price in germany and price in the uk. a car with a higher speed has a higher price. kwh and range have a higher correlation.\nwhat's next for predicting the price of electric transportation\ni'll be using india's data to create a more efficient supply chain in order to increase profits and electric vehicle penetration in the indian market!", "sortedWord": "None", "removed": "Nan", "score": 0, "comments": 0, "media": null, "medialink": null, "identifyer": 59507753}], "name": "plotDevpost"}