{"interestingcomments": [{"autor": "Chuprina91", "date": 1586879669000, "content": "The In-depth 2020 Guide to E-commerce Fraud Detection /!/ &amp;#x200B;\n\nhttps://preview.redd.it/1j78avy01ts41.jpg?width=1136&amp;format=pjpg&amp;auto=webp&amp;s=d54704d3b4b6b63a3521cd26db4948c596887273\n\nI would like to recommend this article  [https://spd.group/machine-learning/e-commerce-fraud-detection/](https://spd.group/machine-learning/e-commerce-fraud-detection/) . It starts with describing Fraud in E-Commerce, then moves to the traditional methods to fight Fraud, some E-Commerce Fraud Prevention tools and after that Machine Learning methods are described. The methods include Supervised Decision Tree, Supervised Support Vector Machine (SVM), Anomaly Detection Using Autoencoder, Outlier Detection: Isolation Forest. Feel free to share your opinion, post comments, suggestions and feedback. I would love to hear from you and hear your thoughts. I think this is a very interesting area for Artificial Intelligence, and it will be even more widespread in 2020. Use cases from Subuno, Riskified, Fraudlabs Pro, Dupzapper, Kount show that ML in E-Commerce Fraud Detection is already a reality!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g182oa/the_indepth_2020_guide_to_ecommerce_fraud/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "the in-depth 2020 guide to e-commerce fraud detection /!/ &amp;#x200b;\n\nhttps://preview.redd.it/1j78avy01ts41.jpg?width=1136&amp;format=pjpg&amp;auto=webp&amp;s=d54704d3b4b6b63a3521cd26db4948c596887273\n\ni would like to recommend this article  [https://spd.group/machine-learning/e-commerce-fraud-detection/](https://spd.group/machine-learning/e-commerce-fraud-detection/) . it starts with describing fraud in e-commerce, then moves to the traditional methods to fight fraud, some e-commerce fraud prevention tools and after that machine learning methods are described. the methods include supervised decision -----> tree !!! , supervised support vector machine (svm), anomaly detection using autoencoder, outlier detection: isolation forest. feel free to share your opinion, post comments, suggestions and feedback. i would love to hear from you and hear your thoughts. i think this is a very interesting area for artificial intelligence, and it will be even more widespread in 2020. use cases from subuno, riskified, fraudlabs pro, dupzapper, kount show that ml in e-commerce fraud detection is already a reality!", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/ArtificialInteligence/comments/g182oa/the_indepth_2020_guide_to_ecommerce_fraud/',)", "identifyer": 5599157, "year": "2020"}, {"autor": "corzoai", "date": 1582930475000, "content": "Minimax (AB) and MCTS hybrid /!/ Could Minimax search trees be implemented alongside MCTS rollouts for the nodes' values? For instance, let's say we searched up to depth 5. When getting the value of each state, could we run rollouts from that positions and assign those results to the nodes' values? Or could a pure MCTS (with selection, expansion, simulation and backpropagation) be used inside that Minimax tree instead of the simple rollouts? Would it work in games with high branching factor such as chess? Which would be the pros and cons of such approach? \n\nThanks,", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/fb356s/minimax_ab_and_mcts_hybrid/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "minimax (ab) and mcts hybrid /!/ could minimax search trees be implemented alongside mcts rollouts for the nodes' values? for instance, let's say we searched up to depth 5. when getting the value of each state, could we run rollouts from that positions and assign those results to the nodes' values? or could a pure mcts (with selection, expansion, simulation and backpropagation) be used inside that minimax -----> tree !!!  instead of the simple rollouts? would it work in games with high branching factor such as chess? which would be the pros and cons of such approach? \n\nthanks,", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/ArtificialInteligence/comments/fb356s/minimax_ab_and_mcts_hybrid/',)", "identifyer": 5600871, "year": "2020"}, {"autor": "raghunathsamal", "date": 1588076269000, "content": "Decision Tree in Data Mining | Decision Tree in Machine Learning | Deci...", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g9m4pj/decision_tree_in_data_mining_decision_tree_in/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "decision -----> tree !!!  in data mining | decision -----> tree !!!  in machine learning | deci...", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 1, "media": "('rich:video',)", "medialink": "('https://www.youtube.com/watch?v=CC6RF7Heftk&amp;feature=share',)", "identifyer": 5601796, "year": "2020"}, {"autor": "KumaTheta", "date": 1584732459000, "content": "A.I. Plays Fire Emblem Heroes | Monte Carlo Tree Search | UCB1", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/fm128p/ai_plays_fire_emblem_heroes_monte_carlo_tree/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "a.i. plays fire emblem heroes | monte carlo -----> tree !!!  search | ucb1", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('rich:video',)", "medialink": "('https://youtu.be/KmwlOf41BzU',)", "identifyer": 5601885, "year": "2020"}, {"autor": "hex4c", "date": 1584461900000, "content": "Confused about the worst complexity of AC3 algorithm on a tree structured CSP /!/ I am not sure I am asking this question at the right place. But I am confused about an exercise in *Artificial Intelligence A modern Approach*. It's the exercise 6.12 in the third edition. And the question is :\n\n*What is the worst-case complexity of running AC-3 on a tree-structured CSP?* \n\nThe answer I get on the Internet says :\n\nOn a tree-structured graph, no arc will be considered more than once, so the AC-3 algorithm is O(ED), where E is the number of edges and D is the size of the largest domain.\n\nBut how? According to the AC3 algorithm, not to mention that the complexity of removing inconsistent values is O(D\\^2), the arcs will definitely be added to the queue again when visiting the initial arcs. Thus it will be considered more than once. So have I misunderstood anything or it's just the answer is wrong?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/fk800t/confused_about_the_worst_complexity_of_ac3/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "confused about the worst complexity of ac3 algorithm on a -----> tree !!!  structured csp /!/ i am not sure i am asking this question at the right place. but i am confused about an exercise in *artificial intelligence a modern approach*. it's the exercise 6.12 in the third edition. and the question is :\n\n*what is the worst-case complexity of running ac-3 on a tree-structured csp?* \n\nthe answer i get on the internet says :\n\non a tree-structured graph, no arc will be considered more than once, so the ac-3 algorithm is o(ed), where e is the number of edges and d is the size of the largest domain.\n\nbut how? according to the ac3 algorithm, not to mention that the complexity of removing inconsistent values is o(d\\^2), the arcs will definitely be added to the queue again when visiting the initial arcs. thus it will be considered more than once. so have i misunderstood anything or it's just the answer is wrong?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/ArtificialInteligence/comments/fk800t/confused_about_the_worst_complexity_of_ac3/',)", "identifyer": 5601933, "year": "2020"}, {"autor": "johnsnowlabsUS", "date": 1594656394000, "content": "THE NEW HEALTHCARE AI PLATFORM: AIR-GAP SECURITY &amp; COMPLIANCES MEETS ENTERPRISE-GRADE OPERATIONS, ELASTICITY &amp; SCALE /!/ We\u2019re hugely\u00a0thrilled to announce the immediate availability of the new major version of the Healthcare AI Platform. This release raises the bar on the industry\u2019s only \u201ccleanroom\u201d AI platform that is designed for high-compliance industries where PHI or PII data is analyzed:\u00a0\n\n* Runs in a complete air-gap manner: without Internet access\u00a0\n* All computation is done within the platform. No data, models, or code leave the cluster\u00a0\n* Runs on your infrastructure. Nothing gets sent to a third party\u00a0\n* Central identity management, single sign-on, and key management\u00a0\n\nThe trick, of course, is to achieve all that without trading off the key benefits of cloud services:\u00a0\n\n* Elastic: scales from 5 to 5,000 machines without downtime\u00a0\n* Fully managed, out-of-the-box data science notebooks, model serving, data integration, data processing pipelines, visualization, and dashboards\n* Central security, monitoring, logging, and management tools\u00a0\n\n[The Healthcare AI Platform](https://www.johnsnowlabs.com/ai-platform/) is automatically deployed in 2-4 hours on a cluster of your choice \u2013 on any cloud or on-premise cluster, anywhere in the world \u2013 as one fully-managed Kubernetes cluster.\u00a0\n\n&gt;\u201c*Data science teams in high-compliance industries often have to make hard trade-off between having access to state-of-the-art libraries and tools; the convenience of managed services, elasticity and scale offered by cloud providers, while* *adhering to the highest bar of security, privacy, and compliance. Our goal with the Healthcare AI Platform is to deliver on all three areas without compromise*\u201d, said Ali Naqvi, lead platform product manager at John Snow Labs.\u00a0\n\nThe same platform was recognized last year by CIO Applications as its [AI Platform of the Year](https://www.johnsnowlabs.com/john-snow-labs-is-named-2019-ai-platform-of-the-year/) thanks to a combination of cutting-edge AI technology and proven customer success. The platform is deployed and actively used by multiple Fortune 500 healthcare, life science, and health IT companies to build, deploy, and operate real-world data science systems.\u00a0\n\nThis new release includes over 140 new features and enhancements. Roughly half of them are focused on enhanced security &amp; compliance. The other half adds new productivity features for data scientists and data analysts. As always, this release also updates all of the healthcare-specific datasets, medical terminologies, natural language processing pipelines, and pre-trained deep learning models that are included to jumpstart healthcare &amp; pharma AI projects.\u00a0\n\n[Contact us](https://www.johnsnowlabs.com/schedule-a-demo/) for a live demo or trial version of the Healthcare AI Platform.\u00a0\n\n## Healthcare AI Platform Q2 2020 Release: Major Enhancement &amp; New Features\n\n## Identity &amp; Access Management\n\n* Single sign-on for all new components\n* Two-Factor Authentication\n* Password formats &amp; password strength policies\n* Password expiration policies\n* Support for temporary passwords\n* Support for password-less authentication and multiple credentials per user\n* Signed and Encrypted ID Token Support\n* Fine-grained authorization &amp; authentication controls\n\n## For SecOps: Security Hardening\n\n* New image vulnerability scanners are in use and previous ones have been upgraded\n* Dynamic deep image inspection and vulnerability scanning of Docker containers has been implemented\n* Tens of thousands of vulnerabilities in underlying open-source packages have been resolved\n* Distro-less images (initial rollout): These images contain only your application and its runtime dependencies. They do not contain package managers, shells, or other standard Linux programs, drastically reducing what an attacker can do even on a compromised host.\n\n## For DevOps: Scaling &amp; Kubernetes Operations\n\n* Upgraded to Kubernetes 1.17 with GPU support\n* Support for allocating GPU\u2019s to specific users or services\n* Support for pod priority and preemption\n* Support for pod readiness gates\n* Hardened the discovery of Kubernetes role-based access controls\n* Scalability &amp; fault tolerance for the visualization &amp; dashboarding services\n* Fault tolerance for the identity &amp; access management database\n\n## For Data Scientists: Managed Notebooks\n\n* New built-in HTML viewer\n* Find &amp; replace\n* Find &amp; go-to line in the CSV viewer\n* Enhanced node structure in the JSON tree viewer\n* Drag &amp; drop between console &amp; notebook cells\n* Notebook cell tags\n* Presentation mode for notebooks\n* Added a \u201cRestart Kernel and Run All Cells\u2026\u201d button\n* Added a status bar\n* Better performance, especially for large notebooks\n* New keyboard shortcuts for navigation and better tooltips\n* Pasting cell attachments and dragging attachments from the file browser", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hqi0g5/the_new_healthcare_ai_platform_airgap_security/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "the new healthcare ai platform: air-gap security &amp; compliances meets enterprise-grade operations, elasticity &amp; scale /!/ we\u2019re hugely\u00a0thrilled to announce the immediate availability of the new major version of the healthcare ai platform. this release raises the bar on the industry\u2019s only \u201ccleanroom\u201d ai platform that is designed for high-compliance industries where phi or pii data is analyzed:\u00a0\n\n* runs in a complete air-gap manner: without internet access\u00a0\n* all computation is done within the platform. no data, models, or code leave the cluster\u00a0\n* runs on your infrastructure. nothing gets sent to a third party\u00a0\n* central identity management, single sign-on, and key management\u00a0\n\nthe trick, of course, is to achieve all that without trading off the key benefits of cloud services:\u00a0\n\n* elastic: scales from 5 to 5,000 machines without downtime\u00a0\n* fully managed, out-of-the-box data science notebooks, model serving, data integration, data processing pipelines, visualization, and dashboards\n* central security, monitoring, logging, and management tools\u00a0\n\n[the healthcare ai platform](https://www.johnsnowlabs.com/ai-platform/) is automatically deployed in 2-4 hours on a cluster of your choice \u2013 on any cloud or on-premise cluster, anywhere in the world \u2013 as one fully-managed kubernetes cluster.\u00a0\n\n&gt;\u201c*data science teams in high-compliance industries often have to make hard trade-off between having access to state-of-the-art libraries and tools; the convenience of managed services, elasticity and scale offered by cloud providers, while* *adhering to the highest bar of security, privacy, and compliance. our goal with the healthcare ai platform is to deliver on all three areas without compromise*\u201d, said ali naqvi, lead platform product manager at john snow labs.\u00a0\n\nthe same platform was recognized last year by cio applications as its [ai platform of the year](https://www.johnsnowlabs.com/john-snow-labs-is-named-2019-ai-platform-of-the-year/) thanks to a combination of cutting-edge ai technology and proven customer success. the platform is deployed and actively used by multiple fortune 500 healthcare, life science, and health it companies to build, deploy, and operate real-world data science systems.\u00a0\n\nthis new release includes over 140 new features and enhancements. roughly half of them are focused on enhanced security &amp; compliance. the other half adds new productivity features for data scientists and data analysts. as always, this release also updates all of the healthcare-specific datasets, medical terminologies, natural language processing pipelines, and pre-trained deep learning models that are included to jumpstart healthcare &amp; pharma ai projects.\u00a0\n\n[contact us](https://www.johnsnowlabs.com/schedule-a-demo/) for a live demo or trial version of the healthcare ai platform.\u00a0\n\n## healthcare ai platform q2 2020 release: major enhancement &amp; new features\n\n## identity &amp; access management\n\n* single sign-on for all new components\n* two-factor authentication\n* password formats &amp; password strength policies\n* password expiration policies\n* support for temporary passwords\n* support for password-less authentication and multiple credentials per user\n* signed and encrypted id token support\n* fine-grained authorization &amp; authentication controls\n\n## for secops: security hardening\n\n* new image vulnerability scanners are in use and previous ones have been upgraded\n* dynamic deep image inspection and vulnerability scanning of docker containers has been implemented\n* tens of thousands of vulnerabilities in underlying open-source packages have been resolved\n* distro-less images (initial rollout): these images contain only your application and its runtime dependencies. they do not contain package managers, shells, or other standard linux programs, drastically reducing what an attacker can do even on a compromised host.\n\n## for devops: scaling &amp; kubernetes operations\n\n* upgraded to kubernetes 1.17 with gpu support\n* support for allocating gpu\u2019s to specific users or services\n* support for pod priority and preemption\n* support for pod readiness gates\n* hardened the discovery of kubernetes role-based access controls\n* scalability &amp; fault tolerance for the visualization &amp; dashboarding services\n* fault tolerance for the identity &amp; access management database\n\n## for data scientists: managed notebooks\n\n* new built-in html viewer\n* find &amp; replace\n* find &amp; go-to line in the csv viewer\n* enhanced node structure in the json -----> tree !!!  viewer\n* drag &amp; drop between console &amp; notebook cells\n* notebook cell tags\n* presentation mode for notebooks\n* added a \u201crestart kernel and run all cells\u2026\u201d button\n* added a status bar\n* better performance, especially for large notebooks\n* new keyboard shortcuts for navigation and better tooltips\n* pasting cell attachments and dragging attachments from the file browser", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/ArtificialInteligence/comments/hqi0g5/the_new_healthcare_ai_platform_airgap_security/',)", "identifyer": 5602423, "year": "2020"}, {"autor": "Yuqing7", "date": 1603394074000, "content": "Preferred Networks\u2019 ChainerRL Joins PyTorch Ecosystem as \u2018PFRL\u2019 /!/ Japanese AI startup Preferred Networks (PFN) is moving ChainerRL to the PyTorch ecosystem, it was announced yesterday. The resulting PyTorch-based open-source deep Reinforcement Learning (RL) library, Preferred RL ([PFRL](https://github.com/pfnet/pfrl)), represents the latest in PFN\u2019s continuing efforts to build and maintain strong ties with the PyTorch developer community.\n\nChainerRL is a PFN deep RL library that implements various state-of-the-art algorithms in Python using the flexible deep learning framework [Chainer](https://github.com/chainer/chainer), which PFN open-sourced in June 2015. Last December, the company unveiled a plan to migrate its deep learning research platform from Chainer to PyTorch, and promised to provide documentation and a library for Chainer users to facilitate the transition. PFRL is the PyTorch-based successor to ChainerRL\n\nHere is a quick read: [Preferred Networks\u2019 ChainerRL Joins PyTorch Ecosystem as \u2018PFRL\u2019](https://syncedreview.com/2020/10/22/preferred-networks-chainerrl-joins-pytorch-ecosystem-as-pfrl/)\n\nExample scripts utilizing these algorithms and features can be found in the project [GitHub](https://github.com/pfnet/pfrl/tree/master/examples).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jg6ck5/preferred_networks_chainerrl_joins_pytorch/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "preferred networks\u2019 chainerrl joins pytorch ecosystem as \u2018pfrl\u2019 /!/ japanese ai startup preferred networks (pfn) is moving chainerrl to the pytorch ecosystem, it was announced yesterday. the resulting pytorch-based open-source deep reinforcement learning (rl) library, preferred rl ([pfrl](https://github.com/pfnet/pfrl)), represents the latest in pfn\u2019s continuing efforts to build and maintain strong ties with the pytorch developer community.\n\nchainerrl is a pfn deep rl library that implements various state-of-the-art algorithms in python using the flexible deep learning framework [chainer](https://github.com/chainer/chainer), which pfn open-sourced in june 2015. last december, the company unveiled a plan to migrate its deep learning research platform from chainer to pytorch, and promised to provide documentation and a library for chainer users to facilitate the transition. pfrl is the pytorch-based successor to chainerrl\n\nhere is a quick read: [preferred networks\u2019 chainerrl joins pytorch ecosystem as \u2018pfrl\u2019](https://syncedreview.com/2020/10/22/preferred-networks-chainerrl-joins-pytorch-ecosystem-as-pfrl/)\n\nexample scripts utilizing these algorithms and features can be found in the project [github](https://github.com/pfnet/pfrl/-----> tree !!! /master/examples).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/ArtificialInteligence/comments/jg6ck5/preferred_networks_chainerrl_joins_pytorch/',)", "identifyer": 5602905, "year": "2020"}, {"autor": "Yuqing7", "date": 1603221665000, "content": "[R] Facebook AI Model Directly Translates 100 Languages Without Using English Data /!/ To better preserve meanings and improve accuracy, Facebook AI yesterday [open-sourced ](https://ai.facebook.com/blog/introducing-many-to-many-multilingual-machine-translation)an MMT model that directly trains on Chinese to French and other language-pair data.\n\nFacebook is hailing the new **M2M-100** (Many-to-Many) model as a \u201cmajor milestone\u201d in their years of work in MMT and the first AI model that can directly translate between any pair of 100 languages without relying on any English data. In quality evaluations, when translating between non-English languages using the popular BLEU (Bilingual Evaluation Understudy) metric, M2M-100 achieved a 10 BLEU point improvement over English-centric multilingual models.\n\n\u201c**This English-Centric bias in the data and resulting models is not reflective of how people use translation and empirically leads to lower performance for non-English translation directions,**\u201d reads the paper *Beyond English-Centric Multilingual Machine Translation.*\n\nHere is a quick read: [Facebook AI Model Directly Translates 100 Languages Without Using English Data](https://syncedreview.com/2020/10/20/facebook-ai-model-directly-translates-100-languages-without-using-english-data/)\n\nThe paper *Beyond English-Centric Multilingual Machine Translation* is on this [Facebook repository](https://scontent.fyyz1-2.fna.fbcdn.net/v/t39.8562-6/122020792_383950172763065_1301307024427415119_n.pdf?_nc_cat=109&amp;_nc_sid=ae5e01&amp;_nc_ohc=nrxKNsWl6VcAX8Pcnas&amp;_nc_ht=scontent.fyyz1-2.fna&amp;oh=aad18e73aae30708f85fd9678bf2a991&amp;oe=5FB3BDF9), and the open-source project can be found on [GitHub](https://github.com/pytorch/fairseq/tree/master/examples/m2m_100?fbclid=IwAR2KsQJxKkaJHQnmcdYUYT2xoKPZ9Ce0RveCa5YmYpwthrOd9QeYLZW6wEE).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jewkue/r_facebook_ai_model_directly_translates_100/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] facebook ai model directly translates 100 languages without using english data /!/ to better preserve meanings and improve accuracy, facebook ai yesterday [open-sourced ](https://ai.facebook.com/blog/introducing-many-to-many-multilingual-machine-translation)an mmt model that directly trains on chinese to french and other language-pair data.\n\nfacebook is hailing the new **m2m-100** (many-to-many) model as a \u201cmajor milestone\u201d in their years of work in mmt and the first ai model that can directly translate between any pair of 100 languages without relying on any english data. in quality evaluations, when translating between non-english languages using the popular bleu (bilingual evaluation understudy) metric, m2m-100 achieved a 10 bleu point improvement over english-centric multilingual models.\n\n\u201c**this english-centric bias in the data and resulting models is not reflective of how people use translation and empirically leads to lower performance for non-english translation directions,**\u201d reads the paper *beyond english-centric multilingual machine translation.*\n\nhere is a quick read: [facebook ai model directly translates 100 languages without using english data](https://syncedreview.com/2020/10/20/facebook-ai-model-directly-translates-100-languages-without-using-english-data/)\n\nthe paper *beyond english-centric multilingual machine translation* is on this [facebook repository](https://scontent.fyyz1-2.fna.fbcdn.net/v/t39.8562-6/122020792_383950172763065_1301307024427415119_n.pdf?_nc_cat=109&amp;_nc_sid=ae5e01&amp;_nc_ohc=nrxknswl6vcax8pcnas&amp;_nc_ht=scontent.fyyz1-2.fna&amp;oh=aad18e73aae30708f85fd9678bf2a991&amp;oe=5fb3bdf9), and the open-source project can be found on [github](https://github.com/pytorch/fairseq/-----> tree !!! /master/examples/m2m_100?fbclid=iwar2ksqjxkkajhqnmcdyuyt2xokpz9ce0rveca5ymypwthrod9qeylzw6wee).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/ArtificialInteligence/comments/jewkue/r_facebook_ai_model_directly_translates_100/',)", "identifyer": 5602945, "year": "2020"}, {"autor": "aarklyy", "date": 1603739301000, "content": "Need some names over conditional generative models for tree and hierarchical structures. What are the best models for this purpose? /!/ Hello\nFor some reason, I need some entry point to generative models that are trained over hierarchical data alongside with conditions; and output hierarchies according to input conditions. Deep models are preferred. \n\nThank you so much..", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jikwu6/need_some_names_over_conditional_generative/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "need some names over conditional generative models for -----> tree !!!  and hierarchical structures. what are the best models for this purpose? /!/ hello\nfor some reason, i need some entry point to generative models that are trained over hierarchical data alongside with conditions; and output hierarchies according to input conditions. deep models are preferred. \n\nthank you so much..", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/ArtificialInteligence/comments/jikwu6/need_some_names_over_conditional_generative/',)", "identifyer": 5603660, "year": "2020"}, {"autor": "elevatorbeat", "date": 1595952133000, "content": "Everything You Need to Understand Artificial Intelligence /!/ **Need a primer on AI? We\u2019ve got you\u00a0covered!**\n\nIn working with many enterprise customers over the years, we\u2019ve discovered that there are lots of misconceptions and misunderstandings about Artificial Intelligence. All of the resources we tried to point them to were never clear or thorough enough\u200a\u2014\u200aso we decided to make our own.\n\nIn this guide, we\u2019ll not only walk you through the essentials of Artificial Intelligence but help you locate it within your broader IT strategy. Learn what an AI model is, how it\u2019s built, and finally, how data scientists can put the model to work at your organization.\n\n&amp;#x200B;\n\n&gt;Artificial intelligence is a software capability that allows computers to detect patterns and abstract rules based on a series of extremely complex\u00a0inputs.\n\n&amp;#x200B;\n\nThese inputs can include any dataset, including:\n\n* pixels in an image,\n* sound waves in an audio file,\n* letters on a page,\n* the mathematical relationships between all the words in the English language,\n* financial transactions of the Fortune 500,\n* the location of every star in the galaxy,\n* etc.\n\nThe **dataset** itself doesn\u2019t matter much. As long as an AI model can take a look at the **input** and **match** it to its **output**, the system itself can start to map\u200a\u2014\u200aand ultimately predict\u200a\u2014\u200athe rules that connect inputs and outputs.\n\nFor example, a financial institution may have a dataset of historical stock market prices and lots of information about each company. By matching **company information** as the input with **stock price** as the output, an AI could learn to identify company information that is highly correlated with a rising stock price.\n\nWhat\u2019s great about AI is that it is uniquely able to consider thousands of inputs and correlations far too subtle for humans to even notice. For example, almost no stockbroker integrates CEO commute time into their investment strategy. However, artificial intelligence has found it to be a relevant predictor of CEO performance.\n\nIn any case, over time, these predictions become more accurate. Eventually, the model becomes reliable and useful enough that it can be deployed and put to work.\n\nLet\u2019s look at another example.\n\nAt a factory, quality assurance officers must pull broken eggs from a conveyor belt. To accomplish this task, the inspectors will look for obvious indicators such as a cracked shell or a shimmer of yolk on the conveyor belt. In other words, these folks are using visual information (inputs) to categorize eggs (outputs).\n\nThis effort is a perfect task for an AI model. In fact, if we were to assign an AI model the same task, it would tackle the problem much in the same way as its human counterparts: it would look at an egg and check to see if there were any visual indications that it was cracked.\n\nTo accomplish this task, however, an AI would need to be **trained**. In this case, the model would need to chew on hundreds, maybe thousands, of photos of cracked and uncracked eggs to start to figure out the pattern.\n\nEventually, the model would create mathematical rules to define what a cracked egg looks like. With more training, the **accuracy** of the model would improve, and eventually, it would be reliable enough to put into **production**.\n\n### A Note About Accuracy and\u00a0AI\n\nArtificial intelligence is not yet capable of achieving 100% accuracy. So, depending on the use case, data scientists must make judgments about whether an AI model meets a certain threshold to put it into production.\n\nMost AI models can get to about 75% accuracy without too much trouble. Beyond that, there\u2019s a logarithmic increase in (a) the number of inputs the model needs to train on and (b) the amount of processing power it takes to create the model. The former is time-consuming, the latter is expensive, and in most cases, 100% accuracy isn\u2019t necessary. Depending on the task at hand, the accuracy threshold will vary.\n\nThis lack of 100% accuracy is one of the reasons self-driving cars still have a long way to go. In data science, a 90% accuracy rate is quite good but imagine if an autonomous vehicle only noticed 90% of the pedestrians who crossed the street.\n\nMoreover, *how* things are inaccurate can also be a factor. For example, in a lung cancer model, false positives aren\u2019t nearly as bad as false negatives. Therefore, the best disease diagnostic models will be optimized to detect every single possible instance of cancer (avoiding false negatives)\u200a\u2014\u200aeven if it means a few healthy lungs get incorrectly flagged along the way (allowing for false positives).\n\nExperts who build AI solutions must decide on acceptable accuracy thresholds before putting a model into production.\n\n### What does it mean to put a model into production?\n\nWell, as we\u2019ve discussed, AI models are really good at matching inputs to outputs. However, for that capability to be useful to anyone, the model must be piped into some kind of app or hardware to be put to work.\n\nIn the egg example, the food processing plant would have to do more than train the broken-or-not-broken model to get any use out of it. It would need to set up a camera to film the eggs coming down the belt, pipe that footage into the model for processing, and then alert the line workers of a broken egg via some kind of interface.\n\nMost AI service providers consider training a model and putting it into production as two separate steps. Because the former is much more complex (and expensive), many IT departments opt to do the production piece themselves. In most cases, the average programmer can access the AI model (usually via an API) and put it to work.\n\n### What is Deep Learning?\n\nFor AI, identifying whether an egg is broken is relatively simple. By contrast, looking ahead at a red, round object and labeling it a \u201cstop sign\u201d is much more complex.\n\nThis is where **deep learning** comes in. Deep learning enables AI models to sort things into tinier and tinier categories. AI experts think about this sorting as a layered process.\n\nIn the case of the stop sign, the relevant layers might be:\n\n1. Distance from car.\n2. Shape.\n3. Estimated height.\n4. Position on the road.\n5. Color.\n6. Text on the sign.\n7. Etc.\n\nTo identify the stop sign, a self-driving car would have to pass the image of the stop sign through a series of layers to make sure it wasn\u2019t a mountain, a tree, a speed limit sign, or a Starbucks. By layering simple AI categorization models on top of each other, AIs become much more sophisticated.\n\nLet\u2019s look at another example related to emotion detection. Could an AI detect whether someone was in a bad mood? To consider that question, let\u2019s first think about how humans can tell whether someone is in a bad mood.\n\nIn order to make that judgment, our brains must integrate a lot of visual and auditory information about the subject.\n\nFor example:\n\n1. Mouth position (smiling, frowning)\n2. Eyebrow position (raised, narrow)\n3. Pronounced wrinkles (laugh or frown lines)\n4. Tone and volume of voice (yelling)\n5. Speaking speed\n6. Posture\n7. Shoulder position\n8. etc\u2026\n\nIn fact, there are so many subtle and not-so-subtle indicators that it\u2019s nearly impossible to list them all out. What\u2019s nice about AI is that we never have to define those messy and long-tail indicators. AI\u2019s superpower is that it can figure out the rules for itself.\n\nBy showing an AI model dozens of faces and labeling each with an emotion, the model could be trained to find the pattern, thereby integrating a wealth of obscure information about how someone looks to predict how someone is feeling.\n\nThis is the same facial recognition capability that Apple uses to unlock your iPhone. In that case, instead of matching your face with an emotion, the system is ensuring your face matches your account.\n\nAI researchers are using images of people\u2019s faces as inputs for all kinds of models, including lie detection, age detection, disease diagnostics, and even imaging technologies that age-up missing children.\n\nAs you begin to think more and more about the ways artificial intelligence can transform your company, challenge yourself to think in terms of inputs (data) and outputs (categorization).\n\nRemember, AI is amazingly powerful. AI models can use Xrays to diagnose disease, billions of financial transactions to detect fraud, and boxes of handwritten case files to prove someone is innocent.\n\nDon\u2019t worry if the distance between inputs and outputs seems vast. AI is more than capable of making those connections.\n\nThis chapter is an excerpt from the ebook, The Complete Guide to Bringing Artificial Intelligence to your Organization.\n\n[Access the full guide here.](https://www.manceps.com/ai-guide?utm_source=Reddit&amp;utm_medium=Post&amp;utm_campaign=Everything%20You%20Need%20to%20Understand%20Artificial%20Intelligence)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hzh9vd/everything_you_need_to_understand_artificial/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "everything you need to understand artificial intelligence /!/ **need a primer on ai? we\u2019ve got you\u00a0covered!**\n\nin working with many enterprise customers over the years, we\u2019ve discovered that there are lots of misconceptions and misunderstandings about artificial intelligence. all of the resources we tried to point them to were never clear or thorough enough\u200a\u2014\u200aso we decided to make our own.\n\nin this guide, we\u2019ll not only walk you through the essentials of artificial intelligence but help you locate it within your broader it strategy. learn what an ai model is, how it\u2019s built, and finally, how data scientists can put the model to work at your organization.\n\n&amp;#x200b;\n\n&gt;artificial intelligence is a software capability that allows computers to detect patterns and abstract rules based on a series of extremely complex\u00a0inputs.\n\n&amp;#x200b;\n\nthese inputs can include any dataset, including:\n\n* pixels in an image,\n* sound waves in an audio file,\n* letters on a page,\n* the mathematical relationships between all the words in the english language,\n* financial transactions of the fortune 500,\n* the location of every star in the galaxy,\n* etc.\n\nthe **dataset** itself doesn\u2019t matter much. as long as an ai model can take a look at the **input** and **match** it to its **output**, the system itself can start to map\u200a\u2014\u200aand ultimately predict\u200a\u2014\u200athe rules that connect inputs and outputs.\n\nfor example, a financial institution may have a dataset of historical stock market prices and lots of information about each company. by matching **company information** as the input with **stock price** as the output, an ai could learn to identify company information that is highly correlated with a rising stock price.\n\nwhat\u2019s great about ai is that it is uniquely able to consider thousands of inputs and correlations far too subtle for humans to even notice. for example, almost no stockbroker integrates ceo commute time into their investment strategy. however, artificial intelligence has found it to be a relevant predictor of ceo performance.\n\nin any case, over time, these predictions become more accurate. eventually, the model becomes reliable and useful enough that it can be deployed and put to work.\n\nlet\u2019s look at another example.\n\nat a factory, quality assurance officers must pull broken eggs from a conveyor belt. to accomplish this task, the inspectors will look for obvious indicators such as a cracked shell or a shimmer of yolk on the conveyor belt. in other words, these folks are using visual information (inputs) to categorize eggs (outputs).\n\nthis effort is a perfect task for an ai model. in fact, if we were to assign an ai model the same task, it would tackle the problem much in the same way as its human counterparts: it would look at an egg and check to see if there were any visual indications that it was cracked.\n\nto accomplish this task, however, an ai would need to be **trained**. in this case, the model would need to chew on hundreds, maybe thousands, of photos of cracked and uncracked eggs to start to figure out the pattern.\n\neventually, the model would create mathematical rules to define what a cracked egg looks like. with more training, the **accuracy** of the model would improve, and eventually, it would be reliable enough to put into **production**.\n\n### a note about accuracy and\u00a0ai\n\nartificial intelligence is not yet capable of achieving 100% accuracy. so, depending on the use case, data scientists must make judgments about whether an ai model meets a certain threshold to put it into production.\n\nmost ai models can get to about 75% accuracy without too much trouble. beyond that, there\u2019s a logarithmic increase in (a) the number of inputs the model needs to train on and (b) the amount of processing power it takes to create the model. the former is time-consuming, the latter is expensive, and in most cases, 100% accuracy isn\u2019t necessary. depending on the task at hand, the accuracy threshold will vary.\n\nthis lack of 100% accuracy is one of the reasons self-driving cars still have a long way to go. in data science, a 90% accuracy rate is quite good but imagine if an autonomous vehicle only noticed 90% of the pedestrians who crossed the street.\n\nmoreover, *how* things are inaccurate can also be a factor. for example, in a lung cancer model, false positives aren\u2019t nearly as bad as false negatives. therefore, the best disease diagnostic models will be optimized to detect every single possible instance of cancer (avoiding false negatives)\u200a\u2014\u200aeven if it means a few healthy lungs get incorrectly flagged along the way (allowing for false positives).\n\nexperts who build ai solutions must decide on acceptable accuracy thresholds before putting a model into production.\n\n### what does it mean to put a model into production?\n\nwell, as we\u2019ve discussed, ai models are really good at matching inputs to outputs. however, for that capability to be useful to anyone, the model must be piped into some kind of app or hardware to be put to work.\n\nin the egg example, the food processing plant would have to do more than train the broken-or-not-broken model to get any use out of it. it would need to set up a camera to film the eggs coming down the belt, pipe that footage into the model for processing, and then alert the line workers of a broken egg via some kind of interface.\n\nmost ai service providers consider training a model and putting it into production as two separate steps. because the former is much more complex (and expensive), many it departments opt to do the production piece themselves. in most cases, the average programmer can access the ai model (usually via an api) and put it to work.\n\n### what is deep learning?\n\nfor ai, identifying whether an egg is broken is relatively simple. by contrast, looking ahead at a red, round object and labeling it a \u201cstop sign\u201d is much more complex.\n\nthis is where **deep learning** comes in. deep learning enables ai models to sort things into tinier and tinier categories. ai experts think about this sorting as a layered process.\n\nin the case of the stop sign, the relevant layers might be:\n\n1. distance from car.\n2. shape.\n3. estimated height.\n4. position on the road.\n5. color.\n6. text on the sign.\n7. etc.\n\nto identify the stop sign, a self-driving car would have to pass the image of the stop sign through a series of layers to make sure it wasn\u2019t a mountain, a -----> tree !!! , a speed limit sign, or a starbucks. by layering simple ai categorization models on top of each other, ais become much more sophisticated.\n\nlet\u2019s look at another example related to emotion detection. could an ai detect whether someone was in a bad mood? to consider that question, let\u2019s first think about how humans can tell whether someone is in a bad mood.\n\nin order to make that judgment, our brains must integrate a lot of visual and auditory information about the subject.\n\nfor example:\n\n1. mouth position (smiling, frowning)\n2. eyebrow position (raised, narrow)\n3. pronounced wrinkles (laugh or frown lines)\n4. tone and volume of voice (yelling)\n5. speaking speed\n6. posture\n7. shoulder position\n8. etc\u2026\n\nin fact, there are so many subtle and not-so-subtle indicators that it\u2019s nearly impossible to list them all out. what\u2019s nice about ai is that we never have to define those messy and long-tail indicators. ai\u2019s superpower is that it can figure out the rules for itself.\n\nby showing an ai model dozens of faces and labeling each with an emotion, the model could be trained to find the pattern, thereby integrating a wealth of obscure information about how someone looks to predict how someone is feeling.\n\nthis is the same facial recognition capability that apple uses to unlock your iphone. in that case, instead of matching your face with an emotion, the system is ensuring your face matches your account.\n\nai researchers are using images of people\u2019s faces as inputs for all kinds of models, including lie detection, age detection, disease diagnostics, and even imaging technologies that age-up missing children.\n\nas you begin to think more and more about the ways artificial intelligence can transform your company, challenge yourself to think in terms of inputs (data) and outputs (categorization).\n\nremember, ai is amazingly powerful. ai models can use xrays to diagnose disease, billions of financial transactions to detect fraud, and boxes of handwritten case files to prove someone is innocent.\n\ndon\u2019t worry if the distance between inputs and outputs seems vast. ai is more than capable of making those connections.\n\nthis chapter is an excerpt from the ebook, the complete guide to bringing artificial intelligence to your organization.\n\n[access the full guide here.](https://www.manceps.com/ai-guide?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=everything%20you%20need%20to%20understand%20artificial%20intelligence)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('self',)", "medialink": "('https://www.reddit.com/r/ArtificialInteligence/comments/hzh9vd/everything_you_need_to_understand_artificial/',)", "identifyer": 5603833, "year": "2020"}, {"autor": "Yuqing7", "date": 1595367593000, "content": "[R] Automating Machine Learning: Google AutoML-Zero Evolves ML Algorithms From Scratch /!/ In a recent ICML paper, Google researchers propose an \u201cAutoML-Zero\u201d approach designed to automatically search for machine learning (ML) algorithms from scratch, requiring minimal human expertise or input. Starting from empty programs, AutoML-Zero uses only basic mathematical operations as building blocks and applies evolutionary methods to automatically find the code for complete ML algorithms.\n\nHere is a quick: [Automating Machine Learning: Google AutoML-Zero Evolves ML Algorithms From Scratch](https://syncedreview.com/2020/07/21/automating-machine-learning-google-automl-zero-evolves-ml-algorithms-from-scratch/)\n\nThe paper *AutoML-Zero: Evolving Machine Learning Algorithms From Scratch* is on [arXiv](https://arxiv.org/pdf/2003.03384.pdf) and the open-sourced code is on [GitHub](https://github.com/google-research/google-research/tree/master/automl_zero#automl-zero).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hvgig9/r_automating_machine_learning_google_automlzero/", "origin": "Reddit", "suborigin": "ArtificialInteligence", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] automating machine learning: google automl-zero evolves ml algorithms from scratch /!/ in a recent icml paper, google researchers propose an \u201cautoml-zero\u201d approach designed to automatically search for machine learning (ml) algorithms from scratch, requiring minimal human expertise or input. starting from empty programs, automl-zero uses only basic mathematical operations as building blocks and applies evolutionary methods to automatically find the code for complete ml algorithms.\n\nhere is a quick: [automating machine learning: google automl-zero evolves ml algorithms from scratch](https://syncedreview.com/2020/07/21/automating-machine-learning-google-automl-zero-evolves-ml-algorithms-from-scratch/)\n\nthe paper *automl-zero: evolving machine learning algorithms from scratch* is on [arxiv](https://arxiv.org/pdf/2003.03384.pdf) and the open-sourced code is on [github](https://github.com/google-research/google-research/-----> tree !!! /master/automl_zero#automl-zero).", "sortedWord": "None", "removed": "('nan',)", "score": 6, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/ArtificialInteligence/comments/hvgig9/r_automating_machine_learning_google_automlzero/',)", "identifyer": 5604364, "year": "2020"}], "name": "treeArtificialInteligence2020"}