{"interestingcomments": [{"autor": "Yuli-Ban", "date": 1590087186000, "content": "The emergence of functional or \"weak\" general AI /!/ Over the past decade, I've been mulling on the philosophical ideas of AI. One of my biggest issues with our discussions around it is our limited terminology: there's narrow AI, general AI, and super AI. Barely anything else. Most other terminologies are just synonyms for these: narrow AI has been called weak AI, shallow AI, limited AI, single-purpose AI, and my favorite: \"not AI\" (because narrow AI functions are almost always downplayed as not being AI but instead some other comp-sci phrase, e.g. genetic algorithms, tree searches, optimizers, expert systems, Boolean functions, etc.). General AI has its own bevy of terms like strong AI, deep AI, human-level AI, and more. \n\nBut I think there may be something lost in translation there. It was GPT-2 that really struck me\u2014 [this particular AI is incredibly generalized for what it is](https://www.reddit.com/r/singularity/comments/ggybxf/poll_what_decade_do_you_think_our_civilization/fqae5py/), doing things that it wasn't designed to do. It's still limited, of course, and a lot of its generalized functions only appeared after retraining. But with enough data, one could get a future transformer network to do everything from generate images to write text to generate audio with no need for extensive retraining the weights. That sounds to me a lot like an AGI. This goes triply so when you take into account factors like rudimentary commonsense reasoning and spatial awareness.\n\nOf course, GPT-2 is not an AGI or anything even remotely close. It's still extremely narrow; just less narrow than its contemporaries. But this does beg the question: is it possible that we're actually closer than we think?\n\nI know I've been talking about using BCIs to generate neural data to feed into neural networks. Let's just assume that there's a company right now that's already done this. They've gathered tens of thousands of hours of neurofeedback from an advanced set of BCIs that utilize MEG, fMRI, ECoG, and so on techniques (or at least techniques equivalent to them). Things vastly superior to EEG without the need for invasive procedures, allowing us to get data in sickening high amounts that's much higher quality than anything else. Feeding this data plus a knock-out amount of internet data into a transformer has given us GPT-3, the world's first AGI.\n\n\nIf this is something that has actually happened, then I feel confident in expressing that this AGI is very *functional* and nothing more. \n\nWhat do I mean by that?\n\nI mean that this AGI can generalize across all domains; it can understand &amp; generate text (including interactively), playing video games, synthesize audio, parse gargantuan amounts of data to find patterns, and drive a car. Sounds super impressive; the Singularity must be near, right? And it is. But it's not now. It's not even any time particularly soon. This is because said AGI has no consciousness. It has no sapience. It has no \"true\" understanding of things, even though it \"understands\" things. It is not an artificial person; it is a super tool, a descendant of the flint spears that proto-humans made (and hunter-gatherer tribes today still make). This early form of AGI would still be an invaluable tool, but it would not be superhuman or have any chance of becoming such immediately. \n\nIt's a good example of the \"plane vs. bird\" analogy: it won't think like a human being, though it might resemble it at times when it comes to generating text or finding patterns. It would be a very \"computerized\" intelligence if anything. So computerized that I genuinely wouldn't be surprised if there are *still* people who claim it's \"not a real AI\" because it lacks consciousness or sapience or self-drive. Even if instructed to improve itself, it wouldn't actually be able to engage in an intelligence explosion. \n\nIt would be like an incredibly generalized expert system, now that I think about it. Something invaluable to businesses and governments which can also provide amusement and stress for average people. But to say it's worldchanging would actually be an overstatement; indeed, the first few years in a world of AGI might actually prove *disappointing* for many people. Imagine the letdown: for so long we've been waiting for computers that can do whatever a human can, and here they are\u2014 and they're actually not as good as we expected! Indeed, to use a cliche that a colleague mentioned in regards to this potential tech, it will almost certainly be a jack of all trades and master of none\u2014 as good as it will be, the best narrow systems will almost always be orders of magnitude better. Only in natural language generation would it be indisputably superior, and that's only if transformers are used to create it. It would still be so good as to potentially pose a national security risk should other nations come into possession of it or its fundamentals, so if anything, it might actually be more prudent to keep it hidden and only release certain bits of its capabilities piecemeal over the course of several years.\n\nBelieve it or not, I can see such an AGI being created very soon. It was realizing the full capabilities of GPT-2 that struck me, and the discovery of Kernel's progress in BCIs was also another catalyst. Before them, I was sure Openwater would be the one, and they likely will still release a product soon. It was really just a big race to see which one would release this tech first; as it happened, Kernel not only beat everyone to the punch but even had the same presence of mind. We're just all waiting to actually see how much data their headsets can recover (it's likely a massive amount). \n\nInteresting that they happened to achieve this right around the same time that transformer neural networks were created. Transformers themselves will likely be replaced by a newer, even more generalizable network, but they alone are amazing.\n\nWith both of these, this functional kind of AGI actually seems tangible to me now. There's no reason it ought to take longer than 5 years to create one. Which is insane.\n\nOf course, I might be wrong.", "link": "https://www.reddit.com/r/singularity/comments/go2rdv/the_emergence_of_functional_or_weak_general_ai/", "origin": "Reddit", "suborigin": "singularity", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "the emergence of functional or \"weak\" general ai /!/ over the past decade, i've been mulling on the philosophical ideas of ai. one of my biggest issues with our discussions around it is our limited terminology: there's narrow ai, general ai, and super ai. barely anything else. most other terminologies are just synonyms for these: narrow ai has been called weak ai, shallow ai, limited ai, single-purpose ai, and my favorite: \"not ai\" (because narrow ai functions are almost always downplayed as not being ai but instead some other comp-sci phrase, e.g. genetic algorithms, -----> tree !!!  searches, optimizers, expert systems, boolean functions, etc.). general ai has its own bevy of terms like strong ai, deep ai, human-level ai, and more. \n\nbut i think there may be something lost in translation there. it was gpt-2 that really struck me\u2014 [this particular ai is incredibly generalized for what it is](https://www.reddit.com/r/singularity/comments/ggybxf/poll_what_decade_do_you_think_our_civilization/fqae5py/), doing things that it wasn't designed to do. it's still limited, of course, and a lot of its generalized functions only appeared after retraining. but with enough data, one could get a future transformer network to do everything from generate images to write text to generate audio with no need for extensive retraining the weights. that sounds to me a lot like an agi. this goes triply so when you take into account factors like rudimentary commonsense reasoning and spatial awareness.\n\nof course, gpt-2 is not an agi or anything even remotely close. it's still extremely narrow; just less narrow than its contemporaries. but this does beg the question: is it possible that we're actually closer than we think?\n\ni know i've been talking about using bcis to generate neural data to feed into neural networks. let's just assume that there's a company right now that's already done this. they've gathered tens of thousands of hours of neurofeedback from an advanced set of bcis that utilize meg, fmri, ecog, and so on techniques (or at least techniques equivalent to them). things vastly superior to eeg without the need for invasive procedures, allowing us to get data in sickening high amounts that's much higher quality than anything else. feeding this data plus a knock-out amount of internet data into a transformer has given us gpt-3, the world's first agi.\n\n\nif this is something that has actually happened, then i feel confident in expressing that this agi is very *functional* and nothing more. \n\nwhat do i mean by that?\n\ni mean that this agi can generalize across all domains; it can understand &amp; generate text (including interactively), playing video games, synthesize audio, parse gargantuan amounts of data to find patterns, and drive a car. sounds super impressive; the singularity must be near, right? and it is. but it's not now. it's not even any time particularly soon. this is because said agi has no consciousness. it has no sapience. it has no \"true\" understanding of things, even though it \"understands\" things. it is not an artificial person; it is a super tool, a descendant of the flint spears that proto-humans made (and hunter-gatherer tribes today still make). this early form of agi would still be an invaluable tool, but it would not be superhuman or have any chance of becoming such immediately. \n\nit's a good example of the \"plane vs. bird\" analogy: it won't think like a human being, though it might resemble it at times when it comes to generating text or finding patterns. it would be a very \"computerized\" intelligence if anything. so computerized that i genuinely wouldn't be surprised if there are *still* people who claim it's \"not a real ai\" because it lacks consciousness or sapience or self-drive. even if instructed to improve itself, it wouldn't actually be able to engage in an intelligence explosion. \n\nit would be like an incredibly generalized expert system, now that i think about it. something invaluable to businesses and governments which can also provide amusement and stress for average people. but to say it's worldchanging would actually be an overstatement; indeed, the first few years in a world of agi might actually prove *disappointing* for many people. imagine the letdown: for so long we've been waiting for computers that can do whatever a human can, and here they are\u2014 and they're actually not as good as we expected! indeed, to use a cliche that a colleague mentioned in regards to this potential tech, it will almost certainly be a jack of all trades and master of none\u2014 as good as it will be, the best narrow systems will almost always be orders of magnitude better. only in natural language generation would it be indisputably superior, and that's only if transformers are used to create it. it would still be so good as to potentially pose a national security risk should other nations come into possession of it or its fundamentals, so if anything, it might actually be more prudent to keep it hidden and only release certain bits of its capabilities piecemeal over the course of several years.\n\nbelieve it or not, i can see such an agi being created very soon. it was realizing the full capabilities of gpt-2 that struck me, and the discovery of kernel's progress in bcis was also another catalyst. before them, i was sure openwater would be the one, and they likely will still release a product soon. it was really just a big race to see which one would release this tech first; as it happened, kernel not only beat everyone to the punch but even had the same presence of mind. we're just all waiting to actually see how much data their headsets can recover (it's likely a massive amount). \n\ninteresting that they happened to achieve this right around the same time that transformer neural networks were created. transformers themselves will likely be replaced by a newer, even more generalizable network, but they alone are amazing.\n\nwith both of these, this functional kind of agi actually seems tangible to me now. there's no reason it ought to take longer than 5 years to create one. which is insane.\n\nof course, i might be wrong.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 10, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/singularity/comments/go2rdv/the_emergence_of_functional_or_weak_general_ai/',)", "identifyer": 5757454, "year": "2020"}, {"autor": "AGI_Civilization", "date": 1595253064000, "content": "Wouldn't it be hard to call it AGI even if it passed the Turing test? /!/ I think I've seen a lot of posts about the GPT-3 recently.\n\nI think that language model cannot be AGI, no matter how developed.\n\nIn order to reach true intelligence, I think there should be a model capable of physical reasoning rather than extremely mastering the combination of grammars.\n\nI think it's possible to evade attacks that hit the loopholes of AI with extreme amounts of data.\n\nIn particular, the broader and less detailed the question is, the easier it is to be consistent with a wide range of answers.\n\nFor example, when it comes to questions about life or philosophy, we humans have different experiences, different values \u200b\u200band direction of life, so whatever AI answers, it becomes personality.\n\nIn order for AI to successfully complete the Turing Test, we need to be able to answer questions about science, mathematics, and logic rather than conversations about humanities.\n\nWe need to be able to answer through inference by asking for information that cannot be explored in vast amounts of data.\n\nIf you can solve this problem, I think you have reached 90% of the true AGI.\n\nAfter all, the biggest problem is about'behavior'.\n\nIt is important for human-level AI to be able to communicate as much as humans, but more importantly, it is necessary to build a model for the world by recognizing and conceptualizing numerous objects and situations in the real world mess.\n\nAfter all, physical reasoning is indispensable. (No matter how much you train in the language, it is basically impossible to solve..)\n\nHere is a good example.\n\nThere is a prisoner in prison. This prisoner does not have a driver's license.\n\nTeach you how to drive with only conversation and explanation without giving any physical experience to this prisoner.\n\nThis prisoner will never be able to actually drive after hearing your detailed explanation.\n\nBecause most of the knowledge needed to live the world is nonverbal.\n\nNo matter how much you read a book written by Warren Buffett, you will have a hard time making big money out of stock.\n\nMost of Warren Buffett's know-how will be intuition.\n\nThe word intuition is very simple, but what this short word means is quite profound. Perhaps even studying for a lifetime will not be able to master it.\n\nIn any case, I think language is important to achieving true intelligence, but intelligence that governs behavior is more important.\n\nIn order for human beings to survive in the real world, it is necessary to take appropriate action at the right time and space. Here, most of the action is material control through muscle control. It could be trimming a tree using sophisticated tools, or moving your body to a safe place, avoiding the threat of predators.\n\nEven having a conversation requires proper control of the muscles.\n\n(Shrink the lung muscles and at the same time mix the jaw muscles and tongue muscles appropriately. Various different sound wave cycles are formed depending on the combination.)\n\nThat's why I think it's hard to see it as a complete AGI, even if an AI that perfectly performs a Turing test appears. But it feels very close\n\nWhat are your thoughts?", "link": "https://www.reddit.com/r/singularity/comments/hull4r/wouldnt_it_be_hard_to_call_it_agi_even_if_it/", "origin": "Reddit", "suborigin": "singularity", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "wouldn't it be hard to call it agi even if it passed the turing test? /!/ i think i've seen a lot of posts about the gpt-3 recently.\n\ni think that language model cannot be agi, no matter how developed.\n\nin order to reach true intelligence, i think there should be a model capable of physical reasoning rather than extremely mastering the combination of grammars.\n\ni think it's possible to evade attacks that hit the loopholes of ai with extreme amounts of data.\n\nin particular, the broader and less detailed the question is, the easier it is to be consistent with a wide range of answers.\n\nfor example, when it comes to questions about life or philosophy, we humans have different experiences, different values \u200b\u200band direction of life, so whatever ai answers, it becomes personality.\n\nin order for ai to successfully complete the turing test, we need to be able to answer questions about science, mathematics, and logic rather than conversations about humanities.\n\nwe need to be able to answer through inference by asking for information that cannot be explored in vast amounts of data.\n\nif you can solve this problem, i think you have reached 90% of the true agi.\n\nafter all, the biggest problem is about'behavior'.\n\nit is important for human-level ai to be able to communicate as much as humans, but more importantly, it is necessary to build a model for the world by recognizing and conceptualizing numerous objects and situations in the real world mess.\n\nafter all, physical reasoning is indispensable. (no matter how much you train in the language, it is basically impossible to solve..)\n\nhere is a good example.\n\nthere is a prisoner in prison. this prisoner does not have a driver's license.\n\nteach you how to drive with only conversation and explanation without giving any physical experience to this prisoner.\n\nthis prisoner will never be able to actually drive after hearing your detailed explanation.\n\nbecause most of the knowledge needed to live the world is nonverbal.\n\nno matter how much you read a book written by warren buffett, you will have a hard time making big money out of stock.\n\nmost of warren buffett's know-how will be intuition.\n\nthe word intuition is very simple, but what this short word means is quite profound. perhaps even studying for a lifetime will not be able to master it.\n\nin any case, i think language is important to achieving true intelligence, but intelligence that governs behavior is more important.\n\nin order for human beings to survive in the real world, it is necessary to take appropriate action at the right time and space. here, most of the action is material control through muscle control. it could be trimming a -----> tree !!!  using sophisticated tools, or moving your body to a safe place, avoiding the threat of predators.\n\neven having a conversation requires proper control of the muscles.\n\n(shrink the lung muscles and at the same time mix the jaw muscles and tongue muscles appropriately. various different sound wave cycles are formed depending on the combination.)\n\nthat's why i think it's hard to see it as a complete agi, even if an ai that perfectly performs a turing test appears. but it feels very close\n\nwhat are your thoughts?", "sortedWord": "None", "removed": "('nan',)", "score": 6, "comments": 26, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/singularity/comments/hull4r/wouldnt_it_be_hard_to_call_it_agi_even_if_it/',)", "identifyer": 5758887, "year": "2020"}], "name": "treesingularity2020"}