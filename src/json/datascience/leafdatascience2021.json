{"interestingcomments": [{"autor": "jahzan_99", "date": 1610593275000, "content": "We're gonna develop an app where the DEFECT OF THE PLANT CAN BE FOUND BY SCANNING THE LEAF for our Uni Group Project. We found a Data Set which has 50,000 classified leaf images. Any suggestions on Data Science technologies , Languages that we can use to do this? Coz we are clueless now on starting /!/ I'm a Second Year Software Engineering Undergrad. We have got a group project where there should be Data Science as the main core. So we came up with an idea to develop an app where the DEFECT OF THE PLANT CAN BE FOUND BY SCANNING THE LEAF. We have found a Data Set which has 50,000 classified images of defected and healthy leaves. We done with the UI part and we are clueless about the back end and the Data Science Part. Can anyone please give me suggestions on what are the technologies and languages that we can use to achieve this. Because we are clueless now on where to start. Coz we have only 3 months left to develop both the Back End and the Data Science Part.", "link": "https://www.reddit.com/r/datascience/comments/kwwsuc/were_gonna_develop_an_app_where_the_defect_of_the/", "origin": "Reddit", "suborigin": "datascience", "result": true, "Selector": "leaf", "selectorShort": "leaf", "MarkedSent": "we're gonna develop an app where the defect of the plant can be found by scanning the -----> leaf !!!  for our uni group project. we found a data set which has 50,000 classified leaf images. any suggestions on data science technologies , languages that we can use to do this? coz we are clueless now on starting /!/ i'm a second year software engineering undergrad. we have got a group project where there should be data science as the main core. so we came up with an idea to develop an app where the defect of the plant can be found by scanning the leaf. we have found a data set which has 50,000 classified images of defected and healthy leaves. we done with the ui part and we are clueless about the back end and the data science part. can anyone please give me suggestions on what are the technologies and languages that we can use to achieve this. because we are clueless now on where to start. coz we have only 3 months left to develop both the back end and the data science part.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 8, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/datascience/comments/kwwsuc/were_gonna_develop_an_app_where_the_defect_of_the/',)", "identifyer": 5588196, "year": "2021"}, {"autor": "jebuz23", "date": 1613022770000, "content": "Is it possible a dataset is simply not predictive? /!/ So I have a data set that I\u2019m trying to perform some supervised modeling on (regression). Over 50,000 records and over 50 potential predictors. Most of them are categorical, so my first attempt was using random forest. Train/validation/test sets randomly split to 60/20/20. \n\nThing is, my adjusted R sq for validation is constantly around 2% regardless of my hyper parameters. Most of the time my adj. R sq for training data is around there as well, unless I let the trees get really deep (like 10,000+ leaves). Then training adj. r sq is around 80% but validation stays around 2%. \n\nAt first I thought this might be an overfitting issue but I\u2019ve adjusted hyper parameters to address this. Variables to try 5 to 35, leaf size 5 to 1000, max leaf count 2500 to 10,000.  Nothing seems to break validation away from 2% r sq. As mentioned, most of the tuning values have training r sq. near that as well, unless the trees get really deep. \n\nSo my question is half \u201cwhat else can I try?\u201d And half \u201cis it simply the case that the data can\u2019t predict the target?\u201d  \n\nOpen to any and all thoughts on this, I\u2019m at a loss!  TIA!", "link": "https://www.reddit.com/r/datascience/comments/lhe71y/is_it_possible_a_dataset_is_simply_not_predictive/", "origin": "Reddit", "suborigin": "datascience", "result": true, "Selector": "leaf", "selectorShort": "leaf", "MarkedSent": "is it possible a dataset is simply not predictive? /!/ so i have a data set that i\u2019m trying to perform some supervised modeling on (regression). over 50,000 records and over 50 potential predictors. most of them are categorical, so my first attempt was using random forest. train/validation/test sets randomly split to 60/20/20. \n\nthing is, my adjusted r sq for validation is constantly around 2% regardless of my hyper parameters. most of the time my adj. r sq for training data is around there as well, unless i let the trees get really deep (like 10,000+ leaves). then training adj. r sq is around 80% but validation stays around 2%. \n\nat first i thought this might be an overfitting issue but i\u2019ve adjusted hyper parameters to address this. variables to try 5 to 35, -----> leaf !!!  size 5 to 1000, max -----> leaf !!!  count 2500 to 10,000.  nothing seems to break validation away from 2% r sq. as mentioned, most of the tuning values have training r sq. near that as well, unless the trees get really deep. \n\nso my question is half \u201cwhat else can i try?\u201d and half \u201cis it simply the case that the data can\u2019t predict the target?\u201d  \n\nopen to any and all thoughts on this, i\u2019m at a loss!  tia!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 60, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/datascience/comments/lhe71y/is_it_possible_a_dataset_is_simply_not_predictive/',)", "identifyer": 5591305, "year": "2021"}, {"autor": "prashantmdgl9", "date": 1613599730000, "content": "How my mother started using CNN /!/ My mother was spending hours on YouTube to find the remedy for her plants; I don't know much about Botany, so I tried to help her using some machine learning.\n\nI helped her in identifying:\n\n1. Soil type \n2. Leaf diseases\n\nThe app is deployed on streamlit here - [https://share.streamlit.io/prashantmdgl9/soil-analysis/main/app.py](https://share.streamlit.io/prashantmdgl9/soil-analysis/main/app.py)\n\n&amp;#x200B;\n\nThe main article - [https://towardsdatascience.com/how-my-mother-started-using-cnn-for-her-plants-f0913e5548db](https://towardsdatascience.com/how-my-mother-started-using-cnn-for-her-plants-f0913e5548db)", "link": "https://www.reddit.com/r/datascience/comments/lm63o0/how_my_mother_started_using_cnn/", "origin": "Reddit", "suborigin": "datascience", "result": true, "Selector": "leaf", "selectorShort": "leaf", "MarkedSent": "how my mother started using cnn /!/ my mother was spending hours on youtube to find the remedy for her plants; i don't know much about botany, so i tried to help her using some machine learning.\n\ni helped her in identifying:\n\n1. soil type \n2. -----> leaf !!!  diseases\n\nthe app is deployed on streamlit here - [https://share.streamlit.io/prashantmdgl9/soil-analysis/main/app.py](https://share.streamlit.io/prashantmdgl9/soil-analysis/main/app.py)\n\n&amp;#x200b;\n\nthe main article - [https://towardsdatascience.com/how-my-mother-started-using-cnn-for-her-plants-f0913e5548db](https://towardsdatascience.com/how-my-mother-started-using-cnn-for-her-plants-f0913e5548db)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/datascience/comments/lm63o0/how_my_mother_started_using_cnn/',)", "identifyer": 5593092, "year": "2021"}, {"autor": "aTestCandidate", "date": 1633688946000, "content": "Ready, Steady, Go AI: A practical tutorial on fundamentals of artificial intelligence and its applications in phenomics image analysis /!/ Advances in AI technologies have the potential to significantly increase our ability to turn plant phenomics data into valuable insights. However, performing such analyses requires specialized programming skills commonly reserved for computer scientists. We created an interactive tutorial with free, open-source, and FAIR notebooks that can aid researchers to conduct such analyses without the need for an extensive coding experience. We supplemented it with a practical guide on how to implement AI and explainable AI (X-AI) algorithms that augment and complement human experience in classifying tomato leaf diseases and spider mites. Our tutorial is not only applicable to other stresses but also transferable to other plants and research domains, making it possible for researchers from various scientific fields to generate insights into their data. Check out our paper at https://doi.org/10.1016/j.patter.2021.100323", "link": "https://www.reddit.com/r/datascience/comments/q3v043/ready_steady_go_ai_a_practical_tutorial_on/", "origin": "Reddit", "suborigin": "datascience", "result": true, "Selector": "leaf", "selectorShort": "leaf", "MarkedSent": "ready, steady, go ai: a practical tutorial on fundamentals of artificial intelligence and its applications in phenomics image analysis /!/ advances in ai technologies have the potential to significantly increase our ability to turn plant phenomics data into valuable insights. however, performing such analyses requires specialized programming skills commonly reserved for computer scientists. we created an interactive tutorial with free, open-source, and fair notebooks that can aid researchers to conduct such analyses without the need for an extensive coding experience. we supplemented it with a practical guide on how to implement ai and explainable ai (x-ai) algorithms that augment and complement human experience in classifying tomato -----> leaf !!!  diseases and spider mites. our tutorial is not only applicable to other stresses but also transferable to other plants and research domains, making it possible for researchers from various scientific fields to generate insights into their data. check out our paper at https://doi.org/10.1016/j.patter.2021.100323", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/datascience/comments/q3v043/ready_steady_go_ai_a_practical_tutorial_on/',)", "identifyer": 5596263, "year": "2021"}, {"autor": "HerrX2000", "date": 1619359486000, "content": "Questions about Data Acquisition for Bachelor Thesis about User Commitment and User Turnover on country-specific Subreddits /!/ Greetings reddit, for my business informatics bachelor I would like to investigate subreddits and user behaviour. I am in the phase of presenting my idea to the \u201csocial media &amp; data science\u201d chair in the form of an expose. I am gonna try to give a concise summary of my idea. My current working title is: \u201cAnalysis of user commitment to country- and city-specific subreddits depending on the community's size on Reddit\u201d.\n\nI would like to look at three subreddits, likely r/europe, r/de, and r/Berlin. Reddit provides two kinds of APIs, the [json version of post](https://api.reddit.com/r/de/comments/my4a4q/hufeisentheorie_bei_focus_online/), subs and users and the [API](https://www.reddit.com/dev/api/) providing the ability to interact with reddit, e.g. post/comment etc. Therefore the json api is more relevant for my endeavour.\n\nThe following is a sketch of what data I\u2019d need at the end for my data analysis: Post: id, title, user, subreddit, karma (after seven days) User: id, first interaction on subreddit (calculated once on first query of user) Comments (after seven days): id, body, user, karma, post\n\nThe observation period is planned to be a month. After some rough calculation this should result in 2GB for larger subreddits like r/de (152 Post/Day), and 0.5 GB for smaller subs like r/berlin (34 Post/Day) when estimating each post to be around 450 KB. Therefore I would save all raw data. The data acquisition would be done via a java app, here I have already found various libraries that make this process easy.\n\nPossible Research Hypothesis:\n\n* Group size will be positively related to attraction of new members.\n* Group variety will be positively related to attraction of new members.\n* Group size will be positively related to diverse representation of users in featured posts.\n* Group variety will be positively related to diverse representation of users in featured  posts.\n* High positive interaction rate will be positively related to a user's commitment in a community.\n\nFor analysing data I would write my final data result to a csv and analyse them in R. Here I know how and when to apply the following statistical techniques: linear regression, loese, logistic regression, probit, and logit leaf model.\n\nReference [paper](https://journals.sagepub.com/doi/full/10.1177/2056305118815908)\n\nMy questions:\n\n1. Would a raspberry pi 4 + (headless) ubuntu + cron job do the job? Would I need an extra cooling solution or could it run passively in my closet.\n2. Could you recommend any backups soltions, that I could easily implement in my java app?\n3. I\u2019ve attended data science courses but are there sources that you highly recommend to read?\n4. Are there other statistical techniques that could be interesting to look into for my use case?\n5. Do you see any dangers in using the public reddit api? What should I be prepared for?\n6. For what I have described so far, does it seam under- or over-scoped for a bachelor thesis?\n\nShould you have written a bachelor or master thesis with a similar scope, I would very much be interested in taking a look. I would also very much appreciate any other feedback :)", "link": "https://www.reddit.com/r/datascience/comments/my8y3e/questions_about_data_acquisition_for_bachelor/", "origin": "Reddit", "suborigin": "datascience", "result": true, "Selector": "leaf", "selectorShort": "leaf", "MarkedSent": "questions about data acquisition for bachelor thesis about user commitment and user turnover on country-specific subreddits /!/ greetings reddit, for my business informatics bachelor i would like to investigate subreddits and user behaviour. i am in the phase of presenting my idea to the \u201csocial media &amp; data science\u201d chair in the form of an expose. i am gonna try to give a concise summary of my idea. my current working title is: \u201canalysis of user commitment to country- and city-specific subreddits depending on the community's size on reddit\u201d.\n\ni would like to look at three subreddits, likely r/europe, r/de, and r/berlin. reddit provides two kinds of apis, the [json version of post](https://api.reddit.com/r/de/comments/my4a4q/hufeisentheorie_bei_focus_online/), subs and users and the [api](https://www.reddit.com/dev/api/) providing the ability to interact with reddit, e.g. post/comment etc. therefore the json api is more relevant for my endeavour.\n\nthe following is a sketch of what data i\u2019d need at the end for my data analysis: post: id, title, user, subreddit, karma (after seven days) user: id, first interaction on subreddit (calculated once on first query of user) comments (after seven days): id, body, user, karma, post\n\nthe observation period is planned to be a month. after some rough calculation this should result in 2gb for larger subreddits like r/de (152 post/day), and 0.5 gb for smaller subs like r/berlin (34 post/day) when estimating each post to be around 450 kb. therefore i would save all raw data. the data acquisition would be done via a java app, here i have already found various libraries that make this process easy.\n\npossible research hypothesis:\n\n* group size will be positively related to attraction of new members.\n* group variety will be positively related to attraction of new members.\n* group size will be positively related to diverse representation of users in featured posts.\n* group variety will be positively related to diverse representation of users in featured  posts.\n* high positive interaction rate will be positively related to a user's commitment in a community.\n\nfor analysing data i would write my final data result to a csv and analyse them in r. here i know how and when to apply the following statistical techniques: linear regression, loese, logistic regression, probit, and logit -----> leaf !!!  model.\n\nreference [paper](https://journals.sagepub.com/doi/full/10.1177/2056305118815908)\n\nmy questions:\n\n1. would a raspberry pi 4 + (headless) ubuntu + cron job do the job? would i need an extra cooling solution or could it run passively in my closet.\n2. could you recommend any backups soltions, that i could easily implement in my java app?\n3. i\u2019ve attended data science courses but are there sources that you highly recommend to read?\n4. are there other statistical techniques that could be interesting to look into for my use case?\n5. do you see any dangers in using the public reddit api? what should i be prepared for?\n6. for what i have described so far, does it seam under- or over-scoped for a bachelor thesis?\n\nshould you have written a bachelor or master thesis with a similar scope, i would very much be interested in taking a look. i would also very much appreciate any other feedback :)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/datascience/comments/my8y3e/questions_about_data_acquisition_for_bachelor/',)", "identifyer": 5596662, "year": "2021"}, {"autor": "vietlinh12hoa", "date": 1627859220000, "content": "Feature Importance from Random Forest /!/ I've tried to play with Feature Importance in Random Forest. Surprisingly every time I modify hyper parameters (max depth, max leaf ...), the level of importance has been changed.\n\nWhat I have done is to remove one feature each time to see how descent the model performance in the test set. If the more significantly the performance drop, the more important the feature is. However, it's a bit time consuming. And we can only know the feature already being engineered (binning, encoding,) not the original features.\n\nAny solution we can know which variable is important at the EDA stage, instead of waiting for modeling and testing?", "link": "https://www.reddit.com/r/datascience/comments/ow2i2a/feature_importance_from_random_forest/", "origin": "Reddit", "suborigin": "datascience", "result": true, "Selector": "leaf", "selectorShort": "leaf", "MarkedSent": "feature importance from random forest /!/ i've tried to play with feature importance in random forest. surprisingly every time i modify hyper parameters (max depth, max -----> leaf !!!  ...), the level of importance has been changed.\n\nwhat i have done is to remove one feature each time to see how descent the model performance in the test set. if the more significantly the performance drop, the more important the feature is. however, it's a bit time consuming. and we can only know the feature already being engineered (binning, encoding,) not the original features.\n\nany solution we can know which variable is important at the eda stage, instead of waiting for modeling and testing?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 13, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/datascience/comments/ow2i2a/feature_importance_from_random_forest/',)", "identifyer": 5598882, "year": "2021"}], "name": "leafdatascience2021"}