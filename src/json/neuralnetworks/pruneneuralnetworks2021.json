{"interestingcomments": [{"autor": "grid_world", "date": 1619276736000, "content": "Accessing modules - PyTorch ResNet-18 /!/ I am using a ResNet-18 coded as follows:\n\n    \n    class ResidualBlock(nn.Module):\n        '''\n        Residual Block within a ResNet CNN model\n        '''\n        def __init__(self, input_channels, num_channels, \n                     use_1x1_conv = False, strides = 1):\n            # super(ResidualBlock, self).__init__()\n            super().__init__()\n         \n            self.conv1 = nn.Conv2d(\n                in_channels = input_channels, out_channels = num_channels,\n                kernel_size = 3, padding = 1, stride = strides,\n                bias = False\n                )\n            self.bn1 = nn.BatchNorm2d(num_features = num_channels)\n            \n            self.conv2 = nn.Conv2d(\n                in_channels = num_channels, out_channels = num_channels,\n                kernel_size = 3, padding = 1, stride = 1,\n                bias = False\n                )\n            self.bn2 = nn.BatchNorm2d(num_features = num_channels)\n            \n            if use_1x1_conv:\n                self.conv3 = nn.Conv2d(\n                    in_channels = input_channels, out_channels = num_channels,\n                    kernel_size = 1, stride = strides\n                    )\n                self.bn3 = nn.BatchNorm2d(num_features = num_channels)\n            else:\n                self.conv3 = None\n            \n            self.relu = nn.ReLU(inplace = True)\n    \n            self.initialize_weights()\n            \n        \n        def forward(self, X):\n            Y = F.relu(self.bn1(self.conv1(X)))\n            Y = self.bn2(self.conv2(Y))\n            \n            if self.conv3:\n                X = self.bn3(self.conv3(X))\n                # print(f\"X.shape due to 1x1: {X.shape} &amp; Y.shape = {Y.shape}\")\n            else:\n                # print(f\"X.shape without 1x1: {X.shape} &amp; Y.shape = {Y.shape}\")\n                pass\n            \n            Y += X\n            return F.relu(Y)\n        \n        \n        def shape_computation(self, X):\n            Y = self.conv1(X)\n            print(f\"self.conv1(X).shape: {Y.shape}\")\n            Y = self.conv2(Y)\n            print(f\"self.conv2(X).shape: {Y.shape}\")\n            \n            if self.conv3:\n                h = self.conv3(X)\n                print(f\"self.conv3(X).shape: {h.shape}\")\n        \n    \n        def initialize_weights(self):\n            for m in self.modules():\n                # print(m)\n                if isinstance(m, nn.Conv2d):\n                    nn.init.kaiming_uniform_(m.weight)\n    \n                    '''\n                    # Do not initialize bias (due to batchnorm)-\n                    if m.bias is not None:\n                        nn.init.constant_(m.bias, 0)\n                    '''\n                \n                elif isinstance(m, nn.BatchNorm2d):\n                    # Standard initialization for batch normalization-\n                    nn.init.constant_(m.weight, 1)\n                    nn.init.constant_(m.bias, 0)\n    \n                elif isinstance(m, nn.Linear):\n                    nn.init.kaiming_normal_(m.weight)\n                    nn.init.constant_(m.bias, 0)\n    \n    b0 = nn.Sequential(\n        nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n        nn.BatchNorm2d(num_features = 64),\n        nn.ReLU())\n    \n    def create_resnet_block(input_filters, output_filters, num_residuals, first_block = False):\n        # Python list to hold the created ResNet blocks-\n        resnet_blk = []\n        \n        for i in range(num_residuals):\n            if i == 0 and first_block:\n                resnet_blk.append(ResidualBlock(input_channels = input_filters, num_channels = output_filters, use_1x1_conv = True, strides = 2))\n            else:\n                resnet_blk.append(ResidualBlock(input_channels = output_filters, num_channels = output_filters, use_1x1_conv = False, strides = 1))\n        \n        return resnet_blk\n    \n    b1 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 64, num_residuals = 2, first_block = True))\n    \n    b2 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 128, num_residuals = 2, first_block = True))\n    \n    b3 = nn.Sequential(*create_resnet_block(input_filters = 128, output_filters = 256, num_residuals = 2, first_block = True))\n    \n    b4 = nn.Sequential(*create_resnet_block(input_filters = 256, output_filters = 512, num_residuals = 2, first_block = True))\n    \n    # Initialize a ResNet-18 CNN model-\n    model = nn.Sequential(\n        b0, b1, b2, b3, b4,\n        nn.AdaptiveAvgPool2d(output_size = (1, 1)),\n        nn.Flatten(),\n        nn.Linear(in_features = 512, out_features = 10))\n\nThe layer names are now as follows:\n\n    for layer_name, param in trained_model.named_parameters():\n        print(f\"layer name: {layer_name} has {param.shape}\")\n    \n\n&gt;layer name: 0.0.weight has torch.Size(\\[64, 3, 3, 3\\])  \n&gt;  \n&gt;layer name: 0.0.bias has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 0.1.weight has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 0.1.bias has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.conv1.weight has torch.Size(\\[64, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 1.0.bn1.weight has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.bn1.bias has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.conv2.weight has torch.Size(\\[64, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 1.0.bn2.weight has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.bn2.bias has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.conv3.weight has torch.Size(\\[64, 64, 1, 1\\])  \n&gt;  \n&gt;layer name: 1.0.conv3.bias has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.bn3.weight has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.bn3.bias has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.1.conv1.weight has torch.Size(\\[64, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 1.1.bn1.weight has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.1.bn1.bias has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.1.conv2.weight has torch.Size(\\[64, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 1.1.bn2.weight has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.1.bn2.bias has torch.Size(\\[64\\])  \n&gt;  \n&gt;layer name: 2.0.conv1.weight has torch.Size(\\[128, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 2.0.bn1.weight has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.bn1.bias has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.conv2.weight has torch.Size(\\[128, 128, 3, 3\\])  \n&gt;  \n&gt;layer name: 2.0.bn2.weight has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.bn2.bias has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.conv3.weight has torch.Size(\\[128, 64, 1, 1\\])  \n&gt;  \n&gt;layer name: 2.0.conv3.bias has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.bn3.weight has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.bn3.bias has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.1.conv1.weight has torch.Size(\\[128, 128, 3, 3\\])  \n&gt;  \n&gt;layer name: 2.1.bn1.weight has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.1.bn1.bias has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.1.conv2.weight has torch.Size(\\[128, 128, 3, 3\\])  \n&gt;  \n&gt;layer name: 2.1.bn2.weight has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.1.bn2.bias has torch.Size(\\[128\\])  \n&gt;  \n&gt;layer name: 3.0.conv1.weight has torch.Size(\\[256, 128, 3, 3\\])  \n&gt;  \n&gt;layer name: 3.0.bn1.weight has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.bn1.bias has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.conv2.weight has torch.Size(\\[256, 256, 3, 3\\])  \n&gt;  \n&gt;layer name: 3.0.bn2.weight has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.bn2.bias has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.conv3.weight has torch.Size(\\[256, 128, 1, 1\\])  \n&gt;  \n&gt;layer name: 3.0.conv3.bias has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.bn3.weight has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.bn3.bias has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.1.conv1.weight has torch.Size(\\[256, 256, 3, 3\\])  \n&gt;  \n&gt;layer name: 3.1.bn1.weight has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.1.bn1.bias has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.1.conv2.weight has torch.Size(\\[256, 256, 3, 3\\])  \n&gt;  \n&gt;layer name: 3.1.bn2.weight has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.1.bn2.bias has torch.Size(\\[256\\])  \n&gt;  \n&gt;layer name: 4.0.conv1.weight has torch.Size(\\[512, 256, 3, 3\\])  \n&gt;  \n&gt;layer name: 4.0.bn1.weight has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.bn1.bias has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.conv2.weight has torch.Size(\\[512, 512, 3, 3\\])  \n&gt;  \n&gt;layer name: 4.0.bn2.weight has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.bn2.bias has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.conv3.weight has torch.Size(\\[512, 256, 1, 1\\])  \n&gt;  \n&gt;layer name: 4.0.conv3.bias has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.bn3.weight has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.bn3.bias has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.1.conv1.weight has torch.Size(\\[512, 512, 3, 3\\])  \n&gt;  \n&gt;layer name: 4.1.bn1.weight has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.1.bn1.bias has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.1.conv2.weight has torch.Size(\\[512, 512, 3, 3\\])  \n&gt;  \n&gt;layer name: 4.1.bn2.weight has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.1.bn2.bias has torch.Size(\\[512\\])  \n&gt;  \n&gt;layer name: 7.weight has torch.Size(\\[10, 512\\])  \n&gt;  \n&gt;layer name: 7.bias has torch.Size(\\[10\\])\n\n&amp;#x200B;\n\nIn order to prune this model, I am referring to [PyTorch pruning tutorial](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#inspect-a-module). It's mentioned here that to prune a module/layer, use the following code:\n\n&amp;#x200B;\n\n    parameters_to_prune = (\n        (model.conv1, 'weight'),\n        (model.conv2, 'weight'),\n        (model.fc1, 'weight'),\n        (model.fc2, 'weight'),\n        (model.fc3, 'weight'),\n    )\n\nBut for the code above, the modules/layers no longer have this naming convention. For example, to prune the first conv layer of this model:\n\n&gt;layer name: 0.0.weight has torch.Size(\\[64, 3, 3, 3\\])\n\n&amp;#x200B;\n\non trying the following code:\n\n    prune.random_unstructured(model.0.0, name = 'weight', amount = 0.3)\n\nIt gives me the error:\n\n&gt;prune.random\\_unstructured(trained\\_model.0.0, name = 'weight', amount = 0.3)  \n&gt;  \n&gt;\\^  \n&gt;  \n&gt;SyntaxError: invalid syntax\n\nHow do I handle this?", "link": "https://www.reddit.com/r/neuralnetworks/comments/mxlr30/accessing_modules_pytorch_resnet18/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "prune", "selectorShort": "prune", "MarkedSent": "accessing modules - pytorch resnet-18 /!/ i am using a resnet-18 coded as follows:\n\n    \n    class residualblock(nn.module):\n        '''\n        residual block within a resnet cnn model\n        '''\n        def __init__(self, input_channels, num_channels, \n                     use_1x1_conv = false, strides = 1):\n            # super(residualblock, self).__init__()\n            super().__init__()\n         \n            self.conv1 = nn.conv2d(\n                in_channels = input_channels, out_channels = num_channels,\n                kernel_size = 3, padding = 1, stride = strides,\n                bias = false\n                )\n            self.bn1 = nn.batchnorm2d(num_features = num_channels)\n            \n            self.conv2 = nn.conv2d(\n                in_channels = num_channels, out_channels = num_channels,\n                kernel_size = 3, padding = 1, stride = 1,\n                bias = false\n                )\n            self.bn2 = nn.batchnorm2d(num_features = num_channels)\n            \n            if use_1x1_conv:\n                self.conv3 = nn.conv2d(\n                    in_channels = input_channels, out_channels = num_channels,\n                    kernel_size = 1, stride = strides\n                    )\n                self.bn3 = nn.batchnorm2d(num_features = num_channels)\n            else:\n                self.conv3 = none\n            \n            self.relu = nn.relu(inplace = true)\n    \n            self.initialize_weights()\n            \n        \n        def forward(self, x):\n            y = f.relu(self.bn1(self.conv1(x)))\n            y = self.bn2(self.conv2(y))\n            \n            if self.conv3:\n                x = self.bn3(self.conv3(x))\n                # print(f\"x.shape due to 1x1: {x.shape} &amp; y.shape = {y.shape}\")\n            else:\n                # print(f\"x.shape without 1x1: {x.shape} &amp; y.shape = {y.shape}\")\n                pass\n            \n            y += x\n            return f.relu(y)\n        \n        \n        def shape_computation(self, x):\n            y = self.conv1(x)\n            print(f\"self.conv1(x).shape: {y.shape}\")\n            y = self.conv2(y)\n            print(f\"self.conv2(x).shape: {y.shape}\")\n            \n            if self.conv3:\n                h = self.conv3(x)\n                print(f\"self.conv3(x).shape: {h.shape}\")\n        \n    \n        def initialize_weights(self):\n            for m in self.modules():\n                # print(m)\n                if isinstance(m, nn.conv2d):\n                    nn.init.kaiming_uniform_(m.weight)\n    \n                    '''\n                    # do not initialize bias (due to batchnorm)-\n                    if m.bias is not none:\n                        nn.init.constant_(m.bias, 0)\n                    '''\n                \n                elif isinstance(m, nn.batchnorm2d):\n                    # standard initialization for batch normalization-\n                    nn.init.constant_(m.weight, 1)\n                    nn.init.constant_(m.bias, 0)\n    \n                elif isinstance(m, nn.linear):\n                    nn.init.kaiming_normal_(m.weight)\n                    nn.init.constant_(m.bias, 0)\n    \n    b0 = nn.sequential(\n        nn.conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n        nn.batchnorm2d(num_features = 64),\n        nn.relu())\n    \n    def create_resnet_block(input_filters, output_filters, num_residuals, first_block = false):\n        # python list to hold the created resnet blocks-\n        resnet_blk = []\n        \n        for i in range(num_residuals):\n            if i == 0 and first_block:\n                resnet_blk.append(residualblock(input_channels = input_filters, num_channels = output_filters, use_1x1_conv = true, strides = 2))\n            else:\n                resnet_blk.append(residualblock(input_channels = output_filters, num_channels = output_filters, use_1x1_conv = false, strides = 1))\n        \n        return resnet_blk\n    \n    b1 = nn.sequential(*create_resnet_block(input_filters = 64, output_filters = 64, num_residuals = 2, first_block = true))\n    \n    b2 = nn.sequential(*create_resnet_block(input_filters = 64, output_filters = 128, num_residuals = 2, first_block = true))\n    \n    b3 = nn.sequential(*create_resnet_block(input_filters = 128, output_filters = 256, num_residuals = 2, first_block = true))\n    \n    b4 = nn.sequential(*create_resnet_block(input_filters = 256, output_filters = 512, num_residuals = 2, first_block = true))\n    \n    # initialize a resnet-18 cnn model-\n    model = nn.sequential(\n        b0, b1, b2, b3, b4,\n        nn.adaptiveavgpool2d(output_size = (1, 1)),\n        nn.flatten(),\n        nn.linear(in_features = 512, out_features = 10))\n\nthe layer names are now as follows:\n\n    for layer_name, param in trained_model.named_parameters():\n        print(f\"layer name: {layer_name} has {param.shape}\")\n    \n\n&gt;layer name: 0.0.weight has torch.size(\\[64, 3, 3, 3\\])  \n&gt;  \n&gt;layer name: 0.0.bias has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 0.1.weight has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 0.1.bias has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.conv1.weight has torch.size(\\[64, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 1.0.bn1.weight has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.bn1.bias has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.conv2.weight has torch.size(\\[64, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 1.0.bn2.weight has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.bn2.bias has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.conv3.weight has torch.size(\\[64, 64, 1, 1\\])  \n&gt;  \n&gt;layer name: 1.0.conv3.bias has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.bn3.weight has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.0.bn3.bias has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.1.conv1.weight has torch.size(\\[64, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 1.1.bn1.weight has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.1.bn1.bias has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.1.conv2.weight has torch.size(\\[64, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 1.1.bn2.weight has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 1.1.bn2.bias has torch.size(\\[64\\])  \n&gt;  \n&gt;layer name: 2.0.conv1.weight has torch.size(\\[128, 64, 3, 3\\])  \n&gt;  \n&gt;layer name: 2.0.bn1.weight has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.bn1.bias has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.conv2.weight has torch.size(\\[128, 128, 3, 3\\])  \n&gt;  \n&gt;layer name: 2.0.bn2.weight has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.bn2.bias has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.conv3.weight has torch.size(\\[128, 64, 1, 1\\])  \n&gt;  \n&gt;layer name: 2.0.conv3.bias has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.bn3.weight has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.0.bn3.bias has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.1.conv1.weight has torch.size(\\[128, 128, 3, 3\\])  \n&gt;  \n&gt;layer name: 2.1.bn1.weight has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.1.bn1.bias has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.1.conv2.weight has torch.size(\\[128, 128, 3, 3\\])  \n&gt;  \n&gt;layer name: 2.1.bn2.weight has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 2.1.bn2.bias has torch.size(\\[128\\])  \n&gt;  \n&gt;layer name: 3.0.conv1.weight has torch.size(\\[256, 128, 3, 3\\])  \n&gt;  \n&gt;layer name: 3.0.bn1.weight has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.bn1.bias has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.conv2.weight has torch.size(\\[256, 256, 3, 3\\])  \n&gt;  \n&gt;layer name: 3.0.bn2.weight has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.bn2.bias has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.conv3.weight has torch.size(\\[256, 128, 1, 1\\])  \n&gt;  \n&gt;layer name: 3.0.conv3.bias has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.bn3.weight has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.0.bn3.bias has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.1.conv1.weight has torch.size(\\[256, 256, 3, 3\\])  \n&gt;  \n&gt;layer name: 3.1.bn1.weight has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.1.bn1.bias has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.1.conv2.weight has torch.size(\\[256, 256, 3, 3\\])  \n&gt;  \n&gt;layer name: 3.1.bn2.weight has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 3.1.bn2.bias has torch.size(\\[256\\])  \n&gt;  \n&gt;layer name: 4.0.conv1.weight has torch.size(\\[512, 256, 3, 3\\])  \n&gt;  \n&gt;layer name: 4.0.bn1.weight has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.bn1.bias has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.conv2.weight has torch.size(\\[512, 512, 3, 3\\])  \n&gt;  \n&gt;layer name: 4.0.bn2.weight has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.bn2.bias has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.conv3.weight has torch.size(\\[512, 256, 1, 1\\])  \n&gt;  \n&gt;layer name: 4.0.conv3.bias has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.bn3.weight has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.0.bn3.bias has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.1.conv1.weight has torch.size(\\[512, 512, 3, 3\\])  \n&gt;  \n&gt;layer name: 4.1.bn1.weight has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.1.bn1.bias has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.1.conv2.weight has torch.size(\\[512, 512, 3, 3\\])  \n&gt;  \n&gt;layer name: 4.1.bn2.weight has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 4.1.bn2.bias has torch.size(\\[512\\])  \n&gt;  \n&gt;layer name: 7.weight has torch.size(\\[10, 512\\])  \n&gt;  \n&gt;layer name: 7.bias has torch.size(\\[10\\])\n\n&amp;#x200b;\n\nin order to -----> prune !!!  this model, i am referring to [pytorch pruning tutorial](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#inspect-a-module). it's mentioned here that to prune a module/layer, use the following code:\n\n&amp;#x200b;\n\n    parameters_to_prune = (\n        (model.conv1, 'weight'),\n        (model.conv2, 'weight'),\n        (model.fc1, 'weight'),\n        (model.fc2, 'weight'),\n        (model.fc3, 'weight'),\n    )\n\nbut for the code above, the modules/layers no longer have this naming convention. for example, to prune the first conv layer of this model:\n\n&gt;layer name: 0.0.weight has torch.size(\\[64, 3, 3, 3\\])\n\n&amp;#x200b;\n\non trying the following code:\n\n    prune.random_unstructured(model.0.0, name = 'weight', amount = 0.3)\n\nit gives me the error:\n\n&gt;prune.random\\_unstructured(trained\\_model.0.0, name = 'weight', amount = 0.3)  \n&gt;  \n&gt;\\^  \n&gt;  \n&gt;syntaxerror: invalid syntax\n\nhow do i handle this?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/mxlr30/accessing_modules_pytorch_resnet18/',)", "identifyer": 5754771, "year": "2021"}, {"autor": "grid_world", "date": 1617415427000, "content": "Iterative Pruning: LeNet-300-100 - PyTorch /!/ I am trying to implement iterative pruning  algorithm (as described in the research papers in [\\[1\\]](https://arxiv.org/abs/1506.02626), [\\[2\\]](https://arxiv.org/abs/1803.03635)) which is: train a model, prune p% of smallest weights per layer, re-train the pruned model and repeat. For experiment purposes, I  am using LeNet-300-100 neural network on MNIST.\n\nThe code can be accessed [here](https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/LeNet_300_100-Iterative_Pruning.ipynb)\n\nWithin the function \u201ctrain\\_with\\_grad\\_freezing(model, epoch)\u201d, I am  using the following lines of code for freezing the pruned weights by  making their computed gradients equal to 0:\n\n    for layer_name, param in model.named_parameters():\n        if 'weight' in layer_name:\n            tensor = param.data.cpu().numpy()\n            grad_tensor = param.grad.data.cpu().numpy()\n            grad_tensor = np.where(tensor == 0, 0, grad_tensor)\n            param.grad.data = torch.from_numpy(grad_tensor).to(device) \n\nThe first time I train the model, the code works fine after which I prune the layers by using the code:\n\n    # Prune 15% of smallest magnitude weights in FC layers and 10% in output layer- pruned_d = prune_lenet(model = best_model, pruning_params_fc = 15, pruning_params_op = 10) \n    # Initialize and load pruned Python3 dict into a new model-\n    pruned_model = LeNet300() pruned_model.load_state_dict(pruned_d) \n\nHowever, on re-training this pruned model, the training metric is stuck for these values:\n\n&gt;training loss = 0.0285, training accuracy = 99.04%, val\\_loss = 0.0910 &amp; val\\_accuracy = 97.68%  \n \n\nWhat\u2019s going wrong?", "link": "https://www.reddit.com/r/neuralnetworks/comments/miz2gy/iterative_pruning_lenet300100_pytorch/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "prune", "selectorShort": "prune", "MarkedSent": "iterative pruning: lenet-300-100 - pytorch /!/ i am trying to implement iterative pruning  algorithm (as described in the research papers in [\\[1\\]](https://arxiv.org/abs/1506.02626), [\\[2\\]](https://arxiv.org/abs/1803.03635)) which is: train a model, -----> prune !!!  p% of smallest weights per layer, re-train the pruned model and repeat. for experiment purposes, i  am using lenet-300-100 neural network on mnist.\n\nthe code can be accessed [here](https://github.com/arjun-majumdar/lottery_ticket_hypothesis-tensorflow_2/blob/master/lenet_300_100-iterative_pruning.ipynb)\n\nwithin the function \u201ctrain\\_with\\_grad\\_freezing(model, epoch)\u201d, i am  using the following lines of code for freezing the pruned weights by  making their computed gradients equal to 0:\n\n    for layer_name, param in model.named_parameters():\n        if 'weight' in layer_name:\n            tensor = param.data.cpu().numpy()\n            grad_tensor = param.grad.data.cpu().numpy()\n            grad_tensor = np.where(tensor == 0, 0, grad_tensor)\n            param.grad.data = torch.from_numpy(grad_tensor).to(device) \n\nthe first time i train the model, the code works fine after which i prune the layers by using the code:\n\n    # prune 15% of smallest magnitude weights in fc layers and 10% in output layer- pruned_d = prune_lenet(model = best_model, pruning_params_fc = 15, pruning_params_op = 10) \n    # initialize and load pruned python3 dict into a new model-\n    pruned_model = lenet300() pruned_model.load_state_dict(pruned_d) \n\nhowever, on re-training this pruned model, the training metric is stuck for these values:\n\n&gt;training loss = 0.0285, training accuracy = 99.04%, val\\_loss = 0.0910 &amp; val\\_accuracy = 97.68%  \n \n\nwhat\u2019s going wrong?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/miz2gy/iterative_pruning_lenet300100_pytorch/',)", "identifyer": 5754844, "year": "2021"}, {"autor": "grid_world", "date": 1621435884000, "content": "Freeze certain weights - TensorFlow 2 /!/ I am using a Conv-6 CNN in TensorFlow 2.5 and Python3. The objective is to selectively set certain weights within any trainable layer. The Conv-6 CNN model definition is as follows:\n\n&amp;#x200B;\n\n        def conv6_cnn():\n            \"\"\"\n            Function to define the architecture of a neural network model\n            following Conv-6 architecture for CIFAR-10 dataset and using\n            provided parameter which are used to prune the model.\n            \n            Conv-6 architecture-\n            64, 64, pool  -- convolutional layers\n            128, 128, pool -- convolutional layers\n            256, 256, pool -- convolutional layers\n            256, 256, 10  -- fully connected layers\n            \n            Output: Returns designed and compiled neural network model\n            \"\"\"\n            \n            l = tf.keras.layers\n            \n            model = Sequential()\n            \n            model.add(\n                Conv2D(\n                    filters = 64, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),\n                    strides = (1, 1), padding = 'same',\n                    input_shape=(32, 32, 3)\n                )    \n            )\n                \n            model.add(\n                Conv2D(\n                    filters = 64, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n            \n            model.add(\n                MaxPooling2D(\n                    pool_size = (2, 2),\n                    strides = (2, 2)\n                )\n            )\n            \n            model.add(\n                Conv2D(\n                    filters = 128, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n        \n            model.add(\n                Conv2D(\n                    filters = 128, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n        \n            model.add(\n                MaxPooling2D(\n                    pool_size = (2, 2),\n                    strides = (2, 2)\n                )\n            )\n        \n            model.add(\n                Conv2D(\n                    filters = 256, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n        \n            model.add(\n                Conv2D(\n                    filters = 256, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n        \n            model.add(\n                MaxPooling2D(\n                    pool_size = (2, 2),\n                    strides = (2, 2)\n                )\n            )\n            \n            model.add(Flatten())\n            \n            model.add(\n                Dense(\n                    units = 256, activation='relu',\n                    kernel_initializer = tf.initializers.GlorotNormal()\n                )\n            )\n            \n            model.add(\n                Dense(\n                    units = 256, activation='relu',\n                    kernel_initializer = tf.initializers.GlorotNormal()\n                )\n            )\n            \n            model.add(\n                Dense(\n                    units = 10, activation='softmax'\n                )\n            )\n            \n        \n            '''\n            # Compile CNN-\n            model.compile(\n                loss=tf.keras.losses.categorical_crossentropy,\n                # optimizer='adam',\n                optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0003),\n                metrics=['accuracy']\n            )\n            '''\n            \n            \n            return model\n    \n    \n        # Load trained model from before-\n        best_model = conv6_cnn()\n        best_model.load_weights(\"best_weights.h5\")\n\n&amp;#x200B;\n\nI came across [this](https://github.com/tensorflow/tensorflow/issues/6264) GitHub answer of freezing certain weights during training. On it's basis, I coded the following to freeze weights in the first and sixth conv layers:\n\n&amp;#x200B;\n\n        conv1 = pruned_model.trainable_weights[0]\n        \n        # Find all weights less than a threshold (0.1) and set them to zero-\n        conv1 = tf.where(conv1 &lt; 0.1, 0, conv1)\n        \n        # For all weights set to zero, stop training them-\n        conv1 = tf.where(conv1 == 0, tf.stop_gradient(conv1), conv1)\n        \n        \n        # Sanity check: number of parameters set at 0-\n        tf.math.count_nonzero(conv1, axis = None).numpy()\n        # 133\n        \n        # Original number of paramaters-\n        tf.math.count_nonzero(best_model.trainable_weights[0], axis = None).numpy()\n        # 1728\n        \n        # Assign conv layer1 back to pruned model-\n        pruned_model.trainable_weights[0].assign(conv1)\n        \n        # Sanity check-\n        tf.math.count_nonzero(pruned_model.trainable_weights[0], axis = None).numpy()\n        # 133\n        \n        # conv layer 6-\n        conv6 = pruned_model.trainable_weights[10]\n        \n        # Find all weights less than a threshold (0.1) and set them to zero-\n        conv6 = tf.where(conv6 &lt; 0.1, 0, conv6)\n        \n        # For all weights set to zero, stop training them-\n        conv6 = tf.where(conv6 == 0, tf.stop_gradient(conv6), conv6)\n        \n        # Sanity check: number of parameters set at 0-\n        tf.math.count_nonzero(conv6, axis = None).numpy()\n        # 5369\n        \n        # Original number of paramaters-\n        tf.math.count_nonzero(best_model.trainable_weights[10], axis = None).numpy()\n        # 589824\n        \n        # Assign conv layer6 back to pruned model-\n        pruned_model.trainable_weights[10].assign(conv6)\n        \n        # Sanity check-\n        tf.math.count_nonzero(pruned_model.trainable_weights[10], axis = None).numpy()\n        # 5369\n        \n        \n        # Train model for 10 epochs for testing:\n        \n        # Compile CNN-\n        pruned_model.compile(\n            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n            optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),\n            metrics=['accuracy']\n        )\n        \n        history = pruned_model.fit(\n            x = X_train, y = y_train,\n            epochs = 10, validation_data = (X_test, y_test)\n        )\n\nHowever, after training when I check the number of non-zero weights:\n\n&amp;#x200B;\n\n        # first conv layer-\n        tf.math.count_nonzero(pruned_model.trainable_weights[0], axis = None).numpy()\n        \n        # sixth conv layer-\n        tf.math.count_nonzero(pruned_model.trainable_weights[10], axis = None).numpy()\n\n&amp;#x200B;\n\nThe weights have increased in numbers again. They should have been 133 and 5369, but they are not.\n\n&amp;#x200B;\n\nHelp?", "link": "https://www.reddit.com/r/neuralnetworks/comments/ng7wun/freeze_certain_weights_tensorflow_2/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "prune", "selectorShort": "prune", "MarkedSent": "freeze certain weights - tensorflow 2 /!/ i am using a conv-6 cnn in tensorflow 2.5 and python3. the objective is to selectively set certain weights within any trainable layer. the conv-6 cnn model definition is as follows:\n\n&amp;#x200b;\n\n        def conv6_cnn():\n            \"\"\"\n            function to define the architecture of a neural network model\n            following conv-6 architecture for cifar-10 dataset and using\n            provided parameter which are used to -----> prune !!!  the model.\n            \n            conv-6 architecture-\n            64, 64, pool  -- convolutional layers\n            128, 128, pool -- convolutional layers\n            256, 256, pool -- convolutional layers\n            256, 256, 10  -- fully connected layers\n            \n            output: returns designed and compiled neural network model\n            \"\"\"\n            \n            l = tf.keras.layers\n            \n            model = sequential()\n            \n            model.add(\n                conv2d(\n                    filters = 64, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.glorotnormal(),\n                    strides = (1, 1), padding = 'same',\n                    input_shape=(32, 32, 3)\n                )    \n            )\n                \n            model.add(\n                conv2d(\n                    filters = 64, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.glorotnormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n            \n            model.add(\n                maxpooling2d(\n                    pool_size = (2, 2),\n                    strides = (2, 2)\n                )\n            )\n            \n            model.add(\n                conv2d(\n                    filters = 128, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.glorotnormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n        \n            model.add(\n                conv2d(\n                    filters = 128, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.glorotnormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n        \n            model.add(\n                maxpooling2d(\n                    pool_size = (2, 2),\n                    strides = (2, 2)\n                )\n            )\n        \n            model.add(\n                conv2d(\n                    filters = 256, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.glorotnormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n        \n            model.add(\n                conv2d(\n                    filters = 256, kernel_size = (3, 3),\n                    activation='relu', kernel_initializer = tf.initializers.glorotnormal(),\n                    strides = (1, 1), padding = 'same'\n                )\n            )\n        \n            model.add(\n                maxpooling2d(\n                    pool_size = (2, 2),\n                    strides = (2, 2)\n                )\n            )\n            \n            model.add(flatten())\n            \n            model.add(\n                dense(\n                    units = 256, activation='relu',\n                    kernel_initializer = tf.initializers.glorotnormal()\n                )\n            )\n            \n            model.add(\n                dense(\n                    units = 256, activation='relu',\n                    kernel_initializer = tf.initializers.glorotnormal()\n                )\n            )\n            \n            model.add(\n                dense(\n                    units = 10, activation='softmax'\n                )\n            )\n            \n        \n            '''\n            # compile cnn-\n            model.compile(\n                loss=tf.keras.losses.categorical_crossentropy,\n                # optimizer='adam',\n                optimizer=tf.keras.optimizers.adam(learning_rate = 0.0003),\n                metrics=['accuracy']\n            )\n            '''\n            \n            \n            return model\n    \n    \n        # load trained model from before-\n        best_model = conv6_cnn()\n        best_model.load_weights(\"best_weights.h5\")\n\n&amp;#x200b;\n\ni came across [this](https://github.com/tensorflow/tensorflow/issues/6264) github answer of freezing certain weights during training. on it's basis, i coded the following to freeze weights in the first and sixth conv layers:\n\n&amp;#x200b;\n\n        conv1 = pruned_model.trainable_weights[0]\n        \n        # find all weights less than a threshold (0.1) and set them to zero-\n        conv1 = tf.where(conv1 &lt; 0.1, 0, conv1)\n        \n        # for all weights set to zero, stop training them-\n        conv1 = tf.where(conv1 == 0, tf.stop_gradient(conv1), conv1)\n        \n        \n        # sanity check: number of parameters set at 0-\n        tf.math.count_nonzero(conv1, axis = none).numpy()\n        # 133\n        \n        # original number of paramaters-\n        tf.math.count_nonzero(best_model.trainable_weights[0], axis = none).numpy()\n        # 1728\n        \n        # assign conv layer1 back to pruned model-\n        pruned_model.trainable_weights[0].assign(conv1)\n        \n        # sanity check-\n        tf.math.count_nonzero(pruned_model.trainable_weights[0], axis = none).numpy()\n        # 133\n        \n        # conv layer 6-\n        conv6 = pruned_model.trainable_weights[10]\n        \n        # find all weights less than a threshold (0.1) and set them to zero-\n        conv6 = tf.where(conv6 &lt; 0.1, 0, conv6)\n        \n        # for all weights set to zero, stop training them-\n        conv6 = tf.where(conv6 == 0, tf.stop_gradient(conv6), conv6)\n        \n        # sanity check: number of parameters set at 0-\n        tf.math.count_nonzero(conv6, axis = none).numpy()\n        # 5369\n        \n        # original number of paramaters-\n        tf.math.count_nonzero(best_model.trainable_weights[10], axis = none).numpy()\n        # 589824\n        \n        # assign conv layer6 back to pruned model-\n        pruned_model.trainable_weights[10].assign(conv6)\n        \n        # sanity check-\n        tf.math.count_nonzero(pruned_model.trainable_weights[10], axis = none).numpy()\n        # 5369\n        \n        \n        # train model for 10 epochs for testing:\n        \n        # compile cnn-\n        pruned_model.compile(\n            loss = tf.keras.losses.categoricalcrossentropy(from_logits=false),\n            optimizer=tf.keras.optimizers.adam(learning_rate = 0.01),\n            metrics=['accuracy']\n        )\n        \n        history = pruned_model.fit(\n            x = x_train, y = y_train,\n            epochs = 10, validation_data = (x_test, y_test)\n        )\n\nhowever, after training when i check the number of non-zero weights:\n\n&amp;#x200b;\n\n        # first conv layer-\n        tf.math.count_nonzero(pruned_model.trainable_weights[0], axis = none).numpy()\n        \n        # sixth conv layer-\n        tf.math.count_nonzero(pruned_model.trainable_weights[10], axis = none).numpy()\n\n&amp;#x200b;\n\nthe weights have increased in numbers again. they should have been 133 and 5369, but they are not.\n\n&amp;#x200b;\n\nhelp?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/ng7wun/freeze_certain_weights_tensorflow_2/',)", "identifyer": 5754881, "year": "2021"}, {"autor": "grid_world", "date": 1626850704000, "content": "Prune Neural Networks layers for f% sparsity - TensorFlow2 /!/ I am using TensorFlow 2.5 and Python3.8 where I have a simple TF2 CNN having one conv layer and an output layer for binary classification as follows:\n\n        num_filters = 32    \n        def cnn_model():\n                model = Sequential()\n                \n                model.add(\n                    InputLayer(input_shape = (32, 32, 3))\n                )\n                \n                model.add(\n                    Conv2D(\n                        filters = num_filters, kernel_size = (3, 3),\n                        activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n                        strides = (1, 1), padding = 'same',\n                        use_bias = True, \n                        bias_initializer = RandomNormal(mean = 0.0, stddev = 0.05)\n                        # kernel_regularizer = regularizers.l2(weight_decay)\n                    )\n                )\n                \n                model.add(Flatten())\n                \n                model.add(\n                    Dense(\n                        units = 1, activation = 'sigmoid'\n                    )\n                )\n                \n                return model\n    \n        \n        # I then instantiate two instances of it:\n    \n        model = cnn_model()\n        model2 = cnn_model()\n    \n        model.summary()\n        '''\n        Model: \"sequential_2\"\n        _________________________________________________________________\n        Layer (type)                 Output Shape              Param #   \n        =================================================================\n        conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n        _________________________________________________________________\n        flatten_2 (Flatten)          (None, 32768)             0         \n        _________________________________________________________________\n        dense_2 (Dense)              (None, 1)                 32769     \n        =================================================================\n        Total params: 33,665\n        Trainable params: 33,665\n        Non-trainable params: 0\n        '''\n    \n        def count_nonzero_params(model):\n            # Count number of non-zero parameters in each layer and in total-\n            model_sum_params = 0\n            \n            for layer in model.trainable_weights:\n                loc_param = tf.math.count_nonzero(layer, axis = None).numpy()\n                model_sum_params += loc_param\n            \n            # print(\"Total number of trainable parameters = {0}\\n\".format(model_sum_params))\n            \n            return model_sum_params\n    \n        # Sanity check-\n        count_nonzero_params(model)\n        # 33664\n\nA random input is used to make predictions using the two models-\n\n        x = tf.random.normal(shape = (5, 32, 32, 3))\n        pred = model(x)\n        pred2 = model2(x)\n        pred.shape, pred.shape\n        # (TensorShape([5, 1]), TensorShape([5, 1]))\n\nA pruning function has been defined to prune f% of smallest magnitude weights **for model1** *for each layer* such that:\n\n&gt;for connections in model, **only those connections are pruned** (per layer) **which are f% of smallest magnitude weights in both the models** viz., model and model2\n\n        def custom_pruning(model1, model2, p):\n            \"\"\"\n            Function to prune p% of smallest magnitude weights of \n            a given CNN model globally.\n            \n            Input:\n            model1            TF2 Convolutional Neural Network model\n            model2            TF2 Convolutional Neural Network model\n            \n                              \n            p                 Prune p% of smallest magnitude weights globally\n            \n            Output:\n            Returns a Python3 list containing layer-wise pruned weights.    \n            \"\"\"\n            \n            # Python3 list to hold weights of model1-\n            model1_np_wts = []\n            \n            for layer in model1.weights:\n                model1_np_wts.append(layer.numpy())\n            \n            # Python3 list to hold flattened weights-\n            flattened_wts = []\n        \n            for layer in model1_np_wts:\n                flattened_wts.append(np.abs(layer.flatten()))\n        \n            # Compute pth percentile threshold using all weights from model1-\n            threshold_weights1 = np.percentile(np.concatenate(flattened_wts), p)\n            \n            del flattened_wts\n            \n            \n            # Python3 list to hold weights of model2-\n            model2_np_wts = []\n        \n            for layer in model2.weights:\n                model2_np_wts.append(layer.numpy())\n        \n            # Python3 list to hold flattened weights for model2-\n            flattened_wts2 = []\n        \n            for layer in model2_np_wts:\n                flattened_wts2.append(np.abs(layer.flatten()))\n        \n            # Compute pth percentile threshold using all weights from model2-\n            threshold_weights2 = np.percentile(np.concatenate(flattened_wts2), p)\n            \n            del flattened_wts2\n            \n            \n            # Python3 list to contain pruned weights-\n            pruned_wts = []\n            \n            for layer_model1, layer_model2 in zip(model1_np_wts, model2_np_wts):\n                if len(layer_model1.shape) == 4:\n                    layer_wts_abs = np.abs(layer_model1)\n                    layer_wts2_abs = np.abs(layer_model2)\n                    layer_wts_abs[(layer_wts_abs &lt; threshold_weights1) &amp; (layer_wts2_abs &lt; threshold_weights2)] = 0\n                    layer_mod = np.where(layer_wts_abs == 0, 0, layer_model1)\n                    pruned_wts.append(layer_mod)\n                elif len(layer_model1.shape) == 2:\n                    layer_wts_abs = np.abs(layer_model1)\n                    layer_wts2_abs = np.abs(layer_model2)\n                    layer_wts_abs[(layer_wts_abs &lt; threshold_weights1) &amp; (layer_wts2_abs &lt; threshold_weights2)] = 0\n                    layer_mod = np.where(layer_wts_abs == 0, 0, layer_model1)\n                    pruned_wts.append(layer_mod)\n                else:\n                    pruned_wts.append(layer_model1)\n                \n                \n            return pruned_wts\n            \n    \n        # Prune 15% of smallest magnitude weights-\n        pruned_wts = custom_pruning(model1 = model, model2 = model2, p = 15)\n    \n        # Initialize and load weights for pruned model-\n        new_model = cnn_model()\n        new_model.set_weights(pruned_wts)\n        \n        # Count original and unpruned parameters-\n        orig_params = count_nonzero_params(model)\n        \n        # Count pruned parameters-\n        pruned_params = count_nonzero_params(new_model)\n        \n        # Compute actual sparsity-\n        sparsity = ((orig_params - pruned_params) / orig_params) * 100\n        \n        print(f\"actual sparsity = {sparsity:.2f}% for a given sparsity = 15%\")\n        # actual sparsity = 2.22% for a given sparsity = 15%\n\nThe problem is that for a given sparsity of 15%, only 2.22% connections are pruned. To achieve the desired 15% sparsity, a hit and trial method to find 'p' parameter's value-\n\n        # Prune 15% of smallest magnitude weights-\n        pruned_wts = custom_pruning(model1 = model, model2 = model2, p = 38)\n    \n        # Initialize and load weights for pruned model-\n        new_model = cnn_model()\n        new_model.set_weights(pruned_wts)\n        \n        # Count pruned parameters-\n        pruned_params = count_nonzero_params(new_model)\n        \n        # Compute actual sparsity-\n        sparsity = ((orig_params - pruned_params) / orig_params) * 100\n        \n        print(f\"actual sparsity = {sparsity:.2f}% for a given sparsity = 15%\")\n        # actual sparsity = 14.40% for a given sparsity = 15%\n\nDue to two conditions while filtering in 'custom\\_pruning()', this difference between desired and actual sparsity levels are occurring.\n\n&amp;#x200B;\n\nIs there some other better way to achieve this that I am missing out?\n\n&amp;#x200B;\n\nThanks!", "link": "https://www.reddit.com/r/neuralnetworks/comments/ookrvs/prune_neural_networks_layers_for_f_sparsity/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "prune", "selectorShort": "prune", "MarkedSent": "-----> prune !!!  neural networks layers for f% sparsity - tensorflow2 /!/ i am using tensorflow 2.5 and python3.8 where i have a simple tf2 cnn having one conv layer and an output layer for binary classification as follows:\n\n        num_filters = 32    \n        def cnn_model():\n                model = sequential()\n                \n                model.add(\n                    inputlayer(input_shape = (32, 32, 3))\n                )\n                \n                model.add(\n                    conv2d(\n                        filters = num_filters, kernel_size = (3, 3),\n                        activation = 'relu', kernel_initializer = tf.initializers.he_normal(),\n                        strides = (1, 1), padding = 'same',\n                        use_bias = true, \n                        bias_initializer = randomnormal(mean = 0.0, stddev = 0.05)\n                        # kernel_regularizer = regularizers.l2(weight_decay)\n                    )\n                )\n                \n                model.add(flatten())\n                \n                model.add(\n                    dense(\n                        units = 1, activation = 'sigmoid'\n                    )\n                )\n                \n                return model\n    \n        \n        # i then instantiate two instances of it:\n    \n        model = cnn_model()\n        model2 = cnn_model()\n    \n        model.summary()\n        '''\n        model: \"sequential_2\"\n        _________________________________________________________________\n        layer (type)                 output shape              param #   \n        =================================================================\n        conv2d_5 (conv2d)            (none, 32, 32, 32)        896       \n        _________________________________________________________________\n        flatten_2 (flatten)          (none, 32768)             0         \n        _________________________________________________________________\n        dense_2 (dense)              (none, 1)                 32769     \n        =================================================================\n        total params: 33,665\n        trainable params: 33,665\n        non-trainable params: 0\n        '''\n    \n        def count_nonzero_params(model):\n            # count number of non-zero parameters in each layer and in total-\n            model_sum_params = 0\n            \n            for layer in model.trainable_weights:\n                loc_param = tf.math.count_nonzero(layer, axis = none).numpy()\n                model_sum_params += loc_param\n            \n            # print(\"total number of trainable parameters = {0}\\n\".format(model_sum_params))\n            \n            return model_sum_params\n    \n        # sanity check-\n        count_nonzero_params(model)\n        # 33664\n\na random input is used to make predictions using the two models-\n\n        x = tf.random.normal(shape = (5, 32, 32, 3))\n        pred = model(x)\n        pred2 = model2(x)\n        pred.shape, pred.shape\n        # (tensorshape([5, 1]), tensorshape([5, 1]))\n\na pruning function has been defined to prune f% of smallest magnitude weights **for model1** *for each layer* such that:\n\n&gt;for connections in model, **only those connections are pruned** (per layer) **which are f% of smallest magnitude weights in both the models** viz., model and model2\n\n        def custom_pruning(model1, model2, p):\n            \"\"\"\n            function to prune p% of smallest magnitude weights of \n            a given cnn model globally.\n            \n            input:\n            model1            tf2 convolutional neural network model\n            model2            tf2 convolutional neural network model\n            \n                              \n            p                 prune p% of smallest magnitude weights globally\n            \n            output:\n            returns a python3 list containing layer-wise pruned weights.    \n            \"\"\"\n            \n            # python3 list to hold weights of model1-\n            model1_np_wts = []\n            \n            for layer in model1.weights:\n                model1_np_wts.append(layer.numpy())\n            \n            # python3 list to hold flattened weights-\n            flattened_wts = []\n        \n            for layer in model1_np_wts:\n                flattened_wts.append(np.abs(layer.flatten()))\n        \n            # compute pth percentile threshold using all weights from model1-\n            threshold_weights1 = np.percentile(np.concatenate(flattened_wts), p)\n            \n            del flattened_wts\n            \n            \n            # python3 list to hold weights of model2-\n            model2_np_wts = []\n        \n            for layer in model2.weights:\n                model2_np_wts.append(layer.numpy())\n        \n            # python3 list to hold flattened weights for model2-\n            flattened_wts2 = []\n        \n            for layer in model2_np_wts:\n                flattened_wts2.append(np.abs(layer.flatten()))\n        \n            # compute pth percentile threshold using all weights from model2-\n            threshold_weights2 = np.percentile(np.concatenate(flattened_wts2), p)\n            \n            del flattened_wts2\n            \n            \n            # python3 list to contain pruned weights-\n            pruned_wts = []\n            \n            for layer_model1, layer_model2 in zip(model1_np_wts, model2_np_wts):\n                if len(layer_model1.shape) == 4:\n                    layer_wts_abs = np.abs(layer_model1)\n                    layer_wts2_abs = np.abs(layer_model2)\n                    layer_wts_abs[(layer_wts_abs &lt; threshold_weights1) &amp; (layer_wts2_abs &lt; threshold_weights2)] = 0\n                    layer_mod = np.where(layer_wts_abs == 0, 0, layer_model1)\n                    pruned_wts.append(layer_mod)\n                elif len(layer_model1.shape) == 2:\n                    layer_wts_abs = np.abs(layer_model1)\n                    layer_wts2_abs = np.abs(layer_model2)\n                    layer_wts_abs[(layer_wts_abs &lt; threshold_weights1) &amp; (layer_wts2_abs &lt; threshold_weights2)] = 0\n                    layer_mod = np.where(layer_wts_abs == 0, 0, layer_model1)\n                    pruned_wts.append(layer_mod)\n                else:\n                    pruned_wts.append(layer_model1)\n                \n                \n            return pruned_wts\n            \n    \n        # prune 15% of smallest magnitude weights-\n        pruned_wts = custom_pruning(model1 = model, model2 = model2, p = 15)\n    \n        # initialize and load weights for pruned model-\n        new_model = cnn_model()\n        new_model.set_weights(pruned_wts)\n        \n        # count original and unpruned parameters-\n        orig_params = count_nonzero_params(model)\n        \n        # count pruned parameters-\n        pruned_params = count_nonzero_params(new_model)\n        \n        # compute actual sparsity-\n        sparsity = ((orig_params - pruned_params) / orig_params) * 100\n        \n        print(f\"actual sparsity = {sparsity:.2f}% for a given sparsity = 15%\")\n        # actual sparsity = 2.22% for a given sparsity = 15%\n\nthe problem is that for a given sparsity of 15%, only 2.22% connections are pruned. to achieve the desired 15% sparsity, a hit and trial method to find 'p' parameter's value-\n\n        # prune 15% of smallest magnitude weights-\n        pruned_wts = custom_pruning(model1 = model, model2 = model2, p = 38)\n    \n        # initialize and load weights for pruned model-\n        new_model = cnn_model()\n        new_model.set_weights(pruned_wts)\n        \n        # count pruned parameters-\n        pruned_params = count_nonzero_params(new_model)\n        \n        # compute actual sparsity-\n        sparsity = ((orig_params - pruned_params) / orig_params) * 100\n        \n        print(f\"actual sparsity = {sparsity:.2f}% for a given sparsity = 15%\")\n        # actual sparsity = 14.40% for a given sparsity = 15%\n\ndue to two conditions while filtering in 'custom\\_pruning()', this difference between desired and actual sparsity levels are occurring.\n\n&amp;#x200b;\n\nis there some other better way to achieve this that i am missing out?\n\n&amp;#x200b;\n\nthanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/ookrvs/prune_neural_networks_layers_for_f_sparsity/',)", "identifyer": 5755044, "year": "2021"}, {"autor": "markurtz", "date": 1628710356000, "content": "Tutorial: Prune and quantize YOLOv5 for 12x smaller size and 10x better performance on CPUs", "link": "https://www.reddit.com/r/neuralnetworks/comments/p2kap5/tutorial_prune_and_quantize_yolov5_for_12x/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "prune", "selectorShort": "prune", "MarkedSent": "tutorial: -----> prune !!!  and quantize yolov5 for 12x smaller size and 10x better performance on cpus", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('hosted:video',)", "medialink": "('https://v.redd.it/lw0hcy096sg71',)", "identifyer": 5755157, "year": "2021"}, {"autor": "gauravc2796", "date": 1632244651000, "content": "New Research Paper video Explainer: Block Pruning For Faster Transformers by Hugging Face /!/ Hi,\n\nA new research paper explainer has been released:\n\nBlock Pruning For Faster Transformers by Hugging Face [https://youtu.be/CyJdzkcdGl0](https://youtu.be/CyJdzkcdGl0)\n\nVideo explains the basics of pruning, distillation, paper overview, and also codes.\n\nTLDR:\n\n1. Large pre-trained NN to have billions of parameters to train. It is computationally expensive to load or download these models.\n2. Here comes pruning and distillation. Both of these techniques try to eliminate parameters (weights) with very little drop in accuracy.\n3. If we want to prune weights when finetuning our model, then movement pruning works best for that. However, the time and space requirements to train these models again to drop unnecessary could be expensive.\n4. Here comes block pruning where it creates square blocks in the weight matrix and then tries to perform movement pruning on the blocks rather than weights.\n\nFor an in-depth overview refer to the video explainer.\n\n&amp;#x200B;\n\nIf you like this content, do share it with friends and support the channel. If any opinions, clarifications, or anything you can mention in the comments.", "link": "https://www.reddit.com/r/neuralnetworks/comments/psnc87/new_research_paper_video_explainer_block_pruning/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "prune", "selectorShort": "prune", "MarkedSent": "new research paper video explainer: block pruning for faster transformers by hugging face /!/ hi,\n\na new research paper explainer has been released:\n\nblock pruning for faster transformers by hugging face [https://youtu.be/cyjdzkcdgl0](https://youtu.be/cyjdzkcdgl0)\n\nvideo explains the basics of pruning, distillation, paper overview, and also codes.\n\ntldr:\n\n1. large pre-trained nn to have billions of parameters to train. it is computationally expensive to load or download these models.\n2. here comes pruning and distillation. both of these techniques try to eliminate parameters (weights) with very little drop in accuracy.\n3. if we want to -----> prune !!!  weights when finetuning our model, then movement pruning works best for that. however, the time and space requirements to train these models again to drop unnecessary could be expensive.\n4. here comes block pruning where it creates square blocks in the weight matrix and then tries to perform movement pruning on the blocks rather than weights.\n\nfor an in-depth overview refer to the video explainer.\n\n&amp;#x200b;\n\nif you like this content, do share it with friends and support the channel. if any opinions, clarifications, or anything you can mention in the comments.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/psnc87/new_research_paper_video_explainer_block_pruning/',)", "identifyer": 5755203, "year": "2021"}], "name": "pruneneuralnetworks2021"}