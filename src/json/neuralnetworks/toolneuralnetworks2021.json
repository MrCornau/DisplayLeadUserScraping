{"interestingcomments": [{"autor": "binaryfor", "date": 1617031106000, "content": "deep-daze: Simple command line tool for text to image generation using OpenAI's CLIP and Siren (Implicit neural representation network)", "link": "https://www.reddit.com/r/neuralnetworks/comments/mfrtrj/deepdaze_simple_command_line_tool_for_text_to/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "deep-daze: simple command line -----> tool !!!  for text to image generation using openai's clip and siren (implicit neural representation network)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://github.com/lucidrains/deep-daze',)", "identifyer": 5754519, "year": "2021"}, {"autor": "bernatfp", "date": 1611829970000, "content": "Tool for Complex Data Labelling Tasks /!/ Hi r/neuralnetworks readers!\n\nWe have created a [labelling tool](https://humanlambdas.com/solutions/data-labelling) that can be customized to display all sorts of data models and tasks. Here are a couple of examples for [NLP](https://humanlambdas.com/templates/nlp-news-article-annotation) and [CV](https://humanlambdas.com/templates/computer-vision-annotation).\n\nI hope some of you will find this useful, and if you have any thoughts I would love to hear your feedback!", "link": "https://www.reddit.com/r/neuralnetworks/comments/l6tlme/tool_for_complex_data_labelling_tasks/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "-----> tool !!!  for complex data labelling tasks /!/ hi r/neuralnetworks readers!\n\nwe have created a [labelling tool](https://humanlambdas.com/solutions/data-labelling) that can be customized to display all sorts of data models and tasks. here are a couple of examples for [nlp](https://humanlambdas.com/templates/nlp-news-article-annotation) and [cv](https://humanlambdas.com/templates/computer-vision-annotation).\n\ni hope some of you will find this useful, and if you have any thoughts i would love to hear your feedback!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/l6tlme/tool_for_complex_data_labelling_tasks/',)", "identifyer": 5754579, "year": "2021"}, {"autor": "LordJasonK", "date": 1611602224000, "content": "Need help on how to create a learning neural network on my trading tool.. /!/ [removed]", "link": "https://www.reddit.com/r/neuralnetworks/comments/l4v4bq/need_help_on_how_to_create_a_learning_neural/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "need help on how to create a learning neural network on my trading -----> tool !!! .. /!/ [removed]", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/l4v4bq/need_help_on_how_to_create_a_learning_neural/',)", "identifyer": 5754589, "year": "2021"}, {"autor": "cmillionaire9", "date": 1611314105000, "content": "Exploring the Latent Space of Cats (Link to Tool In Description)", "link": "https://www.reddit.com/r/neuralnetworks/comments/l2lng1/exploring_the_latent_space_of_cats_link_to_tool/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "exploring the latent space of cats (link to -----> tool !!!  in description)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('rich:video',)", "medialink": "('https://youtu.be/9m7U2MSKyzc',)", "identifyer": 5754602, "year": "2021"}, {"autor": "Togfox", "date": 1614248986000, "content": "My first foray into neural networks /!/ I've read about a dozen articles on how a NN works. 2 inputs. An optional bias. One output. Hidden layers. Activation function etc but every article so far fails to explain what the inputs are, how they are determined and why a sigmoid function that results in a 0/1 could be remotely valuable.\n\nI have a very fundamental question that demonstrates my lack of even basic understanding and I think I'm trying to, perhaps, use the wrong tool to solve my problem:\n\nHow do I transform a range of possible real world actions my agent can take into a normalised input layer? If my agent has the following options:\n\n- wake up when the alarm sounds\n\n- sleep in q minutes after the alarm sounds\n\n- wake up w minutes before the alarm\n\nand then get rewarded (i.e. reduced error) when the bot is:\n\n- not late and misses the bus\n\n- not excessively early at the bus stop\n\n\nHow do I take those inputs (lets say it's a time range of fine number of minutes) and turn that into a suitable input layer?\n\n: great to see the down vote already. Reddit never fails the noobs /s;", "link": "https://www.reddit.com/r/neuralnetworks/comments/ls3mqb/my_first_foray_into_neural_networks/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "my first foray into neural networks /!/ i've read about a dozen articles on how a nn works. 2 inputs. an optional bias. one output. hidden layers. activation function etc but every article so far fails to explain what the inputs are, how they are determined and why a sigmoid function that results in a 0/1 could be remotely valuable.\n\ni have a very fundamental question that demonstrates my lack of even basic understanding and i think i'm trying to, perhaps, use the wrong -----> tool !!!  to solve my problem:\n\nhow do i transform a range of possible real world actions my agent can take into a normalised input layer? if my agent has the following options:\n\n- wake up when the alarm sounds\n\n- sleep in q minutes after the alarm sounds\n\n- wake up w minutes before the alarm\n\nand then get rewarded (i.e. reduced error) when the bot is:\n\n- not late and misses the bus\n\n- not excessively early at the bus stop\n\n\nhow do i take those inputs (lets say it's a time range of fine number of minutes) and turn that into a suitable input layer?\n\n: great to see the down vote already. reddit never fails the noobs /s;", "sortedWord": "None", "removed": "('nan',)", "score": 8, "comments": 10, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/ls3mqb/my_first_foray_into_neural_networks/',)", "identifyer": 5754679, "year": "2021"}, {"autor": "hoti0101", "date": 1619056913000, "content": "Just started to dip my toes in the water. I have a project ave want to know if a neural network would be a good tool to solve this problem /!/ I want to find a way to read text from labels. The labels are mostly standardized, maybe 10-12ish variations. Each variation should have standardized text attributes in set locations I\u2019d like to extract and validate against a database. In total there are probably 5 sections of text I\u2019d like to pull out of the image. \n\nWould a neural network be a good way to solve this problem? Or would a simpler OCR algorithm be better? \n\nKnowing absolutely nothing about neural nets. I\u2019m my head I see it working as follows. Find binding edges of the label. Identify which label variation is in the image. Identify text in specific locations for that label variation. Store output in a table/database. \n\nPlease let me know if I\u2019m approaching the problem wrong. Ideally I\u2019d like a solution that can scale and avoid having to manually document the label attributes.", "link": "https://www.reddit.com/r/neuralnetworks/comments/mvuwxg/just_started_to_dip_my_toes_in_the_water_i_have_a/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "just started to dip my toes in the water. i have a project ave want to know if a neural network would be a good -----> tool !!!  to solve this problem /!/ i want to find a way to read text from labels. the labels are mostly standardized, maybe 10-12ish variations. each variation should have standardized text attributes in set locations i\u2019d like to extract and validate against a database. in total there are probably 5 sections of text i\u2019d like to pull out of the image. \n\nwould a neural network be a good way to solve this problem? or would a simpler ocr algorithm be better? \n\nknowing absolutely nothing about neural nets. i\u2019m my head i see it working as follows. find binding edges of the label. identify which label variation is in the image. identify text in specific locations for that label variation. store output in a table/database. \n\nplease let me know if i\u2019m approaching the problem wrong. ideally i\u2019d like a solution that can scale and avoid having to manually document the label attributes.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/mvuwxg/just_started_to_dip_my_toes_in_the_water_i_have_a/',)", "identifyer": 5754781, "year": "2021"}, {"autor": "prakhar21", "date": 1620746287000, "content": "Explanability for Transformers with Transformers-Interpret \u2014 A Model Explainability Tool", "link": "https://www.reddit.com/r/neuralnetworks/comments/n9zeei/explanability_for_transformers_with/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "explanability for transformers with transformers-interpret \u2014 a model explainability -----> tool !!! ", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://link.medium.com/Hu616O0Tagb',)", "identifyer": 5754902, "year": "2021"}, {"autor": "riverofsky", "date": 1620459099000, "content": "Is there any tool which can be used to train/make a neural net on excel/tabular data? /!/ Data is stored in Excel. I don't know much about neural networks. Please help", "link": "https://www.reddit.com/r/neuralnetworks/comments/n7jxmb/is_there_any_tool_which_can_be_used_to_trainmake/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "is there any -----> tool !!!  which can be used to train/make a neural net on excel/tabular data? /!/ data is stored in excel. i don't know much about neural networks. please help", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 6, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/n7jxmb/is_there_any_tool_which_can_be_used_to_trainmake/',)", "identifyer": 5754914, "year": "2021"}, {"autor": "rshpkamil", "date": 1624647974000, "content": "Nvidia\u2019s Canvas AI painting tool instantly turns blobs into realistic landscapes /!/ Original article: [https://blogs.nvidia.com/blog/2021/06/23/studio-canvas-app/](https://blogs.nvidia.com/blog/2021/06/23/studio-canvas-app/)\n\n&amp;#x200B;\n\nMore similar articles related to AI &amp; Data Science [here](https://thereshape.co/join?utm_source=reddit_nn_4).", "link": "https://www.reddit.com/r/neuralnetworks/comments/o7u8z4/nvidias_canvas_ai_painting_tool_instantly_turns/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "nvidia\u2019s canvas ai painting -----> tool !!!  instantly turns blobs into realistic landscapes /!/ original article: [https://blogs.nvidia.com/blog/2021/06/23/studio-canvas-app/](https://blogs.nvidia.com/blog/2021/06/23/studio-canvas-app/)\n\n&amp;#x200b;\n\nmore similar articles related to ai &amp; data science [here](https://thereshape.co/join?utm_source=reddit_nn_4).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/o7u8z4/nvidias_canvas_ai_painting_tool_instantly_turns/',)", "identifyer": 5754956, "year": "2021"}, {"autor": "techsucker", "date": 1629654961000, "content": "Researchers from Skoltech and KU Leuven Employ Deep Learning to Augment 3D Micro-CT Images of Fibrous Materials Using Neural Networks /!/ Researchers from KU Leuven and Skoltech utilized machine learning to help recreate three-dimensional micro-CT images of fibrous materials. This task, which is essential for sophisticated material analysis, is complex and time-consuming for humans. This research work was published in\u00a0[Computational Materials Science Journal](https://www.sciencedirect.com/science/article/abs/pii/S0927025621002780?via%3Dihub).\n\nMicro-computed tomography is incredibly helpful for studying the 3D microstructure of fiber-reinforced composites and other complex materials. It is, however, a picky tool: samples are small, and photos frequently contain abnormalities such as darkened, missing, or damaged regions. Researchers took inspiration and knowledge from the art industry to help them deal with this, where damaged artworks must be restored while maintaining their overall integrity. As a result, inpainting has become a standard digital image processing technique.\n\n[3 Min Read](https://www.marktechpost.com/2021/08/22/researchers-from-skoltech-and-ku-leuven-employ-deep-learning-to-augment-3d-micro-ct-images-of-fibrous-materials-using-neural-networks/) | [Paper](https://www.sciencedirect.com/science/article/abs/pii/S0927025621002780?via%3Dihub)", "link": "https://www.reddit.com/r/neuralnetworks/comments/p9haex/researchers_from_skoltech_and_ku_leuven_employ/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "researchers from skoltech and ku leuven employ deep learning to augment 3d micro-ct images of fibrous materials using neural networks /!/ researchers from ku leuven and skoltech utilized machine learning to help recreate three-dimensional micro-ct images of fibrous materials. this task, which is essential for sophisticated material analysis, is complex and time-consuming for humans. this research work was published in\u00a0[computational materials science journal](https://www.sciencedirect.com/science/article/abs/pii/s0927025621002780?via%3dihub).\n\nmicro-computed tomography is incredibly helpful for studying the 3d microstructure of fiber-reinforced composites and other complex materials. it is, however, a picky -----> tool !!! : samples are small, and photos frequently contain abnormalities such as darkened, missing, or damaged regions. researchers took inspiration and knowledge from the art industry to help them deal with this, where damaged artworks must be restored while maintaining their overall integrity. as a result, inpainting has become a standard digital image processing technique.\n\n[3 min read](https://www.marktechpost.com/2021/08/22/researchers-from-skoltech-and-ku-leuven-employ-deep-learning-to-augment-3d-micro-ct-images-of-fibrous-materials-using-neural-networks/) | [paper](https://www.sciencedirect.com/science/article/abs/pii/s0927025621002780?via%3dihub)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/p9haex/researchers_from_skoltech_and_ku_leuven_employ/',)", "identifyer": 5755128, "year": "2021"}, {"autor": "techsucker", "date": 1629276815000, "content": "Researchers from Baidu, Nanjing and Rutgers University Propose \u2018Paint Transformer\u2019 Tool To Predict The Parameters Of A Stroke Set With A Feed Forward Network /!/ Painting has been an excellent way for people to record what they perceive or even how they imagine about the world. It\u2019s long been known that painting requires professional knowledge/skills and is not easy for ordinary people, but with computer-aided art creation, many of us can create our own artistic compositions. With the AI era coming upon us in no time at all, natural images can be transformed into artwork via image style transfer or image-to use translation\u2013and you don\u2019t have to know as much about it either.\n\nInspired by a recent object detector DETR, researchers from Baidu, Nanjing University and Rutgers University propose this novel [\u2018Paint Transformer\u2019](https://github.com/wzmsltw/PaintTransformer) to generate painting via predicting parameters of multiple strokes with a feed-forward Transformer. Unlike object detection, stroke predictor lacks annotated data. That\u2019s why researchers came up with a novel self-training pipeline that utilizes synthetically generated images, which is an original and creative idea.\n\n[4 Min Read](https://www.marktechpost.com/2021/08/18/researchers-from-baidu-nanjing-and-rutgers-university-propose-paint-transformer-tool-to-predict-the-parameters-of-a-stroke-set-with-a-feed-forward-network/) | [Paper](https://arxiv.org/pdf/2108.03798.pdf) | [Github](https://github.com/wzmsltw/PaintTransformer)\n\n&amp;#x200B;\n\nhttps://i.redd.it/oi1bs40yy2i71.gif", "link": "https://www.reddit.com/r/neuralnetworks/comments/p6nc1q/researchers_from_baidu_nanjing_and_rutgers/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "researchers from baidu, nanjing and rutgers university propose \u2018paint transformer\u2019 -----> tool !!!  to predict the parameters of a stroke set with a feed forward network /!/ painting has been an excellent way for people to record what they perceive or even how they imagine about the world. it\u2019s long been known that painting requires professional knowledge/skills and is not easy for ordinary people, but with computer-aided art creation, many of us can create our own artistic compositions. with the ai era coming upon us in no time at all, natural images can be transformed into artwork via image style transfer or image-to use translation\u2013and you don\u2019t have to know as much about it either.\n\ninspired by a recent object detector detr, researchers from baidu, nanjing university and rutgers university propose this novel [\u2018paint transformer\u2019](https://github.com/wzmsltw/painttransformer) to generate painting via predicting parameters of multiple strokes with a feed-forward transformer. unlike object detection, stroke predictor lacks annotated data. that\u2019s why researchers came up with a novel self-training pipeline that utilizes synthetically generated images, which is an original and creative idea.\n\n[4 min read](https://www.marktechpost.com/2021/08/18/researchers-from-baidu-nanjing-and-rutgers-university-propose-paint-transformer-tool-to-predict-the-parameters-of-a-stroke-set-with-a-feed-forward-network/) | [paper](https://arxiv.org/pdf/2108.03798.pdf) | [github](https://github.com/wzmsltw/painttransformer)\n\n&amp;#x200b;\n\nhttps://i.redd.it/oi1bs40yy2i71.gif", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/p6nc1q/researchers_from_baidu_nanjing_and_rutgers/',)", "identifyer": 5755139, "year": "2021"}, {"autor": "RileyStang", "date": 1632099924000, "content": "Looking for help with TensorflowJS based midi pattern generation project /!/ Firstly, here's a demo video of the original software generating midi drum patterns based on input from another midi or audio file: [https://youtu.be/eYUaYzfZUCo](https://youtu.be/eYUaYzfZUCo)\n\nTo further explain what is happening: A Google research team had several professional drummers come in to play on electronic drum kits that turn their performances into midi files. They then trained a neural network with Tensorflow on over 14 hours of drum midis played by professional drummers. This is what creates such profound results as seen in the above video. And I have used this myself and found that if you repeatedly give it the same input, it will give nearly the same output, only with very slight variations, as I would expect from a real drummer that is improvising.\n\nFor further details on this project from the Google research team that started it, go here: [https://magenta.tensorflow.org/studio-announce](https://magenta.tensorflow.org/studio-announce)\n\nMy overall goal is to create a fork of this software that has Drumify with a model that is trained on my data-set of midi drum files. So far the furthest I've gotten is a MatMul error, after following one of the repo contributor's instructions that he gave me. It was not without many other issues, like being unable to rebuild natively on Windows, and having to do it through the Windows Subsystem for Linux to get further. I will link here to the issue that has more detailed information. This seems like an old, seemingly abandoned project, and the people who worked on it are probably busy trying to attend to their job responsibilities so they can stay financially afloat. I just figured I would try this avenue for more assistance since I see a lot of potential in this project when artists can control the output of the plugins through training their models with the data of their choice.\n\nI'm here to have a tool that is useful to other musicians to streamline their creative workflow, without stifling their style of expression. So, anyone that helps, their contribution will be forever made known to the world.\n\nHere is the link to the issue I've created on the repo for more detailed information: [https://github.com/magenta/magenta-studio/issues/54](https://github.com/magenta/magenta-studio/issues/54)\n\nThank you for taking the time to read!", "link": "https://www.reddit.com/r/neuralnetworks/comments/prkiol/looking_for_help_with_tensorflowjs_based_midi/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "looking for help with tensorflowjs based midi pattern generation project /!/ firstly, here's a demo video of the original software generating midi drum patterns based on input from another midi or audio file: [https://youtu.be/eyuayzfzuco](https://youtu.be/eyuayzfzuco)\n\nto further explain what is happening: a google research team had several professional drummers come in to play on electronic drum kits that turn their performances into midi files. they then trained a neural network with tensorflow on over 14 hours of drum midis played by professional drummers. this is what creates such profound results as seen in the above video. and i have used this myself and found that if you repeatedly give it the same input, it will give nearly the same output, only with very slight variations, as i would expect from a real drummer that is improvising.\n\nfor further details on this project from the google research team that started it, go here: [https://magenta.tensorflow.org/studio-announce](https://magenta.tensorflow.org/studio-announce)\n\nmy overall goal is to create a fork of this software that has drumify with a model that is trained on my data-set of midi drum files. so far the furthest i've gotten is a matmul error, after following one of the repo contributor's instructions that he gave me. it was not without many other issues, like being unable to rebuild natively on windows, and having to do it through the windows subsystem for linux to get further. i will link here to the issue that has more detailed information. this seems like an old, seemingly abandoned project, and the people who worked on it are probably busy trying to attend to their job responsibilities so they can stay financially afloat. i just figured i would try this avenue for more assistance since i see a lot of potential in this project when artists can control the output of the plugins through training their models with the data of their choice.\n\ni'm here to have a -----> tool !!!  that is useful to other musicians to streamline their creative workflow, without stifling their style of expression. so, anyone that helps, their contribution will be forever made known to the world.\n\nhere is the link to the issue i've created on the repo for more detailed information: [https://github.com/magenta/magenta-studio/issues/54](https://github.com/magenta/magenta-studio/issues/54)\n\nthank you for taking the time to read!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('self',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/prkiol/looking_for_help_with_tensorflowjs_based_midi/',)", "identifyer": 5755208, "year": "2021"}, {"autor": "emadboctor", "date": 1630952763000, "content": "xagents: deep reinforcement learning command line tool box /!/ &amp;#x200B;\n\n[xagents-features](https://i.redd.it/vhygerp5exl71.gif)\n\nXagents is a command line tool box that provides 7 deep reinforcement learning algorithms, implemented in tensorflow 2.x and optimized for performance.\n\n## Features\n\n* Supported on all platforms mac, linux, windows.\n* Algorithms: A2C, ACER, DDPG, DQN, PPO, TD3, TRPO.\n* Multiple environments (All agents).\n* 3 commands available (train, tune, play).\n* Early stopping / reduce on plateau.\n* Discrete and continuous action spaces.\n* Unit tests.\n* Keras models are loaded from .cfg files.\n* Training history checkpoints.\n* Reproducible results.\n* Resumable training and history.\n\n## How to\n\n* Project [page](https://github.com/schissmantics/xagents)\n* Feature walkthrough/tutorial jupyter [notebook](https://github.com/schissmantics/xagents/blob/main/walkthrough.ipynb)", "link": "https://www.reddit.com/r/neuralnetworks/comments/pj59sc/xagents_deep_reinforcement_learning_command_line/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "xagents: deep reinforcement learning command line -----> tool !!!  box /!/ &amp;#x200b;\n\n[xagents-features](https://i.redd.it/vhygerp5exl71.gif)\n\nxagents is a command line -----> tool !!!  box that provides 7 deep reinforcement learning algorithms, implemented in tensorflow 2.x and optimized for performance.\n\n## features\n\n* supported on all platforms mac, linux, windows.\n* algorithms: a2c, acer, ddpg, dqn, ppo, td3, trpo.\n* multiple environments (all agents).\n* 3 commands available (train, tune, play).\n* early stopping / reduce on plateau.\n* discrete and continuous action spaces.\n* unit tests.\n* keras models are loaded from .cfg files.\n* training history checkpoints.\n* reproducible results.\n* resumable training and history.\n\n## how to\n\n* project [page](https://github.com/schissmantics/xagents)\n* feature walkthrough/tutorial jupyter [notebook](https://github.com/schissmantics/xagents/blob/main/walkthrough.ipynb)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/pj59sc/xagents_deep_reinforcement_learning_command_line/',)", "identifyer": 5755244, "year": "2021"}], "name": "toolneuralnetworks2021"}