{"interestingcomments": [{"autor": "hellopaperspace", "date": 1615837599000, "content": "[Article] Breakdown of MobileNeXT (ECCV 2020) /!/ There have been various channels of research looking into efficient neural networks, ranging from Binary Neural Networks and Efficient Networks to component-based research like PyConv and Depthwise Convolution Layers. One work that has stood the test of time is the collection of MobileNet models, which include [MobileNet](https://arxiv.org/abs/1704.04861), [MobileNetV2](https://arxiv.org/abs/1801.04381), and [MobileNetV3](https://arxiv.org/abs/1905.02244).\n\nThis article dives into a recent advancement to the MobileNet range of models, namely **MobileNeXt**, which was published at ECCV 2020. Topics covered include:\n\n* Bottleneck Structures (Main Branch, Residual Connection, and Inverted Residual Connections)\n* MobileNeXt (SandGlass Block, PyTorch Code)\n* Results (ImageNet Classification, Object Detection on PASCAL VOC)\n* Shortcomings and Further Comments\n\nArticle link: [https://blog.paperspace.com/mobilenext-eccv-2020/](https://blog.paperspace.com/mobilenext-eccv-2020/)\n\nComments and discussion welcome!", "link": "https://www.reddit.com/r/neuralnetworks/comments/m5t4dx/article_breakdown_of_mobilenext_eccv_2020/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "[article] breakdown of mobilenext (eccv 2020) /!/ there have been various channels of research looking into efficient neural networks, ranging from binary neural networks and efficient networks to component-based research like pyconv and depthwise convolution layers. one work that has stood the test of time is the collection of mobilenet models, which include [mobilenet](https://arxiv.org/abs/1704.04861), [mobilenetv2](https://arxiv.org/abs/1801.04381), and [mobilenetv3](https://arxiv.org/abs/1905.02244).\n\nthis article dives into a recent advancement to the mobilenet range of models, namely **mobilenext**, which was published at eccv 2020. topics covered include:\n\n* bottleneck structures (main -----> branch !!! , residual connection, and inverted residual connections)\n* mobilenext (sandglass block, pytorch code)\n* results (imagenet classification, object detection on pascal voc)\n* shortcomings and further comments\n\narticle link: [https://blog.paperspace.com/mobilenext-eccv-2020/](https://blog.paperspace.com/mobilenext-eccv-2020/)\n\ncomments and discussion welcome!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/m5t4dx/article_breakdown_of_mobilenext_eccv_2020/',)", "identifyer": 5754533, "year": "2021"}, {"autor": "m1900kang2", "date": 1621300112000, "content": "[R] Editing Conditional Radiance Fields /!/ This paper by researchers from MIT CSAIL, Adobe Research, and Carnegie Mellon introduces a method for propagating coarse 2D user scribbles to the 3D space, to modify the color or shape of a local region with NeRF. \n\n\\[[5-Min Paper Presentation](https://crossminds.ai/video/editing-conditional-radiance-fields-609ed58f442aca4efd150ef0/)\\] \\[[arXiv Link](https://arxiv.org/abs/2105.06466)\\] \\[[Project Link](http://editnerf.csail.mit.edu/)\\]\n\n**Abstract:** A neural radiance field (NeRF) is a scene model supporting high-quality view synthesis, optimized per scene. In this paper, we explore enabling user editing of a category-level NeRF - also known as a conditional radiance field - trained on a shape category. Specifically, we introduce a method for propagating coarse 2D user scribbles to the 3D space, to modify the color or shape of a local region. First, we propose a conditional radiance field that incorporates new modular network components, including a shape branch that is shared across object instances. Observing multiple instances of the same category, our model learns underlying part semantics without any supervision, thereby allowing the propagation of coarse 2D user scribbles to the entire 3D region (e.g., chair seat). Next, we propose a hybrid network update strategy that targets specific network components, which balances efficiency and accuracy. During user interaction, we formulate an optimization problem that both satisfies the user's constraints and preserves the original object structure. We demonstrate our approach on various editing tasks over three shape datasets and show that it outperforms prior neural editing approaches. Finally, we edit the appearance and shape of a real photograph and show that the edit propagates to extrapolated novel views\n\n&amp;#x200B;\n\n[Example of the work](https://preview.redd.it/06cyl5p24sz61.png?width=762&amp;format=png&amp;auto=webp&amp;s=d920cae57092a955c52a0d4c8c35282fac8e82d6)\n\n**Authors:** Steven Liu, Xiuming Zhang, Zhoutong Zhang, Richard Zhang, Jun-Yan Zhu, Bryan Russell (Adobe Research, MIT, CMU)", "link": "https://www.reddit.com/r/neuralnetworks/comments/nex7lf/r_editing_conditional_radiance_fields/", "origin": "Reddit", "suborigin": "neuralnetworks", "result": true, "Selector": "branch", "selectorShort": "branch", "MarkedSent": "[r] editing conditional radiance fields /!/ this paper by researchers from mit csail, adobe research, and carnegie mellon introduces a method for propagating coarse 2d user scribbles to the 3d space, to modify the color or shape of a local region with nerf. \n\n\\[[5-min paper presentation](https://crossminds.ai/video/editing-conditional-radiance-fields-609ed58f442aca4efd150ef0/)\\] \\[[arxiv link](https://arxiv.org/abs/2105.06466)\\] \\[[project link](http://editnerf.csail.mit.edu/)\\]\n\n**abstract:** a neural radiance field (nerf) is a scene model supporting high-quality view synthesis, optimized per scene. in this paper, we explore enabling user editing of a category-level nerf - also known as a conditional radiance field - trained on a shape category. specifically, we introduce a method for propagating coarse 2d user scribbles to the 3d space, to modify the color or shape of a local region. first, we propose a conditional radiance field that incorporates new modular network components, including a shape -----> branch !!!  that is shared across object instances. observing multiple instances of the same category, our model learns underlying part semantics without any supervision, thereby allowing the propagation of coarse 2d user scribbles to the entire 3d region (e.g., chair seat). next, we propose a hybrid network update strategy that targets specific network components, which balances efficiency and accuracy. during user interaction, we formulate an optimization problem that both satisfies the user's constraints and preserves the original object structure. we demonstrate our approach on various editing tasks over three shape datasets and show that it outperforms prior neural editing approaches. finally, we edit the appearance and shape of a real photograph and show that the edit propagates to extrapolated novel views\n\n&amp;#x200b;\n\n[example of the work](https://preview.redd.it/06cyl5p24sz61.png?width=762&amp;format=png&amp;auto=webp&amp;s=d920cae57092a955c52a0d4c8c35282fac8e82d6)\n\n**authors:** steven liu, xiuming zhang, zhoutong zhang, richard zhang, jun-yan zhu, bryan russell (adobe research, mit, cmu)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/neuralnetworks/comments/nex7lf/r_editing_conditional_radiance_fields/',)", "identifyer": 5754888, "year": "2021"}], "name": "branchneuralnetworks2021"}