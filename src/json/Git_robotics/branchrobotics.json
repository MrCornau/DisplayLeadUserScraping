{"interestingcomments": [{"Unnamed: 0": 1270, "autor": 250, "date": null, "content": "IHMC Open Robotics Software\nCompile: Test (3000+ tests):\n<-- Download from Bintray\nTested Platforms\nRobots\nAtlas\nValkyrie\nDevelopers\nWe test all of our software on OSX, Windows, and Ubuntu. It is likely to work on other platforms but not necessarily tested.\nBranches\nThis repository uses the git-flow branching model. You can find more about git-flow here.\nLicensing\nAll of the software in IHMC Open Robotics Software is licensed under the Apache 2.0 license.\nGetting Started\nUsing IHMC Open Robotics Software .jar releases with Maven/Gradle\nThe release .jars for the various IHMC Open Robotics Software packages are hosted on Bintray. You can browse the release packages at https://bintray.com/ihmcrobotics/maven-release. Instructions for adding the Maven repository and identifying the artifacts can also be found on Bintray for each package.\nAt a minimum, you will need to have the following repositories declared in your build script to use IHMC Open Robotics Software .jars:\nrepositories {\nmaven {\nurl \"https://dl.bintray.com/ihmcrobotics/maven-release\" // IHMC Code releases\n}\nmaven {\nurl \"https://dl.bintray.com/ihmcrobotics/maven-vendor\" // Third-party libraries that we have vendored for various reasons\n}\n/* You will also need to add either jcenter() or mavenCentral() or both, depending on your preference */\n}\nDeveloping with IHMC Open Robotics Software from source\nRequirements\nIHMC Open Robotics Software uses the Gradle build system, and requires JDK 8 with JavaFX. We also strongly suggest an IDE, either Eclipse or IntelliJ (Ultimate or Community is fine). Currently, we require Gradle 4.10+.\nInstalling Gradle: https://gradle.org/install/\nCompanion Software\nOther IHMC Libraries\nIHMC Open Robotics Software both depends on and is depended on by many other IHMC Robotics Libraries. A small sampling of our other software includes:\nSimulation Construction Set, our own simulation environment with built-in analysis tools: https://github.com/ihmcrobotics/simulation-construction-set\nEuclid, an alternative vector/geometry library for Java with support for additional structures common in 3D geometry without needing vecmath or Java3D: https://github.com/ihmcrobotics/euclid\nMecano, a rigid-body dynamics library built on top of Euclid and EJML: https://github.com/ihmcrobotics/mecano\nIHMC YoVariables, our core data structures tools that enable the time-series tracing and analysis of Simulation Construction Set: https://github.com/ihmcrobotics/ihmc-yovariables\nJOctoMap, a Java implementation of OctoMap: https://github.com/ihmcrobotics/joctomap\nIHMC Realtime, a library for enabling soft real-time threading for Java on Linux using the RT_PREEMPT patches: https://github.com/ihmcrobotics/ihmc-realtime\nIHMC EtherCAT Master, a Java library using IHMC Realtime and Simple Open EtherCAT Master (SOEM) that makes it simple to start a software EtherCAT Master and pure Java data structures that map to EtherCAT Slave defintions: https://github.com/ihmcrobotics/ihmc-ethercat-master\nYou can find all of our other repositories as well as the ones above at https://github.com/ihmcrobotics\nROS API's\nWe provide a native ROS 2 API for many of the core components in our software stack. You can find the .msg definitions for use in your own projects here: https://github.com/ihmcrobotics/ihmc_interfaces\nWe have ROS 1 support via the ROS 2 ros1_bridge package. You can find the ROS 1 message definitions and instructions on using the ROS 1 Bridge here: https://github.com/ihmcrobotics/ihmc_msgs\nIDE Support\nOur Gradle models are tested in IntelliJ IDEA 2018 (both Community and Ultimate) with the Gradle plugin. Eclipse 2018.09+ or higher with the Buildship plugin. The Buildship plugin is bundled with the Eclipse IDE for Java Developers (but not Java EE Developers). It can always be manually installed to any version of Eclipse using the installation instructions.\nBuilding .jars\nIHMC Open Robotics Software is pre-configured for generating Maven publications. You can publish directly from the source code right in to your local Maven repository, e.g. the $HOME/.m2 directory. These builds will be tagged with a build \"version\" of \"LOCAL\" instead of an incrementing version number.\nAn example workflow for developing against a local clone of the software:\nClone IHMC Open Robotics Software\nMake modifications\nPublish to your local $HOME/.m2 repository\nTo publish jars to your local Maven repository:\n$ cd /path/to/ihmc-open-robotics-software\n$ gradle publishAll -PcompositeSearchHeight=0\nTo depend on the jars in your local Maven repository:\nIn this example we'll have a compile-time dependency of the locally built Simulation Construction Set project. In the build.gradle of the project you wish to have link against Simulation Construction Set:\nrepositories {\nmavenLocal()\n<your other repositories>\n}\ndependencies {\ncompile group: \"us.ihmc\", name: \"simulation-construction-set\", version: \"LOCAL\", changing: true\n}\nCreating a project\nTo create a project that uses IHMC Open Robotics Software, your project hierarchy needs to take a particular form.\nFirst be sure you have completed the section above titled \"Clone repositories\".\nNext, create your project folder:\nmkdir -p src/ihmc/my-project-a\nFollow the project setup tutorial at https://github.com/ihmcrobotics/ihmc-build#quick-project-setup.\nYour directory structure should now look something like:\nsrc/ihmc\n\u251c\u2500\u2500 my-project-a\n\u2502 \u2514\u2500\u2500 build.gradle\n\u2502 \u2514\u2500\u2500 gradle.properties\n\u2502 \u2514\u2500\u2500 settings.gradle\n\u251c\u2500\u2500 my-project-b\n\u2502 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 ihmc-open-robotics-software\n\u2502 \u2514\u2500\u2500 atlas\n\u2502 \u2514\u2500\u2500 common-walking-control-modules\n\u2502 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 my-multi-project-c\n\u2502 \u2514\u2500\u2500 subproject-a\n\u2502 \u2502 \u2514\u2500\u2500 build.gradle\n\u2502 \u2514\u2500\u2500 subproject-b\n\u2502 \u2514\u2500\u2500 build.gradle\n\u251c\u2500\u2500 ...\n\u251c\u2500\u2500 build.gradle\n\u251c\u2500\u2500 gradle.properties\n\u2514\u2500\u2500 settings.gradle\nIf this is set up correctly, you will have applied the ihmc-build plugin and use the dependency resolver methods exposed by the build extension. Alternatively, you can manually identify dependencies on projects using the normal Gradle syntax for project dependencies. A sample build.gradle dependency block:\n/* Normal Gradle way */\ndependencies {\ncompile project(':ihmc-open-robotics-software:ihmc-java-toolkit')\ntestCompile project(':ihmc-open-robotics-software:ihmc-java-toolkit-test')\n}\n/* ihmc-build way */\nmainDependencies {\ncompile group: \"us.ihmc\", name: \"ihmc-java-toolkit\", version: \"source\"\n}\ntestDependencies {\ncompile group: \"us.ihmc\", name: \"ihmc-java-toolkit-test\", version: \"source\"\n}\nMaintainers\nJerry Pratt (jpratt@ihmc.us)\nPeter Neuhaus (pneuhaus@ihmc.us)\nDoug Stephen (dstephen@ihmc.us)\nSylvain Bertrand (sbertrand@ihmc.us)\nDuncan Calvert (dcalvert@ihmc.us)\nStephen McCrory (smcrory@ihmc.us)\nRobert Griffin (rgriffin@ihmc.us)\nGeorg Wiedebach (gwiedebach@ihmc.us)\nInho Lee (ilee@ihmc.us)\nDaniel Duran (dduran@ihmc.us)\nJohn Carff (jcarff@ihmc.us)", "link": "https://github.com/ihmcrobotics/ihmc-open-robotics-software", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "ihmc open robotics software\ncompile: test (3000+ tests):\n<-- download from bintray\ntested platforms\nrobots\natlas\nvalkyrie\ndevelopers\nwe test all of our software on osx, windows, and ubuntu. it is likely to work on other platforms but not necessarily tested.\n-----> branches !!! \nthis repository uses the git-flow branching model. you can find more about git-flow here.\nlicensing\nall of the software in ihmc open robotics software is licensed under the apache 2.0 license.\ngetting started\nusing ihmc open robotics software .jar releases with maven/gradle\nthe release .jars for the various ihmc open robotics software packages are hosted on bintray. you can browse the release packages at https://bintray.com/ihmcrobotics/maven-release. instructions for adding the maven repository and identifying the artifacts can also be found on bintray for each package.\nat a minimum, you will need to have the following repositories declared in your build script to use ihmc open robotics software .jars:\nrepositories {\nmaven {\nurl \"https://dl.bintray.com/ihmcrobotics/maven-release\" // ihmc code releases\n}\nmaven {\nurl \"https://dl.bintray.com/ihmcrobotics/maven-vendor\" // third-party libraries that we have vendored for various reasons\n}\n/* you will also need to add either jcenter() or mavencentral() or both, depending on your preference */\n}\ndeveloping with ihmc open robotics software from source\nrequirements\nihmc open robotics software uses the gradle build system, and requires jdk 8 with javafx. we also strongly suggest an ide, either eclipse or intellij (ultimate or community is fine). currently, we require gradle 4.10+.\ninstalling gradle: https://gradle.org/install/\ncompanion software\nother ihmc libraries\nihmc open robotics software both depends on and is depended on by many other ihmc robotics libraries. a small sampling of our other software includes:\nsimulation construction set, our own simulation environment with built-in analysis tools: https://github.com/ihmcrobotics/simulation-construction-set\neuclid, an alternative vector/geometry library for java with support for additional structures common in 3d geometry without needing vecmath or java3d: https://github.com/ihmcrobotics/euclid\nmecano, a rigid-body dynamics library built on top of euclid and ejml: https://github.com/ihmcrobotics/mecano\nihmc yovariables, our core data structures tools that enable the time-series tracing and analysis of simulation construction set: https://github.com/ihmcrobotics/ihmc-yovariables\njoctomap, a java implementation of octomap: https://github.com/ihmcrobotics/joctomap\nihmc realtime, a library for enabling soft real-time threading for java on linux using the rt_preempt patches: https://github.com/ihmcrobotics/ihmc-realtime\nihmc ethercat master, a java library using ihmc realtime and simple open ethercat master (soem) that makes it simple to start a software ethercat master and pure java data structures that map to ethercat slave defintions: https://github.com/ihmcrobotics/ihmc-ethercat-master\nyou can find all of our other repositories as well as the ones above at https://github.com/ihmcrobotics\nros api's\nwe provide a native ros 2 api for many of the core components in our software stack. you can find the .msg definitions for use in your own projects here: https://github.com/ihmcrobotics/ihmc_interfaces\nwe have ros 1 support via the ros 2 ros1_bridge package. you can find the ros 1 message definitions and instructions on using the ros 1 bridge here: https://github.com/ihmcrobotics/ihmc_msgs\nide support\nour gradle models are tested in intellij idea 2018 (both community and ultimate) with the gradle plugin. eclipse 2018.09+ or higher with the buildship plugin. the buildship plugin is bundled with the eclipse ide for java developers (but not java ee developers). it can always be manually installed to any version of eclipse using the installation instructions.\nbuilding .jars\nihmc open robotics software is pre-configured for generating maven publications. you can publish directly from the source code right in to your local maven repository, e.g. the $home/.m2 directory. these builds will be tagged with a build \"version\" of \"local\" instead of an incrementing version number.\nan example workflow for developing against a local clone of the software:\nclone ihmc open robotics software\nmake modifications\npublish to your local $home/.m2 repository\nto publish jars to your local maven repository:\n$ cd /path/to/ihmc-open-robotics-software\n$ gradle publishall -pcompositesearchheight=0\nto depend on the jars in your local maven repository:\nin this example we'll have a compile-time dependency of the locally built simulation construction set project. in the build.gradle of the project you wish to have link against simulation construction set:\nrepositories {\nmavenlocal()\n<your other repositories>\n}\ndependencies {\ncompile group: \"us.ihmc\", name: \"simulation-construction-set\", version: \"local\", changing: true\n}\ncreating a project\nto create a project that uses ihmc open robotics software, your project hierarchy needs to take a particular form.\nfirst be sure you have completed the section above titled \"clone repositories\".\nnext, create your project folder:\nmkdir -p src/ihmc/my-project-a\nfollow the project setup tutorial at https://github.com/ihmcrobotics/ihmc-build#quick-project-setup.\nyour directory structure should now look something like:\nsrc/ihmc\n\u251c\u2500\u2500 my-project-a\n\u2502 \u2514\u2500\u2500 build.gradle\n\u2502 \u2514\u2500\u2500 gradle.properties\n\u2502 \u2514\u2500\u2500 settings.gradle\n\u251c\u2500\u2500 my-project-b\n\u2502 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 ihmc-open-robotics-software\n\u2502 \u2514\u2500\u2500 atlas\n\u2502 \u2514\u2500\u2500 common-walking-control-modules\n\u2502 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 my-multi-project-c\n\u2502 \u2514\u2500\u2500 subproject-a\n\u2502 \u2502 \u2514\u2500\u2500 build.gradle\n\u2502 \u2514\u2500\u2500 subproject-b\n\u2502 \u2514\u2500\u2500 build.gradle\n\u251c\u2500\u2500 ...\n\u251c\u2500\u2500 build.gradle\n\u251c\u2500\u2500 gradle.properties\n\u2514\u2500\u2500 settings.gradle\nif this is set up correctly, you will have applied the ihmc-build plugin and use the dependency resolver methods exposed by the build extension. alternatively, you can manually identify dependencies on projects using the normal gradle syntax for project dependencies. a sample build.gradle dependency block:\n/* normal gradle way */\ndependencies {\ncompile project(':ihmc-open-robotics-software:ihmc-java-toolkit')\ntestcompile project(':ihmc-open-robotics-software:ihmc-java-toolkit-test')\n}\n/* ihmc-build way */\nmaindependencies {\ncompile group: \"us.ihmc\", name: \"ihmc-java-toolkit\", version: \"source\"\n}\ntestdependencies {\ncompile group: \"us.ihmc\", name: \"ihmc-java-toolkit-test\", version: \"source\"\n}\nmaintainers\njerry pratt (jpratt@ihmc.us)\npeter neuhaus (pneuhaus@ihmc.us)\ndoug stephen (dstephen@ihmc.us)\nsylvain bertrand (sbertrand@ihmc.us)\nduncan calvert (dcalvert@ihmc.us)\nstephen mccrory (smcrory@ihmc.us)\nrobert griffin (rgriffin@ihmc.us)\ngeorg wiedebach (gwiedebach@ihmc.us)\ninho lee (ilee@ihmc.us)\ndaniel duran (dduran@ihmc.us)\njohn carff (jcarff@ihmc.us)", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000250, "year": null}, {"Unnamed: 0": 1551, "autor": 531, "date": null, "content": "SimSlides\nImport PDF files into robot simulation and present flying from slide to slide.\nFeatures\nSimSlides consists of plugins for two simulators: Gazebo Classic and Ignition Gazebo. There are different features for each simulator.\nIgnition\nNavigate through keyframes using mouse, keyboard or wireless presenter\nKeyframes can:\nLook at a slide (even if it has moved)\nMove camera to a specific pose\nGo through slides stacked on the same pose\n... plus all Ignition features!\nGazebo classic\nImport PDF files into simulation through the GUI\nNavigate through keyframes using mouse, keyboard or wireless presenter\nKeyframes can:\nLook at a slide (even if it has moved)\nMove camera to a specific pose\nSeek to specific spot in a log file\nGo through slides stacked on the same pose\nWrite copiable HTML text to a dialog\n... plus all Gazebo features!\nChecking out a couple other tutorials is also recommended if you want to use each simulator's potential to customize your presentations. Maybe you want to setup keyboard triggers? Control a robot using ROS? The possibilities are endless!\nInstall\nSimSlides' main branch supports both Gazebo Classic and Ignition. It's ok if you don't have both simulators installed, only the plugin for the simulator present will be compiled.\nIgnition\nThe main branch supports Ignition Citadel, Edifice and Fortress.\nFollow the official install instructions.\nGazebo Classic\nThe main branch has been tested on Gazebo version 11.\nFollow the official install instructions.\nExtra dependencies:\nsudo apt install imagemagick\nIt's also recommended that you make sure ImageMagick can convert PDFs, see this.\nBuild SimSlides\nBy default, SimSlides will try to build against Ignition Citadel and Gazebo 11. For other Ignition versions, set the IGNITION_VERSION environment variable before building. For example:\nexport IGNITION_VERSION=fortress\nSimSlides can be built with a basic cmake workflow, for example:\nmkdir build\ncd build\ncmake ..\nmake\nsudo make install\ncd ..\nBe sure to add your CMAKE_PREFIX_PATH to LD_LIBRARY_PATH, for example, when following the steps above, you should do this before running:\nexport LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\nIt's also possible to build SimSlides inside a colcon workspace.\nRun SimSlides\nIgnition\nRun simslides:\nsimslides_ignition\nGazebo classic\nImportant: Source Gazebo, this may be in a different place depending on your Gazebo installation:\nsource /usr/share/gazebo/setup.sh\nRun simslides:\nsimslides_classic\nThis starts SimSlides in an empty world. You're ready to create your own presentation!\nDemo\nYou can find a demo presentation inside the worlds directory. The same demo works for both simulators.\nRun it as follows:\nMove to the simslides clone directory\ncd <path to> simslides\n(Only for Gazebo classic) Source Gazebo\nsource /usr/share/gazebo/setup.sh\nLoad the world\nsimslides_ignition worlds/demo_slide.sdf\nsimslides_classic worlds/demo_slide.sdf\nYour own presentation\nYou can generate your own presentation as follows:\nGenerate a new presentation\nOn the top menu, choose SimSlides -> Import PDF (or press F2)\nChoose a PDF file from your computer\nChoose the folder to save the generated slide models at\nChoose a prefix for your model names, they will be named prefix-0, prefix-1, ...\nClick Generate. A model will be created for each page of your PDF. This may take a while, the screen goes black... But it works in the end. Sometimes it looks like not all pages of the PDF become models... That's an open issue.\nWhen it's done, all slides will show up on the world in a grid.\nA world file is also created, so you can reload that any time.\nPresentation mode\nOnce you have the slides loaded into the world, present as follows:\nPress F5 or the play button on the top left to start presentation mode\nPress the arrow keys to go back and forth on the slides\nYou're free to use the rest of Gazebo's interface while presenting. If you've navigated far away from the current slide, you can press F1 to return to it.\nAt any moment, you can press F6 to return to the initial camera pose.\nExisting presentations\nWhen this project was started, all presentations were kept in different branches of the same repository. Since mid 2019, new presentations are being created in their own repositories.\nUntil mid 2019\nMove to the presentation branch, available ones are:\nCppCon2015: CppCon, September 2015\nBuenosAires_Nov2015: University of Buenos Aires, November 2015\nChile_Nov2015: Universidad de Chile, November 2015\nIEEE_WiE_ILC_2016: IEEE Women in Engineering International Leadership Conference, May 2016\nROSCon_Oct2016: ROSCon, October 2016\nROSIndustrial_Jan2017: ROS Industrial web meeting, January 2017\nOSS4DM_Mar2017: Open Source Software for Decision Making, March 2017\nOSCON_May2017: Open Source Conference, May 2017\nROSCon_Sep2017: ROSCon, Sep 2017\nBrasil_Mar2018: Brasil visits, Mar 2018\nQConSF_Nov2018: QConSF, Nov 2018\nUCSC_Feb2019: University of California, Santa Cruz, Feb 2019\nQConAI_Apr2019: QCon.ai, Apr 2019\nA lot changes from one presentation to the next. Follow instructions on that branch's README to run the presentation. I've done my best to document it all, but each presentation may take some massaging to work years later.\nSince mid 2019\nSee each repository / world:\nROSConJP 2019 (video)\nROSCon 2019 (video)\nROS-Industrial Conference 2019: (video)\nAll Things Open 2020 (video)\nOpen Source 101 2021 (video)\nHistory\nThis project started as a few bash scripts for CppCon 2015. Back then, it used to be hosted on BitBucket using Mercurial.\nOver the years, the project evolved into more handy GUI plugins, and is gaining more features for each presentation.\nThe repository was ported to GitHub + Git in August 2019, when BitBucket dropped Mercurial support.", "link": "https://github.com/chapulina/simslides", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "simslides\nimport pdf files into robot simulation and present flying from slide to slide.\nfeatures\nsimslides consists of plugins for two simulators: gazebo classic and ignition gazebo. there are different features for each simulator.\nignition\nnavigate through keyframes using mouse, keyboard or wireless presenter\nkeyframes can:\nlook at a slide (even if it has moved)\nmove camera to a specific pose\ngo through slides stacked on the same pose\n... plus all ignition features!\ngazebo classic\nimport pdf files into simulation through the gui\nnavigate through keyframes using mouse, keyboard or wireless presenter\nkeyframes can:\nlook at a slide (even if it has moved)\nmove camera to a specific pose\nseek to specific spot in a log file\ngo through slides stacked on the same pose\nwrite copiable html text to a dialog\n... plus all gazebo features!\nchecking out a couple other tutorials is also recommended if you want to use each simulator's potential to customize your presentations. maybe you want to setup keyboard triggers? control a robot using ros? the possibilities are endless!\ninstall\nsimslides' main branch supports both gazebo classic and ignition. it's ok if you don't have both simulators installed, only the plugin for the simulator present will be compiled.\nignition\nthe main branch supports ignition citadel, edifice and fortress.\nfollow the official install instructions.\ngazebo classic\nthe main branch has been tested on gazebo version 11.\nfollow the official install instructions.\nextra dependencies:\nsudo apt install imagemagick\nit's also recommended that you make sure imagemagick can convert pdfs, see this.\nbuild simslides\nby default, simslides will try to build against ignition citadel and gazebo 11. for other ignition versions, set the ignition_version environment variable before building. for example:\nexport ignition_version=fortress\nsimslides can be built with a basic cmake workflow, for example:\nmkdir build\ncd build\ncmake ..\nmake\nsudo make install\ncd ..\nbe sure to add your cmake_prefix_path to ld_library_path, for example, when following the steps above, you should do this before running:\nexport ld_library_path=/usr/local/lib:$ld_library_path\nit's also possible to build simslides inside a colcon workspace.\nrun simslides\nignition\nrun simslides:\nsimslides_ignition\ngazebo classic\nimportant: source gazebo, this may be in a different place depending on your gazebo installation:\nsource /usr/share/gazebo/setup.sh\nrun simslides:\nsimslides_classic\nthis starts simslides in an empty world. you're ready to create your own presentation!\ndemo\nyou can find a demo presentation inside the worlds directory. the same demo works for both simulators.\nrun it as follows:\nmove to the simslides clone directory\ncd <path to> simslides\n(only for gazebo classic) source gazebo\nsource /usr/share/gazebo/setup.sh\nload the world\nsimslides_ignition worlds/demo_slide.sdf\nsimslides_classic worlds/demo_slide.sdf\nyour own presentation\nyou can generate your own presentation as follows:\ngenerate a new presentation\non the top menu, choose simslides -> import pdf (or press f2)\nchoose a pdf file from your computer\nchoose the folder to save the generated slide models at\nchoose a prefix for your model names, they will be named prefix-0, prefix-1, ...\nclick generate. a model will be created for each page of your pdf. this may take a while, the screen goes black... but it works in the end. sometimes it looks like not all pages of the pdf become models... that's an open issue.\nwhen it's done, all slides will show up on the world in a grid.\na world file is also created, so you can reload that any time.\npresentation mode\nonce you have the slides loaded into the world, present as follows:\npress f5 or the play button on the top left to start presentation mode\npress the arrow keys to go back and forth on the slides\nyou're free to use the rest of gazebo's interface while presenting. if you've navigated far away from the current slide, you can press f1 to return to it.\nat any moment, you can press f6 to return to the initial camera pose.\nexisting presentations\nwhen this project was started, all presentations were kept in different -----> branches !!!  of the same repository. since mid 2019, new presentations are being created in their own repositories.\nuntil mid 2019\nmove to the presentation branch, available ones are:\ncppcon2015: cppcon, september 2015\nbuenosaires_nov2015: university of buenos aires, november 2015\nchile_nov2015: universidad de chile, november 2015\nieee_wie_ilc_2016: ieee women in engineering international leadership conference, may 2016\nroscon_oct2016: roscon, october 2016\nrosindustrial_jan2017: ros industrial web meeting, january 2017\noss4dm_mar2017: open source software for decision making, march 2017\noscon_may2017: open source conference, may 2017\nroscon_sep2017: roscon, sep 2017\nbrasil_mar2018: brasil visits, mar 2018\nqconsf_nov2018: qconsf, nov 2018\nucsc_feb2019: university of california, santa cruz, feb 2019\nqconai_apr2019: qcon.ai, apr 2019\na lot changes from one presentation to the next. follow instructions on that branch's readme to run the presentation. i've done my best to document it all, but each presentation may take some massaging to work years later.\nsince mid 2019\nsee each repository / world:\nrosconjp 2019 (video)\nroscon 2019 (video)\nros-industrial conference 2019: (video)\nall things open 2020 (video)\nopen source 101 2021 (video)\nhistory\nthis project started as a few bash scripts for cppcon 2015. back then, it used to be hosted on bitbucket using mercurial.\nover the years, the project evolved into more handy gui plugins, and is gaining more features for each presentation.\nthe repository was ported to github + git in august 2019, when bitbucket dropped mercurial support.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000531, "year": null}, {"Unnamed: 0": 1684, "autor": 664, "date": null, "content": "robotology-superbuild\nThis is a meta repository (so-called \"superbuild\") that uses CMake and YCM to automatically download and compile software developed in the robotology GitHub organization, such as the YARP middleware or software used to run the iCub humanoid robot.\nCMake is an open-source, cross-platform family of tools designed to build, test and package software. A YCM Superbuild is a CMake project whose only goal is to download and build several other projects. If you are familiar with ROS, it is something similar to catkin or colcon workspace, but using pure CMake for portability reasons and for customizing the build via CMake options. Furthermore, the robotology-superbuild also contains some infrastructure to build binaries of the contained projects for some platforms. You can read more about the superbuild concept in YCM documentation or in the related IRC paper.\nSystem Continuous Integration Status\nLinux/macOS/Windows\nTable of Contents\nSuperbuild\nBinary Installation\nSource Installation\nClone the repo\nDebian/Ubuntu Linux with dependencies provided by apt\nLinux, macOS or Windows with dependencies provided by conda-forge\nUpdate\nFAQs\nMantainers\nSuperbuild\nThe robotology-superbuild is an infrastructure to simplify development and use of open source research software developed at the Italian Institute of Technology, in particular as part of the iCub project.\nProfiles and Optional Dependencies\nAs a huge number of software projects are contained in the robotology-superbuild, and a tipical user is only interested in some of them, there are several options to instruct the superbuild on which packages should be built and which one should not be built. In particular, the robotology-superbuild is divided in different profiles, that specify the specific subset of robotology packages to build. You can read more on the available profiles and how to enable them in the doc/cmake-options.md#profile-specific-documentation.\nFurthermore, some dependencies of software contained in the robotology-superbuild are either tricky to install or proprietary, and for this reason software that depends on those optional dependencies can be enabled or disabled with specific options,as documented in doc/cmake-options.md#dependencies-specific-documentation.\nVersioning\nFor what regards versioning, software in the robotology-superbuild can be consumed in two forms:\nRolling update\nIn this form, the superbuild will get the latest changes for a branch of each subproject, and will build it. This has the advantage that you get all the latest changes from the software contained in the robotology-superbuild, while the downside that the specific software that you use may change at each update. The rolling update can be used only when building robotology-superbuild software from source. By default, the robotology-superbuild uses the latest \"stable\" branches of the robotology repositories, but in some cases it may be necessary to use the \"unstable\" active development branches. For this advanced functionalities, please refer to the documentation on changing the default project tags, available at doc/change-project-tags.md.\nReleases\nOnce every three months, a set of releases of the software in the robotology-superbuild is freezed and used as a \"Distro Release\", following the policies of iCub software described in https://icub-tech-iit.github.io/documentation/sw_versioning_table/ . Releases can be used both when building the software from source, and when obtaining it from binaries.\nThe available releases can be seen on GitHub's release page.\nBinary Installation\nWe provide binary packages for Linux, macOS and Windows of the software contained in the robotology-superbuild via the conda package manager, relying on the community-mantained conda-forge channel and for some packages on on our own robotology conda channel.\nPlease refer to doc/conda-forge.md document for instruction on how to install the conda binary packages, in particualr the Binary Installation section.\nNote that the default binary installed by the conda package manager is the latest available, so if you need to get exactly the version corresponding to a specific robotology-superbuild distro release (for example for compatibility with an existing robot setup), please install the required versions by inspecting the version tables of the specific distro you are interested in https://icub-tech-iit.github.io/documentation/sw_versioning_table/ .\nIf you need to use the robotology packages with dependencies provided by other package managers, for example with the aptpackages on Debina/Ubuntu distributions, please install robotology-superbuild from source code as explained in the approprate section, as we do not provide binary packages for all software contained in the robotology-superbuild for the apt package manager.\nWe also support a deprecated way of installing binary packages just on Windows using dependencies provided by vcpkg, documentation for it can be found in doc/deprecated-installation-methods.md. However for new deployments we recommend to use conda binary packages also on Windows.\nSource Installation\nClone the repo\nThe first step to install robotology-superbuild from source is to download the robotology-superbuild code itself, and this is done through Git.\nOnce you install Git, you need to set your name and email to sign your commits, as this is required by the superbuild:\ngit config --global user.name FirstName LastName\ngit config --global user.email user@email.domain\nOnce git is configured, you can open a command line terminal. If you want to use the robotology-superbuild in rolling update mode, just clone the superbuild:\ngit clone https://github.com/robotology/robotology-superbuild\nthis will clone the superbuild in its default branch.\nYou can download and use the robotology-superbuild anywhere on your system, but if you are installing it on an iCub robot laptop following the official iCub instructions, you should clone it in the /usr/local/src/robot directory.\nIf instead you want to use a specific release of the robotology superbuild, after you clone switch to use to a specific release tag:\ngit checkout v<YYYY.MM>\nFor the list of actually available tags, see the GitHub's releases page.\nOnce you cloned the repo, to go forward you can follow the different instructions on how to install robotology-superbuild from the source code, depending on your operating system and the package manager you want to use to install the required dependencies:\nLinux with dependencies provided by apt: use the superbuild on Debian/Ubuntu distributions installing the dependencies with apt,\nLinux, macOS or Windows with dependencies provided by conda-forge: use the superbuild on any supported operating system, installing the dependencies with conda package manager,\nWindows Subsystem For Linux: use the superbuild on Windows Subsystem For Linux.\nThe exact versions of the operating systems supported by the robotology-superbuild follow the one supported by the YARP library, that are documented in https://github.com/robotology/yarp/blob/master/.github/CONTRIBUTING.md#supported-systems .\nComplete documentation on how to use a YCM-based superbuild is available in the YCM documentation.\nWhen compiled from source, robotology-superbuild will download and build a number of software. For each project, the repository will be downloaded in the src/<package_name> subdirectory of the superbuild root. The build directory for a given project will be instead the src/<package_name> subdirectory of the superbuild build directory. All the software packages are installed using the install directory of the build as installation prefix.\nWe also support two additional deprecated ways of compiling the superbuild, on Windows using dependencies provided by vcpkg or on macOS using dependencies provided by Homebrew](https://brew.sh/). Documentation for them can be found in doc/deprecated-installation-methods.md.\nLinux from source with dependencies provided by apt\nSystem Dependencies\nOn Debian based systems (as Ubuntu) you can install the C++ toolchain, Git, CMake and Eigen (and other dependencies necessary for the software include in robotology-superbuild) using apt-get. This can be done by installing the packages listed in the apt.txt file using the following script:\ncd robotology-superbuild\nsudo bash ./scripts/install_apt_dependencies.sh\nBesides the packages listed in apt.txt file, the script install_apt_dependencies.sh also installs some other packages depending on the distribution used, please inspect the script for more information.\nFor what regards CMake, the robotology-superbuild requires CMake 3.16 . If you are using a recent Debian-based system such as Ubuntu 20.04, the default CMake is recent enough and you do not need to do further steps.\nIf instead you use an older distro in which the default version of CMake is older, you can easily install a newer CMake version in several ways. For the following distributions, we recommend the following methods:\nUbuntu 18.04 : use the latest CMake release in the Kitware APT repository. You can find the full instructions for the installation on the website.\nDebian 10 : use the CMake in the buster-backports repository, following the instructions to install from backports available in Debian documentation. More details can be found at https://github.com/robotology/QA/issues/364 .\nIf you enabled any profile or dependency specific CMake option you may need to install additional system dependencies, following the dependency-specific documentation (in particular, the ROBOTOLOGY_USES_GAZEBO option is enabled by default, so you should install Gazebo unless you plan to disable this option):\nROBOTOLOGY_USES_GAZEBO\nCompile the superbuild\nFinally it is possible to install robotology software using the YCM superbuild:\ncd robotology-superbuild\nmkdir build\ncd build\nccmake ../\nmake\nYou can configure the ccmake environment if you know you will use some particular set of software (put them in \"ON\"). See Superbuild CMake options for a list of available options.\nConfigure your environment\nThe superbuild provides an automatically generated setup.sh sh script that will set all the necessary enviromental variables to use the software installed in the robotology-superbuild. To do so automatically for any new terminal that you open, append the following line to the .bashrc file:\nsource <directory-where-you-downloaded-robotology-superbuild>/build/install/share/robotology-superbuild/setup.sh\nTo use the updated .bashrc in your terminal you should run the following command:\nuser@host:~$ source ~/.bashrc\nIf may also be necessary to updates the cache of the dynamic linker:\nuser@host:~$ sudo ldconfig\nIf for any reason you do not want to use the provided setup.sh script and you want to manage your enviroment variables manually, please refer to the documentation available at doc/environment-variables-configuration.md .\nLinux, macOS or Windows from source with dependencies provided by conda-forge\nPlease refer to doc/conda-forge.md document for instruction on how to compile the superbuild from source using the conda-forge provided dependencies, in particular the Source Installation section.\nWindows Subsystem for Linux from source\nThe Windows Subsystem for Linux (wsl) lets developers run a GNU/Linux environment -- including most command-line tools, utilities, and applications -- directly on Windows, unmodified.\nAs all the software running on Linux distributions can run unmodified on Windows via WSL, to install the robotology-superbuild in WSL you can just install a Debian-based distribution for WSL, and then follow the instructions on how to install the robotology-superbuild on Linux, with dependencies provided either by apt or by conda. As the WSL enviroment is nevertheless different, there are a few things you need to care before using the robotology-superbuild on WSL, that are listed in the following, depending on whetever you are using WSL2 or WSL1.\nWSL2\nRun graphical applications on WSL2\nThe Linux instance in WSL2 are running as part of a lightweight virtual machine, so effectively the IP address of the WSL2 instance will be different from the IP address of the Windows host, and the Windows host can communicate with the WSL2 instance thanks to a virtual IP network. For this reason, to run graphical applications on WSL2, you first need to install an X Server for Windows. Furthermore, you will need to configure your application to connect to the X Server that is running on the Windows host, you can do so by adding the following lines in the ~/.bashrc file of the WSL2 instance:\nexport WINDOWS_HOST=$(grep nameserver /etc/resolv.conf | awk '{print $2}')\nexport DISPLAY=${WINDOWS_HOST}:0.0\nAs unfortunately the IP addresses of the virtual IP network change at every reboot, it is also necessary to configure the X Server that you use to accept connection for arbitrary IP addresses. Check doc/wsl2-xserver-configuration.md for instructions on how to do so on several X Servers.\nSanitize PATH enviroment variable for WSL2\nBy default, the PATH enviroment variable in WSL will contain the path of the host Windows system, see https://github.com/microsoft/WSL/issues/1640 and https://github.com/microsoft/WSL/issues/1493. This can create problems, as the CMake in WSL may find (incompatible) Windows CMake packages and try to use them, creating errors due to the compilation. To avoid that, you can create in your WSL2 instance the /etc/wsl.conf file, and then populate it with the following content:\n[interop]\nappendWindowsPath = false\nNote that you will need to restart your machine to make sure that this setting is taked into account.\nConnect to a YARP server on a Windows host on WSL2\nIf you want your YARP applications on WSL2 to connect to a yarpserver that you launched on the Windows host, you need to add the following line to your WSL's ~/.bashrc:\nyarp conf ${WINDOWS_HOST} 10000 > /dev/null 2>&1\nwhere WINDOWS_HOST needs to be defined as in \"Run graphical applications on WSL2\" section.\nWSL1\nWith respect to WSL2, WSL1 uses the same IP address used by the Windows machine, so the amount of configuration and tweaks required are less.\nRun graphical applications on WSL1\nTo run graphical applications on WSL, you need to install a X Server for Windows, that will be able to visualize the windows WSL-based applications, see https://www.howtogeek.com/261575/how-to-run-graphical-linux-desktop-applications-from-windows-10s-bash-shell/ for more info. For information of X Servers that can be installed on Windows, follow the docs in https://github.com/sirredbeard/Awesome-WSL#10-gui-apps .\nSanitize enviroment variables for WSL1\nBy default, the PATH enviroment variable in WSL will contain the path of the host Windows system, see https://github.com/microsoft/WSL/issues/1640 and https://github.com/microsoft/WSL/issues/1493. This can create problems, as the CMake in WSL may find (incompatible) Windows CMake packages and try to use them, creating errors due to the compilation. To avoid that, you can add the following line in the WSL .bashrc that filters all the Windows paths from the WSL's enviromental variables:\nfor var in $(env | awk {'FS=\"=\"} /\\/mnt\\//{print $1}'); do export ${var}=\\\"$(echo ${!var} | awk -v RS=: -v ORS=: '/\\/mnt\\// {next} {print $1}')\\\" ; done\nUpdate\nIf you are using the robotology-superbuild in its default branch and not from a release tag (i.e. in rolling update mode), to update the superbuild you need to first update the robotology-superbuild repository itself with the git command:\ngit pull\nAfter that, you will need to also run the equivalent of git pull on all the repositories managed by the robotology-superbuild, you have to run in your build system the appropriate target.\nTo do this, make sure to be in the build directory of the robotology-superbuild and run:\nmake update-all\nmake\nusing make on Linux or macOS or\ncmake --build . --target ALL_UPDATE\ncmake --build .\nusing Visual Studio on Windows or\ncmake --build . --target ALL_UPDATE\ncmake --build .\nusing Xcode on macOS.\nNote that the update will try to update all the software in the robotology-superbuild, and it will complain if the repository is not in the expected branch. For this reason, if you are activly developing on a repository managed by the robotology-superbuild, remember to switch the YCM_EP_DEVEL_MODE_<package_name> option to TRUE. This option will ensure that the superbuild will not try to automatically update the <package_name> repository. See https://robotology.github.io/ycm/gh-pages/git-master/manual/ycm-superbuild.7.html#developer-mode for more details on this options.\nBy default, the robotology-superbuild uses the latest \"stable\" branches of the robotology repositories, but in some cases it may be necessary to use the \"unstable\" active development branches, or use some fixed tags. For this advanced functionalities, please refer to the documentation on changing the default project tags, available at doc/change-project-tags.md.\nFAQs\nSee also YCM documentation for YCM's FAQs. For questions related to how to modify the rootology-superbuild itself, such as how to add a new package, how to do a release, check the Developers' FAQs document at doc/developers-faqs.md.\nHow do I pass CMake options to the projects built by the robotology-superbuild ?\nWhen configuration the robotology-superbuild, you can pass the YCM_EP_ADDITIONAL_CMAKE_ARGS CMake option:\ncmake -DYCM_EP_ADDITIONAL_CMAKE_ARGS:STRING=\"-DENABLE_yarpmod_SDLJoypad:BOOL=ON\"\nThis option can be used to specify parameters that are passed to all CMake projects of the superbuild (as it is useful for some options, for example -DBUILD_TESTING:BOOL=ON). This option can be used also for CMake options that are related to a single project, as all the other projects will ignore the option.\nFor more information on this option, see the official YCM documentation.\nHow can I check the status of each subproject?\nIt is possible to run the bash script named robotologyGitStatus.sh in the scripts folder. For example, on linux, from the robotology-superbuild root run bash scripts/robotologyGitStatus.sh to print the status of each subproject. This script can run from any directory, provided that the path to the robotologyGitStatus.sh script is given to bash.\nI successfully used the robotology-superbuild for my project, how do I cite it in my publication?\nThe robotology-superbuild is based on YCM, you can cite one of these papers:\nA Build System for Software Development in Robotic Academic Collaborative Environments, D.E. Domenichelli, S. Traversaro, L. Muratore, A. Rocchi, F. Nori, L. Natale, Second IEEE International Conference on Robotic Computing (IRC), 2018, https://doi.org/10.1109/IRC.2018.00014\nA Build System for Software Development in Robotic Academic Collaborative Environments, D.E. Domenichelli, S. Traversaro, L. Muratore, A. Rocchi, F. Nori, L. Natale, International Journal of Semantic Computing (IJSC), Vol. 13, No. 02, 2019\nMantainers\nProfile Maintainer\nCore, Dynamics, iCub Head, iCub Basic Demos Silvio Traversaro @traversaro\nTeleoperation Kourosh Darvish @kouroshD\nHuman Dynamics Yeshasvi Tirupachuri @Yeshasvitvs\nEvent-driven Arren Glover @arrenglover\nDynamics full deps Giulio Romualdi @GiulioRomualdi", "link": "https://github.com/robotology/robotology-superbuild", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "robotology-superbuild\nthis is a meta repository (so-called \"superbuild\") that uses cmake and ycm to automatically download and compile software developed in the robotology github organization, such as the yarp middleware or software used to run the icub humanoid robot.\ncmake is an open-source, cross-platform family of tools designed to build, test and package software. a ycm superbuild is a cmake project whose only goal is to download and build several other projects. if you are familiar with ros, it is something similar to catkin or colcon workspace, but using pure cmake for portability reasons and for customizing the build via cmake options. furthermore, the robotology-superbuild also contains some infrastructure to build binaries of the contained projects for some platforms. you can read more about the superbuild concept in ycm documentation or in the related irc paper.\nsystem continuous integration status\nlinux/macos/windows\ntable of contents\nsuperbuild\nbinary installation\nsource installation\nclone the repo\ndebian/ubuntu linux with dependencies provided by apt\nlinux, macos or windows with dependencies provided by conda-forge\nupdate\nfaqs\nmantainers\nsuperbuild\nthe robotology-superbuild is an infrastructure to simplify development and use of open source research software developed at the italian institute of technology, in particular as part of the icub project.\nprofiles and optional dependencies\nas a huge number of software projects are contained in the robotology-superbuild, and a tipical user is only interested in some of them, there are several options to instruct the superbuild on which packages should be built and which one should not be built. in particular, the robotology-superbuild is divided in different profiles, that specify the specific subset of robotology packages to build. you can read more on the available profiles and how to enable them in the doc/cmake-options.md#profile-specific-documentation.\nfurthermore, some dependencies of software contained in the robotology-superbuild are either tricky to install or proprietary, and for this reason software that depends on those optional dependencies can be enabled or disabled with specific options,as documented in doc/cmake-options.md#dependencies-specific-documentation.\nversioning\nfor what regards versioning, software in the robotology-superbuild can be consumed in two forms:\nrolling update\nin this form, the superbuild will get the latest changes for a branch of each subproject, and will build it. this has the advantage that you get all the latest changes from the software contained in the robotology-superbuild, while the downside that the specific software that you use may change at each update. the rolling update can be used only when building robotology-superbuild software from source. by default, the robotology-superbuild uses the latest \"stable\" -----> branches !!!  of the robotology repositories, but in some cases it may be necessary to use the \"unstable\" active development -----> branches !!! . for this advanced functionalities, please refer to the documentation on changing the default project tags, available at doc/change-project-tags.md.\nreleases\nonce every three months, a set of releases of the software in the robotology-superbuild is freezed and used as a \"distro release\", following the policies of icub software described in https://icub-tech-iit.github.io/documentation/sw_versioning_table/ . releases can be used both when building the software from source, and when obtaining it from binaries.\nthe available releases can be seen on github's release page.\nbinary installation\nwe provide binary packages for linux, macos and windows of the software contained in the robotology-superbuild via the conda package manager, relying on the community-mantained conda-forge channel and for some packages on on our own robotology conda channel.\nplease refer to doc/conda-forge.md document for instruction on how to install the conda binary packages, in particualr the binary installation section.\nnote that the default binary installed by the conda package manager is the latest available, so if you need to get exactly the version corresponding to a specific robotology-superbuild distro release (for example for compatibility with an existing robot setup), please install the required versions by inspecting the version tables of the specific distro you are interested in https://icub-tech-iit.github.io/documentation/sw_versioning_table/ .\nif you need to use the robotology packages with dependencies provided by other package managers, for example with the aptpackages on debina/ubuntu distributions, please install robotology-superbuild from source code as explained in the approprate section, as we do not provide binary packages for all software contained in the robotology-superbuild for the apt package manager.\nwe also support a deprecated way of installing binary packages just on windows using dependencies provided by vcpkg, documentation for it can be found in doc/deprecated-installation-methods.md. however for new deployments we recommend to use conda binary packages also on windows.\nsource installation\nclone the repo\nthe first step to install robotology-superbuild from source is to download the robotology-superbuild code itself, and this is done through git.\nonce you install git, you need to set your name and email to sign your commits, as this is required by the superbuild:\ngit config --global user.name firstname lastname\ngit config --global user.email user@email.domain\nonce git is configured, you can open a command line terminal. if you want to use the robotology-superbuild in rolling update mode, just clone the superbuild:\ngit clone https://github.com/robotology/robotology-superbuild\nthis will clone the superbuild in its default branch.\nyou can download and use the robotology-superbuild anywhere on your system, but if you are installing it on an icub robot laptop following the official icub instructions, you should clone it in the /usr/local/src/robot directory.\nif instead you want to use a specific release of the robotology superbuild, after you clone switch to use to a specific release tag:\ngit checkout v<yyyy.mm>\nfor the list of actually available tags, see the github's releases page.\nonce you cloned the repo, to go forward you can follow the different instructions on how to install robotology-superbuild from the source code, depending on your operating system and the package manager you want to use to install the required dependencies:\nlinux with dependencies provided by apt: use the superbuild on debian/ubuntu distributions installing the dependencies with apt,\nlinux, macos or windows with dependencies provided by conda-forge: use the superbuild on any supported operating system, installing the dependencies with conda package manager,\nwindows subsystem for linux: use the superbuild on windows subsystem for linux.\nthe exact versions of the operating systems supported by the robotology-superbuild follow the one supported by the yarp library, that are documented in https://github.com/robotology/yarp/blob/master/.github/contributing.md#supported-systems .\ncomplete documentation on how to use a ycm-based superbuild is available in the ycm documentation.\nwhen compiled from source, robotology-superbuild will download and build a number of software. for each project, the repository will be downloaded in the src/<package_name> subdirectory of the superbuild root. the build directory for a given project will be instead the src/<package_name> subdirectory of the superbuild build directory. all the software packages are installed using the install directory of the build as installation prefix.\nwe also support two additional deprecated ways of compiling the superbuild, on windows using dependencies provided by vcpkg or on macos using dependencies provided by homebrew](https://brew.sh/). documentation for them can be found in doc/deprecated-installation-methods.md.\nlinux from source with dependencies provided by apt\nsystem dependencies\non debian based systems (as ubuntu) you can install the c++ toolchain, git, cmake and eigen (and other dependencies necessary for the software include in robotology-superbuild) using apt-get. this can be done by installing the packages listed in the apt.txt file using the following script:\ncd robotology-superbuild\nsudo bash ./scripts/install_apt_dependencies.sh\nbesides the packages listed in apt.txt file, the script install_apt_dependencies.sh also installs some other packages depending on the distribution used, please inspect the script for more information.\nfor what regards cmake, the robotology-superbuild requires cmake 3.16 . if you are using a recent debian-based system such as ubuntu 20.04, the default cmake is recent enough and you do not need to do further steps.\nif instead you use an older distro in which the default version of cmake is older, you can easily install a newer cmake version in several ways. for the following distributions, we recommend the following methods:\nubuntu 18.04 : use the latest cmake release in the kitware apt repository. you can find the full instructions for the installation on the website.\ndebian 10 : use the cmake in the buster-backports repository, following the instructions to install from backports available in debian documentation. more details can be found at https://github.com/robotology/qa/issues/364 .\nif you enabled any profile or dependency specific cmake option you may need to install additional system dependencies, following the dependency-specific documentation (in particular, the robotology_uses_gazebo option is enabled by default, so you should install gazebo unless you plan to disable this option):\nrobotology_uses_gazebo\ncompile the superbuild\nfinally it is possible to install robotology software using the ycm superbuild:\ncd robotology-superbuild\nmkdir build\ncd build\nccmake ../\nmake\nyou can configure the ccmake environment if you know you will use some particular set of software (put them in \"on\"). see superbuild cmake options for a list of available options.\nconfigure your environment\nthe superbuild provides an automatically generated setup.sh sh script that will set all the necessary enviromental variables to use the software installed in the robotology-superbuild. to do so automatically for any new terminal that you open, append the following line to the .bashrc file:\nsource <directory-where-you-downloaded-robotology-superbuild>/build/install/share/robotology-superbuild/setup.sh\nto use the updated .bashrc in your terminal you should run the following command:\nuser@host:~$ source ~/.bashrc\nif may also be necessary to updates the cache of the dynamic linker:\nuser@host:~$ sudo ldconfig\nif for any reason you do not want to use the provided setup.sh script and you want to manage your enviroment variables manually, please refer to the documentation available at doc/environment-variables-configuration.md .\nlinux, macos or windows from source with dependencies provided by conda-forge\nplease refer to doc/conda-forge.md document for instruction on how to compile the superbuild from source using the conda-forge provided dependencies, in particular the source installation section.\nwindows subsystem for linux from source\nthe windows subsystem for linux (wsl) lets developers run a gnu/linux environment -- including most command-line tools, utilities, and applications -- directly on windows, unmodified.\nas all the software running on linux distributions can run unmodified on windows via wsl, to install the robotology-superbuild in wsl you can just install a debian-based distribution for wsl, and then follow the instructions on how to install the robotology-superbuild on linux, with dependencies provided either by apt or by conda. as the wsl enviroment is nevertheless different, there are a few things you need to care before using the robotology-superbuild on wsl, that are listed in the following, depending on whetever you are using wsl2 or wsl1.\nwsl2\nrun graphical applications on wsl2\nthe linux instance in wsl2 are running as part of a lightweight virtual machine, so effectively the ip address of the wsl2 instance will be different from the ip address of the windows host, and the windows host can communicate with the wsl2 instance thanks to a virtual ip network. for this reason, to run graphical applications on wsl2, you first need to install an x server for windows. furthermore, you will need to configure your application to connect to the x server that is running on the windows host, you can do so by adding the following lines in the ~/.bashrc file of the wsl2 instance:\nexport windows_host=$(grep nameserver /etc/resolv.conf | awk '{print $2}')\nexport display=${windows_host}:0.0\nas unfortunately the ip addresses of the virtual ip network change at every reboot, it is also necessary to configure the x server that you use to accept connection for arbitrary ip addresses. check doc/wsl2-xserver-configuration.md for instructions on how to do so on several x servers.\nsanitize path enviroment variable for wsl2\nby default, the path enviroment variable in wsl will contain the path of the host windows system, see https://github.com/microsoft/wsl/issues/1640 and https://github.com/microsoft/wsl/issues/1493. this can create problems, as the cmake in wsl may find (incompatible) windows cmake packages and try to use them, creating errors due to the compilation. to avoid that, you can create in your wsl2 instance the /etc/wsl.conf file, and then populate it with the following content:\n[interop]\nappendwindowspath = false\nnote that you will need to restart your machine to make sure that this setting is taked into account.\nconnect to a yarp server on a windows host on wsl2\nif you want your yarp applications on wsl2 to connect to a yarpserver that you launched on the windows host, you need to add the following line to your wsl's ~/.bashrc:\nyarp conf ${windows_host} 10000 > /dev/null 2>&1\nwhere windows_host needs to be defined as in \"run graphical applications on wsl2\" section.\nwsl1\nwith respect to wsl2, wsl1 uses the same ip address used by the windows machine, so the amount of configuration and tweaks required are less.\nrun graphical applications on wsl1\nto run graphical applications on wsl, you need to install a x server for windows, that will be able to visualize the windows wsl-based applications, see https://www.howtogeek.com/261575/how-to-run-graphical-linux-desktop-applications-from-windows-10s-bash-shell/ for more info. for information of x servers that can be installed on windows, follow the docs in https://github.com/sirredbeard/awesome-wsl#10-gui-apps .\nsanitize enviroment variables for wsl1\nby default, the path enviroment variable in wsl will contain the path of the host windows system, see https://github.com/microsoft/wsl/issues/1640 and https://github.com/microsoft/wsl/issues/1493. this can create problems, as the cmake in wsl may find (incompatible) windows cmake packages and try to use them, creating errors due to the compilation. to avoid that, you can add the following line in the wsl .bashrc that filters all the windows paths from the wsl's enviromental variables:\nfor var in $(env | awk {'fs=\"=\"} /\\/mnt\\//{print $1}'); do export ${var}=\\\"$(echo ${!var} | awk -v rs=: -v ors=: '/\\/mnt\\// {next} {print $1}')\\\" ; done\nupdate\nif you are using the robotology-superbuild in its default branch and not from a release tag (i.e. in rolling update mode), to update the superbuild you need to first update the robotology-superbuild repository itself with the git command:\ngit pull\nafter that, you will need to also run the equivalent of git pull on all the repositories managed by the robotology-superbuild, you have to run in your build system the appropriate target.\nto do this, make sure to be in the build directory of the robotology-superbuild and run:\nmake update-all\nmake\nusing make on linux or macos or\ncmake --build . --target all_update\ncmake --build .\nusing visual studio on windows or\ncmake --build . --target all_update\ncmake --build .\nusing xcode on macos.\nnote that the update will try to update all the software in the robotology-superbuild, and it will complain if the repository is not in the expected branch. for this reason, if you are activly developing on a repository managed by the robotology-superbuild, remember to switch the ycm_ep_devel_mode_<package_name> option to true. this option will ensure that the superbuild will not try to automatically update the <package_name> repository. see https://robotology.github.io/ycm/gh-pages/git-master/manual/ycm-superbuild.7.html#developer-mode for more details on this options.\nby default, the robotology-superbuild uses the latest \"stable\" branches of the robotology repositories, but in some cases it may be necessary to use the \"unstable\" active development branches, or use some fixed tags. for this advanced functionalities, please refer to the documentation on changing the default project tags, available at doc/change-project-tags.md.\nfaqs\nsee also ycm documentation for ycm's faqs. for questions related to how to modify the rootology-superbuild itself, such as how to add a new package, how to do a release, check the developers' faqs document at doc/developers-faqs.md.\nhow do i pass cmake options to the projects built by the robotology-superbuild ?\nwhen configuration the robotology-superbuild, you can pass the ycm_ep_additional_cmake_args cmake option:\ncmake -dycm_ep_additional_cmake_args:string=\"-denable_yarpmod_sdljoypad:bool=on\"\nthis option can be used to specify parameters that are passed to all cmake projects of the superbuild (as it is useful for some options, for example -dbuild_testing:bool=on). this option can be used also for cmake options that are related to a single project, as all the other projects will ignore the option.\nfor more information on this option, see the official ycm documentation.\nhow can i check the status of each subproject?\nit is possible to run the bash script named robotologygitstatus.sh in the scripts folder. for example, on linux, from the robotology-superbuild root run bash scripts/robotologygitstatus.sh to print the status of each subproject. this script can run from any directory, provided that the path to the robotologygitstatus.sh script is given to bash.\ni successfully used the robotology-superbuild for my project, how do i cite it in my publication?\nthe robotology-superbuild is based on ycm, you can cite one of these papers:\na build system for software development in robotic academic collaborative environments, d.e. domenichelli, s. traversaro, l. muratore, a. rocchi, f. nori, l. natale, second ieee international conference on robotic computing (irc), 2018, https://doi.org/10.1109/irc.2018.00014\na build system for software development in robotic academic collaborative environments, d.e. domenichelli, s. traversaro, l. muratore, a. rocchi, f. nori, l. natale, international journal of semantic computing (ijsc), vol. 13, no. 02, 2019\nmantainers\nprofile maintainer\ncore, dynamics, icub head, icub basic demos silvio traversaro @traversaro\nteleoperation kourosh darvish @kouroshd\nhuman dynamics yeshasvi tirupachuri @yeshasvitvs\nevent-driven arren glover @arrenglover\ndynamics full deps giulio romualdi @giulioromualdi", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000664, "year": null}, {"Unnamed: 0": 1728, "autor": 708, "date": null, "content": "Welcome to FusionAD\nFusionAD is an autonomous driving software stack developed by the SJSU Autonomous Driving Team at San Jose State University (SJSU), San Jose, CA.\nOur challenge is to create a fully functional autonomous driving vehicle within the 1 Year timeline of a Mechanical Engineering Senior Project at SJSU.\nSee KPIX Bay Area's coverage on SJSU autonomous driving on Youtube\nFusionAD's Software Architecture\nThis repository mainly capture the software application layer within FusionAD's architecture.\nApplication Modules\nCurrently, all the modules are under work in progress and they are located under FusionAD/src/modules\nCurrent capabilities of the software modules:\nPerception\nIntegration done with Yolo V3 image detector\nLocalization\nEKF through robot_localization package\nDead reckoning vehicle kinematic model\nInitial Calibration routine\nTransforms between sensors and tracking frames\nPlanning\n\"Virtual rail\" planner - Basic route planner\nControl\nHigh-level motion controller\nLow-level actuator controller\nTele-op interface\nCAN Bus interface\nSimulation\nOSV Sim\nA full fledge vehicle simulator on the Gazebo Simulation Platform\nControl SIL\nA Real-time, Software In the Loop testing environment for high-level controller vaidation.\nOperating Systems and Requirements\nFusionAD is developed on ROS KINETICS and UBUNTU 16.04 LTS. We do not support other version of ROS or Ubuntu at the moment.\nHardware\nSensor Stack\nOne of the goals at SJSU Autonomous Driving is to make autonomy development more accessible and cheaper.\nTherefore, our sensor stack consisted of mainly low-cost and easily attainable sensors.\nGPS\nSwiftNav Piksi Multi RTK\nIMU\nSparkfun Razor 9Dof IMU\nWheel Encoders\nGeneric Incremental Encoder\nCameras\nPi Camera + Raspberry Pi together forms a camera node\nLidar\nVelodyne VLP-16\nComputation\nCurrent computation architecture mimics a distributed system for distributing tasks and loads between the two resource-heavy modules, perception and map-based localization.\nMain Computer\nSpec: i7-7700HQ + GTX 1050 + 16 Gb Ram\nHandles most localization + planning + control computations\n2x Nvidia Jetson TX2\nDedicated to perform image detection computations\nHow to build FusionAD:\nRun: sudo ext_package_build.sh at the root directory to ensure all the prerequisites of the external ROS packages used in this stack are met and installed\nRun: catkin_make at the root directory\nDevelopment\nBranches\nmaster\nMost stable branch\nFusionAD do not recommend performing development from this branch\ndevelop\nContains tested features\nFusionAD recommends performing development on this branch\ntest_deployment\nContains features that are pending to be tested on the vehicle\nFusionAD do not recommend performing development from this branch\nslave_tx2\nContains software for the Jetson TX2 modules\nNot Open for main FusionAD development except for software related to the TX2 board\nrelease_branches\nSealed branch for storing past releases\nNot Open for development\nMaintainers\nThe Core FusionAD team\nFusionAD also appreciate the help of other passionate SJSU students!\nWe would like to acknowledge the following FusionADers:\nJohn Phung\nFusionAD Program and Community Manager\nNelson Wong\nSJSU Autonomous Driving Perception and Localization Engineer\nFrancisco Ibrarra\nSJSU Autonomous Driving Perception Engineer", "link": "https://github.com/SJSU-AD/FusionAD", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "welcome to fusionad\nfusionad is an autonomous driving software stack developed by the sjsu autonomous driving team at san jose state university (sjsu), san jose, ca.\nour challenge is to create a fully functional autonomous driving vehicle within the 1 year timeline of a mechanical engineering senior project at sjsu.\nsee kpix bay area's coverage on sjsu autonomous driving on youtube\nfusionad's software architecture\nthis repository mainly capture the software application layer within fusionad's architecture.\napplication modules\ncurrently, all the modules are under work in progress and they are located under fusionad/src/modules\ncurrent capabilities of the software modules:\nperception\nintegration done with yolo v3 image detector\nlocalization\nekf through robot_localization package\ndead reckoning vehicle kinematic model\ninitial calibration routine\ntransforms between sensors and tracking frames\nplanning\n\"virtual rail\" planner - basic route planner\ncontrol\nhigh-level motion controller\nlow-level actuator controller\ntele-op interface\ncan bus interface\nsimulation\nosv sim\na full fledge vehicle simulator on the gazebo simulation platform\ncontrol sil\na real-time, software in the loop testing environment for high-level controller vaidation.\noperating systems and requirements\nfusionad is developed on ros kinetics and ubuntu 16.04 lts. we do not support other version of ros or ubuntu at the moment.\nhardware\nsensor stack\none of the goals at sjsu autonomous driving is to make autonomy development more accessible and cheaper.\ntherefore, our sensor stack consisted of mainly low-cost and easily attainable sensors.\ngps\nswiftnav piksi multi rtk\nimu\nsparkfun razor 9dof imu\nwheel encoders\ngeneric incremental encoder\ncameras\npi camera + raspberry pi together forms a camera node\nlidar\nvelodyne vlp-16\ncomputation\ncurrent computation architecture mimics a distributed system for distributing tasks and loads between the two resource-heavy modules, perception and map-based localization.\nmain computer\nspec: i7-7700hq + gtx 1050 + 16 gb ram\nhandles most localization + planning + control computations\n2x nvidia jetson tx2\ndedicated to perform image detection computations\nhow to build fusionad:\nrun: sudo ext_package_build.sh at the root directory to ensure all the prerequisites of the external ros packages used in this stack are met and installed\nrun: catkin_make at the root directory\ndevelopment\n-----> branches !!! \nmaster\nmost stable branch\nfusionad do not recommend performing development from this branch\ndevelop\ncontains tested features\nfusionad recommends performing development on this branch\ntest_deployment\ncontains features that are pending to be tested on the vehicle\nfusionad do not recommend performing development from this branch\nslave_tx2\ncontains software for the jetson tx2 modules\nnot open for main fusionad development except for software related to the tx2 board\nrelease_branches\nsealed branch for storing past releases\nnot open for development\nmaintainers\nthe core fusionad team\nfusionad also appreciate the help of other passionate sjsu students!\nwe would like to acknowledge the following fusionaders:\njohn phung\nfusionad program and community manager\nnelson wong\nsjsu autonomous driving perception and localization engineer\nfrancisco ibrarra\nsjsu autonomous driving perception engineer", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000708, "year": null}, {"Unnamed: 0": 1849, "autor": 829, "date": null, "content": "ASCO Aerial Autonomy\nIntroduction\nThe doxygen documentation to the project can be found here.\nSetup\nRun the setup script in scripts/setup/setup.sh to configure Git hooks.\nInstall the following dependencies (lcov, protobuf, doxygen, doxypy, coverxygen, google-glog, class-loader). On Ubuntu 18.04 run the following in a terminal (for different versions of Ubuntu replace melodic with your ROS version)\nsudo apt-get install lcov protobuf-compiler libprotobuf-dev doxygen doxypy libgoogle-glog-dev ros-melodic-class-loader ros-melodic-ar-track-alvar-msgs autoconf python-pip ros-melodic-serial ros-melodic-map-server libarmadillo-dev\nsudo pip install coverxygen\nInstall protobuf 3.1: (Alternatively, protobuf 3.0.0, which is default with ROS Melodic, can be used and these steps can be skipped. Check version with protoc --version)\ngit clone https://github.com/google/protobuf.git\ncd protobuf\ngit checkout v3.1.0\n./autogen.sh\n./configure\nmake\nsudo make install\nsudo ldconfig\nInstall googletest release 1.8.0. This version fixes a bug with ASSERT_TRUE as explained here. To install googletest, follow these steps\ngit clone https://github.com/google/googletest.git\ncd googletest\ngit checkout release-1.8.0\nmkdir build\ncd build\ncmake .. -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=ON -DBUILD_GMOCK=ON -DBUILD_GTEST=ON\nmake\nsudo make install\nsudo ldconfig\nInstall OpenCV with OpenCV Contrib (version must include tracking module). Follow the steps for installing from source here to install from source on Ubuntu 18.04. If a version of OpenCV is already installed on your system you may want to install that version from source. Note: Source code for OpenCV 3.2.0 has an extra else statement on line 21 of cmake/OpenCVCompilerOptions.cmake. This block needs to be removed. The following can be used to check if your system currently has a version of OpenCV installed:\npkg-config --modversion opencv\npython3 -c \"import cv2; print(cv2.version)\"\npython2 -c \"import cv2; print(cv2.version)\"\nInstall our GCOP (Geometric Control, Optimization, and Planning) package. Build with support for casadi (USE_CASADI) and install the dependences from the GCOP README. Do the following after required and optional dependencies from the GCOP README have been installed (Numbers 5 and 6):\ngit clone https://github.com/jhu-asco/gcop.git\ncd gcop\nmkdir build\ncd build\ncmake -DUSE_CASADI=ON ..\nsudo make install\nCreate a ROS workspace. Run the following in your ROS workspace src folder to setup UAV hardware drivers\ngit clone -b hydro-devel https://github.com/jhu-asco/quadcopter_parsers.git\ngit clone -b 3.2.3 https://github.com/jhu-asco/Onboard-SDK-ROS.git\nInstall gcop_comm for trajectory visualization (other packages in the repo can be ignored) in the ROS workspace src folder\ngit clone -b hydro-devel https://github.com/jhu-asco/gcop_ros_packages.git\nOptional: Manipulator packages\nOptionally, to install drivers related to aerial manipulation, run the following in your ROS src folder\ngit clone https://git.lcsr.jhu.edu/mshecke1/arm_plugins.git\ngit clone https://git.lcsr.jhu.edu/ggarime1/controllers.git\ngit clone https://git.lcsr.jhu.edu/ggarime1/dynamixelsdk.git\nBuild\nThis package can be cloned into the same ROS workspace src folder and built with catkin build. Be sure to source the workspace's devel/setup.bash.\nArm Plugins\nBuilding with arm plugins can be turned off by setting the USE_ARM_PLUGINS cmake argument to OFF\ncatkin build -DUSE_ARM_PLUGINS=OFF\nThis is recommended, when arm plugins are not needed, for the code to compile faster and using less system resources.\nRunning Executables\nThe package provides a uav_system_node executable which loads a state machine and hardware and waits for event commands from a ROS topic. The rqt_aerial_autonomy_gui script provides a GUI to generate events for the state machine. The rqt plugin can be loaded along with rqt_rviz in the rqt_gui framework.\nThe simulator.launch file in the launch folder executes the state machine node using simulated hardware. The GUI can be launched individually using rosrun, or with simulator_rqt_aerial_autonomy.launch. The steps to launch a simulated quadrotor with the state machine are\nroslaunch aerial_autonomy simulator.launch\nroslaunch aerial_autonomy simulator_rqt_aerial_autonomy.launch # In a separate tab\nRunning Tests\nTo build and run tests use catkin build aerial_autonomy --catkin-make-args run_tests. Output of individual tests can be checked using rosrun aerial_autonomy test_name. To see all test outputs run catkin run_tests --this.\nLogging\nGLOG is used to log messages from the state machine. The messages are divided into different levels (INFO, WARNING, ERROR, etc.,). The information messages are divided into different verbosity levels (0,1,2 and so on). The verbosity level can be adjusted using the environment variable GLOG_v. If the environment variable is set to 1 (export GLOG_v=1), then all the messages with verbosity 0 and 1 are streamed to stderr output.\nThe log messages are also recorded into log files in the logs folder. The symbolic links uav_system_node.INFO and uav_system_node.WARNING in the log folder point to the latest log files. The log directory can be changed using the GLOG_log_dir environment variable. More information about the log files can be found in the Google Log documentation.\nThe simulator launch file introduced above allows for specifying the log level and log directory using roslaunch arguments log_level and log_dir respectively. For example\nroslaunch aerial_autonomy simulator.launch log_level:=1 # Prints all the verbose log messages with priority 0 and 1.\nStyle\nThis repository uses clang-format for style checking. Pre-commit hooks ensure that all staged files conform to the style conventions. To skip pre-commit hooks and force a commit, use git commit -n.\nDocumentation Coverage\nWe use coverxygen to generate documentation coverage for the doc: https://github.com/psycofdj/coverxygen\nUse the script scripts/generate_documentation_coverage.bash to generate documentation into .documentation_coverage_info folder. Check the html page in .documentation_coverage_info/index.html to verify the documentation coverage of the code.\nDocumentation coverage is also added as a pre-push hook. This verifies that 95% of the code is covered with documentation before pushing to remote. It can be skipped for branches with their name starting with develop* and also by using git push --no-verify command.\nTest Coverage\nWe use lcov to generate the test coverage report into the .test_coverage_info folder. The script scripts/generate_test_coverage.bash is used to run tests in the project and generate test coverage report into .test_coverage_info folder. The script is generated using CMake. Run catkin build aerial_autonomy to create the script. Check the html page .test_coverage_info/index.html to check the line and function coverage. The bash script is generated by running CMake using catkin build aerial_autonomy.\nThe test generation is integrated into the pre-push commit hook. This runs the above test coverage generation script and verifies that the coverage level is above 95% threshold. This can be skipped by either naming the branch as develop[your_branch_name] or using git push --no-verify.\nUploading documentation\nThe documentation is uploaded through gh-pages branch. The docs are created in master and passed to the gh-pages branch using scripts/applydocs.bash script. The script checks that there are not uncommited changes before uploading documentation to avoid issues with git. The script also requires that you explicitly link gh-pages branch to the remote using git branch --set-upstream-to=[GH_PAGES_REMOTE]\nGenerating Visual graphs from state machines\nThe script scripts/generate_dot_files.py converts the transition tables in state machines to dot format and also png format. The script automatically runs through all the state machines stored in the include/aerial_autonomy/state_machines folder.\nUsage: ./generate_dot_files.py\nHand-eye Calibration\nThis section describes how to automatically calibrate a transform from a camera to an arm.\nData Collection\nAttach an AR tag to the end effector of your arm.\nUse rosbag record /ar_pose_marker /your_end_effector_position where /your_end_effector_position is published by your arm driver and gives the position of the end effector in the arm frame (probably based on forward kinematics).\nLaunch ar_track_alvar and move the arm around so that the end effector AR tag is visible in the camera.\nExtract the AR marker data from the bag file to a csv: rostopic echo -b your_data.bag -p --nostr /ar_pose_marker > marker_data.csv\nCalibration script\nUse the matlab script scripts/calib/arm_camera_calib.m along with your_data.bag and marker_data.csv to generate a calibrated transformation. It uses non-linear least squares to find the hand-eye transformation.", "link": "https://github.com/jhu-asco/aerial_autonomy", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "asco aerial autonomy\nintroduction\nthe doxygen documentation to the project can be found here.\nsetup\nrun the setup script in scripts/setup/setup.sh to configure git hooks.\ninstall the following dependencies (lcov, protobuf, doxygen, doxypy, coverxygen, google-glog, class-loader). on ubuntu 18.04 run the following in a terminal (for different versions of ubuntu replace melodic with your ros version)\nsudo apt-get install lcov protobuf-compiler libprotobuf-dev doxygen doxypy libgoogle-glog-dev ros-melodic-class-loader ros-melodic-ar-track-alvar-msgs autoconf python-pip ros-melodic-serial ros-melodic-map-server libarmadillo-dev\nsudo pip install coverxygen\ninstall protobuf 3.1: (alternatively, protobuf 3.0.0, which is default with ros melodic, can be used and these steps can be skipped. check version with protoc --version)\ngit clone https://github.com/google/protobuf.git\ncd protobuf\ngit checkout v3.1.0\n./autogen.sh\n./configure\nmake\nsudo make install\nsudo ldconfig\ninstall googletest release 1.8.0. this version fixes a bug with assert_true as explained here. to install googletest, follow these steps\ngit clone https://github.com/google/googletest.git\ncd googletest\ngit checkout release-1.8.0\nmkdir build\ncd build\ncmake .. -dcmake_build_type=release -dbuild_shared_libs=on -dbuild_gmock=on -dbuild_gtest=on\nmake\nsudo make install\nsudo ldconfig\ninstall opencv with opencv contrib (version must include tracking module). follow the steps for installing from source here to install from source on ubuntu 18.04. if a version of opencv is already installed on your system you may want to install that version from source. note: source code for opencv 3.2.0 has an extra else statement on line 21 of cmake/opencvcompileroptions.cmake. this block needs to be removed. the following can be used to check if your system currently has a version of opencv installed:\npkg-config --modversion opencv\npython3 -c \"import cv2; print(cv2.version)\"\npython2 -c \"import cv2; print(cv2.version)\"\ninstall our gcop (geometric control, optimization, and planning) package. build with support for casadi (use_casadi) and install the dependences from the gcop readme. do the following after required and optional dependencies from the gcop readme have been installed (numbers 5 and 6):\ngit clone https://github.com/jhu-asco/gcop.git\ncd gcop\nmkdir build\ncd build\ncmake -duse_casadi=on ..\nsudo make install\ncreate a ros workspace. run the following in your ros workspace src folder to setup uav hardware drivers\ngit clone -b hydro-devel https://github.com/jhu-asco/quadcopter_parsers.git\ngit clone -b 3.2.3 https://github.com/jhu-asco/onboard-sdk-ros.git\ninstall gcop_comm for trajectory visualization (other packages in the repo can be ignored) in the ros workspace src folder\ngit clone -b hydro-devel https://github.com/jhu-asco/gcop_ros_packages.git\noptional: manipulator packages\noptionally, to install drivers related to aerial manipulation, run the following in your ros src folder\ngit clone https://git.lcsr.jhu.edu/mshecke1/arm_plugins.git\ngit clone https://git.lcsr.jhu.edu/ggarime1/controllers.git\ngit clone https://git.lcsr.jhu.edu/ggarime1/dynamixelsdk.git\nbuild\nthis package can be cloned into the same ros workspace src folder and built with catkin build. be sure to source the workspace's devel/setup.bash.\narm plugins\nbuilding with arm plugins can be turned off by setting the use_arm_plugins cmake argument to off\ncatkin build -duse_arm_plugins=off\nthis is recommended, when arm plugins are not needed, for the code to compile faster and using less system resources.\nrunning executables\nthe package provides a uav_system_node executable which loads a state machine and hardware and waits for event commands from a ros topic. the rqt_aerial_autonomy_gui script provides a gui to generate events for the state machine. the rqt plugin can be loaded along with rqt_rviz in the rqt_gui framework.\nthe simulator.launch file in the launch folder executes the state machine node using simulated hardware. the gui can be launched individually using rosrun, or with simulator_rqt_aerial_autonomy.launch. the steps to launch a simulated quadrotor with the state machine are\nroslaunch aerial_autonomy simulator.launch\nroslaunch aerial_autonomy simulator_rqt_aerial_autonomy.launch # in a separate tab\nrunning tests\nto build and run tests use catkin build aerial_autonomy --catkin-make-args run_tests. output of individual tests can be checked using rosrun aerial_autonomy test_name. to see all test outputs run catkin run_tests --this.\nlogging\nglog is used to log messages from the state machine. the messages are divided into different levels (info, warning, error, etc.,). the information messages are divided into different verbosity levels (0,1,2 and so on). the verbosity level can be adjusted using the environment variable glog_v. if the environment variable is set to 1 (export glog_v=1), then all the messages with verbosity 0 and 1 are streamed to stderr output.\nthe log messages are also recorded into log files in the logs folder. the symbolic links uav_system_node.info and uav_system_node.warning in the log folder point to the latest log files. the log directory can be changed using the glog_log_dir environment variable. more information about the log files can be found in the google log documentation.\nthe simulator launch file introduced above allows for specifying the log level and log directory using roslaunch arguments log_level and log_dir respectively. for example\nroslaunch aerial_autonomy simulator.launch log_level:=1 # prints all the verbose log messages with priority 0 and 1.\nstyle\nthis repository uses clang-format for style checking. pre-commit hooks ensure that all staged files conform to the style conventions. to skip pre-commit hooks and force a commit, use git commit -n.\ndocumentation coverage\nwe use coverxygen to generate documentation coverage for the doc: https://github.com/psycofdj/coverxygen\nuse the script scripts/generate_documentation_coverage.bash to generate documentation into .documentation_coverage_info folder. check the html page in .documentation_coverage_info/index.html to verify the documentation coverage of the code.\ndocumentation coverage is also added as a pre-push hook. this verifies that 95% of the code is covered with documentation before pushing to remote. it can be skipped for -----> branches !!!  with their name starting with develop* and also by using git push --no-verify command.\ntest coverage\nwe use lcov to generate the test coverage report into the .test_coverage_info folder. the script scripts/generate_test_coverage.bash is used to run tests in the project and generate test coverage report into .test_coverage_info folder. the script is generated using cmake. run catkin build aerial_autonomy to create the script. check the html page .test_coverage_info/index.html to check the line and function coverage. the bash script is generated by running cmake using catkin build aerial_autonomy.\nthe test generation is integrated into the pre-push commit hook. this runs the above test coverage generation script and verifies that the coverage level is above 95% threshold. this can be skipped by either naming the branch as develop[your_branch_name] or using git push --no-verify.\nuploading documentation\nthe documentation is uploaded through gh-pages branch. the docs are created in master and passed to the gh-pages branch using scripts/applydocs.bash script. the script checks that there are not uncommited changes before uploading documentation to avoid issues with git. the script also requires that you explicitly link gh-pages branch to the remote using git branch --set-upstream-to=[gh_pages_remote]\ngenerating visual graphs from state machines\nthe script scripts/generate_dot_files.py converts the transition tables in state machines to dot format and also png format. the script automatically runs through all the state machines stored in the include/aerial_autonomy/state_machines folder.\nusage: ./generate_dot_files.py\nhand-eye calibration\nthis section describes how to automatically calibrate a transform from a camera to an arm.\ndata collection\nattach an ar tag to the end effector of your arm.\nuse rosbag record /ar_pose_marker /your_end_effector_position where /your_end_effector_position is published by your arm driver and gives the position of the end effector in the arm frame (probably based on forward kinematics).\nlaunch ar_track_alvar and move the arm around so that the end effector ar tag is visible in the camera.\nextract the ar marker data from the bag file to a csv: rostopic echo -b your_data.bag -p --nostr /ar_pose_marker > marker_data.csv\ncalibration script\nuse the matlab script scripts/calib/arm_camera_calib.m along with your_data.bag and marker_data.csv to generate a calibrated transformation. it uses non-linear least squares to find the hand-eye transformation.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000829, "year": null}, {"Unnamed: 0": 1865, "autor": 845, "date": null, "content": "Description\nInterface (driver) software, including ROS node, for inertial sensors compatible with the Microstrain Communication Library (MSCL).\nMSCL is developed by LORD Sensing - Microstrain in Williston, VT.\nDifferent Codebases\nThis repo is now structured differently as of 2.0.0.\nImportant Branches\nThere are three important branches that you may want to checkout:\nros -- Contains ROS1 implementation for this node as of 2.0.0. This version is being actively updated and supported\nros2 -- Contains ROS2 implementation for this node as of 2.0.0. This version is being actively updated and supported\nmaster -- Contains the most recent ROS1 changes before the transition to 2.0.0. Kept for backwards compatibility, but no longer updated or supported\nBoth the ros and ros2 branches share most of their code by using gis submodules. The following submodules contain most of the actual implementations:\nmicrostrain_inertial_driver_common submoduled in this repo at microstrain_inertial_driver/microstrain_inertial_driver_common\nmicrostrain_inertial_msgs_common submoduled in this repo at microstrain_inertial_msgs/microstrain_inertial_msgs_common\nDifferent Package Names\nPrior to version 2.0.0, this repo contained the following ROS packages:\nros_mscl -- ROS node that will communicate with the devices\nmscl_msgs -- Collection of messages produced by the ros_mscl node\nros_mscl_cpp_example -- Simple subscriber written in C++ that will consume a message produced by ros_mscl\nros_mscl_py_example -- Simple subscriber written in Python that will consume a message produced by ros_mscl\nDue to requirements laid out by the ROS maintainers here, as of version 2.0.0, this repo contains the following ROS packages:\nmicrostrain_inertial_driver -- ROS node that will communicate with the devices\nmicrostrain_inertial_msgs -- Collection of messages produces by the microstrain_inertial_driver node\nmicrostrain_inretial_examples -- Collection of examples that show how to interact with the microstrain_inertial_driver node. Currently contains one simple C++ and python subscriber node\nBuild Instructions\nBuildfarm\nAs of v2.0.5 this package is being built and distributed by the ROS build farm. If you do not need to modify the source, it is recommended to install directly from the buildfarm by running the following commands where ROS_DISTRO is the version of ROS you are using such as melodic or noetic:\nsudo apt-get update && sudo apt-get install ros-ROS_DISTRO-microstrain-inertial-driver\nFor more information on the ROS distros and platforms we support, please see index.ros.org\nSource\nIf you need to modify the source of this repository, or are running on a platform that we do not support, you can build from source by following these instructions\nSubmodules\nThis repo now takes advantage of git submodules in order to share code between ROS versions. When cloning the repo, you should clone with the --recursive flag to get all of the submodules.\nIf you have already cloned the repo, you can checkout the submodules by running git submodule init && git submodule update --recursive from the project directory\nThe CMakeLists.txt will automatically checkout the submodule if it does not exist, but it will not keep it up to date. In order to keep up to date, every time you pull changes you should pull with the --recurse-submodules flag, or alternatively run git submodule update --recursive after you have pulled changes\nMSCL\nMSCL is now installed in the CMakeLists.txt. The version installed can be changed by passing the flag -DMSCL_VERSION=\"62.0.0\"\nIf you already have MSCL installed and want to use your installed version instead of the one automatically downloaded, you can specify the location by passing the flag -DMSCL_DIR=/usr/share/c++-mscl\nWe do our best to keep ROS-MSCL up-to-date with the latest MSCL changes, but sometimes there is a delay. The currently supported version of MSCL is v62.1.2\nBuilding from source\nInstall ROS and create a workspace: Installing and Configuring Your ROS Environment\nMove the entire microstrain_inertial folder (microstrain_inertial_driver, microstrain_inertial_msgs , and microstrain_common for just source) to the your_workspace/src directory.\nLocate and register the ros_mscl package: rospack find microstrain_inertial_driver\nInstall rosdeps for this package: rosdep install --from-paths ~/your_workspace/src --ignore-src -r -y\nBuild your workspace:\ncd ~/your_workspace\ncatkin_make\nsource ~/your_workspace/devel/setup.bash\nThe source command may need to be run in each terminal prior to launching a ROS node.\nLaunch the node and publish data\nThe following command will launch the driver. Keep in mind each instance needs to be run in a separate terminal.\nroslaunch microstrain_inertial_driver microstrain.launch\nOptional launch parameters:\nname: namespace the node will publish messages to, default: gx5\nport: serial port name to connect to the device over, default: /dev/ttyACM0\nbaudrate: baud rate to open the connection with, default: 115200\nimu_rate: sample rate for IMU data (hz), default: 100\ndebug: output debug info? default: false\ndiagnostics: output diagnostic info? default: true\nTo check published topics:\nrostopic list\nExample: Connect to and publish data from two devices simultaneously\nIn two different terminals:\nroslaunch microstrain_inertial_driver microstrain.launch name:=sensor1234\nroslaunch microstrain_inertial_driver microstrain.launch name:=bestSensor port:=/dev/ttyACM1\nThis will launch two nodes that publish data to different namespaces:\nsensor1234, connected over port: /dev/ttyACM0\nbestSensor, connected over port: /dev/ttyACM1\nAn example subscriber node can be found here: Microstrain Examples\nDocker Integration\nVSCode\nThe easiest way to use docker while still using an IDE is to use VSCode as an IDE. Follow the steps below to develop on this repo in a docker container\nInstall the following dependencies:\nVSCode\nDocker\nOpen VSCode and install the following plugins:\nVSCode Docker plugin\nVSCode Remote Containers plugin\nOpen this directory in a container by following this guide\nDue to a bug in the remote container plugin, you will need to refresh the window once it comes up. To do this, type Ctrl+Shift+p and type Reload Window and hit enter. Note that this will have to be repeated every time the container is rebuilt\nOnce the folder is open in VSCode, you can build the project by running Ctrl+Shift+B to trigger a build, or Ctrl+p to open quick open, then type task build and hit enter\nYou can run the project by following this guide\nMake\nIf you are comfortable working from the command line, or want to produce runtime images, the Makefile in the .devcontainer directory can be used to build docker images, run a shell inside the docker images and produce a runtime image. Follow the steps below to setup your environment to use the Makefile\nInstall the following dependencies:\nMake\nDocker\nqemu-user-static (for multiarch builds)\nRun the following command to register the qemu binaries with docker: docker run --rm --privileged multiarch/qemu-user-static:register\nThe Makefile exposes the following tasks. They can all be run from the .devcontainer directory:\nmake build-shell - Builds the docker image and starts a shell session in the image allowing the user to develop and build the ROS project using common commands such as catkin_make\nmake image - Builds the runtim image that contains only the required dependencies and the ROS node. The resulting image is names ros-mscl\nmake clean - Cleans up after the above two tasks\nLicense\nmicrostrain_inertial is released under the MIT License - see the LICENSE file in the source distribution.\nCopyright (c) 2021, Parker Hannifin Corp.", "link": "https://github.com/LORD-MicroStrain/microstrain_inertial", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "description\ninterface (driver) software, including ros node, for inertial sensors compatible with the microstrain communication library (mscl).\nmscl is developed by lord sensing - microstrain in williston, vt.\ndifferent codebases\nthis repo is now structured differently as of 2.0.0.\nimportant -----> branches !!! \nthere are three important -----> branches !!!  that you may want to checkout:\nros -- contains ros1 implementation for this node as of 2.0.0. this version is being actively updated and supported\nros2 -- contains ros2 implementation for this node as of 2.0.0. this version is being actively updated and supported\nmaster -- contains the most recent ros1 changes before the transition to 2.0.0. kept for backwards compatibility, but no longer updated or supported\nboth the ros and ros2 branches share most of their code by using gis submodules. the following submodules contain most of the actual implementations:\nmicrostrain_inertial_driver_common submoduled in this repo at microstrain_inertial_driver/microstrain_inertial_driver_common\nmicrostrain_inertial_msgs_common submoduled in this repo at microstrain_inertial_msgs/microstrain_inertial_msgs_common\ndifferent package names\nprior to version 2.0.0, this repo contained the following ros packages:\nros_mscl -- ros node that will communicate with the devices\nmscl_msgs -- collection of messages produced by the ros_mscl node\nros_mscl_cpp_example -- simple subscriber written in c++ that will consume a message produced by ros_mscl\nros_mscl_py_example -- simple subscriber written in python that will consume a message produced by ros_mscl\ndue to requirements laid out by the ros maintainers here, as of version 2.0.0, this repo contains the following ros packages:\nmicrostrain_inertial_driver -- ros node that will communicate with the devices\nmicrostrain_inertial_msgs -- collection of messages produces by the microstrain_inertial_driver node\nmicrostrain_inretial_examples -- collection of examples that show how to interact with the microstrain_inertial_driver node. currently contains one simple c++ and python subscriber node\nbuild instructions\nbuildfarm\nas of v2.0.5 this package is being built and distributed by the ros build farm. if you do not need to modify the source, it is recommended to install directly from the buildfarm by running the following commands where ros_distro is the version of ros you are using such as melodic or noetic:\nsudo apt-get update && sudo apt-get install ros-ros_distro-microstrain-inertial-driver\nfor more information on the ros distros and platforms we support, please see index.ros.org\nsource\nif you need to modify the source of this repository, or are running on a platform that we do not support, you can build from source by following these instructions\nsubmodules\nthis repo now takes advantage of git submodules in order to share code between ros versions. when cloning the repo, you should clone with the --recursive flag to get all of the submodules.\nif you have already cloned the repo, you can checkout the submodules by running git submodule init && git submodule update --recursive from the project directory\nthe cmakelists.txt will automatically checkout the submodule if it does not exist, but it will not keep it up to date. in order to keep up to date, every time you pull changes you should pull with the --recurse-submodules flag, or alternatively run git submodule update --recursive after you have pulled changes\nmscl\nmscl is now installed in the cmakelists.txt. the version installed can be changed by passing the flag -dmscl_version=\"62.0.0\"\nif you already have mscl installed and want to use your installed version instead of the one automatically downloaded, you can specify the location by passing the flag -dmscl_dir=/usr/share/c++-mscl\nwe do our best to keep ros-mscl up-to-date with the latest mscl changes, but sometimes there is a delay. the currently supported version of mscl is v62.1.2\nbuilding from source\ninstall ros and create a workspace: installing and configuring your ros environment\nmove the entire microstrain_inertial folder (microstrain_inertial_driver, microstrain_inertial_msgs , and microstrain_common for just source) to the your_workspace/src directory.\nlocate and register the ros_mscl package: rospack find microstrain_inertial_driver\ninstall rosdeps for this package: rosdep install --from-paths ~/your_workspace/src --ignore-src -r -y\nbuild your workspace:\ncd ~/your_workspace\ncatkin_make\nsource ~/your_workspace/devel/setup.bash\nthe source command may need to be run in each terminal prior to launching a ros node.\nlaunch the node and publish data\nthe following command will launch the driver. keep in mind each instance needs to be run in a separate terminal.\nroslaunch microstrain_inertial_driver microstrain.launch\noptional launch parameters:\nname: namespace the node will publish messages to, default: gx5\nport: serial port name to connect to the device over, default: /dev/ttyacm0\nbaudrate: baud rate to open the connection with, default: 115200\nimu_rate: sample rate for imu data (hz), default: 100\ndebug: output debug info? default: false\ndiagnostics: output diagnostic info? default: true\nto check published topics:\nrostopic list\nexample: connect to and publish data from two devices simultaneously\nin two different terminals:\nroslaunch microstrain_inertial_driver microstrain.launch name:=sensor1234\nroslaunch microstrain_inertial_driver microstrain.launch name:=bestsensor port:=/dev/ttyacm1\nthis will launch two nodes that publish data to different namespaces:\nsensor1234, connected over port: /dev/ttyacm0\nbestsensor, connected over port: /dev/ttyacm1\nan example subscriber node can be found here: microstrain examples\ndocker integration\nvscode\nthe easiest way to use docker while still using an ide is to use vscode as an ide. follow the steps below to develop on this repo in a docker container\ninstall the following dependencies:\nvscode\ndocker\nopen vscode and install the following plugins:\nvscode docker plugin\nvscode remote containers plugin\nopen this directory in a container by following this guide\ndue to a bug in the remote container plugin, you will need to refresh the window once it comes up. to do this, type ctrl+shift+p and type reload window and hit enter. note that this will have to be repeated every time the container is rebuilt\nonce the folder is open in vscode, you can build the project by running ctrl+shift+b to trigger a build, or ctrl+p to open quick open, then type task build and hit enter\nyou can run the project by following this guide\nmake\nif you are comfortable working from the command line, or want to produce runtime images, the makefile in the .devcontainer directory can be used to build docker images, run a shell inside the docker images and produce a runtime image. follow the steps below to setup your environment to use the makefile\ninstall the following dependencies:\nmake\ndocker\nqemu-user-static (for multiarch builds)\nrun the following command to register the qemu binaries with docker: docker run --rm --privileged multiarch/qemu-user-static:register\nthe makefile exposes the following tasks. they can all be run from the .devcontainer directory:\nmake build-shell - builds the docker image and starts a shell session in the image allowing the user to develop and build the ros project using common commands such as catkin_make\nmake image - builds the runtim image that contains only the required dependencies and the ros node. the resulting image is names ros-mscl\nmake clean - cleans up after the above two tasks\nlicense\nmicrostrain_inertial is released under the mit license - see the license file in the source distribution.\ncopyright (c) 2021, parker hannifin corp.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000845, "year": null}, {"Unnamed: 0": 1986, "autor": 966, "date": null, "content": "Introduction To Electronics\nTOC\nElectrical & Electronics Engineering\nElectronics And Robotics\nThe Microcontroller\nArduino UNO\nCircuit\nTwo Basic Types of Circuits\nTech Terms\nVoltage Vs Amperage\nElectronic Components Used In Our Project\nArduino and TinkerCAD\nElectrical And Electronics Engineering\nElectrical and electronics engineering, the branch of engineering concerned with the practical applications of electricity in all its forms, including those of the field of electronics. Electronics engineering is that branch of electrical engineering concerned with the uses of the electromagnetic spectrum and with the application of such electronic devices as integrated circuits and transistors.\nIn engineering practice, the distinction between electrical engineering and electronics is usually based on the comparative strength of the electric currents used. In this sense, electrical engineering is the branch dealing with \u201cheavy current\u201d\u2014that is, electric light and power systems and apparatuses\u2014whereas electronics engineering deals with such \u201clight current\u201d applications as telephone and radio communication, computers, radar, and automatic control systems.\nsource: https://www.britannica.com/technology/electrical-and-electronics-engineering\nElectronics And Robotics\nElectronic devices can simply be controlled by adding a microcontroller. When we program an electronic device to do specific tasks (particularly with sensors), we are now dealing with robotics.\nThe Microcontroller\nA microcontroller is a compact integrated circuit designed to govern a specific operation in an embedded system. A typical microcontroller includes a processor, memory and input/output (I/O) peripherals on a single chip.\nSometimes referred to as an embedded controller or microcontroller unit (MCU), microcontrollers are found in vehicles, robots, office machines, medical devices, mobile radio transceivers, vending machines and home appliances, among other devices. They are essentially simple miniature personal computers (PCs) designed to control small features of a larger component, without a complex front-end operating system (OS).\nsource: https://internetofthingsagenda.techtarget.com/definition/microcontroller\nArduino UNO\nCircuit\nIn electronics, a circuit is a closed path that allows electricity to flow from one point to another. It may include various electrical components, such as transistors, resistors, and capacitors, but the flow is unimpeded by a gap or break in the circuit.\nsource: https://techterms.com/definition/circuit\nTwo Basic Types of Circuits\nSeries Circuit\na series circuit comprises a path along which the whole current flows through each component.\nParallel Circuit\na parallel circuit comprises branches so that the current divides and only part of it flows through any branch.\nsource: https://www.britannica.com/technology/electric-circuit#ref22644\nTech Terms\nopen circuit - an electrical circuit that is not complete.\nelectric current - the rate at which electric charge flows past a point on the electric circuit.\nground - In electronics and electrical engineering, it is by convention, we define a point in a circuit as a reference point. This reference point is known as ground (or GND) and carries a voltage of 0V. Voltage measurements are relative measurements. That is, a voltage measurement must be compared to another point in the circuit. If it is not, the measurement is meaningless.\nsource: https://www.allaboutcircuits.com/technical-articles/an-introduction-to-ground/\nAn earth ground is when a circuit has a physical connection to the earth, in order to sink electrons, thereby saving lives. When an electrical system has a direct connection to the earth ground (the 3-prong plug: one is positive, one is negative, one is the earth ground prong), instead of the flow of charge going to our bodies in some instances, it will go directly to earth ground.\nsource: http://www.learningaboutelectronics.com/Articles/Why-does-a-circuit-always-have-to-have-ground\nFYI - Even though one side of the circuit is the live wire, you CANNOT simply touch it even there is no apparent neutral wire completing the circuit: you yourself is standing on the earth ground! A bird will not be shocked by landing on a live wire because it is not touching the ground, so even if there is the live wire, there is no return path completing the circuit and there is no electric shock.\nsource: https://www.ibiblio.org/kuphaldt/electricCircuits/DC/DC_3.html\nhot wire (electrical term) - carries the electricity, also called live wire\nterminal - is the point at which a conductor from a component, device or network comes to an end. It is the point other components can be connected.\nVoltage Vs Amperage\nVoltage and amperage are two measures of electrical current or flow of electrons. Voltage is a measure of the pressure that allows electrons to flow, while amperage is a measure of the volume of electrons.\nsource: https://www.thespruce.com/amperage-not-voltage-kills-1152476#:~:text=Voltage%20and%20amperage%20are%20two,of%20the%20volume%20of%20electrons.\nvolt - the SI unit of electromotive force, the difference of potential that would drive one ampere of current against one ohm resistance.\nampere - the SI base unit of electrical current.\nElectronic Components Used In Our Project\nPower Supply - It is the one responsible to power electrical components. We'll be using a Direct Current source, a battery.\nWires\nLight-Emitting Diode - a diode that emits light. A diode is a semiconductor device with two terminals, typically allowing the flow of current in one direction only. A semiconductor is a substance, usually a solid chemical element or compound, that can conduct electricity under some conditions but not others, making it a good medium for the control of electrical current. source: https://whatis.techtarget.com/definition/semiconductor\nSwitch (slide switch) - the component that can disrupt the flow of a circuit, thereby giving us control.\nArduino and TinkerCAD\nArduino is a prototyping platform consisting of both hardware and software. When we say prototyping, we want to create a working model first before we build the actual product, so that we can test first whether our idea will work and to reduce the cost of building the product.\nTinkerCAD is an online simulator for our circuit designs. It's just like you are in a Robotics laboratory and there is the complete setup, but this time, it's just virtual. And since it is accessible through a browser, all you need is a device with a browser and an Internet connection and you are good to go: no further setup, no additional downloads.\nYou can check out my projects:\nhttps://github.com/xdvrx1/single-display-arduino-project\nhttps://github.com/xdvrx1/blinking-led-arduino", "link": "https://github.com/xdvrx1/basic-electronics", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "branches", "selectorShort": "branch", "MarkedSent": "introduction to electronics\ntoc\nelectrical & electronics engineering\nelectronics and robotics\nthe microcontroller\narduino uno\ncircuit\ntwo basic types of circuits\ntech terms\nvoltage vs amperage\nelectronic components used in our project\narduino and tinkercad\nelectrical and electronics engineering\nelectrical and electronics engineering, the branch of engineering concerned with the practical applications of electricity in all its forms, including those of the field of electronics. electronics engineering is that branch of electrical engineering concerned with the uses of the electromagnetic spectrum and with the application of such electronic devices as integrated circuits and transistors.\nin engineering practice, the distinction between electrical engineering and electronics is usually based on the comparative strength of the electric currents used. in this sense, electrical engineering is the branch dealing with \u201cheavy current\u201d\u2014that is, electric light and power systems and apparatuses\u2014whereas electronics engineering deals with such \u201clight current\u201d applications as telephone and radio communication, computers, radar, and automatic control systems.\nsource: https://www.britannica.com/technology/electrical-and-electronics-engineering\nelectronics and robotics\nelectronic devices can simply be controlled by adding a microcontroller. when we program an electronic device to do specific tasks (particularly with sensors), we are now dealing with robotics.\nthe microcontroller\na microcontroller is a compact integrated circuit designed to govern a specific operation in an embedded system. a typical microcontroller includes a processor, memory and input/output (i/o) peripherals on a single chip.\nsometimes referred to as an embedded controller or microcontroller unit (mcu), microcontrollers are found in vehicles, robots, office machines, medical devices, mobile radio transceivers, vending machines and home appliances, among other devices. they are essentially simple miniature personal computers (pcs) designed to control small features of a larger component, without a complex front-end operating system (os).\nsource: https://internetofthingsagenda.techtarget.com/definition/microcontroller\narduino uno\ncircuit\nin electronics, a circuit is a closed path that allows electricity to flow from one point to another. it may include various electrical components, such as transistors, resistors, and capacitors, but the flow is unimpeded by a gap or break in the circuit.\nsource: https://techterms.com/definition/circuit\ntwo basic types of circuits\nseries circuit\na series circuit comprises a path along which the whole current flows through each component.\nparallel circuit\na parallel circuit comprises -----> branches !!!  so that the current divides and only part of it flows through any branch.\nsource: https://www.britannica.com/technology/electric-circuit#ref22644\ntech terms\nopen circuit - an electrical circuit that is not complete.\nelectric current - the rate at which electric charge flows past a point on the electric circuit.\nground - in electronics and electrical engineering, it is by convention, we define a point in a circuit as a reference point. this reference point is known as ground (or gnd) and carries a voltage of 0v. voltage measurements are relative measurements. that is, a voltage measurement must be compared to another point in the circuit. if it is not, the measurement is meaningless.\nsource: https://www.allaboutcircuits.com/technical-articles/an-introduction-to-ground/\nan earth ground is when a circuit has a physical connection to the earth, in order to sink electrons, thereby saving lives. when an electrical system has a direct connection to the earth ground (the 3-prong plug: one is positive, one is negative, one is the earth ground prong), instead of the flow of charge going to our bodies in some instances, it will go directly to earth ground.\nsource: http://www.learningaboutelectronics.com/articles/why-does-a-circuit-always-have-to-have-ground\nfyi - even though one side of the circuit is the live wire, you cannot simply touch it even there is no apparent neutral wire completing the circuit: you yourself is standing on the earth ground! a bird will not be shocked by landing on a live wire because it is not touching the ground, so even if there is the live wire, there is no return path completing the circuit and there is no electric shock.\nsource: https://www.ibiblio.org/kuphaldt/electriccircuits/dc/dc_3.html\nhot wire (electrical term) - carries the electricity, also called live wire\nterminal - is the point at which a conductor from a component, device or network comes to an end. it is the point other components can be connected.\nvoltage vs amperage\nvoltage and amperage are two measures of electrical current or flow of electrons. voltage is a measure of the pressure that allows electrons to flow, while amperage is a measure of the volume of electrons.\nsource: https://www.thespruce.com/amperage-not-voltage-kills-1152476#:~:text=voltage%20and%20amperage%20are%20two,of%20the%20volume%20of%20electrons.\nvolt - the si unit of electromotive force, the difference of potential that would drive one ampere of current against one ohm resistance.\nampere - the si base unit of electrical current.\nelectronic components used in our project\npower supply - it is the one responsible to power electrical components. we'll be using a direct current source, a battery.\nwires\nlight-emitting diode - a diode that emits light. a diode is a semiconductor device with two terminals, typically allowing the flow of current in one direction only. a semiconductor is a substance, usually a solid chemical element or compound, that can conduct electricity under some conditions but not others, making it a good medium for the control of electrical current. source: https://whatis.techtarget.com/definition/semiconductor\nswitch (slide switch) - the component that can disrupt the flow of a circuit, thereby giving us control.\narduino and tinkercad\narduino is a prototyping platform consisting of both hardware and software. when we say prototyping, we want to create a working model first before we build the actual product, so that we can test first whether our idea will work and to reduce the cost of building the product.\ntinkercad is an online simulator for our circuit designs. it's just like you are in a robotics laboratory and there is the complete setup, but this time, it's just virtual. and since it is accessible through a browser, all you need is a device with a browser and an internet connection and you are good to go: no further setup, no additional downloads.\nyou can check out my projects:\nhttps://github.com/xdvrx1/single-display-arduino-project\nhttps://github.com/xdvrx1/blinking-led-arduino", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000966, "year": null}], "name": "branchrobotics"}