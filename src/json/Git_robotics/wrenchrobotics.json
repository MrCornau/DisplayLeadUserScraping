{"interestingcomments": [{"Unnamed: 0": 1026, "autor": 6, "date": null, "content": "JPL Open Source Rover Project\nThe JPL Open Source Rover is an open source, build it yourself, scaled down version of the 6 wheel rover design that JPL uses to explore the surface of Mars. The Open Source Rover is designed almost entirely out of consumer off the shelf (COTS) parts. This project is intended to be a teaching and learning experience for those who want to get involved in mechanical engineering, software, electronics, or robotics.\nA gallery of some community builds can be found here.\nAbout the Project\nMotivation\nJPL is always looking to inspire the next generation of scientists, engineers, and roboticists to help us explore and learn about our solar system (and beyond!). We release the plans for this rover as a way to try and give budding enthusiasts a fun robotics project that will help teach them and get them involved in robotics sooner and at a lower cost.\nSpecifications & Technical Attributes\nThe specific attributes of the robot you build will depend slightly on the type of electronics and motors you buy for the system. The numbers shown below are for the version of the robot that contains exactly the parts that we suggest in our build documents and parts list. Below, you can see which parts could be changed for which spec upgrades.\nAttribute Value [imperial] Value [SI]\nWeight 28 [lbs] 12.7 [kg]\nFootprint 24x14 [in] 60.96x30.48 [cm]\nBattery Capacity 5200 [mAh] 5200 [mAh]\nBattery Discharge Rate 8 [A] 8 [A]\nNominal Current Draw 1.2 [A] 1.2 [A]\nOperating time 5 [hrs] (continual use) 5 [hrs] (continual use)\nApproximate Max speed 68.8 [in/s] 1.75 [m/s]\nMaximum 90 deg vertical scale 12 [in] 30.48 [cm]\nMaximum height differential between sides 14 [in] 35.56 [cm]\nCommunication (in this guide) Bluetooth app (Android only) and Xbox Controller\nCost (*) ~ $2,500\nAgain, the above statistics depend on which components you select when buying parts. One potential change is for the motors; you can, for example, select higher RPM motors (to drive your rover faster) at the sacrifice of max stall torque, which would potentially limit your rover's ability to climb. A selection of motors that would integrate easily with the rest of the suggested rover design can be found at GoBilda.\n(*) Other open-source, cheaper alternatives exist but are slower, less strong, and are more fragile. See Additional Projects.\nCommunication\nIn addition to this repository which holds all the documentation for this project, there are two additional websites tied to this project. One is a landing site which holds general information and an overview of the rover and how it works:\nWe have a few ways to connect with the team and community of Open Source Rover builders:\nSlack (Preferred method)\nTapaTalk - JPL Open Source Rover (Tapatalk is being monitored less since the addition of Slack, that's the easiest way to reach many of us now)\nWe also use Github Discussions\nNote: JPL and Caltech have no official affiliation with this forum; it is run by individuals of the general public. On these you can ask questions if you need help or clarification on any aspects of the project. Additionally, you can post and promote any modifications or addons that you have created on this project. We highly encourage additions and modifications to be posted so that this project and community can grow.\nFeatures\nThis rover is designed to function similarly to the 6 wheel rover designs on Mars and employs a few of the major driving mechanics that the mars rovers use to traverse rocky surfaces:\nRocker-Bogie: The Rocker-Bogie suspension system allows all 6 wheels to continually be in contact with the ground while climbing over obstacles\nDifferential Pivot: Allows weight to be mechanically offloaded from one side of the rover to the other while climbing\n6-Wheel Ackerman Steering: Driving and steering/turning mechanism that governs where the wheels point and how fast each of them will move.\nWe chose a Raspberry Pi to be the \"brain\" of this rover for its versatility, accessibility, simplicity, and ability to add and upgrade your own modifications. Any method with which you can communicate with a Raspberry Pi (bluetooth, WiFi, USB devices, etc) can be interfaced into the control system of the robot.\nIn addition, here are the open communication ports and hardware on the Raspberry Pi:\n4 USB ports (3 if using Xbox controller)\nRPi Camera port\n1 I2C Bus (0 if using LED Matrix screen)\n2 SPI Bus (1 if using LED Matrix screen)\n3.5mm Audio Jack\n13 GPIO pins (6 if using LED Matrix screen)\nUsing the above ports, you could theoretically drive the rover autonomously from the camera, via a USB dongle attached to anything (your own video game controller, a USB microphone, or many others... be creative!), or through any interface using the Pi's GPIO ports (distance sensors, accelerometers, and much more). We've only given you two simple ways to control the rover to start... we want you to come up with even more!\nFor the power system of the rover, there is also ample spare power which can be used for your own addons and upgrades. See the Electrical subsystem documentation for more specific details.\nMaintenance Status\nAs an open-source hardware project, the rover is continuously improving. Please check ongoing projects, issues, pull requests, and the forum (see below) to see if any big changes are expected soon.\nOnline 3D Model\nThere is also an Onshape model of the Open Source Rover. The model includes the state of the rover at each individual step throughout our build instructions! Therefore, you should be able to reference the online 3D model in addition to the photos in the build instructions as you are building to ensure your build is going well. NOTE: The most updated model and single source of truth are the SolidWorks assemblies and the OnShape model may be out of date.\nRover Mission Patch\nThank you to Lauren Schooley for creating a mission patch for the project. The patch is free for use as a team patch, for stickers, or decorating your rover. The design is released under the Creative Commons Attribution-NoDerivatives public license. A variety of file formats is available.\nMission Patch\nSkills Necessary\nThis project has elements in mechanical assembly/fabrication, uses a host of electrical components, and has software that will run it all. In order to complete this project, you will need to have some experience in the following:\nFabrication/Machining: Although most the parts are COTS there are a few modifications necessary to adapt them to the project. These modifications will be in the form of\nMetal cutting using band saw/dremel\nDrilling using drill press/hand drill\nFiling and sanding for part cleanup\nGeneral Fabrication/Machining Safety\nElectronics: This project uses components like motors, motor controllers, and batteries. It will be important to have experience with the following electrical processes.\nSoldering\nElectrical debugging\nWiring\nElectrical Safety\nSoftware: The rover's brain is a Raspberry Pi. All code can be found in the osr-rover-code repository along with step-by-step instructions to set it up. Basic familiarity with Linux, ROS, and Python will be helpful though.\nMost of the above are skills that you can learn and pick up fairly quickly from watching videos and doing research on the internet, and throughout the project we try to give supplemental information on some of these as well. See the build documents for more information.\nTools Necessary\nThis project assumes you have some standard tools to help assemble the project. If you do not have any of the optional tools, we provide examples of online services that you can use to have the parts fabricated and sent to you.\nMandatory tools\nSAE Hex Key set\nSAE Wrench set\nPliers\nWire Snips\nWire Strippers\nSolder Iron\nSolder\nDigital Multimeter\nHand Drill or Drill Press\nDremel, Band saw, or hand saw\nItems for operating a Raspberry Pi (Keyboard, mouse, monitor, 5V micro USB power adapter)\nWire strippers, e.g. these\nOptional Tools\n3D printer\nLaser Cutter\nPower Supply (to test without using battery)\nExpected time commitment\nIn our experience, this project takes no less than 200 person-hours to build, and depending on the familiarity and skill level of those involved could be significantly more. Experienced builders may be able to build this project in this amount of time. However, this project is generally meant to be a teaching and learning tool. Throughout the documentation, we try to give supplemental information for those who might be new to this kind of project.\nDisclaimer\nReference herein to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise, does not constitute or imply its endorsement by the United States Government or the Jet Propulsion Laboratory, California Institute of Technology. Government sponsorship acknowledged.\nBy downloading, cloning, or otherwise using the contents of this repository, you agree to the terms specified in the attached DISCLAIMER.txt file.\nGetting Started\nOrdering parts\nParts Lists\nThe Master Parts List contains all the parts necessary to build the entirety of the robot as it is listed in our documentation. We recognize that you may want to change, add, and redesign some sections, so each of the individual build sections also contain a parts list for that corresponding section of the project. Note that these individual parts list recommend buying quantities necessary only for that section. Be sure to assess the quantities you need for common items (particularly screws, nuts, bolts, and other common hardware) if you are changing subassemblies.\nCart Share\nIn order to help this ordering process we have compiled a few links of a large number of these together already, if you wish to build exactly what is in our build documentation. Note that some of these parts might not be available or outdated. Please check the master parts list for the most up-to-date list of items.\nMcMaster Amazon Pololu Adafruit\nElectronics\nThe easiest way to buy the electronics parts is to use the links (to e.g. Digikey) on the Kitspace pages:\ncontrol-board\narduino-shield\nAnother way to order from Digikey is to upload the Digikey Bill of Materials at Digikey.com.\n3D printing and Laser cutting\nIn addition to ordering all of the parts on the parts list, we recommend that some pieces be 3D printed and laser cut. If you do not have access to a 3D printer or laser cutter, we've added some online services as examples for where you can get those manufactured and shipped to you. You'll find instructions on this in the Body Build Doc, Corner Steering Build Doc, and Head Assembly Build Doc.\nPrinted Circuit Boards (PCBs)\nThe main electrical system of this rover relies on a custom printed circuit board (PCB) that handles the routing between the majority of the electrical components. This board greatly simplifies the build process and eliminates the need for you to route all the wires yourself. You can find the PCB board files at PCB Files.\nThe easiest way to order the PCBs is through the links (to e.g JLCPCB) on the Kitspace pages:\ncontrol-board\narduino-shield\nYou can also download the \"Gerber\" files there (a typical file format for PCBs) and upload them to any other PCB service that doesn't have a direct link on Kitspace.\nRover Build Roadmap\nAbove is an example roadmap of how you can build the rover and which parts of the build are dependent on the other sections. It is broken down into 5 stages:\nStage 1: Start getting all the parts!\nStage 2: Once you have all the parts, everything in stage 2 can be completed in parallel. It is highly recommended to start on the electrical testing of components outside the robot before doing any electrical work inside the completed robot body. You can also work on the software at any stage between here and the end.\nStage 3: During stage 3, the mechanical subassemblies should all be assembled and start to be integrated together. There should be some amount of testing done on the electrical system, as well as some progress on the software.\nStage 4: The rover is mechanically built and all subassemblies integrated together. During stage 4, you begin the integration of the electrical components and the various power and data wires that run throughout the rover.\nStage 5: Once the electronics are all powered and communicating, you need to test and calibrate all the motors in the system.\nStage 6: After everything has been tested and calibrated and the software is up and running, the robot will be fully functioning and built!\nStage 7: Add your own upgrades! We chose Raspberry Pi as the brain of the project so that it should be easy to add, change, and upgrade to build exciting things on top of this already cool robot. Some upgrade ideas to get you brainstorming: sonar for collision detection, IMU for orientation / closed-loop driving / obstacle mapping, camera for object identification and tracking, sensor packages (temperature, pressure, humidity), solar panels, or even a robotic arm!\nGetting help / joining the community\nIf you have any questions or run into problems during your build, please search for answers and/or reach out on Github Discussions. Please also take a look at the list of open issues. If you think there is an error or a part is missing, please create a new issue.\nProject Team\nThese were the original creators of this project. Now, this open-source repository is run by volunteer maintainers from the community.\nProject Lead:\nMichael (Mik) Cox\nDevelopment Team:\nEric Junkins and Olivia Lofaro\nSpecial Thanks To:\nMagdy Bareh, Michelle Viotti, Tom Soderstrom, Dave Gallagher, Jim Rinaldi, Molly Bittner, Christine Fuller, Billy Allen, and Charles Dandino\nAdditional Projects!\nWe recognize that there might be a some individuals, hobbyists, and groups that might be hesitant or unable to build the Open Source Rover due to skills/tools necessary, or budgetary constraints. Here are some other open-source alternatives.\nSawppy Rover\nESA ExoMy", "link": "https://github.com/nasa-jpl/open-source-rover", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "wrench", "selectorShort": "wrench", "MarkedSent": "jpl open source rover project\nthe jpl open source rover is an open source, build it yourself, scaled down version of the 6 wheel rover design that jpl uses to explore the surface of mars. the open source rover is designed almost entirely out of consumer off the shelf (cots) parts. this project is intended to be a teaching and learning experience for those who want to get involved in mechanical engineering, software, electronics, or robotics.\na gallery of some community builds can be found here.\nabout the project\nmotivation\njpl is always looking to inspire the next generation of scientists, engineers, and roboticists to help us explore and learn about our solar system (and beyond!). we release the plans for this rover as a way to try and give budding enthusiasts a fun robotics project that will help teach them and get them involved in robotics sooner and at a lower cost.\nspecifications & technical attributes\nthe specific attributes of the robot you build will depend slightly on the type of electronics and motors you buy for the system. the numbers shown below are for the version of the robot that contains exactly the parts that we suggest in our build documents and parts list. below, you can see which parts could be changed for which spec upgrades.\nattribute value [imperial] value [si]\nweight 28 [lbs] 12.7 [kg]\nfootprint 24x14 [in] 60.96x30.48 [cm]\nbattery capacity 5200 [mah] 5200 [mah]\nbattery discharge rate 8 [a] 8 [a]\nnominal current draw 1.2 [a] 1.2 [a]\noperating time 5 [hrs] (continual use) 5 [hrs] (continual use)\napproximate max speed 68.8 [in/s] 1.75 [m/s]\nmaximum 90 deg vertical scale 12 [in] 30.48 [cm]\nmaximum height differential between sides 14 [in] 35.56 [cm]\ncommunication (in this guide) bluetooth app (android only) and xbox controller\ncost (*) ~ $2,500\nagain, the above statistics depend on which components you select when buying parts. one potential change is for the motors; you can, for example, select higher rpm motors (to drive your rover faster) at the sacrifice of max stall torque, which would potentially limit your rover's ability to climb. a selection of motors that would integrate easily with the rest of the suggested rover design can be found at gobilda.\n(*) other open-source, cheaper alternatives exist but are slower, less strong, and are more fragile. see additional projects.\ncommunication\nin addition to this repository which holds all the documentation for this project, there are two additional websites tied to this project. one is a landing site which holds general information and an overview of the rover and how it works:\nwe have a few ways to connect with the team and community of open source rover builders:\nslack (preferred method)\ntapatalk - jpl open source rover (tapatalk is being monitored less since the addition of slack, that's the easiest way to reach many of us now)\nwe also use github discussions\nnote: jpl and caltech have no official affiliation with this forum; it is run by individuals of the general public. on these you can ask questions if you need help or clarification on any aspects of the project. additionally, you can post and promote any modifications or addons that you have created on this project. we highly encourage additions and modifications to be posted so that this project and community can grow.\nfeatures\nthis rover is designed to function similarly to the 6 wheel rover designs on mars and employs a few of the major driving mechanics that the mars rovers use to traverse rocky surfaces:\nrocker-bogie: the rocker-bogie suspension system allows all 6 wheels to continually be in contact with the ground while climbing over obstacles\ndifferential pivot: allows weight to be mechanically offloaded from one side of the rover to the other while climbing\n6-wheel ackerman steering: driving and steering/turning mechanism that governs where the wheels point and how fast each of them will move.\nwe chose a raspberry pi to be the \"brain\" of this rover for its versatility, accessibility, simplicity, and ability to add and upgrade your own modifications. any method with which you can communicate with a raspberry pi (bluetooth, wifi, usb devices, etc) can be interfaced into the control system of the robot.\nin addition, here are the open communication ports and hardware on the raspberry pi:\n4 usb ports (3 if using xbox controller)\nrpi camera port\n1 i2c bus (0 if using led matrix screen)\n2 spi bus (1 if using led matrix screen)\n3.5mm audio jack\n13 gpio pins (6 if using led matrix screen)\nusing the above ports, you could theoretically drive the rover autonomously from the camera, via a usb dongle attached to anything (your own video game controller, a usb microphone, or many others... be creative!), or through any interface using the pi's gpio ports (distance sensors, accelerometers, and much more). we've only given you two simple ways to control the rover to start... we want you to come up with even more!\nfor the power system of the rover, there is also ample spare power which can be used for your own addons and upgrades. see the electrical subsystem documentation for more specific details.\nmaintenance status\nas an open-source hardware project, the rover is continuously improving. please check ongoing projects, issues, pull requests, and the forum (see below) to see if any big changes are expected soon.\nonline 3d model\nthere is also an onshape model of the open source rover. the model includes the state of the rover at each individual step throughout our build instructions! therefore, you should be able to reference the online 3d model in addition to the photos in the build instructions as you are building to ensure your build is going well. note: the most updated model and single source of truth are the solidworks assemblies and the onshape model may be out of date.\nrover mission patch\nthank you to lauren schooley for creating a mission patch for the project. the patch is free for use as a team patch, for stickers, or decorating your rover. the design is released under the creative commons attribution-noderivatives public license. a variety of file formats is available.\nmission patch\nskills necessary\nthis project has elements in mechanical assembly/fabrication, uses a host of electrical components, and has software that will run it all. in order to complete this project, you will need to have some experience in the following:\nfabrication/machining: although most the parts are cots there are a few modifications necessary to adapt them to the project. these modifications will be in the form of\nmetal cutting using band saw/dremel\ndrilling using drill press/hand drill\nfiling and sanding for part cleanup\ngeneral fabrication/machining safety\nelectronics: this project uses components like motors, motor controllers, and batteries. it will be important to have experience with the following electrical processes.\nsoldering\nelectrical debugging\nwiring\nelectrical safety\nsoftware: the rover's brain is a raspberry pi. all code can be found in the osr-rover-code repository along with step-by-step instructions to set it up. basic familiarity with linux, ros, and python will be helpful though.\nmost of the above are skills that you can learn and pick up fairly quickly from watching videos and doing research on the internet, and throughout the project we try to give supplemental information on some of these as well. see the build documents for more information.\ntools necessary\nthis project assumes you have some standard tools to help assemble the project. if you do not have any of the optional tools, we provide examples of online services that you can use to have the parts fabricated and sent to you.\nmandatory tools\nsae hex key set\nsae -----> wrench !!!  set\npliers\nwire snips\nwire strippers\nsolder iron\nsolder\ndigital multimeter\nhand drill or drill press\ndremel, band saw, or hand saw\nitems for operating a raspberry pi (keyboard, mouse, monitor, 5v micro usb power adapter)\nwire strippers, e.g. these\noptional tools\n3d printer\nlaser cutter\npower supply (to test without using battery)\nexpected time commitment\nin our experience, this project takes no less than 200 person-hours to build, and depending on the familiarity and skill level of those involved could be significantly more. experienced builders may be able to build this project in this amount of time. however, this project is generally meant to be a teaching and learning tool. throughout the documentation, we try to give supplemental information for those who might be new to this kind of project.\ndisclaimer\nreference herein to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise, does not constitute or imply its endorsement by the united states government or the jet propulsion laboratory, california institute of technology. government sponsorship acknowledged.\nby downloading, cloning, or otherwise using the contents of this repository, you agree to the terms specified in the attached disclaimer.txt file.\ngetting started\nordering parts\nparts lists\nthe master parts list contains all the parts necessary to build the entirety of the robot as it is listed in our documentation. we recognize that you may want to change, add, and redesign some sections, so each of the individual build sections also contain a parts list for that corresponding section of the project. note that these individual parts list recommend buying quantities necessary only for that section. be sure to assess the quantities you need for common items (particularly screws, nuts, bolts, and other common hardware) if you are changing subassemblies.\ncart share\nin order to help this ordering process we have compiled a few links of a large number of these together already, if you wish to build exactly what is in our build documentation. note that some of these parts might not be available or outdated. please check the master parts list for the most up-to-date list of items.\nmcmaster amazon pololu adafruit\nelectronics\nthe easiest way to buy the electronics parts is to use the links (to e.g. digikey) on the kitspace pages:\ncontrol-board\narduino-shield\nanother way to order from digikey is to upload the digikey bill of materials at digikey.com.\n3d printing and laser cutting\nin addition to ordering all of the parts on the parts list, we recommend that some pieces be 3d printed and laser cut. if you do not have access to a 3d printer or laser cutter, we've added some online services as examples for where you can get those manufactured and shipped to you. you'll find instructions on this in the body build doc, corner steering build doc, and head assembly build doc.\nprinted circuit boards (pcbs)\nthe main electrical system of this rover relies on a custom printed circuit board (pcb) that handles the routing between the majority of the electrical components. this board greatly simplifies the build process and eliminates the need for you to route all the wires yourself. you can find the pcb board files at pcb files.\nthe easiest way to order the pcbs is through the links (to e.g jlcpcb) on the kitspace pages:\ncontrol-board\narduino-shield\nyou can also download the \"gerber\" files there (a typical file format for pcbs) and upload them to any other pcb service that doesn't have a direct link on kitspace.\nrover build roadmap\nabove is an example roadmap of how you can build the rover and which parts of the build are dependent on the other sections. it is broken down into 5 stages:\nstage 1: start getting all the parts!\nstage 2: once you have all the parts, everything in stage 2 can be completed in parallel. it is highly recommended to start on the electrical testing of components outside the robot before doing any electrical work inside the completed robot body. you can also work on the software at any stage between here and the end.\nstage 3: during stage 3, the mechanical subassemblies should all be assembled and start to be integrated together. there should be some amount of testing done on the electrical system, as well as some progress on the software.\nstage 4: the rover is mechanically built and all subassemblies integrated together. during stage 4, you begin the integration of the electrical components and the various power and data wires that run throughout the rover.\nstage 5: once the electronics are all powered and communicating, you need to test and calibrate all the motors in the system.\nstage 6: after everything has been tested and calibrated and the software is up and running, the robot will be fully functioning and built!\nstage 7: add your own upgrades! we chose raspberry pi as the brain of the project so that it should be easy to add, change, and upgrade to build exciting things on top of this already cool robot. some upgrade ideas to get you brainstorming: sonar for collision detection, imu for orientation / closed-loop driving / obstacle mapping, camera for object identification and tracking, sensor packages (temperature, pressure, humidity), solar panels, or even a robotic arm!\ngetting help / joining the community\nif you have any questions or run into problems during your build, please search for answers and/or reach out on github discussions. please also take a look at the list of open issues. if you think there is an error or a part is missing, please create a new issue.\nproject team\nthese were the original creators of this project. now, this open-source repository is run by volunteer maintainers from the community.\nproject lead:\nmichael (mik) cox\ndevelopment team:\neric junkins and olivia lofaro\nspecial thanks to:\nmagdy bareh, michelle viotti, tom soderstrom, dave gallagher, jim rinaldi, molly bittner, christine fuller, billy allen, and charles dandino\nadditional projects!\nwe recognize that there might be a some individuals, hobbyists, and groups that might be hesitant or unable to build the open source rover due to skills/tools necessary, or budgetary constraints. here are some other open-source alternatives.\nsawppy rover\nesa exomy", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000006, "year": null}, {"Unnamed: 0": 1300, "autor": 280, "date": null, "content": "GraspIt!\nIntroduction\nPlease see the User Manual found at http://graspit-simulator.github.io/ for an introduction to GraspIt!, a list of features, installation instructions, getting started examples, etc.\nDistribution Contents\nCMakeLists.txt: Used to compile GraspIt!, multiple flags that can be set with ccmake.\nCMakeMacros: contains .cmake files used to find GraspIt! dependencies.\ncmdline: command line parser used by GraspIt!.\nci: contains scripts used by travis ci.\ndoc: Documentation. Contains both the User Manual and code Reference Manual. The User Manual contains installation instructions, pointers for getting started, examples, and trouble shooting and contact information.\nimages: A place to put images saved from GraspIt!\ninclude: Header files for the main GraspIt! source code\nLICENSE.txt: A copy of the license you accepted when you downloaded this.\nmodels: The geometry and configuration files for all the robots and objects.\nplugins: Examples for creating plugins that can be loaded into GraspIt! at run time, and can use GraspIt! without being statically linked into GraspIt's main executable.\nply: Code for loading .ply files; see header files for authorship information and detail.\nqhull: A popular package for computing n-dimensional convex hulls. This is used both for the contact system and to create grasp wrench spaces.\nREADME.md: This file.\nsrc: The source code for GraspIt!.\nsrc/DBase: source code for the interface between GraspIt and the Columbia Grasp Database\ntinyxml: a library for processing XML documents. See the header files therein for license and author information for this package.\nui: The dialog windows and interfaces for GraspIt!.\nworlds: A place to save GraspIt! worlds. Also includes a few examples.\nExamples of How to Integrate GraspIt! into your own Project\nhttps://github.com/graspit-simulator/graspit_interface\nhttps://github.com/JenniferBuehler/graspit-pkgs\nhttps://github.com/ros-interactive-manipulation/graspit_simulator\nhttps://github.com/OSUrobotics/graspit_ros_plannings", "link": "https://github.com/graspit-simulator/graspit", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "wrench", "selectorShort": "wrench", "MarkedSent": "graspit!\nintroduction\nplease see the user manual found at http://graspit-simulator.github.io/ for an introduction to graspit!, a list of features, installation instructions, getting started examples, etc.\ndistribution contents\ncmakelists.txt: used to compile graspit!, multiple flags that can be set with ccmake.\ncmakemacros: contains .cmake files used to find graspit! dependencies.\ncmdline: command line parser used by graspit!.\nci: contains scripts used by travis ci.\ndoc: documentation. contains both the user manual and code reference manual. the user manual contains installation instructions, pointers for getting started, examples, and trouble shooting and contact information.\nimages: a place to put images saved from graspit!\ninclude: header files for the main graspit! source code\nlicense.txt: a copy of the license you accepted when you downloaded this.\nmodels: the geometry and configuration files for all the robots and objects.\nplugins: examples for creating plugins that can be loaded into graspit! at run time, and can use graspit! without being statically linked into graspit's main executable.\nply: code for loading .ply files; see header files for authorship information and detail.\nqhull: a popular package for computing n-dimensional convex hulls. this is used both for the contact system and to create grasp -----> wrench !!!  spaces.\nreadme.md: this file.\nsrc: the source code for graspit!.\nsrc/dbase: source code for the interface between graspit and the columbia grasp database\ntinyxml: a library for processing xml documents. see the header files therein for license and author information for this package.\nui: the dialog windows and interfaces for graspit!.\nworlds: a place to save graspit! worlds. also includes a few examples.\nexamples of how to integrate graspit! into your own project\nhttps://github.com/graspit-simulator/graspit_interface\nhttps://github.com/jenniferbuehler/graspit-pkgs\nhttps://github.com/ros-interactive-manipulation/graspit_simulator\nhttps://github.com/osurobotics/graspit_ros_plannings", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000280, "year": null}, {"Unnamed: 0": 1410, "autor": 390, "date": null, "content": "ros2_control Demos\nThis repository provides templates for the development of ros2_control-enabled robots and a simple simulations to demonstrate and prove ros2_control concepts.\nGoals\nThe repository has three goals:\nImplements the example configuration described in the ros-controls/roadmap repository file components_architecture_and_urdf_examples.\nIt provides templates for faster implementation of custom hardware and controllers;\nThe repository is a validation environment for ros2_control concepts, which can only be tested during run-time (e.g., execution of controllers by the controller manager, communication between robot hardware and controllers).\nDescription\nThe repository is inspired by the ros_control_boilerplate repository from Dave Coleman. The examples have three parts/packages according to usual structure of ROS packages for robots:\nThe bringup package ros2_control_demo_bringup, holds launch files and runtime configurations for demo robots.\nDescription packages rrbot_description and diffbot_description (inside ros2_control_demo_description), store URDF-description files, rviz configurations and meshes for the demo robots.\nHardware interface package ros2_control_demo_hardware, implements the hardware interfaces described in the roadmap.\nThe examples of RRBot and DiffBot are trivial simulations to demonstrate and test ros2_control concepts. This package does not have any dependencies except ros2 core packages and can, therefore, be used on SoC-hardware or headless systems.\nThis repository demonstrates the following ros2_control concepts:\nCreating a *HardwareInterface for a System, Sensor, and Actuator.\nCreating a robot description in the form of URDF files.\nLoading the configuration and starting a robot using launch files.\nControl of a differential mobile base DiffBot.\nControl of two joints of RRBot.\nUsing simulated robots and starting ros2_control with Gazebo simulator.\nImplementing a controller switching strategy for a robot.\nUsing joint limits and transmission concepts in ros2_control.\nQuick Hints\nThese are some quick hints, especially for those coming from a ROS1 control background:\nThere are now three categories of hardware components: Sensor, Actuator, and System. Sensor is for individual sensors; Actuator is for individual actuators; System is for any combination of multiple sensors/actuators. You could think of a Sensor as read-only. All components are used as plugins and therefore exported using PLUGINLIB_EXPORT_CLASS macro.\nros(1)_control only allowed three hardware interface types: position, velocity, and effort. ros2_control allows you to create any interface type by defining a custom string. For example, you might define a position_in_degrees or a temperature interface. The most common (position, velocity, acceleration, effort) are already defined as constants in hardware_interface/types/hardware_interface_type_values.hpp.\nJoint names in <ros2_control> tags in the URDF must be compatible with the controller's configuration.\nIn ros2_control, all parameters for the driver are specified in the URDF. The ros2_control framework uses the <ros2_control> tag in the URDF.\nJoint names in <ros2_control> tags in the URDF must be compatible with the controller's configuration.\nBuild from source\ngit clone https://github.com/ros-controls/ros2_control\ngit clone https://github.com/ros-controls/ros2_controllers\ngit clone https://github.com/ros-controls/ros2_control_demos\nNOTE: ros2_control and ros2_controllers packages are released for foxy and can be installed using a package manager. We provide officially released and maintained debian packages, which can easily be installed via aptitude. However, there might be cases in which not-yet released demos or features are only available through a source build in your own workspace.\nInstall dependencies:\nrosdep install --from-paths src --ignore-src -r -y\nBuild everything, e.g. with:\ncolcon build --symlink-install\nDo not forget to source setup.bash from the install folder!\nGetting Started with demos\nThis repository provides the following simple example robots: a 2 degrees of freedom manipulator - RRBot - and a mobile differential drive base - DiffBot. The first two examples demonstrate the minimal setup for those two robots to run. Later examples show more details about ros2_control-concepts and some more advanced use-cases.\nRRBot\nRRBot, or ''Revolute-Revolute Manipulator Robot'', is a simple 3-linkage, 2-joint arm that we will use to demonstrate various features. It is essentially a double inverted pendulum and demonstrates some fun control concepts within a simulator and was originally introduced for Gazebo tutorials. The RRBot URDF files can be found in the urdf folder of rrbot_description package.\nTo check that RRBot descriptions are working properly use following launch commands:\nRRBot\nros2 launch rrbot_description view_robot.launch.py\nNOTE: Getting the following output in terminal is OK: Warning: Invalid frame ID \"odom\" passed to canTransform argument target_frame - frame does not exist. This happens because joint_state_publisher_gui node need some time to start. The joint_state_publisher_gui provides a GUI to generate a random configuration for rrbot. It is immediately displayed in Rviz.\nTo start RRBot example open open a terminal, source your ROS2-workspace and execute its launch file with:\nros2 launch ros2_control_demo_bringup rrbot.launch.py\nThe launch file loads and starts the robot hardware, controllers and opens RViz. In starting terminal you will see a lot of output from the hardware implementation showing its internal states. This is only of exemplary purpuses and should be avoided as much as possible in a hardware interface implementation.\nIf you can see two orange and one yellow rectangle in in RViz everything has started properly. Still, to be sure, let's introspect the control system before moving RRBot.\nCheck if the hardware interface loaded properly, by opening another terminal and executing:\nros2 control list_hardware_interfaces\nYou should get:\ncommand interfaces\njoint1/position [claimed]\njoint2/position [claimed]\nstate interfaces\njoint1/position\njoint2/position\nMarker [claimed] by command interfaces means that a controller has access to command RRBot.\nCheck is controllers are running:\nros2 control list_controllers\nYou should get:\njoint_state_broadcaster[joint_state_broadcaster/JointStateBroadcaster] active\nforward_position_controller[forward_command_controller/ForwardCommandController] active\nIf you get output from above you can send commands to Forward Command Controller, either:\na. Manually using ros2 cli interface:\nros2 topic pub /position_commands std_msgs/msg/Float64MultiArray \"data:\n- 0.5\n- 0.5\"\nB. Or you can start a demo node which sends two goals every 5 seconds in a loop:\nros2 launch ros2_control_demo_bringup test_forward_position_controller.launch.py\nYou should now see orange and yellow blocks moving in RViz. Also, you should see changing states in the terminal where launch file is started.\nFiles used for this demos:\nLaunch file: rrbot.launch.py\nControllers yaml: rrbot_controllers.yaml\nURDF file: rrbot.urdf.xacro\nDescription: rrbot_description.urdf.xacro\nros2_control tag: rrbot.ros2_control.xacro\nRViz configuration: rrbot.rviz\nHardware interface plugin: rrbot_system_position_only.cpp\nControllers from this demo:\nJoint State Broadcaster (ros2_controllers repository): doc\nForward Command Controller (ros2_controllers repository): doc\nDiffBot\nDiffBot, or ''Differential Mobile Robot'', is a simple mobile base with differential drive. The robot is basically a box moving according to differential drive kinematics. The DiffBot URDF files can be found in urdf folder of diffbot_description package.\nTo check that DiffBot description is working properly use following launch commands:\nros2 launch diffbot_description view_robot.launch.py\nNOTE: Getting the following output in terminal is OK: Warning: Invalid frame ID \"odom\" passed to canTransform argument target_frame - frame does not exist. This happens because joint_state_publisher_gui node need some time to start.\nTo start DiffBot example open a terminal, source your ROS2-workspace and execute its launch file with:\nros2 launch ros2_control_demo_bringup diffbot.launch.py\nThe launch file loads and starts the robot hardware, controllers and opens RViz. In the starting terminal you will see a lot of output from the hardware implementation showing its internal states. This excessive printing is only added for demonstration. In general, printing to the terminal should be avoided as much as possible in a hardware interface implementation.\nIf you can see an orange box in RViz everything has started properly. Still, to be sure, let's introspect the control system before moving DiffBot.\nCheck if the hardware interface loaded properly, by opening another terminal and executing:\nros2 control list_hardware_interfaces\nYou should get:\ncommand interfaces\nleft_wheel_joint/velocity [claimed]\nright_wheel_joint/velocity [claimed]\nstate interfaces\nleft_wheel_joint/position\nleft_wheel_joint/velocity\nright_wheel_joint/position\nright_wheel_joint/velocity\nThe [claimed] marker on command interfaces means that a controller has access to command DiffBot.\nCheck if controllers are running:\nros2 control list_controllers\nYou should get:\ndiffbot_base_controller[diff_drive_controller/DiffDriveController] active\njoint_state_broadcaster[joint_state_broadcaster/JointStateBroadcaster] active\nIf everything is fine, now you can send a command to Diff Drive Controller using ros2 cli interface:\nros2 topic pub --rate 30 /cmd_vel geometry_msgs/msg/Twist \"linear:\nx: 0.7\ny: 0.0\nz: 0.0\nangular:\nx: 0.0\ny: 0.0\nz: 1.0\"\nYou should now see an orange box circling in RViz. Also, you should see changing states in the terminal where launch file is started.\nFiles used for this demos:\nLaunch file: diffbot.launch.py\nControllers yaml: diffbot_controllers.yaml\nURDF file: diffbot.urdf.xacro\nDescription: diffbot_description.urdf.xacro\nros2_control tag: diffbot.ros2_control.xacro\nRViz configuration: diffbot.rviz\nHardware interface plugin: diffbot_system.cpp\nControllers from this demo:\nJoint State Broadcaster (ros2_controllers repository): doc\nDiff Drive Controller (ros2_controllers repository): doc\nExamples of ros2_control concepts\nEach of the described example cases from the roadmap has its own launch and URDF file.\nGeneral notes about examples\nEach example is started with a single launch file which starts up the robot hardware, loads controller configurations and it also opens RViz.\nThe RViz setup can be recreated following these steps:\nThe robot models can be visualized using RobotModel display using /robot_description topic.\nOr you can simply open the configuration from rviz folder in rrbot_description or diffbot_description package manually or directly by executing:\nrviz2 --display-config `ros2 pkg prefix rrbot_description`/share/rrbot_description/config/rrbot.rviz\nTo check that robot descriptions are working properly use following launch commands:\nros2 launch rrbot_description view_robot.launch.py\nOptional arguments for specific example (the robot visualization will be the same for all examples):\ndescription_file:=rrbot_system_multi_interface.urdf.xacro\nNOTE: Getting the following output in terminal is OK: Warning: Invalid frame ID \"odom\" passed to canTransform argument target_frame - frame does not exist. This happens because joint_state_publisher_gui node need some time to start.\nTo start an example open a terminal, source your ROS2-workspace and execute a launch file with:\nros2 launch ros2_control_demo_bringup <example_launch_file>\nTo stop RViz2 from auto-start use start_rviz:=false launch file argument.\nTo check if the hardware interface loaded properly, open another terminal and execute:\nros2 control list_hardware_interfaces\nYou should get something like:\ncommand interfaces\njoint1/position [unclaimed]\njoint2/position [unclaimed]\nstate interfaces\njoint1/position\njoint2/position\nCheck which controllers are running using:\nros2 control list_controllers\nYou should get something like:\nforward_position_controller[forward_command_controller/ForwardCommandController] unconfigured\njoint_state_broadcaster[joint_state_broadcaster/JointStateBroadcaster] active\nCheck Controllers and moving hardware section to move RRBot.\nNOTE: The examples reuse the same, configurable base-launch file rrbot_base.launch.py. This also demonstrates how launch files are usually reused for different scenarios when working with ros2_control.\nExample 1: \"Industrial Robots with only one interface\"\nFiles:\nLaunch file: rrbot_system_position_only.launch.py\nControllers yaml: rrbot_controllers.yaml\nros2_control URDF tag: rrbot_system_position_only.ros2_control.xacro\nInterfaces:\nCommand interfaces:\njoint1/position\njoint2/position\nState interfaces:\njoint1/position\njoint2/position\nAvailable controllers:\njoint_state_broadcaster[joint_state_broadcaster/JointStateBroadcaster]\nforward_position_controller[forward_command_controller/ForwardCommandController] (position)\nMoving the robot:\nsee below description of forward_position_controller\nAvailable launch file options:\nuse_fake_hardware:=true - start FakeSystem instead of hardware. This is a simple simulation that mimics joint command to their states. This is useful to test ros2_control integration and controllers without physical hardware.\nExample 1-Sim: \"Industrial Robots with only one interface\" (Gazebo simulation)\nTBA\nExample 2: \"Robots with multiple interfaces\"\nFiles:\nLaunch file: rrbot_system_multi_interface.launch.py\nControllers yaml: rrbot_multi_interface_forward_controllers.yaml\nros2_control URDF tag: rrbot_system_multi_interface.ros2_control.xacro\nInterfaces:\nCommand interfaces:\njoint1/position\njoint2/position\njoint1/velocity\njoint2/velocity\njoint1/acceleration\njoint2/acceleration\nState interfaces:\njoint1/position\njoint2/position\njoint1/velocity\njoint2/velocity\njoint1/acceleration\njoint2/acceleration\nAvailable controllers:\njoint_state_broadcaster[joint_state_broadcaster/JointStateBroadcaster]\nforward_position_controller[position_controllers/JointGroupPositionController]\nforward_velocity_controller[velocity_controllers/JointGroupVelocityController]\nforward_acceleration_controller[forward_command_controller/ForwardCommandController]\nforward_illegal1_controller[forward_command_controller/ForwardCommandController]\nforward_illegal2_controller[forward_command_controller/ForwardCommandController]\nNotes:\nThe example shows how to implement multi-interface robot hardware taking care about interfaces used. The two illegal controllers demonstrate how hardware interface declines faulty claims to access joint command interfaces.\nMoving the robot:\nwhen using velocity controller:\nros2 topic pub /forward_velocity_controller/commands std_msgs/msg/Float64MultiArray \"data:\n- 5\n- 5\"\nwhen using acceleration controller\nros2 topic pub /forward_acceleration_controller/commands std_msgs/msg/Float64MultiArray \"data:\n- 10\n- 10\"\nUseful launch-file options:\nrobot_controller:=forward_position_controller - starts demo and spawns position controller. Robot can be then controlled using forward_position_controller as described below.\nrobot_controller:=forward_acceleration_controller - starts demo and spawns acceleration controller. Robot can be then controlled using forward_acceleration_controller as described below.\nExample 3: \"Industrial robot with integrated sensor\"\nLaunch file: rrbot_system_with_sensor.launch.py\nURDF: rrbot_system_with_sensor.urdf.xacro\nros2_control URDF: rrbot_system_with_sensor.ros2_control.xacro\nCommand interfaces:\njoint1/position\njoint2/position\nState interfaces:\njoint1/position\njoint2/position\ntcp_fts_sensor/force.x\ntcp_fts_sensor/torque.z\nAvailable controllers:\nforward_position_controller[forward_command_controller/ForwardCommandController]\nfts_broadcaster[force_torque_sensor_broadcaster/ForceTorqueSensorBroadcaster]\njoint_state_broadcaster[joint_state_broadcaster/JointStateBroadcaster]\nNotes:\nWrench messages are may not be displayed properly in Rviz as NaN values are not handled in Rviz and FTS Broadcaster may send NaN values.\nCommanding the robot: see the commands below.\nAccessing Wrench data from 2D FTS:\nros2 topic echo /fts_broadcaster/wrench\nExample 4: \"Industrial Robots with externally connected sensor\"\nLaunch file: rrbot_system_with_external_sensor.launch.py\nURDF: rrbot_with_external_sensor_controllers.urdf.xacro\nros2_control URDF: external_rrbot_force_torque_sensor.ros2_control.xacro\nCommand interfaces:\njoint1/position\njoint2/position\nState interfaces:\njoint1/position\njoint2/position\ntcp_fts_sensor/force.x\ntcp_fts_sensor/force.y\ntcp_fts_sensor/force.z\ntcp_fts_sensor/torque.x\ntcp_fts_sensor/torque.y\ntcp_fts_sensor/torque.z\nAvailable controllers:\nforward_position_controller[forward_command_controller/ForwardCommandController]\nfts_broadcaster[force_torque_sensor_broadcaster/ForceTorqueSensorBroadcaster]\njoint_state_broadcaster[joint_state_broadcaster/JointStateBroadcaster]\nCommanding the robot: see the commands below.\nAccessing Wrench data from 2D FTS:\nros2 topic echo /fts_broadcaster/wrench\nExample 5: \"Modular Robots with separate communication to each actuator\"\nLaunch file: rrbot_modular_actuators.launch.py\nURDF: rrbot_modular_actuators.urdf.xacro\nros2_control URDF: rrbot_modular_actuators.ros2_control.xacro\nCommand interfaces:\njoint1/position\njoint2/position\nState interfaces:\njoint1/position\njoint2/position\nAvailable controllers:\nforward_position_controller[forward_command_controller/ForwardCommandController]\njoint_state_broadcaster[joint_state_broadcaster/JointStateBroadcaster]\nCommanding the robot: see the commands below.\nControllers and moving hardware\nTo move the robot you should load and start controllers. The JointStateController is used to publish the joint states to ROS topics. Direct joint commands are sent to this robot via the ForwardCommandController and JointTrajectoryController. The sections below describe their usage. Check the Results section on how to ensure that things went well.\nNOTE: Before doing any action with controllers check their state using command:\nros2 control list_controllers\nJointStateController\nOpen another terminal and load, configure and start joint_state_controller:\nros2 control set_controller_state joint_state_controller start\nCheck if controller is loaded properly:\nros2 control list_controllers\nYou should get the response:\njoint_state_controller[joint_state_controller/JointStateController] active\nNow you should also see the RRbot represented correctly in RViz.\nUsing ForwardCommandController\nIf you want to test hardware with ForwardCommandController first load a controller (not always needed):\nros2 control load_controller forward_position_controller\nCheck if the controller is loaded properly:\nros2 control list_controllers\nThen configure it:\nros2 control set_controller_state forward_position_controller configure\nCheck if the controller is loaded properly:\nros2 control list_controllers\nYou should get the response:\nforward_position_controller[forward_command_controller/ForwardCommandController] inactive\nNow start the controller:\nros2 control switch_controllers --start forward_position_controller\nCheck if controllers are activated:\nros2 control list_controllers\nYou should get active in the response:\njoint_state_controller[joint_state_controller/JointStateController] active\nforward_position_controller[forward_command_controller/ForwardCommandController] active\nSend a command to the controller, either:\na. Manually using ros2 cli interface:\nros2 topic pub /forward_position_controller/commands std_msgs/msg/Float64MultiArray \"data:\n- 0.5\n- 0.5\"\nB. Or you can start a demo node which sends two goals every 5 seconds in a loop:\nros2 launch ros2_control_demo_bringup test_forward_position_controller.launch.py\nYou can adjust the goals in rrbot_forward_position_publisher.yaml.\nUsing JointTrajectoryController\nIf you want to test hardware with JointTrajectoryController first load and configure a controller (not always needed):\nros2 control load_controller position_trajectory_controller --set-state configure\nCheck if the controller is loaded and configured properly:\nros2 control list_controllers\nYou should get the response:\nposition_trajectory_controller[joint_trajectory_controller/JointTrajectoryController] inactive\nNow start the controller (and stop other running contorller):\nros2 control switch_controllers --stop forward_position_controller --start position_trajectory_controller\nCheck if controllers are activated:\nros2 control list_controllers\nYou should get active in the response:\njoint_state_controller[joint_state_controller/JointStateController] active\nposition_trajectory_controller[joint_trajectory_controller/JointTrajectoryController] active\nSend a command to the controller using demo node which sends two goals every 5 seconds in a loop:\nros2 launch ros2_control_demo_bringup test_forward_position_controller.launch.py\nYou can adjust the goals in rrbot_joint_trajectory_publisher.yaml.\nResult\nIndependently from the controller you should see how the example's output changes. Look for the following lines\n[RRBotSystemPositionOnlyHardware]: Got state 0.0 for joint 0!\n[RRBotSystemPositionOnlyHardware]: Got state 0.0 for joint 1!\nIf you echo the /joint_states or /dynamic_joint_states topics you should also get similar values.\nros2 topic echo /joint_states\nros2 topic echo /dynamic_joint_states\nYou should also see the RRbot moving in RViz.", "link": "https://github.com/ros-controls/ros2_control_demos", "origin": "Github", "suborigin": "robotics", "result": true, "Selector": "wrench", "selectorShort": "wrench", "MarkedSent": "ros2_control demos\nthis repository provides templates for the development of ros2_control-enabled robots and a simple simulations to demonstrate and prove ros2_control concepts.\ngoals\nthe repository has three goals:\nimplements the example configuration described in the ros-controls/roadmap repository file components_architecture_and_urdf_examples.\nit provides templates for faster implementation of custom hardware and controllers;\nthe repository is a validation environment for ros2_control concepts, which can only be tested during run-time (e.g., execution of controllers by the controller manager, communication between robot hardware and controllers).\ndescription\nthe repository is inspired by the ros_control_boilerplate repository from dave coleman. the examples have three parts/packages according to usual structure of ros packages for robots:\nthe bringup package ros2_control_demo_bringup, holds launch files and runtime configurations for demo robots.\ndescription packages rrbot_description and diffbot_description (inside ros2_control_demo_description), store urdf-description files, rviz configurations and meshes for the demo robots.\nhardware interface package ros2_control_demo_hardware, implements the hardware interfaces described in the roadmap.\nthe examples of rrbot and diffbot are trivial simulations to demonstrate and test ros2_control concepts. this package does not have any dependencies except ros2 core packages and can, therefore, be used on soc-hardware or headless systems.\nthis repository demonstrates the following ros2_control concepts:\ncreating a *hardwareinterface for a system, sensor, and actuator.\ncreating a robot description in the form of urdf files.\nloading the configuration and starting a robot using launch files.\ncontrol of a differential mobile base diffbot.\ncontrol of two joints of rrbot.\nusing simulated robots and starting ros2_control with gazebo simulator.\nimplementing a controller switching strategy for a robot.\nusing joint limits and transmission concepts in ros2_control.\nquick hints\nthese are some quick hints, especially for those coming from a ros1 control background:\nthere are now three categories of hardware components: sensor, actuator, and system. sensor is for individual sensors; actuator is for individual actuators; system is for any combination of multiple sensors/actuators. you could think of a sensor as read-only. all components are used as plugins and therefore exported using pluginlib_export_class macro.\nros(1)_control only allowed three hardware interface types: position, velocity, and effort. ros2_control allows you to create any interface type by defining a custom string. for example, you might define a position_in_degrees or a temperature interface. the most common (position, velocity, acceleration, effort) are already defined as constants in hardware_interface/types/hardware_interface_type_values.hpp.\njoint names in <ros2_control> tags in the urdf must be compatible with the controller's configuration.\nin ros2_control, all parameters for the driver are specified in the urdf. the ros2_control framework uses the <ros2_control> tag in the urdf.\njoint names in <ros2_control> tags in the urdf must be compatible with the controller's configuration.\nbuild from source\ngit clone https://github.com/ros-controls/ros2_control\ngit clone https://github.com/ros-controls/ros2_controllers\ngit clone https://github.com/ros-controls/ros2_control_demos\nnote: ros2_control and ros2_controllers packages are released for foxy and can be installed using a package manager. we provide officially released and maintained debian packages, which can easily be installed via aptitude. however, there might be cases in which not-yet released demos or features are only available through a source build in your own workspace.\ninstall dependencies:\nrosdep install --from-paths src --ignore-src -r -y\nbuild everything, e.g. with:\ncolcon build --symlink-install\ndo not forget to source setup.bash from the install folder!\ngetting started with demos\nthis repository provides the following simple example robots: a 2 degrees of freedom manipulator - rrbot - and a mobile differential drive base - diffbot. the first two examples demonstrate the minimal setup for those two robots to run. later examples show more details about ros2_control-concepts and some more advanced use-cases.\nrrbot\nrrbot, or ''revolute-revolute manipulator robot'', is a simple 3-linkage, 2-joint arm that we will use to demonstrate various features. it is essentially a double inverted pendulum and demonstrates some fun control concepts within a simulator and was originally introduced for gazebo tutorials. the rrbot urdf files can be found in the urdf folder of rrbot_description package.\nto check that rrbot descriptions are working properly use following launch commands:\nrrbot\nros2 launch rrbot_description view_robot.launch.py\nnote: getting the following output in terminal is ok: warning: invalid frame id \"odom\" passed to cantransform argument target_frame - frame does not exist. this happens because joint_state_publisher_gui node need some time to start. the joint_state_publisher_gui provides a gui to generate a random configuration for rrbot. it is immediately displayed in rviz.\nto start rrbot example open open a terminal, source your ros2-workspace and execute its launch file with:\nros2 launch ros2_control_demo_bringup rrbot.launch.py\nthe launch file loads and starts the robot hardware, controllers and opens rviz. in starting terminal you will see a lot of output from the hardware implementation showing its internal states. this is only of exemplary purpuses and should be avoided as much as possible in a hardware interface implementation.\nif you can see two orange and one yellow rectangle in in rviz everything has started properly. still, to be sure, let's introspect the control system before moving rrbot.\ncheck if the hardware interface loaded properly, by opening another terminal and executing:\nros2 control list_hardware_interfaces\nyou should get:\ncommand interfaces\njoint1/position [claimed]\njoint2/position [claimed]\nstate interfaces\njoint1/position\njoint2/position\nmarker [claimed] by command interfaces means that a controller has access to command rrbot.\ncheck is controllers are running:\nros2 control list_controllers\nyou should get:\njoint_state_broadcaster[joint_state_broadcaster/jointstatebroadcaster] active\nforward_position_controller[forward_command_controller/forwardcommandcontroller] active\nif you get output from above you can send commands to forward command controller, either:\na. manually using ros2 cli interface:\nros2 topic pub /position_commands std_msgs/msg/float64multiarray \"data:\n- 0.5\n- 0.5\"\nb. or you can start a demo node which sends two goals every 5 seconds in a loop:\nros2 launch ros2_control_demo_bringup test_forward_position_controller.launch.py\nyou should now see orange and yellow blocks moving in rviz. also, you should see changing states in the terminal where launch file is started.\nfiles used for this demos:\nlaunch file: rrbot.launch.py\ncontrollers yaml: rrbot_controllers.yaml\nurdf file: rrbot.urdf.xacro\ndescription: rrbot_description.urdf.xacro\nros2_control tag: rrbot.ros2_control.xacro\nrviz configuration: rrbot.rviz\nhardware interface plugin: rrbot_system_position_only.cpp\ncontrollers from this demo:\njoint state broadcaster (ros2_controllers repository): doc\nforward command controller (ros2_controllers repository): doc\ndiffbot\ndiffbot, or ''differential mobile robot'', is a simple mobile base with differential drive. the robot is basically a box moving according to differential drive kinematics. the diffbot urdf files can be found in urdf folder of diffbot_description package.\nto check that diffbot description is working properly use following launch commands:\nros2 launch diffbot_description view_robot.launch.py\nnote: getting the following output in terminal is ok: warning: invalid frame id \"odom\" passed to cantransform argument target_frame - frame does not exist. this happens because joint_state_publisher_gui node need some time to start.\nto start diffbot example open a terminal, source your ros2-workspace and execute its launch file with:\nros2 launch ros2_control_demo_bringup diffbot.launch.py\nthe launch file loads and starts the robot hardware, controllers and opens rviz. in the starting terminal you will see a lot of output from the hardware implementation showing its internal states. this excessive printing is only added for demonstration. in general, printing to the terminal should be avoided as much as possible in a hardware interface implementation.\nif you can see an orange box in rviz everything has started properly. still, to be sure, let's introspect the control system before moving diffbot.\ncheck if the hardware interface loaded properly, by opening another terminal and executing:\nros2 control list_hardware_interfaces\nyou should get:\ncommand interfaces\nleft_wheel_joint/velocity [claimed]\nright_wheel_joint/velocity [claimed]\nstate interfaces\nleft_wheel_joint/position\nleft_wheel_joint/velocity\nright_wheel_joint/position\nright_wheel_joint/velocity\nthe [claimed] marker on command interfaces means that a controller has access to command diffbot.\ncheck if controllers are running:\nros2 control list_controllers\nyou should get:\ndiffbot_base_controller[diff_drive_controller/diffdrivecontroller] active\njoint_state_broadcaster[joint_state_broadcaster/jointstatebroadcaster] active\nif everything is fine, now you can send a command to diff drive controller using ros2 cli interface:\nros2 topic pub --rate 30 /cmd_vel geometry_msgs/msg/twist \"linear:\nx: 0.7\ny: 0.0\nz: 0.0\nangular:\nx: 0.0\ny: 0.0\nz: 1.0\"\nyou should now see an orange box circling in rviz. also, you should see changing states in the terminal where launch file is started.\nfiles used for this demos:\nlaunch file: diffbot.launch.py\ncontrollers yaml: diffbot_controllers.yaml\nurdf file: diffbot.urdf.xacro\ndescription: diffbot_description.urdf.xacro\nros2_control tag: diffbot.ros2_control.xacro\nrviz configuration: diffbot.rviz\nhardware interface plugin: diffbot_system.cpp\ncontrollers from this demo:\njoint state broadcaster (ros2_controllers repository): doc\ndiff drive controller (ros2_controllers repository): doc\nexamples of ros2_control concepts\neach of the described example cases from the roadmap has its own launch and urdf file.\ngeneral notes about examples\neach example is started with a single launch file which starts up the robot hardware, loads controller configurations and it also opens rviz.\nthe rviz setup can be recreated following these steps:\nthe robot models can be visualized using robotmodel display using /robot_description topic.\nor you can simply open the configuration from rviz folder in rrbot_description or diffbot_description package manually or directly by executing:\nrviz2 --display-config `ros2 pkg prefix rrbot_description`/share/rrbot_description/config/rrbot.rviz\nto check that robot descriptions are working properly use following launch commands:\nros2 launch rrbot_description view_robot.launch.py\noptional arguments for specific example (the robot visualization will be the same for all examples):\ndescription_file:=rrbot_system_multi_interface.urdf.xacro\nnote: getting the following output in terminal is ok: warning: invalid frame id \"odom\" passed to cantransform argument target_frame - frame does not exist. this happens because joint_state_publisher_gui node need some time to start.\nto start an example open a terminal, source your ros2-workspace and execute a launch file with:\nros2 launch ros2_control_demo_bringup <example_launch_file>\nto stop rviz2 from auto-start use start_rviz:=false launch file argument.\nto check if the hardware interface loaded properly, open another terminal and execute:\nros2 control list_hardware_interfaces\nyou should get something like:\ncommand interfaces\njoint1/position [unclaimed]\njoint2/position [unclaimed]\nstate interfaces\njoint1/position\njoint2/position\ncheck which controllers are running using:\nros2 control list_controllers\nyou should get something like:\nforward_position_controller[forward_command_controller/forwardcommandcontroller] unconfigured\njoint_state_broadcaster[joint_state_broadcaster/jointstatebroadcaster] active\ncheck controllers and moving hardware section to move rrbot.\nnote: the examples reuse the same, configurable base-launch file rrbot_base.launch.py. this also demonstrates how launch files are usually reused for different scenarios when working with ros2_control.\nexample 1: \"industrial robots with only one interface\"\nfiles:\nlaunch file: rrbot_system_position_only.launch.py\ncontrollers yaml: rrbot_controllers.yaml\nros2_control urdf tag: rrbot_system_position_only.ros2_control.xacro\ninterfaces:\ncommand interfaces:\njoint1/position\njoint2/position\nstate interfaces:\njoint1/position\njoint2/position\navailable controllers:\njoint_state_broadcaster[joint_state_broadcaster/jointstatebroadcaster]\nforward_position_controller[forward_command_controller/forwardcommandcontroller] (position)\nmoving the robot:\nsee below description of forward_position_controller\navailable launch file options:\nuse_fake_hardware:=true - start fakesystem instead of hardware. this is a simple simulation that mimics joint command to their states. this is useful to test ros2_control integration and controllers without physical hardware.\nexample 1-sim: \"industrial robots with only one interface\" (gazebo simulation)\ntba\nexample 2: \"robots with multiple interfaces\"\nfiles:\nlaunch file: rrbot_system_multi_interface.launch.py\ncontrollers yaml: rrbot_multi_interface_forward_controllers.yaml\nros2_control urdf tag: rrbot_system_multi_interface.ros2_control.xacro\ninterfaces:\ncommand interfaces:\njoint1/position\njoint2/position\njoint1/velocity\njoint2/velocity\njoint1/acceleration\njoint2/acceleration\nstate interfaces:\njoint1/position\njoint2/position\njoint1/velocity\njoint2/velocity\njoint1/acceleration\njoint2/acceleration\navailable controllers:\njoint_state_broadcaster[joint_state_broadcaster/jointstatebroadcaster]\nforward_position_controller[position_controllers/jointgrouppositioncontroller]\nforward_velocity_controller[velocity_controllers/jointgroupvelocitycontroller]\nforward_acceleration_controller[forward_command_controller/forwardcommandcontroller]\nforward_illegal1_controller[forward_command_controller/forwardcommandcontroller]\nforward_illegal2_controller[forward_command_controller/forwardcommandcontroller]\nnotes:\nthe example shows how to implement multi-interface robot hardware taking care about interfaces used. the two illegal controllers demonstrate how hardware interface declines faulty claims to access joint command interfaces.\nmoving the robot:\nwhen using velocity controller:\nros2 topic pub /forward_velocity_controller/commands std_msgs/msg/float64multiarray \"data:\n- 5\n- 5\"\nwhen using acceleration controller\nros2 topic pub /forward_acceleration_controller/commands std_msgs/msg/float64multiarray \"data:\n- 10\n- 10\"\nuseful launch-file options:\nrobot_controller:=forward_position_controller - starts demo and spawns position controller. robot can be then controlled using forward_position_controller as described below.\nrobot_controller:=forward_acceleration_controller - starts demo and spawns acceleration controller. robot can be then controlled using forward_acceleration_controller as described below.\nexample 3: \"industrial robot with integrated sensor\"\nlaunch file: rrbot_system_with_sensor.launch.py\nurdf: rrbot_system_with_sensor.urdf.xacro\nros2_control urdf: rrbot_system_with_sensor.ros2_control.xacro\ncommand interfaces:\njoint1/position\njoint2/position\nstate interfaces:\njoint1/position\njoint2/position\ntcp_fts_sensor/force.x\ntcp_fts_sensor/torque.z\navailable controllers:\nforward_position_controller[forward_command_controller/forwardcommandcontroller]\nfts_broadcaster[force_torque_sensor_broadcaster/forcetorquesensorbroadcaster]\njoint_state_broadcaster[joint_state_broadcaster/jointstatebroadcaster]\nnotes:\n-----> wrench !!!  messages are may not be displayed properly in rviz as nan values are not handled in rviz and fts broadcaster may send nan values.\ncommanding the robot: see the commands below.\naccessing wrench data from 2d fts:\nros2 topic echo /fts_broadcaster/wrench\nexample 4: \"industrial robots with externally connected sensor\"\nlaunch file: rrbot_system_with_external_sensor.launch.py\nurdf: rrbot_with_external_sensor_controllers.urdf.xacro\nros2_control urdf: external_rrbot_force_torque_sensor.ros2_control.xacro\ncommand interfaces:\njoint1/position\njoint2/position\nstate interfaces:\njoint1/position\njoint2/position\ntcp_fts_sensor/force.x\ntcp_fts_sensor/force.y\ntcp_fts_sensor/force.z\ntcp_fts_sensor/torque.x\ntcp_fts_sensor/torque.y\ntcp_fts_sensor/torque.z\navailable controllers:\nforward_position_controller[forward_command_controller/forwardcommandcontroller]\nfts_broadcaster[force_torque_sensor_broadcaster/forcetorquesensorbroadcaster]\njoint_state_broadcaster[joint_state_broadcaster/jointstatebroadcaster]\ncommanding the robot: see the commands below.\naccessing wrench data from 2d fts:\nros2 topic echo /fts_broadcaster/wrench\nexample 5: \"modular robots with separate communication to each actuator\"\nlaunch file: rrbot_modular_actuators.launch.py\nurdf: rrbot_modular_actuators.urdf.xacro\nros2_control urdf: rrbot_modular_actuators.ros2_control.xacro\ncommand interfaces:\njoint1/position\njoint2/position\nstate interfaces:\njoint1/position\njoint2/position\navailable controllers:\nforward_position_controller[forward_command_controller/forwardcommandcontroller]\njoint_state_broadcaster[joint_state_broadcaster/jointstatebroadcaster]\ncommanding the robot: see the commands below.\ncontrollers and moving hardware\nto move the robot you should load and start controllers. the jointstatecontroller is used to publish the joint states to ros topics. direct joint commands are sent to this robot via the forwardcommandcontroller and jointtrajectorycontroller. the sections below describe their usage. check the results section on how to ensure that things went well.\nnote: before doing any action with controllers check their state using command:\nros2 control list_controllers\njointstatecontroller\nopen another terminal and load, configure and start joint_state_controller:\nros2 control set_controller_state joint_state_controller start\ncheck if controller is loaded properly:\nros2 control list_controllers\nyou should get the response:\njoint_state_controller[joint_state_controller/jointstatecontroller] active\nnow you should also see the rrbot represented correctly in rviz.\nusing forwardcommandcontroller\nif you want to test hardware with forwardcommandcontroller first load a controller (not always needed):\nros2 control load_controller forward_position_controller\ncheck if the controller is loaded properly:\nros2 control list_controllers\nthen configure it:\nros2 control set_controller_state forward_position_controller configure\ncheck if the controller is loaded properly:\nros2 control list_controllers\nyou should get the response:\nforward_position_controller[forward_command_controller/forwardcommandcontroller] inactive\nnow start the controller:\nros2 control switch_controllers --start forward_position_controller\ncheck if controllers are activated:\nros2 control list_controllers\nyou should get active in the response:\njoint_state_controller[joint_state_controller/jointstatecontroller] active\nforward_position_controller[forward_command_controller/forwardcommandcontroller] active\nsend a command to the controller, either:\na. manually using ros2 cli interface:\nros2 topic pub /forward_position_controller/commands std_msgs/msg/float64multiarray \"data:\n- 0.5\n- 0.5\"\nb. or you can start a demo node which sends two goals every 5 seconds in a loop:\nros2 launch ros2_control_demo_bringup test_forward_position_controller.launch.py\nyou can adjust the goals in rrbot_forward_position_publisher.yaml.\nusing jointtrajectorycontroller\nif you want to test hardware with jointtrajectorycontroller first load and configure a controller (not always needed):\nros2 control load_controller position_trajectory_controller --set-state configure\ncheck if the controller is loaded and configured properly:\nros2 control list_controllers\nyou should get the response:\nposition_trajectory_controller[joint_trajectory_controller/jointtrajectorycontroller] inactive\nnow start the controller (and stop other running contorller):\nros2 control switch_controllers --stop forward_position_controller --start position_trajectory_controller\ncheck if controllers are activated:\nros2 control list_controllers\nyou should get active in the response:\njoint_state_controller[joint_state_controller/jointstatecontroller] active\nposition_trajectory_controller[joint_trajectory_controller/jointtrajectorycontroller] active\nsend a command to the controller using demo node which sends two goals every 5 seconds in a loop:\nros2 launch ros2_control_demo_bringup test_forward_position_controller.launch.py\nyou can adjust the goals in rrbot_joint_trajectory_publisher.yaml.\nresult\nindependently from the controller you should see how the example's output changes. look for the following lines\n[rrbotsystempositiononlyhardware]: got state 0.0 for joint 0!\n[rrbotsystempositiononlyhardware]: got state 0.0 for joint 1!\nif you echo the /joint_states or /dynamic_joint_states topics you should also get similar values.\nros2 topic echo /joint_states\nros2 topic echo /dynamic_joint_states\nyou should also see the rrbot moving in rviz.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000390, "year": null}], "name": "wrenchrobotics"}