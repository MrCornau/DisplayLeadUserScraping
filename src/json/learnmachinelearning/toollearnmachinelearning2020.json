{"interestingcomments": [{"autor": "jeffelhefe", "date": 1584111083000, "content": "I Needed a Tool to Search My Jupyter Notebooks, so I Wrote One. Here It Is. /!/ [I released an open source library to search Jupyter Notebooks on github](https://github.com/gitjeff05/kapitsa). \n\n*The long version:*\n\nAs I have been learning and developing more Jupyter notebooks, some common problems arise:\n\n1. I know I've done this operation before (e.g., merge two dataframes), but I cannot recall the API details and my other notebook containing the solution is not easy to find.\n2. I would like to \"tag\" Jupyter cells as I go so that I can easily find them later.\n3. I cannot find notebook X.\n\nTo address these concerns, I built a simple tool in bash to query my local notebooks. I have found it quite useful and have decided to release it on github.\n\nI would love some feedback from this community. Any feature requests are welcome also.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fi0ta8/i_needed_a_tool_to_search_my_jupyter_notebooks_so/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i needed a -----> tool !!!  to search my jupyter notebooks, so i wrote one. here it is. /!/ [i released an open source library to search jupyter notebooks on github](https://github.com/gitjeff05/kapitsa). \n\n*the long version:*\n\nas i have been learning and developing more jupyter notebooks, some common problems arise:\n\n1. i know i've done this operation before (e.g., merge two dataframes), but i cannot recall the api details and my other notebook containing the solution is not easy to find.\n2. i would like to \"tag\" jupyter cells as i go so that i can easily find them later.\n3. i cannot find notebook x.\n\nto address these concerns, i built a simple tool in bash to query my local notebooks. i have found it quite useful and have decided to release it on github.\n\ni would love some feedback from this community. any feature requests are welcome also.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fi0ta8/i_needed_a_tool_to_search_my_jupyter_notebooks_so/',)", "identifyer": 5741102, "year": "2020"}, {"autor": "ronanbrady04", "date": 1584039513000, "content": "Is there a GUI for setting up sentiment analysis projects? /!/ I've been learning ML for a couple years now and just started reading up on sentiment analysis. Is there a quick GUI tool I could use to poke around before diving into the backend of this stuff? I just want to get a feel for what I should be working towards as I jump in.\n\nThanks! :)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fhlhs4/is_there_a_gui_for_setting_up_sentiment_analysis/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "is there a gui for setting up sentiment analysis projects? /!/ i've been learning ml for a couple years now and just started reading up on sentiment analysis. is there a quick gui -----> tool !!!  i could use to poke around before diving into the backend of this stuff? i just want to get a feel for what i should be working towards as i jump in.\n\nthanks! :)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fhlhs4/is_there_a_gui_for_setting_up_sentiment_analysis/',)", "identifyer": 5741126, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1584016869000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fhfpte/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fhfpte/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5741136, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1584016813000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fhfpep/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fhfpep/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5741138, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1584013838000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fhf3yg/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fhf3yg/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5741140, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1584013791000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fhf3mm/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fhf3mm/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5741143, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1584013769000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fhf3h8/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fhf3h8/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5741145, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1584013743000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fhf37m/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fhf37m/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5741147, "year": "2020"}, {"autor": "LimarcAmbalina", "date": 1583892430000, "content": "Machine learning as a creative tool, and the quest for artificial general intelligence", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fgpnki/machine_learning_as_a_creative_tool_and_the_quest/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "machine learning as a creative -----> tool !!! , and the quest for artificial general intelligence", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('https://towardsdatascience.com/machine-learning-as-a-creative-tool-and-the-quest-for-artificial-general-intelligence-dfaf81ce7927',)", "identifyer": 5741183, "year": "2020"}, {"autor": "yubrshen", "date": 1587176728000, "content": "Computer-aided legal statutes (briefs) comprehension and interpretation? /!/ I found it interesting that some lawyers and related people spend a lot of time discussing how to interpret the regulations (statutes) of governments repeatedly. I wonder if there is any tool to support them so that they can have more effective interpretation or at least their hard-won interpretation can be better captured and shared?\n\nI don't know where to start the research. Using the \"tool to understand legal documents\" to search on Google, I was only able to find this one like pieces of advice:\n\n[https://www.lawaccess.nsw.gov.au/Pages/representing/lawassist\\_readingwritinghome\\_wysk/lawassist\\_reading\\_wysk/lawassist\\_reading\\_wysk.aspx](https://www.lawaccess.nsw.gov.au/Pages/representing/lawassist_readingwritinghome_wysk/lawassist_reading_wysk/lawassist_reading_wysk.aspx)\n\nWith \"tool to understand legal statutes\", it leads to more promising results. \n\nFrom this, \n\n[https://towardsdatascience.com/law-and-word-order-nlp-in-legal-tech-bd14257ebd06](https://towardsdatascience.com/law-and-word-order-nlp-in-legal-tech-bd14257ebd06)\n\na very helpful survey, but  I still don't find any direct relevant tool.\n\nI did get a lead on a book on how humans to be trained to read the deeds and statutes:\n\n[https://archive.org/details/constructionofde00odgeuoft/mode/2up](https://archive.org/details/constructionofde00odgeuoft/mode/2up) (The construction of deeds and statutes)\n\nI'd appreciate any pointer to improve my understanding.\n\nThank all who helped me to my initial question:[https://www.reddit.com/r/legaladviceofftopic/comments/g344ol/computer\\_tool\\_software\\_to\\_help\\_study\\_legal\\_text/](https://www.reddit.com/r/legaladviceofftopic/comments/g344ol/computer_tool_software_to_help_study_legal_text/)\n\nThanks in advance!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g3fted/computeraided_legal_statutes_briefs_comprehension/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "computer-aided legal statutes (briefs) comprehension and interpretation? /!/ i found it interesting that some lawyers and related people spend a lot of time discussing how to interpret the regulations (statutes) of governments repeatedly. i wonder if there is any -----> tool !!!  to support them so that they can have more effective interpretation or at least their hard-won interpretation can be better captured and shared?\n\ni don't know where to start the research. using the \"tool to understand legal documents\" to search on google, i was only able to find this one like pieces of advice:\n\n[https://www.lawaccess.nsw.gov.au/pages/representing/lawassist\\_readingwritinghome\\_wysk/lawassist\\_reading\\_wysk/lawassist\\_reading\\_wysk.aspx](https://www.lawaccess.nsw.gov.au/pages/representing/lawassist_readingwritinghome_wysk/lawassist_reading_wysk/lawassist_reading_wysk.aspx)\n\nwith \"tool to understand legal statutes\", it leads to more promising results. \n\nfrom this, \n\n[https://towardsdatascience.com/law-and-word-order-nlp-in-legal-tech-bd14257ebd06](https://towardsdatascience.com/law-and-word-order-nlp-in-legal-tech-bd14257ebd06)\n\na very helpful survey, but  i still don't find any direct relevant tool.\n\ni did get a lead on a book on how humans to be trained to read the deeds and statutes:\n\n[https://archive.org/details/constructionofde00odgeuoft/mode/2up](https://archive.org/details/constructionofde00odgeuoft/mode/2up) (the construction of deeds and statutes)\n\ni'd appreciate any pointer to improve my understanding.\n\nthank all who helped me to my initial question:[https://www.reddit.com/r/legaladviceofftopic/comments/g344ol/computer\\_tool\\_software\\_to\\_help\\_study\\_legal\\_text/](https://www.reddit.com/r/legaladviceofftopic/comments/g344ol/computer_tool_software_to_help_study_legal_text/)\n\nthanks in advance!", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g3fted/computeraided_legal_statutes_briefs_comprehension/',)", "identifyer": 5741226, "year": "2020"}, {"autor": "Sujata_b", "date": 1580902403000, "content": "AI is becoming a useful tool to predict coronavirus outbreak globally", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ez88xu/ai_is_becoming_a_useful_tool_to_predict/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "ai is becoming a useful -----> tool !!!  to predict coronavirus outbreak globally", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('https://infotech.report/news/in-coronavirus-response-ai-is-becoming-a-useful-tool-in-a-global-outbreak/8623',)", "identifyer": 5741307, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1580886834000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ez5nvt/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ez5nvt/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5741316, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1580883076000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ez4yl8/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ez4yl8/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5741319, "year": "2020"}, {"autor": "Snoo-11146", "date": 1596485248000, "content": "Are there any applications/softwares/websites that help create neural networks using a gamification tool for non ML and DL professionals?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/i34gjg/are_there_any_applicationssoftwareswebsites_that/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "are there any applications/softwares/websites that help create neural networks using a gamification -----> tool !!!  for non ml and dl professionals?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/i34gjg/are_there_any_applicationssoftwareswebsites_that/',)", "identifyer": 5741687, "year": "2020"}, {"autor": "kartikaya12", "date": 1599798653000, "content": "As we all know that a resume is an important tool for your job search because it offers a page or two where you can display your top skills and qualities. That is why I am sharing this article on Python Developer Resume, that will help you to build your resume and make it attractive", "link": "https://www.reddit.com/r/learnmachinelearning/comments/iqjtu2/as_we_all_know_that_a_resume_is_an_important_tool/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "as we all know that a resume is an important -----> tool !!!  for your job search because it offers a page or two where you can display your top skills and qualities. that is why i am sharing this article on python developer resume, that will help you to build your resume and make it attractive", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('https://www.mygreatlearning.com/blog/python-developer-resume/?utm_source=Developer&amp;utm_medium=Facebook',)", "identifyer": 5741709, "year": "2020"}, {"autor": "reputationEK", "date": 1602779063000, "content": "Extract specific data from unstructured text /!/ Hi,\n\nI'm faced with what should be a fairly easy ML problem.\n\nI would like to extract the same product charateristics from gumtree ad text. For instance, for laptops, I would try to extract screen size, RAM and storage. Usually the information is given in a unstructured list format .\n\nHere are some examples:\n\n[https://www.gumtree.com/p/laptops/dell-inspiron-15-7586-2-in-1-i7-8565u-16gb-ram-512gb-rom-laptop-tablet-touch-screen/1384239917](https://www.gumtree.com/p/laptops/dell-inspiron-15-7586-2-in-1-i7-8565u-16gb-ram-512gb-rom-laptop-tablet-touch-screen/1384239917)\n\n[https://www.gumtree.com/p/laptops/hp-envy-laptop-13-aq0003na-8th-gen-i7-16gb-ram-1tb-ssd-storage-with-included-cover/1382135866](https://www.gumtree.com/p/laptops/hp-envy-laptop-13-aq0003na-8th-gen-i7-16gb-ram-1tb-ssd-storage-with-included-cover/1382135866)\n\n[https://www.gumtree.com/p/laptops/hp-compaq-15.6-inc-laptop-pc-amd-m500-2.20-ghz-160-gb-hdd-4-gb-ram-win-10-pro-office-2019-pro/1387371358](https://www.gumtree.com/p/laptops/hp-compaq-15.6-inc-laptop-pc-amd-m500-2.20-ghz-160-gb-hdd-4-gb-ram-win-10-pro-office-2019-pro/1387371358)\n\nMy initial research led me into the direction of NLP but I suspect that this is not quite the right tool/an overkill, given that the information is usually contained in a unstructured list rather than a complete sentence. \n\nThe format of the ad text always varies slightly making regular expression based approaches error-prone or cumbersome.\n\nI'm unexperienced with ML algorithms but I'm fairly comfortable with Python.\n\nWould love some general pointers :)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jbqt2s/extract_specific_data_from_unstructured_text/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "extract specific data from unstructured text /!/ hi,\n\ni'm faced with what should be a fairly easy ml problem.\n\ni would like to extract the same product charateristics from gumtree ad text. for instance, for laptops, i would try to extract screen size, ram and storage. usually the information is given in a unstructured list format .\n\nhere are some examples:\n\n[https://www.gumtree.com/p/laptops/dell-inspiron-15-7586-2-in-1-i7-8565u-16gb-ram-512gb-rom-laptop-tablet-touch-screen/1384239917](https://www.gumtree.com/p/laptops/dell-inspiron-15-7586-2-in-1-i7-8565u-16gb-ram-512gb-rom-laptop-tablet-touch-screen/1384239917)\n\n[https://www.gumtree.com/p/laptops/hp-envy-laptop-13-aq0003na-8th-gen-i7-16gb-ram-1tb-ssd-storage-with-included-cover/1382135866](https://www.gumtree.com/p/laptops/hp-envy-laptop-13-aq0003na-8th-gen-i7-16gb-ram-1tb-ssd-storage-with-included-cover/1382135866)\n\n[https://www.gumtree.com/p/laptops/hp-compaq-15.6-inc-laptop-pc-amd-m500-2.20-ghz-160-gb-hdd-4-gb-ram-win-10-pro-office-2019-pro/1387371358](https://www.gumtree.com/p/laptops/hp-compaq-15.6-inc-laptop-pc-amd-m500-2.20-ghz-160-gb-hdd-4-gb-ram-win-10-pro-office-2019-pro/1387371358)\n\nmy initial research led me into the direction of nlp but i suspect that this is not quite the right -----> tool !!! /an overkill, given that the information is usually contained in a unstructured list rather than a complete sentence. \n\nthe format of the ad text always varies slightly making regular expression based approaches error-prone or cumbersome.\n\ni'm unexperienced with ml algorithms but i'm fairly comfortable with python.\n\nwould love some general pointers :)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jbqt2s/extract_specific_data_from_unstructured_text/',)", "identifyer": 5741860, "year": "2020"}, {"autor": "earnnu0", "date": 1580646010000, "content": "Extracting information from table within invoices /!/ I am trying to find specific information from supplier invoices using ML. Now, I have a lot of invoices I can use to create a dataset (+100k). I figure the first step is to label them, so I can train a model to extract the information I need.\n\nBelow is a sample invoice (I have anonymized it by removing the shipper address details, logo etc.).\n\n&amp;#x200B;\n\n[Example invoice](https://preview.redd.it/82luba2f6ie41.png?width=1576&amp;format=png&amp;auto=webp&amp;s=0bd1f90c03310a9ff67aadf86b72da069829842e)\n\nAs you can see in the above image, I am trying to extract three entities from the invoice:\n\n1. table\n2. amount (for each line in the table)\n3. tariff (for each line in the table)\n\nNow I actually don't need the table, but what seems to be common across all my supplier invoices is that the `amount` and `tariff` for line items, is always within a table. In the above example, the table only contains 1 line-item - it can contain multiple (spanning multiple pages as well)\n\nMy idea of a pipeline is:\n\n* Get all invoices (PDF files) and convert each page to a PNG image.\n* Label all the individual pages, using a label annotation tool, to label `table`, `amount` and `tariff` \\- including the **bbox** information for each label.\n* Train a model using the above dataset.\n* ???\n\nMy questions are:\n\n* Does this seem like a good approach to such a problem?\n* Do I have to split up the model into two? With this I mean, does it make more sense to *first* identify the `table` within an image with **one model**, then serve the table image to another model, and extract the `tariff` and `amount` with the 2nd model?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/exnnzb/extracting_information_from_table_within_invoices/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "extracting information from table within invoices /!/ i am trying to find specific information from supplier invoices using ml. now, i have a lot of invoices i can use to create a dataset (+100k). i figure the first step is to label them, so i can train a model to extract the information i need.\n\nbelow is a sample invoice (i have anonymized it by removing the shipper address details, logo etc.).\n\n&amp;#x200b;\n\n[example invoice](https://preview.redd.it/82luba2f6ie41.png?width=1576&amp;format=png&amp;auto=webp&amp;s=0bd1f90c03310a9ff67aadf86b72da069829842e)\n\nas you can see in the above image, i am trying to extract three entities from the invoice:\n\n1. table\n2. amount (for each line in the table)\n3. tariff (for each line in the table)\n\nnow i actually don't need the table, but what seems to be common across all my supplier invoices is that the `amount` and `tariff` for line items, is always within a table. in the above example, the table only contains 1 line-item - it can contain multiple (spanning multiple pages as well)\n\nmy idea of a pipeline is:\n\n* get all invoices (pdf files) and convert each page to a png image.\n* label all the individual pages, using a label annotation -----> tool !!! , to label `table`, `amount` and `tariff` \\- including the **bbox** information for each label.\n* train a model using the above dataset.\n* ???\n\nmy questions are:\n\n* does this seem like a good approach to such a problem?\n* do i have to split up the model into two? with this i mean, does it make more sense to *first* identify the `table` within an image with **one model**, then serve the table image to another model, and extract the `tariff` and `amount` with the 2nd model?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/exnnzb/extracting_information_from_table_within_invoices/',)", "identifyer": 5741899, "year": "2020"}, {"autor": "RiggedHilbert", "date": 1580393428000, "content": "ML on a black box code /!/ I am a computational physicist but relatively new to machine learning. I'm looking for a proof of concept project in ML that includes a tool used at my institution.\n\nThe training data would be produced by a code that is to be treated as a \"black box\". This code takes input a list of ingredients (chemical species) at specified conditions and then produces a set of properties of the resultant mixture as output. The code takes about 1-3 seconds to run per mixture. Not terribly long, but often has to be run many times to find a mixture with desired properties. Users of the code typically do not know the internal models (hence why I call it a black box) but do know not to ask for silly things like a mixture of water and steel at 25C and 1 atm and expect sensible mixture properties. There is nothing stopping one from nonsensical inputs but it would be something I'd hope the ML model would \"learn\" to avoid.\n\nMy question is would it be possible to replace this black code being run many times over to find an optimal mixture (a constrained optimization problem, classically) with, say, a neural network?\n\nIf so, what would be the best approach to get started?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ew5zd5/ml_on_a_black_box_code/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "ml on a black box code /!/ i am a computational physicist but relatively new to machine learning. i'm looking for a proof of concept project in ml that includes a -----> tool !!!  used at my institution.\n\nthe training data would be produced by a code that is to be treated as a \"black box\". this code takes input a list of ingredients (chemical species) at specified conditions and then produces a set of properties of the resultant mixture as output. the code takes about 1-3 seconds to run per mixture. not terribly long, but often has to be run many times to find a mixture with desired properties. users of the code typically do not know the internal models (hence why i call it a black box) but do know not to ask for silly things like a mixture of water and steel at 25c and 1 atm and expect sensible mixture properties. there is nothing stopping one from nonsensical inputs but it would be something i'd hope the ml model would \"learn\" to avoid.\n\nmy question is would it be possible to replace this black code being run many times over to find an optimal mixture (a constrained optimization problem, classically) with, say, a neural network?\n\nif so, what would be the best approach to get started?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ew5zd5/ml_on_a_black_box_code/',)", "identifyer": 5741985, "year": "2020"}, {"autor": "anupvasudev", "date": 1578995857000, "content": "GUI based Machine Learning (ML) tools/software for Numerical/Categorical/Time series data /!/ Dear Redditors,\n\nI am a computer science engineer. For the last few months I have been learning ML. My intention is to build a easy to use free GUI web tool for ML which can be used by business/domain experts who understand the data but may not fully understand how ML works. The web tool will also have enough options for data scientists to tinker around as well. I have looked around and haven't yet found an easy to use free web tool. I have found some which needs to be installed on the computer. But in this age of cloud computing, I was put off by that idea.\n\nThe main limitation I found in existing tools, is when it comes to publishing and using the model. The services generated over the model expects the input to be normalized/feature engineered. This leads to additional work of manipulating the data before using the service. The predicted result is also normalized/feature engineered. Hence the result needs to be reversed into its original form. This again leads to more work.\n\nI would like to build the the web tool where the above works out of the box.\n\nMy approach is to build it as a wizard so that the users can simply follow the steps in order.\n\nUpload Data -&gt; Select Normalization/Feature Engineering Options-&gt;Select data split range ( Training vs Testing)-&gt; Select ML Model-&gt;Train ML Model-&gt; Publish Model\n\nPublishing the model will generate - \n\n1. Webservice (REST service) - Which takes the original data as input and the predicted result is also in the original form and not in normalized/feature engineered form.\n\n2. GUI (web URL) - Which allow users to input the values or upload a file to get the predicted outputs.\n\nI am half way done with the implementation. I would like this community's opinion. What limitations do you see in the existing GUI tools ? What sort of features do you want to see in such tools ? Would you use such a web tool?\n\nI will post this in other relevant subreddits as well. Thank you for your time.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/eojb1m/gui_based_machine_learning_ml_toolssoftware_for/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "gui based machine learning (ml) tools/software for numerical/categorical/time series data /!/ dear redditors,\n\ni am a computer science engineer. for the last few months i have been learning ml. my intention is to build a easy to use free gui web -----> tool !!!  for ml which can be used by business/domain experts who understand the data but may not fully understand how ml works. the web tool will also have enough options for data scientists to tinker around as well. i have looked around and haven't yet found an easy to use free web tool. i have found some which needs to be installed on the computer. but in this age of cloud computing, i was put off by that idea.\n\nthe main limitation i found in existing tools, is when it comes to publishing and using the model. the services generated over the model expects the input to be normalized/feature engineered. this leads to additional work of manipulating the data before using the service. the predicted result is also normalized/feature engineered. hence the result needs to be reversed into its original form. this again leads to more work.\n\ni would like to build the the web tool where the above works out of the box.\n\nmy approach is to build it as a wizard so that the users can simply follow the steps in order.\n\nupload data -&gt; select normalization/feature engineering options-&gt;select data split range ( training vs testing)-&gt; select ml model-&gt;train ml model-&gt; publish model\n\npublishing the model will generate - \n\n1. webservice (rest service) - which takes the original data as input and the predicted result is also in the original form and not in normalized/feature engineered form.\n\n2. gui (web url) - which allow users to input the values or upload a file to get the predicted outputs.\n\ni am half way done with the implementation. i would like this community's opinion. what limitations do you see in the existing gui tools ? what sort of features do you want to see in such tools ? would you use such a web tool?\n\ni will post this in other relevant subreddits as well. thank you for your time.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/eojb1m/gui_based_machine_learning_ml_toolssoftware_for/',)", "identifyer": 5742069, "year": "2020"}, {"autor": "hiphop1987", "date": 1586975150000, "content": "Pandas Pivot \u2014 The Ultimate Guide /!/ Pandas pivot is an essential tool of every Data Scientist. Some use it daily and others avoid it because it seems complex. I was in the latter group for quite a while. After I took the time and did some research, I felt like I wasted a lot of time writing unnecessary code. To my surprise, I already knew the main building blocks of pandas. It is all simpler than it may seem.\n\n[https://towardsdatascience.com/pandas-pivot-the-ultimate-guide-5c693e0771f3](https://towardsdatascience.com/pandas-pivot-the-ultimate-guide-5c693e0771f3)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g1xn8b/pandas_pivot_the_ultimate_guide/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "pandas pivot \u2014 the ultimate guide /!/ pandas pivot is an essential -----> tool !!!  of every data scientist. some use it daily and others avoid it because it seems complex. i was in the latter group for quite a while. after i took the time and did some research, i felt like i wasted a lot of time writing unnecessary code. to my surprise, i already knew the main building blocks of pandas. it is all simpler than it may seem.\n\n[https://towardsdatascience.com/pandas-pivot-the-ultimate-guide-5c693e0771f3](https://towardsdatascience.com/pandas-pivot-the-ultimate-guide-5c693e0771f3)", "sortedWord": "None", "removed": "('nan',)", "score": 5, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g1xn8b/pandas_pivot_the_ultimate_guide/',)", "identifyer": 5742136, "year": "2020"}, {"autor": "braincrowd", "date": 1586875891000, "content": "I have labeled data now what? Gender and Age detection. /!/ Hello\n\nFor a Project that im doing I have a very large dataset (couple Millions of Images) of People. (Most of the time i have multible images per person)\n\nI have about 1 Million Images labeled with correct Age and Gender of the person.\n\nI would like to train a network on the labeled data i already have to help label the rest of the data.\n\nWhat i would like as a label is a agegroup (labeled data has age as number but a appromiate range is enough) and gender of the person (male/female)\n\nI would say i understand the basic principles and already used some finished tensor flow and python scripts but i dont really know where to start with this project. I would prefer a simple already made tool/script/libary/network that i can only feed my dataset to train.\n\n&amp;#x200B;\n\nI have all Images in Full (Picture of upper body) and in crop of only face. What is better to train the algorythm on? Probably only the face i guess to minimize training on wrong features right?\n\n&amp;#x200B;\n\nThanks a lot for your help.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g16wsa/i_have_labeled_data_now_what_gender_and_age/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i have labeled data now what? gender and age detection. /!/ hello\n\nfor a project that im doing i have a very large dataset (couple millions of images) of people. (most of the time i have multible images per person)\n\ni have about 1 million images labeled with correct age and gender of the person.\n\ni would like to train a network on the labeled data i already have to help label the rest of the data.\n\nwhat i would like as a label is a agegroup (labeled data has age as number but a appromiate range is enough) and gender of the person (male/female)\n\ni would say i understand the basic principles and already used some finished tensor flow and python scripts but i dont really know where to start with this project. i would prefer a simple already made -----> tool !!! /script/libary/network that i can only feed my dataset to train.\n\n&amp;#x200b;\n\ni have all images in full (picture of upper body) and in crop of only face. what is better to train the algorythm on? probably only the face i guess to minimize training on wrong features right?\n\n&amp;#x200b;\n\nthanks a lot for your help.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g16wsa/i_have_labeled_data_now_what_gender_and_age/',)", "identifyer": 5742175, "year": "2020"}, {"autor": "Cosmic_Ishan", "date": 1583795316000, "content": "AI is a tool. The choice about how it gets deployed is ours. - Oren Etzioni", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fg3tlf/ai_is_a_tool_the_choice_about_how_it_gets/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "ai is a -----> tool !!! . the choice about how it gets deployed is ours. - oren etzioni", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('image',)", "medialink": "('https://i.redd.it/ut8xrhd3bql41.jpg',)", "identifyer": 5742217, "year": "2020"}, {"autor": "Wirusiux", "date": 1606051669000, "content": "Model generated curve fitting to real experiment results /!/ Hi,  \nPhd student here. For my thesis i have a problem to solve. I have written an algorithm, which generates curve for some model (alpha-hemolysin makes spores on cell membrane over time). That model uses like 20 constants: k\\_01 ... k\\_20. Now what i need to do, is make other way around: I have a curve (from real experiment data). Now need to find those constants k\\_xx, so that generated curve would best fit real experiment curve, marked by arrow between blue marks.  Image attached.  I will probably need to write some function, which would return total difference from generated curve to real curve and try to minimize it by applying various k\\_xx sets.  Would machine learning be suitable for it? Heard ResNet, GoogleNet/InceptionV4, Adam algorithms are good, would any of them fit? Any suggestions or hints are very welcome, as i had no experience before and this is very new to me. PS will use Orange as a tool. Thank you!\n\nhttps://preview.redd.it/9q8cnt9kls061.png?width=1283&amp;format=png&amp;auto=webp&amp;s=c47552295fc701a5e524f9cd5e0153778cec4a59", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jyvmnb/model_generated_curve_fitting_to_real_experiment/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "model generated curve fitting to real experiment results /!/ hi,  \nphd student here. for my thesis i have a problem to solve. i have written an algorithm, which generates curve for some model (alpha-hemolysin makes spores on cell membrane over time). that model uses like 20 constants: k\\_01 ... k\\_20. now what i need to do, is make other way around: i have a curve (from real experiment data). now need to find those constants k\\_xx, so that generated curve would best fit real experiment curve, marked by arrow between blue marks.  image attached.  i will probably need to write some function, which would return total difference from generated curve to real curve and try to minimize it by applying various k\\_xx sets.  would machine learning be suitable for it? heard resnet, googlenet/inceptionv4, adam algorithms are good, would any of them fit? any suggestions or hints are very welcome, as i had no experience before and this is very new to me. ps will use orange as a -----> tool !!! . thank you!\n\nhttps://preview.redd.it/9q8cnt9kls061.png?width=1283&amp;format=png&amp;auto=webp&amp;s=c47552295fc701a5e524f9cd5e0153778cec4a59", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jyvmnb/model_generated_curve_fitting_to_real_experiment/',)", "identifyer": 5742437, "year": "2020"}, {"autor": "Flicked_Up", "date": 1585348798000, "content": "Tools for drawing datasets for representation /!/ Hello guys,\n\nI am doing my thesis on machine learning, and I need to draw several plots for demonstration purposes, to represent different classes, imbalance, etc.\n\nWhat is the best tool to construct these plots, in a mouse-clickable fashion? My only requirementis that it exports to any vectorized from (pdf, eps, svg are all fine, but no jpeg or png).\n\n&amp;#x200B;\n\nThanks in advance!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fq7ky8/tools_for_drawing_datasets_for_representation/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "tools for drawing datasets for representation /!/ hello guys,\n\ni am doing my thesis on machine learning, and i need to draw several plots for demonstration purposes, to represent different classes, imbalance, etc.\n\nwhat is the best -----> tool !!!  to construct these plots, in a mouse-clickable fashion? my only requirementis that it exports to any vectorized from (pdf, eps, svg are all fine, but no jpeg or png).\n\n&amp;#x200b;\n\nthanks in advance!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fq7ky8/tools_for_drawing_datasets_for_representation/',)", "identifyer": 5742676, "year": "2020"}, {"autor": "Brilliant_Potato", "date": 1588587094000, "content": "Which data Annotation tool for texture recognition? /!/ Hello :).\n\nFor my bachelor thesis i want to train two CNN's to get a texture descriptor from a given sub-image. \n\nOne CNN is going to be trained, the other one is an auto-encoder. I will compare how well they perform. \n\nI got some images from my prof. which i will be using, but they aren't labeled. So i need some software to label the data. \n\nWhen i researched this, i found that there are many solutions and i didn't know which would be most applicable to my usecase, which is:\n\n&amp;#x200B;\n\nLabel the data in a way, such that every sub-image (e.g. 32x32 square) is labeled with exactly one class (or none). \n\nIt would be ok if the image is labeled pixel-wise and the exact outlines of the object are labeled, if i can convert that to the desired structure. (should be quite simple ... e.g. more then 1/4 of pixel labeled as class -&gt; square labeled as class.)\n\n&amp;#x200B;\n\nI hope you guys can recommend me a tool which is suitable. Thanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gd8xpl/which_data_annotation_tool_for_texture_recognition/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "which data annotation -----> tool !!!  for texture recognition? /!/ hello :).\n\nfor my bachelor thesis i want to train two cnn's to get a texture descriptor from a given sub-image. \n\none cnn is going to be trained, the other one is an auto-encoder. i will compare how well they perform. \n\ni got some images from my prof. which i will be using, but they aren't labeled. so i need some software to label the data. \n\nwhen i researched this, i found that there are many solutions and i didn't know which would be most applicable to my usecase, which is:\n\n&amp;#x200b;\n\nlabel the data in a way, such that every sub-image (e.g. 32x32 square) is labeled with exactly one class (or none). \n\nit would be ok if the image is labeled pixel-wise and the exact outlines of the object are labeled, if i can convert that to the desired structure. (should be quite simple ... e.g. more then 1/4 of pixel labeled as class -&gt; square labeled as class.)\n\n&amp;#x200b;\n\ni hope you guys can recommend me a tool which is suitable. thanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gd8xpl/which_data_annotation_tool_for_texture_recognition/',)", "identifyer": 5742778, "year": "2020"}, {"autor": "ai_research_purposes", "date": 1590080319000, "content": "Would anyone be interested in a 2-3 hours online workshop introducing Python with emphasis on Data Science/Engineering/ML purposes? /!/ There's thousands if not millions of resources already for learning Python, some from experienced and seasoned programmers, and some from complete newbies who post it as a way of reinforcing what they've learned. As for me I'm a MSc student in Computer Vision and Deep Learning for Biomedical Applications, so I get to use it often, but I'm still definitely not as proficient as I would like to be, and some of the code I write is definitely not pythonic or good code, but it works, mostly.\n\nSo my question is, would me doing my own live tutorial/exposition to Python would add any sort of value? I was planning on a little introduction to what can you do with the language, the absolute basics, and how to approach to doing stuff using Python, in a general sense. I originally was thinking about mainly tailoring it for friends/classmates who're interested in learning a programming language, mostly for engineering purposes, as a data analysis and math tool, substituting Matlab which is what we mostly used in our previous institution, but after using Python for a year or two I feel it's much more versatile in the sense that basically it can be used for almost anything, and it's therefore much more valuable to learn, and have on your resume.\n\nIn any case, would anyone here be interested? It would probably be conducted over Google Meet or similar, in English, and would be open for anyone to join. The recorded session would probably be also uploaded to YT, written in a blog or something. Hopefully it would include both a lecture and tutorial parts, along with open to questions, in either English, Spanish and to a certain extent Chinese.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/go0lke/would_anyone_be_interested_in_a_23_hours_online/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "would anyone be interested in a 2-3 hours online workshop introducing python with emphasis on data science/engineering/ml purposes? /!/ there's thousands if not millions of resources already for learning python, some from experienced and seasoned programmers, and some from complete newbies who post it as a way of reinforcing what they've learned. as for me i'm a msc student in computer vision and deep learning for biomedical applications, so i get to use it often, but i'm still definitely not as proficient as i would like to be, and some of the code i write is definitely not pythonic or good code, but it works, mostly.\n\nso my question is, would me doing my own live tutorial/exposition to python would add any sort of value? i was planning on a little introduction to what can you do with the language, the absolute basics, and how to approach to doing stuff using python, in a general sense. i originally was thinking about mainly tailoring it for friends/classmates who're interested in learning a programming language, mostly for engineering purposes, as a data analysis and math -----> tool !!! , substituting matlab which is what we mostly used in our previous institution, but after using python for a year or two i feel it's much more versatile in the sense that basically it can be used for almost anything, and it's therefore much more valuable to learn, and have on your resume.\n\nin any case, would anyone here be interested? it would probably be conducted over google meet or similar, in english, and would be open for anyone to join. the recorded session would probably be also uploaded to yt, written in a blog or something. hopefully it would include both a lecture and tutorial parts, along with open to questions, in either english, spanish and to a certain extent chinese.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/go0lke/would_anyone_be_interested_in_a_23_hours_online/',)", "identifyer": 5742848, "year": "2020"}, {"autor": "frlazzeri", "date": 1590077663000, "content": "Fairlearn - A Python package to assess AI system's fairness /!/ In 2015, Claire Cain Miller wrote on [The New York Times](https://www.nytimes.com/2015/07/10/upshot/when-algorithms-discriminate.html) that there was a widespread belief that software and algorithms that rely on data were objective. Five years later, we know for sure that AI is not free of human influence. Data is created, stored, and processed by people, machine learning algorithms are written and maintained by people, and AI applications simply reflect people\u2019s attitudes and behavior.\u00a0\n\nData scientists know that no longer accuracy is the only concern when developing machine learning models, fairness must be considered as well. In order to make sure that machine learning solutions are fair and the value of their predictions easy to understand and explain, it is essential to build tools that developers and data scientists can use to assess their AI system\u2019s fairness and mitigate any observed unfairness issues.\n\nThis article will focus on **AI fairness**, by explaining the following aspects and tools:\n\n1. [**Fairlearn**](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri): a tool to assess AI system\u2019s fairness and mitigate any observed unfairness issues\n2. How to use [**Fairlearn**](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri) in [**Azure Machine Learning**](http://www.aka.ms/AzureMLDoc)\n3. What we mean by fairness\n4. [**Fairlearn algorithms**](https://github.com/fairlearn/fairlearn?WT.mc_id=docs-twitter-lazzeri#fairlearn-algorithms)\n5. [**Fairlearn dashboard**](https://github.com/fairlearn/fairlearn?WT.mc_id=docs-twitter-lazzeri#fairlearn-dashboard)\n6. Comparing multiple models\n7. Additional resources and [**how to contribute**](https://github.com/fairlearn/fairlearn?WT.mc_id=docs-twitter-lazzeri#contributing)\n\n## 1. Fairlearn: a tool to assess AI system\u2019s fairness and mitigate any observed unfairness issues\n\n[Fairlearn](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri) is a Python package that empowers developers of artificial intelligence (AI) systems to assess their system\u2019s fairness and mitigate any observed unfairness issues. [Fairlearn](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri) contains mitigation algorithms as well as a Jupyter widget for model assessment. The [Fairlearn](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri) package has two components:\n\n* A\u00a0*dashboard*\u00a0for assessing which groups are negatively impacted by a model, and for comparing multiple models in terms of various fairness and accuracy metrics.\n* *Algorithms*\u00a0for mitigating unfairness in a variety of AI tasks and along a variety of fairness definitions.\n\nThere is also a collection of [Jupyter notebooks](https://github.com/fairlearn/fairlearn/tree/master/notebooks?WT.mc_id=build2020_ca-blogpost-lazzeri) and an a detailed [API guide](https://fairlearn.github.io/api_reference/index.html?WT.mc_id=build2020_ca-blogpost-lazzeri), that you can check to learn how to leverage [Fairlearn](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri) for your own data science scenario.\n\n## 2. How to use Fairlearn in Azure Machine Learning\n\nThe [Fairlearn](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri) package can be installed via:\n\n`pip install fairlearn` \n\nor optionally with a full feature set by adding extras, e.g. pip install fairlearn\\[customplots\\], or you can clone the repository locally via:\n\n`git clone git@github.com:fairlearn/fairlearn.git` \n\nIn Azure Machine Learning, there are a few options to use Jupyter notebooks for your experiments:\n\n### a) Get Fairlearn samples on your notebook server\n\nIf you\u2019d like to bring your own notebook server for local development, follow these steps:\n\n1. Use the instructions at\u00a0[**Azure Machine Learning SDK**](https://docs.microsoft.com/python/api/overview/azure/ml/install?view=azure-ml-py?WT.mc_id=build2020_ca-blogpost-lazzeri)\u00a0to install the Azure Machine Learning SDK for Python\n2. Create an\u00a0[**Azure Machine Learning workspace**](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?WT.mc_id=build2020_ca-blogpost-lazzeri).\n3. Write a\u00a0[**configuration file**](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#workspace?WT.mc_id=build2020_ca-blogpost-lazzeri) \n4. Clone\u00a0[**the GitHub repository**](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri).\n\n`git clone git@github.com:fairlearn/fairlearn.git` \n\n5. Start the notebook server from your cloned directory.\n\n`jupyter notebook` \n\nFor more information, see [Install the Azure Machine Learning SDK for Python](https://docs.microsoft.com/python/api/overview/azure/ml/install?WT.mc_id=build2020_ca-blogpost-lazzeri).\n\nb) Get Fairlearn samples on DSVM\n\nThe Data Science Virtual Machine (DSVM) is a customized VM image built specifically for doing data science. If you\u00a0[create a DSVM](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment?WT.mc_id=build2020_ca-blogpost-lazzeri#dsvm), the SDK and notebook server are installed and configured for you. However, you\u2019ll still need to create a workspace and clone the sample repository.\n\n1. [Create an Azure Machine Learning workspace](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?WT.mc_id=build2020_ca-blogpost-lazzeri).\n2. Clone\u00a0[the GitHub repository](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri).\n\n`git clone git@github.com:fairlearn/fairlearn.git`\n\n3. Add a workspace configuration file to the cloned directory using either of these methods:\n\n* In the\u00a0[Azure portal](https://ms.portal.azure.com/?WT.mc_id=build2020_ca-blogpost-lazzeri), select\u00a0Download config.json\u00a0from the\u00a0Overview section of your workspace.\n* Create a new workspace using code in the\u00a0[configuration.ipynb](https://github.com/Azure/MachineLearningNotebooks/blob/master/configuration.ipynb?WT.mc_id=build2020_ca-blogpost-lazzeri) notebook in your cloned directory\n\n4. Start the notebook server from your cloned directory:\n\n`jupyter notebook`\n\n## 3. What we mean by\u00a0fairness\n\nFighting against unfairness and discrimination has a long history in philosophy and psychology, and recently in machine learning. However, in order to be able to achieve fairness, we should first define the notion of it. An AI system can behave unfairly for a variety of reasons and many different fairness explanations have been used in literature, making this definition even more challenging. In general, fairness definitions fall under three different categories as follows:\n\n* *Individual Fairness* \u2013 Give similar predictions to similar individuals.\u00a0\n* *Group Fairness* \u2013 Treat different groups equally.\n* *Subgroup Fairness* \u2013 Subgroup fairness intends to obtain the best properties of the group and individual notions of fairness.\u00a0\n\nIn [Fairlearn](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri), we define whether an AI system is behaving unfairly in terms of its impact on people \u2013 i.e., in terms of harms. We focus on two kinds of harms:\n\n* *Allocation harms*. These harms can occur when AI systems extend or withhold opportunities, resources, or information. Some of the key applications are in hiring, school admissions, and lending.\n* *Quality-of-service harms*.\u00a0Quality of service refers to whether a system works as well for one person as it does for another, even if no opportunities, resources, or information are extended or withheld.\n\nWe follow the approach known as group fairness, which asks: Which groups of individuals are at risk of experiencing harm? The relevant groups need to be specified by the data scientist and are application-specific. Group fairness is formalized by a set of constraints, which require that some aspect (or aspects) of the AI system\u2019s behavior be comparable across the groups. The [Fairlearn](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri) package enables the assessment and mitigation of unfairness under several common definitions.\n\n## 4. Fairlearn algorithms\n\n[Fairlearn](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri) contains the following algorithms for mitigating unfairness in binary classification and regression:\n\nhttps://preview.redd.it/2inmvd6g75051.png?width=899&amp;format=png&amp;auto=webp&amp;s=3386410974a9e3640ef8ef8a409a2f19f989330a\n\n## 5. Fairlearn dashboard\n\n[Fairlearn](https://github.com/fairlearn/fairlearn?WT.mc_id=build2020_ca-blogpost-lazzeri) dashboard is a Jupyter notebook widget for assessing how a model\u2019s predictions impact different groups (e.g., different ethnicities), and also for comparing multiple models along different fairness and accuracy metrics.\n\nTo assess a single model\u2019s fairness and accuracy, the dashboard widget can be launched within a Jupyter notebook as follows:\n\n`from fairlearn.widget import FairlearnDashboard`\n\n`# A_test containts your sensitive features (e.g., age, binary gender)` \n\n`# sensitive_feature_names containts your sensitive feature names` \n\n`# y_true contains ground truth labels` \n\n`# y_pred contains prediction labels` \n\n`FairlearnDashboard(sensitive_features=A_test,` \n\n`sensitive_feature_names=['BinaryGender', 'Age'],`  \n\n`y_true=Y_test.tolist(),`  \n\n`y_pred=[y_pred.tolist()])`\n\nAfter the launch, the widget walks the user through the assessment set-up, where the user is asked to select:\n\n1. the sensitive feature of interest (e.g., binary gender or age)\n2. the accuracy metric (e.g., model precision) along which to evaluate the overall model performance as well as any disparities across groups.\u00a0\n\nThese selections are then used to obtain the visualization of the model\u2019s impact on the subgroups (e.g., model precision for females and model precision for males). The following figures illustrate the set-up steps, where binary gender is selected as a sensitive feature and the accuracy rate is selected as the accuracy metric:\n\nAfter the set-up, the dashboard presents the model assessment in two panels, as summarized in the table, and visualized in the screenshot below:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/enskhh7i75051.png?width=900&amp;format=png&amp;auto=webp&amp;s=db98cb058029655757df1946e42bca4831170451\n\n## 6. Comparing multiple models\n\nAn additional feature that this dashboard offers is the comparison of multiple models, such as the models produced by different learning algorithms and different mitigation approaches, including:\n\n* `fairlearn.reductions.GridSearch`\n* `fairlearn.reductions.ExponentiatedGradient`\n* `fairlearn.postprocessing.ThresholdOptimizer`\n\nAs before, the user is first asked to select the sensitive feature and the accuracy metric. The\u00a0model comparison\u00a0view then depicts the accuracy and disparity of all the provided models in a scatter plot. This allows the user to examine trade-offs between algorithm accuracy and fairness. Moreover, each of the dots can be clicked to open the assessment of the corresponding model.\u00a0\n\nThe figure below shows the model comparison view with binary gender selected as a sensitive feature and\u00a0accuracy rate\u00a0selected as the accuracy metric.\n\n# 7. Additional resources and how to contribute\n\nFor references and additional resources, please refer to:\n\n* Fairlearn GitHub repo: [**www.aka.ms/FairlearnAI**](http://www.aka.ms/FairlearnAI) \n* Azure Machine Learning: [**www.aka.ms/AzureMLDoc**](http://www.aka.ms/AzureMLDoc)\n* Responsible ML at Microsoft Build: [**www.aka.ms/Build2020ResponsibleML**](http://www.aka.ms/Build2020ResponsibleML) \n* Responsible ML on Azure: [**www.aka.ms/AzureResponsibleML**](http://www.aka.ms/AzureResponsibleML)\n* Responsible ML documentation: [**www.aka.ms/ResponsibleMLDoc**](http://www.aka.ms/ResponsibleMLDoc)\n* Discrimination-aware Data Mining: [**http://pages.di.unipi.it/ruggieri/Papers/kdd2008.pdf**\u00a0](https://dl.acm.org/doi/10.1145/1401890.1401959)\n* A Survey on Bias and Fairness in Machine Learning: [**https://arxiv.org/pdf/1908.09635.pdf**](https://arxiv.org/pdf/1908.09635.pdf)\n* Can an Algorithm Hire Better Than a Human? [**https://www.nytimes.com/2015/06/26/upshot/can-an-algorithm-hire-better-than-a-human.html**](https://www.nytimes.com/2015/06/26/upshot/can-an-algorithm-hire-better-than-a-human.html)\n\nTo contribute please check this\u00a0[contributing guide](https://fairlearn.github.io/?WT.mc_id=build2020_ca-blogpost-lazzeri#contribute).", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gnzrs3/fairlearn_a_python_package_to_assess_ai_systems/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "fairlearn - a python package to assess ai system's fairness /!/ in 2015, claire cain miller wrote on [the new york times](https://www.nytimes.com/2015/07/10/upshot/when-algorithms-discriminate.html) that there was a widespread belief that software and algorithms that rely on data were objective. five years later, we know for sure that ai is not free of human influence. data is created, stored, and processed by people, machine learning algorithms are written and maintained by people, and ai applications simply reflect people\u2019s attitudes and behavior.\u00a0\n\ndata scientists know that no longer accuracy is the only concern when developing machine learning models, fairness must be considered as well. in order to make sure that machine learning solutions are fair and the value of their predictions easy to understand and explain, it is essential to build tools that developers and data scientists can use to assess their ai system\u2019s fairness and mitigate any observed unfairness issues.\n\nthis article will focus on **ai fairness**, by explaining the following aspects and tools:\n\n1. [**fairlearn**](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri): a -----> tool !!!  to assess ai system\u2019s fairness and mitigate any observed unfairness issues\n2. how to use [**fairlearn**](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri) in [**azure machine learning**](http://www.aka.ms/azuremldoc)\n3. what we mean by fairness\n4. [**fairlearn algorithms**](https://github.com/fairlearn/fairlearn?wt.mc_id=docs-twitter-lazzeri#fairlearn-algorithms)\n5. [**fairlearn dashboard**](https://github.com/fairlearn/fairlearn?wt.mc_id=docs-twitter-lazzeri#fairlearn-dashboard)\n6. comparing multiple models\n7. additional resources and [**how to contribute**](https://github.com/fairlearn/fairlearn?wt.mc_id=docs-twitter-lazzeri#contributing)\n\n## 1. fairlearn: a tool to assess ai system\u2019s fairness and mitigate any observed unfairness issues\n\n[fairlearn](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri) is a python package that empowers developers of artificial intelligence (ai) systems to assess their system\u2019s fairness and mitigate any observed unfairness issues. [fairlearn](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri) contains mitigation algorithms as well as a jupyter widget for model assessment. the [fairlearn](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri) package has two components:\n\n* a\u00a0*dashboard*\u00a0for assessing which groups are negatively impacted by a model, and for comparing multiple models in terms of various fairness and accuracy metrics.\n* *algorithms*\u00a0for mitigating unfairness in a variety of ai tasks and along a variety of fairness definitions.\n\nthere is also a collection of [jupyter notebooks](https://github.com/fairlearn/fairlearn/tree/master/notebooks?wt.mc_id=build2020_ca-blogpost-lazzeri) and an a detailed [api guide](https://fairlearn.github.io/api_reference/index.html?wt.mc_id=build2020_ca-blogpost-lazzeri), that you can check to learn how to leverage [fairlearn](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri) for your own data science scenario.\n\n## 2. how to use fairlearn in azure machine learning\n\nthe [fairlearn](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri) package can be installed via:\n\n`pip install fairlearn` \n\nor optionally with a full feature set by adding extras, e.g. pip install fairlearn\\[customplots\\], or you can clone the repository locally via:\n\n`git clone git@github.com:fairlearn/fairlearn.git` \n\nin azure machine learning, there are a few options to use jupyter notebooks for your experiments:\n\n### a) get fairlearn samples on your notebook server\n\nif you\u2019d like to bring your own notebook server for local development, follow these steps:\n\n1. use the instructions at\u00a0[**azure machine learning sdk**](https://docs.microsoft.com/python/api/overview/azure/ml/install?view=azure-ml-py?wt.mc_id=build2020_ca-blogpost-lazzeri)\u00a0to install the azure machine learning sdk for python\n2. create an\u00a0[**azure machine learning workspace**](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?wt.mc_id=build2020_ca-blogpost-lazzeri).\n3. write a\u00a0[**configuration file**](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#workspace?wt.mc_id=build2020_ca-blogpost-lazzeri) \n4. clone\u00a0[**the github repository**](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri).\n\n`git clone git@github.com:fairlearn/fairlearn.git` \n\n5. start the notebook server from your cloned directory.\n\n`jupyter notebook` \n\nfor more information, see [install the azure machine learning sdk for python](https://docs.microsoft.com/python/api/overview/azure/ml/install?wt.mc_id=build2020_ca-blogpost-lazzeri).\n\nb) get fairlearn samples on dsvm\n\nthe data science virtual machine (dsvm) is a customized vm image built specifically for doing data science. if you\u00a0[create a dsvm](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment?wt.mc_id=build2020_ca-blogpost-lazzeri#dsvm), the sdk and notebook server are installed and configured for you. however, you\u2019ll still need to create a workspace and clone the sample repository.\n\n1. [create an azure machine learning workspace](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?wt.mc_id=build2020_ca-blogpost-lazzeri).\n2. clone\u00a0[the github repository](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri).\n\n`git clone git@github.com:fairlearn/fairlearn.git`\n\n3. add a workspace configuration file to the cloned directory using either of these methods:\n\n* in the\u00a0[azure portal](https://ms.portal.azure.com/?wt.mc_id=build2020_ca-blogpost-lazzeri), select\u00a0download config.json\u00a0from the\u00a0overview section of your workspace.\n* create a new workspace using code in the\u00a0[configuration.ipynb](https://github.com/azure/machinelearningnotebooks/blob/master/configuration.ipynb?wt.mc_id=build2020_ca-blogpost-lazzeri) notebook in your cloned directory\n\n4. start the notebook server from your cloned directory:\n\n`jupyter notebook`\n\n## 3. what we mean by\u00a0fairness\n\nfighting against unfairness and discrimination has a long history in philosophy and psychology, and recently in machine learning. however, in order to be able to achieve fairness, we should first define the notion of it. an ai system can behave unfairly for a variety of reasons and many different fairness explanations have been used in literature, making this definition even more challenging. in general, fairness definitions fall under three different categories as follows:\n\n* *individual fairness* \u2013 give similar predictions to similar individuals.\u00a0\n* *group fairness* \u2013 treat different groups equally.\n* *subgroup fairness* \u2013 subgroup fairness intends to obtain the best properties of the group and individual notions of fairness.\u00a0\n\nin [fairlearn](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri), we define whether an ai system is behaving unfairly in terms of its impact on people \u2013 i.e., in terms of harms. we focus on two kinds of harms:\n\n* *allocation harms*. these harms can occur when ai systems extend or withhold opportunities, resources, or information. some of the key applications are in hiring, school admissions, and lending.\n* *quality-of-service harms*.\u00a0quality of service refers to whether a system works as well for one person as it does for another, even if no opportunities, resources, or information are extended or withheld.\n\nwe follow the approach known as group fairness, which asks: which groups of individuals are at risk of experiencing harm? the relevant groups need to be specified by the data scientist and are application-specific. group fairness is formalized by a set of constraints, which require that some aspect (or aspects) of the ai system\u2019s behavior be comparable across the groups. the [fairlearn](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri) package enables the assessment and mitigation of unfairness under several common definitions.\n\n## 4. fairlearn algorithms\n\n[fairlearn](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri) contains the following algorithms for mitigating unfairness in binary classification and regression:\n\nhttps://preview.redd.it/2inmvd6g75051.png?width=899&amp;format=png&amp;auto=webp&amp;s=3386410974a9e3640ef8ef8a409a2f19f989330a\n\n## 5. fairlearn dashboard\n\n[fairlearn](https://github.com/fairlearn/fairlearn?wt.mc_id=build2020_ca-blogpost-lazzeri) dashboard is a jupyter notebook widget for assessing how a model\u2019s predictions impact different groups (e.g., different ethnicities), and also for comparing multiple models along different fairness and accuracy metrics.\n\nto assess a single model\u2019s fairness and accuracy, the dashboard widget can be launched within a jupyter notebook as follows:\n\n`from fairlearn.widget import fairlearndashboard`\n\n`# a_test containts your sensitive features (e.g., age, binary gender)` \n\n`# sensitive_feature_names containts your sensitive feature names` \n\n`# y_true contains ground truth labels` \n\n`# y_pred contains prediction labels` \n\n`fairlearndashboard(sensitive_features=a_test,` \n\n`sensitive_feature_names=['binarygender', 'age'],`  \n\n`y_true=y_test.tolist(),`  \n\n`y_pred=[y_pred.tolist()])`\n\nafter the launch, the widget walks the user through the assessment set-up, where the user is asked to select:\n\n1. the sensitive feature of interest (e.g., binary gender or age)\n2. the accuracy metric (e.g., model precision) along which to evaluate the overall model performance as well as any disparities across groups.\u00a0\n\nthese selections are then used to obtain the visualization of the model\u2019s impact on the subgroups (e.g., model precision for females and model precision for males). the following figures illustrate the set-up steps, where binary gender is selected as a sensitive feature and the accuracy rate is selected as the accuracy metric:\n\nafter the set-up, the dashboard presents the model assessment in two panels, as summarized in the table, and visualized in the screenshot below:\n\n&amp;#x200b;\n\nhttps://preview.redd.it/enskhh7i75051.png?width=900&amp;format=png&amp;auto=webp&amp;s=db98cb058029655757df1946e42bca4831170451\n\n## 6. comparing multiple models\n\nan additional feature that this dashboard offers is the comparison of multiple models, such as the models produced by different learning algorithms and different mitigation approaches, including:\n\n* `fairlearn.reductions.gridsearch`\n* `fairlearn.reductions.exponentiatedgradient`\n* `fairlearn.postprocessing.thresholdoptimizer`\n\nas before, the user is first asked to select the sensitive feature and the accuracy metric. the\u00a0model comparison\u00a0view then depicts the accuracy and disparity of all the provided models in a scatter plot. this allows the user to examine trade-offs between algorithm accuracy and fairness. moreover, each of the dots can be clicked to open the assessment of the corresponding model.\u00a0\n\nthe figure below shows the model comparison view with binary gender selected as a sensitive feature and\u00a0accuracy rate\u00a0selected as the accuracy metric.\n\n# 7. additional resources and how to contribute\n\nfor references and additional resources, please refer to:\n\n* fairlearn github repo: [**www.aka.ms/fairlearnai**](http://www.aka.ms/fairlearnai) \n* azure machine learning: [**www.aka.ms/azuremldoc**](http://www.aka.ms/azuremldoc)\n* responsible ml at microsoft build: [**www.aka.ms/build2020responsibleml**](http://www.aka.ms/build2020responsibleml) \n* responsible ml on azure: [**www.aka.ms/azureresponsibleml**](http://www.aka.ms/azureresponsibleml)\n* responsible ml documentation: [**www.aka.ms/responsiblemldoc**](http://www.aka.ms/responsiblemldoc)\n* discrimination-aware data mining: [**http://pages.di.unipi.it/ruggieri/papers/kdd2008.pdf**\u00a0](https://dl.acm.org/doi/10.1145/1401890.1401959)\n* a survey on bias and fairness in machine learning: [**https://arxiv.org/pdf/1908.09635.pdf**](https://arxiv.org/pdf/1908.09635.pdf)\n* can an algorithm hire better than a human? [**https://www.nytimes.com/2015/06/26/upshot/can-an-algorithm-hire-better-than-a-human.html**](https://www.nytimes.com/2015/06/26/upshot/can-an-algorithm-hire-better-than-a-human.html)\n\nto contribute please check this\u00a0[contributing guide](https://fairlearn.github.io/?wt.mc_id=build2020_ca-blogpost-lazzeri#contribute).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gnzrs3/fairlearn_a_python_package_to_assess_ai_systems/',)", "identifyer": 5742851, "year": "2020"}, {"autor": "aagnone", "date": 1598140851000, "content": "[D] With an AWS Copilot, Give Kubernetes a Second Thought /!/ Kubernetes is a fantastic container orchestration tool for scalable cloud computing applications. However, we don\u2019t always need all of its batteries included. Enter ECS, with its convenient copilot CLI. Pretty slick for small apps!\n\n[https://www.lifewithdata.org/blog/aws-ecs-copilot-cli](https://www.lifewithdata.org/blog/aws-ecs-copilot-cli)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ietbvb/d_with_an_aws_copilot_give_kubernetes_a_second/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "[d] with an aws copilot, give kubernetes a second thought /!/ kubernetes is a fantastic container orchestration -----> tool !!!  for scalable cloud computing applications. however, we don\u2019t always need all of its batteries included. enter ecs, with its convenient copilot cli. pretty slick for small apps!\n\n[https://www.lifewithdata.org/blog/aws-ecs-copilot-cli](https://www.lifewithdata.org/blog/aws-ecs-copilot-cli)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ietbvb/d_with_an_aws_copilot_give_kubernetes_a_second/',)", "identifyer": 5743091, "year": "2020"}, {"autor": "ElegantFeeling", "date": 1598079303000, "content": "We built an interactive learning tool to help people get machine learning/data science jobs at Twitter, Google, Apple, ... /!/ Tool link: [**Confetti AI**](https://www.confetti.ai)\n\nWe've been working on a platform to help people prepare for machine learning and data science interviews. It builds on our experience successfully interviewing and receiving machine learning offers from many tech companies including Twitter, Apple, Google, etc. It contains questions, resources, and complete study plans for those trying to get jobs in these fields. Hopefully you find it helpful!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/iedwvz/we_built_an_interactive_learning_tool_to_help/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "we built an interactive learning -----> tool !!!  to help people get machine learning/data science jobs at twitter, google, apple, ... /!/ tool link: [**confetti ai**](https://www.confetti.ai)\n\nwe've been working on a platform to help people prepare for machine learning and data science interviews. it builds on our experience successfully interviewing and receiving machine learning offers from many tech companies including twitter, apple, google, etc. it contains questions, resources, and complete study plans for those trying to get jobs in these fields. hopefully you find it helpful!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/iedwvz/we_built_an_interactive_learning_tool_to_help/',)", "identifyer": 5743114, "year": "2020"}, {"autor": "Herrkarlson", "date": 1598045211000, "content": "Why is tensorflow king? /!/ I've done a couple of home projects using tensorflow and thought I'd give a simpler tool a try for a simple project. What a dream sklearn was! No fighting with my arrays stuck in sessions, tensors actually just being a weirdly formatted array formats and convoluted ways of building the models.\n\nWhat am I missing? Why is tf king? What can you do in tf easier or better than in, for instance, sklearn?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ie5pf1/why_is_tensorflow_king/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "why is tensorflow king? /!/ i've done a couple of home projects using tensorflow and thought i'd give a simpler -----> tool !!!  a try for a simple project. what a dream sklearn was! no fighting with my arrays stuck in sessions, tensors actually just being a weirdly formatted array formats and convoluted ways of building the models.\n\nwhat am i missing? why is tf king? what can you do in tf easier or better than in, for instance, sklearn?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 9, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ie5pf1/why_is_tensorflow_king/',)", "identifyer": 5743124, "year": "2020"}, {"autor": "yogarora235", "date": 1596339054000, "content": "Text to Numeric conversion for Classifier algo /!/ Hi guys, I am looking for help in my Classification problem.\n\nWhat I am trying to classify ?\n\nI receive 15000 daily data violations from data loss prevention tool and want to classify violations as high risk vs low risk.\n\nHow does my input look like ?\n\nTypical fields in my each of the 15000 daily violations.\n\n1. Name of policy violated  e.g. USB used, Email sent to outside network, Malicious URL visited\n\n2. Department of User e.g. HR, Admin\n\n3. Software product used e.g Salesforce, Chrome\n\n4. Time of violation e.g. Off business hours, on business hours\n\n5. Time to leave organisation e.g. 1 week, 2 weeks etc. \n\nP.S. Some policies are low risk compared to other policies and series of low risk violations can make it high risk overall.\n\n For e.g. \n\nStandalone, USB used is high risk policy violation and Email sent to outside network is low risk.\n\n\nAnother,\n\nExample of low risk\nUSB used by HR team is low risk because HR has past pattern of using USB\n\nExample of high risk\nUSB used by Network team with access to sensitive data is high risk because Network team has no past pattern of using USB\n\n\nWhat help do I need ?\n\nFirstly,\nIf someone can please help how do I convert the textual data to numeric data. What technique can I use to convert all my textual data to numeric so later I can apply any Classification algorithm ?\n\nSecondly, after first is answered above,\n\nWhich classification algorithm can I use on it ?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/i25gyh/text_to_numeric_conversion_for_classifier_algo/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "text to numeric conversion for classifier algo /!/ hi guys, i am looking for help in my classification problem.\n\nwhat i am trying to classify ?\n\ni receive 15000 daily data violations from data loss prevention -----> tool !!!  and want to classify violations as high risk vs low risk.\n\nhow does my input look like ?\n\ntypical fields in my each of the 15000 daily violations.\n\n1. name of policy violated  e.g. usb used, email sent to outside network, malicious url visited\n\n2. department of user e.g. hr, admin\n\n3. software product used e.g salesforce, chrome\n\n4. time of violation e.g. off business hours, on business hours\n\n5. time to leave organisation e.g. 1 week, 2 weeks etc. \n\np.s. some policies are low risk compared to other policies and series of low risk violations can make it high risk overall.\n\n for e.g. \n\nstandalone, usb used is high risk policy violation and email sent to outside network is low risk.\n\n\nanother,\n\nexample of low risk\nusb used by hr team is low risk because hr has past pattern of using usb\n\nexample of high risk\nusb used by network team with access to sensitive data is high risk because network team has no past pattern of using usb\n\n\nwhat help do i need ?\n\nfirstly,\nif someone can please help how do i convert the textual data to numeric data. what technique can i use to convert all my textual data to numeric so later i can apply any classification algorithm ?\n\nsecondly, after first is answered above,\n\nwhich classification algorithm can i use on it ?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 7, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/i25gyh/text_to_numeric_conversion_for_classifier_algo/',)", "identifyer": 5743446, "year": "2020"}, {"autor": "hiphop1987", "date": 1602681518000, "content": "How NOT to write pandas code? /!/ I\u2019ve been using pandas as my main tool for data analysis for the last 3 years. I must admit that most of \u201cHow NOT to code with pandas\u201d comes from my beginnings. While doing code reviews I still see many of \u201cHot NOT to-s\u201d with more experienced programmers.\n\n# Sample Dataset\n\n    import pandas as pd\n    import numpy as np\n    size = 10000\n    cities = [\"paris\", \"barcelona\", \"berlin\", \"new york\"]\n    df = pd.DataFrame(\n        {\"city\": np.random.choice(cities, size=size), \"booked_perc\": np.random.rand(size)}\n    )\n    df[\"id\"] = df.index.map(str) + \"-\" + df.city\n    df = df[[\"id\", \"city\", \"booked_perc\"]]\n    df.head()\n\nhttps://preview.redd.it/3dmoldeg92t51.png?width=1038&amp;format=png&amp;auto=webp&amp;s=71f71b0ae2e97de0e81e50fcd44bf60040abc50a\n\n# 1. How NOT to access previous values\n\nLet\u2019s calculate a percentage change from one row to another with and without a for a loop.\n\n    %%timeit\n    for i in range(1, len(df)):\n        df.loc[i, \"perc_change\"] =  (df.loc[i].booked_perc - df.loc[i - 1].booked_perc) / df.loc[i - 1].booked_perc\n    \n    7.02 s \u00b1 24.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nHow to do it pandas way?\n\n    %%timeit\n    df[\"perc_change\"] = df.booked_perc.pct_change()\n    586 \u00b5s \u00b1 17.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n\n# 2. How NOT to apply complex functions\n\nSometimes, we need to apply a complex function (a function with multiple variables) to a DataFrame. Let\u2019s say we would like to multiply booking\\_perc by two from New York, set others to 0 and name the column sales\\_factor.\n\n    %%timeit\n    for i, row in df.iterrows():\n        if row.city == 'new york':\n            df.loc[i, 'sales_factor'] = row.booked_perc * 2\n        else:\n            df.loc[i, 'sales_factor'] = 0\n    3.58 s \u00b1 48.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each\n\nHow to do it pandas way?\n\n    %%timeit\n    def calculate_sales_factor(row):\n        if row.city == 'new york':\n            return row.booked_perc * 2\n        return 0\n    df['sales_factor'] = df.apply(calculate_sales_factor, axis=1)\n    165 ms \u00b1 2.48 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n\nLearn more in: [How NOT to write pandas code](https://towardsdatascience.com/how-not-to-write-pandas-code-2cbda8b3816c)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jb0htj/how_not_to_write_pandas_code/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "how not to write pandas code? /!/ i\u2019ve been using pandas as my main -----> tool !!!  for data analysis for the last 3 years. i must admit that most of \u201chow not to code with pandas\u201d comes from my beginnings. while doing code reviews i still see many of \u201chot not to-s\u201d with more experienced programmers.\n\n# sample dataset\n\n    import pandas as pd\n    import numpy as np\n    size = 10000\n    cities = [\"paris\", \"barcelona\", \"berlin\", \"new york\"]\n    df = pd.dataframe(\n        {\"city\": np.random.choice(cities, size=size), \"booked_perc\": np.random.rand(size)}\n    )\n    df[\"id\"] = df.index.map(str) + \"-\" + df.city\n    df = df[[\"id\", \"city\", \"booked_perc\"]]\n    df.head()\n\nhttps://preview.redd.it/3dmoldeg92t51.png?width=1038&amp;format=png&amp;auto=webp&amp;s=71f71b0ae2e97de0e81e50fcd44bf60040abc50a\n\n# 1. how not to access previous values\n\nlet\u2019s calculate a percentage change from one row to another with and without a for a loop.\n\n    %%timeit\n    for i in range(1, len(df)):\n        df.loc[i, \"perc_change\"] =  (df.loc[i].booked_perc - df.loc[i - 1].booked_perc) / df.loc[i - 1].booked_perc\n    \n    7.02 s \u00b1 24.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nhow to do it pandas way?\n\n    %%timeit\n    df[\"perc_change\"] = df.booked_perc.pct_change()\n    586 \u00b5s \u00b1 17.3 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n\n# 2. how not to apply complex functions\n\nsometimes, we need to apply a complex function (a function with multiple variables) to a dataframe. let\u2019s say we would like to multiply booking\\_perc by two from new york, set others to 0 and name the column sales\\_factor.\n\n    %%timeit\n    for i, row in df.iterrows():\n        if row.city == 'new york':\n            df.loc[i, 'sales_factor'] = row.booked_perc * 2\n        else:\n            df.loc[i, 'sales_factor'] = 0\n    3.58 s \u00b1 48.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each\n\nhow to do it pandas way?\n\n    %%timeit\n    def calculate_sales_factor(row):\n        if row.city == 'new york':\n            return row.booked_perc * 2\n        return 0\n    df['sales_factor'] = df.apply(calculate_sales_factor, axis=1)\n    165 ms \u00b1 2.48 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n\nlearn more in: [how not to write pandas code](https://towardsdatascience.com/how-not-to-write-pandas-code-2cbda8b3816c)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jb0htj/how_not_to_write_pandas_code/',)", "identifyer": 5743511, "year": "2020"}, {"autor": "reddituser20-08", "date": 1602573470000, "content": "Need help with collecting data for a healthcare Flutter app /!/  Hey everyone. A few of my college mates and I are working on a project that aims to make the quality of life for PD patients better. We are also planning on applying to hackathons to win funds to better support this project of ours. Our idea aims to provide a Parkinson\u2019s Disease symptom assessment tool on an Android app. This app would allow PD patients to self-assess their symptoms with the help of image analysis by a machine learning model to analyze the severity of PD. The problem we have run into is the lack of data hence the accuracy of our model suffers. We are therefore requesting anyone who can here, to volunteer to collect more data for us by requesting as many PD patients as they can, to take this test on our behalf. This data will be submitted anonymously with the consent of the patient. Please find the google drive link as a comment which consists of a smaller app that we have developed to collect this data. Anyone who volunteers to help us with this needs to get the PD patients to take the tests on the app and send me the result images as a direct chat message without the personal details of the patient. The video there explains how that app is to be used. Please find a presentation file in the drive link for more details on this project. Thank you for taking your time out to read this, especially if you are volunteering to help us in this endeavor.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ja8ln1/need_help_with_collecting_data_for_a_healthcare/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "need help with collecting data for a healthcare flutter app /!/  hey everyone. a few of my college mates and i are working on a project that aims to make the quality of life for pd patients better. we are also planning on applying to hackathons to win funds to better support this project of ours. our idea aims to provide a parkinson\u2019s disease symptom assessment -----> tool !!!  on an android app. this app would allow pd patients to self-assess their symptoms with the help of image analysis by a machine learning model to analyze the severity of pd. the problem we have run into is the lack of data hence the accuracy of our model suffers. we are therefore requesting anyone who can here, to volunteer to collect more data for us by requesting as many pd patients as they can, to take this test on our behalf. this data will be submitted anonymously with the consent of the patient. please find the google drive link as a comment which consists of a smaller app that we have developed to collect this data. anyone who volunteers to help us with this needs to get the pd patients to take the tests on the app and send me the result images as a direct chat message without the personal details of the patient. the video there explains how that app is to be used. please find a presentation file in the drive link for more details on this project. thank you for taking your time out to read this, especially if you are volunteering to help us in this endeavor.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ja8ln1/need_help_with_collecting_data_for_a_healthcare/',)", "identifyer": 5743549, "year": "2020"}, {"autor": "purethabang", "date": 1602495025000, "content": "Machine Learning Model Testing in Staging /!/ Hey all,\n\nI'm a 19 y/o software engineer wanting to dive deeper into machine learning. Although, I know ML/DL/Ai is still brand new (compared to software eng.), why isn't there a way for machine learning models to be tested in staging environments?\n\nNo, really. Hear me out. Coming from S.W.E, we are spoiled with the plethora of developer tools (spoiled is an understatement). Whether it's a simple feature test or a full-on product preview, we have many ways to deploy software (even mobile apps) into staging instead of directly into production.\n\nWhy isn't there something like this for ML? I have a concept in my head of what it would look like...\n\nYou've just built the coolest model that allows you to serve relevant cat pictures to your super cool cat social media platform. You jump into a command-line tool and simply deploy this model as an API (whatever you use I guess, I'm new to this world so I'm not sure). You then find open-source social media source code on GitHub or get your team, friend, or cat to make you one. You hook it up to the API and deploy it on the same platform as the model and can now allow public/private access to your staging environment for beta testing or internal testing. Now, your model is tested in the real world and you have real analytics that feedbacks on how it would be used in the real world along with model performance.\n\nAll of this without any S.W.E or DevOps/MLOps teams to drag your solo tests on.\n\n10x more accurate working models for you, you, and YOU!\n\nMaybe this is just a personal problem coming from the S.W.E world but I don't get why there isn't something like this out there - if there is, please link me because I would love to use it lol.\n\nAlso, if there isn't something like this, being the S.W.E I am, who's up for the challenge to try to build it?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/j9ns99/machine_learning_model_testing_in_staging/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "machine learning model testing in staging /!/ hey all,\n\ni'm a 19 y/o software engineer wanting to dive deeper into machine learning. although, i know ml/dl/ai is still brand new (compared to software eng.), why isn't there a way for machine learning models to be tested in staging environments?\n\nno, really. hear me out. coming from s.w.e, we are spoiled with the plethora of developer tools (spoiled is an understatement). whether it's a simple feature test or a full-on product preview, we have many ways to deploy software (even mobile apps) into staging instead of directly into production.\n\nwhy isn't there something like this for ml? i have a concept in my head of what it would look like...\n\nyou've just built the coolest model that allows you to serve relevant cat pictures to your super cool cat social media platform. you jump into a command-line -----> tool !!!  and simply deploy this model as an api (whatever you use i guess, i'm new to this world so i'm not sure). you then find open-source social media source code on github or get your team, friend, or cat to make you one. you hook it up to the api and deploy it on the same platform as the model and can now allow public/private access to your staging environment for beta testing or internal testing. now, your model is tested in the real world and you have real analytics that feedbacks on how it would be used in the real world along with model performance.\n\nall of this without any s.w.e or devops/mlops teams to drag your solo tests on.\n\n10x more accurate working models for you, you, and you!\n\nmaybe this is just a personal problem coming from the s.w.e world but i don't get why there isn't something like this out there - if there is, please link me because i would love to use it lol.\n\nalso, if there isn't something like this, being the s.w.e i am, who's up for the challenge to try to build it?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/j9ns99/machine_learning_model_testing_in_staging/',)", "identifyer": 5743581, "year": "2020"}, {"autor": "mllearning", "date": 1579802491000, "content": "Amazon's new no-code ML tool Sagemaker Autopilot - cool, but charges on tiny run and returns strange results /!/ I am not a data scientist at all.\u00a0   \nI have one dataset that I like to play and learn with. It involves predicting the number of crimes in a day in my city (between about 100-200) based on weather (and some basics like day of the week etc.). A very basic linear regression problem. It's actually not very predictive.. (my\u00a0 r2\u00a0/'coefficient of determination' is in the .3-.4 range.) But I know the data and it's small, so it's fun to play with as it's quick and easy for learning.. (about 2000 rows about\u00a015 columns).   \nI have used AzureML studio and it works well there in minutes, I've also written very basic ML jobs in Python and R and all worked well and in minutes and produced similar results.  \n\n\n* Autopilot Pros:   \nIt shows you the code it's is using, so it would be relatively straightforward to take the code and drop it into a Python notebook and edit and go.\u00a0\n* Autopilot Cons :\u00a0   \nOne run used up my free tier and I was charged $12. ran for hours In theory I could have used the generated python code, and edited it to use smaller machines, run less iterations.. (It appears to run many hyperparameter tuning iterations...), but you can't do that, with the base AutoPilot, as far as I can see)  \nFinal output doesn't look correct. ObjectiveMetric = 19833  \n\n\nQuestions :\u00a0  \n 1. Is there a way to run one tiny dataset in autopilot for free?  \n 2. The final primary output is : Objective Metric... looked like a\u00a0 r2\u00a0 in the videos.. but my numbers, don't make any sense?  \nObjective Metric:   \nAverage - 26061  \nFinal Value 19833   (I don't think that is my r2)  \nCount : 22  \n\n\n(my primary source was this video series from ReInvent last month :\u00a0 [https://www.youtube.com/watch?v=qMEtqJPhqpA&amp;feature=youtu.be](https://www.youtube.com/watch?v=qMEtqJPhqpA&amp;feature=youtu.be)\u00a0)  \nAutopilot is in Preview and only works in USEast2 (and your S3 buckets must be in USEast2 also)  \ntl;dr:   \n\\-Tried to use AWS new no-code ML tool   \n\\-Sagemaker Autopilot Was charged to test one tiny dataset.\u00a0   \n\\-Results don't match other outputs.\u00a0\u00a0", "link": "https://www.reddit.com/r/learnmachinelearning/comments/esws3y/amazons_new_nocode_ml_tool_sagemaker_autopilot/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "amazon's new no-code ml -----> tool !!!  sagemaker autopilot - cool, but charges on tiny run and returns strange results /!/ i am not a data scientist at all.\u00a0   \ni have one dataset that i like to play and learn with. it involves predicting the number of crimes in a day in my city (between about 100-200) based on weather (and some basics like day of the week etc.). a very basic linear regression problem. it's actually not very predictive.. (my\u00a0 r2\u00a0/'coefficient of determination' is in the .3-.4 range.) but i know the data and it's small, so it's fun to play with as it's quick and easy for learning.. (about 2000 rows about\u00a015 columns).   \ni have used azureml studio and it works well there in minutes, i've also written very basic ml jobs in python and r and all worked well and in minutes and produced similar results.  \n\n\n* autopilot pros:   \nit shows you the code it's is using, so it would be relatively straightforward to take the code and drop it into a python notebook and edit and go.\u00a0\n* autopilot cons :\u00a0   \none run used up my free tier and i was charged $12. ran for hours in theory i could have used the generated python code, and edited it to use smaller machines, run less iterations.. (it appears to run many hyperparameter tuning iterations...), but you can't do that, with the base autopilot, as far as i can see)  \nfinal output doesn't look correct. objectivemetric = 19833  \n\n\nquestions :\u00a0  \n 1. is there a way to run one tiny dataset in autopilot for free?  \n 2. the final primary output is : objective metric... looked like a\u00a0 r2\u00a0 in the videos.. but my numbers, don't make any sense?  \nobjective metric:   \naverage - 26061  \nfinal value 19833   (i don't think that is my r2)  \ncount : 22  \n\n\n(my primary source was this video series from reinvent last month :\u00a0 [https://www.youtube.com/watch?v=qmetqjphqpa&amp;feature=youtu.be](https://www.youtube.com/watch?v=qmetqjphqpa&amp;feature=youtu.be)\u00a0)  \nautopilot is in preview and only works in useast2 (and your s3 buckets must be in useast2 also)  \ntl;dr:   \n\\-tried to use aws new no-code ml tool   \n\\-sagemaker autopilot was charged to test one tiny dataset.\u00a0   \n\\-results don't match other outputs.\u00a0\u00a0", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/esws3y/amazons_new_nocode_ml_tool_sagemaker_autopilot/',)", "identifyer": 5743594, "year": "2020"}, {"autor": "xderpt1", "date": 1579634682000, "content": "Making a usable prediction model with multilayer perceptron /!/ I'm a researcher who is beginning to look into creating a predictive model for patient outcomes after surgery using neural networks. I've been learning how to use spss and weka's mutlilayer perceptron functions but I don't know how to take the models they build and then somehow enter a new patients information and get a predictive output. \n\nAny help with this would be really appreciated. I am hoping to create a tool where we can enter patient's information into a program and get an output that predicts whether or not they will have a particular post operative complication.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/erzl16/making_a_usable_prediction_model_with_multilayer/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "making a usable prediction model with multilayer perceptron /!/ i'm a researcher who is beginning to look into creating a predictive model for patient outcomes after surgery using neural networks. i've been learning how to use spss and weka's mutlilayer perceptron functions but i don't know how to take the models they build and then somehow enter a new patients information and get a predictive output. \n\nany help with this would be really appreciated. i am hoping to create a -----> tool !!!  where we can enter patient's information into a program and get an output that predicts whether or not they will have a particular post operative complication.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/erzl16/making_a_usable_prediction_model_with_multilayer/',)", "identifyer": 5743650, "year": "2020"}, {"autor": "earnnu0", "date": 1580387243000, "content": "Extraction information from PDF files (Invoice number, line items in table) /!/ Hi there\n\n  \nFirst of all, I am fairly new to the ML world. I have researched quite a lot on the different use cases that ML have, both in regards to working with text and images.\n\nI am trying to build a \"pipeline\", that can extract a few data points from various supplier **invoices**:\n\n1. Invoice number\n2. Line items (that resides in tables)\n   1. For each line item, I would need: **quantity** and **line amount**\n\n&amp;#x200B;\n\nMy first thought was to just use a classic OCR parsing tool such as DocParser (which is basically a template-based OCR parsing tool, where you can create parsing rules for each different type of invoice layout). However, I took a look at my suppliers, and I have a lot of different layouts (with new ones being added regularly).\n\n**I was thinking if ML can be used to accomplish this task?**   \n\n\nMy idea for a pipeline:\n\n1. All supplier invoices are converted from PDF to an image file (.jpg) and then resized so all have the same width and height.\n2. Train a custom model to extract invoice number using **named entity recognization (NER)** \n3. Train a custom *computer vision* model to identify tables that contain line items (product information)\n   1. For each table found, extract that as an image and train another model to identify the entities that I need for each line: **quantity** and **line amount**\n\n  \nI am not sure if this is a good approach to this problem? Does it make sense to ultimately end off with **three** models to extract the information that I need? Is there an easier way to detect the **quantity** and **line amount,** than by first locating the table on the PDF file?  \n\n\nDoes anyone have any experience with a similar process?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ew4og5/extraction_information_from_pdf_files_invoice/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "extraction information from pdf files (invoice number, line items in table) /!/ hi there\n\n  \nfirst of all, i am fairly new to the ml world. i have researched quite a lot on the different use cases that ml have, both in regards to working with text and images.\n\ni am trying to build a \"pipeline\", that can extract a few data points from various supplier **invoices**:\n\n1. invoice number\n2. line items (that resides in tables)\n   1. for each line item, i would need: **quantity** and **line amount**\n\n&amp;#x200b;\n\nmy first thought was to just use a classic ocr parsing -----> tool !!!  such as docparser (which is basically a template-based ocr parsing -----> tool !!! , where you can create parsing rules for each different type of invoice layout). however, i took a look at my suppliers, and i have a lot of different layouts (with new ones being added regularly).\n\n**i was thinking if ml can be used to accomplish this task?**   \n\n\nmy idea for a pipeline:\n\n1. all supplier invoices are converted from pdf to an image file (.jpg) and then resized so all have the same width and height.\n2. train a custom model to extract invoice number using **named entity recognization (ner)** \n3. train a custom *computer vision* model to identify tables that contain line items (product information)\n   1. for each table found, extract that as an image and train another model to identify the entities that i need for each line: **quantity** and **line amount**\n\n  \ni am not sure if this is a good approach to this problem? does it make sense to ultimately end off with **three** models to extract the information that i need? is there an easier way to detect the **quantity** and **line amount,** than by first locating the table on the pdf file?  \n\n\ndoes anyone have any experience with a similar process?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 7, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ew4og5/extraction_information_from_pdf_files_invoice/',)", "identifyer": 5743690, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1580216823000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ev5dce/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ev5dce/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5743756, "year": "2020"}, {"autor": "ptrenko123", "date": 1586717713000, "content": "Visualizing the full graph calculation in keras or tensorflow? /!/ So i'm new to DL and I wanted be able to visually see each and every calculation that happens in a graph.\n\nThe standard visualization only returns the model without the weights and actual calculation output for a particular input. Is there any tool for this?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g02fkx/visualizing_the_full_graph_calculation_in_keras/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "visualizing the full graph calculation in keras or tensorflow? /!/ so i'm new to dl and i wanted be able to visually see each and every calculation that happens in a graph.\n\nthe standard visualization only returns the model without the weights and actual calculation output for a particular input. is there any -----> tool !!!  for this?", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g02fkx/visualizing_the_full_graph_calculation_in_keras/',)", "identifyer": 5744061, "year": "2020"}, {"autor": "izafolle", "date": 1605884647000, "content": "Looking for deep learning tutor /!/ Hi all, \n\nI have started writing a thesis in NMT that would include training a NN and I chose fairseq as the toolkit I am using. I can't for the life of me, after struggling with this for more than 3 months get the absolute super basic baseline model to give me any results whatsoever. (Like off the shelf tool that I haven't modified anything in with hyperparameters taken from papers and proven to work and the fairseq's native preprocessing files) I have never trained a NN before, but now I have already put a lot of effort into it so now sunk costs and all. \n\nI am poor but desperate so I pay accordingly.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jxqlit/looking_for_deep_learning_tutor/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "looking for deep learning tutor /!/ hi all, \n\ni have started writing a thesis in nmt that would include training a nn and i chose fairseq as the toolkit i am using. i can't for the life of me, after struggling with this for more than 3 months get the absolute super basic baseline model to give me any results whatsoever. (like off the shelf -----> tool !!!  that i haven't modified anything in with hyperparameters taken from papers and proven to work and the fairseq's native preprocessing files) i have never trained a nn before, but now i have already put a lot of effort into it so now sunk costs and all. \n\ni am poor but desperate so i pay accordingly.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jxqlit/looking_for_deep_learning_tutor/',)", "identifyer": 5744096, "year": "2020"}, {"autor": "OnlyProggingForFun", "date": 1605870853000, "content": "This AI was Made For Artists! Create Fantastical Creatures From a Quick Draft - Chimera Painter by Google (Demo Tool already Available for free)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jxn8j2/this_ai_was_made_for_artists_create_fantastical/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "this ai was made for artists! create fantastical creatures from a quick draft - chimera painter by google (demo -----> tool !!!  already available for free)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 10, "media": "('rich:video',)", "medialink": "('https://youtu.be/6zbVlf7n1zY',)", "identifyer": 5744108, "year": "2020"}, {"autor": "dulldata", "date": 1605822150000, "content": "No Code Machine Learning Microsoft Tool Lobe.AI Tutorial", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jxbyxk/no_code_machine_learning_microsoft_tool_lobeai/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "no code machine learning microsoft -----> tool !!!  lobe.ai tutorial", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('rich:video',)", "medialink": "('https://youtu.be/rm6HFfqwUPs',)", "identifyer": 5744129, "year": "2020"}, {"autor": "bendee983", "date": 1605801831000, "content": "Create adversarial examples with this interactive JavaScript tool", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jx5d1t/create_adversarial_examples_with_this_interactive/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "create adversarial examples with this interactive javascript -----> tool !!! ", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('https://bdtechtalks.com/2020/11/19/machine-learning-adversarial-js/',)", "identifyer": 5744142, "year": "2020"}, {"autor": "RepulsiveTea2", "date": 1582890184000, "content": "Need collaborators/evangelists for new AutoML library /!/ Hi: we are looking for a few good data scientists or engineers interested in trying out, collaborating and evangelizing a new AutoML tool called \u201cAuto_ViML\u201d that was published just 6 months ago. It is very good and has quite a few downloads. But it will probably be widely popular like TPOT if it had more collaborators. If anyone is interested please ping the author in the below GitHub:", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fathdl/need_collaboratorsevangelists_for_new_automl/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "need collaborators/evangelists for new automl library /!/ hi: we are looking for a few good data scientists or engineers interested in trying out, collaborating and evangelizing a new automl -----> tool !!!  called \u201cauto_viml\u201d that was published just 6 months ago. it is very good and has quite a few downloads. but it will probably be widely popular like tpot if it had more collaborators. if anyone is interested please ping the author in the below github:", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fathdl/need_collaboratorsevangelists_for_new_automl/',)", "identifyer": 5744320, "year": "2020"}, {"autor": "reduls", "date": 1582762554000, "content": "Introduction to Kurobako: A Benchmark Tool for Hyperparameter Optimization Algorithms", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fa370a/introduction_to_kurobako_a_benchmark_tool_for/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "introduction to kurobako: a benchmark -----> tool !!!  for hyperparameter optimization algorithms", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('https://medium.com/optuna/kurobako-a2e3f7b760c7',)", "identifyer": 5744375, "year": "2020"}, {"autor": "flight505", "date": 1582744733000, "content": "Creating a database from handwritten documents /!/ Hi, \n\nI have some data that I would like to move to a database. The data comes from patient records and contains information on hydration, weight, cell counts, plasma concentration etc. The records are templates and the values are written in the same place on the papers. One solution is the create a database and hire someone to manually punch in the data. But, I was hoping that it was possible to use a pre-trained model to parse the records. Or it there an azure ML tool for this?   \nany suggestions are appreciated..", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f9yi0y/creating_a_database_from_handwritten_documents/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "creating a database from handwritten documents /!/ hi, \n\ni have some data that i would like to move to a database. the data comes from patient records and contains information on hydration, weight, cell counts, plasma concentration etc. the records are templates and the values are written in the same place on the papers. one solution is the create a database and hire someone to manually punch in the data. but, i was hoping that it was possible to use a pre-trained model to parse the records. or it there an azure ml -----> tool !!!  for this?   \nany suggestions are appreciated..", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f9yi0y/creating_a_database_from_handwritten_documents/',)", "identifyer": 5744380, "year": "2020"}, {"autor": "Ohmanthatwasnice", "date": 1593259839000, "content": "I need to know to something /!/ I have always been fascinated with ML so at 15\nI stopped wanting to be a software engineer so I could learn ML .\nI started learning python and sql and after learning I went to Coursera  machine learning course by Andrew ng.\nThe problem is the topics are really hard and he goes very fast for me.\nHe will say if you don\u2019t understand it ok but I want to understand everything.\nI spend 1 hour trying to understand a 15 min video.\nAfter 2 hours of lesson my brain is being burned so i cant learn further.\nMany people i talked said nothing about ot being hard.\nI keep saying channels like samuel artz,codebullet and 2 minute papers.\nI want to be able to do what they are doing.\nI may be becouse of Hype.\nSo is ML not for me becouse people who know seem really smart and i think i am not the shapest tool in the shed.\nSorry i just needed to vent.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hgsgsw/i_need_to_know_to_something/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i need to know to something /!/ i have always been fascinated with ml so at 15\ni stopped wanting to be a software engineer so i could learn ml .\ni started learning python and sql and after learning i went to coursera  machine learning course by andrew ng.\nthe problem is the topics are really hard and he goes very fast for me.\nhe will say if you don\u2019t understand it ok but i want to understand everything.\ni spend 1 hour trying to understand a 15 min video.\nafter 2 hours of lesson my brain is being burned so i cant learn further.\nmany people i talked said nothing about ot being hard.\ni keep saying channels like samuel artz,codebullet and 2 minute papers.\ni want to be able to do what they are doing.\ni may be becouse of hype.\nso is ml not for me becouse people who know seem really smart and i think i am not the shapest -----> tool !!!  in the shed.\nsorry i just needed to vent.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 7, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hgsgsw/i_need_to_know_to_something/',)", "identifyer": 5744442, "year": "2020"}, {"autor": "takathur", "date": 1593256504000, "content": "ML to convert text into a handwritten document like school homework. /!/ Hi,\n\nI have been through open-book handwritten exams and the last exam really tended to break my hand. I have been thinking about the idea of converting text to the handwritten documents. For example, I will input text with formatting and the output would be a formatted handwritten document in form of an image that looks like scanned using a mobile app and have the option to configure metadata so that my professor doesn't catch me since he has written a Java code that reads metadata, there are some projects (I could find only two, one of them is super unnatural and the other is not completely open-source).\n\nI would like to know if anyone here has such a tool already and would like to share and if not could you guys please walk me through how can I create one of my own? Because my professor told the final exam would be of 8 hours and we won't be able to wipe the sweat off our foreheads lol.\n\nThanks.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hgrs48/ml_to_convert_text_into_a_handwritten_document/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "ml to convert text into a handwritten document like school homework. /!/ hi,\n\ni have been through open-book handwritten exams and the last exam really tended to break my hand. i have been thinking about the idea of converting text to the handwritten documents. for example, i will input text with formatting and the output would be a formatted handwritten document in form of an image that looks like scanned using a mobile app and have the option to configure metadata so that my professor doesn't catch me since he has written a java code that reads metadata, there are some projects (i could find only two, one of them is super unnatural and the other is not completely open-source).\n\ni would like to know if anyone here has such a -----> tool !!!  already and would like to share and if not could you guys please walk me through how can i create one of my own? because my professor told the final exam would be of 8 hours and we won't be able to wipe the sweat off our foreheads lol.\n\nthanks.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hgrs48/ml_to_convert_text_into_a_handwritten_document/',)", "identifyer": 5744444, "year": "2020"}, {"autor": "sachio222", "date": 1583486061000, "content": "What are best practices in visualizing data when deep learning with pytorch? /!/ As I train my models, I display my los and have an averaged loss per epoch that I output to the terminal. For decision making, my visualizations have largely been of weights, intermediate layers, outputs and that sort of thing, but I haven't yet jumped into creating charts and analytics tht most practitioners use.\n\nWhen I google it, I see plenty of options. w&amp;b, tensorboard, etc... Which is why I want to ask - do we have fairly established best practices for visualizing in pytorch during and after training? Which frameworks, techniques etc? Are there certain things that everyone just does, and they're a must have in your tool belt as a deep learning practitioner?\n\nThank you", "link": "https://www.reddit.com/r/learnmachinelearning/comments/feazb7/what_are_best_practices_in_visualizing_data_when/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "what are best practices in visualizing data when deep learning with pytorch? /!/ as i train my models, i display my los and have an averaged loss per epoch that i output to the terminal. for decision making, my visualizations have largely been of weights, intermediate layers, outputs and that sort of thing, but i haven't yet jumped into creating charts and analytics tht most practitioners use.\n\nwhen i google it, i see plenty of options. w&amp;b, tensorboard, etc... which is why i want to ask - do we have fairly established best practices for visualizing in pytorch during and after training? which frameworks, techniques etc? are there certain things that everyone just does, and they're a must have in your -----> tool !!!  belt as a deep learning practitioner?\n\nthank you", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/feazb7/what_are_best_practices_in_visualizing_data_when/',)", "identifyer": 5744512, "year": "2020"}, {"autor": "alexx600", "date": 1583430371000, "content": "offline skeleton extraction from the depth map /!/ Hello!\nI have the following problem. I have motion recordings recorded with the D435 intel realsense depth camera. The recording contains only depth channel, the files are *.bag.\n\nI'm looking for a tool that would allow to determine the skeleton either from a single frame or the whole recording.\n\nFor RGB images is openPose or do you know the equivalent for the depth image?\n\nI've had a few approaches to the subject I've tried \"cubemos\" but it gives poor results (and also requires RGB). At the moment I'm trying to get started with \"nuitrack\".\n\nI would appreciate your help.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fdyy8y/offline_skeleton_extraction_from_the_depth_map/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "offline skeleton extraction from the depth map /!/ hello!\ni have the following problem. i have motion recordings recorded with the d435 intel realsense depth camera. the recording contains only depth channel, the files are *.bag.\n\ni'm looking for a -----> tool !!!  that would allow to determine the skeleton either from a single frame or the whole recording.\n\nfor rgb images is openpose or do you know the equivalent for the depth image?\n\ni've had a few approaches to the subject i've tried \"cubemos\" but it gives poor results (and also requires rgb). at the moment i'm trying to get started with \"nuitrack\".\n\ni would appreciate your help.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fdyy8y/offline_skeleton_extraction_from_the_depth_map/',)", "identifyer": 5744528, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1583326318000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fdcjz8/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 11, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fdcjz8/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5744562, "year": "2020"}, {"autor": "cantfindusernameomg", "date": 1581987527000, "content": "Exponential time series prediction /!/ I'm trying to use the fitting tool in MATLAB to fit a simple exponential curve of the form f(x) = A + B\\*(1-exp(-k\\*x)).\n\nHowever, the way I want to do it is to:\n\nInput 9 elements -&gt; Output the 10th that follows\n\nI have 600,000 such samples.\n\nI'll admit that my machine learning basics aren't great, so I'm just trying to practice by example. How many layers would this problem require since the function is exponential? Also what is the size of each layer? It would greatly help if you guys could post some intuition behind your choice since I'm doing trial and error at the moment.\n\nI've tried a simple feedforward network with 2 hidden layers (size of 10), and the results aren't as great as I want. I can do this problem using non-linear-least-squares and get a very accurate answer, but I want to try a neural network approach.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f5j6g4/exponential_time_series_prediction/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "exponential time series prediction /!/ i'm trying to use the fitting -----> tool !!!  in matlab to fit a simple exponential curve of the form f(x) = a + b\\*(1-exp(-k\\*x)).\n\nhowever, the way i want to do it is to:\n\ninput 9 elements -&gt; output the 10th that follows\n\ni have 600,000 such samples.\n\ni'll admit that my machine learning basics aren't great, so i'm just trying to practice by example. how many layers would this problem require since the function is exponential? also what is the size of each layer? it would greatly help if you guys could post some intuition behind your choice since i'm doing trial and error at the moment.\n\ni've tried a simple feedforward network with 2 hidden layers (size of 10), and the results aren't as great as i want. i can do this problem using non-linear-least-squares and get a very accurate answer, but i want to try a neural network approach.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f5j6g4/exponential_time_series_prediction/',)", "identifyer": 5744760, "year": "2020"}, {"autor": "changerqu1", "date": 1581966177000, "content": "How can I train any model if I know only excel and statistics ? Recommend some service please /!/ Hi! I new to python and data science. My background is mostly statistics and plain old excel. Maybe you guys, can suggest me some tools or service that helps to train model and predict data based on the model without coding ? I need some simple drag and drop tool with couple buttons.\n\nAfter training I have to deploy the model at companies infrastructure. What tool can help to make it easier ?\n\nThe developers at my company are such jerks and don't want to help me to deploy it. At least I have to prepare docker image. And it also require specific skills.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f5don7/how_can_i_train_any_model_if_i_know_only_excel/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "how can i train any model if i know only excel and statistics ? recommend some service please /!/ hi! i new to python and data science. my background is mostly statistics and plain old excel. maybe you guys, can suggest me some tools or service that helps to train model and predict data based on the model without coding ? i need some simple drag and drop -----> tool !!!  with couple buttons.\n\nafter training i have to deploy the model at companies infrastructure. what tool can help to make it easier ?\n\nthe developers at my company are such jerks and don't want to help me to deploy it. at least i have to prepare docker image. and it also require specific skills.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 6, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f5don7/how_can_i_train_any_model_if_i_know_only_excel/',)", "identifyer": 5744768, "year": "2020"}, {"autor": "meowklaski", "date": 1581952404000, "content": "Python-based Educational Tools for Machine Learning /!/ Hi all,\n\nI teach a high school outreach course in ML through MIT and have been developing some free educational tools / resources towards this end over the past few years. Hopefully these will be helpful for students / teachers alike:\n\n[mygrad](https://mygrad.readthedocs.io/en/latest/intro.html) is a auto-differentiation library that is a thin wrapper around NumPy. With mygrad in hand, my students need only learn NumPy's syntax and rules for array mathematics, but still have the power of auto-diff available to them. It also provides essential operations (e.g. N-dimensional convolutions, pooling, batch-norm, a numba-compiled GRU, etc.) for creating neural networks. This library is simple but quite powerful, if I do say so myself!\n\n[noggin](https://noggin.readthedocs.io/en/latest/) is a library for live-logging and live-plotting measurements during experiments, all in a Jupyter notebook. Think of this as extremely simple version of TensorBoard. This is a great tool for my students to monitor their models' progress in real time. The logging is quite nice too and exports measurements as xarrays (I also use this tool in my actual research!)\n\n[Python Like You Mean It](https://www.pythonlikeyoumeanit.com/) is a totally-free (no ads!) resource for learning the basics of Python and NumPy, with a bent towards STEM applications. This has proven to be an effective resource for students to develop the sort of Python experience that they need in order to be effective in ML.\n\nI hope that you all find these resources useful. Please also pass these along to educators who may be well-served by them! :)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f5a33r/pythonbased_educational_tools_for_machine_learning/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "python-based educational tools for machine learning /!/ hi all,\n\ni teach a high school outreach course in ml through mit and have been developing some free educational tools / resources towards this end over the past few years. hopefully these will be helpful for students / teachers alike:\n\n[mygrad](https://mygrad.readthedocs.io/en/latest/intro.html) is a auto-differentiation library that is a thin wrapper around numpy. with mygrad in hand, my students need only learn numpy's syntax and rules for array mathematics, but still have the power of auto-diff available to them. it also provides essential operations (e.g. n-dimensional convolutions, pooling, batch-norm, a numba-compiled gru, etc.) for creating neural networks. this library is simple but quite powerful, if i do say so myself!\n\n[noggin](https://noggin.readthedocs.io/en/latest/) is a library for live-logging and live-plotting measurements during experiments, all in a jupyter notebook. think of this as extremely simple version of tensorboard. this is a great -----> tool !!!  for my students to monitor their models' progress in real time. the logging is quite nice too and exports measurements as xarrays (i also use this tool in my actual research!)\n\n[python like you mean it](https://www.pythonlikeyoumeanit.com/) is a totally-free (no ads!) resource for learning the basics of python and numpy, with a bent towards stem applications. this has proven to be an effective resource for students to develop the sort of python experience that they need in order to be effective in ml.\n\ni hope that you all find these resources useful. please also pass these along to educators who may be well-served by them! :)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 8, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f5a33r/pythonbased_educational_tools_for_machine_learning/',)", "identifyer": 5744781, "year": "2020"}, {"autor": "Moritz_W", "date": 1607529626000, "content": "LaserFocusCam \u2014 an ML Distraction detector \ud83d\udc40 \ud83d\uddb2 \ud83d\udda5 /!/ I want to build a simple web-app that you can run in the **background while working** that uses your webcam to detect and alerts you when **your face looks distracted**.\n\n# Project Design Thoughts\n\n* **Model**: I know that I can train the model using tools like [Teachable Machine](https://teachablemachine.withgoogle.com/), which I tried did. This seems to work, but if you know of any similar more professional tool, let me know. \n* **App Architecture**: I think running the Model on the frontend is best because it reduces privacy risks. The trade-off is the high processing demand, but when one only tracks the distraction state every 5 seconds or so, that should be alight. \n\nSince I have a lot of experience with react as a web developer, I would prefer this as a framework but am open to suggestions. I know the basics of AI and ML but want to get my hands dirty on a project right away. \n\nAny help, suggestion, and recommendations are highly appreciated!!!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/k9uful/laserfocuscam_an_ml_distraction_detector/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "laserfocuscam \u2014 an ml distraction detector \ud83d\udc40 \ud83d\uddb2 \ud83d\udda5 /!/ i want to build a simple web-app that you can run in the **background while working** that uses your webcam to detect and alerts you when **your face looks distracted**.\n\n# project design thoughts\n\n* **model**: i know that i can train the model using tools like [teachable machine](https://teachablemachine.withgoogle.com/), which i tried did. this seems to work, but if you know of any similar more professional -----> tool !!! , let me know. \n* **app architecture**: i think running the model on the frontend is best because it reduces privacy risks. the trade-off is the high processing demand, but when one only tracks the distraction state every 5 seconds or so, that should be alight. \n\nsince i have a lot of experience with react as a web developer, i would prefer this as a framework but am open to suggestions. i know the basics of ai and ml but want to get my hands dirty on a project right away. \n\nany help, suggestion, and recommendations are highly appreciated!!!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/k9uful/laserfocuscam_an_ml_distraction_detector/',)", "identifyer": 5744923, "year": "2020"}, {"autor": "1amrocket", "date": 1584698061000, "content": "Is there a Collaborative free text labelling tool /!/ I have a dataset consisting of questions and possible answers to that question {question, {answer1, answer2,...}}\n\nI am trying to find a free labelling web tool I can distribute to friends where for each question they select most likely answer. Have you encountered something similar by any chance?\n\nThe closest thing I found is ([https://prodi.gy/demo](https://prodi.gy/demo) Single Choice(Text)) but it's not free", "link": "https://www.reddit.com/r/learnmachinelearning/comments/flseyc/is_there_a_collaborative_free_text_labelling_tool/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "is there a collaborative free text labelling -----> tool !!!  /!/ i have a dataset consisting of questions and possible answers to that question {question, {answer1, answer2,...}}\n\ni am trying to find a free labelling web tool i can distribute to friends where for each question they select most likely answer. have you encountered something similar by any chance?\n\nthe closest thing i found is ([https://prodi.gy/demo](https://prodi.gy/demo) single choice(text)) but it's not free", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/flseyc/is_there_a_collaborative_free_text_labelling_tool/',)", "identifyer": 5745102, "year": "2020"}, {"autor": "PM_ME_GOOD_NEWS_", "date": 1584654118000, "content": "How to use these pre-trained models? /!/ Hi everyone, \n\nI'm trying to build a tool to detect fish in an image. I found some pre-trained models that I think might work:\n\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models\n\nI'm still new to this stuff though so I don't know how to utilize these. Can someone give me a very rough guide on how to use the files included in each of these models (a \"graph proto\", a *frozen* graph proto, a checkpoint and a config file).\n\nI really appreciate any help you can give! Thanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/flig7g/how_to_use_these_pretrained_models/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "how to use these pre-trained models? /!/ hi everyone, \n\ni'm trying to build a -----> tool !!!  to detect fish in an image. i found some pre-trained models that i think might work:\n\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models\n\ni'm still new to this stuff though so i don't know how to utilize these. can someone give me a very rough guide on how to use the files included in each of these models (a \"graph proto\", a *frozen* graph proto, a checkpoint and a config file).\n\ni really appreciate any help you can give! thanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/flig7g/how_to_use_these_pretrained_models/',)", "identifyer": 5745117, "year": "2020"}, {"autor": "StoneCypher", "date": 1597294327000, "content": "Is there a good just-tooling Tensorflow fast start for programmers? /!/ I already know the theory.  What I don't know is Tensorflow.\n\nWhat I would really like is a tutorial that didn't try to teach me almost anything, other than the actual tooling.  Here's mNIST, let's make an autoencoder.\n\nI want it to start from installing the libraries, and I don't want to be taught how an autoencoder works, or about the magic of machine learning\n\nI really just want to know how to do ground zero in this tool\n\nIs there a place I can start reading that minimizes the side stuff?  Thanks", "link": "https://www.reddit.com/r/learnmachinelearning/comments/i8toak/is_there_a_good_justtooling_tensorflow_fast_start/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "is there a good just-tooling tensorflow fast start for programmers? /!/ i already know the theory.  what i don't know is tensorflow.\n\nwhat i would really like is a tutorial that didn't try to teach me almost anything, other than the actual tooling.  here's mnist, let's make an autoencoder.\n\ni want it to start from installing the libraries, and i don't want to be taught how an autoencoder works, or about the magic of machine learning\n\ni really just want to know how to do ground zero in this -----> tool !!! \n\nis there a place i can start reading that minimizes the side stuff?  thanks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 40, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/i8toak/is_there_a_good_justtooling_tensorflow_fast_start/',)", "identifyer": 5745299, "year": "2020"}, {"autor": "YouMakeMeSaaaaaad", "date": 1597200207000, "content": "Keypoint detection problem - Image tagging /!/ guys, please help me. I can't find any tool or software like \"LabelImg\" with which I can save keypoints data in pascal VOC format.\ni am at my wits end. I had been using website makesense.ai to get keypoints in csv file.\nplease kindly give me some solution/suggestion. i am at my wits end. i am at my breaking point. this is hard. i am in hell", "link": "https://www.reddit.com/r/learnmachinelearning/comments/i85qry/keypoint_detection_problem_image_tagging/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "keypoint detection problem - image tagging /!/ guys, please help me. i can't find any -----> tool !!!  or software like \"labelimg\" with which i can save keypoints data in pascal voc format.\ni am at my wits end. i had been using website makesense.ai to get keypoints in csv file.\nplease kindly give me some solution/suggestion. i am at my wits end. i am at my breaking point. this is hard. i am in hell", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/i85qry/keypoint_detection_problem_image_tagging/',)", "identifyer": 5745339, "year": "2020"}, {"autor": "MusingEtMachina", "date": 1597165774000, "content": "We built an interactive learning tool to help people ace their machine learning and data science interviews", "link": "https://www.reddit.com/r/learnmachinelearning/comments/i7vn6a/we_built_an_interactive_learning_tool_to_help/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "we built an interactive learning -----> tool !!!  to help people ace their machine learning and data science interviews", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('http://www.confetti.ai',)", "identifyer": 5745359, "year": "2020"}, {"autor": "mathmage", "date": 1591600194000, "content": "Text recognition: detecting Bible references in literature /!/ The Bible might be the most influential book of all time.  I'm scoping out a project to develop a tool which would take a passage from a literary text and attempt to detect any Biblical references in that text.\n\nA Biblical reference in this case would be a quote or near-quote from the Bible - I'm not trying to get my tool to recognize that Aslan is Jesus or anything.  I'll be using a bunch of different English translations of the Bible as the reference material.  I would like to strip \"references\" that are totally generic sentences.  Ideally, I would like to be able to scale the tool to be able to analyze patterns of Biblical reference across a large body of literature.\n\nThis is still a very messy project concept.  I'm not even sure whether it's trivial or way too difficult.  However, I'd like to know if the community can suggest useful angles of attack.  Thanks for your patience with a newbie!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gyubeo/text_recognition_detecting_bible_references_in/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "text recognition: detecting bible references in literature /!/ the bible might be the most influential book of all time.  i'm scoping out a project to develop a -----> tool !!!  which would take a passage from a literary text and attempt to detect any biblical references in that text.\n\na biblical reference in this case would be a quote or near-quote from the bible - i'm not trying to get my tool to recognize that aslan is jesus or anything.  i'll be using a bunch of different english translations of the bible as the reference material.  i would like to strip \"references\" that are totally generic sentences.  ideally, i would like to be able to scale the tool to be able to analyze patterns of biblical reference across a large body of literature.\n\nthis is still a very messy project concept.  i'm not even sure whether it's trivial or way too difficult.  however, i'd like to know if the community can suggest useful angles of attack.  thanks for your patience with a newbie!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gyubeo/text_recognition_detecting_bible_references_in/',)", "identifyer": 5745751, "year": "2020"}, {"autor": "Are_We_There_Yet256", "date": 1590996107000, "content": "Git just isn't the right tool for me to track my model's performance and parameters - what else to use instead? /!/ Hello!\n\n  \nI've noticed that for me Git just isn't the right tool for Data Science with some uses cases left unresolved. Just like there are migrations for databases to track the changes in the schemes of the db, there should be some tool to track the changes in the parameters, changes in the data ( important for real time analysis ), the accuracy and recall for different iterations and so on. \n\nDo you guys into this kind of similar problem?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gufzwj/git_just_isnt_the_right_tool_for_me_to_track_my/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "git just isn't the right -----> tool !!!  for me to track my model's performance and parameters - what else to use instead? /!/ hello!\n\n  \ni've noticed that for me git just isn't the right tool for data science with some uses cases left unresolved. just like there are migrations for databases to track the changes in the schemes of the db, there should be some tool to track the changes in the parameters, changes in the data ( important for real time analysis ), the accuracy and recall for different iterations and so on. \n\ndo you guys into this kind of similar problem?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gufzwj/git_just_isnt_the_right_tool_for_me_to_track_my/',)", "identifyer": 5745827, "year": "2020"}, {"autor": "pp314159", "date": 1589292778000, "content": "An Automated Machine Learning Python Package with Explanations and Markdown Reports /!/ The [mljar-supervised](https://github.com/mljar/mljar-supervised) is an AutoML tool that works with tabular data. It can handle binary classification, multiclass classification, and regression problems.\n\nWhat's good in it:\n\n- it can produce markdown reports which you can commit to the repository, for example: https://github.com/mljar/mljar-examples/tree/master/House_price_regression\n\n- it computes the Baseline, so you can check if you need ML or not\n\n- this package is training simple Decision Trees with max_depth &lt;= 5, so you can easily visualize them with amazing dtreeviz to better understand your data.\n\n- it is using simple linear regression and include its coefficients in the summary report,\n\n- it has a vast set of algorithms: Random Forest, Extra Trees, LightGBM, Xgboost, CatBoost (Neural Networks will be added soon).\n\n- it can do features preprocessing, like: missing values imputation and converting categoricals. What is more, it can also handle target values preprocessing (You won't believe how often it is needed!). For example, converting categorical target into numeric.\n\n- it tunes hyper-parameters with not-so-random-search algorithm (random-search over a defined set of values) and hill-climbing to fine-tune final models.\n\n- it cares about the explainability of models: for every algorithm, the feature importance is computed based on permutation. Additionally, for every algorithm, the SHAP explanations are computed: feature importance, dependence plots, and decision plots (explanations can be switched off with explain_level parameter).", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gibz2j/an_automated_machine_learning_python_package_with/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "an automated machine learning python package with explanations and markdown reports /!/ the [mljar-supervised](https://github.com/mljar/mljar-supervised) is an automl -----> tool !!!  that works with tabular data. it can handle binary classification, multiclass classification, and regression problems.\n\nwhat's good in it:\n\n- it can produce markdown reports which you can commit to the repository, for example: https://github.com/mljar/mljar-examples/tree/master/house_price_regression\n\n- it computes the baseline, so you can check if you need ml or not\n\n- this package is training simple decision trees with max_depth &lt;= 5, so you can easily visualize them with amazing dtreeviz to better understand your data.\n\n- it is using simple linear regression and include its coefficients in the summary report,\n\n- it has a vast set of algorithms: random forest, extra trees, lightgbm, xgboost, catboost (neural networks will be added soon).\n\n- it can do features preprocessing, like: missing values imputation and converting categoricals. what is more, it can also handle target values preprocessing (you won't believe how often it is needed!). for example, converting categorical target into numeric.\n\n- it tunes hyper-parameters with not-so-random-search algorithm (random-search over a defined set of values) and hill-climbing to fine-tune final models.\n\n- it cares about the explainability of models: for every algorithm, the feature importance is computed based on permutation. additionally, for every algorithm, the shap explanations are computed: feature importance, dependence plots, and decision plots (explanations can be switched off with explain_level parameter).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gibz2j/an_automated_machine_learning_python_package_with/',)", "identifyer": 5746038, "year": "2020"}, {"autor": "drum_playing_twig", "date": 1589247594000, "content": "People who work as ML engineers, when do you use notebooks vs a traditional IDE? /!/ I'm a front end developer looking to transition to machine learning / data science. \n\nFrom what I understand so far, notebooks are a useful tool for executing code in cells so you don't have to re-run certain time consuming steps, but in most tutorials and I don't see much mention of a IDEs like PyCharm.\n\nSo a couple of question to all of you **who work for a company** (not studying or in a school environment) as ML engineers:\n\n1. When do you use a notebook vs an IDE?\n2. Do you use both? \n3. Are notebooks used only in the initial step of a project, e.g. when you're exploring the data, and then you \"move\" over to an IDE when it's time to integrate your model to your code base / APIs?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gi1e09/people_who_work_as_ml_engineers_when_do_you_use/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "people who work as ml engineers, when do you use notebooks vs a traditional ide? /!/ i'm a front end developer looking to transition to machine learning / data science. \n\nfrom what i understand so far, notebooks are a useful -----> tool !!!  for executing code in cells so you don't have to re-run certain time consuming steps, but in most tutorials and i don't see much mention of a ides like pycharm.\n\nso a couple of question to all of you **who work for a company** (not studying or in a school environment) as ml engineers:\n\n1. when do you use a notebook vs an ide?\n2. do you use both? \n3. are notebooks used only in the initial step of a project, e.g. when you're exploring the data, and then you \"move\" over to an ide when it's time to integrate your model to your code base / apis?", "sortedWord": "None", "removed": "('nan',)", "score": 4, "comments": 13, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gi1e09/people_who_work_as_ml_engineers_when_do_you_use/',)", "identifyer": 5746058, "year": "2020"}, {"autor": "levelupdigital", "date": 1589226259000, "content": "How to make a web tool out of my trained model? /!/ Machine learning model to web tool?\n\nHi,\nthis might seem like a strange and rather broad question but I can\u2019t seem to find anything on this topic that really helps me out.\n\nMy problem:\nI have a trained model (python) and I\u2019d like to make a web tool out of that model. (Example: classify images by uploading an image, ...)\n\nI know how to make the model and how to train it and I can also make a web application (with simple backend - auth, database, etc)\n\nBut I don\u2019t seem to find any recourses on how to \u2018combine\u2019 that and make a ml tool. I don\u2019t even know where to start...\n\nCan somebody give sort of a roadmap or something how I can do that or learn that?\n\nThank you very much.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ghux1g/how_to_make_a_web_tool_out_of_my_trained_model/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "how to make a web -----> tool !!!  out of my trained model? /!/ machine learning model to web tool?\n\nhi,\nthis might seem like a strange and rather broad question but i can\u2019t seem to find anything on this topic that really helps me out.\n\nmy problem:\ni have a trained model (python) and i\u2019d like to make a web tool out of that model. (example: classify images by uploading an image, ...)\n\ni know how to make the model and how to train it and i can also make a web application (with simple backend - auth, database, etc)\n\nbut i don\u2019t seem to find any recourses on how to \u2018combine\u2019 that and make a ml tool. i don\u2019t even know where to start...\n\ncan somebody give sort of a roadmap or something how i can do that or learn that?\n\nthank you very much.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ghux1g/how_to_make_a_web_tool_out_of_my_trained_model/',)", "identifyer": 5746068, "year": "2020"}, {"autor": "felipep31", "date": 1588462086000, "content": "What should i use for IA /!/ Hello, i am computer science student, just started learning AI, i am want to know what the best programming language (Tool), for me to learn artificial inteligence:\n\nPython\nR\nJulia\nOthers...", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gcg89g/what_should_i_use_for_ia/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "what should i use for ia /!/ hello, i am computer science student, just started learning ai, i am want to know what the best programming language (-----> tool !!! ), for me to learn artificial inteligence:\n\npython\nr\njulia\nothers...", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 6, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gcg89g/what_should_i_use_for_ia/',)", "identifyer": 5746116, "year": "2020"}, {"autor": "happypuppy100", "date": 1601774131000, "content": "Help! What does basic clustering of items? /!/ Items are words, not numbers.\n\nNeed good Viz tool that does this basic thing\n\n1. Say you have a set of 5-7 associated/related  items\n2. There's multiple sets\n3. The viz tool automatically creates clusters / a network graph of these items\n   1. and associated moreso with each other are closer in the clusters\n\nI know there are viz sites/tools out there that make making certain kinds of visualizations simple with a click of a button\n\nKnow of any sites like that ??", "link": "https://www.reddit.com/r/learnmachinelearning/comments/j4qjbq/help_what_does_basic_clustering_of_items/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "help! what does basic clustering of items? /!/ items are words, not numbers.\n\nneed good viz -----> tool !!!  that does this basic thing\n\n1. say you have a set of 5-7 associated/related  items\n2. there's multiple sets\n3. the viz tool automatically creates clusters / a network graph of these items\n   1. and associated moreso with each other are closer in the clusters\n\ni know there are viz sites/tools out there that make making certain kinds of visualizations simple with a click of a button\n\nknow of any sites like that ??", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/j4qjbq/help_what_does_basic_clustering_of_items/',)", "identifyer": 5746211, "year": "2020"}, {"autor": "happypuppy100", "date": 1601518923000, "content": "Help! What viz tools can do this? /!/ Need Viz tool that does this basic thing\n\n1. Say you have a set of 5-7 associated/related  items\n2. There's multiple sets\n3. The viz tool automatically creates clusters / a network graph of these items\n   1. and associated moreso with each other are closer in the clusters\n\nI know there are viz sites/tools out there that make making certain kinds of visualizations simple with a click of a button\n\nKnow of any sites like that?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/j2zyef/help_what_viz_tools_can_do_this/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "help! what viz tools can do this? /!/ need viz -----> tool !!!  that does this basic thing\n\n1. say you have a set of 5-7 associated/related  items\n2. there's multiple sets\n3. the viz tool automatically creates clusters / a network graph of these items\n   1. and associated moreso with each other are closer in the clusters\n\ni know there are viz sites/tools out there that make making certain kinds of visualizations simple with a click of a button\n\nknow of any sites like that?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/j2zyef/help_what_viz_tools_can_do_this/',)", "identifyer": 5746283, "year": "2020"}, {"autor": "caseyjack7", "date": 1599233785000, "content": "Algomatic: An Artificial Intelligence Trading Platform /!/ [Algomatic](https://algomatic.co/) is a web-based no-code AI trading tool and we're looking for early feedback. One key feature of the site is a Wiki and we're looking to see if it could become a learning platform for AI in finance without having to know how to code.\n\nAt the moment we have some basic regression models, decisions trees and a neural net with a single hidden layer. We have more models on the way and of course more data points to plug in.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/imi5lt/algomatic_an_artificial_intelligence_trading/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "algomatic: an artificial intelligence trading platform /!/ [algomatic](https://algomatic.co/) is a web-based no-code ai trading -----> tool !!!  and we're looking for early feedback. one key feature of the site is a wiki and we're looking to see if it could become a learning platform for ai in finance without having to know how to code.\n\nat the moment we have some basic regression models, decisions trees and a neural net with a single hidden layer. we have more models on the way and of course more data points to plug in.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/imi5lt/algomatic_an_artificial_intelligence_trading/',)", "identifyer": 5746326, "year": "2020"}, {"autor": "prestodigitarium", "date": 1602205529000, "content": "Where do you find datasets? /!/ Hi there! How do you all usually find good datasets to work with or augment other datasets with? Is there anything about that process that you wish was improved?\n\nWe're a couple of machine learning students working on a tool to try to make it easier to find and download relevant tabular datasets, by searching by lat/long, date/time, and hopefully other joinable column types in the future.\n\nWe're basically trying to make it possible to:\n\n* search for datasets that are joinable to your dataframe and have significant overlap (if your data is all about Boston, there's no point scrolling through 1,000 NYC datasets)\n* download the parts/rows that match your data, delivered as a pandas dataframe, to avoid any CSV munging \n* do it all within your notebook, via a python library\n\nI think NOAA's general summary of the day weather dataset had 10s of thousands of CSVs in each of a bunch of folders to massage and combine. That was stupid. And the 2010 US decennial census, holy crap. The PDF docs about the file format was multiple hundreds of pages. There's no reason every user of this data should have to repeat that work. That's a big part of the reason we're working on this.\n\nWe've been hacking on the fun crunchy challenges this involves for a bit, but we realized that we never really bothered to check to see if anyone else wanted something like this. Does this sound like something you might be interested in?\n\nIf so, any requests for public datasets that would be be useful? So far we just have a few from NOAA, EPA, Census, USGS, and some other public orgs. \n\nCould you see yourself exploring datasets using a python library and interpreter/notebook, or do you think you'd rather mostly do that on a website? Could you see yourself ever uploading a dataset to a public searchable repository of datasets? Anything you'd be particularly concerned about when doing so, like licenses?\n\nAnd if this all seems stupid, we'd love to hear why it's a stupid idea.\n\nWhew. Thanks for any input you can give.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/j7pmgv/where_do_you_find_datasets/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "where do you find datasets? /!/ hi there! how do you all usually find good datasets to work with or augment other datasets with? is there anything about that process that you wish was improved?\n\nwe're a couple of machine learning students working on a -----> tool !!!  to try to make it easier to find and download relevant tabular datasets, by searching by lat/long, date/time, and hopefully other joinable column types in the future.\n\nwe're basically trying to make it possible to:\n\n* search for datasets that are joinable to your dataframe and have significant overlap (if your data is all about boston, there's no point scrolling through 1,000 nyc datasets)\n* download the parts/rows that match your data, delivered as a pandas dataframe, to avoid any csv munging \n* do it all within your notebook, via a python library\n\ni think noaa's general summary of the day weather dataset had 10s of thousands of csvs in each of a bunch of folders to massage and combine. that was stupid. and the 2010 us decennial census, holy crap. the pdf docs about the file format was multiple hundreds of pages. there's no reason every user of this data should have to repeat that work. that's a big part of the reason we're working on this.\n\nwe've been hacking on the fun crunchy challenges this involves for a bit, but we realized that we never really bothered to check to see if anyone else wanted something like this. does this sound like something you might be interested in?\n\nif so, any requests for public datasets that would be be useful? so far we just have a few from noaa, epa, census, usgs, and some other public orgs. \n\ncould you see yourself exploring datasets using a python library and interpreter/notebook, or do you think you'd rather mostly do that on a website? could you see yourself ever uploading a dataset to a public searchable repository of datasets? anything you'd be particularly concerned about when doing so, like licenses?\n\nand if this all seems stupid, we'd love to hear why it's a stupid idea.\n\nwhew. thanks for any input you can give.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/j7pmgv/where_do_you_find_datasets/',)", "identifyer": 5746476, "year": "2020"}, {"autor": "MusingEtMachina", "date": 1600875950000, "content": "We developed a study guide for becoming a machine learning engineer /!/ Tool link: [**Confetti AI**](https://www.confetti.ai/)\n\nWe are releasing a full curriculum guide for becoming a machine learning engineer. It builds on our experiences as machine learning engineers/full-stack data scientists, and it contains questions and resources for those trying to get jobs in these fields. Hopefully you find it helpful!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/iycmfv/we_developed_a_study_guide_for_becoming_a_machine/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "we developed a study guide for becoming a machine learning engineer /!/ -----> tool !!!  link: [**confetti ai**](https://www.confetti.ai/)\n\nwe are releasing a full curriculum guide for becoming a machine learning engineer. it builds on our experiences as machine learning engineers/full-stack data scientists, and it contains questions and resources for those trying to get jobs in these fields. hopefully you find it helpful!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 20, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/iycmfv/we_developed_a_study_guide_for_becoming_a_machine/',)", "identifyer": 5746712, "year": "2020"}, {"autor": "qi-zheng", "date": 1598727940000, "content": "Create Machine Learning Web Apps /!/ I'm currently studying data science in an online master's program and during the semester break, I decided to look into the possibility of simple web apps to demonstrate a tool (i.e., some ML model) that could be developed within any given project. The goal of this Kaggle kernel is to show others how they can also create a web app, but I try to go further by containerizing it first with Docker and then deploying it on Heroku. I explain more about these services in the post below. I hope that it can help you guys to do the same for your own projects.\n\n[https://www.kaggle.com/yuqizheng/creating-a-data-science-web-app](https://www.kaggle.com/yuqizheng/creating-a-data-science-web-app)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/iiy5sq/create_machine_learning_web_apps/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "create machine learning web apps /!/ i'm currently studying data science in an online master's program and during the semester break, i decided to look into the possibility of simple web apps to demonstrate a -----> tool !!!  (i.e., some ml model) that could be developed within any given project. the goal of this kaggle kernel is to show others how they can also create a web app, but i try to go further by containerizing it first with docker and then deploying it on heroku. i explain more about these services in the post below. i hope that it can help you guys to do the same for your own projects.\n\n[https://www.kaggle.com/yuqizheng/creating-a-data-science-web-app](https://www.kaggle.com/yuqizheng/creating-a-data-science-web-app)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/iiy5sq/create_machine_learning_web_apps/',)", "identifyer": 5746758, "year": "2020"}, {"autor": "richardvecsey", "date": 1598723515000, "content": "Repository to help training with larger batch size /!/  Hi guys,\n\nLet me introduce a repository that you might find useful during deep learning training especially when you use large batch size in PyTorch. If you ever needed or wished to try out the training of a model with bigger batch size than you could solve with your own GPU memory or with Google Colab you would find our library a useful tool. There are some useful tools that help to manage CUDA memory. Remember, this is a first release, but we are working on the code to improve it.\n\n[https://github.com/hyperrixel/infinitybatch](https://github.com/hyperrixel/infinitybatch)\n\nRegards,\n\nRichard", "link": "https://www.reddit.com/r/learnmachinelearning/comments/iiwu8t/repository_to_help_training_with_larger_batch_size/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "repository to help training with larger batch size /!/  hi guys,\n\nlet me introduce a repository that you might find useful during deep learning training especially when you use large batch size in pytorch. if you ever needed or wished to try out the training of a model with bigger batch size than you could solve with your own gpu memory or with google colab you would find our library a useful -----> tool !!! . there are some useful tools that help to manage cuda memory. remember, this is a first release, but we are working on the code to improve it.\n\n[https://github.com/hyperrixel/infinitybatch](https://github.com/hyperrixel/infinitybatch)\n\nregards,\n\nrichard", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/iiwu8t/repository_to_help_training_with_larger_batch_size/',)", "identifyer": 5746762, "year": "2020"}, {"autor": "diabulusInMusica", "date": 1598522953000, "content": "I published a video where I explain the Discrete Fourier Transform easily /!/ We live in a world engulfed with digital (audio) signals \ud83c\udfa7 \ud83c\udfa7. To make sense of these signals, we can\u2019t use the (Continuous) Fourier Transform. We should adapt this powerful tool to the digital domain. Hence, the Digital Fourier Transform (DFT). Discover the secrets of DFT in my new video!\n\nThis video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data \ud83c\udfa7 and extract relevant audio features for your machine learning applications \ud83e\udd16\ud83e\udd16.\n\nHere\u2019s the video:\n\n[https://www.youtube.com/watch?v=ZUi\\_jdOyxIQ&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=13](https://www.youtube.com/watch?v=ZUi_jdOyxIQ&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=13)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ihidxd/i_published_a_video_where_i_explain_the_discrete/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i published a video where i explain the discrete fourier transform easily /!/ we live in a world engulfed with digital (audio) signals \ud83c\udfa7 \ud83c\udfa7. to make sense of these signals, we can\u2019t use the (continuous) fourier transform. we should adapt this powerful -----> tool !!!  to the digital domain. hence, the digital fourier transform (dft). discover the secrets of dft in my new video!\n\nthis video is part of the audio processing for machine learning series. this course aims to teach you how to process audio data \ud83c\udfa7 and extract relevant audio features for your machine learning applications \ud83e\udd16\ud83e\udd16.\n\nhere\u2019s the video:\n\n[https://www.youtube.com/watch?v=zui\\_jdoyxiq&amp;list=pl-watfeyamnqiee7ch3q1bh4qjfaaenv0&amp;index=13](https://www.youtube.com/watch?v=zui_jdoyxiq&amp;list=pl-watfeyamnqiee7ch3q1bh4qjfaaenv0&amp;index=13)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ihidxd/i_published_a_video_where_i_explain_the_discrete/',)", "identifyer": 5746853, "year": "2020"}, {"autor": "thejournalclub", "date": 1587712143000, "content": "The Journal Club: A tool to help you organize your journal clubs/reading groups /!/ [removed]", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g73u6n/the_journal_club_a_tool_to_help_you_organize_your/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "the journal club: a -----> tool !!!  to help you organize your journal clubs/reading groups /!/ [removed]", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g73u6n/the_journal_club_a_tool_to_help_you_organize_your/',)", "identifyer": 5746950, "year": "2020"}, {"autor": "geeksforgeeks", "date": 1605589339000, "content": "How Does NASA Use Machine Learning? /!/ [NASA](https://www.nasa.gov/) is involved in all aspects of space ranging from studying Earth\u2019s outer atmosphere to finding signs of life on other planets! And [Machine Learning](https://www.geeksforgeeks.org/machine-learning/) is a big part of this space discovery as it is a necessary tool in this data age. The amount of data generated by various NASA spacecraft and satellites is insane (As an example, consider that only the [**Sloan Digital Sky Survey**](https://www.sdss.org/) will create more than **50 million** images of galaxies in the future!) and hence Machine Learning is necessary to identify patterns in this data which will lead to exciting new discoveries in the future!  \n\nInteresting Topic? Well then Read More-&gt; [https://www.geeksforgeeks.org/how-does-nasa-use-machine-learning/](https://www.geeksforgeeks.org/how-does-nasa-use-machine-learning/)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jvn1nh/how_does_nasa_use_machine_learning/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "how does nasa use machine learning? /!/ [nasa](https://www.nasa.gov/) is involved in all aspects of space ranging from studying earth\u2019s outer atmosphere to finding signs of life on other planets! and [machine learning](https://www.geeksforgeeks.org/machine-learning/) is a big part of this space discovery as it is a necessary -----> tool !!!  in this data age. the amount of data generated by various nasa spacecraft and satellites is insane (as an example, consider that only the [**sloan digital sky survey**](https://www.sdss.org/) will create more than **50 million** images of galaxies in the future!) and hence machine learning is necessary to identify patterns in this data which will lead to exciting new discoveries in the future!  \n\ninteresting topic? well then read more-&gt; [https://www.geeksforgeeks.org/how-does-nasa-use-machine-learning/](https://www.geeksforgeeks.org/how-does-nasa-use-machine-learning/)", "sortedWord": "None", "removed": "('nan',)", "score": 0, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jvn1nh/how_does_nasa_use_machine_learning/',)", "identifyer": 5747016, "year": "2020"}, {"autor": "PJDubsen", "date": 1582667998000, "content": "I want to learn ML as a hobby, not in hopes of getting a job. /!/ Screw \"real world\" data science. I want to learn ML for the sake of doing something fun, and to learn something new.\n\nI have a solid background in math and comp sci, I know some python but I prefer c++ and java, but what I really want to do is implement everything in C. Yea yea its not a functional language and there are next to no resources, BUT WHERES THE FUN IF ITS EASY? Ive already written a decent linear algebra library in C and implemented linear regression, so I kinda know what Im getting myself into.\n\nMy problem is that it seems like a lot of resources now are targeted to real-world problems like business analytics, computer vision, etc. where you learn less about the theoretical and more about the implementation, using whatever fuckin tool is the new buzzword. Screw that. I need something that spares no details. Something that isnt afraid to go beyond the scope of a job interview. Im here to have fun. But obviously my definition of fun isnt very universal.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f9i317/i_want_to_learn_ml_as_a_hobby_not_in_hopes_of/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i want to learn ml as a hobby, not in hopes of getting a job. /!/ screw \"real world\" data science. i want to learn ml for the sake of doing something fun, and to learn something new.\n\ni have a solid background in math and comp sci, i know some python but i prefer c++ and java, but what i really want to do is implement everything in c. yea yea its not a functional language and there are next to no resources, but wheres the fun if its easy? ive already written a decent linear algebra library in c and implemented linear regression, so i kinda know what im getting myself into.\n\nmy problem is that it seems like a lot of resources now are targeted to real-world problems like business analytics, computer vision, etc. where you learn less about the theoretical and more about the implementation, using whatever fuckin -----> tool !!!  is the new buzzword. screw that. i need something that spares no details. something that isnt afraid to go beyond the scope of a job interview. im here to have fun. but obviously my definition of fun isnt very universal.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 41, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f9i317/i_want_to_learn_ml_as_a_hobby_not_in_hopes_of/',)", "identifyer": 5747083, "year": "2020"}, {"autor": "lucidhiho", "date": 1582633740000, "content": "I\u2019m building a tool that recommends cities to live in based on previous users submissions /!/ Hey friends I would love some help building a web application that recommends cities based on a survey and previous user submissions.\n\nHere\u2019s how it would work:\n\nUser completes a related survey and they also rate any city they\u2019ve previously lived in on a scale from 1-100. The tool outputs cities that it recommends.\n\nIs this possible to do?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f99jfg/im_building_a_tool_that_recommends_cities_to_live/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i\u2019m building a -----> tool !!!  that recommends cities to live in based on previous users submissions /!/ hey friends i would love some help building a web application that recommends cities based on a survey and previous user submissions.\n\nhere\u2019s how it would work:\n\nuser completes a related survey and they also rate any city they\u2019ve previously lived in on a scale from 1-100. the tool outputs cities that it recommends.\n\nis this possible to do?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f99jfg/im_building_a_tool_that_recommends_cities_to_live/',)", "identifyer": 5747096, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1582539795000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f8pazv/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f8pazv/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5747135, "year": "2020"}, {"autor": "oh_my_god_jc", "date": 1586439099000, "content": "Your ideas: How to forecast prices / find good trades in game economy /!/ Hi Reddit! \n\nI play an MMO that has a virtual economy. Now, I'd like to write a decision support tool that helps me find better trades. How can I use ML (or simple statistics) to my advantage?\n\nPreface:\n\n* I'm **not** creating a bot, that is against the EULA of the particular game.\n* All money and commodities are virtual, there is no connection to real money.\n\n&amp;#x200B;\n\nThis is what I'm working with:\n\n* I have a database of all commodities and their historic prices\n* Some commodities are volatile, and some are highly cyclic as supply and demand changes between days of the week\n* I've seen some busy traders, but the market is far from efficient\n\nSo, it is definitely possible to predict price movements. In fact, I have some commodities that I trade regularly. But it's not enough :)\n\n&amp;#x200B;\n\nNow I want to crunch all that data and find trading strategies with reasonable return and risk, while only requiring me to trade 1-2x per day. The output could be, for example:\n\n* A daily recommendation, such as \"Buy/Sell amount X of commodity Y on day Z\".\n* The expected return and risk on a specific trade that I want to do\n* Individual price forecasts for specific commodities (including uncertainty)\n\nHow should I go about it? I guess I could split my data and then write some LSTM regressions. Maybe crunch all the data and try to find the best cycles? Or maybe I could write an RL agent that can suggest trades? Surely some of you have thought about this before. Thanks :)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fxsgv0/your_ideas_how_to_forecast_prices_find_good/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "your ideas: how to forecast prices / find good trades in game economy /!/ hi reddit! \n\ni play an mmo that has a virtual economy. now, i'd like to write a decision support -----> tool !!!  that helps me find better trades. how can i use ml (or simple statistics) to my advantage?\n\npreface:\n\n* i'm **not** creating a bot, that is against the eula of the particular game.\n* all money and commodities are virtual, there is no connection to real money.\n\n&amp;#x200b;\n\nthis is what i'm working with:\n\n* i have a database of all commodities and their historic prices\n* some commodities are volatile, and some are highly cyclic as supply and demand changes between days of the week\n* i've seen some busy traders, but the market is far from efficient\n\nso, it is definitely possible to predict price movements. in fact, i have some commodities that i trade regularly. but it's not enough :)\n\n&amp;#x200b;\n\nnow i want to crunch all that data and find trading strategies with reasonable return and risk, while only requiring me to trade 1-2x per day. the output could be, for example:\n\n* a daily recommendation, such as \"buy/sell amount x of commodity y on day z\".\n* the expected return and risk on a specific trade that i want to do\n* individual price forecasts for specific commodities (including uncertainty)\n\nhow should i go about it? i guess i could split my data and then write some lstm regressions. maybe crunch all the data and try to find the best cycles? or maybe i could write an rl agent that can suggest trades? surely some of you have thought about this before. thanks :)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fxsgv0/your_ideas_how_to_forecast_prices_find_good/',)", "identifyer": 5747162, "year": "2020"}, {"autor": "ISkipLegDayAMA", "date": 1586394398000, "content": "Modern Approaches to Facial Recognition? /!/ Hey all,\n\nI'm new to field of CV and deep learning, and am working on a face recognition tool in python to practice my skills. The database is fairly small (maybe 6 people tops), and the number of training images per person is also very small (only a few images per person). What is the standard practice for face recognition, given these limitations? My best guess would be to perform a haar cascade for a basic region proposal, and then send the detected region(s) through a CNN and compute the triplet loss of the final layer to try to guess the person(s). \n\nI took an online course on CV that taught haar cascades, but it was fairly outdated by computer science standards (~6 years old), so I have no idea if this is still the go-to method for general face detection. As for the facial recognition part, I've seen people use Google's pre-trained Facenet CNN, add a couple additional fully connected layers on, and re-train the neural network on their custom own database of faces. Would this sort of transferrable learning be effective with a fairly small training set?\n\nThanks in advance, and sorry if these questions are super basic/already answered elsewhere. As I mentioned, I'm super new to the field and still trying to learn. :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fxiwdq/modern_approaches_to_facial_recognition/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "modern approaches to facial recognition? /!/ hey all,\n\ni'm new to field of cv and deep learning, and am working on a face recognition -----> tool !!!  in python to practice my skills. the database is fairly small (maybe 6 people tops), and the number of training images per person is also very small (only a few images per person). what is the standard practice for face recognition, given these limitations? my best guess would be to perform a haar cascade for a basic region proposal, and then send the detected region(s) through a cnn and compute the triplet loss of the final layer to try to guess the person(s). \n\ni took an online course on cv that taught haar cascades, but it was fairly outdated by computer science standards (~6 years old), so i have no idea if this is still the go-to method for general face detection. as for the facial recognition part, i've seen people use google's pre-trained facenet cnn, add a couple additional fully connected layers on, and re-train the neural network on their custom own database of faces. would this sort of transferrable learning be effective with a fairly small training set?\n\nthanks in advance, and sorry if these questions are super basic/already answered elsewhere. as i mentioned, i'm super new to the field and still trying to learn. :-)", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fxiwdq/modern_approaches_to_facial_recognition/',)", "identifyer": 5747182, "year": "2020"}, {"autor": "dekardar", "date": 1585871877000, "content": "Deployment and Monitoring of ML models /!/ For the people who are working in the industry. What has been your go to tool-set for the deployment and monitoring of Ml models? What issues did you face? Mistakes you made?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ftxjk1/deployment_and_monitoring_of_ml_models/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "deployment and monitoring of ml models /!/ for the people who are working in the industry. what has been your go to -----> tool !!! -set for the deployment and monitoring of ml models? what issues did you face? mistakes you made?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ftxjk1/deployment_and_monitoring_of_ml_models/',)", "identifyer": 5747307, "year": "2020"}, {"autor": "MrShlkHms", "date": 1600228653000, "content": "What tool should I use to find a curve close to the black ones I drew in this graph?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/itoclj/what_tool_should_i_use_to_find_a_curve_close_to/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "what -----> tool !!!  should i use to find a curve close to the black ones i drew in this graph?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 33, "media": "('image',)", "medialink": "('https://i.redd.it/h07rn1shnfn51.png',)", "identifyer": 5747463, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1579310306000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/eq9qlf/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/eq9qlf/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5747671, "year": "2020"}, {"autor": "trecoolman", "date": 1605044307000, "content": "fasttext to create embeddings for news articles using Python /!/ Hi!\nFirst off: I'm completely new to Python &amp; ML in general and everything I've done so far is basically copy and pasting code until it worked.\n\nI want to create a simple tool that analyzes news articles I gathered and put them on a 2D plot based on their content and how they are written. What I've done so far: Fetching the articles, cleaning them up, feeding them into a pre-trained fasttext model and then visualizing what I got using t-SNE.\nIt works quite well and I'm getting clusters based on what the articles are talking about, great so far. Now I want to improve on that a little bit (with my little understanding of...well, everything) and ran into a few options.\n\nFirstly, I read that fasttext (or basically anything that reduces a sentence down to tokens) can run into problems in terms of semantics of a sentence. Meaning that the order of how words appear in a sentence, which can influence the meaning, is ignored and as long sentences contain the same words, the resulting vectors will be the same. Then I ran into BERT, which seems to work with sentences. My question now is: In the context of news (I have about 400 articles about the same topic from a range of one week from different outlets), would there be any noticeable difference in the output? Or am I understanding this wrong from the start?\n\nSecondly: While some sources say that t-SNE is the way to go, others talk about PCA or UMAP. Is there an inherent benefit to using any of them or does it boil down to \"whatever works for me\"?\n\nSo, basically: I already like what I get from fasttext + t-SNE + a simple scatter plot. Is there a way to drastically improve what I get or would anything else for my use-case be overkill?\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jru8es/fasttext_to_create_embeddings_for_news_articles/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "fasttext to create embeddings for news articles using python /!/ hi!\nfirst off: i'm completely new to python &amp; ml in general and everything i've done so far is basically copy and pasting code until it worked.\n\ni want to create a simple -----> tool !!!  that analyzes news articles i gathered and put them on a 2d plot based on their content and how they are written. what i've done so far: fetching the articles, cleaning them up, feeding them into a pre-trained fasttext model and then visualizing what i got using t-sne.\nit works quite well and i'm getting clusters based on what the articles are talking about, great so far. now i want to improve on that a little bit (with my little understanding of...well, everything) and ran into a few options.\n\nfirstly, i read that fasttext (or basically anything that reduces a sentence down to tokens) can run into problems in terms of semantics of a sentence. meaning that the order of how words appear in a sentence, which can influence the meaning, is ignored and as long sentences contain the same words, the resulting vectors will be the same. then i ran into bert, which seems to work with sentences. my question now is: in the context of news (i have about 400 articles about the same topic from a range of one week from different outlets), would there be any noticeable difference in the output? or am i understanding this wrong from the start?\n\nsecondly: while some sources say that t-sne is the way to go, others talk about pca or umap. is there an inherent benefit to using any of them or does it boil down to \"whatever works for me\"?\n\nso, basically: i already like what i get from fasttext + t-sne + a simple scatter plot. is there a way to drastically improve what i get or would anything else for my use-case be overkill?\nthanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jru8es/fasttext_to_create_embeddings_for_news_articles/',)", "identifyer": 5747797, "year": "2020"}, {"autor": "shyamcody", "date": 1604925500000, "content": "How to leverage more granular data for higher-level labels? /!/ I have private data which I can't show, but let me explain with an example.\n\nThere is a dataset; which contains customer rating of different products. Now, we want to predict the ratings of the products using this customer rating; for each customer. i.e. the prediction should be like: person a1, rates product b1 a rating 3/5. Now, the issue with my data is that the ratings are collated in person groups. i.e. groups of people are collated together while labelling. i.e. let's say all ratings from a part of a district are put under a group and the group wise label is provided to me.\n\nNow, the question is that: given this data, should I create my training data ( other features are also there which are at individual level) at individual person level? or at the persons group level only?  \nMy manager's argument is that as the data label is at person group level; we should also train at person group label. But my argument is that if I create data at an individual person label and then train with the same labels for all the persons in one group; then also individual level distinct features will create better data understanding inside the model implicitly.\n\nWe will be modeling with any modeling tool possible i.e. starting from xgb to CNNs. So modeling tactics related concerns are not needed; but you are welcome to suggest specific modeling techniques to resolve this question. \n\nI would love to give the actual dataset; but this is part of client project and private datasets; so can't really share. But the problem is exactly similar to what my example looks like.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jqwv0g/how_to_leverage_more_granular_data_for/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "how to leverage more granular data for higher-level labels? /!/ i have private data which i can't show, but let me explain with an example.\n\nthere is a dataset; which contains customer rating of different products. now, we want to predict the ratings of the products using this customer rating; for each customer. i.e. the prediction should be like: person a1, rates product b1 a rating 3/5. now, the issue with my data is that the ratings are collated in person groups. i.e. groups of people are collated together while labelling. i.e. let's say all ratings from a part of a district are put under a group and the group wise label is provided to me.\n\nnow, the question is that: given this data, should i create my training data ( other features are also there which are at individual level) at individual person level? or at the persons group level only?  \nmy manager's argument is that as the data label is at person group level; we should also train at person group label. but my argument is that if i create data at an individual person label and then train with the same labels for all the persons in one group; then also individual level distinct features will create better data understanding inside the model implicitly.\n\nwe will be modeling with any modeling -----> tool !!!  possible i.e. starting from xgb to cnns. so modeling tactics related concerns are not needed; but you are welcome to suggest specific modeling techniques to resolve this question. \n\ni would love to give the actual dataset; but this is part of client project and private datasets; so can't really share. but the problem is exactly similar to what my example looks like.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jqwv0g/how_to_leverage_more_granular_data_for/',)", "identifyer": 5747874, "year": "2020"}, {"autor": "Jake_Stack808", "date": 1607199950000, "content": "I am working on a tool for machine learning projects that converts spreadsheets into Python /!/ I have lots of spreadsheet processes that I do for my machine learning tasks, and I really wanted them to be more Python integrated, so me and some friends of mine from school, made this [tool](https://trymito.io?source=learnmachinelearning2) thats lets you edit your Python data in a spreadsheet and then have all those edits converted back to the equivalent Python. Essentially translation from spreadsheet to Python. It has been great for data cleaning processes and automating parts of my workflow generally. \n\nI posted in here about it a little while back and got some great feedback and some people started using it, so I thought I would do so again and see if there is any more feedback on the idea. Thanks!\n\nYou can check it out [here!](https://trymito.io?source=learnmachinelearning2)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/k7f1h8/i_am_working_on_a_tool_for_machine_learning/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i am working on a -----> tool !!!  for machine learning projects that converts spreadsheets into python /!/ i have lots of spreadsheet processes that i do for my machine learning tasks, and i really wanted them to be more python integrated, so me and some friends of mine from school, made this [tool](https://trymito.io?source=learnmachinelearning2) thats lets you edit your python data in a spreadsheet and then have all those edits converted back to the equivalent python. essentially translation from spreadsheet to python. it has been great for data cleaning processes and automating parts of my workflow generally. \n\ni posted in here about it a little while back and got some great feedback and some people started using it, so i thought i would do so again and see if there is any more feedback on the idea. thanks!\n\nyou can check it out [here!](https://trymito.io?source=learnmachinelearning2)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/k7f1h8/i_am_working_on_a_tool_for_machine_learning/',)", "identifyer": 5748144, "year": "2020"}, {"autor": "DeadliestToast", "date": 1606755184000, "content": "I built an ML tool to analyse the dashboard recommendation post from a few days ago: /!/ Yeah right. I just aggregated the results and stuck them into google sheets =p\n\nThought it might be useful to the community to roughly aggregate the results together.\nAnyway, here are the rough results when asking the question:\n**What dashboard should I use?**\n\n|Solution|Upvotes|# Independent Recommendations|\n:--|--:|--:|\n|Don't Roll Your Own|90|2|\n|Django + Chart.js|59|5|\n|Plotly/Dash|48|3|\n|Metabase|8|1|\n|Rshiny|27|2|\n|Retool|12|1|\n|Streamlit|19|6|\n|Tableau|14|4|\n|Google datastudio|3|1|\n|Grafana|6|3|\n|PowerBi|2|5|\n|Exago BI|1|1|\n|d3.js|1|1|\n|Altair + quilt|1|1|\n|Domo|1|1|\n|Bokeh|2|2|\n|Panel|1|1|\n|WeightsAndBiases|1|1|\n|Dash + Flask|0|1\u200b|\n|Datatables|3|1|\n\n#Results interpretation\nCouple of things stand out to me:\n\n* Don't try to roll your own / recreate the wheel.\n* Django + Chart.js /  Some full-stack framework + some plotting framework are fairly clear winners (Surprised Flask + Plotly wasn't mentioned more)\n* Rolling Plotly-Dash on its own is okay, but some performance concerns.\n* Streamlit seems to be a surprisingly well loved tool by many people (An up and coming quick result tool?)\n* Power BI is recommended a lot, but rarely upvoted (controversial choice? Seems like a love-or-hate thing\n\n\nExcellent selection of choices though! Well done community =) Hope this summary helps!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/k3znco/i_built_an_ml_tool_to_analyse_the_dashboard/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i built an ml -----> tool !!!  to analyse the dashboard recommendation post from a few days ago: /!/ yeah right. i just aggregated the results and stuck them into google sheets =p\n\nthought it might be useful to the community to roughly aggregate the results together.\nanyway, here are the rough results when asking the question:\n**what dashboard should i use?**\n\n|solution|upvotes|# independent recommendations|\n:--|--:|--:|\n|don't roll your own|90|2|\n|django + chart.js|59|5|\n|plotly/dash|48|3|\n|metabase|8|1|\n|rshiny|27|2|\n|retool|12|1|\n|streamlit|19|6|\n|tableau|14|4|\n|google datastudio|3|1|\n|grafana|6|3|\n|powerbi|2|5|\n|exago bi|1|1|\n|d3.js|1|1|\n|altair + quilt|1|1|\n|domo|1|1|\n|bokeh|2|2|\n|panel|1|1|\n|weightsandbiases|1|1|\n|dash + flask|0|1\u200b|\n|datatables|3|1|\n\n#results interpretation\ncouple of things stand out to me:\n\n* don't try to roll your own / recreate the wheel.\n* django + chart.js /  some full-stack framework + some plotting framework are fairly clear winners (surprised flask + plotly wasn't mentioned more)\n* rolling plotly-dash on its own is okay, but some performance concerns.\n* streamlit seems to be a surprisingly well loved tool by many people (an up and coming quick result tool?)\n* power bi is recommended a lot, but rarely upvoted (controversial choice? seems like a love-or-hate thing\n\n\nexcellent selection of choices though! well done community =) hope this summary helps!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/k3znco/i_built_an_ml_tool_to_analyse_the_dashboard/',)", "identifyer": 5748165, "year": "2020"}, {"autor": "sunnywill", "date": 1606549710000, "content": "Looking for useful projects that people have created using Machine Learning, as inspiration for my own website. /!/ Hi,\n\nI've recently launched a website: [https://www.sunnyville.ai/](https://www.sunnyville.ai/) in which I plan to create useful tools using Machine Learning that people can use for free. So far I just have a summarization app and a translation app, and I'm looking for more ideas.\n\nCould you recommend me a method of finding more such tool ideas? I guess one possible way would be to search twitter and reddit for such ideas, but I'm having a really hard time finding them.\n\nWould appreciate any help.\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/k2jsc4/looking_for_useful_projects_that_people_have/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "looking for useful projects that people have created using machine learning, as inspiration for my own website. /!/ hi,\n\ni've recently launched a website: [https://www.sunnyville.ai/](https://www.sunnyville.ai/) in which i plan to create useful tools using machine learning that people can use for free. so far i just have a summarization app and a translation app, and i'm looking for more ideas.\n\ncould you recommend me a method of finding more such -----> tool !!!  ideas? i guess one possible way would be to search twitter and reddit for such ideas, but i'm having a really hard time finding them.\n\nwould appreciate any help.\n\nthanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/k2jsc4/looking_for_useful_projects_that_people_have/',)", "identifyer": 5748259, "year": "2020"}, {"autor": "nidhaloff", "date": 1604152347000, "content": "Introducing igel: a delightful machine learning tool that provides machine learning for everyone", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jliq0j/introducing_igel_a_delightful_machine_learning/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "introducing igel: a delightful machine learning -----> tool !!!  that provides machine learning for everyone", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('https://github.com/nidhaloff/igel',)", "identifyer": 5748262, "year": "2020"}, {"autor": "VyasBharvi", "date": 1581751502000, "content": "51 Most Used Machine Learning Tools by Experts! /!/ Machine Learning is a great technology to work with. It gets joyful when you learn to use it in the right way. Once you learn how to use the tools of ML, it becomes very convenient. You can play around with data, train your own models, create your own algorithms, and discover new methods. This can all be possible once you master the use of Machine Learning tools.\n\nML has a vast array of tools, software, and platforms. Also, the technology keeps on advancing forward. This means new technology always gets discovered. You have to choose to work on a particular Machine Learning tool to gain experience. This article is about those lists of Machine Learning tools. You can refer to this article if you are having trouble choosing the best Machine Learning tools. [Read More](https://techvidvan.com/tutorials/machine-learning-tools/)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f466yw/51_most_used_machine_learning_tools_by_experts/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "51 most used machine learning tools by experts! /!/ machine learning is a great technology to work with. it gets joyful when you learn to use it in the right way. once you learn how to use the tools of ml, it becomes very convenient. you can play around with data, train your own models, create your own algorithms, and discover new methods. this can all be possible once you master the use of machine learning tools.\n\nml has a vast array of tools, software, and platforms. also, the technology keeps on advancing forward. this means new technology always gets discovered. you have to choose to work on a particular machine learning -----> tool !!!  to gain experience. this article is about those lists of machine learning tools. you can refer to this article if you are having trouble choosing the best machine learning tools. [read more](https://techvidvan.com/tutorials/machine-learning-tools/)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f466yw/51_most_used_machine_learning_tools_by_experts/',)", "identifyer": 5748508, "year": "2020"}, {"autor": "CrazyCapivara", "date": 1581705207000, "content": "Face2Data: Machine Learning with Keras and Flask to extract meaningful information from a persons face (with Unit tests and Live Demo) /!/ \nIn the past years I have been working as a Machine Learning developer, mostly with Computer Vision tasks, so on my spare time I've developed a tool to extract meaningful information from human faces using CNN and Keras framework. The model was trained on the UTK Face Dataset, with around 20 thousand annotated faces.\n\nThis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\nI tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with Codacy and **continuous integration** with Travis CI, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nLooking forward to any reviews about the source code. Any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**Github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\nCode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nLive Demo (it may take some time to load due to Heroku's free plan): https://face2data.herokuapp.com/\n\nThanks and I hope it can help somebody out there :-)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f3wgvk/face2data_machine_learning_with_keras_and_flask/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "face2data: machine learning with keras and flask to extract meaningful information from a persons face (with unit tests and live demo) /!/ \nin the past years i have been working as a machine learning developer, mostly with computer vision tasks, so on my spare time i've developed a -----> tool !!!  to extract meaningful information from human faces using cnn and keras framework. the model was trained on the utk face dataset, with around 20 thousand annotated faces.\n\nthis project is intended to be easy to use and flexible to most of the existent scenarios, but if you find any other need or issue to be fixed, do not hesitate to ask.\n\ni tried to add some interesting stuff on the project, such as **unit tests**, **code coverage** with codacy and **continuous integration** with travis ci, so if any of you are interested in how to set up your project to have these features, feel free to use it as a base project.\n\nlooking forward to any reviews about the source code. any tip to improve the readability or even performance, its really welcome and well appreciated.\n\n**github:** [**https://github.com/rodrigobressan/face2data**](https://github.com/rodrigobressan/face2data)\n\ncode coverage (nowadays reaching 87%): [https://coveralls.io/github/rodrigobressan/face2data?branch=master](https://coveralls.io/github/rodrigobressan/face2data?branch=master)\n\nlive demo (it may take some time to load due to heroku's free plan): https://face2data.herokuapp.com/\n\nthanks and i hope it can help somebody out there :-)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f3wgvk/face2data_machine_learning_with_keras_and_flask/',)", "identifyer": 5748523, "year": "2020"}, {"autor": "HyperkiteAI", "date": 1581171216000, "content": "[P] Looking for alpha testers for hyperparameter tuning tool: hyperkite.ai", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f0s2tt/p_looking_for_alpha_testers_for_hyperparameter/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "[p] looking for alpha testers for hyperparameter tuning -----> tool !!! : hyperkite.ai", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('/r/MachineLearning/comments/f0rzwx/p_looking_for_alpha_testers_for_hyperparameter/',)", "identifyer": 5748604, "year": "2020"}, {"autor": "thisisabujee", "date": 1583156454000, "content": "Automatic De-identification tool for Echo-cardiogram images (CAMUS data set) /!/ Is there any tool that can help me with de-identification of electrocardiogram images.\n\n*Processing img 5uzichefj9k41...*", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fcc7sy/automatic_deidentification_tool_for/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "automatic de-identification -----> tool !!!  for echo-cardiogram images (camus data set) /!/ is there any tool that can help me with de-identification of electrocardiogram images.\n\n*processing img 5uzichefj9k41...*", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fcc7sy/automatic_deidentification_tool_for/',)", "identifyer": 5748707, "year": "2020"}, {"autor": "ubwfibqdinqunuxneihq", "date": 1593080690000, "content": "I wanted to create something to my team. Make a machine learning tool. What did you do to innovate that the boss liked?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hfjqqm/i_wanted_to_create_something_to_my_team_make_a/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i wanted to create something to my team. make a machine learning -----> tool !!! . what did you do to innovate that the boss liked?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hfjqqm/i_wanted_to_create_something_to_my_team_make_a/',)", "identifyer": 5748796, "year": "2020"}, {"autor": "AskSid_AI", "date": 1592464103000, "content": "Is AI and Machine Learning the same? /!/ We have all heard or read about how AI is the next big thing. It seems like every 3rd article or blog is about AI and how companies are leveraging this shiny new tech to solve some of their biggest problems. And the same words are seen together. AI vs Machine learning, Machine learning vs Deep Learning, Neural Networks \u2026.. and so on.\n\nEvery so often I get asked (by engineers and non-engineers both) \u201cAre AI and machine learning the same?\u201d So let\u2019s answer this.\n\nWhat is AI? What are its goals?\n\nI don\u2019t want to give a textbook answer here on the AI meaning. I am sick of them myself. So here it goes\u2026\n\nAI\u2019s primary goal is to create an artificial intelligence. This may or may not include a robotic body as such. That\u2019s only for movies, not in real world always. An artificial intelligence needs to be capable of most, if not all, the things that humans do.\n\nIt should be able to learn by observation or actions.\n\nIt should be able to decide on a goal\n\nIt should be able to create a plan to achieve this goal in an optimal way.\n\nIt should be able to sense or feel and have an awareness of its surroundings\n\nIt should be able to reason and draw conclusions and so on..\n\nAs you can see this is a pretty lofty goal. It is quite abstract as to how this can be achieved. And that\u2019s the main point. AI is abstract in general. It has goals but needs ways of achieving them.\n\nHow does machine learning assist AI goals? Is machine learning the same as AI?\n\nMachine learning is one of many tools that is used by an AI to achieve its goals. Machine learning unlike AI is very clear about its goals. Machine learning wants to create function approximations or models for some input and output combinations (we call this \u201ctraining data\u201d). Using these AI models, it can later generate outputs (we call this \u201cpredictions\u201d) on unseen data. To create these models, it uses various AI algorithms which have hyper-parameters to help tune them.A very easy example is,\n\nInput (X)         Output (Y)\n\n1                      3\n\n2                      6\n\n3                      9\n\n4                      12\n\nIt\u2019s clear from these combinations that the output is 3 times the input. So the function would be,\n\nY = 3X\n\nNow this becomes our model. If we have unseen X values, we apply the model to predict the Y values. But of course, the AI algorithm is never this simple in real life. Here X could refer to a vector generated by text, image, audio, etc and Y could be any useful prediction.\n\nThese types of predictive models are used by AI to reach its goals.\n\nWhere exactly is Machine Learning used?\n\nSo we know that machine learning is used to create predictive models. But where exactly are these models used? What can you do with them? Let\u2019s look at some relevant examples for businesses.\n\nPersonalized recommendations \u2013 When netflix recommends movies based on your previous actions, when amazon recommends products for you to checkout, Machine learning is used to predict them\n\nSearch engines \u2013 Google uses machine learning to provide you with search results for your queries\n\nMaps \u2013 Google uses machine learning to recommend the best route for your journey based to driving time calculations taking into consideration the live traffic and road closures data\n\nVirtual Assistants and Customer Service Chatbot \u2013 [Natural language processing](https://www.asksid.ai/resources/what-is-natural-language-processing/) techniques of machine learning are used to provide a conversational AI experience to the user. This can be used in a wide variety of fields like customer service and customer engagement in ecommerce.\n\nVideo Surveillance uses machine learning to reduce human effort by predicting any unusual behavior in video feeds\n\nFace Recognition \u2013 Many smartphone providers use machine learning to help you unlock your phone with your face\n\nSpam filtering \u2013 Email and SMS providers use machine learning to help filter out unwanted messages\n\nAI vs Machine learning vs Deep learning\n\nThis is another familiar question: AI vs machine learning \u2013 what is the difference? If I had a nickel\u2026\n\nMachine learning\u2019s goal is to create predictive models. Deep learning wants to do the same. Really. They\u2019re like twins.\n\nWhile machine learning likes to use traditional models like SVM, Decision trees, etc Deep learning uses fancier (read as \u201cmore complex\u201d) neural network AI algorithms which work like the human brain (in theory). And that\u2019s it. Everything else is pretty much the same.\n\nI usually don\u2019t refer to Deep Learning as a separate term. To me they are the same. Deep Learning is Machine Learning with updated AI Algorithms.\n\nConclusion \u2013 AI vs Machine learning\n\n**To summarise,**\n\nAI vs Machine learning \u2013 AI is an abstract concept with many goals. Machine Learning is a specific tool used by AI to realise them.\n\nDeep Learning is Machine Learning with updated algorithms.\n\nFor more content on AI and how businesses can leverage it, please check this article from Dinesh Sharma  \u201cCan AI make your business far more intelligent\u201d\n\nCurious Much? Drop us a note at [contact@asksid.ai](mailto:contact@asksid.ai) or visit our website [www.asksid.ai](https://www.asksid.ai) and let\u2019s start a conversation!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hb9rki/is_ai_and_machine_learning_the_same/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "is ai and machine learning the same? /!/ we have all heard or read about how ai is the next big thing. it seems like every 3rd article or blog is about ai and how companies are leveraging this shiny new tech to solve some of their biggest problems. and the same words are seen together. ai vs machine learning, machine learning vs deep learning, neural networks \u2026.. and so on.\n\nevery so often i get asked (by engineers and non-engineers both) \u201care ai and machine learning the same?\u201d so let\u2019s answer this.\n\nwhat is ai? what are its goals?\n\ni don\u2019t want to give a textbook answer here on the ai meaning. i am sick of them myself. so here it goes\u2026\n\nai\u2019s primary goal is to create an artificial intelligence. this may or may not include a robotic body as such. that\u2019s only for movies, not in real world always. an artificial intelligence needs to be capable of most, if not all, the things that humans do.\n\nit should be able to learn by observation or actions.\n\nit should be able to decide on a goal\n\nit should be able to create a plan to achieve this goal in an optimal way.\n\nit should be able to sense or feel and have an awareness of its surroundings\n\nit should be able to reason and draw conclusions and so on..\n\nas you can see this is a pretty lofty goal. it is quite abstract as to how this can be achieved. and that\u2019s the main point. ai is abstract in general. it has goals but needs ways of achieving them.\n\nhow does machine learning assist ai goals? is machine learning the same as ai?\n\nmachine learning is one of many tools that is used by an ai to achieve its goals. machine learning unlike ai is very clear about its goals. machine learning wants to create function approximations or models for some input and output combinations (we call this \u201ctraining data\u201d). using these ai models, it can later generate outputs (we call this \u201cpredictions\u201d) on unseen data. to create these models, it uses various ai algorithms which have hyper-parameters to help tune them.a very easy example is,\n\ninput (x)         output (y)\n\n1                      3\n\n2                      6\n\n3                      9\n\n4                      12\n\nit\u2019s clear from these combinations that the output is 3 times the input. so the function would be,\n\ny = 3x\n\nnow this becomes our model. if we have unseen x values, we apply the model to predict the y values. but of course, the ai algorithm is never this simple in real life. here x could refer to a vector generated by text, image, audio, etc and y could be any useful prediction.\n\nthese types of predictive models are used by ai to reach its goals.\n\nwhere exactly is machine learning used?\n\nso we know that machine learning is used to create predictive models. but where exactly are these models used? what can you do with them? let\u2019s look at some relevant examples for businesses.\n\npersonalized recommendations \u2013 when netflix recommends movies based on your previous actions, when amazon recommends products for you to checkout, machine learning is used to predict them\n\nsearch engines \u2013 google uses machine learning to provide you with search results for your queries\n\nmaps \u2013 google uses machine learning to recommend the best route for your journey based to driving time calculations taking into consideration the live traffic and road closures data\n\nvirtual assistants and customer service chatbot \u2013 [natural language processing](https://www.asksid.ai/resources/what-is-natural-language-processing/) techniques of machine learning are used to provide a conversational ai experience to the user. this can be used in a wide variety of fields like customer service and customer engagement in ecommerce.\n\nvideo surveillance uses machine learning to reduce human effort by predicting any unusual behavior in video feeds\n\nface recognition \u2013 many smartphone providers use machine learning to help you unlock your phone with your face\n\nspam filtering \u2013 email and sms providers use machine learning to help filter out unwanted messages\n\nai vs machine learning vs deep learning\n\nthis is another familiar question: ai vs machine learning \u2013 what is the difference? if i had a nickel\u2026\n\nmachine learning\u2019s goal is to create predictive models. deep learning wants to do the same. really. they\u2019re like twins.\n\nwhile machine learning likes to use traditional models like svm, decision trees, etc deep learning uses fancier (read as \u201cmore complex\u201d) neural network ai algorithms which work like the human brain (in theory). and that\u2019s it. everything else is pretty much the same.\n\ni usually don\u2019t refer to deep learning as a separate term. to me they are the same. deep learning is machine learning with updated ai algorithms.\n\nconclusion \u2013 ai vs machine learning\n\n**to summarise,**\n\nai vs machine learning \u2013 ai is an abstract concept with many goals. machine learning is a specific -----> tool !!!  used by ai to realise them.\n\ndeep learning is machine learning with updated algorithms.\n\nfor more content on ai and how businesses can leverage it, please check this article from dinesh sharma  \u201ccan ai make your business far more intelligent\u201d\n\ncurious much? drop us a note at [contact@asksid.ai](mailto:contact@asksid.ai) or visit our website [www.asksid.ai](https://www.asksid.ai) and let\u2019s start a conversation!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hb9rki/is_ai_and_machine_learning_the_same/',)", "identifyer": 5748897, "year": "2020"}, {"autor": "diabulusInMusica", "date": 1597071516000, "content": "I published a video where I explain the Fourier Transform easily /!/ In my new video, I explain how the Fourier Transform works. I avoid getting into the mathematical intricacies (for now!). Instead, I focus on the intuition using a visual approach. The Fourier Transform is a fundamental tool used in audio signal processing for extracting information from audio data, and transform a signal from the time to the frequency domain.\n\nThis video is part of the Audio Processing for Machine Learning series. This course aims to teach you how to process audio data \ud83c\udfa7 and extract relevant audio features for your machine learning applications \ud83e\udd16\ud83e\udd16.\n\nHere\u2019s the video:\n\n[https://www.youtube.com/watch?v=XQ45IgG6rJ4&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=10](https://www.youtube.com/watch?v=XQ45IgG6rJ4&amp;list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&amp;index=10)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/i76d7i/i_published_a_video_where_i_explain_the_fourier/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i published a video where i explain the fourier transform easily /!/ in my new video, i explain how the fourier transform works. i avoid getting into the mathematical intricacies (for now!). instead, i focus on the intuition using a visual approach. the fourier transform is a fundamental -----> tool !!!  used in audio signal processing for extracting information from audio data, and transform a signal from the time to the frequency domain.\n\nthis video is part of the audio processing for machine learning series. this course aims to teach you how to process audio data \ud83c\udfa7 and extract relevant audio features for your machine learning applications \ud83e\udd16\ud83e\udd16.\n\nhere\u2019s the video:\n\n[https://www.youtube.com/watch?v=xq45igg6rj4&amp;list=pl-watfeyamnqiee7ch3q1bh4qjfaaenv0&amp;index=10](https://www.youtube.com/watch?v=xq45igg6rj4&amp;list=pl-watfeyamnqiee7ch3q1bh4qjfaaenv0&amp;index=10)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/i76d7i/i_published_a_video_where_i_explain_the_fourier/',)", "identifyer": 5749072, "year": "2020"}, {"autor": "Permazen", "date": 1597049581000, "content": "What are some great ways to generate text commentary from data (structured)? /!/ Hello everyone. I'm currently building a tool that generates commentary for a report. This report is similar to quarterly reports of public companies. What are some great ways and good practices to build such a tool (data to text generation)?\n\nSo far, I have tried:\n\nGPT-2: Training GPT-2 with previous commentaries and seed it with new data to get commentaries.\n\nMy goal is to build a tool similar to the text generation aspect of Quill: https://narrativescience.com/quill\n\nIf you have solved data to text generation problems before, would love to know your experience!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/i71a3d/what_are_some_great_ways_to_generate_text/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "what are some great ways to generate text commentary from data (structured)? /!/ hello everyone. i'm currently building a -----> tool !!!  that generates commentary for a report. this report is similar to quarterly reports of public companies. what are some great ways and good practices to build such a tool (data to text generation)?\n\nso far, i have tried:\n\ngpt-2: training gpt-2 with previous commentaries and seed it with new data to get commentaries.\n\nmy goal is to build a tool similar to the text generation aspect of quill: https://narrativescience.com/quill\n\nif you have solved data to text generation problems before, would love to know your experience!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/i71a3d/what_are_some_great_ways_to_generate_text/',)", "identifyer": 5749086, "year": "2020"}, {"autor": "solvew10problems", "date": 1590456653000, "content": "ml power: text site/tool that auto completes words based on ml? /!/ or based on frequency: if a word is in the top 10-20% of all the words you used, it would auto-complete", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gqnoa7/ml_power_text_sitetool_that_auto_completes_words/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "ml power: text site/-----> tool !!!  that auto completes words based on ml? /!/ or based on frequency: if a word is in the top 10-20% of all the words you used, it would auto-complete", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gqnoa7/ml_power_text_sitetool_that_auto_completes_words/',)", "identifyer": 5749252, "year": "2020"}, {"autor": "confusedartboi", "date": 1589484986000, "content": "Artist with some questions /!/ Hello, I'm the illustrator for a weekly webcomic with a lot of spare time in the coming months, and an interest in machine learning. I know some super basic python and java. I've also taken calculus, linear algebra, and statistics classes. \n\nI'm also curious about what it would take (or if it would even be possible) to develop a tool that could fill in lineart with flat colors (essentially a paint bucket tool, but modified to work even with gaps in the lines). Tools like style2paints are obviously incredible, but not paticularly useful for many artists. Any recommendations on where I should start? Is the above project potentially doable, given a lot of time and effort? Where could I even start?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gjtcau/artist_with_some_questions/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "artist with some questions /!/ hello, i'm the illustrator for a weekly webcomic with a lot of spare time in the coming months, and an interest in machine learning. i know some super basic python and java. i've also taken calculus, linear algebra, and statistics classes. \n\ni'm also curious about what it would take (or if it would even be possible) to develop a -----> tool !!!  that could fill in lineart with flat colors (essentially a paint bucket -----> tool !!! , but modified to work even with gaps in the lines). tools like style2paints are obviously incredible, but not paticularly useful for many artists. any recommendations on where i should start? is the above project potentially doable, given a lot of time and effort? where could i even start?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gjtcau/artist_with_some_questions/',)", "identifyer": 5749414, "year": "2020"}, {"autor": "cmillionaire9", "date": 1589452057000, "content": "Nifty Online Tool Animates Your Actions in Real-Time", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gjjrgu/nifty_online_tool_animates_your_actions_in/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "nifty online -----> tool !!!  animates your actions in real-time", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('rich:video',)", "medialink": "('https://youtu.be/wu7_NZc4kMg',)", "identifyer": 5749440, "year": "2020"}, {"autor": "AethericEye", "date": 1590858447000, "content": "Recommendations on online ground-up ML course I could do over summer? /!/ TL;DR: I am a bluecollar nerd and I want to learn ML and programming over the summer. How do? I am willing to pay for an instructed class, or access to a well developed course.\n\n&amp;#x200B;\n\nI'm am a machinist, but I have had a deep interest in ML for some years now, which originally grew from an existential fascination with the neurological bases of consciousness and cognition. \n\nMaybe I'm wrong about my intended use-case being well matched to ML, but I want to learn anyway, because fuckin wow. Even if I can't figure out how to use ML effectively at work, I'll enjoy it as yet another hobby. I am unironically interested in strong AI, and I continue to study the control problem and AI safety, though I am more directly interested in making smart-tools. \n\nI want to use ML in my work, specifically to predicatively model the dimensional changes in complex small cross-section parts through sintering processes, and then use that model to train a generative model to produce pre-process geometries that result in more accurate finished parts. I also think that ML could be an incredibly powerful tool for both part-design and process control. \n\n I know I'll need to generate my own training data, but we have the metrology to do that, and I am willing to design and run large numbers of test pieces.\n\nMy only meaningful coding experience is G-code, which I doubt is at all relevant. I have fiddled with a little bit of Java, but not extensively or recently. I absorbed the logical structures and methods easily, but got bogged down by the syntactic garbage. \n\nI have been successful in and enjoyed all of the math classes I've taken, through calc3. My current mathematical tool kit is mostly limited to \"shop math\"... basic algebra and trig, but as long as the concepts can be framed geometrically or spatially, I will learn the symbol manipulation quickly. I think that includes higher dimensional information as well; I can mentally manipulate a 6-axis tool-path while considering dynamic manipulation of cutter radial offset, feed, and spindle speed. I've also tried to exercise myself by imagining additional axis that don't actually exist... like adding color-space and tone-space to the process (not sure how to describe that better, but practicing mentally manipulating extra simultaneous variables made it much easier to work with the normal set). \n\nI'm sure my specific application goals are way out of reach for what I can reasonably learn by summer's end, but I want to get up to the point where I'm able to continue learning and developing skill and knowledge independently by then. I have this issue where I can't self-teach through the introductory phase, I need to be guided up to the first or second plateau, but beyond that point I can climb quickly on my own. \n\nI am honestly pretty intimidated, but I'm ready to dive in, just want to make sure I'm jumping into the right pool.\n\nI appreciate any thoughts or guidance.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gthmkv/recommendations_on_online_groundup_ml_course_i/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "recommendations on online ground-up ml course i could do over summer? /!/ tl;dr: i am a bluecollar nerd and i want to learn ml and programming over the summer. how do? i am willing to pay for an instructed class, or access to a well developed course.\n\n&amp;#x200b;\n\ni'm am a machinist, but i have had a deep interest in ml for some years now, which originally grew from an existential fascination with the neurological bases of consciousness and cognition. \n\nmaybe i'm wrong about my intended use-case being well matched to ml, but i want to learn anyway, because fuckin wow. even if i can't figure out how to use ml effectively at work, i'll enjoy it as yet another hobby. i am unironically interested in strong ai, and i continue to study the control problem and ai safety, though i am more directly interested in making smart-tools. \n\ni want to use ml in my work, specifically to predicatively model the dimensional changes in complex small cross-section parts through sintering processes, and then use that model to train a generative model to produce pre-process geometries that result in more accurate finished parts. i also think that ml could be an incredibly powerful -----> tool !!!  for both part-design and process control. \n\n i know i'll need to generate my own training data, but we have the metrology to do that, and i am willing to design and run large numbers of test pieces.\n\nmy only meaningful coding experience is g-code, which i doubt is at all relevant. i have fiddled with a little bit of java, but not extensively or recently. i absorbed the logical structures and methods easily, but got bogged down by the syntactic garbage. \n\ni have been successful in and enjoyed all of the math classes i've taken, through calc3. my current mathematical tool kit is mostly limited to \"shop math\"... basic algebra and trig, but as long as the concepts can be framed geometrically or spatially, i will learn the symbol manipulation quickly. i think that includes higher dimensional information as well; i can mentally manipulate a 6-axis tool-path while considering dynamic manipulation of cutter radial offset, feed, and spindle speed. i've also tried to exercise myself by imagining additional axis that don't actually exist... like adding color-space and tone-space to the process (not sure how to describe that better, but practicing mentally manipulating extra simultaneous variables made it much easier to work with the normal set). \n\ni'm sure my specific application goals are way out of reach for what i can reasonably learn by summer's end, but i want to get up to the point where i'm able to continue learning and developing skill and knowledge independently by then. i have this issue where i can't self-teach through the introductory phase, i need to be guided up to the first or second plateau, but beyond that point i can climb quickly on my own. \n\ni am honestly pretty intimidated, but i'm ready to dive in, just want to make sure i'm jumping into the right pool.\n\ni appreciate any thoughts or guidance.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gthmkv/recommendations_on_online_groundup_ml_course_i/',)", "identifyer": 5749468, "year": "2020"}, {"autor": "begooboi", "date": 1590724006000, "content": "Code review: Is this the right way to implement logistic regression in python? /!/ I have used [this article](https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac) as a guiding tool for building logistic regression in python\n\n    import numpy as np\n    from sklearn.datasets import make_blobs\n\n    def sigmoid(z):\n        return 1/(1+np.exp(-z))\n\n    def loss(h, y):\n        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n\n\n    X, y = make_blobs(n_samples=100, centers=2, n_features=2)\n    w = np.random.rand(2,1) # random weights\n    lr = 0.001\n    epochs = 100\n\n    for i in range(epochs): \n        z = np.dot(X,w)\n        h = sigmoid(z)\n        print(\"Loss\",loss(h,y))\n        gradient = (np.dot(X.T, (h - y)) / y.shape[0]).mean(1).reshape(2,1)\n\n        w = w - lr * gradient # weight update", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gslcxo/code_review_is_this_the_right_way_to_implement/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "code review: is this the right way to implement logistic regression in python? /!/ i have used [this article](https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac) as a guiding -----> tool !!!  for building logistic regression in python\n\n    import numpy as np\n    from sklearn.datasets import make_blobs\n\n    def sigmoid(z):\n        return 1/(1+np.exp(-z))\n\n    def loss(h, y):\n        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n\n\n    x, y = make_blobs(n_samples=100, centers=2, n_features=2)\n    w = np.random.rand(2,1) # random weights\n    lr = 0.001\n    epochs = 100\n\n    for i in range(epochs): \n        z = np.dot(x,w)\n        h = sigmoid(z)\n        print(\"loss\",loss(h,y))\n        gradient = (np.dot(x.t, (h - y)) / y.shape[0]).mean(1).reshape(2,1)\n\n        w = w - lr * gradient # weight update", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gslcxo/code_review_is_this_the_right_way_to_implement/',)", "identifyer": 5749536, "year": "2020"}, {"autor": "ToskanoBruno", "date": 1584404897000, "content": "Collecting best tools for ML related tools/skills /!/ Hi guys,\n\nHope you are doing well!\n\nI am creating a **free to use** tool that will provide the best possible resources for an IT related skill/tool to a user (This form is only a subset for DS/ML skills/tools). And the best way to get tested and quality resources is to ask Data Scientists and ML practitioners - what resource would you use if you were to start right now?\n\nI've created the Google Form with a set of skills that I'm interested in collecting resource-links for. It would be awesome if you could devote a bit of your time to fill the form as much as you can!\n\nIt is a bit longer, but almost all questions are optional, so you can go from filling just one to filling all of them (depending on your will and time :-) ).\n\nHere is the form link: [https://forms.gle/JfczpmJP85ECcRdb6](https://forms.gle/JfczpmJP85ECcRdb6) \n\nThank you in advance, and I wish the best of luck to you and your families in this period!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fjvoql/collecting_best_tools_for_ml_related_toolsskills/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "collecting best tools for ml related tools/skills /!/ hi guys,\n\nhope you are doing well!\n\ni am creating a **free to use** -----> tool !!!  that will provide the best possible resources for an it related skill/-----> tool !!!  to a user (this form is only a subset for ds/ml skills/tools). and the best way to get tested and quality resources is to ask data scientists and ml practitioners - what resource would you use if you were to start right now?\n\ni've created the google form with a set of skills that i'm interested in collecting resource-links for. it would be awesome if you could devote a bit of your time to fill the form as much as you can!\n\nit is a bit longer, but almost all questions are optional, so you can go from filling just one to filling all of them (depending on your will and time :-) ).\n\nhere is the form link: [https://forms.gle/jfczpmjp85eccrdb6](https://forms.gle/jfczpmjp85eccrdb6) \n\nthank you in advance, and i wish the best of luck to you and your families in this period!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fjvoql/collecting_best_tools_for_ml_related_toolsskills/',)", "identifyer": 5749682, "year": "2020"}, {"autor": "MusingEtMachina", "date": 1597612066000, "content": "We built an interactive learning tool to help people ace their machine learning and data science interviews /!/ Tool link: [**Confetti AI**](https://www.confetti.ai)\n\nWe've been working on a platform to help people prepare for machine learning and data science interviews. It builds on our experience successfully interviewing and receiving offers from many tech companies including Twitter, Apple, Google, etc. It contains questions, resources, and complete study plans for those trying to get jobs in these fields. Hopefully you find it helpful!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ib0glp/we_built_an_interactive_learning_tool_to_help/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "we built an interactive learning -----> tool !!!  to help people ace their machine learning and data science interviews /!/ tool link: [**confetti ai**](https://www.confetti.ai)\n\nwe've been working on a platform to help people prepare for machine learning and data science interviews. it builds on our experience successfully interviewing and receiving offers from many tech companies including twitter, apple, google, etc. it contains questions, resources, and complete study plans for those trying to get jobs in these fields. hopefully you find it helpful!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ib0glp/we_built_an_interactive_learning_tool_to_help/',)", "identifyer": 5749802, "year": "2020"}, {"autor": "lostsoul8282", "date": 1593796824000, "content": "Using ML for missing data in dataframe? /!/ Hi there,\n\nI've been playing with a interesting(and I believe fairly common) problem. \n\nI'd like to learn more on how to apply ML to input missing data in my dataframe.  Some of the data I can replace with mean or static values(0's, etc) but some I generally don't know what to do with.  I'm not missing the entire dataset just a subset of a few columns so I thought maybe there was a ML approach to address this.\n\nI used the sklearn inputer which works good and I've tried gain (gan based tool for this). The problem is for both I do not know what is going on under the hood.  \n\nI'm wondering if there is any tutorials or things I do to learn how to build my own model to resolve the missing data? My goal is not only to get the outcome I want (fill in missing data) but also learn and understand how it's done.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hkn1su/using_ml_for_missing_data_in_dataframe/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "using ml for missing data in dataframe? /!/ hi there,\n\ni've been playing with a interesting(and i believe fairly common) problem. \n\ni'd like to learn more on how to apply ml to input missing data in my dataframe.  some of the data i can replace with mean or static values(0's, etc) but some i generally don't know what to do with.  i'm not missing the entire dataset just a subset of a few columns so i thought maybe there was a ml approach to address this.\n\ni used the sklearn inputer which works good and i've tried gain (gan based -----> tool !!!  for this). the problem is for both i do not know what is going on under the hood.  \n\ni'm wondering if there is any tutorials or things i do to learn how to build my own model to resolve the missing data? my goal is not only to get the outcome i want (fill in missing data) but also learn and understand how it's done.", "sortedWord": "None", "removed": "('nan',)", "score": 4, "comments": 10, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hkn1su/using_ml_for_missing_data_in_dataframe/',)", "identifyer": 5750031, "year": "2020"}, {"autor": "MichaelXenon", "date": 1593766549000, "content": "HELP! I need a tool for text segmentation! /!/ I'm a beginner in ML and my boss gave me 1000 Resumes.\nHe wants them in a CSV file, segmented into: \"Name, Experience, Education, Gender, Phone Number, Email, ... etc.\" \nI'm looking for a tool that can transform raw text from those CVs into well structured format.\nDeadline is TOMORROW!\nPlease help...", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hkfokh/help_i_need_a_tool_for_text_segmentation/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "help! i need a -----> tool !!!  for text segmentation! /!/ i'm a beginner in ml and my boss gave me 1000 resumes.\nhe wants them in a csv file, segmented into: \"name, experience, education, gender, phone number, email, ... etc.\" \ni'm looking for a tool that can transform raw text from those cvs into well structured format.\ndeadline is tomorrow!\nplease help...", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hkfokh/help_i_need_a_tool_for_text_segmentation/',)", "identifyer": 5750047, "year": "2020"}, {"autor": "Milo55545", "date": 1591295144000, "content": "Easy software to train a neural network? /!/ Does anyone know of any user-friendly software that I could use to train an input-output image neural network without putting too much time into learning something like TensorFlow? I am only making one neural network tool for one purpose, and I don't think that it would be worth it to learn how to create complicated neural networks at the moment. I would prefer just to provide a dataset with pairs of image files and train it, then I could give it an input and it would return an output image based on what it had learned. Any help would be appreciated. Thank you!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gwn2ck/easy_software_to_train_a_neural_network/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "easy software to train a neural network? /!/ does anyone know of any user-friendly software that i could use to train an input-output image neural network without putting too much time into learning something like tensorflow? i am only making one neural network -----> tool !!!  for one purpose, and i don't think that it would be worth it to learn how to create complicated neural networks at the moment. i would prefer just to provide a dataset with pairs of image files and train it, then i could give it an input and it would return an output image based on what it had learned. any help would be appreciated. thank you!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gwn2ck/easy_software_to_train_a_neural_network/',)", "identifyer": 5750063, "year": "2020"}, {"autor": "dliteful23", "date": 1591201191000, "content": "[P] whisk - an open-source ML project framework that makes collaboration, reproducibility, and deployment \u201cjust work\u201d /!/ Hey folks,\n\nI used to dive into a data science project with just a Jupyter Notebook and lots of impatience. However, that boundless, explore-at-all-cost drive soon backfired. In short time, I\u2019d have an unorganized notebook, duplicate code, plenty of ugly hacks, and a project that\u2019s difficult to share, reproduce, and deploy as an ML model.\n\nAbstracted from my own pain, I\u2019m happy to introduce [**whisk**](http://docs.whisk-ml.org/)**,** an open-source data science project framework that makes collaboration, reproducibility, and deployment \u201cjust work\u201d. It combines a [data science-flavored Python project structure](https://docs.whisk-ml.org/en/latest/project_structure.html) with a suite of lightweight tools. It adds *just enough* structure to make a project easy to share.\n\nIf you're looking for another magical, highly-abstracted ML tool, this isn't it. Instead, whisk leverages the ability to do special things when your project resembles the [standard Python project structure](https://docs.python-guide.org/writing/structure/). From collaboration to distribution, it's all easier when this foundation is used.\n\nEnough fluff - here's some sample projects using whisk. You should be able to clone these from GitHub, run locally, and even deploy to Heroku with just a couple of commands:\n\n* [Bike Image Classifier](https://github.com/whisk-ml/bike_image_classifier_tensorflow) \\- A Tensorflow-backed Classifier that determines if an image is of a Mountain bike or a Road bike.\n* [Real or Not? NLP with disaster tweets](https://github.com/whisk-ml/disaster_tweets) \\- A Tensorflow-backed Keras model that predicts which tweets are about real disasters and which ones are not. [DVC](https://dvc.org) is used to version control the model training pipeline.\n\nWant to setup your own project? Much like `django-admin startproject` creates the structure for a Django web app, whisk sets up a project directory structure and environment for you. Open a terminal and run:\n\n    pip3 install whisk\n    whisk create &lt;project_name&gt;\n\nReplacing &lt;project\\_name&gt; with your unique name. See the [quick tour](https://docs.whisk-ml.org/en/latest/tour_of_whisk.html) in the docs for more on setting up a project.\n\n[Screen recording of \\`whisk create\\` at https:\\/\\/asciinema.org\\/a\\/uXW9s6FtkmbxNQQIdtDRLFYII](https://preview.redd.it/7kkpxops1q251.png?width=808&amp;format=png&amp;auto=webp&amp;s=215310c69d868b189d1b057771a7857068583067)\n\nAnyway, give whisk a shot. Would be great to hear your feedback.\n\n## whisk resources\n\n* [Documentation](https://docs.whisk-ml.org)\n* [whisk on GitHub](https://github.com/whisk-ml/whisk)\n* [Announcement post](https://dlite.cc/2020/06/02/whisk-data-science-project-framework.html) \\- has more details and screen recordings of the whisk CLI commands.\n* Example projects\n   * [Disaster Tweets](https://github.com/whisk-ml/disaster_tweets)\n   * [Bike Image Classifier](https://github.com/whisk-ml/bike_image_classifier_tensorflow)\n\n## PS - what about Cookiecutter Data Science?\n\nMy first attempts at structuring an ML project used [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/), and life was way better. whisk takes this well-regarded structure and sprinkles on some magic: more graceful upgrades, environment configuration, packaging, [DVC](https://dvc.org), and deployment. I go into more details on the differences between whisk and Cookie DS on my blog in my [announcement post](https://dlite.cc/2020/06/02/whisk-data-science-project-framework.html).\n\nHonestly though: if you are deciding between Cookiecutter DS and whisk, we\u2019re already winning the war against sloppy data science.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gvwyqh/p_whisk_an_opensource_ml_project_framework_that/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "[p] whisk - an open-source ml project framework that makes collaboration, reproducibility, and deployment \u201cjust work\u201d /!/ hey folks,\n\ni used to dive into a data science project with just a jupyter notebook and lots of impatience. however, that boundless, explore-at-all-cost drive soon backfired. in short time, i\u2019d have an unorganized notebook, duplicate code, plenty of ugly hacks, and a project that\u2019s difficult to share, reproduce, and deploy as an ml model.\n\nabstracted from my own pain, i\u2019m happy to introduce [**whisk**](http://docs.whisk-ml.org/)**,** an open-source data science project framework that makes collaboration, reproducibility, and deployment \u201cjust work\u201d. it combines a [data science-flavored python project structure](https://docs.whisk-ml.org/en/latest/project_structure.html) with a suite of lightweight tools. it adds *just enough* structure to make a project easy to share.\n\nif you're looking for another magical, highly-abstracted ml -----> tool !!! , this isn't it. instead, whisk leverages the ability to do special things when your project resembles the [standard python project structure](https://docs.python-guide.org/writing/structure/). from collaboration to distribution, it's all easier when this foundation is used.\n\nenough fluff - here's some sample projects using whisk. you should be able to clone these from github, run locally, and even deploy to heroku with just a couple of commands:\n\n* [bike image classifier](https://github.com/whisk-ml/bike_image_classifier_tensorflow) \\- a tensorflow-backed classifier that determines if an image is of a mountain bike or a road bike.\n* [real or not? nlp with disaster tweets](https://github.com/whisk-ml/disaster_tweets) \\- a tensorflow-backed keras model that predicts which tweets are about real disasters and which ones are not. [dvc](https://dvc.org) is used to version control the model training pipeline.\n\nwant to setup your own project? much like `django-admin startproject` creates the structure for a django web app, whisk sets up a project directory structure and environment for you. open a terminal and run:\n\n    pip3 install whisk\n    whisk create &lt;project_name&gt;\n\nreplacing &lt;project\\_name&gt; with your unique name. see the [quick tour](https://docs.whisk-ml.org/en/latest/tour_of_whisk.html) in the docs for more on setting up a project.\n\n[screen recording of \\`whisk create\\` at https:\\/\\/asciinema.org\\/a\\/uxw9s6ftkmbxnqqidtdrlfyii](https://preview.redd.it/7kkpxops1q251.png?width=808&amp;format=png&amp;auto=webp&amp;s=215310c69d868b189d1b057771a7857068583067)\n\nanyway, give whisk a shot. would be great to hear your feedback.\n\n## whisk resources\n\n* [documentation](https://docs.whisk-ml.org)\n* [whisk on github](https://github.com/whisk-ml/whisk)\n* [announcement post](https://dlite.cc/2020/06/02/whisk-data-science-project-framework.html) \\- has more details and screen recordings of the whisk cli commands.\n* example projects\n   * [disaster tweets](https://github.com/whisk-ml/disaster_tweets)\n   * [bike image classifier](https://github.com/whisk-ml/bike_image_classifier_tensorflow)\n\n## ps - what about cookiecutter data science?\n\nmy first attempts at structuring an ml project used [cookiecutter data science](https://drivendata.github.io/cookiecutter-data-science/), and life was way better. whisk takes this well-regarded structure and sprinkles on some magic: more graceful upgrades, environment configuration, packaging, [dvc](https://dvc.org), and deployment. i go into more details on the differences between whisk and cookie ds on my blog in my [announcement post](https://dlite.cc/2020/06/02/whisk-data-science-project-framework.html).\n\nhonestly though: if you are deciding between cookiecutter ds and whisk, we\u2019re already winning the war against sloppy data science.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gvwyqh/p_whisk_an_opensource_ml_project_framework_that/',)", "identifyer": 5750124, "year": "2020"}, {"autor": "ItisAhmad", "date": 1591448240000, "content": "Visualize your Github Profile /!/ Visualize Your Github profile with the Sourcerer tool. Check mine at\n\n [https://sourcerer.io/ahmadmustafaanis?utm\\_source=email&amp;utm\\_medium=RI&amp;utm\\_campaign=SeeMyProfile](https://sourcerer.io/ahmadmustafaanis?utm_source=email&amp;utm_medium=RI&amp;utm_campaign=SeeMyProfile) \n\nhttps://preview.redd.it/m4t257h0fa351.png?width=433&amp;format=png&amp;auto=webp&amp;s=b6150292c21b86cb7af60ba3aa51e4096a4db71b", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gxqi8p/visualize_your_github_profile/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "visualize your github profile /!/ visualize your github profile with the sourcerer -----> tool !!! . check mine at\n\n [https://sourcerer.io/ahmadmustafaanis?utm\\_source=email&amp;utm\\_medium=ri&amp;utm\\_campaign=seemyprofile](https://sourcerer.io/ahmadmustafaanis?utm_source=email&amp;utm_medium=ri&amp;utm_campaign=seemyprofile) \n\nhttps://preview.redd.it/m4t257h0fa351.png?width=433&amp;format=png&amp;auto=webp&amp;s=b6150292c21b86cb7af60ba3aa51e4096a4db71b", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gxqi8p/visualize_your_github_profile/',)", "identifyer": 5750199, "year": "2020"}, {"autor": "cl_m4ster", "date": 1588848573000, "content": "Which model should I use for my predictor? (little data)(timeseriesforecasting) /!/ Hello!  \n\n\nI'm writing this post because I need help with my college project - I am saying this because I have some strict requirements due to that. One of them is necessity of using model that will help with predicting certain values. I hope that you will be able to give me some advice.\n\nMy project in few words is tool for predicting your internet speed- based on measurements. The more measurements there are gathered, the better result.\n\nThe most important part of my project is the predictor. I have automated process of gathering data, now its time to use that data. And here comes my problem. I decided to use ARIMA model for time series forecasting. But it turned out to be complete disaster with my data. I don't know if arima in python is just not that good as it should be or it's just wrong model for my task. \n\nShould I maybe use R language for that? will it perform better? Which model should I use with my data? \n\nHere's sample of my data - it's not complete for now. It will be spectrum of full 24hours.\n\n[https://i.imgur.com/xuyFiSx.png](https://i.imgur.com/xuyFiSx.png)\n\n&amp;#x200B;\n\nThanks for any advice and have a nice day!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gf4b9d/which_model_should_i_use_for_my_predictor_little/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "which model should i use for my predictor? (little data)(timeseriesforecasting) /!/ hello!  \n\n\ni'm writing this post because i need help with my college project - i am saying this because i have some strict requirements due to that. one of them is necessity of using model that will help with predicting certain values. i hope that you will be able to give me some advice.\n\nmy project in few words is -----> tool !!!  for predicting your internet speed- based on measurements. the more measurements there are gathered, the better result.\n\nthe most important part of my project is the predictor. i have automated process of gathering data, now its time to use that data. and here comes my problem. i decided to use arima model for time series forecasting. but it turned out to be complete disaster with my data. i don't know if arima in python is just not that good as it should be or it's just wrong model for my task. \n\nshould i maybe use r language for that? will it perform better? which model should i use with my data? \n\nhere's sample of my data - it's not complete for now. it will be spectrum of full 24hours.\n\n[https://i.imgur.com/xuyfisx.png](https://i.imgur.com/xuyfisx.png)\n\n&amp;#x200b;\n\nthanks for any advice and have a nice day!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gf4b9d/which_model_should_i_use_for_my_predictor_little/',)", "identifyer": 5750335, "year": "2020"}, {"autor": "thezaza101", "date": 1588827286000, "content": "User experience in jypyter notebooks /!/ If articles like this are not allowed please remove.\n\nAll of us here would be familiar with jupyter notebooks, they are a great tool for learning and coding for data science and machine learning.\n\nOne constant annoyance for me is the fact that most of these notebooks are no un-intuitive and it takes forever to trace variables through the code to figure out what's going on. I'm writing a series of posts on how to improve user experience in jupyter notebooks; I've published my first one on handling user input. I welcome any feedback.\n\n[https://medium.com/@zahid.p.akbar/ux-in-jupyter-user-input-essentials-779c9b449f2d](https://medium.com/@zahid.p.akbar/ux-in-jupyter-user-input-essentials-779c9b449f2d)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gf05bu/user_experience_in_jypyter_notebooks/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "user experience in jypyter notebooks /!/ if articles like this are not allowed please remove.\n\nall of us here would be familiar with jupyter notebooks, they are a great -----> tool !!!  for learning and coding for data science and machine learning.\n\none constant annoyance for me is the fact that most of these notebooks are no un-intuitive and it takes forever to trace variables through the code to figure out what's going on. i'm writing a series of posts on how to improve user experience in jupyter notebooks; i've published my first one on handling user input. i welcome any feedback.\n\n[https://medium.com/@zahid.p.akbar/ux-in-jupyter-user-input-essentials-779c9b449f2d](https://medium.com/@zahid.p.akbar/ux-in-jupyter-user-input-essentials-779c9b449f2d)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gf05bu/user_experience_in_jypyter_notebooks/',)", "identifyer": 5750347, "year": "2020"}, {"autor": "diffu5e", "date": 1589076292000, "content": "Tool to quickly add single or multiclass labels to images without using your mouse", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ggsr0y/tool_to_quickly_add_single_or_multiclass_labels/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "-----> tool !!!  to quickly add single or multiclass labels to images without using your mouse", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://i.redd.it/b2j0wm5ehux41.gif',)", "identifyer": 5750423, "year": "2020"}, {"autor": "diffu5e", "date": 1589072969000, "content": "Tool to quickly label single or multiclass image data /!/ I made a tool to quickly associate classification labels with images, without your hands leaving the keyboard.  Improvement suggestions/contributions welcome!\n\nIf anyone is interested [here it is](https://github.com/diffuse/jabber)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ggrvzl/tool_to_quickly_label_single_or_multiclass_image/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "-----> tool !!!  to quickly label single or multiclass image data /!/ i made a tool to quickly associate classification labels with images, without your hands leaving the keyboard.  improvement suggestions/contributions welcome!\n\nif anyone is interested [here it is](https://github.com/diffuse/jabber)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ggrvzl/tool_to_quickly_label_single_or_multiclass_image/',)", "identifyer": 5750425, "year": "2020"}, {"autor": "hiphop1987", "date": 1588080234000, "content": "Are you still using Pandas for big data? /!/ Pandas doesn\u2019t have multiprocessing support and it is slow with bigger datasets. There is a better tool that puts those CPU cores to work!\n\n[https://towardsdatascience.com/are-you-still-using-pandas-for-big-data-12788018ba1a](https://towardsdatascience.com/are-you-still-using-pandas-for-big-data-12788018ba1a)\n\nTLDR;\n\n\\- meet Dask\n\n\\- Dask natively scales Python\n\n\\- Dask can process larger than memory datasets\n\n\\- usage of Dask is recommended only for datasets that don\u2019t fit in the main memory", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g9n3xm/are_you_still_using_pandas_for_big_data/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "are you still using pandas for big data? /!/ pandas doesn\u2019t have multiprocessing support and it is slow with bigger datasets. there is a better -----> tool !!!  that puts those cpu cores to work!\n\n[https://towardsdatascience.com/are-you-still-using-pandas-for-big-data-12788018ba1a](https://towardsdatascience.com/are-you-still-using-pandas-for-big-data-12788018ba1a)\n\ntldr;\n\n\\- meet dask\n\n\\- dask natively scales python\n\n\\- dask can process larger than memory datasets\n\n\\- usage of dask is recommended only for datasets that don\u2019t fit in the main memory", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g9n3xm/are_you_still_using_pandas_for_big_data/',)", "identifyer": 5750483, "year": "2020"}, {"autor": "hiphop1987", "date": 1588010874000, "content": "Are you still using Pandas for big data? /!/ Pandas doesn\u2019t have multiprocessing support and it is slow with bigger datasets. There is a better tool that puts those CPU cores to work!\n\n[https://towardsdatascience.com/are-you-still-using-pandas-for-big-data-12788018ba1a](https://towardsdatascience.com/are-you-still-using-pandas-for-big-data-12788018ba1a)\n\n&amp;#x200B;\n\nTLDR;\n\n\\- meet Dask\n\n\\- Pandas vs Dask\n\n\\- Pandas vs Dask CPU usage\n\n\\- What is happening behind the scenes?\n\n\\- Shortcomings of Dask", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g95ykw/are_you_still_using_pandas_for_big_data/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "are you still using pandas for big data? /!/ pandas doesn\u2019t have multiprocessing support and it is slow with bigger datasets. there is a better -----> tool !!!  that puts those cpu cores to work!\n\n[https://towardsdatascience.com/are-you-still-using-pandas-for-big-data-12788018ba1a](https://towardsdatascience.com/are-you-still-using-pandas-for-big-data-12788018ba1a)\n\n&amp;#x200b;\n\ntldr;\n\n\\- meet dask\n\n\\- pandas vs dask\n\n\\- pandas vs dask cpu usage\n\n\\- what is happening behind the scenes?\n\n\\- shortcomings of dask", "sortedWord": "None", "removed": "('nan',)", "score": 0, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g95ykw/are_you_still_using_pandas_for_big_data/',)", "identifyer": 5750516, "year": "2020"}, {"autor": "analyticsindiam", "date": 1588007116000, "content": "This week, we witnessed open-source tools focusing mostly on making models lighter and explainable. OpenAI, especially, has come up with an interesting tool to promote the interpretability of ML models", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g94q06/this_week_we_witnessed_opensource_tools_focusing/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "this week, we witnessed open-source tools focusing mostly on making models lighter and explainable. openai, especially, has come up with an interesting -----> tool !!!  to promote the interpretability of ml models", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('https://analyticsindiamag.com/open-ai-tensorflow/',)", "identifyer": 5750521, "year": "2020"}, {"autor": "analyticsindiam", "date": 1587964512000, "content": "AWS Launches AppFlow, A New Tool For Managing The Flow Of Data", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g8u9gv/aws_launches_appflow_a_new_tool_for_managing_the/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "aws launches appflow, a new -----> tool !!!  for managing the flow of data", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://analyticsindiamag.com/aws-launches-appflow-a-new-tool-for-managing-the-flow-of-data/',)", "identifyer": 5750555, "year": "2020"}, {"autor": "lblip123", "date": 1601382208000, "content": "I built a data dictionary and collaboration tool. I\u2019m curious if anyone is interested in giving it a try! /!/ At my old job, it seemed like every few weeks I\u2019d have a new project with a new dataset and business need. The hardest part of my job was understanding the data not completing the project. I created a tool to solve this and I\u2019m hoping to find beta users to give it a spin! If anyone is interested in trying it please let me know!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/j1y6c5/i_built_a_data_dictionary_and_collaboration_tool/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i built a data dictionary and collaboration -----> tool !!! . i\u2019m curious if anyone is interested in giving it a try! /!/ at my old job, it seemed like every few weeks i\u2019d have a new project with a new dataset and business need. the hardest part of my job was understanding the data not completing the project. i created a tool to solve this and i\u2019m hoping to find beta users to give it a spin! if anyone is interested in trying it please let me know!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/j1y6c5/i_built_a_data_dictionary_and_collaboration_tool/',)", "identifyer": 5750704, "year": "2020"}, {"autor": "biohacker_tobe", "date": 1599060487000, "content": "Using different sci-kit models with NGBoost /!/ I've come across this new tool of NGBoost from the Machine Learning group of Stanford, I was curious if peopel have started using it yet. They say that one can have a Base learner such as a regression tree etc, but looking at their examples I'm not sure on how my own model to this would be integrated. \n\n&amp;#x200B;\n\nJust mostly curious if anyone has used this tool yet.\n\n&amp;#x200B;\n\nPAPER: \\[[https://arxiv.org/pdf/1910.03225.pdf](https://arxiv.org/pdf/1910.03225.pdf)\\]\\[1\\]\n\n&amp;#x200B;\n\nGithub: \\[GitHub\\]\\[2\\]\n\n&amp;#x200B;\n\nThanks\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n  \\[1\\]: [https://arxiv.org/pdf/1910.03225.pdf](https://arxiv.org/pdf/1910.03225.pdf)\n\n  \\[2\\]: [https://github.com/stanfordmlgroup/ngboost](https://github.com/stanfordmlgroup/ngboost)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/il8wsh/using_different_scikit_models_with_ngboost/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "using different sci-kit models with ngboost /!/ i've come across this new -----> tool !!!  of ngboost from the machine learning group of stanford, i was curious if peopel have started using it yet. they say that one can have a base learner such as a regression tree etc, but looking at their examples i'm not sure on how my own model to this would be integrated. \n\n&amp;#x200b;\n\njust mostly curious if anyone has used this tool yet.\n\n&amp;#x200b;\n\npaper: \\[[https://arxiv.org/pdf/1910.03225.pdf](https://arxiv.org/pdf/1910.03225.pdf)\\]\\[1\\]\n\n&amp;#x200b;\n\ngithub: \\[github\\]\\[2\\]\n\n&amp;#x200b;\n\nthanks\n\n&amp;#x200b;\n\n&amp;#x200b;\n\n  \\[1\\]: [https://arxiv.org/pdf/1910.03225.pdf](https://arxiv.org/pdf/1910.03225.pdf)\n\n  \\[2\\]: [https://github.com/stanfordmlgroup/ngboost](https://github.com/stanfordmlgroup/ngboost)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/il8wsh/using_different_scikit_models_with_ngboost/',)", "identifyer": 5750769, "year": "2020"}, {"autor": "hraath", "date": 1598903931000, "content": "How best to ingest a feature that is a ranked list (eg. of words)? /!/ Hi all,\n\nI've come across this problem when doing analysis on survey-type data, where a (one or more) question may be of the kind \"rank the following n words in order of most to least important\". My data for the question will have then a column for each word containing the ordinal number of rank.\n\nA toy example would be \"rank these colours in order of preference: red blue yellow green\", and an example response \"3 1 4 2\", under columns \"red\", \"blue\", \"yellow\", \"green\".\n\nNaiively I can treat these data columns as independent, and the integer value will have some inverse proportional relationship to sentiment, yet I know there is a contextual relationship here more than \"blue is the favorite colour\". This data also tells us blue is preferred over red/yellow/green, and red is preferred over yellow, etc. Is there some tool/algo/method that allows sets of features to be preprocessed into some sort of ordered list or tree, that is then a useful/digestable feature for a model that considers the whole survey? \n\nHow can I associate entries (blue, yellow, red, green), (yellow, blue, red, green), (yellow, red, blue, green), where there is a pattern pattern of (blue&gt;green, yellow&gt;red), despite mismatching numerical ranks? As a simple integer, those entires would be (3 1 2 4), (3 2 1 4), (2 3 1 4), and I could only hope a decision tree model can find the patterns given enough data.\n\nI'm primarily talking about classical machine/stat learning rather than NN models for this instance. Perhaps this is a philosophical question, in the context of small data, where I don't have the luxury of letting the model learn this context over the course of lots of training data. Is there a way to impose this contextual relationship between features, such that the model has less complexity and can be trained with less data, or that I can use patterns in the rankings AS features? \n\nI suppose 1D convolutional filters of size 2, 3 or, 4 would be able to identify ordered subsets, which might do the job. Is that something that could be done as preproceesing, then passed back (ie N-hot encoded over all combinations of preferences) to a model that handles the mixed datatypes of the survey questions?\n\nThis got a bit wordy, but any insight is welcome.\n\nThanks", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ik5bqn/how_best_to_ingest_a_feature_that_is_a_ranked/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "how best to ingest a feature that is a ranked list (eg. of words)? /!/ hi all,\n\ni've come across this problem when doing analysis on survey-type data, where a (one or more) question may be of the kind \"rank the following n words in order of most to least important\". my data for the question will have then a column for each word containing the ordinal number of rank.\n\na toy example would be \"rank these colours in order of preference: red blue yellow green\", and an example response \"3 1 4 2\", under columns \"red\", \"blue\", \"yellow\", \"green\".\n\nnaiively i can treat these data columns as independent, and the integer value will have some inverse proportional relationship to sentiment, yet i know there is a contextual relationship here more than \"blue is the favorite colour\". this data also tells us blue is preferred over red/yellow/green, and red is preferred over yellow, etc. is there some -----> tool !!! /algo/method that allows sets of features to be preprocessed into some sort of ordered list or tree, that is then a useful/digestable feature for a model that considers the whole survey? \n\nhow can i associate entries (blue, yellow, red, green), (yellow, blue, red, green), (yellow, red, blue, green), where there is a pattern pattern of (blue&gt;green, yellow&gt;red), despite mismatching numerical ranks? as a simple integer, those entires would be (3 1 2 4), (3 2 1 4), (2 3 1 4), and i could only hope a decision tree model can find the patterns given enough data.\n\ni'm primarily talking about classical machine/stat learning rather than nn models for this instance. perhaps this is a philosophical question, in the context of small data, where i don't have the luxury of letting the model learn this context over the course of lots of training data. is there a way to impose this contextual relationship between features, such that the model has less complexity and can be trained with less data, or that i can use patterns in the rankings as features? \n\ni suppose 1d convolutional filters of size 2, 3 or, 4 would be able to identify ordered subsets, which might do the job. is that something that could be done as preproceesing, then passed back (ie n-hot encoded over all combinations of preferences) to a model that handles the mixed datatypes of the survey questions?\n\nthis got a bit wordy, but any insight is welcome.\n\nthanks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ik5bqn/how_best_to_ingest_a_feature_that_is_a_ranked/',)", "identifyer": 5750826, "year": "2020"}, {"autor": "s_basu", "date": 1598865382000, "content": "What sort of project can I possibly build from the knowledge of a Data analysis course? /!/ Hello. I have started this course named \"Python for statistical analysis\" by Samuel Hinton on Udemy, and it covers some bit of Exploratory data analysis and plotting techniques etc. What I was wondering was how do I make use of these bits of knowledge to some actual project. I know I can tinker around with many datasets online and use the EDA on Jupyter notebooks to get insights about the dataset etc. But is this the only way of going at it? can there be some independent projects that utilize and show the full potential of data analysis or do I always have to use it as a prototyping tool?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ijurl7/what_sort_of_project_can_i_possibly_build_from/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "what sort of project can i possibly build from the knowledge of a data analysis course? /!/ hello. i have started this course named \"python for statistical analysis\" by samuel hinton on udemy, and it covers some bit of exploratory data analysis and plotting techniques etc. what i was wondering was how do i make use of these bits of knowledge to some actual project. i know i can tinker around with many datasets online and use the eda on jupyter notebooks to get insights about the dataset etc. but is this the only way of going at it? can there be some independent projects that utilize and show the full potential of data analysis or do i always have to use it as a prototyping -----> tool !!! ?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ijurl7/what_sort_of_project_can_i_possibly_build_from/',)", "identifyer": 5750844, "year": "2020"}, {"autor": "Plastic-Camp", "date": 1602096481000, "content": "Did anyone actually like deep learning book (the one Elon musk endorsed)? /!/ I bought it and started reading it with great enthusiasm but almost instantly became disappointed. The mathematical concepts were never explained. They were just listed in formula form and you had to mentally work through what they did. A lot of things were never explained and with great effort I don't think I even made it past the first chapter to be honest with you.\n\nBut then I look on Amazon and the reviews are all awesome. I don't know maybe I'm really dumb because I can't imagine so many people actually liking that book. I had guessed maybe their fake reviews or their real reviews but not from people who actually tried using the book as a learning tool. But when I Google it there's no negative press about the darn thing.\n\nHave you read the book and if so did you find it useful as a learning tool? If you didn't like it why do you think it has so many positive reviews?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/j6wra6/did_anyone_actually_like_deep_learning_book_the/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "did anyone actually like deep learning book (the one elon musk endorsed)? /!/ i bought it and started reading it with great enthusiasm but almost instantly became disappointed. the mathematical concepts were never explained. they were just listed in formula form and you had to mentally work through what they did. a lot of things were never explained and with great effort i don't think i even made it past the first chapter to be honest with you.\n\nbut then i look on amazon and the reviews are all awesome. i don't know maybe i'm really dumb because i can't imagine so many people actually liking that book. i had guessed maybe their fake reviews or their real reviews but not from people who actually tried using the book as a learning -----> tool !!! . but when i google it there's no negative press about the darn thing.\n\nhave you read the book and if so did you find it useful as a learning tool? if you didn't like it why do you think it has so many positive reviews?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 38, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/j6wra6/did_anyone_actually_like_deep_learning_book_the/',)", "identifyer": 5750874, "year": "2020"}, {"autor": "BoldSlogan", "date": 1602087839000, "content": "I built a tool using machine learning and the RFID in phones to validate your passport /!/ **Feel free to use an invalid passport and/or use the app on airplane mode so that you feel comfortable.**\n\nI used the phone's RFID reader and machine learning to verify the personal data on passports using the secure chip embedded inside.\n\nThe app works by first using the camera to scan the passport\u2019s data page, a step that is needed because the key used for reading the embedded chip is constructed out of the visible printed passport data. Then it will read and verify the embedded chip and display the extracted information.\n\nHere is a 30 second demo: https://www.youtube.com/watch?v=VTdpOcG1NSw\n\nI am looking for users/testers with different passports to try it out. I wanted to see if my weekend hackathon project actually works or if it is only my passport and my friends that works.\n\nWould love to hear your thoughts! \ud83d\ude0a\n\nThe app is available for both iOS and Android and requires an NFC-enabled device (most modern Android devices and all iPhones starting with the iPhone 7 are NFC-enabled). You will also need a biometric passport (sometimes called electronic passport) that you can read. Most modern passports issued today are biometric passports, and you can verify this by looking for a microchip icon usually printed on the passport cover. \n\nhttps://apps.apple.com/us/app/biometric-passport-reader/id1510585886\nhttps://play.google.com/store/apps/details?id=app.iris\"", "link": "https://www.reddit.com/r/learnmachinelearning/comments/j6tyd7/i_built_a_tool_using_machine_learning_and_the/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i built a -----> tool !!!  using machine learning and the rfid in phones to validate your passport /!/ **feel free to use an invalid passport and/or use the app on airplane mode so that you feel comfortable.**\n\ni used the phone's rfid reader and machine learning to verify the personal data on passports using the secure chip embedded inside.\n\nthe app works by first using the camera to scan the passport\u2019s data page, a step that is needed because the key used for reading the embedded chip is constructed out of the visible printed passport data. then it will read and verify the embedded chip and display the extracted information.\n\nhere is a 30 second demo: https://www.youtube.com/watch?v=vtdpocg1nsw\n\ni am looking for users/testers with different passports to try it out. i wanted to see if my weekend hackathon project actually works or if it is only my passport and my friends that works.\n\nwould love to hear your thoughts! \ud83d\ude0a\n\nthe app is available for both ios and android and requires an nfc-enabled device (most modern android devices and all iphones starting with the iphone 7 are nfc-enabled). you will also need a biometric passport (sometimes called electronic passport) that you can read. most modern passports issued today are biometric passports, and you can verify this by looking for a microchip icon usually printed on the passport cover. \n\nhttps://apps.apple.com/us/app/biometric-passport-reader/id1510585886\nhttps://play.google.com/store/apps/details?id=app.iris\"", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/j6tyd7/i_built_a_tool_using_machine_learning_and_the/',)", "identifyer": 5750879, "year": "2020"}, {"autor": "willspag", "date": 1602076740000, "content": "XGBoost /!/ I\u2019m a Tensorflow developer, and very familiar with Neural Networks, but I\u2019ve seen a lot of stuff about how great XGBoost is. Is it another deep learning framework? A tool for optimizing/boosting existing frameworks? A replacement for Deep learning? A tool for hyper parameter tuning?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/j6qnxp/xgboost/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "xgboost /!/ i\u2019m a tensorflow developer, and very familiar with neural networks, but i\u2019ve seen a lot of stuff about how great xgboost is. is it another deep learning framework? a -----> tool !!!  for optimizing/boosting existing frameworks? a replacement for deep learning? a tool for hyper parameter tuning?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/j6qnxp/xgboost/',)", "identifyer": 5750883, "year": "2020"}, {"autor": "HunterDude54", "date": 1602048062000, "content": "Higher detail and resolution photo extracted from a movie? /!/ I want to capture a better image from a movie than simply capturing single frames.  My question is whether there is a tool to improve the single movie frame that you capture in the first place.  For example, if I were to select a frame to capture, then the AI would use adjacent frames, on each side (an image stack?), to improve the resolution and accuracy of the selected one.  Providing a much higher quality jpg/image using the movie itself as the template. I'm not sure this has been done, and google is not my friend in this.  Is this called deconvolution?  Is there an AI or ML app or tool for this?\n\nI am well aware that you can now take a movie still or frame and upscale, denoise or whatever you want to do with AI or ML.  (Or take a movie and improve detail).  My question is sort of the reverse direction, using the additional data in the movie itself.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/j6l6fp/higher_detail_and_resolution_photo_extracted_from/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "higher detail and resolution photo extracted from a movie? /!/ i want to capture a better image from a movie than simply capturing single frames.  my question is whether there is a -----> tool !!!  to improve the single movie frame that you capture in the first place.  for example, if i were to select a frame to capture, then the ai would use adjacent frames, on each side (an image stack?), to improve the resolution and accuracy of the selected one.  providing a much higher quality jpg/image using the movie itself as the template. i'm not sure this has been done, and google is not my friend in this.  is this called deconvolution?  is there an ai or ml app or tool for this?\n\ni am well aware that you can now take a movie still or frame and upscale, denoise or whatever you want to do with ai or ml.  (or take a movie and improve detail).  my question is sort of the reverse direction, using the additional data in the movie itself.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/j6l6fp/higher_detail_and_resolution_photo_extracted_from/',)", "identifyer": 5750892, "year": "2020"}, {"autor": "8329417966", "date": 1595960981000, "content": "AutoViz: A new tool for Automated Visualization in Data Science. /!/ https://youtu.be/aiKa6QCV0qQ", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hzk2b0/autoviz_a_new_tool_for_automated_visualization_in/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "autoviz: a new -----> tool !!!  for automated visualization in data science. /!/ https://youtu.be/aika6qcv0qq", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hzk2b0/autoviz_a_new_tool_for_automated_visualization_in/',)", "identifyer": 5750964, "year": "2020"}, {"autor": "whilneville", "date": 1595870344000, "content": "Trying to set up this, but how? /!/ Im trying to set up this thing, but i dont know how honestly....is there any video that can explain me a little bit? (never done this before) \n\nthis is the tool im trying to run\n\n[https://github.com/CorentinJ/Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)   \n\n\n \\-------------\n\n### 1. Install Requirements\n\n**Python 3.6 or 3.7** is needed to run the toolbox. &lt;&lt;&lt; i know how to do this cuz anyways i did some games tiny games with python (mega basic games lol)\n\n&amp;#x200B;\n\n\\---------------------------\n\nI don't know how to do this, is there a console to just run the code and im good to go?\n\n \n\n* Install [PyTorch](https://pytorch.org/get-started/locally/) (&gt;=1.0.1).\n* Install [ffmpeg](https://ffmpeg.org/download.html#get-packages).\n* Run pip install -r requirements.txt  \n to install the remaining necessary packages.\n\n\\-----------------\n\n for this part, i assume that i have to run the code exactly like i have to do with the previous step?\n\n### 3. (Optional) Test Configuration\n\nBefore you download any dataset, you can begin by testing your configuration with:\n\npython demo\\_cli.py\n\nIf all tests pass, you're good to go.\n\n&amp;#x200B;\n\nI accept any help, thanks mates!.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hywhsv/trying_to_set_up_this_but_how/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "trying to set up this, but how? /!/ im trying to set up this thing, but i dont know how honestly....is there any video that can explain me a little bit? (never done this before) \n\nthis is the -----> tool !!!  im trying to run\n\n[https://github.com/corentinj/real-time-voice-cloning](https://github.com/corentinj/real-time-voice-cloning)   \n\n\n \\-------------\n\n### 1. install requirements\n\n**python 3.6 or 3.7** is needed to run the toolbox. &lt;&lt;&lt; i know how to do this cuz anyways i did some games tiny games with python (mega basic games lol)\n\n&amp;#x200b;\n\n\\---------------------------\n\ni don't know how to do this, is there a console to just run the code and im good to go?\n\n \n\n* install [pytorch](https://pytorch.org/get-started/locally/) (&gt;=1.0.1).\n* install [ffmpeg](https://ffmpeg.org/download.html#get-packages).\n* run pip install -r requirements.txt  \n to install the remaining necessary packages.\n\n\\-----------------\n\n for this part, i assume that i have to run the code exactly like i have to do with the previous step?\n\n### 3. (optional) test configuration\n\nbefore you download any dataset, you can begin by testing your configuration with:\n\npython demo\\_cli.py\n\nif all tests pass, you're good to go.\n\n&amp;#x200b;\n\ni accept any help, thanks mates!.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hywhsv/trying_to_set_up_this_but_how/',)", "identifyer": 5751018, "year": "2020"}, {"autor": "Archa3opt3ryx", "date": 1598512970000, "content": "Unsure of how to get started with using NLP for analyzing user feedback /!/ I have \\~138k records of user feedback that I'd like to analyze to understand broad patterns in what our users are most often saying. Each one has a rating between 1-5 stars, so I don't need to do any sort of sentiment analysis. I'm mostly interested in splitting the dataset into &gt;=4 to see what we're doing well and &lt;= 3 to see what we need to improve upon.\n\nOne key problem I'm running into is that I expect to see a lot of n-grams. Some of these I know, like \"HOV lane\", \"carpool lane\", \"detour time\", etc. But I also want to detect common bi- and tri-grams programmatically. I've been playing around with Spacy a bit, but it doesn't seem to have any capability to do analysis on the corpus level, only on the document level. \n\nIdeally my pipeline would look something like this (I think):\n\n1. Import a list of known n-grams into the tokenizer\n2. Process each string into a tokenized document, removing punctuation, stopwords, etc, while respecting the known n-grams during tokenization (ie, \"HOV lane\" should be a single noun token)\n3. Identify the most common bi- and tri- grams in the corpus that I missed\n4. Re-tokenize using the found n-grams\n5. Split by rating (&gt;=4 and &lt;=3)\n6. Find the most common topics for each split of data in the corpus\n\nI can't seem to find a single tool, or even a collection of tools, that will allow me to do what I want here. Am I approaching this the wrong way somehow? Any pointers on how to get started would be greatly appreciated!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ihgmeo/unsure_of_how_to_get_started_with_using_nlp_for/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "unsure of how to get started with using nlp for analyzing user feedback /!/ i have \\~138k records of user feedback that i'd like to analyze to understand broad patterns in what our users are most often saying. each one has a rating between 1-5 stars, so i don't need to do any sort of sentiment analysis. i'm mostly interested in splitting the dataset into &gt;=4 to see what we're doing well and &lt;= 3 to see what we need to improve upon.\n\none key problem i'm running into is that i expect to see a lot of n-grams. some of these i know, like \"hov lane\", \"carpool lane\", \"detour time\", etc. but i also want to detect common bi- and tri-grams programmatically. i've been playing around with spacy a bit, but it doesn't seem to have any capability to do analysis on the corpus level, only on the document level. \n\nideally my pipeline would look something like this (i think):\n\n1. import a list of known n-grams into the tokenizer\n2. process each string into a tokenized document, removing punctuation, stopwords, etc, while respecting the known n-grams during tokenization (ie, \"hov lane\" should be a single noun token)\n3. identify the most common bi- and tri- grams in the corpus that i missed\n4. re-tokenize using the found n-grams\n5. split by rating (&gt;=4 and &lt;=3)\n6. find the most common topics for each split of data in the corpus\n\ni can't seem to find a single -----> tool !!! , or even a collection of tools, that will allow me to do what i want here. am i approaching this the wrong way somehow? any pointers on how to get started would be greatly appreciated!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ihgmeo/unsure_of_how_to_get_started_with_using_nlp_for/',)", "identifyer": 5751145, "year": "2020"}, {"autor": "fiddlest", "date": 1587586297000, "content": "I am looking for a tool to collect voice data for the voice classifier. /!/ I need to make a voice classifier for my side project. However, it needs a lot of data to create it. The only way to get some voice data is that download a youtube video that has a certain person's voice and cut and extracts only that person's voice. Is there any tool to help me to reduce the manual process?\n\nFor a simple image classifier, I can use python google image downloader to download a bunch of images related to the keyword. However, I can only think of a manual way of collecting dataset for the voice.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g68f3i/i_am_looking_for_a_tool_to_collect_voice_data_for/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i am looking for a -----> tool !!!  to collect voice data for the voice classifier. /!/ i need to make a voice classifier for my side project. however, it needs a lot of data to create it. the only way to get some voice data is that download a youtube video that has a certain person's voice and cut and extracts only that person's voice. is there any tool to help me to reduce the manual process?\n\nfor a simple image classifier, i can use python google image downloader to download a bunch of images related to the keyword. however, i can only think of a manual way of collecting dataset for the voice.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g68f3i/i_am_looking_for_a_tool_to_collect_voice_data_for/',)", "identifyer": 5751402, "year": "2020"}, {"autor": "BillCrum", "date": 1605228980000, "content": "Looking on feedback on concept for no-code tool for deploying models to an API endpoint /!/ Hi there,\n\nI've been really interested in the recent trend of low/no code tools into the ML space.\n\nA friend and I have been working on a concept that allows you to upload a Tensorflow or Pytorch model that you've already built, and then the tool would automatically deploy this model to an API endpoint on the cloud for inference. \n\nBefore we set out to fully build it, do you think a tool like this be useful for you? I know everyone on this sub is at a different point on their ML learning curve and has different skillsets. What are your pain points, if any, when it comes to actually applying ML to a real problem?\n\nHere's the landing page for a more in-depth description of what I'm imagining: [https://www.getaiko.com/](https://www.getaiko.com/)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jt7c00/looking_on_feedback_on_concept_for_nocode_tool/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "looking on feedback on concept for no-code -----> tool !!!  for deploying models to an api endpoint /!/ hi there,\n\ni've been really interested in the recent trend of low/no code tools into the ml space.\n\na friend and i have been working on a concept that allows you to upload a tensorflow or pytorch model that you've already built, and then the tool would automatically deploy this model to an api endpoint on the cloud for inference. \n\nbefore we set out to fully build it, do you think a tool like this be useful for you? i know everyone on this sub is at a different point on their ml learning curve and has different skillsets. what are your pain points, if any, when it comes to actually applying ml to a real problem?\n\nhere's the landing page for a more in-depth description of what i'm imagining: [https://www.getaiko.com/](https://www.getaiko.com/)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jt7c00/looking_on_feedback_on_concept_for_nocode_tool/',)", "identifyer": 5751465, "year": "2020"}, {"autor": "du_dt", "date": 1605137607000, "content": "[Q] Tool to visually inspect predictions? /!/ Hello all.\n\nI'm working on an object detection problem with domain shift. I've done several experiments with different models and architectures, and there are a few that show similar numbers in terms of accuracy. Now I would like to compare their predictions visually on a bunch of unseen and unlabeled pictures. Are there any nice tools to plot prediction images side-by-side? Or, maybe, a simple web interface to review results with basic UI (zooming in, for example)? \n\n&amp;#x200B;\n\nCheers", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jsj9m5/q_tool_to_visually_inspect_predictions/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "[q] -----> tool !!!  to visually inspect predictions? /!/ hello all.\n\ni'm working on an object detection problem with domain shift. i've done several experiments with different models and architectures, and there are a few that show similar numbers in terms of accuracy. now i would like to compare their predictions visually on a bunch of unseen and unlabeled pictures. are there any nice tools to plot prediction images side-by-side? or, maybe, a simple web interface to review results with basic ui (zooming in, for example)? \n\n&amp;#x200b;\n\ncheers", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jsj9m5/q_tool_to_visually_inspect_predictions/',)", "identifyer": 5751524, "year": "2020"}, {"autor": "smith2017", "date": 1582434171000, "content": "Learning AI in the browser by solving real world issues /!/ Hello,\n\nI am currently building a tool for developers willing to learn AI by solving real city issues and having access to all possible data layers. \n\nThe demo isn't finished yet, but you can get the idea [here](https://ofservice-ans2ruhekq-ue.a.run.app/).\n\nThank you", "link": "https://www.reddit.com/r/learnmachinelearning/comments/f84xyu/learning_ai_in_the_browser_by_solving_real_world/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "learning ai in the browser by solving real world issues /!/ hello,\n\ni am currently building a -----> tool !!!  for developers willing to learn ai by solving real city issues and having access to all possible data layers. \n\nthe demo isn't finished yet, but you can get the idea [here](https://ofservice-ans2ruhekq-ue.a.run.app/).\n\nthank you", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/f84xyu/learning_ai_in_the_browser_by_solving_real_world/',)", "identifyer": 5751636, "year": "2020"}, {"autor": "fnunogomes", "date": 1585756965000, "content": "How to build a dataset using Google images /!/ Does anyone know how could I download images from Google images to build a dataset. I have found and tested the \"google_images_download\" tool, but ir doesn't work right for me. I have also tested using the JavaScript console on the browser but it doesn't work for me also. Thanks for the help!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ft2iti/how_to_build_a_dataset_using_google_images/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "how to build a dataset using google images /!/ does anyone know how could i download images from google images to build a dataset. i have found and tested the \"google_images_download\" -----> tool !!! , but ir doesn't work right for me. i have also tested using the javascript console on the browser but it doesn't work for me also. thanks for the help!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ft2iti/how_to_build_a_dataset_using_google_images/',)", "identifyer": 5751654, "year": "2020"}, {"autor": "techie_ray", "date": 1585606725000, "content": "I created a machine learning tool to analyse my dance moves...ended up getting roasted :(", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fs0lqu/i_created_a_machine_learning_tool_to_analyse_my/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i created a machine learning -----> tool !!!  to analyse my dance moves...ended up getting roasted :(", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 39, "media": "('rich:video',)", "medialink": "('https://www.youtube.com/watch?v=bPDoMdn71h0',)", "identifyer": 5751711, "year": "2020"}, {"autor": "cmillionaire9", "date": 1595238540000, "content": "Mobile annotation tool | Dataset", "link": "https://www.reddit.com/r/learnmachinelearning/comments/huij9a/mobile_annotation_tool_dataset/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "mobile annotation -----> tool !!!  | dataset", "sortedWord": "None", "removed": "('nan',)", "score": 0, "comments": 2, "media": "('rich:video',)", "medialink": "('https://youtu.be/dp64fEsFwqE',)", "identifyer": 5751817, "year": "2020"}, {"autor": "borisnhorton", "date": 1586461510000, "content": "Help with forecasting project using machine learning tool /!/ Hi Everyone, any help or pointing in the right direction would be appreciated :)\n\nI am working on a project which is essentially time series modeling where I am trying to predict my companies headcount in a given location by segment for the next few years. I have already built a simple excel model which takes into account historical data for the past 5 years and it is a good phase 1 approach. Essentially what it does is if the segment gives me their forecast I will use it, if not then I will use their historical growth rate.\n\nI understand that this approach isn't that valuable and previous headcount doesn't explain the business drivers. For phase 2, I want to add in historical business drivers (sales etc.) and forecasted drivers in order to triangulate to a better forecast.\n\nI am thinking about using alteryx for the data gathering and cleansing part, but would it be good for the machine learning/predictive part of what I am trying to solve which is combining multiple variables to arrive at an output? I am not a data scientist but I am not opposed enhancing my technical skills to try to make this happen.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fxz7rp/help_with_forecasting_project_using_machine/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "help with forecasting project using machine learning -----> tool !!!  /!/ hi everyone, any help or pointing in the right direction would be appreciated :)\n\ni am working on a project which is essentially time series modeling where i am trying to predict my companies headcount in a given location by segment for the next few years. i have already built a simple excel model which takes into account historical data for the past 5 years and it is a good phase 1 approach. essentially what it does is if the segment gives me their forecast i will use it, if not then i will use their historical growth rate.\n\ni understand that this approach isn't that valuable and previous headcount doesn't explain the business drivers. for phase 2, i want to add in historical business drivers (sales etc.) and forecasted drivers in order to triangulate to a better forecast.\n\ni am thinking about using alteryx for the data gathering and cleansing part, but would it be good for the machine learning/predictive part of what i am trying to solve which is combining multiple variables to arrive at an output? i am not a data scientist but i am not opposed enhancing my technical skills to try to make this happen.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fxz7rp/help_with_forecasting_project_using_machine/',)", "identifyer": 5751837, "year": "2020"}, {"autor": "Sbbarse2121", "date": 1586460613000, "content": "Which platform is effective to implement Machine Learning stuff ? /!/ Hey, what you think which platform is effective to implement ML. It is sklearn,keras or you believe\n\nto build your model from scratch using library like numpy or you use any other tool that nobody uses.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/fxyxkg/which_platform_is_effective_to_implement_machine/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "which platform is effective to implement machine learning stuff ? /!/ hey, what you think which platform is effective to implement ml. it is sklearn,keras or you believe\n\nto build your model from scratch using library like numpy or you use any other -----> tool !!!  that nobody uses.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/fxyxkg/which_platform_is_effective_to_implement_machine/',)", "identifyer": 5751838, "year": "2020"}, {"autor": "debbydai", "date": 1603880410000, "content": "Image Annotation Tools Comparison /!/ I am a newbie to annotation tools. After trying a few FREE annotation tools, I figured why not share my experience with others. I have tried annotation 3 tools, which are Labelbox, dLabel and supervised.\n\nMy comparison will be in sections. \n\n**1 Uploading**\n\nMy images sample were 50 frames. \n\n    dLabel ------easy to upload but a little confused to see\n\n&amp;#x200B;\n\nhttps://preview.redd.it/sxrpueww6tv51.png?width=1124&amp;format=png&amp;auto=webp&amp;s=477a06f8386408d463a10ee815aaf68ee0ec870f\n\nfinding where to upload your own database is easy to spot and upload. However, after uploading the selected images, it doesn\u2019t show how many images have been uploaded. And it doesn't have a complication button to finish uploading which is a bit confusing. This could be a problem if the data is massive.\n\n    Labelbox -----easy and clear to upload \n\n&amp;#x200B;\n\nhttps://preview.redd.it/7zft40ay6tv51.png?width=872&amp;format=png&amp;auto=webp&amp;s=26f284cb67385c851a57988a5e8bb0703058261d\n\nOnce I sign in, I can start to upload your own data and it shows how many images have been added and easily to complete uploading. Like dLabel you can see your items after uploading the dataset, set annotation tool etc. \n\n    Spervisely \u00a0-------Hard to upload for first time users\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6hrkbel07tv51.png?width=615&amp;format=png&amp;auto=webp&amp;s=259381407541edb8b68ba6019dd973a04b2629eb\n\nThough it has a small demonstration Gif, it still takes more time to import the images as it has too many unnecessary steps such as asking about the uploading way and you can only add the project name after uploading your dataset. \n\n**2 adding annotation objects**\n\n    dLabel\u00a0   \n\nI can add annotation objects at both after uploading your dataset and whenever you want. And it has this \u201cattribute\u201d function\u201d where you can define, add more information, classify the objects.  But I can not edit the added annotation objects. \n\n    Labelbox\n\nLike dLabel, you can create annotation objects whenever you want. However, it is less convenient than dLabel as you need to go to the editor\u2019s page and edit or add more annotation objects. There is \u201cclassification\u201d function where you can classify the objects. I personally like the \u201cattribute \u201c feature from dLabel more and it can contain more information about the objects. \n\n    Spervisely \n\nAdding and modifying  the annotation objects are easy and clear. There is no feature like or similar to \u201cattribute\u201d from dLabel or \u201cclassification\u201d form Labelbox. One good part is that I can personalize my own hotkeys for each object, which can adapt an individual's annotation habit.\n\n**3 Annotation speed for 30 frames.**\n\nThe data set is 30images. Using bonding boxes. 2 annotation objects (hand and drink)\n\n&amp;#x200B;\n\n||uploading time time|labeling time|Clicks per frame|\n|:-|:-|:-|:-|\n|dLabel|2 min|9 min|7 clicks|\n|Labelbox|2 min|12min 10 sec|7 clicks|\n|Supervisly|4 min|12min 30 sec|9 clicks|\n\n&amp;#x200B;\n\n**4 layout of the annotation page** \n\n    dLabel \n    \n\n&amp;#x200B;\n\nhttps://preview.redd.it/et1osbo68tv51.png?width=1367&amp;format=png&amp;auto=webp&amp;s=77419947a904a3667c88e50289f1188f515ca7a7\n\nYou have the features at the left, the statues in the right and the image in the centre. \n\nOne the left side, there is one \u201cgroup\u201d feature which I found is very useful. It adds interaction between objects. Like you set the \u201ctomato\u201d and the \u201chand\u201d into one group which indicates they have interactions. The hand is picking the tomato. \n\nThere is a history column on the right where you can also trace the annotation history on the right. \n\nOn the bottom of the centre, there\u2019s one QA bar which can come in hand when doing quality control. \n\n**Labelbox** \n\n&amp;#x200B;\n\nhttps://preview.redd.it/rbk5mpq88tv51.png?width=1374&amp;format=png&amp;auto=webp&amp;s=fae5a6bef8937d97bc3a2bf2799d3f1737ac9ab5\n\nI personally find the layout too simple. There are not many features. So There is nothing much to say. \n\n**Spervisely** \n\n&amp;#x200B;\n\nhttps://preview.redd.it/37mewkw98tv51.png?width=1425&amp;format=png&amp;auto=webp&amp;s=3e45d7332340a1531b288b72f5650b299aac6865\n\nthe right side features are bit confusing...\n\nI didn't quite understand what are\"image properties\" and \"objects properties\". \n\nIt shows the annotation history which Labelbox doesn't have hotkeys easily  .", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jjl6ao/image_annotation_tools_comparison/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "image annotation tools comparison /!/ i am a newbie to annotation tools. after trying a few free annotation tools, i figured why not share my experience with others. i have tried annotation 3 tools, which are labelbox, dlabel and supervised.\n\nmy comparison will be in sections. \n\n**1 uploading**\n\nmy images sample were 50 frames. \n\n    dlabel ------easy to upload but a little confused to see\n\n&amp;#x200b;\n\nhttps://preview.redd.it/sxrpueww6tv51.png?width=1124&amp;format=png&amp;auto=webp&amp;s=477a06f8386408d463a10ee815aaf68ee0ec870f\n\nfinding where to upload your own database is easy to spot and upload. however, after uploading the selected images, it doesn\u2019t show how many images have been uploaded. and it doesn't have a complication button to finish uploading which is a bit confusing. this could be a problem if the data is massive.\n\n    labelbox -----easy and clear to upload \n\n&amp;#x200b;\n\nhttps://preview.redd.it/7zft40ay6tv51.png?width=872&amp;format=png&amp;auto=webp&amp;s=26f284cb67385c851a57988a5e8bb0703058261d\n\nonce i sign in, i can start to upload your own data and it shows how many images have been added and easily to complete uploading. like dlabel you can see your items after uploading the dataset, set annotation -----> tool !!!  etc. \n\n    spervisely \u00a0-------hard to upload for first time users\n\n&amp;#x200b;\n\nhttps://preview.redd.it/6hrkbel07tv51.png?width=615&amp;format=png&amp;auto=webp&amp;s=259381407541edb8b68ba6019dd973a04b2629eb\n\nthough it has a small demonstration gif, it still takes more time to import the images as it has too many unnecessary steps such as asking about the uploading way and you can only add the project name after uploading your dataset. \n\n**2 adding annotation objects**\n\n    dlabel\u00a0   \n\ni can add annotation objects at both after uploading your dataset and whenever you want. and it has this \u201cattribute\u201d function\u201d where you can define, add more information, classify the objects.  but i can not edit the added annotation objects. \n\n    labelbox\n\nlike dlabel, you can create annotation objects whenever you want. however, it is less convenient than dlabel as you need to go to the editor\u2019s page and edit or add more annotation objects. there is \u201cclassification\u201d function where you can classify the objects. i personally like the \u201cattribute \u201c feature from dlabel more and it can contain more information about the objects. \n\n    spervisely \n\nadding and modifying  the annotation objects are easy and clear. there is no feature like or similar to \u201cattribute\u201d from dlabel or \u201cclassification\u201d form labelbox. one good part is that i can personalize my own hotkeys for each object, which can adapt an individual's annotation habit.\n\n**3 annotation speed for 30 frames.**\n\nthe data set is 30images. using bonding boxes. 2 annotation objects (hand and drink)\n\n&amp;#x200b;\n\n||uploading time time|labeling time|clicks per frame|\n|:-|:-|:-|:-|\n|dlabel|2 min|9 min|7 clicks|\n|labelbox|2 min|12min 10 sec|7 clicks|\n|supervisly|4 min|12min 30 sec|9 clicks|\n\n&amp;#x200b;\n\n**4 layout of the annotation page** \n\n    dlabel \n    \n\n&amp;#x200b;\n\nhttps://preview.redd.it/et1osbo68tv51.png?width=1367&amp;format=png&amp;auto=webp&amp;s=77419947a904a3667c88e50289f1188f515ca7a7\n\nyou have the features at the left, the statues in the right and the image in the centre. \n\none the left side, there is one \u201cgroup\u201d feature which i found is very useful. it adds interaction between objects. like you set the \u201ctomato\u201d and the \u201chand\u201d into one group which indicates they have interactions. the hand is picking the tomato. \n\nthere is a history column on the right where you can also trace the annotation history on the right. \n\non the bottom of the centre, there\u2019s one qa bar which can come in hand when doing quality control. \n\n**labelbox** \n\n&amp;#x200b;\n\nhttps://preview.redd.it/rbk5mpq88tv51.png?width=1374&amp;format=png&amp;auto=webp&amp;s=fae5a6bef8937d97bc3a2bf2799d3f1737ac9ab5\n\ni personally find the layout too simple. there are not many features. so there is nothing much to say. \n\n**spervisely** \n\n&amp;#x200b;\n\nhttps://preview.redd.it/37mewkw98tv51.png?width=1425&amp;format=png&amp;auto=webp&amp;s=3e45d7332340a1531b288b72f5650b299aac6865\n\nthe right side features are bit confusing...\n\ni didn't quite understand what are\"image properties\" and \"objects properties\". \n\nit shows the annotation history which labelbox doesn't have hotkeys easily  .", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jjl6ao/image_annotation_tools_comparison/',)", "identifyer": 5751942, "year": "2020"}, {"autor": "hiphop1987", "date": 1607091105000, "content": "What advice do I give to aspiring Data Scientists /!/ I get many messages asking for advice from aspiring Data Scientists. I am no expert in career advising so take everything that I write with a grain of salt. \n\nI give advice based on my observations of the field and the experience that I\u2019ve developed over the years. This is me, advising younger me as I had similar questions at the start of my career.\n\nLet me know if you agree with my views.\n\n# What is the best way to learn and practice Data Science?\n\nMy advice would be to start with practical projects and then slowly progress with theory. [Kaggle notebooks](https://www.kaggle.com/notebooks) are a great way to learn the practical part.\n\nAsk questions in [Reddit communities](https://www.reddit.com/r/MLQuestions/) or in [Cross Validated community](https://stats.stackexchange.com/).\n\nWhen you become satisfied with your knowledge of tools and practices, I would suggest you construct the dataset for some problem by yourself (eg. you can scrape the data) and apply ML algorithms to it. The hardest thing in ML is dataset construction. You might even build a company out of it.\n\n# What are good resources to learn Machine Learning?\n\nI suggest you start with free resources as there are many of them available for Programming, Machine Learning and Data Science:\n\n* [7 Free Programming Books for Data Scientists](https://towardsdatascience.com/7-free-programming-books-every-data-scientist-should-read-in-2020-608c00d7cf3c?sk=b3eddcdf380d0d3e979adbe31bb486de)\n* [7 Free eBooks for Data Scientists](https://towardsdatascience.com/7-free-ebooks-every-data-scientist-should-read-in-2020-32508ad704b7?sk=e604e2515557af9614cdbc2961fd8db8)\n* [7 FREE Artificial Intelligence Courses from the Ivy League Universities](https://towardsdatascience.com/top-7-free-artificial-intelligence-courses-from-the-ivy-league-universities-7c951f787a55?sk=e7c190b81e72e84442e21fff3c42e608)\n\nI personally like the [Machine Learning](https://www.coursera.org/learn/machine-learning) Coursera course by Andrew Ng. The course starts easy and then gradually gets harder as it goes. The good thing about it is that it focuses on the fundamentals of Machine Learning.\n\nI suggest that you listen to at least the first few lectures. Don\u2019t worry if you don\u2019t understand everything, you can always revisit it later. I would also advise that you don\u2019t focus just on a single course. We all learn differently and that\u2019s ok.\n\n# I hardly have any technical background. What do you think would be the best approach to learn?\n\nYou can start practicing Machine Learning in Excel. Try to implement a [Linear Regression in Excel](https://www.ablebits.com/office-addins-blog/2018/08/01/linear-regression-analysis-excel/). It is a great first challenge and it will get you motivated.\n\n# Should I learn Python or R?\n\nLet\u2019s address the elephant in the room. If you\u2019re just starting I would suggest learning Python. The main reasons are:\n\n* rich ecosystem for Data Science, Backend\u2026 you name it, Python has it.\n* the language is still gaining momentum in popularity.\n\nWith Python, you can do the analysis, develop the model from scratch and then run it in production. While I am sure that models in R also run in production, I haven\u2019t heard about one (let me know in the comments if your experience is different).\n\nDon\u2019t get me wrong, if you know R, that\u2019s totally fine. Data Science teams are usually using both languages as some prefer R and others Python.\n\nIn the end, it doesn\u2019t really matter as some models have to be reimplemented in a compiled language (Java, Go) to make faster predictions in production.\n\n# Should I learn SQL?\n\nThis is a great question. The answer is YES \u2014 with capital letters.\n\nWhether you\u2019ll be using the SQL databases or not, you should know the main concepts from relational databases like **joins**, **group by, window functions, lag, lead, etc.** These concepts are essential even when working with pandas, R or some other tool.\n\n# Do I need a Ph.D. to work in Data Science?\n\nYou don\u2019t need a Ph.D. to work in Data Science \u2014 meaning doing analysis of real-world data, applying the Machine Learning models.\n\nIf your goal is doing research and developing new Machine Learning algorithms (eg. working in Deep Mind) then you should pursue a Ph.D.\n\nIn case you're interested, I wrote a longer article about this topic: [You Don\u2019t Need a Ph.D. in Data Science, but](https://towardsdatascience.com/you-dont-need-a-ph-d-in-data-science-but-aef232436315?sk=646d99d0188b4617f79f5e140b6e67df)\n\n#", "link": "https://www.reddit.com/r/learnmachinelearning/comments/k6ll3r/what_advice_do_i_give_to_aspiring_data_scientists/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "what advice do i give to aspiring data scientists /!/ i get many messages asking for advice from aspiring data scientists. i am no expert in career advising so take everything that i write with a grain of salt. \n\ni give advice based on my observations of the field and the experience that i\u2019ve developed over the years. this is me, advising younger me as i had similar questions at the start of my career.\n\nlet me know if you agree with my views.\n\n# what is the best way to learn and practice data science?\n\nmy advice would be to start with practical projects and then slowly progress with theory. [kaggle notebooks](https://www.kaggle.com/notebooks) are a great way to learn the practical part.\n\nask questions in [reddit communities](https://www.reddit.com/r/mlquestions/) or in [cross validated community](https://stats.stackexchange.com/).\n\nwhen you become satisfied with your knowledge of tools and practices, i would suggest you construct the dataset for some problem by yourself (eg. you can scrape the data) and apply ml algorithms to it. the hardest thing in ml is dataset construction. you might even build a company out of it.\n\n# what are good resources to learn machine learning?\n\ni suggest you start with free resources as there are many of them available for programming, machine learning and data science:\n\n* [7 free programming books for data scientists](https://towardsdatascience.com/7-free-programming-books-every-data-scientist-should-read-in-2020-608c00d7cf3c?sk=b3eddcdf380d0d3e979adbe31bb486de)\n* [7 free ebooks for data scientists](https://towardsdatascience.com/7-free-ebooks-every-data-scientist-should-read-in-2020-32508ad704b7?sk=e604e2515557af9614cdbc2961fd8db8)\n* [7 free artificial intelligence courses from the ivy league universities](https://towardsdatascience.com/top-7-free-artificial-intelligence-courses-from-the-ivy-league-universities-7c951f787a55?sk=e7c190b81e72e84442e21fff3c42e608)\n\ni personally like the [machine learning](https://www.coursera.org/learn/machine-learning) coursera course by andrew ng. the course starts easy and then gradually gets harder as it goes. the good thing about it is that it focuses on the fundamentals of machine learning.\n\ni suggest that you listen to at least the first few lectures. don\u2019t worry if you don\u2019t understand everything, you can always revisit it later. i would also advise that you don\u2019t focus just on a single course. we all learn differently and that\u2019s ok.\n\n# i hardly have any technical background. what do you think would be the best approach to learn?\n\nyou can start practicing machine learning in excel. try to implement a [linear regression in excel](https://www.ablebits.com/office-addins-blog/2018/08/01/linear-regression-analysis-excel/). it is a great first challenge and it will get you motivated.\n\n# should i learn python or r?\n\nlet\u2019s address the elephant in the room. if you\u2019re just starting i would suggest learning python. the main reasons are:\n\n* rich ecosystem for data science, backend\u2026 you name it, python has it.\n* the language is still gaining momentum in popularity.\n\nwith python, you can do the analysis, develop the model from scratch and then run it in production. while i am sure that models in r also run in production, i haven\u2019t heard about one (let me know in the comments if your experience is different).\n\ndon\u2019t get me wrong, if you know r, that\u2019s totally fine. data science teams are usually using both languages as some prefer r and others python.\n\nin the end, it doesn\u2019t really matter as some models have to be reimplemented in a compiled language (java, go) to make faster predictions in production.\n\n# should i learn sql?\n\nthis is a great question. the answer is yes \u2014 with capital letters.\n\nwhether you\u2019ll be using the sql databases or not, you should know the main concepts from relational databases like **joins**, **group by, window functions, lag, lead, etc.** these concepts are essential even when working with pandas, r or some other -----> tool !!! .\n\n# do i need a ph.d. to work in data science?\n\nyou don\u2019t need a ph.d. to work in data science \u2014 meaning doing analysis of real-world data, applying the machine learning models.\n\nif your goal is doing research and developing new machine learning algorithms (eg. working in deep mind) then you should pursue a ph.d.\n\nin case you're interested, i wrote a longer article about this topic: [you don\u2019t need a ph.d. in data science, but](https://towardsdatascience.com/you-dont-need-a-ph-d-in-data-science-but-aef232436315?sk=646d99d0188b4617f79f5e140b6e67df)\n\n#", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/k6ll3r/what_advice_do_i_give_to_aspiring_data_scientists/',)", "identifyer": 5752173, "year": "2020"}, {"autor": "arturmame", "date": 1607913876000, "content": "Favorite model visualization tool? /!/ Hi! I've been looking through ways of getting some insights into my model. I used to just do all of the plots myself and save them into txt files, but I tried out CycleGAN and they used Visdom and it was just beautiful. I also see Weights and Biases promoted by Two Minute Papers a lot, which looks pretty too and I've seen Tensorboard introduced in one of my textbooks. Do you guys use visualization software? If so, which one is your favorite?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/kcout1/favorite_model_visualization_tool/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "favorite model visualization -----> tool !!! ? /!/ hi! i've been looking through ways of getting some insights into my model. i used to just do all of the plots myself and save them into txt files, but i tried out cyclegan and they used visdom and it was just beautiful. i also see weights and biases promoted by two minute papers a lot, which looks pretty too and i've seen tensorboard introduced in one of my textbooks. do you guys use visualization software? if so, which one is your favorite?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/kcout1/favorite_model_visualization_tool/',)", "identifyer": 5752302, "year": "2020"}, {"autor": "invertedmatrix", "date": 1600104748000, "content": "Input features in Tensorflow Playground /!/ Hello everyone, I recently got started with [Tensorflow Playground](https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.16352&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false), to see what goes on behind the hidden layers in neural networks when solving problems. I know that the input features X1 and X2 are supposed to represent the X and Y coordinates of the data points in the figure and that the positive class is represented by 1 whereas the negative class is represented by -1.\n\nI attached [this](https://imgur.com/HBjwJ2F) screenshot of the tool to help me formulate my problem. In the red box are highlighted X1 and X2. What I don't understand is why is X1 shown as a box with and orange region on the left hand side and blue region on the right? Similiarly, Why is the top half of X2 blue and bottom half orange? What are these regions supposed to represent in the input features? I will be grateful for a simple explanation. Thank you!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ispn6l/input_features_in_tensorflow_playground/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "input features in tensorflow playground /!/ hello everyone, i recently got started with [tensorflow playground](https://playground.tensorflow.org/#activation=tanh&amp;batchsize=10&amp;dataset=circle&amp;regdataset=reg-plane&amp;learningrate=0.03&amp;regularizationrate=0&amp;noise=0&amp;networkshape=4,2&amp;seed=0.16352&amp;showtestdata=false&amp;discretize=false&amp;perctraindata=50&amp;x=true&amp;y=true&amp;xtimesy=false&amp;xsquared=false&amp;ysquared=false&amp;cosx=false&amp;sinx=false&amp;cosy=false&amp;siny=false&amp;collectstats=false&amp;problem=classification&amp;initzero=false&amp;hidetext=false), to see what goes on behind the hidden layers in neural networks when solving problems. i know that the input features x1 and x2 are supposed to represent the x and y coordinates of the data points in the figure and that the positive class is represented by 1 whereas the negative class is represented by -1.\n\ni attached [this](https://imgur.com/hbjwj2f) screenshot of the -----> tool !!!  to help me formulate my problem. in the red box are highlighted x1 and x2. what i don't understand is why is x1 shown as a box with and orange region on the left hand side and blue region on the right? similiarly, why is the top half of x2 blue and bottom half orange? what are these regions supposed to represent in the input features? i will be grateful for a simple explanation. thank you!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/ispn6l/input_features_in_tensorflow_playground/',)", "identifyer": 5752462, "year": "2020"}, {"autor": "NoreOxford", "date": 1592611311000, "content": "Does gradient descent minimise RSS or your chosen loss function? /!/ I had always assumed your optimiser, for example gradient descent, minimised your chosen loss function, for example RMSE. However, I was watching a lecture on coursera about regression and the lecturer was discussing gradient descent and mentioned it uses the derivative of  residual sum of squares (RSS) to update weights and then she discussed RMSE as the loss function to calculate training loss afterwards.\n\n&amp;#x200B;\n\nDoes each kind of optimisation algorithm (GD, SGD, Adam, etc) use a fixed error function like RSS while training? And if so, is the chosen loss function, ie the one you set loss equal to, just a tool for evaluation that doesn't actually change how training is performed?\n\n&amp;#x200B;\n\nTo ask this question in a different way, if I'm creating a deep learning model and choose say gradient descent or SGD as the optimiser, what exactly is changing when I keep the optimiser fixed but change the loss function? Is the chosen loss function, for instance RMSE, used to calculate the errors that are backpropogated through the model to update weights but the gradient descent algorithm is still using the derivative of RSS to update weights in the forward propagation? Is that how it works? Or is the RMSE loss calculation just a metric that doesn't affect training? In other words, is it just used for plotting the learning curve in order to make decisions on how to modify training? Or alternatively, is the gradient descent algorithm taking the gradient of the chosen loss function, RMSE in this example, and not RSS to update weights the whole time?\n\n&amp;#x200B;\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hcbw0s/does_gradient_descent_minimise_rss_or_your_chosen/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "does gradient descent minimise rss or your chosen loss function? /!/ i had always assumed your optimiser, for example gradient descent, minimised your chosen loss function, for example rmse. however, i was watching a lecture on coursera about regression and the lecturer was discussing gradient descent and mentioned it uses the derivative of  residual sum of squares (rss) to update weights and then she discussed rmse as the loss function to calculate training loss afterwards.\n\n&amp;#x200b;\n\ndoes each kind of optimisation algorithm (gd, sgd, adam, etc) use a fixed error function like rss while training? and if so, is the chosen loss function, ie the one you set loss equal to, just a -----> tool !!!  for evaluation that doesn't actually change how training is performed?\n\n&amp;#x200b;\n\nto ask this question in a different way, if i'm creating a deep learning model and choose say gradient descent or sgd as the optimiser, what exactly is changing when i keep the optimiser fixed but change the loss function? is the chosen loss function, for instance rmse, used to calculate the errors that are backpropogated through the model to update weights but the gradient descent algorithm is still using the derivative of rss to update weights in the forward propagation? is that how it works? or is the rmse loss calculation just a metric that doesn't affect training? in other words, is it just used for plotting the learning curve in order to make decisions on how to modify training? or alternatively, is the gradient descent algorithm taking the gradient of the chosen loss function, rmse in this example, and not rss to update weights the whole time?\n\n&amp;#x200b;\n\nthanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 6, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hcbw0s/does_gradient_descent_minimise_rss_or_your_chosen/',)", "identifyer": 5752695, "year": "2020"}, {"autor": "tim-hilt", "date": 1592830122000, "content": "Search spoken phrase in Video /!/ I'm a CS-Student and because of the current situation most of our lectures are delivered via Video-conferencing. This has the advantage, that i'm able to record all lectures and review them if i'm stuck somewhere in the learning-process.\n\nSometimes the question arises, that i know that my professor talked about something/ said a particular phrase and i would really want to know in which lecture at what timestamp the wanted sentence was spoken.\n\nWhat i'm searching for is some NLP-tool, that has a similar functionality as `grep` or comparable utilities, where i can input content (a video- or audio-track) and a search-string and the tool tells me in what file at what timestamp the sentence was spoken.\n\nIs there a tool already that can do that? I'm german-speaking, if this is relevant. Would such a tool be something worth building or are there better approaches?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hdrqta/search_spoken_phrase_in_video/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "search spoken phrase in video /!/ i'm a cs-student and because of the current situation most of our lectures are delivered via video-conferencing. this has the advantage, that i'm able to record all lectures and review them if i'm stuck somewhere in the learning-process.\n\nsometimes the question arises, that i know that my professor talked about something/ said a particular phrase and i would really want to know in which lecture at what timestamp the wanted sentence was spoken.\n\nwhat i'm searching for is some nlp------> tool !!! , that has a similar functionality as `grep` or comparable utilities, where i can input content (a video- or audio-track) and a search-string and the -----> tool !!!  tells me in what file at what timestamp the sentence was spoken.\n\nis there a tool already that can do that? i'm german-speaking, if this is relevant. would such a tool be something worth building or are there better approaches?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/hdrqta/search_spoken_phrase_in_video/',)", "identifyer": 5752823, "year": "2020"}, {"autor": "aicoding", "date": 1592804821000, "content": "Check out this automation tool built in Python and Selenium to automatically apply for jobs on LinkedIn using the easy apply function.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hdmbq1/check_out_this_automation_tool_built_in_python/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "check out this automation -----> tool !!!  built in python and selenium to automatically apply for jobs on linkedin using the easy apply function.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 8, "media": "('hosted:video',)", "medialink": "('https://v.redd.it/ivg4e4rvge651',)", "identifyer": 5752833, "year": "2020"}, {"autor": "aicoding", "date": 1592804432000, "content": "Check out this automation tool built in Python and Selenium to automatically apply for jobs on LinkedIn using the easy apply function.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hdm8lg/check_out_this_automation_tool_built_in_python/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "check out this automation -----> tool !!!  built in python and selenium to automatically apply for jobs on linkedin using the easy apply function.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://v.redd.it/lombcarqfe651',)", "identifyer": 5752834, "year": "2020"}, {"autor": "aicoding", "date": 1592804100000, "content": "Check out this automation tool built in Python and Selenium to automatically apply for jobs on LinkedIn using the easy apply function.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hdm5u5/check_out_this_automation_tool_built_in_python/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "check out this automation -----> tool !!!  built in python and selenium to automatically apply for jobs on linkedin using the easy apply function.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://v.redd.it/4sliuztree651',)", "identifyer": 5752835, "year": "2020"}, {"autor": "aicoding", "date": 1592803986000, "content": "Check out this automation tool built in Python and Selenium to automatically apply for jobs on LinkedIn using the easy apply function. Playlist tutorial: https://www.youtube.com/watch?v=6plKL95a134&amp;list=PLNpKaH98va-EbBrOvqpiSoJB_ghWb5O1n", "link": "https://www.reddit.com/r/learnmachinelearning/comments/hdm4vl/check_out_this_automation_tool_built_in_python/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "check out this automation -----> tool !!!  built in python and selenium to automatically apply for jobs on linkedin using the easy apply function. playlist tutorial: https://www.youtube.com/watch?v=6plkl95a134&amp;list=plnpkah98va-ebbrovqpisojb_ghwb5o1n", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://v.redd.it/z7kcbmh5ee651',)", "identifyer": 5752837, "year": "2020"}, {"autor": "Manaphy91", "date": 1592057158000, "content": "Doubts about classification problem on unbalanced dataset /!/ Hi everyone,\n\nI'm a computer science student and for a ML course I have to provide a paper about the analysis performed on a dataset of my choice. It should consists in a dataset overview, data preprocessing, feature selections, classification models training and learners comparison.\n\nI chose a Taxi trips dataset and the task I would like to accomplish consists in classifing a taxi trip as eligible or not for a tip, given some attributes as input.\n\nTwo of these attributes are start and end date. In order to make them more meaningful then they are, I read online that it is better to handle them as cyclic features. Thus I extracted the day of week, hours, minutes and seconds and apply sin and cos function to them in order to obtain the trigonometric coordinates of each value. I.e. for the day of week, I used the following the formula: sin(2\\*pi\\*day\\_of\\_week/7).\n\nHere my doubt about the feature selection phase: how could I perform a feature selection assuring that sin and cos transformation for the same attribute like day\\_of\\_week\\_sin and day\\_of\\_week\\_cos will be taken or excluded together from the feature selection pahse? I personally retain meaningless a feature selection result that bring me to select just one of the couple of coordinates of the same feature, i.e. day\\_of\\_week\\_sin and not day\\_of\\_week\\_cos. Is it right or it has to be considered as a feasible and meaningful selection result one that take the sin and not the cos or vice versa?\n\nRegarding the dataset, after playing with it, removing records with missing attributes and so on, I became aware that it is too much unbalanced. On about 7.000.000 records, just the 10% are records having n as value  for the tip attribute, the remaining part consists of record having y for that attribute.\n\nLooking for possible solutions to the unbalanced problem, I found out at [this page](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html) a solution titled \"Ensemble different resampled datasets\" that I would like to implement, it consists in:\n\n* splitting the training portion of the dataset in different sets made by one constant part of records belonging to the positve class (records with n as tip value) and one part containing records having y as tip value\n* obtaining a classification model from each set and then use the voting system to classify each record and obtain the confusion matrix.\n\nIs this method working? What about if after partitioning the training portion I use the cross validation before get the performance metrics at the end of the training phase? Will it bring to such a wrong/influenced or overfitting prone training dataset?\n\nRegarding the above method to handle the unbalanced dataset, I am not sure if I need to execute the feature selection on each partition or just on one partition and apply it to each classifier obtained from a partition.\n\nLast but not least, the suggested tool to use is Knime. It seems working well on not big partition of the original dataset but have bad performances and goes quickly to the heap overflow with the entire dataset using classifiers like Weka RandomForest. Dow you have any trick to suggest me about how to use this tool? What I should do and what I shouldn't?\n\nThanks for reading and have a good weekend.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/h885q8/doubts_about_classification_problem_on_unbalanced/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "doubts about classification problem on unbalanced dataset /!/ hi everyone,\n\ni'm a computer science student and for a ml course i have to provide a paper about the analysis performed on a dataset of my choice. it should consists in a dataset overview, data preprocessing, feature selections, classification models training and learners comparison.\n\ni chose a taxi trips dataset and the task i would like to accomplish consists in classifing a taxi trip as eligible or not for a tip, given some attributes as input.\n\ntwo of these attributes are start and end date. in order to make them more meaningful then they are, i read online that it is better to handle them as cyclic features. thus i extracted the day of week, hours, minutes and seconds and apply sin and cos function to them in order to obtain the trigonometric coordinates of each value. i.e. for the day of week, i used the following the formula: sin(2\\*pi\\*day\\_of\\_week/7).\n\nhere my doubt about the feature selection phase: how could i perform a feature selection assuring that sin and cos transformation for the same attribute like day\\_of\\_week\\_sin and day\\_of\\_week\\_cos will be taken or excluded together from the feature selection pahse? i personally retain meaningless a feature selection result that bring me to select just one of the couple of coordinates of the same feature, i.e. day\\_of\\_week\\_sin and not day\\_of\\_week\\_cos. is it right or it has to be considered as a feasible and meaningful selection result one that take the sin and not the cos or vice versa?\n\nregarding the dataset, after playing with it, removing records with missing attributes and so on, i became aware that it is too much unbalanced. on about 7.000.000 records, just the 10% are records having n as value  for the tip attribute, the remaining part consists of record having y for that attribute.\n\nlooking for possible solutions to the unbalanced problem, i found out at [this page](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html) a solution titled \"ensemble different resampled datasets\" that i would like to implement, it consists in:\n\n* splitting the training portion of the dataset in different sets made by one constant part of records belonging to the positve class (records with n as tip value) and one part containing records having y as tip value\n* obtaining a classification model from each set and then use the voting system to classify each record and obtain the confusion matrix.\n\nis this method working? what about if after partitioning the training portion i use the cross validation before get the performance metrics at the end of the training phase? will it bring to such a wrong/influenced or overfitting prone training dataset?\n\nregarding the above method to handle the unbalanced dataset, i am not sure if i need to execute the feature selection on each partition or just on one partition and apply it to each classifier obtained from a partition.\n\nlast but not least, the suggested -----> tool !!!  to use is knime. it seems working well on not big partition of the original dataset but have bad performances and goes quickly to the heap overflow with the entire dataset using classifiers like weka randomforest. dow you have any trick to suggest me about how to use this tool? what i should do and what i shouldn't?\n\nthanks for reading and have a good weekend.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/h885q8/doubts_about_classification_problem_on_unbalanced/',)", "identifyer": 5752866, "year": "2020"}, {"autor": "dfnathan6", "date": 1592035349000, "content": "Industry use case (tl:dr) /!/ Hello All,\n\n&amp;#x200B;\n\nI am fairly new to machine learning and have a complex business problem. Just started to talk to lot of big vendors who provide ML/AI services. Posting here to know if I am looking at it from the right lens.   \n\n\nProblem : I get a lot of pdfs and word documents from Business vendors which consist of some rates and specifications.  There are  more than 100 Business vendors who have their own sales reps and they put down the Product rates and specifications as per their own requirements.  Example \" The R**ide** is capped at $100\" Where as a Business vendor might say. \" $100 for a single **Ride**\"  In this case \"**RIDE**\" is like a *label*\n\n  \nWe have a team (lets call them data entry) who receives this document from the Business Vendor (sales reps).  We have a system where we maintain \"*Labels*\" on **forms**.  A particular product docment typically has information which has label in large numbers.  Our data entry team (humans), then look at these documents and know which labels to fill out as per the document. So our system form has *label* \"**Ride**\", DE team will fill ***$100*** against it. This information which is fed to the system is used later on for various purposes. \n\nWe in general receive more than 100 product documents in a month. Each document to manually go through and search for appropriate label takes a lot of time. \n\nI did try some OCR tools but the problem is that the documents received from various Business vendors (sales reps) are constructed differently. So even if OCR is done I get the raw text data which I cannot feed into the system as the original document is not standard.    \n\n\nI am looking for a tool which will do OCR (text extraction) and then make a correlation of *labels* and *answers.*\n\n&amp;#x200B;\n\nWhere do I start. I have used amazon textract, google vision, Azure. All of these extract text but how do I make sense out of the documents? Am I looking at the right solutions?   \n\n\nthank you.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/h83ax2/industry_use_case_tldr/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "industry use case (tl:dr) /!/ hello all,\n\n&amp;#x200b;\n\ni am fairly new to machine learning and have a complex business problem. just started to talk to lot of big vendors who provide ml/ai services. posting here to know if i am looking at it from the right lens.   \n\n\nproblem : i get a lot of pdfs and word documents from business vendors which consist of some rates and specifications.  there are  more than 100 business vendors who have their own sales reps and they put down the product rates and specifications as per their own requirements.  example \" the r**ide** is capped at $100\" where as a business vendor might say. \" $100 for a single **ride**\"  in this case \"**ride**\" is like a *label*\n\n  \nwe have a team (lets call them data entry) who receives this document from the business vendor (sales reps).  we have a system where we maintain \"*labels*\" on **forms**.  a particular product docment typically has information which has label in large numbers.  our data entry team (humans), then look at these documents and know which labels to fill out as per the document. so our system form has *label* \"**ride**\", de team will fill ***$100*** against it. this information which is fed to the system is used later on for various purposes. \n\nwe in general receive more than 100 product documents in a month. each document to manually go through and search for appropriate label takes a lot of time. \n\ni did try some ocr tools but the problem is that the documents received from various business vendors (sales reps) are constructed differently. so even if ocr is done i get the raw text data which i cannot feed into the system as the original document is not standard.    \n\n\ni am looking for a -----> tool !!!  which will do ocr (text extraction) and then make a correlation of *labels* and *answers.*\n\n&amp;#x200b;\n\nwhere do i start. i have used amazon textract, google vision, azure. all of these extract text but how do i make sense out of the documents? am i looking at the right solutions?   \n\n\nthank you.", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/h83ax2/industry_use_case_tldr/',)", "identifyer": 5752879, "year": "2020"}, {"autor": "mrnerdy59", "date": 1592244529000, "content": "Need help with developing a image segmentation tool /!/ Hi Guys\n\nI'm planning to work on image segmentation tool, that can identify different objects in a image using an unsupervised manner. To show an example, looking to work on something like this:  [https://segments.ai/](https://segments.ai/) \n\nIf anyone has worked on something similar, please guide. I'm looking for \"basics\" as I want to do this without any pre-trained model, where should I start, what should I look at, any videos or links, please drop here.\n\nThanks", "link": "https://www.reddit.com/r/learnmachinelearning/comments/h9ligf/need_help_with_developing_a_image_segmentation/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "need help with developing a image segmentation -----> tool !!!  /!/ hi guys\n\ni'm planning to work on image segmentation tool, that can identify different objects in a image using an unsupervised manner. to show an example, looking to work on something like this:  [https://segments.ai/](https://segments.ai/) \n\nif anyone has worked on something similar, please guide. i'm looking for \"basics\" as i want to do this without any pre-trained model, where should i start, what should i look at, any videos or links, please drop here.\n\nthanks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/h9ligf/need_help_with_developing_a_image_segmentation/',)", "identifyer": 5752993, "year": "2020"}, {"autor": "kamran7143", "date": 1596771066000, "content": "What does a ML engineer do? /!/ So I\u2019ve been learning python for a while now and came to a realization that I HATE coding software. For example making games or programs where code needs to be efficiently made so everyone can use and all that. Instead I enjoy using python libraries to get results and as a tool for classifications or so. I was just wondering if a career would be more of developing software or using keras tensorflow scikit and all that to analyze data. It\u2019s very interesting to learn about different algorithms and how they work and their applications irl.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/i56i57/what_does_a_ml_engineer_do/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "what does a ml engineer do? /!/ so i\u2019ve been learning python for a while now and came to a realization that i hate coding software. for example making games or programs where code needs to be efficiently made so everyone can use and all that. instead i enjoy using python libraries to get results and as a -----> tool !!!  for classifications or so. i was just wondering if a career would be more of developing software or using keras tensorflow scikit and all that to analyze data. it\u2019s very interesting to learn about different algorithms and how they work and their applications irl.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/i56i57/what_does_a_ml_engineer_do/',)", "identifyer": 5753108, "year": "2020"}, {"autor": "Gravfity", "date": 1608584772000, "content": "ML pipeline interface /!/ Is there any tool that would present a bird\u2019s eye view of the processes being ran? For example, the feature set used, model training progress, error etc I know one could always view these in the individual process log in the terminal, but what about a more tractable interface for multiple processes running simultaneously?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/khq8al/ml_pipeline_interface/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "ml pipeline interface /!/ is there any -----> tool !!!  that would present a bird\u2019s eye view of the processes being ran? for example, the feature set used, model training progress, error etc i know one could always view these in the individual process log in the terminal, but what about a more tractable interface for multiple processes running simultaneously?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/khq8al/ml_pipeline_interface/',)", "identifyer": 5753479, "year": "2020"}, {"autor": "Neuromaster", "date": 1608572002000, "content": "Combat log analysis - ML right tool for the job? /!/ The MMO World of Warcraft can produce \"combat logs\" that look something like this:\n\n    00:00:01.625\tThrasta Melee Maexxna 197\n    00:00:02.598\tThrasta Sunder Armor Maexxna Parry\n    00:00:03.786\tDromar Melee Maexxna Parry\n    00:00:04.083\tThrasta Melee Maexxna 171 (B: 46)\n    00:00:04.083\tDromar Melee Maexxna *473*\n    00:00:04.885\tBrutalitox Melee Maexxna *780*\n    00:00:04.885\tFiggs Melee Maexxna 117 Glancing\n    00:00:04.886\tFiggs Melee Maexxna Miss\n    00:00:05.290\tFiggs Melee Maexxna 202 Glancing\n    00:00:05.690\tThrasta Bloodthirst Maexxna 414\n    00:00:06.090\tThrasta Melee Maexxna 196 Glancing\n\t\nA large number of combat logs are available at [Warcraft Logs](https://www.warcraftlogs.com/), with an available [API](https://www.warcraftlogs.com/api/docs) presumably suitable for automation.\n\nUsing some subset of this training data, I'd like to produce a model capable of processing a real-time stream of combat log data. At any point during a fight, I'd like to predict the time remaining in the fight, whether it's more likely to end in a kill (success) or a wipe (failure), and the model's degree of confidence in that prediction.\n\nA \"holy grail\" for me would be to compile that model into LUA suitable for packaging into an in-game addon, but if I were to undertake this project I'd certainly begin with a more modest proof-of-concept prototype.\n\nI feel like ML has decent potential to solve this problem but although I'm a software engineer by trade, ML isn't something I've touched since undergrad. I'm not about to ask Reddit to build this thing for me, but I could use help figuring out whether this is a feasible/appropriate problem for ML to solve, what tools/frameworks to investigate, peripherally-relatated projects I could read up on, etc. Even getting the vocabulary right is challenging, which makes research difficult.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/khlx2u/combat_log_analysis_ml_right_tool_for_the_job/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "combat log analysis - ml right -----> tool !!!  for the job? /!/ the mmo world of warcraft can produce \"combat logs\" that look something like this:\n\n    00:00:01.625\tthrasta melee maexxna 197\n    00:00:02.598\tthrasta sunder armor maexxna parry\n    00:00:03.786\tdromar melee maexxna parry\n    00:00:04.083\tthrasta melee maexxna 171 (b: 46)\n    00:00:04.083\tdromar melee maexxna *473*\n    00:00:04.885\tbrutalitox melee maexxna *780*\n    00:00:04.885\tfiggs melee maexxna 117 glancing\n    00:00:04.886\tfiggs melee maexxna miss\n    00:00:05.290\tfiggs melee maexxna 202 glancing\n    00:00:05.690\tthrasta bloodthirst maexxna 414\n    00:00:06.090\tthrasta melee maexxna 196 glancing\n\t\na large number of combat logs are available at [warcraft logs](https://www.warcraftlogs.com/), with an available [api](https://www.warcraftlogs.com/api/docs) presumably suitable for automation.\n\nusing some subset of this training data, i'd like to produce a model capable of processing a real-time stream of combat log data. at any point during a fight, i'd like to predict the time remaining in the fight, whether it's more likely to end in a kill (success) or a wipe (failure), and the model's degree of confidence in that prediction.\n\na \"holy grail\" for me would be to compile that model into lua suitable for packaging into an in-game addon, but if i were to undertake this project i'd certainly begin with a more modest proof-of-concept prototype.\n\ni feel like ml has decent potential to solve this problem but although i'm a software engineer by trade, ml isn't something i've touched since undergrad. i'm not about to ask reddit to build this thing for me, but i could use help figuring out whether this is a feasible/appropriate problem for ml to solve, what tools/frameworks to investigate, peripherally-relatated projects i could read up on, etc. even getting the vocabulary right is challenging, which makes research difficult.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/khlx2u/combat_log_analysis_ml_right_tool_for_the_job/',)", "identifyer": 5753485, "year": "2020"}, {"autor": "rahulrajpl", "date": 1591334752000, "content": "WExDA - a web based data exploration tool /!/ WExDA is a web based data exploration tool primarily useful for data  preperation/ data analysis stage. This automates the EDA via web ui and  is built using [streamlit](https://discuss.streamlit.io/)\n\nAll comments/ suggestions are welcome. Please report bugs if any. Thank in advance. \n\n\\-regards, rahul", "link": "https://www.reddit.com/r/learnmachinelearning/comments/gwyhqu/wexda_a_web_based_data_exploration_tool/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "wexda - a web based data exploration -----> tool !!!  /!/ wexda is a web based data exploration tool primarily useful for data  preperation/ data analysis stage. this automates the eda via web ui and  is built using [streamlit](https://discuss.streamlit.io/)\n\nall comments/ suggestions are welcome. please report bugs if any. thank in advance. \n\n\\-regards, rahul", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/gwyhqu/wexda_a_web_based_data_exploration_tool/',)", "identifyer": 5753633, "year": "2020"}, {"autor": "Floppy_Trombone", "date": 1588791238000, "content": "I have an idea that uses machine learning but I don't know ho doable it is. /!/ I was thinking of a program that could discern between quality of instrument tone (Or sound quality). Particularly for beginners, it would be helpful to have a tool that could rate your tone say from 1-10. As a trombone player I'd want to start with trombone tone, and if it works expand to many different instruments.\n\nI'm not a programmer and I only know basic stuff about machine learning. How doable is this?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/geq1av/i_have_an_idea_that_uses_machine_learning_but_i/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i have an idea that uses machine learning but i don't know ho doable it is. /!/ i was thinking of a program that could discern between quality of instrument tone (or sound quality). particularly for beginners, it would be helpful to have a -----> tool !!!  that could rate your tone say from 1-10. as a trombone player i'd want to start with trombone tone, and if it works expand to many different instruments.\n\ni'm not a programmer and i only know basic stuff about machine learning. how doable is this?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/geq1av/i_have_an_idea_that_uses_machine_learning_but_i/',)", "identifyer": 5753666, "year": "2020"}, {"autor": "Chillo4747", "date": 1587488820000, "content": "Creating Object Detection and Tracking Tool /!/ Hey Guys,\n\nI am pretty new into Object Detection and Tracking.\n\nI want to create a Tool, which can do following things:\n\n1. Detect Objects (not only one)\n2. Track them\n3. Create Trajectories from the Trackings\n4. Convert the Trajectories from image coordinates to real world coordinates\n5. Give me a .csv or something similar with the trajectories for each object\n\nWhat would you say is the best way to create such a tool?\n\nWhere do i start? Are there some good tutorial to begin with?\n\n&amp;#x200B;\n\nThank you!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g5j4wy/creating_object_detection_and_tracking_tool/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "creating object detection and tracking -----> tool !!!  /!/ hey guys,\n\ni am pretty new into object detection and tracking.\n\ni want to create a tool, which can do following things:\n\n1. detect objects (not only one)\n2. track them\n3. create trajectories from the trackings\n4. convert the trajectories from image coordinates to real world coordinates\n5. give me a .csv or something similar with the trajectories for each object\n\nwhat would you say is the best way to create such a tool?\n\nwhere do i start? are there some good tutorial to begin with?\n\n&amp;#x200b;\n\nthank you!", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 7, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g5j4wy/creating_object_detection_and_tracking_tool/',)", "identifyer": 5754046, "year": "2020"}, {"autor": "GiletsJaunesKiki", "date": 1587486371000, "content": "In-browser note taking tool designed for online learning /!/ Hey all- my company [Beastnotes](https://www.beastnotes.com/) built a note taking chrome extension that is designed to work with Coursera. It has the unique feature of allowing note-taking in the same browser you are watching your lecture, no longer do you have to pause and flip between browsers to take your notes and it\u2019s free to use for the first three coursebooks. I wrote an article about it [here](https://medium.com/@beastnotes/online-note-taking-without-distraction-e47a440aa890) if you want to learn more!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/g5idem/inbrowser_note_taking_tool_designed_for_online/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "in-browser note taking -----> tool !!!  designed for online learning /!/ hey all- my company [beastnotes](https://www.beastnotes.com/) built a note taking chrome extension that is designed to work with coursera. it has the unique feature of allowing note-taking in the same browser you are watching your lecture, no longer do you have to pause and flip between browsers to take your notes and it\u2019s free to use for the first three coursebooks. i wrote an article about it [here](https://medium.com/@beastnotes/online-note-taking-without-distraction-e47a440aa890) if you want to learn more!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/g5idem/inbrowser_note_taking_tool_designed_for_online/',)", "identifyer": 5754049, "year": "2020"}, {"autor": "iwanttobemayor", "date": 1605108531000, "content": "How can I approach a computer vision program as a complete beginner in the area? /!/ Hello, I am completely new to Machine Learning and Computer Vision (I ask this here because I believe they are related) but I got involved in a project that needs to detect clothing to a sensible level (for example the final thing must be able to recognize the difference between a short sleeve shirt and a normal polo).\n\nI\u2019ve been checking out many of the tutorials available online for things such as OpenCV but most of them just take an algorithm from an XML file and magically it does what they need them to do (which is usually just face detection).\n\nMy questions would be:\n\n1. How can I approach this? I know this is a bit too general but I find it overwhelming the amount of ways that there are to tackle this problem and as someone with zero experience on the field I\u2019d like some suggestions on which way should I start.\n\n2. How large should my training datasets should be for obtaining mostly accurate reasults?\n\n3. Are things such as AWS Rekognitio/any other cloud CV tool a good fit for this? I\u2019ve seen some that work but the thing is that if for some reason I don\u2019t get the result I am expecting it would be hard or impossible to tweak it because as far as I know I am just calling their API.\n\nWe still have around 6-8 months until the final deadline, so if there\u2019s anything I need to check out in depth I have the time to go through it.\n\nThanks for taking the time to read this and I would really appreciate your help!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/jsa446/how_can_i_approach_a_computer_vision_program_as_a/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "how can i approach a computer vision program as a complete beginner in the area? /!/ hello, i am completely new to machine learning and computer vision (i ask this here because i believe they are related) but i got involved in a project that needs to detect clothing to a sensible level (for example the final thing must be able to recognize the difference between a short sleeve shirt and a normal polo).\n\ni\u2019ve been checking out many of the tutorials available online for things such as opencv but most of them just take an algorithm from an xml file and magically it does what they need them to do (which is usually just face detection).\n\nmy questions would be:\n\n1. how can i approach this? i know this is a bit too general but i find it overwhelming the amount of ways that there are to tackle this problem and as someone with zero experience on the field i\u2019d like some suggestions on which way should i start.\n\n2. how large should my training datasets should be for obtaining mostly accurate reasults?\n\n3. are things such as aws rekognitio/any other cloud cv -----> tool !!!  a good fit for this? i\u2019ve seen some that work but the thing is that if for some reason i don\u2019t get the result i am expecting it would be hard or impossible to tweak it because as far as i know i am just calling their api.\n\nwe still have around 6-8 months until the final deadline, so if there\u2019s anything i need to check out in depth i have the time to go through it.\n\nthanks for taking the time to read this and i would really appreciate your help!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/jsa446/how_can_i_approach_a_computer_vision_program_as_a/',)", "identifyer": 5754128, "year": "2020"}, {"autor": "sarabella2021", "date": 1595074742000, "content": "Help with video classification /!/ So I am creating an app which would allow me to classify both hand positions and gestures. For example, the machine would classify what number I am showing based on how many fingers I hold up, and would also be able to tell the difference between someone waving and showing the number 5. I have already learned that I can analyze a video by taking the frames of the video and checking each one to see if it matches a class I have created. However, I don\u2019t know how to enable my machine to detect motion. For example, if I had a video of someone waving, my machine would classify it as the number 5 because it only checks individual frames and it can\u2019t \u201csee\u201d motion. Gestures are a big part of my app, and I can\u2019t find any articles that would point me to a tool that would aid me. Does anyone have any recommendations for a tool that allows me to analyze video for different motions with custom labels?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/htfpfu/help_with_video_classification/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "help with video classification /!/ so i am creating an app which would allow me to classify both hand positions and gestures. for example, the machine would classify what number i am showing based on how many fingers i hold up, and would also be able to tell the difference between someone waving and showing the number 5. i have already learned that i can analyze a video by taking the frames of the video and checking each one to see if it matches a class i have created. however, i don\u2019t know how to enable my machine to detect motion. for example, if i had a video of someone waving, my machine would classify it as the number 5 because it only checks individual frames and it can\u2019t \u201csee\u201d motion. gestures are a big part of my app, and i can\u2019t find any articles that would point me to a -----> tool !!!  that would aid me. does anyone have any recommendations for a tool that allows me to analyze video for different motions with custom labels?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/htfpfu/help_with_video_classification/',)", "identifyer": 5754201, "year": "2020"}, {"autor": "No_Situation_452", "date": 1599915254000, "content": "A little help /!/ so i want to train my dataset in order to predict a binary result 0 or 1. I have a dataset sample results i.e 0 and 1. I want to use this data to predict results using the new inputs from user. I know aws has a real time prediction tool but how do i do that in python.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/irc2yj/a_little_help/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "a little help /!/ so i want to train my dataset in order to predict a binary result 0 or 1. i have a dataset sample results i.e 0 and 1. i want to use this data to predict results using the new inputs from user. i know aws has a real time prediction -----> tool !!!  but how do i do that in python.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/irc2yj/a_little_help/',)", "identifyer": 5754281, "year": "2020"}, {"autor": "Seankala", "date": 1608350273000, "content": "Model's gradients are converging quickly to zero. /!/ Hi everyone. I'm running a model and am using [Weights &amp; Biases](https://www.wandb.com/) to visualize things. There's a tool in the library you can use called `wandb.watch` that visualizes the gradient histograms for you. The code that I'm testing is my own personal implementation of the Transformer architecture. You can find the code [here](github.com/seanswyi/transformer-implementation) if you're curious.\n\nI've been able to do that, but I'm not sure how I should interpret the histograms. Right now my thing looks kinda like this:\n\nhttps://preview.redd.it/26yla4vurx561.png?width=1809&amp;format=png&amp;auto=webp&amp;s=b0677ddf378fd65dd50e2148d62c6452acd51f10\n\nI'm assuming that training isn't properly taking place at all. Are there any resources out there that deal with interpreting gradient flow? I thought that a potential problem would be dying ReLU's, but changing the ReLU to leaky ReLU doesn't help.\n\nI'm a little stuck and not sure what else may be the problem, and would really appreciate any feedback.\n\nThanks.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/kg0qb6/models_gradients_are_converging_quickly_to_zero/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "model's gradients are converging quickly to zero. /!/ hi everyone. i'm running a model and am using [weights &amp; biases](https://www.wandb.com/) to visualize things. there's a -----> tool !!!  in the library you can use called `wandb.watch` that visualizes the gradient histograms for you. the code that i'm testing is my own personal implementation of the transformer architecture. you can find the code [here](github.com/seanswyi/transformer-implementation) if you're curious.\n\ni've been able to do that, but i'm not sure how i should interpret the histograms. right now my thing looks kinda like this:\n\nhttps://preview.redd.it/26yla4vurx561.png?width=1809&amp;format=png&amp;auto=webp&amp;s=b0677ddf378fd65dd50e2148d62c6452acd51f10\n\ni'm assuming that training isn't properly taking place at all. are there any resources out there that deal with interpreting gradient flow? i thought that a potential problem would be dying relu's, but changing the relu to leaky relu doesn't help.\n\ni'm a little stuck and not sure what else may be the problem, and would really appreciate any feedback.\n\nthanks.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/kg0qb6/models_gradients_are_converging_quickly_to_zero/',)", "identifyer": 5754419, "year": "2020"}, {"autor": "mathowned", "date": 1608224345000, "content": "[P] Dataset Enhancer - A free Data Augmentation tool that generates more samples for your Dataset", "link": "https://www.reddit.com/r/learnmachinelearning/comments/kf188z/p_dataset_enhancer_a_free_data_augmentation_tool/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "[p] dataset enhancer - a free data augmentation -----> tool !!!  that generates more samples for your dataset", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('/r/MachineLearning/comments/kf0wlb/p_dataset_enhancer_a_free_data_augmentation_tool/',)", "identifyer": 5754470, "year": "2020"}, {"autor": "toothfairy222", "date": 1592145838000, "content": "Beginner here , looking for an online tool to create a dataset of (image, label ) /!/  Hi ! I hope someone can help me out because at this point I dont even know what Im doing .\n\nI am working on a small Edge detection project ( I have a background in GIS ) and this is my first time working with deep learning . I am not looking to get better at it or anything I just need to get this done for school . My goal is to compare results ( canny+segmentation VS semantic segmentation ).I will be using Unet, and my understanding is that I need to train this network using an already segmented dataset , containing 512x512 tiles of (image, label) .\n\nSo far, I have a georeferenced satellite image (3bands) with its matching vector file (where I drew the edges ) , I did rasterize the vector file to get a mask.\n\nNow Im completely lost at to how to cut my image and mask to tiles and how to label them. I found some solutions online like geo-label maker that seems appropriate for me but I would like to avoid using code (because I have to learn programming from the beginning and I dont have a lot of time to invest in programming) .\n\nSo I guess my question is , is there any online tool that will help me achieve this ? or maybe a software I can download ?\n\nPlease feel free to correct anything I just said and to give any information you judge useful . Thank you for reading .", "link": "https://www.reddit.com/r/learnmachinelearning/comments/h8v1kh/beginner_here_looking_for_an_online_tool_to/", "origin": "Reddit", "suborigin": "learnmachinelearning", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "beginner here , looking for an online -----> tool !!!  to create a dataset of (image, label ) /!/  hi ! i hope someone can help me out because at this point i dont even know what im doing .\n\ni am working on a small edge detection project ( i have a background in gis ) and this is my first time working with deep learning . i am not looking to get better at it or anything i just need to get this done for school . my goal is to compare results ( canny+segmentation vs semantic segmentation ).i will be using unet, and my understanding is that i need to train this network using an already segmented dataset , containing 512x512 tiles of (image, label) .\n\nso far, i have a georeferenced satellite image (3bands) with its matching vector file (where i drew the edges ) , i did rasterize the vector file to get a mask.\n\nnow im completely lost at to how to cut my image and mask to tiles and how to label them. i found some solutions online like geo-label maker that seems appropriate for me but i would like to avoid using code (because i have to learn programming from the beginning and i dont have a lot of time to invest in programming) .\n\nso i guess my question is , is there any online tool that will help me achieve this ? or maybe a software i can download ?\n\nplease feel free to correct anything i just said and to give any information you judge useful . thank you for reading .", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/learnmachinelearning/comments/h8v1kh/beginner_here_looking_for_an_online_tool_to/',)", "identifyer": 5754493, "year": "2020"}], "name": "toollearnmachinelearning2020"}