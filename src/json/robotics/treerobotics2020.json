{"interestingcomments": [{"Unnamed: 0": 413, "autor": "Kinglens311", "date": 1593451475000, "content": "Robot Performance - our latest andyRobot work, covers live performances in China, 3 variations of robot bands, laser bots, basket bot, roboScreens, Christmas Tree decorating and more. These were all done with RobotAnimator, KUKA, and ABB robots animated synchronously.", "link": "https://www.reddit.com/r/robotics/comments/hi4703/robot_performance_our_latest_andyrobot_work/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "robot performance - our latest andyrobot work, covers live performances in china, 3 variations of robot bands, laser bots, basket bot, roboscreens, christmas -----> tree !!!  decorating and more. these were all done with robotanimator, kuka, and abb robots animated synchronously.", "sortedWord": "None", "removed": "reddit", "score": 1, "comments": 0, "media": "link", "medialink": "https://www.reddit.com/r/robotics/comments/hi3q13/robot_performance_our_latest_andyrobot_work/?utm_source=ifttt", "identifyer": 3500416, "year": "2020"}, {"Unnamed: 0": 1770, "autor": "duburcqa", "date": 1582587910000, "content": "Jiminy, a robotic simulator for control and machine learning with Python interface [Research][Project] /!/ Hi everyone!\n\nI'm doing a PhD in robotics and machine learning applied to lower-limb exoskeletons. I wanted to explore some reinforcement learning approaches a few mouths ago and I was struck by the lack of open-source fast and repeatable simulator for robotics systems. So I started to implement one on my own, and that's how I came up with **Jiminy, an extremely fast Python/C++ simulator for poly-articulated systems and compatible with openAI Gym learning framework**.\n\nI think the project is now mature enough to be shared with everyone,  even though the documentation is incomplete. **The library has been designed for fast prototyping of control algorithms and machine learning.** Thanks to OpenAI Gym interface, training a policy by reinforcement learning, monitoring the progress and visualizing the final model is no more than 5 lines on code !  It is easy to use and several examples of classical control theory and machine learning are available for cartpole, double and simple pendulums. Getting started should be a matter of minutes ! The project has a few dependencies and it is straightforward to install on Ubuntu 18.04.\n\n**Disclamer**: It does not intend to replace the famous robot simulator [Gazebo](http://gazebosim.org/) and is missing many features that Gazebo has. Jiminy does not use any collision library and can only handle a finite set of potential contact points with a ground profile. Moreover, only IMUs, Force sensors, and encoders are available. So far, no ROS interface is available, although it should not be difficult to implement one.\n\nHere is a video showing the comparison of two different control strategies for the exoskeleton Atalante I have been work on recently:\n\n![video](n0mgsolskyi41 \"Simulation using Jiminy of two different controllers for the exoskeleton Atalante\")\n\nIf you think to may be interested, please have a look to the [github repository](https://github.com/Wandercraft/jiminy/tree/master). I'm eager to hear feedbacks from you !", "link": "https://www.reddit.com/r/robotics/comments/f90nk1/jiminy_a_robotic_simulator_for_control_and/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "jiminy, a robotic simulator for control and machine learning with python interface [research][project] /!/ hi everyone!\n\ni'm doing a phd in robotics and machine learning applied to lower-limb exoskeletons. i wanted to explore some reinforcement learning approaches a few mouths ago and i was struck by the lack of open-source fast and repeatable simulator for robotics systems. so i started to implement one on my own, and that's how i came up with **jiminy, an extremely fast python/c++ simulator for poly-articulated systems and compatible with openai gym learning framework**.\n\ni think the project is now mature enough to be shared with everyone,  even though the documentation is incomplete. **the library has been designed for fast prototyping of control algorithms and machine learning.** thanks to openai gym interface, training a policy by reinforcement learning, monitoring the progress and visualizing the final model is no more than 5 lines on code !  it is easy to use and several examples of classical control theory and machine learning are available for cartpole, double and simple pendulums. getting started should be a matter of minutes ! the project has a few dependencies and it is straightforward to install on ubuntu 18.04.\n\n**disclamer**: it does not intend to replace the famous robot simulator [gazebo](http://gazebosim.org/) and is missing many features that gazebo has. jiminy does not use any collision library and can only handle a finite set of potential contact points with a ground profile. moreover, only imus, force sensors, and encoders are available. so far, no ros interface is available, although it should not be difficult to implement one.\n\nhere is a video showing the comparison of two different control strategies for the exoskeleton atalante i have been work on recently:\n\n![video](n0mgsolskyi41 \"simulation using jiminy of two different controllers for the exoskeleton atalante\")\n\nif you think to may be interested, please have a look to the [github repository](https://github.com/wandercraft/jiminy/-----> tree !!! /master). i'm eager to hear feedbacks from you !", "sortedWord": "None", "removed": null, "score": 1, "comments": 6, "media": null, "medialink": "https://www.reddit.com/r/robotics/comments/f90nk1/jiminy_a_robotic_simulator_for_control_and/", "identifyer": 3501785, "year": "2020"}, {"Unnamed: 0": 1771, "autor": "duburcqa", "date": 1582587766000, "content": "[Research] Jiminy, a robotic simulator for control and machine learning in Python /!/ Hi everyone!\n\nI'm doing a PhD in robotics and machine learning applied to lower-limb exoskeletons. I wanted to explore some reinforcement learning approaches a few mouths ago and I was struck by the lack of open-source fast and repeatable simulator for robotics systems. So I started to implement one on my own, and that's how I came up with **Jiminy, an extremely fast Python/C++ simulator for poly-articulated systems and compatible with openAI Gym learning framework**.\n\nI think the project is now mature enough to be shared with everyone,  even though the documentation is incomplete. **The library has been designed for fast prototyping of control algorithms and machine learning.** Thanks to OpenAI Gym interface, training a policy by reinforcement learning, monitoring the progress and visualizing the final model is no more than 5 lines on code !  It is easy to use and several examples of classical control theory and machine learning are available for cartpole, double and simple pendulums. Getting started should be a matter of minutes ! The project has a few dependencies and it is straightforward to install on Ubuntu 18.04.\n\n**Disclamer**: It does not intend to replace the famous robot simulator [Gazebo](http://gazebosim.org/) and is missing many features that Gazebo has. Jiminy does not use any collision library and can only handle a finite set of potential contact points with a ground profile. Moreover, only IMUs, Force sensors, and encoders are available. So far, no ROS interface is available, although it should not be difficult to implement one.\n\nHere is a video showing the comparison of two different control strategies for the exoskeleton Atalante I have been work on recently:\n\n*Processing video r8khmjeyjyi41...*\n\nIf you think to may be interested, please have a look to the [github repository](https://github.com/Wandercraft/jiminy/tree/master). I'm eager to hear feedbacks from you !", "link": "https://www.reddit.com/r/robotics/comments/f90md4/research_jiminy_a_robotic_simulator_for_control/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[research] jiminy, a robotic simulator for control and machine learning in python /!/ hi everyone!\n\ni'm doing a phd in robotics and machine learning applied to lower-limb exoskeletons. i wanted to explore some reinforcement learning approaches a few mouths ago and i was struck by the lack of open-source fast and repeatable simulator for robotics systems. so i started to implement one on my own, and that's how i came up with **jiminy, an extremely fast python/c++ simulator for poly-articulated systems and compatible with openai gym learning framework**.\n\ni think the project is now mature enough to be shared with everyone,  even though the documentation is incomplete. **the library has been designed for fast prototyping of control algorithms and machine learning.** thanks to openai gym interface, training a policy by reinforcement learning, monitoring the progress and visualizing the final model is no more than 5 lines on code !  it is easy to use and several examples of classical control theory and machine learning are available for cartpole, double and simple pendulums. getting started should be a matter of minutes ! the project has a few dependencies and it is straightforward to install on ubuntu 18.04.\n\n**disclamer**: it does not intend to replace the famous robot simulator [gazebo](http://gazebosim.org/) and is missing many features that gazebo has. jiminy does not use any collision library and can only handle a finite set of potential contact points with a ground profile. moreover, only imus, force sensors, and encoders are available. so far, no ros interface is available, although it should not be difficult to implement one.\n\nhere is a video showing the comparison of two different control strategies for the exoskeleton atalante i have been work on recently:\n\n*processing video r8khmjeyjyi41...*\n\nif you think to may be interested, please have a look to the [github repository](https://github.com/wandercraft/jiminy/-----> tree !!! /master). i'm eager to hear feedbacks from you !", "sortedWord": "None", "removed": null, "score": 1, "comments": 0, "media": null, "medialink": "https://www.reddit.com/r/robotics/comments/f90md4/research_jiminy_a_robotic_simulator_for_control/", "identifyer": 3501786, "year": "2020"}, {"Unnamed: 0": 2403, "autor": "Grassblade555", "date": 1600930799000, "content": "New Creative Robot Design, the Naminukas by Mykolas Juraitis /!/   Today I stumbled across a brilliant, innovative open source robot. Its new form factor has great potential and I hope this post can help bring it to a well-deserved spotlight within the robotics community. This project is currently competing for the Hackaday Prize 2020 by its creator Mykolas Juraitis. \n\n  The robot can climb walls, manipulate stored tools as a 4-axis robot arm, drive around, and Juraitis shows it completing a variety of bizarre tasks such as straddling tree branches, disinfecting with a UV LED, and even riding a skateboard. Juraitis is spot-on when he says in his latest Hackaday post: \"...it has the potential of becoming an industrial inspection robot, cleaning robot, kitchen helper, entertainment robot and much more.\"\n\n  I am a roboticist in the San Francisco area and I am constantly surveying emerging tech. I have no affiliation with Juraitis or his project, I was just inspired by it and I believe this idea is in just the beginning of a long and interesting family tree of future robots. It was rightly described as having \"most utility per servo robot\" by Hackaday. I am confident that this form factor will find its niche and evolve into a common-place design for functional robotic platforms. I love that it's open source and I already have gears turning in my head about how to make it better. What do you guys think of it?", "link": "https://www.reddit.com/r/robotics/comments/iyscor/new_creative_robot_design_the_naminukas_by/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "new creative robot design, the naminukas by mykolas juraitis /!/   today i stumbled across a brilliant, innovative open source robot. its new form factor has great potential and i hope this post can help bring it to a well-deserved spotlight within the robotics community. this project is currently competing for the hackaday prize 2020 by its creator mykolas juraitis. \n\n  the robot can climb walls, manipulate stored tools as a 4-axis robot arm, drive around, and juraitis shows it completing a variety of bizarre tasks such as straddling -----> tree !!!  branches, disinfecting with a uv led, and even riding a skateboard. juraitis is spot-on when he says in his latest hackaday post: \"...it has the potential of becoming an industrial inspection robot, cleaning robot, kitchen helper, entertainment robot and much more.\"\n\n  i am a roboticist in the san francisco area and i am constantly surveying emerging tech. i have no affiliation with juraitis or his project, i was just inspired by it and i believe this idea is in just the beginning of a long and interesting family tree of future robots. it was rightly described as having \"most utility per servo robot\" by hackaday. i am confident that this form factor will find its niche and evolve into a common-place design for functional robotic platforms. i love that it's open source and i already have gears turning in my head about how to make it better. what do you guys think of it?", "sortedWord": "None", "removed": null, "score": 1, "comments": 8, "media": null, "medialink": "https://www.reddit.com/r/robotics/comments/iyscor/new_creative_robot_design_the_naminukas_by/", "identifyer": 3502422, "year": "2020"}, {"Unnamed: 0": 2686, "autor": "rmigofun", "date": 1605599171000, "content": "Cute robot checks if you start the X-mas tree project and dodge your fire", "link": "https://www.reddit.com/r/robotics/comments/jvp121/cute_robot_checks_if_you_start_the_xmas_tree/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "cute robot checks if you start the x-mas -----> tree !!!  project and dodge your fire", "sortedWord": "None", "removed": null, "score": 46, "comments": 4, "media": "hosted:video", "medialink": "https://v.redd.it/4hz9ouva8rz51", "identifyer": 3502709, "year": "2020"}, {"Unnamed: 0": 3382, "autor": "braingame26", "date": 1590886866000, "content": "Part 2 - motorized \"shoes\" you wear while playing a virtual reality game /!/ [Part 1](https://www.reddit.com/r/robotics/comments/g7kc92/my_project_motorized_shoes_you_wear_while_playing/)\n\nIn the last post I shared my design for VR shoes, a pair of motorized shoes/platforms that keep you in the same spot as you walk or strafe in any direction, like an omni treadmill, but smaller, lighter, portable, more responsive, and cheaper.\n\nI mentioned I had kinks in the design to work out. I was using roller chains and they weren't tensioned properly. I updated the design so that I could tension the chains more easily.\n\n[Tensioning the chains](https://imgur.com/a/LOucVAQ)\n\nI had some issue with distributing the user's load. Like I went over in the last post, there are 3 sets of wheels for left/right movement, and 2 sets for forward/backwards movement, so 5 axles of wheels. You can again see [that here](https://imgur.com/a/KrsLLCw).\n\nIt seemed that some of the axles were bearing more of my weight than others. Specifically, the middle 3 seemed to be bearing most of the load, so when the other 2 on the ends spun, they didn't have enough force pushing them into the ground and the wheels would just skid. If I purposely leaned back to redistribute my weight, then the wheels got enough traction.\n\nTo help with this weight distribution issue I took out one of the axles, specifically the middle one for left/right movement. I also made the omni-spheres out of flexible filament, TPU, instead of rigid PETG, so that the spheres could flex a little. This helped, but didn't completely eliminate the issue.\n\n[One less axle](https://imgur.com/a/9xWziT6)\n\nI also did some testing with linear hall effect sensors so that I could precisely orient the omni-spheres. The omni-spheres have to be precisely oriented, as I explain [in these clip](https://imgur.com/a/QV2ax4g). I added linear hall effect sensors and magnets to the end of the axle.\n\n[Linear hall effect sensor](https://imgur.com/a/JeciJY7)\n\nSo it's basically an encoder. I hooked the sensor up to the Arudino I'm using. When the magnet is right above the sensor, the motor stops turning.\n\n[Automatic orientation of omni-sphere](https://imgur.com/a/3Nu0URj)\n\nI also did some testing with having the motors hold their position. Using a brake current of 40 amps, I had the Arduino constantly send a brake signal to the VESCs so the motors wouldn't move.\n\n[Full brake at 40A](https://imgur.com/a/BDelwNM)\n\nI found that I was able to still turn the axles with a little bit of force. This ended up being a problem.\n\nI did more testing with the shoe after these improvements. It worked okay. Some of the lessons I learned were\n\n1. The less axles the better.\n2. Proper weight distribution must be a priority. The wheels by the user's heel take most of the load.\n3. The wheels would still turn a little when the motor was supposed to be holding them in place. So the electronic braking of the motor isn't the best, even at 40 or 50 amps.\n4. Having to precisely control the orientation of the omni-spheres is not ideal, especially with electronic braking not being great. Maybe I should again try to design an omni-wheel that will work.\n5. Roller chains are noisy.\n6. It's a little bit of a pain to have to build in a way to tension a bunch of roller chains. The use of belts/chains should be minimized or eliminated.\n7. The little 3D printed sprockets I was using weren't very strong. Nylon CF sprockets seemed to hold up, but avoiding them would be best.\n8. 3D printed double helix gears are strong.\n9. 3:1 gearing or higher is preferred.\n10. TPU wheels are quiet.\n11. I'd prefer to reduce the size of the shoe considerably. Right now, it's huge.\n12. The shoe can be a little taller, maybe by 0.5 inches, which opens up the possibility to use slightly larger wheels and putting the motors under the platform.\n\nWith all these things and more in mind, I took a few weeks to do some thinking, brainstorming, then redesigning. I thought about how I could make an omni wheel work, slim the shoe down, maximize traction of the wheels, using more or less motors, etc.\n\nAfter some research and brainstorming, I designed an omni-wheel that is 2 inches in diameter and I think will work for this application. I've made 2 so far and they do not suffer from the 2 main problems I ran into with other omni wheel designs (bumpiness as they rolled and rollers at an angle not rolling at all). Being able to raise the platform a little also helped a lot, since the wheels could be larger and that gave me more space to work with.\n\n[Omni-wheel design](https://imgur.com/a/5CEBXYU)\n\nThe omni-wheel consists of 2 halves, each half has 4 rollers. Each roller is 3 parts. Each part of the roller has a 3mm bearing embedded into it. With each roller having 3 bearings, they roll very nicely when they are at an angle relative to the ground. Each roller is held in place by two \"arms\". Having 2 arms means they can be thinner, making the gaps they produce smaller, and these gaps don't cause noticable bumps as they roll.\n\nAfter designing the omni-wheel, I experimented with different designs and layouts for the motors, gears, and electronics. Here's the next design.\n\n[The next VR shoe design](https://imgur.com/a/B3UzD92)\n\n[Bottom view](https://imgur.com/a/CKDR6sX)\n\nThe arrow indicates where the user's heel will be. There is a wheel for forward/backward movement and a wheel for left/right movement directly under the heel, so both of them should take most of the load. I'm hoping this means that I won't have traction problems in any direction.\n\n[View of one of the drives](https://imgur.com/a/I2xRhQh)\n\nThis design eliminates roller chains, is much smaller, uses less parts, is simpler, and uses omni-wheels so it's truly omni-directional.\n\n[Here is](https://imgur.com/a/qtOh0Cw) a detailed video of how the omni-wheels are assembled.\n\n[Here is](https://imgur.com/a/CsxQTxz) what the drive looks like so far. I'm still in the process of putting it together.\n\nThis project is open source. I upload my design changes [here](https://github.com/finallyfunctional/vr-shoes-3d-models/tree/master) regularly.\n\nI have a discord for this project now: [https://discord.gg/w3eSp5P](https://discord.gg/w3eSp5P)\n\nI have a video build log for this project on YouTube. Link to my channel is in my user profile description.", "link": "https://www.reddit.com/r/robotics/comments/gtpqj5/part_2_motorized_shoes_you_wear_while_playing_a/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "part 2 - motorized \"shoes\" you wear while playing a virtual reality game /!/ [part 1](https://www.reddit.com/r/robotics/comments/g7kc92/my_project_motorized_shoes_you_wear_while_playing/)\n\nin the last post i shared my design for vr shoes, a pair of motorized shoes/platforms that keep you in the same spot as you walk or strafe in any direction, like an omni treadmill, but smaller, lighter, portable, more responsive, and cheaper.\n\ni mentioned i had kinks in the design to work out. i was using roller chains and they weren't tensioned properly. i updated the design so that i could tension the chains more easily.\n\n[tensioning the chains](https://imgur.com/a/loucvaq)\n\ni had some issue with distributing the user's load. like i went over in the last post, there are 3 sets of wheels for left/right movement, and 2 sets for forward/backwards movement, so 5 axles of wheels. you can again see [that here](https://imgur.com/a/krsllcw).\n\nit seemed that some of the axles were bearing more of my weight than others. specifically, the middle 3 seemed to be bearing most of the load, so when the other 2 on the ends spun, they didn't have enough force pushing them into the ground and the wheels would just skid. if i purposely leaned back to redistribute my weight, then the wheels got enough traction.\n\nto help with this weight distribution issue i took out one of the axles, specifically the middle one for left/right movement. i also made the omni-spheres out of flexible filament, tpu, instead of rigid petg, so that the spheres could flex a little. this helped, but didn't completely eliminate the issue.\n\n[one less axle](https://imgur.com/a/9xwzit6)\n\ni also did some testing with linear hall effect sensors so that i could precisely orient the omni-spheres. the omni-spheres have to be precisely oriented, as i explain [in these clip](https://imgur.com/a/qv2ax4g). i added linear hall effect sensors and magnets to the end of the axle.\n\n[linear hall effect sensor](https://imgur.com/a/jecijy7)\n\nso it's basically an encoder. i hooked the sensor up to the arudino i'm using. when the magnet is right above the sensor, the motor stops turning.\n\n[automatic orientation of omni-sphere](https://imgur.com/a/3nu0urj)\n\ni also did some testing with having the motors hold their position. using a brake current of 40 amps, i had the arduino constantly send a brake signal to the vescs so the motors wouldn't move.\n\n[full brake at 40a](https://imgur.com/a/bdelwnm)\n\ni found that i was able to still turn the axles with a little bit of force. this ended up being a problem.\n\ni did more testing with the shoe after these improvements. it worked okay. some of the lessons i learned were\n\n1. the less axles the better.\n2. proper weight distribution must be a priority. the wheels by the user's heel take most of the load.\n3. the wheels would still turn a little when the motor was supposed to be holding them in place. so the electronic braking of the motor isn't the best, even at 40 or 50 amps.\n4. having to precisely control the orientation of the omni-spheres is not ideal, especially with electronic braking not being great. maybe i should again try to design an omni-wheel that will work.\n5. roller chains are noisy.\n6. it's a little bit of a pain to have to build in a way to tension a bunch of roller chains. the use of belts/chains should be minimized or eliminated.\n7. the little 3d printed sprockets i was using weren't very strong. nylon cf sprockets seemed to hold up, but avoiding them would be best.\n8. 3d printed double helix gears are strong.\n9. 3:1 gearing or higher is preferred.\n10. tpu wheels are quiet.\n11. i'd prefer to reduce the size of the shoe considerably. right now, it's huge.\n12. the shoe can be a little taller, maybe by 0.5 inches, which opens up the possibility to use slightly larger wheels and putting the motors under the platform.\n\nwith all these things and more in mind, i took a few weeks to do some thinking, brainstorming, then redesigning. i thought about how i could make an omni wheel work, slim the shoe down, maximize traction of the wheels, using more or less motors, etc.\n\nafter some research and brainstorming, i designed an omni-wheel that is 2 inches in diameter and i think will work for this application. i've made 2 so far and they do not suffer from the 2 main problems i ran into with other omni wheel designs (bumpiness as they rolled and rollers at an angle not rolling at all). being able to raise the platform a little also helped a lot, since the wheels could be larger and that gave me more space to work with.\n\n[omni-wheel design](https://imgur.com/a/5cebxyu)\n\nthe omni-wheel consists of 2 halves, each half has 4 rollers. each roller is 3 parts. each part of the roller has a 3mm bearing embedded into it. with each roller having 3 bearings, they roll very nicely when they are at an angle relative to the ground. each roller is held in place by two \"arms\". having 2 arms means they can be thinner, making the gaps they produce smaller, and these gaps don't cause noticable bumps as they roll.\n\nafter designing the omni-wheel, i experimented with different designs and layouts for the motors, gears, and electronics. here's the next design.\n\n[the next vr shoe design](https://imgur.com/a/b3uzd92)\n\n[bottom view](https://imgur.com/a/ckdr6sx)\n\nthe arrow indicates where the user's heel will be. there is a wheel for forward/backward movement and a wheel for left/right movement directly under the heel, so both of them should take most of the load. i'm hoping this means that i won't have traction problems in any direction.\n\n[view of one of the drives](https://imgur.com/a/i2xrhqh)\n\nthis design eliminates roller chains, is much smaller, uses less parts, is simpler, and uses omni-wheels so it's truly omni-directional.\n\n[here is](https://imgur.com/a/qtoh0cw) a detailed video of how the omni-wheels are assembled.\n\n[here is](https://imgur.com/a/csxqtxz) what the drive looks like so far. i'm still in the process of putting it together.\n\nthis project is open source. i upload my design changes [here](https://github.com/finallyfunctional/vr-shoes-3d-models/-----> tree !!! /master) regularly.\n\ni have a discord for this project now: [https://discord.gg/w3esp5p](https://discord.gg/w3esp5p)\n\ni have a video build log for this project on youtube. link to my channel is in my user profile description.", "sortedWord": "None", "removed": null, "score": 1, "comments": 0, "media": "self", "medialink": "https://www.reddit.com/r/robotics/comments/gtpqj5/part_2_motorized_shoes_you_wear_while_playing_a/", "identifyer": 3503415, "year": "2020"}, {"Unnamed: 0": 3526, "autor": "cdossman", "date": 1591958016000, "content": "[Research] Behavior Trees in Robotics and AI: An Introduction /!/ **Abstract:**  A Behavior Tree (BT) is a way to structure the switching between different tasks in an autonomous agent, such as a robot or a virtual entity in a computer game. BTs are a very efficient way of creating complex systems that are both modular and reactive. These properties are crucial in many applications, which has led to the spread of BT from computer game programming to many branches of AI and Robotics. In this book, we will first give an introduction to BTs, then we describe how BTs relate to, and in many cases generalize, earlier switching structures. These ideas are then used as a foundation for a set of efficient and easy to use design principles. Properties such as safety, robustness, and efficiency are important for an autonomous system, and we describe a set of tools for formally analyzing these using a state space description of BTs. With the new analysis tools, we can formalize the descriptions of how BTs generalize earlier approaches. We also show the use of BTs in automated planning and machine learning. Finally, we describe an extended set of tools to capture the behavior of Stochastic BTs, where the outcomes of actions are described by probabilities. These tools enable the computation of both success probabilities and time to completion. \n\nPaper Link:  [https://arxiv.org/abs/1709.00084v4](https://arxiv.org/abs/1709.00084v4)", "link": "https://www.reddit.com/r/robotics/comments/h7iatp/research_behavior_trees_in_robotics_and_ai_an/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[research] behavior trees in robotics and ai: an introduction /!/ **abstract:**  a behavior -----> tree !!!  (bt) is a way to structure the switching between different tasks in an autonomous agent, such as a robot or a virtual entity in a computer game. bts are a very efficient way of creating complex systems that are both modular and reactive. these properties are crucial in many applications, which has led to the spread of bt from computer game programming to many branches of ai and robotics. in this book, we will first give an introduction to bts, then we describe how bts relate to, and in many cases generalize, earlier switching structures. these ideas are then used as a foundation for a set of efficient and easy to use design principles. properties such as safety, robustness, and efficiency are important for an autonomous system, and we describe a set of tools for formally analyzing these using a state space description of bts. with the new analysis tools, we can formalize the descriptions of how bts generalize earlier approaches. we also show the use of bts in automated planning and machine learning. finally, we describe an extended set of tools to capture the behavior of stochastic bts, where the outcomes of actions are described by probabilities. these tools enable the computation of both success probabilities and time to completion. \n\npaper link:  [https://arxiv.org/abs/1709.00084v4](https://arxiv.org/abs/1709.00084v4)", "sortedWord": "None", "removed": null, "score": 1, "comments": 0, "media": null, "medialink": "https://www.reddit.com/r/robotics/comments/h7iatp/research_behavior_trees_in_robotics_and_ai_an/", "identifyer": 3503561, "year": "2020"}, {"Unnamed: 0": 3699, "autor": "Fish6Chips", "date": 1582179367000, "content": "[M] Interview with Software Robotics Engineer at Vicarious /!/ Last week I promised a transcript of my interview, I hope you enjoy it! \n\n&amp;#x200B;\n\n**A:  First and foremost, everything that follows are my own personal opinions and nothing more, I can\u2019t and wouldn\u2019t presume to speak for Vicarious.**\n\nQ: Who is the main buyer for these machines?\n\nA: \u201cOur main buyers are dot coms, and people that have fulfillment operations.\u201d\n\nQ: How often do you need to use oral communication skills such as presentations and conferences?  \n\nA: \u201cConstantly, every minute, whenever you're talking to somebody you\u2019re kinda presenting ideas, it\u2019s a slippery slope to powerpoint. When you and your boss are working towards the same goal you\u2019re gonna be communicating all the time.\u201d \n\nQ: How often do you have to use written communication such as documents, writing journals, or reports? \n\nA: \u201cThe sorts of documentation we\u2019re doing aren\u2019t the kind that they teach you about in school. You might throw a one sentence blurb in there like \u201dI\u2019ve done this thing or im making this change,\u201d but you don\u2019t want to spend the time it takes to make editing passes or have a rough draft, none of that, that does not happen.  About the closest we ever come is editing the wiki.  People with English degrees are both better and cheaper than engineers when the writing quality matters.\u201d\n\nQ: What are the most common forms of communication at Vicarious? \n\nA: \u201cThe common kinds of communication. Lunch is a big one, we\u2019ve got a professional chef and he\u2019s extraordinarily good, so lunch is like a thing at the company. Everyone goes to lunch so a lot gets talked about, a lot gets done there. You\u2019ll have stand up meetings, which is a quick five minute thing.  Those, and the usual suspects:  email, Slack, and Github.\u201d\n\nQ: What made you pursue software engineering? \n\nA: \u201cFamily influence. I'm the first born son programmer, of the first born son programmer, of a first born son engineer... the apple doesn't fall far from the tree.\u201d \n\nQ: Where did you go to school? \n\nA: \u201cOriginally my career started out in web which was not something I was ever passionate about, but it was where I could find work before I had a degree. So I started as a web dev and then I started undergrad. Undergrad was at Colorado State and then for grad school I went to Tufts.\u201d \n\nQ: What is your average day-to-day like? \n\nA: \u201cCoffee, that's step one, and after coffee I can start to think about what I need to do. There is a lot of reddit and coffee while I refresh my memory about all the things I need to do. This is also when I check on the projects I have that are blocked on others. I\u2019ll spend time checking in on the various things I have in flight which will take me until about lunch. The afternoon starts with a stand up meeting to sync with my team, and then after that I can finally start writing code.\u201d\n\nQ: What kind of programming languages do you need to work on these robots? \n\nA: \u201cC and C++ are really important.  C++ sucks , it sucks, it\u2019s a horrible language, but it's everywhere and you do need to know it (and know it well). Python is super important, that\u2019s what much of our stack is in. I personally use a lot of Rust.  One of my projects is a translator that translates between the ROS traffic and the proprietary protocols that run the robots. On top of those, each of the major brands of robots has its own scripting language.\u201d\n\nQ: Did you have any internship while you were in school? \n\nA: \u201cI had a different path, I started in industry first, so I was getting paid when I started school.\u201d\n\nQ: What is the most challenging aspect of your job?  \n\nA: \u201cI personally find the biggest challenge is when i'm interacting with less talented people because I have to  keep them happy about working with me while at the same time telling them to shut up and let me do my job or to stop doing it wrong. Navigating that, telling people that they\u2019re wrong in a way that they don\u2019t hate you for, that\u2019s a big challenge for me.\u201d\n\nQ: What is the most exciting thing you have done at this job? \n\nA: \u201cSafety testing these big Kukas. In order to make sure that your safety code works you have to push them to their extremes because, otherwise, you don't know if your safety is gonna work at the extremes. It was probably 700 kilograms of robot, something like that, flipping around at absolute top speed and stopping inches or millimeters from something, and then going back as fast as it can the other way. \u201d\n\nQ: What led you to advance your career ? \n\nA: \u201cThe only way I\u2019ve really had success advancing my career is by quitting one job and getting hired at another one. That's just how the modern economy is.  People tend not to be promoted. Every other year or so I switch jobs to one that is hungry enough to make me a good offer.  Perhaps this job is different\u2026 time will tell.\u201d\n\nQ: How long have you been working here?\n\nA: \u201c13-14 months, something like that. I was employee number forty-something.\u201d\n\nQ: On average how many projects do you have going on at one time?\n\nA: \u201cI\u2019m a little unusual at the company in that regard, I tend to have a lot of different things in motion at a given time. I\u2019m very much a generalist rather than a specialist.  4-5 different projects at a time is pretty typical for me, when one blocks one someone else I simply switch.\u201d\n\nQ: Is the team heavily based on software engineers or are there people from other engineering fields too? \n\nA: \u201cIt is heavily biased toward software engineers, but we have engineers of all types. We have a mechanical engineering team, we\u2019ve got safety programmers, but it\u2019s mostly software because the problem is mostly a software problem.\u201d\n\nQ: Do you have non engineering majors working?\n\nA: \u201cThere is always gonna be the sales teams and those kinds of people, but we also have people who are primarily AI researchers and they\u2019re really just thinking in terms of AI. Engineering and research are pretty different in practice.\u201d\n\nQ: Do you consider your company to be environmentally friendly?\n\nA: \u201cFairly. We don\u2019t really have anything that burns fossil fuels, so that gets you pretty far. I think the biggest win, environmentally speaking, from what we\u2019re doing is we\u2019re trying to replace people with robots... people are kind of expensive environmentally to keep happy and keep alive.\u201d\n\nQ: Does Vicarious have any specific environmental concerns? \n\nA: \u201cNot really, We don't have all that much waste.  Every trash bin has a recycling bin and a composting bin right next to it, and the lights all turn themselves off so we can\u2019t forget to, but really, the big environmental win will come once we can start displacing hamburger eating, car driving, no-low-power-mode humans.  Or to say it another way, the big environmental win will come from the already-declining birth rate rather than from whether or not we compost our scraps.\u201d\n\nQ: Do buyers tend to buy larger robots or smaller robots?  \n\nA: \u201cIt really depends, you want to size your robot to be as small as possible to get the job done.\u201d\n\nQ: What kind of ethical dilemmas have you encountered here at Vicarious?\n\nA: \u201cThere are a lot of them actually and it depends on where you want to stop thinking in terms of ethics. Is it ethical to be trying to displace people in the workforce in the first place? Maybe, maybe not. There are those of us who would argue that it\u2019s the inevitable consequence of capitalism plus technology. If you\u2019re trying to drive the bottom line as far down as possible, getting people out of the equation is one of those steps.  Is that ethical?  And that's just one of them. There are also ethical issues surrounding safety. How dangerous does something have to be before you step in and say \u201cHard no.  We\u2019re not doing that.\u201d You have to really ask yourself: \u201cPrecisely how much risk am I comfortable watching someone take?  Keep in mind that if you try to answer \u2018none\u2019 I\u2019m going to point out how dangerous commuting is.\u201d\n\nQ: What\u2019s the most valuable thing you have learned working here? \n\nA: \u201cFor me it has all been social.\u201d\n\nQ: How do you see yourself in five years?\n\nA: \u201cWe might IPO within the next five years, I don't know, and if that happens I\u2019ll be retired on a beach in the tropics. Most startups fail and everyone that goes into startups knows this, so perhaps more realistically where am I going to be? I\u2019ll probably be a tech lead or CTO at some startup that currently doesn\u2019t exist.\u201d\n\nQ: What skill are you trying to develop currently?\n\nA: \u201cI'm trying to incorporate the Kuka work which is done by old-school robot people who think in their kind of old-school way with the new-school startup culture.  Don\u2019t get me wrong, I\u2019m not of the old == bad mentality, I\u2019m trying to learn the lessons and wisdom of the old school way and apply them on the software side (which moves at startup speed)... and vice versa.\u201d\n\nQ: Does GPA matter?\n\nA: \u201cNot really, you don't even strictly have to put it on your resume. When we interview you, we\u2019re gonna grill you anyway and that's what we care more about.  Being really good matters, and as a side effect it can make getting good grades easy, but that\u2019s it.\u201d\n\nQ: What kind of questions do you ask in the interview?\n\nA: \u201cI look what the candidates experiences are and I find some overlap between what they know and what I know and then I grill them on that. \u201d\n\nQ: What are the most important skills in the robotics industry?\n\nA: \u201c Python, that's a big one. ROS at the prototyping stages, and thinking clearly. Clear thinking is the biggest skill I see that\u2019s lacking in experienced people and even more so in noobies. Communicating clearly is by far the biggest and most important skill because you are not working alone.\u201d", "link": "https://www.reddit.com/r/robotics/comments/f6ou1k/m_interview_with_software_robotics_engineer_at/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[m] interview with software robotics engineer at vicarious /!/ last week i promised a transcript of my interview, i hope you enjoy it! \n\n&amp;#x200b;\n\n**a:  first and foremost, everything that follows are my own personal opinions and nothing more, i can\u2019t and wouldn\u2019t presume to speak for vicarious.**\n\nq: who is the main buyer for these machines?\n\na: \u201cour main buyers are dot coms, and people that have fulfillment operations.\u201d\n\nq: how often do you need to use oral communication skills such as presentations and conferences?  \n\na: \u201cconstantly, every minute, whenever you're talking to somebody you\u2019re kinda presenting ideas, it\u2019s a slippery slope to powerpoint. when you and your boss are working towards the same goal you\u2019re gonna be communicating all the time.\u201d \n\nq: how often do you have to use written communication such as documents, writing journals, or reports? \n\na: \u201cthe sorts of documentation we\u2019re doing aren\u2019t the kind that they teach you about in school. you might throw a one sentence blurb in there like \u201di\u2019ve done this thing or im making this change,\u201d but you don\u2019t want to spend the time it takes to make editing passes or have a rough draft, none of that, that does not happen.  about the closest we ever come is editing the wiki.  people with english degrees are both better and cheaper than engineers when the writing quality matters.\u201d\n\nq: what are the most common forms of communication at vicarious? \n\na: \u201cthe common kinds of communication. lunch is a big one, we\u2019ve got a professional chef and he\u2019s extraordinarily good, so lunch is like a thing at the company. everyone goes to lunch so a lot gets talked about, a lot gets done there. you\u2019ll have stand up meetings, which is a quick five minute thing.  those, and the usual suspects:  email, slack, and github.\u201d\n\nq: what made you pursue software engineering? \n\na: \u201cfamily influence. i'm the first born son programmer, of the first born son programmer, of a first born son engineer... the apple doesn't fall far from the -----> tree !!! .\u201d \n\nq: where did you go to school? \n\na: \u201coriginally my career started out in web which was not something i was ever passionate about, but it was where i could find work before i had a degree. so i started as a web dev and then i started undergrad. undergrad was at colorado state and then for grad school i went to tufts.\u201d \n\nq: what is your average day-to-day like? \n\na: \u201ccoffee, that's step one, and after coffee i can start to think about what i need to do. there is a lot of reddit and coffee while i refresh my memory about all the things i need to do. this is also when i check on the projects i have that are blocked on others. i\u2019ll spend time checking in on the various things i have in flight which will take me until about lunch. the afternoon starts with a stand up meeting to sync with my team, and then after that i can finally start writing code.\u201d\n\nq: what kind of programming languages do you need to work on these robots? \n\na: \u201cc and c++ are really important.  c++ sucks , it sucks, it\u2019s a horrible language, but it's everywhere and you do need to know it (and know it well). python is super important, that\u2019s what much of our stack is in. i personally use a lot of rust.  one of my projects is a translator that translates between the ros traffic and the proprietary protocols that run the robots. on top of those, each of the major brands of robots has its own scripting language.\u201d\n\nq: did you have any internship while you were in school? \n\na: \u201ci had a different path, i started in industry first, so i was getting paid when i started school.\u201d\n\nq: what is the most challenging aspect of your job?  \n\na: \u201ci personally find the biggest challenge is when i'm interacting with less talented people because i have to  keep them happy about working with me while at the same time telling them to shut up and let me do my job or to stop doing it wrong. navigating that, telling people that they\u2019re wrong in a way that they don\u2019t hate you for, that\u2019s a big challenge for me.\u201d\n\nq: what is the most exciting thing you have done at this job? \n\na: \u201csafety testing these big kukas. in order to make sure that your safety code works you have to push them to their extremes because, otherwise, you don't know if your safety is gonna work at the extremes. it was probably 700 kilograms of robot, something like that, flipping around at absolute top speed and stopping inches or millimeters from something, and then going back as fast as it can the other way. \u201d\n\nq: what led you to advance your career ? \n\na: \u201cthe only way i\u2019ve really had success advancing my career is by quitting one job and getting hired at another one. that's just how the modern economy is.  people tend not to be promoted. every other year or so i switch jobs to one that is hungry enough to make me a good offer.  perhaps this job is different\u2026 time will tell.\u201d\n\nq: how long have you been working here?\n\na: \u201c13-14 months, something like that. i was employee number forty-something.\u201d\n\nq: on average how many projects do you have going on at one time?\n\na: \u201ci\u2019m a little unusual at the company in that regard, i tend to have a lot of different things in motion at a given time. i\u2019m very much a generalist rather than a specialist.  4-5 different projects at a time is pretty typical for me, when one blocks one someone else i simply switch.\u201d\n\nq: is the team heavily based on software engineers or are there people from other engineering fields too? \n\na: \u201cit is heavily biased toward software engineers, but we have engineers of all types. we have a mechanical engineering team, we\u2019ve got safety programmers, but it\u2019s mostly software because the problem is mostly a software problem.\u201d\n\nq: do you have non engineering majors working?\n\na: \u201cthere is always gonna be the sales teams and those kinds of people, but we also have people who are primarily ai researchers and they\u2019re really just thinking in terms of ai. engineering and research are pretty different in practice.\u201d\n\nq: do you consider your company to be environmentally friendly?\n\na: \u201cfairly. we don\u2019t really have anything that burns fossil fuels, so that gets you pretty far. i think the biggest win, environmentally speaking, from what we\u2019re doing is we\u2019re trying to replace people with robots... people are kind of expensive environmentally to keep happy and keep alive.\u201d\n\nq: does vicarious have any specific environmental concerns? \n\na: \u201cnot really, we don't have all that much waste.  every trash bin has a recycling bin and a composting bin right next to it, and the lights all turn themselves off so we can\u2019t forget to, but really, the big environmental win will come once we can start displacing hamburger eating, car driving, no-low-power-mode humans.  or to say it another way, the big environmental win will come from the already-declining birth rate rather than from whether or not we compost our scraps.\u201d\n\nq: do buyers tend to buy larger robots or smaller robots?  \n\na: \u201cit really depends, you want to size your robot to be as small as possible to get the job done.\u201d\n\nq: what kind of ethical dilemmas have you encountered here at vicarious?\n\na: \u201cthere are a lot of them actually and it depends on where you want to stop thinking in terms of ethics. is it ethical to be trying to displace people in the workforce in the first place? maybe, maybe not. there are those of us who would argue that it\u2019s the inevitable consequence of capitalism plus technology. if you\u2019re trying to drive the bottom line as far down as possible, getting people out of the equation is one of those steps.  is that ethical?  and that's just one of them. there are also ethical issues surrounding safety. how dangerous does something have to be before you step in and say \u201chard no.  we\u2019re not doing that.\u201d you have to really ask yourself: \u201cprecisely how much risk am i comfortable watching someone take?  keep in mind that if you try to answer \u2018none\u2019 i\u2019m going to point out how dangerous commuting is.\u201d\n\nq: what\u2019s the most valuable thing you have learned working here? \n\na: \u201cfor me it has all been social.\u201d\n\nq: how do you see yourself in five years?\n\na: \u201cwe might ipo within the next five years, i don't know, and if that happens i\u2019ll be retired on a beach in the tropics. most startups fail and everyone that goes into startups knows this, so perhaps more realistically where am i going to be? i\u2019ll probably be a tech lead or cto at some startup that currently doesn\u2019t exist.\u201d\n\nq: what skill are you trying to develop currently?\n\na: \u201ci'm trying to incorporate the kuka work which is done by old-school robot people who think in their kind of old-school way with the new-school startup culture.  don\u2019t get me wrong, i\u2019m not of the old == bad mentality, i\u2019m trying to learn the lessons and wisdom of the old school way and apply them on the software side (which moves at startup speed)... and vice versa.\u201d\n\nq: does gpa matter?\n\na: \u201cnot really, you don't even strictly have to put it on your resume. when we interview you, we\u2019re gonna grill you anyway and that's what we care more about.  being really good matters, and as a side effect it can make getting good grades easy, but that\u2019s it.\u201d\n\nq: what kind of questions do you ask in the interview?\n\na: \u201ci look what the candidates experiences are and i find some overlap between what they know and what i know and then i grill them on that. \u201d\n\nq: what are the most important skills in the robotics industry?\n\na: \u201c python, that's a big one. ros at the prototyping stages, and thinking clearly. clear thinking is the biggest skill i see that\u2019s lacking in experienced people and even more so in noobies. communicating clearly is by far the biggest and most important skill because you are not working alone.\u201d", "sortedWord": "None", "removed": null, "score": 1, "comments": 6, "media": null, "medialink": "https://www.reddit.com/r/robotics/comments/f6ou1k/m_interview_with_software_robotics_engineer_at/", "identifyer": 3503735, "year": "2020"}, {"Unnamed: 0": 3722, "autor": "KIKAItachi", "date": 1595495300000, "content": "Robot drives while hanging from a tree branch", "link": "https://www.reddit.com/r/robotics/comments/hwcgz6/robot_drives_while_hanging_from_a_tree_branch/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "robot drives while hanging from a -----> tree !!!  branch", "sortedWord": "None", "removed": null, "score": 92, "comments": 40, "media": "rich:video", "medialink": "https://youtu.be/2hPKNMYJi3o", "identifyer": 3503760, "year": "2020"}, {"Unnamed: 0": 3857, "autor": "dmalawey", "date": 1600082405000, "content": "Anyone have a solid robot MQTT data (topic) structure? /!/ I'm outlining a standard topic structure within which to organize MQTT variables for a mobile robot.  \n\nThe purpose is for simple data communication such as \"battery state of charge\" for one of the robots. I want to organize my topics in a way that lasts for several years and through expansion and changes.\n\nExample:\n\nTopic: RobotFleet / UNIT031 / Chassis / Battery / SOC\n\nLater if I add another robot or another module with onboard battery, it fits right in. Maybe the above method is a terrible mistake and the robot unit should be the lowest subtopic.   I've only thought about this for a few days but there are teams out there who surely thought about it for months &amp; made very clever choices.\n\nDo you have knowledge of any robotics company's MQTT topic tree?  If so, can you share examples?", "link": "https://www.reddit.com/r/robotics/comments/isiz6q/anyone_have_a_solid_robot_mqtt_data_topic/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "anyone have a solid robot mqtt data (topic) structure? /!/ i'm outlining a standard topic structure within which to organize mqtt variables for a mobile robot.  \n\nthe purpose is for simple data communication such as \"battery state of charge\" for one of the robots. i want to organize my topics in a way that lasts for several years and through expansion and changes.\n\nexample:\n\ntopic: robotfleet / unit031 / chassis / battery / soc\n\nlater if i add another robot or another module with onboard battery, it fits right in. maybe the above method is a terrible mistake and the robot unit should be the lowest subtopic.   i've only thought about this for a few days but there are teams out there who surely thought about it for months &amp; made very clever choices.\n\ndo you have knowledge of any robotics company's mqtt topic -----> tree !!! ?  if so, can you share examples?", "sortedWord": "None", "removed": null, "score": 1, "comments": 3, "media": null, "medialink": "https://www.reddit.com/r/robotics/comments/isiz6q/anyone_have_a_solid_robot_mqtt_data_topic/", "identifyer": 3503898, "year": "2020"}, {"Unnamed: 0": 4137, "autor": "nexofreak14", "date": 1593961055000, "content": "I want to build a drone that will autonomously move from point A to B , detect a certain tree and pluck its fruits /!/ I'm basically new to drones and planning on working on this project. I'm planning on building a hexacopter drone.  For now I've been told to learn ROS and use Pixhawk PX2 flight controllers and Raspberry Pi  . I have worked with opencv.  But Idk how do I go about this . How do I integrate opencv with PX4 and Raspberry pi and send the data to ROS so that the drone can move automatically?  Thank u", "link": "https://www.reddit.com/r/robotics/comments/hlnxpy/i_want_to_build_a_drone_that_will_autonomously/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "i want to build a drone that will autonomously move from point a to b , detect a certain -----> tree !!!  and pluck its fruits /!/ i'm basically new to drones and planning on working on this project. i'm planning on building a hexacopter drone.  for now i've been told to learn ros and use pixhawk px2 flight controllers and raspberry pi  . i have worked with opencv.  but idk how do i go about this . how do i integrate opencv with px4 and raspberry pi and send the data to ros so that the drone can move automatically?  thank u", "sortedWord": "None", "removed": null, "score": 1, "comments": 7, "media": null, "medialink": "https://www.reddit.com/r/robotics/comments/hlnxpy/i_want_to_build_a_drone_that_will_autonomously/", "identifyer": 3504180, "year": "2020"}, {"Unnamed: 0": 4138, "autor": "nousetest", "date": 1593959196000, "content": "A flexible tree climbing robot: Treebot - design and implementation", "link": "https://www.reddit.com/r/robotics/comments/hlnh5a/a_flexible_tree_climbing_robot_treebot_design_and/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "a flexible -----> tree !!!  climbing robot: treebot - design and implementation", "sortedWord": "None", "removed": null, "score": 1, "comments": 0, "media": "rich:video", "medialink": "https://www.youtube.com/watch?v=wPGoWvKEOAw", "identifyer": 3504181, "year": "2020"}, {"Unnamed: 0": 4298, "autor": "watermooses", "date": 1603392830000, "content": "What is the current trend for localization and obstacle avoidance? /!/ I was looking at the Lidars available on [robotshop.com](https://robotshop.com) and haven't seen anything that isn't 10 year old technology.  Is there anything new in the Lidar field under $5k?  Is localization and obstacle avoidance moving to computer vision based systems?  10 years ago I would have thought at least the costs would have come down and that we'd have affordable 3D lidars by now.\n\nAm I barking up the wrong tech tree and need to look more into computer vision instead?", "link": "https://www.reddit.com/r/robotics/comments/jg5wr1/what_is_the_current_trend_for_localization_and/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "what is the current trend for localization and obstacle avoidance? /!/ i was looking at the lidars available on [robotshop.com](https://robotshop.com) and haven't seen anything that isn't 10 year old technology.  is there anything new in the lidar field under $5k?  is localization and obstacle avoidance moving to computer vision based systems?  10 years ago i would have thought at least the costs would have come down and that we'd have affordable 3d lidars by now.\n\nam i barking up the wrong tech -----> tree !!!  and need to look more into computer vision instead?", "sortedWord": "None", "removed": null, "score": 1, "comments": 2, "media": null, "medialink": "https://www.reddit.com/r/robotics/comments/jg5wr1/what_is_the_current_trend_for_localization_and/", "identifyer": 3504342, "year": "2020"}, {"Unnamed: 0": 4462, "autor": "Snoo_85410", "date": 1606872664000, "content": "[Research] MIT researchers have automated and optimized robot design with the RoboGrammar system. This system can create arthropod-inspired robots for traversing a variety of terrains. /!/ [Check out how RoboGrammar works with this presentation video by MIT!](https://crossminds.ai/video/5fc6a796ec4e469301f04c13/?playlist_id=5f07c51e2de531fe96279ccb)\n\n**Paper Abstract:**\n\nWe present RoboGrammar, a fully automated approach for generating optimized robot structures to traverse given terrains. In this framework, we represent each robot design as a graph, and use a graph grammar to express possible arrangements of physical robot assemblies. Each robot design can then be expressed as a sequence of grammar rules. Using only a small set of rules our grammar can describe hundreds of thousands of possible robot designs. The construction of the grammar limits the design space to designs that can be fabricated. For a given input terrain, the design space is searched to find the top performing robots and their corresponding controllers. We introduce Graph Heuristic Search \u2013 a novel method for efficient search of combinatorial design spaces. In Graph Heuristic Search, we explore the design space while simultaneously learning a function that maps incomplete designs (e.g., nodes in the combinatorial search tree) to the best performance values that can be achieved by expanding these incomplete designs. Graph Heuristic Search prioritizes exploration of the most promising branches of the design space. To test our method we optimize robots for a number of challenging and varied terrains. We demonstrate that RoboGrammar can successfully generate nontrivial robots that are optimized for a single terrain or a combination of terrains.\n\n**Authors:**\n\nAllan Zhao, Jie Xu, Mina Konakovi\u0107 Lukovi\u0107, Josephine Hughes, Andrew Spielberg, Daniela Rus, Wojciech Matusik", "link": "https://www.reddit.com/r/robotics/comments/k4z5cb/research_mit_researchers_have_automated_and/", "origin": "Reddit", "suborigin": "robotics", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[research] mit researchers have automated and optimized robot design with the robogrammar system. this system can create arthropod-inspired robots for traversing a variety of terrains. /!/ [check out how robogrammar works with this presentation video by mit!](https://crossminds.ai/video/5fc6a796ec4e469301f04c13/?playlist_id=5f07c51e2de531fe96279ccb)\n\n**paper abstract:**\n\nwe present robogrammar, a fully automated approach for generating optimized robot structures to traverse given terrains. in this framework, we represent each robot design as a graph, and use a graph grammar to express possible arrangements of physical robot assemblies. each robot design can then be expressed as a sequence of grammar rules. using only a small set of rules our grammar can describe hundreds of thousands of possible robot designs. the construction of the grammar limits the design space to designs that can be fabricated. for a given input terrain, the design space is searched to find the top performing robots and their corresponding controllers. we introduce graph heuristic search \u2013 a novel method for efficient search of combinatorial design spaces. in graph heuristic search, we explore the design space while simultaneously learning a function that maps incomplete designs (e.g., nodes in the combinatorial search -----> tree !!! ) to the best performance values that can be achieved by expanding these incomplete designs. graph heuristic search prioritizes exploration of the most promising branches of the design space. to test our method we optimize robots for a number of challenging and varied terrains. we demonstrate that robogrammar can successfully generate nontrivial robots that are optimized for a single terrain or a combination of terrains.\n\n**authors:**\n\nallan zhao, jie xu, mina konakovi\u0107 lukovi\u0107, josephine hughes, andrew spielberg, daniela rus, wojciech matusik", "sortedWord": "None", "removed": null, "score": 1, "comments": 5, "media": "self", "medialink": "https://www.reddit.com/r/robotics/comments/k4z5cb/research_mit_researchers_have_automated_and/", "identifyer": 3504507, "year": "2020"}], "name": "treerobotics2020"}