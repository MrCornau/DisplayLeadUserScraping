{"interestingcomments": [{"autor": "adwarakanath", "date": 1612028961000, "content": "[D] Decoding stimuli from neuronal responses - generalisation across monkeys (Neuroscience) /!/ Hello everyone!\n\nI have a probably very basic question but this is something I'm struggling with a bit.\n\nI have data recorded from 2 male macaques (prefrontal cortex) in response to some visual stimuli. There are only 2 types of visual stimuli that change stochastically. The PSTHs I plot are aligned at the point of change. I detect points of change and then align the data to this, so I get a number of \"switches\".\n\nI am using 6 recorded sessions, 4 from one monkey and 2 from the other.\n\nDoes it make sense to, for example, train my classifier on the first session and then test it on session 6 (i.e. train one a session from Monkey 1 and generalise to a session from Monkey 2?).\n\nFrom a machine learning perspective, the underlying population shouldn't matter for generalising your model that you trained, right?\n\nThe way I'm thinking about it is this - For decoding, selectivities of the recorded neurons shouldn't matter, as decoding is an inverse problem right? Given the observed activity, we ask, what was the stimulus perceived? So indeed then I can generalise across monkeys?\n\nFor more context, these are chronic recordings from Utah arrays and the 6 sessions were recorded over a time-period of 10 months.\n\nI'd be very thankful for any help, tips and advice!\n\nCheers", "link": "https://www.reddit.com/r/MachineLearning/comments/l8r5cp/d_decoding_stimuli_from_neuronal_responses/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] decoding stimuli from neuronal responses - generalisation across monkeys (neuroscience) /!/ hello everyone!\n\ni have a probably very basic question but this is something i'm struggling with a bit.\n\ni have data recorded from 2 male macaques (prefrontal cortex) in response to some visual stimuli. there are only 2 types of visual stimuli that change stochastically. the psths i -----> plot !!!  are aligned at the point of change. i detect points of change and then align the data to this, so i get a number of \"switches\".\n\ni am using 6 recorded sessions, 4 from one monkey and 2 from the other.\n\ndoes it make sense to, for example, train my classifier on the first session and then test it on session 6 (i.e. train one a session from monkey 1 and generalise to a session from monkey 2?).\n\nfrom a machine learning perspective, the underlying population shouldn't matter for generalising your model that you trained, right?\n\nthe way i'm thinking about it is this - for decoding, selectivities of the recorded neurons shouldn't matter, as decoding is an inverse problem right? given the observed activity, we ask, what was the stimulus perceived? so indeed then i can generalise across monkeys?\n\nfor more context, these are chronic recordings from utah arrays and the 6 sessions were recorded over a time-period of 10 months.\n\ni'd be very thankful for any help, tips and advice!\n\ncheers", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 12, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/l8r5cp/d_decoding_stimuli_from_neuronal_responses/',)", "identifyer": 5721675, "year": "2021"}, {"autor": "Salt_Inflation_6175", "date": 1627651655000, "content": "\"[Project]\" An Introduction to Machine Learning (A Sample Article) /!/ *The following is a sample article from a newsletter I run, called Algo-Fin. This article introduces the common concepts of Machine Learning, the practical use of which will come in future articles when we attempt to model the markets.*\n\n*Algo-Fin aims to provide an alternative study of the financial markets, where the focus isn\u2019t on drawing lines on charts or trying to identify head and shoulders patterns, but instead focusing on what truly drives these markets, the components of the economies. Algo-Fin is a macroeconomic study of the proponents of supply and demand In the forex markets, through the understanding of the theory, presentation of clear and insightful visualisations and the building of algorithms in order to try and predict future performance. If you\u2019re interested in subscribing, you can for free at* [*algofin.substack.com*](http://algofin.substack.com/)*. Thanks for joining!*\n\n\\---\n\nAn Introduction\n\n&gt;\u201c\\[Machine Learning is a\\] field of study that gives computers the ability to learn without being explicitly programmed.\u201d (Arthur Samuel, 1959)\n\nArthur Samuel, considered to be the originator of the term \u201cMachine Learning\u201d defined it with the above quote. This definition still stands today but has been developed with time.\n\n&gt;\u201cA computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.\u201d\u00a0(Tom Mitchell, 1998)\n\nTom Mitchell, a computer science professor at Carnegie Mellon University defined a well-structured machine learning problem in 1998 with the above description.\n\nLet\u2019s break both of these quotes down a little further. The key element in both of these definitions is the word \u201clearn\u201d and that\u2019s exactly what the foundation of machine learning is \u2014 we want machines to learn without us specifically telling them what should be learned.\n\nTypically, we might want our algorithm to learn how to get from one point to another. That\u00a0initial point\u00a0could be\u00a0a dataset of factors\u00a0that describe a situation, such as body measurements of a person for example \u2014 height, weight, BMI, blood pressure levels etc, and our\u00a0final point\u00a0that we want our algorithm to reach could be the life expectancy of that particular person.\n\nUltimately, what we want to do is to provide the start point and the endpoint of our journey and tell the algorithm to figure out which path to take \u2014 that\u2019s what we classify as learning.\n\nThis is typical to what we call a \u201csupervised learning\u201d problem \u2014 unsupervised learning is the alternative, which does not in fact declare a specific endpoint, but instead tells the algorithm to locate similarities between all of the data points.\n\nThe commonality however, is that we do still start without initial dataset and then provide an indication to our algorithm of what we want the output to look like, with varying levels of specification.\n\nIn the second definition, we can consider our experience E to be our initial input dataset, the task T to be the instruction that this dataset must be trained to match our output dataset and our performance P as being some form of accuracy metric that essentially informs us of how well a model is performing.\n\nIntroducing Functions\n\nSo how does all this learning happen? Well, from a high-level view, it happens through the concept of functions. For those that may not be completely familiar, a function is a relation from a set of inputs to a set of possible outputs\\[1\\]. If we look at what our definition of machine learning is, the role of the function is exactly what we want our machine to learn, or estimate. We want it to know how to get from our inputs to our outputs, essentially find out what the relation is.\n\nThe goal of any machine learning algorithm therefore, is to find the best possible approximation for our function that takes our input variables to as close to our output variables as possible.\n\nThe word\u00a0generalisation\u00a0is how we apply this to future scenarios. Essentially, what we have built is a relationship between our inputs and outputs. But what if we now give our relationship a new set of inputs? Will it still be able to transform these unseen inputs into the correct set of outputs?\u00a0Generalisation is the ability to make correct predictions on unseen data.\n\nUltimately, that is what we want our machine learning algorithms to do. We want them to understand relationships in the data that stand the test of data they haven\u2019t seen before.\n\nThe mathematical notation of all the terms described above is noted here:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ct6mk7lbqce71.png?width=999&amp;format=png&amp;auto=webp&amp;s=4e640975c1b53e8c6fdbf82186eb744ef42afe6e\n\nLet\u2019s look a little further into this concept of functions.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/8ilfeuncqce71.png?width=999&amp;format=png&amp;auto=webp&amp;s=414e2b74dfb205f5749231212956296c14e66e7a\n\nWe\u2019ve plotted 4 known data points on a graph and we expect them to have some form of underlying relationship that we are looking to estimate. We\u2019ll call the underlying function\u00a0*f(x)*\u00a0and we have produced 3 basic estimation models, that we call\u00a0*h(x)*.\n\nThe first estimation method is just to draw a line connecting each datapoint. This provides us with a perfect fit for our seen data because we have estimated the exact\u00a0*f(x)*\u00a0value at every\u00a0*x*\u00a0point. This model however has no generalisable properties and if we add an unseen datapoint (the point in red), our model will have no way of estimating this since there is no procedure in place for this\u00a0*x*\u00a0value.\n\nAlternatively, we could use a 3rd order polynomial, which appears to be another good fit for the seen data points. It gathers the general shape of the points and depending on where the unseen datapoint is plotted, this model has the ability to generalise.\n\nA 1st order polynomial in the above case is a straight line. We can see that it doesn\u2019t provide a perfect fit due to the shape of the input data, but again, depending on our\u00a0*x*\u00a0and\u00a0*f(x)*\u00a0relationship, this estimation has the ability to generalise to our unseen data.\n\nThis concept is one of the most important to keep in mind about machine learning. We are not looking for the perfect model, because we don\u2019t expect this perfect model to generalise.\u00a0We\u2019re looking for the best estimation to the data we know in the hope it will also perform well on the data we haven\u2019t exposed the model to yet. In addition to this, the final 2 graphs informs us that the model we choose is always unique to the problem that we are aiming to solve, there is no \u201cone size fits all.\u201d\n\nThis brings us to the next conversation \u2014 machine learning vs pattern recognition. These are often terms that get grouped together and used interchangeably, but they do actually have unique definitions.\n\nPattern Recognition and Machine Learning\n\nMachine Learning is learning from experience, the experience being a set of input data that we provide for our algorithm. In machine learning, our experience, task and performance are clearly defined. Machine Learning is also called supervised learning, because we provide both an input and a target output in our data.\n\nPattern Recognition is the process of finding patterns in our data. It is also called unsupervised learning because, instead of telling the model specifically what the output should be, we ask it to find patterns and relationships within the data. Our experience E will be only feature variables with no target output and our task and performance are more broadly defined because we don\u2019t have a specific path we want our algorithm to follow.\n\nIt\u2019s easiest if we consider a couple of examples\n\n* Data consisting of 1 feature \u2014 age and 1 label \u2014 height \u2192 univariate supervised learning\n* Data consisting of 3 features \u2014 age, height, gender and 1 label \u2014 life expectancy \u2192 multivariable supervised learning\n* Data consisting of 1 feature \u2014 a series of prices of the Dow Jones Index, with the aim of classifying the prices into similar groupings \u2192 univariate unsupervised learning\n* Data consisting of 3 features \u2014 attributes of a song, tempo, length and key, with the aim of classifying them into groups of similar songs that can hopefully be separable by genre \u2192 multivariate unsupervised learning\n\nSupervised Learning\n\nSupervised learning can generally be split into two main categories \u2014 classification and regression.\n\nClassification is a machine learning task where we have a discrete set of outcomes. Classification is often binary, meaning that there are two possible options for the outcome, normally yes/no or 1/0. Examples of classification include face detection, smile detection, spam classification.\n\nRegression is a machine learning task where we have a real-valued outcome in a continuous sub-space. Basically, this means that our outcome is a continuous variable, but that it is usually confined to some sort of range. Examples of regression include age estimation, stock value prediction, temperature prediction.\n\nMathematically we define these as follows:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/lbmmobgeqce71.png?width=999&amp;format=png&amp;auto=webp&amp;s=05dd2c7c2dfde4839e05abd90f0b734100efc396\n\nIn the diagram above, the\u00a0*N*\u00a0is the set of all natural numbers. These are all integers greater than 0. The set of natural numbers would look something like\u00a0*{1,2,3,4,\u2026}*. The\u00a0*R*\u00a0is the set of all real numbers. This includes all natural numbers, integers, rational and irrational numbers. The only values that the set of real numbers doesn\u2019t include are imaginary numbers, such as\u00a0*i*, used to represent the square root of -1, but we don\u2019t encounter these in machine learning so it isn\u2019t something we have to worry about. The important point to note is that classification takes any natural number value, whilst regression takes any real numbered value.\n\nThe Components of an ML Problem\n\nWe have mentioned the terms features and labels, we will define them now.\n\nMultiple data points make up a dataset.\u00a0Data points are also called instances. Our machine learning algorithm will use a dataset to create its\u00a0hypothesis function (estimation function)\u00a0or find a pattern.\n\nIn supervised learning, a data point is made up of a series of inputs, denoted by\u00a0*X*, which we call features, and an output, denoted by\u00a0*y*, which we call labels. We can group them as tuples in the notation\u00a0*{X,y}*.\n\nLabels are what our hypothesis function\u00a0*h(x)*\u00a0tries to predict. Features are what our hypothesis function\u00a0*h(x)*\u00a0will use to predict our label.\n\nIt is assumed that there is some implicit relationship between x and y, otherwise we will be attempting to predict an output based on a variable that doesn\u2019t actually provide any relevant information. This will likely create an inaccurate and fairly useless algorithm.\n\nIt\u2019s important to note that for a given problem, all data points must have the same fixed length set of features. We can\u2019t pass in different lengths because our algorithm won\u2019t be able to generalise.\n\nSo what are the components of a machine learning problem?\n\nLet\u2019s take an example scenario and try to model it.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/s2jsylwfqce71.png?width=999&amp;format=png&amp;auto=webp&amp;s=ce11bb3094e9c169bd93c815bdee06f416b93b1f\n\nLet\u2019s say that\u00a0*x*, our features, are a series of weights of people, measured in kg with a range of 50kg \u2014 120kg. We\u2019ll say that y is the corresponding heights of those people, measured in cm and ranging from 150cm \u2014 200cm. We want to find the best way to use the\u00a0*x*\u00a0value to predict the\u00a0*y.*\u00a0We can start by plotting these points, they might look a little bit like the following diagram. If we decide to use a linear regression to estimate our data, we can plot the straight line estimation on our graph. From graph theory, we know that this line will take the form\u00a0*y = mx + c*, where\u00a0*m*\u00a0is the gradient of the line and\u00a0*c*\u00a0is the y-intercept. In ML theory, we convert this into an\u00a0estimation function:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/649et82hqce71.png?width=252&amp;format=png&amp;auto=webp&amp;s=5908bc5a359f67c998b0c84953985d6f0ddd8d75\n\nIn univariate linear regression, that is regression with a single\u00a0*x*\u00a0variable, our solution space is all possible values of theta\\_0 and theta\\_1.\n\nSo the\u00a0*h(x)*\u00a0that is produced by our model is our training algorithm. We are currently in the stage of training our algorithm and we haven\u2019t provided any unseen data yet to see how well it generalises.\n\nWe have stated a training algorithm, in the example above, to be the algorithm\u00a0*h(x)*.\u00a0The theta parameters are essentially what our algorithm tries to learn. By looking through all our feature and label combinations, it tries to find the best values for theta. The \u201cbest\u201d value will be calculated based on whatever our performance metric is, so our algorithm will pick a set of theta values that provide the optimal performance value.\n\nNote that the above example is an extremely simplified version. It is highly likely that our dataset will contain many more than one feature and we may have hundreds or thousands of theta parameters.\n\nParameters\n\nThere are two types of parameters for any machine learning model.\n\nWe have\u00a0intrinsic parameters, which are parameters unique to each model we build. These are the parameters learned by the model such as\u00a0coefficients in a linear regression\u00a0like in the example above or\u00a0weights in an artificial neural network.\u00a0These are essentially the components of our hypothesis function.\n\nWe also have\u00a0hyper parameters, which can be adjusted by the user and are chosen based on the best performance that they provide. These are far smaller in number than intrinsic parameters. Examples of these are the number of nodes in an artificial neural network, degree of a polynomial for multiple linear regression or the number of features we provide per instance.", "link": "https://www.reddit.com/r/MachineLearning/comments/oukl03/project_an_introduction_to_machine_learning_a/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "\"[project]\" an introduction to machine learning (a sample article) /!/ *the following is a sample article from a newsletter i run, called algo-fin. this article introduces the common concepts of machine learning, the practical use of which will come in future articles when we attempt to model the markets.*\n\n*algo-fin aims to provide an alternative study of the financial markets, where the focus isn\u2019t on drawing lines on charts or trying to identify head and shoulders patterns, but instead focusing on what truly drives these markets, the components of the economies. algo-fin is a macroeconomic study of the proponents of supply and demand in the forex markets, through the understanding of the theory, presentation of clear and insightful visualisations and the building of algorithms in order to try and predict future performance. if you\u2019re interested in subscribing, you can for free at* [*algofin.substack.com*](http://algofin.substack.com/)*. thanks for joining!*\n\n\\---\n\nan introduction\n\n&gt;\u201c\\[machine learning is a\\] field of study that gives computers the ability to learn without being explicitly programmed.\u201d (arthur samuel, 1959)\n\narthur samuel, considered to be the originator of the term \u201cmachine learning\u201d defined it with the above quote. this definition still stands today but has been developed with time.\n\n&gt;\u201ca computer program is said to learn from experience e with respect to some task t and some performance measure p, if its performance on t, as measured by p, improves with experience e.\u201d\u00a0(tom mitchell, 1998)\n\ntom mitchell, a computer science professor at carnegie mellon university defined a well-structured machine learning problem in 1998 with the above description.\n\nlet\u2019s break both of these quotes down a little further. the key element in both of these definitions is the word \u201clearn\u201d and that\u2019s exactly what the foundation of machine learning is \u2014 we want machines to learn without us specifically telling them what should be learned.\n\ntypically, we might want our algorithm to learn how to get from one point to another. that\u00a0initial point\u00a0could be\u00a0a dataset of factors\u00a0that describe a situation, such as body measurements of a person for example \u2014 height, weight, bmi, blood pressure levels etc, and our\u00a0final point\u00a0that we want our algorithm to reach could be the life expectancy of that particular person.\n\nultimately, what we want to do is to provide the start point and the endpoint of our journey and tell the algorithm to figure out which path to take \u2014 that\u2019s what we classify as learning.\n\nthis is typical to what we call a \u201csupervised learning\u201d problem \u2014 unsupervised learning is the alternative, which does not in fact declare a specific endpoint, but instead tells the algorithm to locate similarities between all of the data points.\n\nthe commonality however, is that we do still start without initial dataset and then provide an indication to our algorithm of what we want the output to look like, with varying levels of specification.\n\nin the second definition, we can consider our experience e to be our initial input dataset, the task t to be the instruction that this dataset must be trained to match our output dataset and our performance p as being some form of accuracy metric that essentially informs us of how well a model is performing.\n\nintroducing functions\n\nso how does all this learning happen? well, from a high-level view, it happens through the concept of functions. for those that may not be completely familiar, a function is a relation from a set of inputs to a set of possible outputs\\[1\\]. if we look at what our definition of machine learning is, the role of the function is exactly what we want our machine to learn, or estimate. we want it to know how to get from our inputs to our outputs, essentially find out what the relation is.\n\nthe goal of any machine learning algorithm therefore, is to find the best possible approximation for our function that takes our input variables to as close to our output variables as possible.\n\nthe word\u00a0generalisation\u00a0is how we apply this to future scenarios. essentially, what we have built is a relationship between our inputs and outputs. but what if we now give our relationship a new set of inputs? will it still be able to transform these unseen inputs into the correct set of outputs?\u00a0generalisation is the ability to make correct predictions on unseen data.\n\nultimately, that is what we want our machine learning algorithms to do. we want them to understand relationships in the data that stand the test of data they haven\u2019t seen before.\n\nthe mathematical notation of all the terms described above is noted here:\n\n&amp;#x200b;\n\nhttps://preview.redd.it/ct6mk7lbqce71.png?width=999&amp;format=png&amp;auto=webp&amp;s=4e640975c1b53e8c6fdbf82186eb744ef42afe6e\n\nlet\u2019s look a little further into this concept of functions.\n\n&amp;#x200b;\n\nhttps://preview.redd.it/8ilfeuncqce71.png?width=999&amp;format=png&amp;auto=webp&amp;s=414e2b74dfb205f5749231212956296c14e66e7a\n\nwe\u2019ve plotted 4 known data points on a graph and we expect them to have some form of underlying relationship that we are looking to estimate. we\u2019ll call the underlying function\u00a0*f(x)*\u00a0and we have produced 3 basic estimation models, that we call\u00a0*h(x)*.\n\nthe first estimation method is just to draw a line connecting each datapoint. this provides us with a perfect fit for our seen data because we have estimated the exact\u00a0*f(x)*\u00a0value at every\u00a0*x*\u00a0point. this model however has no generalisable properties and if we add an unseen datapoint (the point in red), our model will have no way of estimating this since there is no procedure in place for this\u00a0*x*\u00a0value.\n\nalternatively, we could use a 3rd order polynomial, which appears to be another good fit for the seen data points. it gathers the general shape of the points and depending on where the unseen datapoint is plotted, this model has the ability to generalise.\n\na 1st order polynomial in the above case is a straight line. we can see that it doesn\u2019t provide a perfect fit due to the shape of the input data, but again, depending on our\u00a0*x*\u00a0and\u00a0*f(x)*\u00a0relationship, this estimation has the ability to generalise to our unseen data.\n\nthis concept is one of the most important to keep in mind about machine learning. we are not looking for the perfect model, because we don\u2019t expect this perfect model to generalise.\u00a0we\u2019re looking for the best estimation to the data we know in the hope it will also perform well on the data we haven\u2019t exposed the model to yet. in addition to this, the final 2 graphs informs us that the model we choose is always unique to the problem that we are aiming to solve, there is no \u201cone size fits all.\u201d\n\nthis brings us to the next conversation \u2014 machine learning vs pattern recognition. these are often terms that get grouped together and used interchangeably, but they do actually have unique definitions.\n\npattern recognition and machine learning\n\nmachine learning is learning from experience, the experience being a set of input data that we provide for our algorithm. in machine learning, our experience, task and performance are clearly defined. machine learning is also called supervised learning, because we provide both an input and a target output in our data.\n\npattern recognition is the process of finding patterns in our data. it is also called unsupervised learning because, instead of telling the model specifically what the output should be, we ask it to find patterns and relationships within the data. our experience e will be only feature variables with no target output and our task and performance are more broadly defined because we don\u2019t have a specific path we want our algorithm to follow.\n\nit\u2019s easiest if we consider a couple of examples\n\n* data consisting of 1 feature \u2014 age and 1 label \u2014 height \u2192 univariate supervised learning\n* data consisting of 3 features \u2014 age, height, gender and 1 label \u2014 life expectancy \u2192 multivariable supervised learning\n* data consisting of 1 feature \u2014 a series of prices of the dow jones index, with the aim of classifying the prices into similar groupings \u2192 univariate unsupervised learning\n* data consisting of 3 features \u2014 attributes of a song, tempo, length and key, with the aim of classifying them into groups of similar songs that can hopefully be separable by genre \u2192 multivariate unsupervised learning\n\nsupervised learning\n\nsupervised learning can generally be split into two main categories \u2014 classification and regression.\n\nclassification is a machine learning task where we have a discrete set of outcomes. classification is often binary, meaning that there are two possible options for the outcome, normally yes/no or 1/0. examples of classification include face detection, smile detection, spam classification.\n\nregression is a machine learning task where we have a real-valued outcome in a continuous sub-space. basically, this means that our outcome is a continuous variable, but that it is usually confined to some sort of range. examples of regression include age estimation, stock value prediction, temperature prediction.\n\nmathematically we define these as follows:\n\n&amp;#x200b;\n\nhttps://preview.redd.it/lbmmobgeqce71.png?width=999&amp;format=png&amp;auto=webp&amp;s=05dd2c7c2dfde4839e05abd90f0b734100efc396\n\nin the diagram above, the\u00a0*n*\u00a0is the set of all natural numbers. these are all integers greater than 0. the set of natural numbers would look something like\u00a0*{1,2,3,4,\u2026}*. the\u00a0*r*\u00a0is the set of all real numbers. this includes all natural numbers, integers, rational and irrational numbers. the only values that the set of real numbers doesn\u2019t include are imaginary numbers, such as\u00a0*i*, used to represent the square root of -1, but we don\u2019t encounter these in machine learning so it isn\u2019t something we have to worry about. the important point to note is that classification takes any natural number value, whilst regression takes any real numbered value.\n\nthe components of an ml problem\n\nwe have mentioned the terms features and labels, we will define them now.\n\nmultiple data points make up a dataset.\u00a0data points are also called instances. our machine learning algorithm will use a dataset to create its\u00a0hypothesis function (estimation function)\u00a0or find a pattern.\n\nin supervised learning, a data point is made up of a series of inputs, denoted by\u00a0*x*, which we call features, and an output, denoted by\u00a0*y*, which we call labels. we can group them as tuples in the notation\u00a0*{x,y}*.\n\nlabels are what our hypothesis function\u00a0*h(x)*\u00a0tries to predict. features are what our hypothesis function\u00a0*h(x)*\u00a0will use to predict our label.\n\nit is assumed that there is some implicit relationship between x and y, otherwise we will be attempting to predict an output based on a variable that doesn\u2019t actually provide any relevant information. this will likely create an inaccurate and fairly useless algorithm.\n\nit\u2019s important to note that for a given problem, all data points must have the same fixed length set of features. we can\u2019t pass in different lengths because our algorithm won\u2019t be able to generalise.\n\nso what are the components of a machine learning problem?\n\nlet\u2019s take an example scenario and try to model it.\n\n&amp;#x200b;\n\nhttps://preview.redd.it/s2jsylwfqce71.png?width=999&amp;format=png&amp;auto=webp&amp;s=ce11bb3094e9c169bd93c815bdee06f416b93b1f\n\nlet\u2019s say that\u00a0*x*, our features, are a series of weights of people, measured in kg with a range of 50kg \u2014 120kg. we\u2019ll say that y is the corresponding heights of those people, measured in cm and ranging from 150cm \u2014 200cm. we want to find the best way to use the\u00a0*x*\u00a0value to predict the\u00a0*y.*\u00a0we can start by plotting these points, they might look a little bit like the following diagram. if we decide to use a linear regression to estimate our data, we can -----> plot !!!  the straight line estimation on our graph. from graph theory, we know that this line will take the form\u00a0*y = mx + c*, where\u00a0*m*\u00a0is the gradient of the line and\u00a0*c*\u00a0is the y-intercept. in ml theory, we convert this into an\u00a0estimation function:\n\n&amp;#x200b;\n\nhttps://preview.redd.it/649et82hqce71.png?width=252&amp;format=png&amp;auto=webp&amp;s=5908bc5a359f67c998b0c84953985d6f0ddd8d75\n\nin univariate linear regression, that is regression with a single\u00a0*x*\u00a0variable, our solution space is all possible values of theta\\_0 and theta\\_1.\n\nso the\u00a0*h(x)*\u00a0that is produced by our model is our training algorithm. we are currently in the stage of training our algorithm and we haven\u2019t provided any unseen data yet to see how well it generalises.\n\nwe have stated a training algorithm, in the example above, to be the algorithm\u00a0*h(x)*.\u00a0the theta parameters are essentially what our algorithm tries to learn. by looking through all our feature and label combinations, it tries to find the best values for theta. the \u201cbest\u201d value will be calculated based on whatever our performance metric is, so our algorithm will pick a set of theta values that provide the optimal performance value.\n\nnote that the above example is an extremely simplified version. it is highly likely that our dataset will contain many more than one feature and we may have hundreds or thousands of theta parameters.\n\nparameters\n\nthere are two types of parameters for any machine learning model.\n\nwe have\u00a0intrinsic parameters, which are parameters unique to each model we build. these are the parameters learned by the model such as\u00a0coefficients in a linear regression\u00a0like in the example above or\u00a0weights in an artificial neural network.\u00a0these are essentially the components of our hypothesis function.\n\nwe also have\u00a0hyper parameters, which can be adjusted by the user and are chosen based on the best performance that they provide. these are far smaller in number than intrinsic parameters. examples of these are the number of nodes in an artificial neural network, degree of a polynomial for multiple linear regression or the number of features we provide per instance.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/oukl03/project_an_introduction_to_machine_learning_a/',)", "identifyer": 5722114, "year": "2021"}, {"autor": "l34df4rm3r", "date": 1630405733000, "content": "[D] Visualizing node representations for graph convolutional networks /!/ I was looking at Thomas Kipf's page on [Graph Convolutional Networks ](https://tkipf.github.io/graph-convolutional-networks/) and on the page, he has a neat animation of how the node features are forming clusters according to their classes. Here is a direct link to the video: [https://tkipf.github.io/graph-convolutional-networks/images/video.mp4](https://tkipf.github.io/graph-convolutional-networks/images/video.mp4)\n\nThis form of visualization can be really helpful to see if a training process is being adversely affected by too much oversmoothing. However, I can't find the code for it. What python libraries are good for plotting networks like this?\n\nI can make a 2D UMap plot showing the node clusters, but I can't figure out how to draw the edges.", "link": "https://www.reddit.com/r/MachineLearning/comments/pf34gu/d_visualizing_node_representations_for_graph/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] visualizing node representations for graph convolutional networks /!/ i was looking at thomas kipf's page on [graph convolutional networks ](https://tkipf.github.io/graph-convolutional-networks/) and on the page, he has a neat animation of how the node features are forming clusters according to their classes. here is a direct link to the video: [https://tkipf.github.io/graph-convolutional-networks/images/video.mp4](https://tkipf.github.io/graph-convolutional-networks/images/video.mp4)\n\nthis form of visualization can be really helpful to see if a training process is being adversely affected by too much oversmoothing. however, i can't find the code for it. what python libraries are good for plotting networks like this?\n\ni can make a 2d umap -----> plot !!!  showing the node clusters, but i can't figure out how to draw the edges.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pf34gu/d_visualizing_node_representations_for_graph/',)", "identifyer": 5722177, "year": "2021"}, {"autor": "stormleone2", "date": 1630352780000, "content": "Help visualizing loss surface plot", "link": "https://www.reddit.com/r/MachineLearning/comments/pepljg/help_visualizing_loss_surface_plot/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "help visualizing loss surface -----> plot !!! ", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('/r/artificial/comments/pepfyv/help_visualizing_loss_surface_plot/',)", "identifyer": 5722215, "year": "2021"}, {"autor": "zahrael97", "date": 1633085868000, "content": "[D] ROC PLOT using cross-validation /!/ how to plot the mean of ROC using cross validation", "link": "https://www.reddit.com/r/MachineLearning/comments/pz5kvx/d_roc_plot_using_crossvalidation/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] roc -----> plot !!!  using cross-validation /!/ how to plot the mean of roc using cross validation", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pz5kvx/d_roc_plot_using_crossvalidation/',)", "identifyer": 5722234, "year": "2021"}, {"autor": "zahrael97", "date": 1633085785000, "content": "ROC plot using crosss_validation #machine_learning /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/pz5k7v/roc_plot_using_crosss_validation_machine_learning/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "roc -----> plot !!!  using crosss_validation #machine_learning /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pz5k7v/roc_plot_using_crosss_validation_machine_learning/',)", "identifyer": 5722235, "year": "2021"}, {"autor": "zahrael97", "date": 1633085747000, "content": "ROC plot using cross_validation /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/pz5jwa/roc_plot_using_cross_validation/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "roc -----> plot !!!  using cross_validation /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pz5jwa/roc_plot_using_cross_validation/',)", "identifyer": 5722236, "year": "2021"}, {"autor": "zahrael97", "date": 1633085641000, "content": "ROC plot using cross validation /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/pz5j0g/roc_plot_using_cross_validation/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "roc -----> plot !!!  using cross validation /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pz5j0g/roc_plot_using_cross_validation/',)", "identifyer": 5722237, "year": "2021"}, {"autor": "Calligraphiti", "date": 1615944598000, "content": "[P] Need help applying Perceptron learning algorithm to data with multiple features. It needs to be graphed. /!/ I'm in a short course about machine learning and we were introduced to Perceptron. Our first homework assignment had us plot a small handful of data points, which were clearly defined points in R^2 such that they were separable. We were to use a random weight vector that we manually updated with the data so that eventually, the right points were properly separated. We did this graphically.\n\nNow we are supposed to do the same graphical separation, but the data we were given has 15 features instead of just 2. Do I just limit the number of features to what seems to correlate to each variable's y-value? I have no idea how to begin to show graphically how this data can be separated. How do I begin plotting this data? Any advice would be appreciated. I hope this is an okay place to ask.", "link": "https://www.reddit.com/r/MachineLearning/comments/m6ou58/p_need_help_applying_perceptron_learning/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[p] need help applying perceptron learning algorithm to data with multiple features. it needs to be graphed. /!/ i'm in a short course about machine learning and we were introduced to perceptron. our first homework assignment had us -----> plot !!!  a small handful of data points, which were clearly defined points in r^2 such that they were separable. we were to use a random weight vector that we manually updated with the data so that eventually, the right points were properly separated. we did this graphically.\n\nnow we are supposed to do the same graphical separation, but the data we were given has 15 features instead of just 2. do i just limit the number of features to what seems to correlate to each variable's y-value? i have no idea how to begin to show graphically how this data can be separated. how do i begin plotting this data? any advice would be appreciated. i hope this is an okay place to ask.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/m6ou58/p_need_help_applying_perceptron_learning/',)", "identifyer": 5722655, "year": "2021"}, {"autor": "Kenna_Pyralis", "date": 1629044785000, "content": "[D] Which AI is there to use that reads the most words from words inputted by the user? /!/ GPT 3 remembers up to 1500 words from the input text. GPT 2 remembered half of that. GPT 4 will probably remember a significant number more than GPT 3. I want to know which text generating Ai remembers the most words inputted by the user. I want to use it for helping me write the plot outline for my book.", "link": "https://www.reddit.com/r/MachineLearning/comments/p4wm66/d_which_ai_is_there_to_use_that_reads_the_most/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] which ai is there to use that reads the most words from words inputted by the user? /!/ gpt 3 remembers up to 1500 words from the input text. gpt 2 remembered half of that. gpt 4 will probably remember a significant number more than gpt 3. i want to know which text generating ai remembers the most words inputted by the user. i want to use it for helping me write the -----> plot !!!  outline for my book.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p4wm66/d_which_ai_is_there_to_use_that_reads_the_most/',)", "identifyer": 5724463, "year": "2021"}, {"autor": "Kenna_Pyralis", "date": 1629044006000, "content": "[D] which text generating AI remembers the most words inputted by the user /!/ GPT 3 remembers up to 1500 words from the input text. GPT 2 remembered half of that. GPT 4 will probably remember a significant number more than GPT 3. I want to know which text generating Ai remembers the most words inputted by the user. I want to use it for helping me write the plot outline for my book.", "link": "https://www.reddit.com/r/MachineLearning/comments/p4wdj3/d_which_text_generating_ai_remembers_the_most/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] which text generating ai remembers the most words inputted by the user /!/ gpt 3 remembers up to 1500 words from the input text. gpt 2 remembered half of that. gpt 4 will probably remember a significant number more than gpt 3. i want to know which text generating ai remembers the most words inputted by the user. i want to use it for helping me write the -----> plot !!!  outline for my book.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p4wdj3/d_which_text_generating_ai_remembers_the_most/',)", "identifyer": 5724464, "year": "2021"}, {"autor": "dot---", "date": 1615252137000, "content": "[Discussion] How many regions of different class does a typical neural network split its input space into? /!/ By definition, a classification model fractures its input space into a number of contiguous regions with different classes. With a one- or two-dimensional input, these regions are easy to visualize; for example, (this)[https://i.imgur.com/cwWvwPe.png] figure shows the class predictions for a neural network trained on 2D toy data. As far as this plot shows, there are five classification regions in total, the permeating orange one and the four distinct blue ones.\n\nI've been wondering recently about roughly how many classification cells you'd find in a real neural network, with high-d input, many layers, and perhaps 10 to 100 classes. Does anyone here know anything about this? Even if not, I'd be curious to hear your guesses, even if they're as vague as \"thousands\" or \"a number exponential in the input dimension.\"\n\nThanks!", "link": "https://www.reddit.com/r/MachineLearning/comments/m0v4if/discussion_how_many_regions_of_different_class/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[discussion] how many regions of different class does a typical neural network split its input space into? /!/ by definition, a classification model fractures its input space into a number of contiguous regions with different classes. with a one- or two-dimensional input, these regions are easy to visualize; for example, (this)[https://i.imgur.com/cwwvwpe.png] figure shows the class predictions for a neural network trained on 2d toy data. as far as this -----> plot !!!  shows, there are five classification regions in total, the permeating orange one and the four distinct blue ones.\n\ni've been wondering recently about roughly how many classification cells you'd find in a real neural network, with high-d input, many layers, and perhaps 10 to 100 classes. does anyone here know anything about this? even if not, i'd be curious to hear your guesses, even if they're as vague as \"thousands\" or \"a number exponential in the input dimension.\"\n\nthanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/m0v4if/discussion_how_many_regions_of_different_class/',)", "identifyer": 5724861, "year": "2021"}, {"autor": "zeeshas901", "date": 1619040559000, "content": "How could I plot the function g efficiently in a single plot for different intervals of t: -1&lt;t&lt;0, 0&lt;t&lt;1 and 1&lt;t&lt;3 in R when x1 and x2 are fixed?", "link": "https://www.reddit.com/r/MachineLearning/comments/mvpxlt/how_could_i_plot_the_function_g_efficiently_in_a/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "how could i -----> plot !!!  the function g efficiently in a single -----> plot !!!  for different intervals of t: -1&lt;t&lt;0, 0&lt;t&lt;1 and 1&lt;t&lt;3 in r when x1 and x2 are fixed?", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('image',)", "medialink": "('https://i.redd.it/o96vewhahlu61.jpg',)", "identifyer": 5725592, "year": "2021"}, {"autor": "SQL_beginner", "date": 1626233317000, "content": "[D] Can Machine Learning be used to Solve these kinds of Problems? /!/  I am working with R.\n\nSuppose you have the following data:\n\n    #generate data\n     set.seed(123) \n    a1 = rnorm(1000,100,10)\n     b1 = rnorm(1000,100,10)\n     c1 = rnorm(1000,5,1)\n     train_data = data.frame(a1,b1,c1)\n    \n     #view data          a1        b1       c1 \n    1 94.39524 90.04201 4.488396 \n    2 97.69823 89.60045 5.236938 \n    3 115.58708 99.82020 4.458411 \n    4 100.70508 98.67825 6.219228 \n    5 101.29288 74.50657 5.174136 \n    6 117.15065 110.40573 4.384732 \n\nWe can visualize the data as follows:\n\n    #visualize data par(mfrow=c(2,2)) \n     plot(train_data$a1, train_data$b1, col = train_data$c1, main = \"plot of a1 vs b1, points colored by c1\") \n    hist(train_data$a1) \n    hist(train_data$b1) \n    hist(train_data$c1) \n\n[https://i.stack.imgur.com/t641h.png](https://i.stack.imgur.com/t641h.png)\n\nHere is the **Problem** :\n\n1. From the data, only take variables \"a1\" and \"b1\" : using **only 2 \"logical conditions\"**, split this data into **3 regions** (e.g. Region 1 WHERE 20 &gt; a1 &gt;0 AND 0&lt; b1 &lt; 25)\n2. In each region, you want the \"average value of c1\" within that region to be as small as possible - but each region must have at least some minimum number of data points, e.g. 100 data points (to prevent trivial solutions)\n3. **Goal** : Is it possible to determine the \"boundaries\" of these 3 regions that minimizes :\n\n* the mean value of \"c1\" for region 1\n* the mean value of \"c1\" for region 2\n* the mean value of \"c1\" for region 3\n* the average \"mean value of c1 for all 3 regions\" (i.e. c\\_avg = (region1\\_c1\\_avg + region2\\_c1\\_avg + region3\\_c1\\_avg) / 3  \n)\n\nIn the end, for a given combination, you would find the following, e.g. (made up numbers):\n\n* Region 1 : WHERE 20&gt; a1 &gt;0 AND 0 &lt; b1 &lt; 25 ; region1\\_c1\\_avg = 4\n* Region 2 : WHERE 50&gt; a1 &gt;20 AND 25 &lt; b1 &lt; 60 ; region2\\_c1\\_avg = 2.9\n* Region 3 : WHERE a1&gt;50 AND b1 &gt; 60 ; region3\\_c1\\_avg = 1.9\n* c\\_avg = (4 + 2.9 + 1.9) / 3 = 2.93\n\nAnd hope that (region1\\_c1\\_avg, region2\\_c1\\_avg, region3\\_c1\\_avg and c\\_avg  \n) are minimized\n\n**My Question**:\n\n**Does this kind of problem have an \"exact solution\"?** The only thing I can think of is performing a \"random search\" that considers many different definitions of (Region 1, Region 2 and Region 3  \n) and compares the corresponding values of (region1\\_c1\\_avg, region2\\_c1\\_avg, region3\\_c1\\_avg and c\\_avg  \n), until a minimum value is found. Is this an application of linear programming or multi-objective optimization (e.g. genetic algorithm)? Has anyone worked on something like this before?\n\nI have done a lot of research and haven't found a similar problem like this. I decided to formulate this problem as a \"multi-objective constrained optimization problem\", and figured out how to implement algorithms like \"random search\" and \"genetic algorithm\". **Can someone please confirm if my general approach to this problem makes sense?**\n\nThanks\n\n**Note 1:** In the context of multi-objective optimization, for a given set of definitions of (Region1, Region2 and Region3  \n): to collectively compare whether a set of values for (region1\\_c1\\_avg, region2\\_c1\\_avg, region3\\_c1\\_avg and c\\_avg  \n) are satisfactory, the concept of \"Pareto Optimality\" ([https://en.wikipedia.org/wiki/Multi-objective\\_optimization#Visualization\\_of\\_the\\_Pareto\\_front](https://en.wikipedia.org/wiki/Multi-objective_optimization#Visualization_of_the_Pareto_front)) is often used to make comparisons between different sets of {(Region1, Region2 and Region3  \n) and (region1\\_c1\\_avg, region2\\_c1\\_avg, region3\\_c1\\_avg and c\\_avg  \n)}\n\n**Note 2** : Ultimately, these 3 Regions can defined by any set of 4 numbers. If each of these 4 numbers can be between \"0 and 100\", and through 0.1 increments (e.g. 12, 12.1, 12.2, 12.3, etc) : this means that there exists 1000 \\^ 4 = 1 e\\^12 possible solutions (roughly 1 trillion) to compare. There are simply far too many solutions to individually verify and compare. I am thinking that a mathematical based search/optimization problem can be used to strategically search for an optimal solution.", "link": "https://www.reddit.com/r/MachineLearning/comments/ojvunx/d_can_machine_learning_be_used_to_solve_these/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] can machine learning be used to solve these kinds of problems? /!/  i am working with r.\n\nsuppose you have the following data:\n\n    #generate data\n     set.seed(123) \n    a1 = rnorm(1000,100,10)\n     b1 = rnorm(1000,100,10)\n     c1 = rnorm(1000,5,1)\n     train_data = data.frame(a1,b1,c1)\n    \n     #view data          a1        b1       c1 \n    1 94.39524 90.04201 4.488396 \n    2 97.69823 89.60045 5.236938 \n    3 115.58708 99.82020 4.458411 \n    4 100.70508 98.67825 6.219228 \n    5 101.29288 74.50657 5.174136 \n    6 117.15065 110.40573 4.384732 \n\nwe can visualize the data as follows:\n\n    #visualize data par(mfrow=c(2,2)) \n     plot(train_data$a1, train_data$b1, col = train_data$c1, main = \"-----> plot !!!  of a1 vs b1, points colored by c1\") \n    hist(train_data$a1) \n    hist(train_data$b1) \n    hist(train_data$c1) \n\n[https://i.stack.imgur.com/t641h.png](https://i.stack.imgur.com/t641h.png)\n\nhere is the **problem** :\n\n1. from the data, only take variables \"a1\" and \"b1\" : using **only 2 \"logical conditions\"**, split this data into **3 regions** (e.g. region 1 where 20 &gt; a1 &gt;0 and 0&lt; b1 &lt; 25)\n2. in each region, you want the \"average value of c1\" within that region to be as small as possible - but each region must have at least some minimum number of data points, e.g. 100 data points (to prevent trivial solutions)\n3. **goal** : is it possible to determine the \"boundaries\" of these 3 regions that minimizes :\n\n* the mean value of \"c1\" for region 1\n* the mean value of \"c1\" for region 2\n* the mean value of \"c1\" for region 3\n* the average \"mean value of c1 for all 3 regions\" (i.e. c\\_avg = (region1\\_c1\\_avg + region2\\_c1\\_avg + region3\\_c1\\_avg) / 3  \n)\n\nin the end, for a given combination, you would find the following, e.g. (made up numbers):\n\n* region 1 : where 20&gt; a1 &gt;0 and 0 &lt; b1 &lt; 25 ; region1\\_c1\\_avg = 4\n* region 2 : where 50&gt; a1 &gt;20 and 25 &lt; b1 &lt; 60 ; region2\\_c1\\_avg = 2.9\n* region 3 : where a1&gt;50 and b1 &gt; 60 ; region3\\_c1\\_avg = 1.9\n* c\\_avg = (4 + 2.9 + 1.9) / 3 = 2.93\n\nand hope that (region1\\_c1\\_avg, region2\\_c1\\_avg, region3\\_c1\\_avg and c\\_avg  \n) are minimized\n\n**my question**:\n\n**does this kind of problem have an \"exact solution\"?** the only thing i can think of is performing a \"random search\" that considers many different definitions of (region 1, region 2 and region 3  \n) and compares the corresponding values of (region1\\_c1\\_avg, region2\\_c1\\_avg, region3\\_c1\\_avg and c\\_avg  \n), until a minimum value is found. is this an application of linear programming or multi-objective optimization (e.g. genetic algorithm)? has anyone worked on something like this before?\n\ni have done a lot of research and haven't found a similar problem like this. i decided to formulate this problem as a \"multi-objective constrained optimization problem\", and figured out how to implement algorithms like \"random search\" and \"genetic algorithm\". **can someone please confirm if my general approach to this problem makes sense?**\n\nthanks\n\n**note 1:** in the context of multi-objective optimization, for a given set of definitions of (region1, region2 and region3  \n): to collectively compare whether a set of values for (region1\\_c1\\_avg, region2\\_c1\\_avg, region3\\_c1\\_avg and c\\_avg  \n) are satisfactory, the concept of \"pareto optimality\" ([https://en.wikipedia.org/wiki/multi-objective\\_optimization#visualization\\_of\\_the\\_pareto\\_front](https://en.wikipedia.org/wiki/multi-objective_optimization#visualization_of_the_pareto_front)) is often used to make comparisons between different sets of {(region1, region2 and region3  \n) and (region1\\_c1\\_avg, region2\\_c1\\_avg, region3\\_c1\\_avg and c\\_avg  \n)}\n\n**note 2** : ultimately, these 3 regions can defined by any set of 4 numbers. if each of these 4 numbers can be between \"0 and 100\", and through 0.1 increments (e.g. 12, 12.1, 12.2, 12.3, etc) : this means that there exists 1000 \\^ 4 = 1 e\\^12 possible solutions (roughly 1 trillion) to compare. there are simply far too many solutions to individually verify and compare. i am thinking that a mathematical based search/optimization problem can be used to strategically search for an optimal solution.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ojvunx/d_can_machine_learning_be_used_to_solve_these/',)", "identifyer": 5725984, "year": "2021"}, {"autor": "human_treadstone", "date": 1623151170000, "content": "[D] confusion matrix plot in few/single shot learning /!/ In few shot learning(FSL) in every episodes they sample N classes(say 5) out of all available classes and then model predict its output classes. During model prediction stage all labels are reconverted to 0-4 for 5 way 1shot classification no matter what their actual value is.  I wanted to plot the confusion matrix but this is not possible as both actual label and predicted label are always in 0-4 range instead of actual labels. Is it possible to get model prediction in terms of actual label or any other pointer so that I can plot confusion matrix in FSL  experiments.", "link": "https://www.reddit.com/r/MachineLearning/comments/nv1ox4/d_confusion_matrix_plot_in_fewsingle_shot_learning/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] confusion matrix -----> plot !!!  in few/single shot learning /!/ in few shot learning(fsl) in every episodes they sample n classes(say 5) out of all available classes and then model predict its output classes. during model prediction stage all labels are reconverted to 0-4 for 5 way 1shot classification no matter what their actual value is.  i wanted to plot the confusion matrix but this is not possible as both actual label and predicted label are always in 0-4 range instead of actual labels. is it possible to get model prediction in terms of actual label or any other pointer so that i can plot confusion matrix in fsl  experiments.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 6, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nv1ox4/d_confusion_matrix_plot_in_fewsingle_shot_learning/',)", "identifyer": 5726776, "year": "2021"}, {"autor": "Mariam_Dundua", "date": 1624296867000, "content": "[D] Shap value for LSTM model /!/  \n\nI have lstm model named lstm\\_model  \n and I am using shap value to explain model. have tabular data.\n\n     import shap    explainer = shap.DeepExplainer(lstm_model, X_train)   shap_values = explainer.shap_values(X_test) \n\nFrom My knowledge in order to calculate the shap value, It uses a 2\\^(number of features) model. I am interesting in what is kind of algorithm it uses for each individual model.  \nThis question comes from the following fact:\n\nWhen I am plotting of effect x  \n feature on output, this effect is linear(increasing or decreasing). For example when x  \n increasing the effect increases (decreasing). What is the reason behind this?\n\nOne additional question:  \nIs it possible to use shap to plot partial dependence plot for the LSTM model?", "link": "https://www.reddit.com/r/MachineLearning/comments/o50nh7/d_shap_value_for_lstm_model/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] shap value for lstm model /!/  \n\ni have lstm model named lstm\\_model  \n and i am using shap value to explain model. have tabular data.\n\n     import shap    explainer = shap.deepexplainer(lstm_model, x_train)   shap_values = explainer.shap_values(x_test) \n\nfrom my knowledge in order to calculate the shap value, it uses a 2\\^(number of features) model. i am interesting in what is kind of algorithm it uses for each individual model.  \nthis question comes from the following fact:\n\nwhen i am plotting of effect x  \n feature on output, this effect is linear(increasing or decreasing). for example when x  \n increasing the effect increases (decreasing). what is the reason behind this?\n\none additional question:  \nis it possible to use shap to -----> plot !!!  partial dependence -----> plot !!!  for the lstm model?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o50nh7/d_shap_value_for_lstm_model/',)", "identifyer": 5727262, "year": "2021"}, {"autor": "DonDuarte", "date": 1635358020000, "content": "[P] I'm trying to program a mean average precision calculator, help me out! /!/ Hello!\n\nI have a dataset of boats that I'm using to train a YOLO based detector through transfer learning and I want to compare the performance of different training exercises. For this I built a mean average precision calculator that takes the .txt files with the annotated ground truths and compares them to the .txt files generated by the trained detector module.\n\nI don't have True Negatives as those would be every spot in an image where there isn't an object or prediction. True Positives are predictions where the IoU with the ground truth is inside the IoU threshold. \n\nBut then the negatives kinda confuse me. I added as False Negatives every object in the ground truth files that doesn't have a corresponding prediction with an IoU above the threshold. The False Positives are all the predictions left over (without a corresponding ground truth).\n\nSo precision would be: TRUE\\_POSITIVE/(TRUE\\_POSITIVE+FALSE\\_POSITIVE)\n\nAnd recall would be: TRUE\\_POSITIVE/(TRUE\\_POSITIVE+FALSE\\_NEGATIVE)\n\nHowever, with this, my precision and recall both have the same growth tendency. If I plot x/y with x being recall and y being precision, the dots will form a line with a positive slope when I know they should form a negative slope. Turns out that for example, when there is a predicted box of IoU = 0.2. If the threshold is 0.3 then it doesn't become a TRUE POSITIVE but it will generate a FALSE POSITIVE (prediction without corresponding ground truth) and a FALSE NEGATIVE (ground truth without a prediction). My throught process is wrong but I don't know how it is really done. What are FALSE NEGATIVES and FALSE POSITIVES?\n\n&amp;#x200B;\n\nHere's my code: [https://pastebin.com/Mu7DGrZf](https://pastebin.com/Mu7DGrZf)", "link": "https://www.reddit.com/r/MachineLearning/comments/qh2pfr/p_im_trying_to_program_a_mean_average_precision/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[p] i'm trying to program a mean average precision calculator, help me out! /!/ hello!\n\ni have a dataset of boats that i'm using to train a yolo based detector through transfer learning and i want to compare the performance of different training exercises. for this i built a mean average precision calculator that takes the .txt files with the annotated ground truths and compares them to the .txt files generated by the trained detector module.\n\ni don't have true negatives as those would be every spot in an image where there isn't an object or prediction. true positives are predictions where the iou with the ground truth is inside the iou threshold. \n\nbut then the negatives kinda confuse me. i added as false negatives every object in the ground truth files that doesn't have a corresponding prediction with an iou above the threshold. the false positives are all the predictions left over (without a corresponding ground truth).\n\nso precision would be: true\\_positive/(true\\_positive+false\\_positive)\n\nand recall would be: true\\_positive/(true\\_positive+false\\_negative)\n\nhowever, with this, my precision and recall both have the same growth tendency. if i -----> plot !!!  x/y with x being recall and y being precision, the dots will form a line with a positive slope when i know they should form a negative slope. turns out that for example, when there is a predicted box of iou = 0.2. if the threshold is 0.3 then it doesn't become a true positive but it will generate a false positive (prediction without corresponding ground truth) and a false negative (ground truth without a prediction). my throught process is wrong but i don't know how it is really done. what are false negatives and false positives?\n\n&amp;#x200b;\n\nhere's my code: [https://pastebin.com/mu7dgrzf](https://pastebin.com/mu7dgrzf)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/qh2pfr/p_im_trying_to_program_a_mean_average_precision/',)", "identifyer": 5727626, "year": "2021"}, {"autor": "ameyashetty1739", "date": 1634139475000, "content": "Box plot not showing up on my graph /!/ Heres the code below", "link": "https://www.reddit.com/r/MachineLearning/comments/q7dst8/box_plot_not_showing_up_on_my_graph/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "box -----> plot !!!  not showing up on my graph /!/ heres the code below", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/q7dst8/box_plot_not_showing_up_on_my_graph/',)", "identifyer": 5727815, "year": "2021"}, {"autor": "RS_Tnap", "date": 1613015206000, "content": "Trouble calling the tensorflow model after successfully compiling it [P] /!/ I am a beginner in machine learning and have created a sequential model using tf keras. I am confused on how to use my\\_model to get a predictions based on one instance. The model uses 4 features columns and tries to determine the label \"diff\". I have posted the model code for context. The following code is from google machine learning crash course and my model is able to be compiled. I am confused on how to use the generated model to predict a value. My model code will be posted under the prediction code(calling my model)\n\n    x={'homePAG':np.int64(7), 'awayPAG':np.int64(7), 'homePPG':np.int64(7), 'awayPPG':np.int64(7)} my_model.predict(x) \n\nThe error given is :\n\n&gt;ValueError: Failed to find data adapter that can handle input: (&lt;class 'dict'&gt; containing {\"&lt;class 'str'&gt;\"} keys and {\"&lt;class 'numpy.int64'&gt;\"} values), &lt;class 'NoneType'&gt;\n\nAttempting to change the shape:\n\n    z=np.array([[10,10,10,10]]) my_model.predict(z) \n\n&gt;ValueError: ('We expected a dictionary here. Instead we got: ', &lt;tf.Tensor 'IteratorGetNext:0' shape=(None, 4) dtype=int64&gt;)\n\nBelow is the model code from google crashcourse with machine learning.\n\n    feature_columns = []  homePAG = tf.feature_column.numeric_column(\"homePAG\") feature_columns.append(homePAG)  awayPAG = tf.feature_column.numeric_column(\"awayPAG\") feature_columns.append(awayPAG)  homePPG = tf.feature_column.numeric_column(\"homePPG\") feature_columns.append(homePPG)  awayPPG = tf.feature_column.numeric_column(\"awayPPG\") feature_columns.append(awayPPG)  fp_feature_layer = layers.DenseFeatures(feature_columns)  def create_model(my_learning_rate, feature_layer):   \"\"\"Create and compile a simple linear regression model.\"\"\"   # Most simple tf.keras models are sequential.   model = tf.keras.models.Sequential()    # Add the layer containing the feature columns to the model.   model.add(feature_layer)    # Add one linear layer to the model to yield a simple linear regressor.   model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))    # Construct the layers into a model that TensorFlow can execute.   model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),                 loss=\"mean_squared_error\",                 metrics=[tf.keras.metrics.RootMeanSquaredError()])    return model              def train_model(model, dataset, epochs, batch_size, label_name):   \"\"\"Feed a dataset into the model in order to train it.\"\"\"    features = {name:np.array(value) for name, value in dataset.items()}   label = np.array(features.pop(label_name))   history = model.fit(x=features, y=label, batch_size=batch_size,                       epochs=epochs, shuffle=True)    # The list of epochs is stored separately from the rest of history.   epochs = history.epoch      # Isolate the mean absolute error for each epoch.   hist = pd.DataFrame(history.history)   rmse = hist[\"root_mean_squared_error\"]    return epochs, rmse      def plot_the_loss_curve(epochs, rmse):   \"\"\"Plot a curve of loss vs. epoch.\"\"\"    plt.figure()   plt.xlabel(\"Epoch\")   plt.ylabel(\"Root Mean Squared Error\")    plt.plot(epochs, rmse, label=\"Loss\")   plt.legend()   plt.ylim([rmse.min()*0.94, rmse.max()* 1.05])   plt.show()    print(\"Defined the create_model, train_model, and plot_the_loss_curve functions.\")  # The following variables are the hyperparameters. learning_rate = 0.01 epochs = 10 batch_size = 75 label_name = 'diff'  # Create and compile the model's topography. my_model = create_model(learning_rate, fp_feature_layer)  # Train the model on the training set. epochs, rmse = train_model(my_model, train_df, epochs, batch_size, label_name)  plot_the_loss_curve(epochs, rmse)  print(\"\\n: Evaluate the new model against the test set:\") test_features = {name:np.array(value) for name, value in test_df.items()} test_label = np.array(test_features.pop(label_name)) #test_label=tf.convert_to_tensor(test_label) my_model.evaluate(x=test_features, y=test_label, batch_size=batch_size) For this code I receive error :", "link": "https://www.reddit.com/r/MachineLearning/comments/lhc51b/trouble_calling_the_tensorflow_model_after/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "trouble calling the tensorflow model after successfully compiling it [p] /!/ i am a beginner in machine learning and have created a sequential model using tf keras. i am confused on how to use my\\_model to get a predictions based on one instance. the model uses 4 features columns and tries to determine the label \"diff\". i have posted the model code for context. the following code is from google machine learning crash course and my model is able to be compiled. i am confused on how to use the generated model to predict a value. my model code will be posted under the prediction code(calling my model)\n\n    x={'homepag':np.int64(7), 'awaypag':np.int64(7), 'homeppg':np.int64(7), 'awayppg':np.int64(7)} my_model.predict(x) \n\nthe error given is :\n\n&gt;valueerror: failed to find data adapter that can handle input: (&lt;class 'dict'&gt; containing {\"&lt;class 'str'&gt;\"} keys and {\"&lt;class 'numpy.int64'&gt;\"} values), &lt;class 'nonetype'&gt;\n\nattempting to change the shape:\n\n    z=np.array([[10,10,10,10]]) my_model.predict(z) \n\n&gt;valueerror: ('we expected a dictionary here. instead we got: ', &lt;tf.tensor 'iteratorgetnext:0' shape=(none, 4) dtype=int64&gt;)\n\nbelow is the model code from google crashcourse with machine learning.\n\n    feature_columns = []  homepag = tf.feature_column.numeric_column(\"homepag\") feature_columns.append(homepag)  awaypag = tf.feature_column.numeric_column(\"awaypag\") feature_columns.append(awaypag)  homeppg = tf.feature_column.numeric_column(\"homeppg\") feature_columns.append(homeppg)  awayppg = tf.feature_column.numeric_column(\"awayppg\") feature_columns.append(awayppg)  fp_feature_layer = layers.densefeatures(feature_columns)  def create_model(my_learning_rate, feature_layer):   \"\"\"create and compile a simple linear regression model.\"\"\"   # most simple tf.keras models are sequential.   model = tf.keras.models.sequential()    # add the layer containing the feature columns to the model.   model.add(feature_layer)    # add one linear layer to the model to yield a simple linear regressor.   model.add(tf.keras.layers.dense(units=1, input_shape=(1,)))    # construct the layers into a model that tensorflow can execute.   model.compile(optimizer=tf.keras.optimizers.rmsprop(lr=my_learning_rate),                 loss=\"mean_squared_error\",                 metrics=[tf.keras.metrics.rootmeansquarederror()])    return model              def train_model(model, dataset, epochs, batch_size, label_name):   \"\"\"feed a dataset into the model in order to train it.\"\"\"    features = {name:np.array(value) for name, value in dataset.items()}   label = np.array(features.pop(label_name))   history = model.fit(x=features, y=label, batch_size=batch_size,                       epochs=epochs, shuffle=true)    # the list of epochs is stored separately from the rest of history.   epochs = history.epoch      # isolate the mean absolute error for each epoch.   hist = pd.dataframe(history.history)   rmse = hist[\"root_mean_squared_error\"]    return epochs, rmse      def plot_the_loss_curve(epochs, rmse):   \"\"\"-----> plot !!!  a curve of loss vs. epoch.\"\"\"    plt.figure()   plt.xlabel(\"epoch\")   plt.ylabel(\"root mean squared error\")    plt.plot(epochs, rmse, label=\"loss\")   plt.legend()   plt.ylim([rmse.min()*0.94, rmse.max()* 1.05])   plt.show()    print(\"defined the create_model, train_model, and plot_the_loss_curve functions.\")  # the following variables are the hyperparameters. learning_rate = 0.01 epochs = 10 batch_size = 75 label_name = 'diff'  # create and compile the model's topography. my_model = create_model(learning_rate, fp_feature_layer)  # train the model on the training set. epochs, rmse = train_model(my_model, train_df, epochs, batch_size, label_name)  plot_the_loss_curve(epochs, rmse)  print(\"\\n: evaluate the new model against the test set:\") test_features = {name:np.array(value) for name, value in test_df.items()} test_label = np.array(test_features.pop(label_name)) #test_label=tf.convert_to_tensor(test_label) my_model.evaluate(x=test_features, y=test_label, batch_size=batch_size) for this code i receive error :", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lhc51b/trouble_calling_the_tensorflow_model_after/',)", "identifyer": 5728185, "year": "2021"}, {"autor": "noahL432", "date": 1620440826000, "content": "Help improving multidimensional function approximation with neural network. [P] /!/  \n\nI am building a neural network to approximate a data set which takes 3 inputs and gives 1 output. After testing the network using a few different iterations of hidden layers and adjusting optimizers and activation functions, there seems to be no significant improvement to the solution. This suggests to me there is something inherently wrong with my approach. Notably, as the amount of input variables increase the problem with accuracy of the solution arises (i.e. with one independent variable I can achieve very good accuracy). I believe applying the basic machine learning techiniques do not translate well to higher dimensional inputs. That being said, I am new to machine learning so there could be something I am missing. Here is an example of the output of the network:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/o0939cnj4tx61.png?width=600&amp;format=png&amp;auto=webp&amp;s=46a62eeceb5935c9c0adfc0df2ecc514694a5b5d\n\nThe three input parameters are altitude, mach, and fault parameter. This plot is an altitude \"slice\". The trend of underprediction I believe is a result of the network trying to satisfy all the different altitudes, at lower altitudes there is a noticable underprediction while higher altitudes tend to overpredict.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6r3m5tok4tx61.png?width=600&amp;format=png&amp;auto=webp&amp;s=b501cab3f65f527b3cd56f6cfec182b9a03c2e99\n\nThe neural network used to generate this approximation had a basic structure. An input layer to a hidden layer of 100 nodes (celu activation) and an output layer. Different iterations of this structure seem to have no effect, they converge to the same solution. I want to know if I am doing something wrong or need to take a different approach to solving this problem. The issue seems to be trying to use a simple network to capture a multidimensional solution, but I cant find anything on proper setups for multidimensional inputs. Also, if you have any recomendations for resources on machine learning (for multidimensional function approximation specifically), I would appreciate them.\n\nEDIT: I am having better results by first randomizing the data then passing it to the trainer (using flux for julia). I think there was an issue with the \"scope\" of local minima being constrained by the initial datapoints (the same ones were being passed first and skewing the training). This is all asuming that Flux does not automatically randomize data points inside its training function, however it seems to improve the convergence so it helped somehow. I am also playing with batch sizing to see if that helps.", "link": "https://www.reddit.com/r/MachineLearning/comments/n7f7hq/help_improving_multidimensional_function/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "help improving multidimensional function approximation with neural network. [p] /!/  \n\ni am building a neural network to approximate a data set which takes 3 inputs and gives 1 output. after testing the network using a few different iterations of hidden layers and adjusting optimizers and activation functions, there seems to be no significant improvement to the solution. this suggests to me there is something inherently wrong with my approach. notably, as the amount of input variables increase the problem with accuracy of the solution arises (i.e. with one independent variable i can achieve very good accuracy). i believe applying the basic machine learning techiniques do not translate well to higher dimensional inputs. that being said, i am new to machine learning so there could be something i am missing. here is an example of the output of the network:\n\n&amp;#x200b;\n\nhttps://preview.redd.it/o0939cnj4tx61.png?width=600&amp;format=png&amp;auto=webp&amp;s=46a62eeceb5935c9c0adfc0df2ecc514694a5b5d\n\nthe three input parameters are altitude, mach, and fault parameter. this -----> plot !!!  is an altitude \"slice\". the trend of underprediction i believe is a result of the network trying to satisfy all the different altitudes, at lower altitudes there is a noticable underprediction while higher altitudes tend to overpredict.\n\n&amp;#x200b;\n\nhttps://preview.redd.it/6r3m5tok4tx61.png?width=600&amp;format=png&amp;auto=webp&amp;s=b501cab3f65f527b3cd56f6cfec182b9a03c2e99\n\nthe neural network used to generate this approximation had a basic structure. an input layer to a hidden layer of 100 nodes (celu activation) and an output layer. different iterations of this structure seem to have no effect, they converge to the same solution. i want to know if i am doing something wrong or need to take a different approach to solving this problem. the issue seems to be trying to use a simple network to capture a multidimensional solution, but i cant find anything on proper setups for multidimensional inputs. also, if you have any recomendations for resources on machine learning (for multidimensional function approximation specifically), i would appreciate them.\n\nedit: i am having better results by first randomizing the data then passing it to the trainer (using flux for julia). i think there was an issue with the \"scope\" of local minima being constrained by the initial datapoints (the same ones were being passed first and skewing the training). this is all asuming that flux does not automatically randomize data points inside its training function, however it seems to improve the convergence so it helped somehow. i am also playing with batch sizing to see if that helps.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n7f7hq/help_improving_multidimensional_function/',)", "identifyer": 5728565, "year": "2021"}, {"autor": "Euphoric-Fisherman84", "date": 1615652703000, "content": "[Project] Identifying Top 3 Time Series with Highest Predictive Power /!/ There isn't a single right answer for this question but I'm curious to hear what's everyone strategy for this problem.\n\nSay you're trying to predict the return of an asset and you have 120 variables on the same time series (in this case daily), what strategy would you adopt to find the top three which holds the highest predictive power?\n\nI'm in the early stages of research in this personal project and I'd like to favour simpler/easy to understand and explain methods as opposed to complex neural nets or similar.\n\nMy approach to far has been to create a scatter plot vs log returns for each of the features with the following lags \\[0, 1, 2, 5, 10, 15, 30\\] days. Looking at those I'm trying to find relationships that look non-random, linear or not.\n\nCurious to hear from you guys what other approaches you think may be appropriate, efficient and most importantly easily explainable.  \n\n\nPS: Scatter plot below is with 0-day lag for 23 indicators, the colour bar being UNIX timestamp.\n\nhttps://preview.redd.it/k3qy0vn2ntm61.jpg?width=2160&amp;format=pjpg&amp;auto=webp&amp;s=ea14f1caed2d5c96b762abb61bccb20d1289de41", "link": "https://www.reddit.com/r/MachineLearning/comments/m49lpf/project_identifying_top_3_time_series_with/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[project] identifying top 3 time series with highest predictive power /!/ there isn't a single right answer for this question but i'm curious to hear what's everyone strategy for this problem.\n\nsay you're trying to predict the return of an asset and you have 120 variables on the same time series (in this case daily), what strategy would you adopt to find the top three which holds the highest predictive power?\n\ni'm in the early stages of research in this personal project and i'd like to favour simpler/easy to understand and explain methods as opposed to complex neural nets or similar.\n\nmy approach to far has been to create a scatter -----> plot !!!  vs log returns for each of the features with the following lags \\[0, 1, 2, 5, 10, 15, 30\\] days. looking at those i'm trying to find relationships that look non-random, linear or not.\n\ncurious to hear from you guys what other approaches you think may be appropriate, efficient and most importantly easily explainable.  \n\n\nps: scatter plot below is with 0-day lag for 23 indicators, the colour bar being unix timestamp.\n\nhttps://preview.redd.it/k3qy0vn2ntm61.jpg?width=2160&amp;format=pjpg&amp;auto=webp&amp;s=ea14f1caed2d5c96b762abb61bccb20d1289de41", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/m49lpf/project_identifying_top_3_time_series_with/',)", "identifyer": 5729375, "year": "2021"}, {"autor": "sergeyfeldman", "date": 1609806624000, "content": "[P] Which Machine Learning Classifiers are best for small datasets? An empirical study /!/ Although \"big data\" and \"deep learning\" are dominant, my own work at the Gates Foundation involves a lot of small (but expensive) datasets, where the number of rows (subjects, samples) is between 100 and 1000. For example, detailed measurements throughout a pregnancy and subsequent neonatal outcomes from pregnant women. A lot of my collaborative investigations involve fitting machine learning models to small datasets like these, and it's not clear what best practices are in this case.\n\nAlong with my own experience, there is some informal wisdom floating around the ML community. Folk wisdom makes me wary and I wanted to do something more systematic. I took the following approach:\n\n* Get a lot of small classification benchmark datasets. I used a subset of this prepackaged repo. The final total was 108 datasets. (To do: also run regression benchmarks using this nice dataset library.)\n* Select some reasonably representative ML classifiers: linear SVM, Logistic Regression, Random Forest, LightGBM (ensemble of gradient boosted decision trees), AugoGluon (fancy automl mega-ensemble).\n* Set up sensible hyperparameter spaces.\n* Run every classifier on every dataset via nested cross-validation.\n* Plot results.\n\nAll the code and results are here: https://github.com/sergeyf/SmallDataBenchmarks\n\nLet's look at the results. The metric of interest is weighted one-vs-all area under the ROC curve, averaged over the outer folds. The [plot](https://user-images.strikinglycdn.com/res/hrscywv4p/image/upload/c_limit,fl_lossy,h_9000,w_1200,f_auto,q_auto/174108/405478_658788.png)\n\nSome observations:\n\n* AutoGluon is best overall, but it has some catastrophic failures (AUROC &lt; 0.5) that Logistic Regression does not and LightGBM has fewer of.\n* You can't tell from this particular plot, but AutoGluon needs \"enough\" time. It has a budget parameter which tells it how much time to spend improving the fancy ensemble. Five minutes per fold was the minimum that worked well - this adds up to 108 datasets * 4 outer folds * 300s = 1.5 days for the entire benchmark.\n* Linear SVC is better than Logistic Regression on average. There are also two datasets where SVC is 0.3 and 0.1 AUROC better than every other model. It's worth keeping in the toolbox.\n* Logistic Regression needs the \"elasticnet\" regularizer to ensure it doesn't have the kind of awful generalization failures that you see with AutoGluon and Random Forest.\n* LightGBM is second best. I used hyperopt to find good hyperparameters. I also tried scikit-optimize and Optuna, but they didn't work as well. User error is possible.\n* Random Forest is pretty good, and much easier/faster to optimize than LightGBM and AutoGluon. I only cross-validated a single parameter for it (depth).\n\nHere are counts of datasets where each algorithm wins or is within 0.5% of winning AUROC (out of 108):\n\n* AutoGluon (sec=300): 71\n* LightGBM (n_hyperparams=50): 43\n* LightGBM (n_hyperparams=25): 41\n* Random Forest: 32\n* Logistic Regression: 28\n* SVC: 23\n\nAnd average AUROC across all datasets:\n\n* AutoGluon (sec=300) - 0.885\n* LightGBM (n_hyperparams=50) - 0.876\n* LightGBM (n_hyperparams=25) - 0.873\n* Random Forest - 0.870\n* SVC - 0.841\n* Logistic Regression - 0.835\n\nAnd counts where each algorithm does the worst or is within 0.5% of the worst AUROC:\n\n* Logistic Regression: 54\n* SVC: 48\n* Random Forest: 25\n* LightGBM (n_hyperparams=25): 19\n* LightGBM (n_hyperparams=50): 18\n* AutoGluon (sec=300): 14\n\nWhich shows that even the smart ensemble can still fail 10% of the time. Not a single free lunch to be eaten anywhere.\n\n[Here](https://user-images.strikinglycdn.com/res/hrscywv4p/image/upload/c_limit,fl_lossy,h_9000,w_1200,f_auto,q_auto/174108/900727_648400.png) is a plot of average (over folds) AUROC vs number of samples.\n\nI was surprised when I saw this for the first time. The collective wisdom that I've ingested is something like: \"don't bother using complex models for tiny data.\" But this doesn't seem true for these 108 datasets. Even at the low end, AutoGluon works very well, and LightGBM/Random Forest handily beat out the two linear models. There's an odd peak in the model where the linear models suddenly do better - I don't think it's meaningful.\n\nThe last [plot](https://user-images.strikinglycdn.com/res/hrscywv4p/image/upload/c_limit,fl_lossy,h_9000,w_1200,f_auto,q_auto/174108/378656_205907.png): standard deviation of AUROC across outer folds.\n\nLinear models don't just generalize worse regardless of dataset size - they also have higher generalization variance. Note the one strange SVC outlier. Another SVC mystery...\n\n**IID Thoughts**\n\nHow applicable are these experiments? Both levels of the nested cross-validation used class-stratified random splits. So the splits were IID: independent and identically distributed. The test data looked like the validation data which looked like the training data. This is both unrealistic and precisely how most peer-reviewed publications evaluate when they try out machine learning. (At least the good ones.) In some cases, there is actual covariate-shifted \"test\" data available. It's possible that LightGBM is better than linear models for IID data regardless of its size, but this is no longer true if the test set is from some related but different distribution than the training set. I can't experiment very easily in this scenario: \"standard\" benchmark datasets are readily available, but realistic pairs of training and covariate-shifted test sets are not.\n\n**Conclusions &amp; Caveats**\n\nSo what can we conclude?\n\n* If you only care about the IID setting or only have access to a single dataset, non-linear models are likely to be superior even if you only have 50 samples.\n* AutoGluon is a great way to get an upper bound on performance, but it's much harder to understand the final complex ensemble than, say, LightGBM where you can plot the SHAP values.\n** hyperopt is old and has some warts but works better than the alternatives that I've tried. I'm going to stick with it.\n** SVC can in rare cases completely dominate all other algorithms.\n\nCaveats:\n\n* LightGBM has a lot of excellent bells and whistles that were not at all used here: native missing value handling (we had none), smarter encoding of categorical variables (I used one-hot encoding for the sake of uniformity/fairness), per-feature monotonic constraints (need to have prior knowledge).\n* AutoGluon includes a tabular neural network in its ensemble, but I haven't run benchmarks on it in isolation. It would be interesting to find out if modern tabular neural network architectures can work out-of-the-box for small datasets.\n* This is just classification. Regression might have different outcomes.\n\nAgain, check out the code and feel free to add new scripts with other algorithms. It shouldn't be too hard. https://github.com/sergeyf/SmallDataBenchmarks", "link": "https://www.reddit.com/r/MachineLearning/comments/kqm5pn/p_which_machine_learning_classifiers_are_best_for/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[p] which machine learning classifiers are best for small datasets? an empirical study /!/ although \"big data\" and \"deep learning\" are dominant, my own work at the gates foundation involves a lot of small (but expensive) datasets, where the number of rows (subjects, samples) is between 100 and 1000. for example, detailed measurements throughout a pregnancy and subsequent neonatal outcomes from pregnant women. a lot of my collaborative investigations involve fitting machine learning models to small datasets like these, and it's not clear what best practices are in this case.\n\nalong with my own experience, there is some informal wisdom floating around the ml community. folk wisdom makes me wary and i wanted to do something more systematic. i took the following approach:\n\n* get a lot of small classification benchmark datasets. i used a subset of this prepackaged repo. the final total was 108 datasets. (to do: also run regression benchmarks using this nice dataset library.)\n* select some reasonably representative ml classifiers: linear svm, logistic regression, random forest, lightgbm (ensemble of gradient boosted decision trees), augogluon (fancy automl mega-ensemble).\n* set up sensible hyperparameter spaces.\n* run every classifier on every dataset via nested cross-validation.\n* -----> plot !!!  results.\n\nall the code and results are here: https://github.com/sergeyf/smalldatabenchmarks\n\nlet's look at the results. the metric of interest is weighted one-vs-all area under the roc curve, averaged over the outer folds. the [plot](https://user-images.strikinglycdn.com/res/hrscywv4p/image/upload/c_limit,fl_lossy,h_9000,w_1200,f_auto,q_auto/174108/405478_658788.png)\n\nsome observations:\n\n* autogluon is best overall, but it has some catastrophic failures (auroc &lt; 0.5) that logistic regression does not and lightgbm has fewer of.\n* you can't tell from this particular plot, but autogluon needs \"enough\" time. it has a budget parameter which tells it how much time to spend improving the fancy ensemble. five minutes per fold was the minimum that worked well - this adds up to 108 datasets * 4 outer folds * 300s = 1.5 days for the entire benchmark.\n* linear svc is better than logistic regression on average. there are also two datasets where svc is 0.3 and 0.1 auroc better than every other model. it's worth keeping in the toolbox.\n* logistic regression needs the \"elasticnet\" regularizer to ensure it doesn't have the kind of awful generalization failures that you see with autogluon and random forest.\n* lightgbm is second best. i used hyperopt to find good hyperparameters. i also tried scikit-optimize and optuna, but they didn't work as well. user error is possible.\n* random forest is pretty good, and much easier/faster to optimize than lightgbm and autogluon. i only cross-validated a single parameter for it (depth).\n\nhere are counts of datasets where each algorithm wins or is within 0.5% of winning auroc (out of 108):\n\n* autogluon (sec=300): 71\n* lightgbm (n_hyperparams=50): 43\n* lightgbm (n_hyperparams=25): 41\n* random forest: 32\n* logistic regression: 28\n* svc: 23\n\nand average auroc across all datasets:\n\n* autogluon (sec=300) - 0.885\n* lightgbm (n_hyperparams=50) - 0.876\n* lightgbm (n_hyperparams=25) - 0.873\n* random forest - 0.870\n* svc - 0.841\n* logistic regression - 0.835\n\nand counts where each algorithm does the worst or is within 0.5% of the worst auroc:\n\n* logistic regression: 54\n* svc: 48\n* random forest: 25\n* lightgbm (n_hyperparams=25): 19\n* lightgbm (n_hyperparams=50): 18\n* autogluon (sec=300): 14\n\nwhich shows that even the smart ensemble can still fail 10% of the time. not a single free lunch to be eaten anywhere.\n\n[here](https://user-images.strikinglycdn.com/res/hrscywv4p/image/upload/c_limit,fl_lossy,h_9000,w_1200,f_auto,q_auto/174108/900727_648400.png) is a plot of average (over folds) auroc vs number of samples.\n\ni was surprised when i saw this for the first time. the collective wisdom that i've ingested is something like: \"don't bother using complex models for tiny data.\" but this doesn't seem true for these 108 datasets. even at the low end, autogluon works very well, and lightgbm/random forest handily beat out the two linear models. there's an odd peak in the model where the linear models suddenly do better - i don't think it's meaningful.\n\nthe last [plot](https://user-images.strikinglycdn.com/res/hrscywv4p/image/upload/c_limit,fl_lossy,h_9000,w_1200,f_auto,q_auto/174108/378656_205907.png): standard deviation of auroc across outer folds.\n\nlinear models don't just generalize worse regardless of dataset size - they also have higher generalization variance. note the one strange svc outlier. another svc mystery...\n\n**iid thoughts**\n\nhow applicable are these experiments? both levels of the nested cross-validation used class-stratified random splits. so the splits were iid: independent and identically distributed. the test data looked like the validation data which looked like the training data. this is both unrealistic and precisely how most peer-reviewed publications evaluate when they try out machine learning. (at least the good ones.) in some cases, there is actual covariate-shifted \"test\" data available. it's possible that lightgbm is better than linear models for iid data regardless of its size, but this is no longer true if the test set is from some related but different distribution than the training set. i can't experiment very easily in this scenario: \"standard\" benchmark datasets are readily available, but realistic pairs of training and covariate-shifted test sets are not.\n\n**conclusions &amp; caveats**\n\nso what can we conclude?\n\n* if you only care about the iid setting or only have access to a single dataset, non-linear models are likely to be superior even if you only have 50 samples.\n* autogluon is a great way to get an upper bound on performance, but it's much harder to understand the final complex ensemble than, say, lightgbm where you can plot the shap values.\n** hyperopt is old and has some warts but works better than the alternatives that i've tried. i'm going to stick with it.\n** svc can in rare cases completely dominate all other algorithms.\n\ncaveats:\n\n* lightgbm has a lot of excellent bells and whistles that were not at all used here: native missing value handling (we had none), smarter encoding of categorical variables (i used one-hot encoding for the sake of uniformity/fairness), per-feature monotonic constraints (need to have prior knowledge).\n* autogluon includes a tabular neural network in its ensemble, but i haven't run benchmarks on it in isolation. it would be interesting to find out if modern tabular neural network architectures can work out-of-the-box for small datasets.\n* this is just classification. regression might have different outcomes.\n\nagain, check out the code and feel free to add new scripts with other algorithms. it shouldn't be too hard. https://github.com/sergeyf/smalldatabenchmarks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 44, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/kqm5pn/p_which_machine_learning_classifiers_are_best_for/',)", "identifyer": 5729686, "year": "2021"}, {"autor": "Kanep96", "date": 1621595597000, "content": "[P] Coding Neural Network from scratch in MATLAB (without the toolset). Would like some assistance, tips, advice, etc. /!/ This is a regression neural network as well, by the way. Simply attempting to estimate an output based on input data. Given 1 as input, if the target output is 2*x, then (after the network is trained, naturally) the output should be 2. If the target is x^2 + 2x, the output should be 3. And so on.\n\n\nAre there any issues with MATLAB going into this that would be nice to know? My regression plots are a bit... odd, even if the numbers look fine, and I'm unsure as to exactly why. I've coded the Neural Network(s) already, and I think I did a fine job doings so and I felt the math was simple to understand after some time with it, but there are some... odd issues that I (as well as my faculty advisor!) can't really figure out. I'd be happy to provide snippets of my code as well, if someone wants to go above-and-beyond in seeing what exactly might be my issue here.\n\n\nI have coded a standard single-layer neural network, a double-layer neural network, and a \"main\" program that allows the user to create a neural network of any size/shape. I utilize the sigmoid activation function (my advisor would like me to do so) in each layer, save for the output layer. However, as of late, I am have *considerably* better results utilizing the Leaky ReLU activation function so I think, at the end of the say, I'm going to utilize this activation function instead of sigmoid. In my programs, I have Sigmoid and its derivative inside of functions, and I have Leaky ReLU commented out inside of said function so that, whenever I want to use it as an activation function, I just comment out the Sigmoid code and un-comment out the Leaky ReLU code and then run again. Its quite nice!\n\n\nAnyway, here is my code for those interested. It isn't too long, but if there are any questions about my design, feel free to let me know of course. There are lots of comments as well... feel free to ignore them. My single-layer NN seemingly works well, but I'm not too confident in it. My double-layer NN... not so much. I've also included a picture of the regression plots that show up for my single-layer NN that seem odd compared to what the toolbox outputs. Thanks!\n\n\nSingle-Layer:\n\n\nhttps://drive.google.com/file/d/1DhDrmx7HGoi_OGt9KOTd7QQQh6L-hq9I/view?usp=sharing\n\n\nOdd-looking Regression plot for Single-Layer NN:\n\n\nhttps://imgur.com/a/hl0pgWV\n\n\nDouble-Layer:\n\n\nhttps://drive.google.com/file/d/1yvD39VNruQvxzq58FavbnomY2nDo8Jxj/view?usp=sharing", "link": "https://www.reddit.com/r/MachineLearning/comments/nhpyto/p_coding_neural_network_from_scratch_in_matlab/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[p] coding neural network from scratch in matlab (without the toolset). would like some assistance, tips, advice, etc. /!/ this is a regression neural network as well, by the way. simply attempting to estimate an output based on input data. given 1 as input, if the target output is 2*x, then (after the network is trained, naturally) the output should be 2. if the target is x^2 + 2x, the output should be 3. and so on.\n\n\nare there any issues with matlab going into this that would be nice to know? my regression plots are a bit... odd, even if the numbers look fine, and i'm unsure as to exactly why. i've coded the neural network(s) already, and i think i did a fine job doings so and i felt the math was simple to understand after some time with it, but there are some... odd issues that i (as well as my faculty advisor!) can't really figure out. i'd be happy to provide snippets of my code as well, if someone wants to go above-and-beyond in seeing what exactly might be my issue here.\n\n\ni have coded a standard single-layer neural network, a double-layer neural network, and a \"main\" program that allows the user to create a neural network of any size/shape. i utilize the sigmoid activation function (my advisor would like me to do so) in each layer, save for the output layer. however, as of late, i am have *considerably* better results utilizing the leaky relu activation function so i think, at the end of the say, i'm going to utilize this activation function instead of sigmoid. in my programs, i have sigmoid and its derivative inside of functions, and i have leaky relu commented out inside of said function so that, whenever i want to use it as an activation function, i just comment out the sigmoid code and un-comment out the leaky relu code and then run again. its quite nice!\n\n\nanyway, here is my code for those interested. it isn't too long, but if there are any questions about my design, feel free to let me know of course. there are lots of comments as well... feel free to ignore them. my single-layer nn seemingly works well, but i'm not too confident in it. my double-layer nn... not so much. i've also included a picture of the regression plots that show up for my single-layer nn that seem odd compared to what the toolbox outputs. thanks!\n\n\nsingle-layer:\n\n\nhttps://drive.google.com/file/d/1dhdrmx7hgoi_ogt9kotd7qqqh6l-hq9i/view?usp=sharing\n\n\nodd-looking regression -----> plot !!!  for single-layer nn:\n\n\nhttps://imgur.com/a/hl0pgwv\n\n\ndouble-layer:\n\n\nhttps://drive.google.com/file/d/1yvd39vnruqvxzq58favbnomy2ndo8jxj/view?usp=sharing", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nhpyto/p_coding_neural_network_from_scratch_in_matlab/',)", "identifyer": 5730660, "year": "2021"}, {"autor": "tomasemilio", "date": 1629408796000, "content": "[D] Can this clustering strategy (DBSCAN followed by TSNE) work? /!/ Hi everyone. I have a pretty binary classification model with an AUC score of 92%, stable learning curves, etc. I would like to run a clustering algorithm on this data using the same features that lead to those supervised-learning results. The data is scaled etc.   \nMy data has many outliers and is a low-dimensionality, non-sparse data. I thought of the following approach:  \n\\- Run DBSCAN trying multiple combinations of eps and min\\_samples.  \n\\- To visualize, run a TSNE with n\\_components=2, plot it in 2D, and see if the plot makes sense with the categories returned by the DBSCAN.  \n\n\nI would love your feedback.", "link": "https://www.reddit.com/r/MachineLearning/comments/p7o6q9/d_can_this_clustering_strategy_dbscan_followed_by/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] can this clustering strategy (dbscan followed by tsne) work? /!/ hi everyone. i have a pretty binary classification model with an auc score of 92%, stable learning curves, etc. i would like to run a clustering algorithm on this data using the same features that lead to those supervised-learning results. the data is scaled etc.   \nmy data has many outliers and is a low-dimensionality, non-sparse data. i thought of the following approach:  \n\\- run dbscan trying multiple combinations of eps and min\\_samples.  \n\\- to visualize, run a tsne with n\\_components=2, -----> plot !!!  it in 2d, and see if the -----> plot !!!  makes sense with the categories returned by the dbscan.  \n\n\ni would love your feedback.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p7o6q9/d_can_this_clustering_strategy_dbscan_followed_by/',)", "identifyer": 5731035, "year": "2021"}, {"autor": "jaekr", "date": 1626600627000, "content": "Why someone tells that the RMSE loss is differentiable? I think that it is not. Its form is like f(x,y)= sqrt(x^2+y^2). So its plot is this figure below.", "link": "https://www.reddit.com/r/MachineLearning/comments/omnd76/why_someone_tells_that_the_rmse_loss_is/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "why someone tells that the rmse loss is differentiable? i think that it is not. its form is like f(x,y)= sqrt(x^2+y^2). so its -----> plot !!!  is this figure below.", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('image',)", "medialink": "('https://i.redd.it/9ylk5nm9xxb71.jpg',)", "identifyer": 5731288, "year": "2021"}, {"autor": "SQL_beginner", "date": 1627273730000, "content": "[D] Using TSNE to visualize higher dimension loss functions /!/ Hello Everyone,\n\nRecently I had this idea : suppose you have a loss function that is in many dimensions, for curiosity sake - does it make sense to use the TSNE (Stochastic Neighbor Embedding) algorithm to visualize a \"lower embedded\" version of the loss function?\n\nSuppose I am working on an optimization problem : I am trying to find a set of inputs \"a1, a2, b1, b2\" that produces the **largest value** of some \"total\". Let's say that there is some \"blackbox\" function that links \"a1, a2, b1, b2\" to \"total\". Suppose we randomly selected 1000 values of \"a1, a2, b1, b2\" and in turn calculated 1000 corresponding values of \"total\":\n\n&amp;#x200B;\n\n[Sample Data](https://preview.redd.it/ihfxe3exfhd71.png?width=498&amp;format=png&amp;auto=webp&amp;s=0cc6fa517027b2d1ad8e4e2a61255a6efdbd7fad)\n\n**Question:**\n\n**1)** Does it make sense to perform the TSNE algorithm on columns \"a1, a2, b1, b2\" of this dataset (suppose we call the resulting TSNE dimensions as \"X1\" and \"X2\"), and then make a new dataset containing the results of the TSNE algorithm and the \"total\" variable? \n\nFor example:\n\n&amp;#x200B;\n\n[TSNE data](https://preview.redd.it/0wrhixswghd71.png?width=237&amp;format=png&amp;auto=webp&amp;s=58ceb00b20ae00db93eee926ef4ab46969a84a12)\n\n**2)** With this TSNE data, does it then make sense to visualize a 3D loss function and the contour plots? \n\nFor example:\n\n&amp;#x200B;\n\n[Plot of 3D Surface and Contours](https://preview.redd.it/9xt1bxdxhhd71.png?width=1715&amp;format=png&amp;auto=webp&amp;s=9f6000c27a1b864d3d0572f55e245ec5bb6d8343)\n\n**Note:** The above graphs are created with randomly generated data and that is why their shapes seem irregular. Also, I understand that the TSNE algorithm is stochastic and might result in a new set of \"embedding vectors\" when repeated on the same data. I also understand that there is no real way to \"trace\" the TSNE embeddings back to the original data. Also, these graphs likely serve no real purpose - they just seem visually appealing.\n\nSo, can someone please try to answer this question: does it make sense to visualize higher dimension loss functions using the TSNE algorithm?\n\nThanks", "link": "https://www.reddit.com/r/MachineLearning/comments/orrejn/d_using_tsne_to_visualize_higher_dimension_loss/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] using tsne to visualize higher dimension loss functions /!/ hello everyone,\n\nrecently i had this idea : suppose you have a loss function that is in many dimensions, for curiosity sake - does it make sense to use the tsne (stochastic neighbor embedding) algorithm to visualize a \"lower embedded\" version of the loss function?\n\nsuppose i am working on an optimization problem : i am trying to find a set of inputs \"a1, a2, b1, b2\" that produces the **largest value** of some \"total\". let's say that there is some \"blackbox\" function that links \"a1, a2, b1, b2\" to \"total\". suppose we randomly selected 1000 values of \"a1, a2, b1, b2\" and in turn calculated 1000 corresponding values of \"total\":\n\n&amp;#x200b;\n\n[sample data](https://preview.redd.it/ihfxe3exfhd71.png?width=498&amp;format=png&amp;auto=webp&amp;s=0cc6fa517027b2d1ad8e4e2a61255a6efdbd7fad)\n\n**question:**\n\n**1)** does it make sense to perform the tsne algorithm on columns \"a1, a2, b1, b2\" of this dataset (suppose we call the resulting tsne dimensions as \"x1\" and \"x2\"), and then make a new dataset containing the results of the tsne algorithm and the \"total\" variable? \n\nfor example:\n\n&amp;#x200b;\n\n[tsne data](https://preview.redd.it/0wrhixswghd71.png?width=237&amp;format=png&amp;auto=webp&amp;s=58ceb00b20ae00db93eee926ef4ab46969a84a12)\n\n**2)** with this tsne data, does it then make sense to visualize a 3d loss function and the contour plots? \n\nfor example:\n\n&amp;#x200b;\n\n[-----> plot !!!  of 3d surface and contours](https://preview.redd.it/9xt1bxdxhhd71.png?width=1715&amp;format=png&amp;auto=webp&amp;s=9f6000c27a1b864d3d0572f55e245ec5bb6d8343)\n\n**note:** the above graphs are created with randomly generated data and that is why their shapes seem irregular. also, i understand that the tsne algorithm is stochastic and might result in a new set of \"embedding vectors\" when repeated on the same data. i also understand that there is no real way to \"trace\" the tsne embeddings back to the original data. also, these graphs likely serve no real purpose - they just seem visually appealing.\n\nso, can someone please try to answer this question: does it make sense to visualize higher dimension loss functions using the tsne algorithm?\n\nthanks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/orrejn/d_using_tsne_to_visualize_higher_dimension_loss/',)", "identifyer": 5731421, "year": "2021"}, {"autor": "bobskithememe", "date": 1626173744000, "content": "[D] Data Analysis and Visualisation on High-Dimensional Dataset /!/ Hello, all!\n\nI currently have a large dataset consisting of 68,000 rows and 1,550 columns. The dataset is an amalgamation of several datasets I've cleaned and merged together. Before modelling, I would like to carry out EDA and visualisation to see how the features play out and to uncover patterns etc.\n\nI'm not entirely sure what's the best approach given the dataset has 1,550 features. I'm planning to do a lot of PCA and clustering given I cannot really plot individual features from the start. Once, I've found interesting relationships and trends, I can do more conventional plotting with features.\n\nI was thinking of using affinity propagation, mean shift, DBSCAN, birch and a Gaussian mixture model but I'm unsure whether to do it on a group of features or all at once.\n\nI'm interested to hear any ideas on how you would approach this or what would be the best plan of attack?\n\nThanks in advance!", "link": "https://www.reddit.com/r/MachineLearning/comments/ojd5uf/d_data_analysis_and_visualisation_on/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] data analysis and visualisation on high-dimensional dataset /!/ hello, all!\n\ni currently have a large dataset consisting of 68,000 rows and 1,550 columns. the dataset is an amalgamation of several datasets i've cleaned and merged together. before modelling, i would like to carry out eda and visualisation to see how the features play out and to uncover patterns etc.\n\ni'm not entirely sure what's the best approach given the dataset has 1,550 features. i'm planning to do a lot of pca and clustering given i cannot really -----> plot !!!  individual features from the start. once, i've found interesting relationships and trends, i can do more conventional plotting with features.\n\ni was thinking of using affinity propagation, mean shift, dbscan, birch and a gaussian mixture model but i'm unsure whether to do it on a group of features or all at once.\n\ni'm interested to hear any ideas on how you would approach this or what would be the best plan of attack?\n\nthanks in advance!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ojd5uf/d_data_analysis_and_visualisation_on/',)", "identifyer": 5731686, "year": "2021"}, {"autor": "nd7141", "date": 1610489192000, "content": "[D] Analysis of Decisions at ICLR 2021 /!/ The decisions for ICLR 2021 have been released and here are some stats of the accepted papers. (Following [this tweet](https://twitter.com/SergeyI49013776/status/1349110655568261121)).\n\nAll decisions can be found in [this google table](https://docs.google.com/spreadsheets/d/1n58O0lgGI5kI0QQY9f4BDDpNB4oFjb5D51yMr9fHAK4/edit). \n\n860 accepted out of 2997 -&gt; 29% acceptance rate 53 Orals, 114 Spotlights, 693 Posters, 1756 Rejected, 381 Withdrawn. Authors tended to withdraw papers at the rebuttal phase if the scores were low, to resubmit them to other conferences. \n\nLooking at distributions of Accepted vs Rejected papers, we can say that both curves are quite centered, without outliers. The overlap is mainly in  5.5-6.5 range.   \n \n\nhttps://preview.redd.it/ulcqim0r3za61.png?width=1459&amp;format=png&amp;auto=webp&amp;s=ec70ed3c0da1bd0b8269d92ff7d44362440b4737\n\nSame plot but breaking down Accepted into Oral, Spotlight, and Poster papers. \n\n&amp;#x200B;\n\nhttps://preview.redd.it/lb1pqeo64za61.png?width=1468&amp;format=png&amp;auto=webp&amp;s=bfa2f277652c2d4b87cf820a2f08a9078bbe974e\n\nOral papers are top-6% of accepted papers and top-2% of all papers.  The average score for oral paper is 7.5, and the minimum score is 6.67.\n\nSpotlight papers are top-13% of accepted papers and top-4% of all papers. The average score is 7 and the minimum score is 6. \n\n&amp;#x200B;\n\nBad beats of this year are:  \n\n* [Lie Algebra Convolutional Neural Networks with Automatic Symmetry Extraction](https://openreview.net/forum?id=cTQnZPLIohy) with scores (7,8,6) getting a reject. \n* And, [For interpolating kernel machines, minimizing the norm of the ERM solution minimizes stability](https://openreview.net/forum?id=p3_z68kKrus) with scores (6,8,6,8) getting reject as well. \n\n&amp;#x200B;\n\nOverall, the lowest average score that would guarantee you acceptance is 7.25.  With an average score 6 (weak accept), you have 39% chance of being accepted.  With an average score 6.5, your chances drastically increase to 91%. \n\n&amp;#x200B;\n\nLet me know your thoughts in the comments and consider following my [**telegram channel**](https://t.me/graphML), [**twitter**](https://twitter.com/SergeyI49013776), and [**graphML newsletter**](https://graphml.substack.com/).\u00a0", "link": "https://www.reddit.com/r/MachineLearning/comments/kw1yt1/d_analysis_of_decisions_at_iclr_2021/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] analysis of decisions at iclr 2021 /!/ the decisions for iclr 2021 have been released and here are some stats of the accepted papers. (following [this tweet](https://twitter.com/sergeyi49013776/status/1349110655568261121)).\n\nall decisions can be found in [this google table](https://docs.google.com/spreadsheets/d/1n58o0lggi5ki0qqy9f4bddpnb4ofjb5d51ymr9fhak4/edit). \n\n860 accepted out of 2997 -&gt; 29% acceptance rate 53 orals, 114 spotlights, 693 posters, 1756 rejected, 381 withdrawn. authors tended to withdraw papers at the rebuttal phase if the scores were low, to resubmit them to other conferences. \n\nlooking at distributions of accepted vs rejected papers, we can say that both curves are quite centered, without outliers. the overlap is mainly in  5.5-6.5 range.   \n \n\nhttps://preview.redd.it/ulcqim0r3za61.png?width=1459&amp;format=png&amp;auto=webp&amp;s=ec70ed3c0da1bd0b8269d92ff7d44362440b4737\n\nsame -----> plot !!!  but breaking down accepted into oral, spotlight, and poster papers. \n\n&amp;#x200b;\n\nhttps://preview.redd.it/lb1pqeo64za61.png?width=1468&amp;format=png&amp;auto=webp&amp;s=bfa2f277652c2d4b87cf820a2f08a9078bbe974e\n\noral papers are top-6% of accepted papers and top-2% of all papers.  the average score for oral paper is 7.5, and the minimum score is 6.67.\n\nspotlight papers are top-13% of accepted papers and top-4% of all papers. the average score is 7 and the minimum score is 6. \n\n&amp;#x200b;\n\nbad beats of this year are:  \n\n* [lie algebra convolutional neural networks with automatic symmetry extraction](https://openreview.net/forum?id=ctqnzpliohy) with scores (7,8,6) getting a reject. \n* and, [for interpolating kernel machines, minimizing the norm of the erm solution minimizes stability](https://openreview.net/forum?id=p3_z68kkrus) with scores (6,8,6,8) getting reject as well. \n\n&amp;#x200b;\n\noverall, the lowest average score that would guarantee you acceptance is 7.25.  with an average score 6 (weak accept), you have 39% chance of being accepted.  with an average score 6.5, your chances drastically increase to 91%. \n\n&amp;#x200b;\n\nlet me know your thoughts in the comments and consider following my [**telegram channel**](https://t.me/graphml), [**twitter**](https://twitter.com/sergeyi49013776), and [**graphml newsletter**](https://graphml.substack.com/).\u00a0", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/kw1yt1/d_analysis_of_decisions_at_iclr_2021/',)", "identifyer": 5732207, "year": "2021"}, {"autor": "solitude-is_bliss", "date": 1622751866000, "content": "Here, I want to plot two figures but with different size. I can only plot both figures with one size defined in the mail subplots function. /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/nrn1jj/here_i_want_to_plot_two_figures_but_with/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "here, i want to -----> plot !!!  two figures but with different size. i can only plot both figures with one size defined in the mail subplots function. /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nrn1jj/here_i_want_to_plot_two_figures_but_with/',)", "identifyer": 5732403, "year": "2021"}, {"autor": "jnwang", "date": 1621895123000, "content": "[N] DataPrep V0.3 has been released! /!/ [DataPrep](https://dataprep.ai/) is the easiest way to prepare data (for ML) in Python. We\u2019re an open-source data preparation library, and we just dropped a very big, very exciting release.\n\nAll 3 of DataPrep\u2019s current components have received some notable updates to make DataPrep closer than ever to a full-fledged, off-the-shelf data preparation solution. Here\u2019s a rundown of some changes:\n\n[EDA](https://www.youtube.com/watch?v=RCZ8c8o6HH0&amp;t=8s)**:**\n\n* Added plot\\_diff(): Compare dataframes\n* plot() now sports geographical heatmaps\n* Customize plots by changing display parameters\n\n[Clean](https://www.youtube.com/watch?v=EHArIpp-DDw&amp;t=7s)**:**\n\n* Added clean\\_duplication: Creates an interface for users to select how to cluster detected duplicate values\n* Added clean\\_address(): Clean US addresses\n* Added clean\\_headers(): Clean column headers\n* Added clean\\_date(): Clean dates\n* Added clean\\_df(): Clean a dataframe\n\n[Connector](https://www.youtube.com/watch?v=kZCi0b4cu1c)**:**\n\n* Added support for more APIs - we now support over 30 APIs on Connector\n* The Connector team is currently working on expanding Connector with the addition of [ConnectorX](https://github.com/sfu-db/connector-x)\n\nThese updates allow users to use DataPrep for all their data preparation needs. We are very excited to be taking this step forward and becoming closer to an end-to-end data preparation tool.\n\n&amp;#x200B;\n\nRelease Blog: [https://towardsdatascience.com/dataprep-v0-3-0-has-been-released-be49b1be0e72](https://towardsdatascience.com/dataprep-v0-3-0-has-been-released-be49b1be0e72)\n\nGitHub:\u00a0[https://github.com/sfu-db/dataprep](https://github.com/sfu-db/dataprep)\n\nPyPI:\u00a0[https://pypi.org/project/dataprep/](https://pypi.org/project/dataprep/)", "link": "https://www.reddit.com/r/MachineLearning/comments/nka4kf/n_dataprep_v03_has_been_released/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[n] dataprep v0.3 has been released! /!/ [dataprep](https://dataprep.ai/) is the easiest way to prepare data (for ml) in python. we\u2019re an open-source data preparation library, and we just dropped a very big, very exciting release.\n\nall 3 of dataprep\u2019s current components have received some notable updates to make dataprep closer than ever to a full-fledged, off-the-shelf data preparation solution. here\u2019s a rundown of some changes:\n\n[eda](https://www.youtube.com/watch?v=rcz8c8o6hh0&amp;t=8s)**:**\n\n* added plot\\_diff(): compare dataframes\n* -----> plot !!! () now sports geographical heatmaps\n* customize plots by changing display parameters\n\n[clean](https://www.youtube.com/watch?v=eharipp-ddw&amp;t=7s)**:**\n\n* added clean\\_duplication: creates an interface for users to select how to cluster detected duplicate values\n* added clean\\_address(): clean us addresses\n* added clean\\_headers(): clean column headers\n* added clean\\_date(): clean dates\n* added clean\\_df(): clean a dataframe\n\n[connector](https://www.youtube.com/watch?v=kzci0b4cu1c)**:**\n\n* added support for more apis - we now support over 30 apis on connector\n* the connector team is currently working on expanding connector with the addition of [connectorx](https://github.com/sfu-db/connector-x)\n\nthese updates allow users to use dataprep for all their data preparation needs. we are very excited to be taking this step forward and becoming closer to an end-to-end data preparation tool.\n\n&amp;#x200b;\n\nrelease blog: [https://towardsdatascience.com/dataprep-v0-3-0-has-been-released-be49b1be0e72](https://towardsdatascience.com/dataprep-v0-3-0-has-been-released-be49b1be0e72)\n\ngithub:\u00a0[https://github.com/sfu-db/dataprep](https://github.com/sfu-db/dataprep)\n\npypi:\u00a0[https://pypi.org/project/dataprep/](https://pypi.org/project/dataprep/)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nka4kf/n_dataprep_v03_has_been_released/',)", "identifyer": 5733151, "year": "2021"}, {"autor": "glassAlloy", "date": 1624277979000, "content": "[D] Multiple Products Time Series with Singlevariate LSTM /!/ \\*\\*Project Description\\*\\*\n\n\\- My project is to pre-order movies online (people receive them at release date) and also to sell them after release date as well.\n\n\\- I have historical for many movies.\n\n\\- Their historic sales plot looks like a bell shape like curve with the symmetric center at the middle when the movie is released.\n\n\\- I use LSTM from the following \\[project\\]([https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)) with Python 3.7, Keras, TensorFlow.\n\n\\- The goal would be to train the model based on all the previouse plots without just averaging all the sales. \n\n\\- All of my historical data contains 2 parameters: 1.) sales date in the following format:  negative integers represent dates before release, 0 date when the release of the movie happening and than positive numbers maxing out at +30 to count the dates after release.\n\n&amp;#x200B;\n\n\\*\\*How to do this\\*\\*\n\n\\- What I want to do is multiple products timeline with the only feature numebr of sales. With LSTM, Python 3.7, Keras, TensorFlow.\n\n\\- Prediction should be on a brand new product until day +30, Not just continuing each product.\n\n&amp;#x200B;\n\n\\*\\*What I have found so far\\*\\* \n\n\\- My issue is that all the recomendation and project that I have found are for 1 product so 1 time line and maybe for multiple features (temperature, revenue, GDP at that time of the country ...) \\[example\\]([https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/))", "link": "https://www.reddit.com/r/MachineLearning/comments/o4tsss/d_multiple_products_time_series_with/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] multiple products time series with singlevariate lstm /!/ \\*\\*project description\\*\\*\n\n\\- my project is to pre-order movies online (people receive them at release date) and also to sell them after release date as well.\n\n\\- i have historical for many movies.\n\n\\- their historic sales -----> plot !!!  looks like a bell shape like curve with the symmetric center at the middle when the movie is released.\n\n\\- i use lstm from the following \\[project\\]([https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)) with python 3.7, keras, tensorflow.\n\n\\- the goal would be to train the model based on all the previouse plots without just averaging all the sales. \n\n\\- all of my historical data contains 2 parameters: 1.) sales date in the following format:  negative integers represent dates before release, 0 date when the release of the movie happening and than positive numbers maxing out at +30 to count the dates after release.\n\n&amp;#x200b;\n\n\\*\\*how to do this\\*\\*\n\n\\- what i want to do is multiple products timeline with the only feature numebr of sales. with lstm, python 3.7, keras, tensorflow.\n\n\\- prediction should be on a brand new product until day +30, not just continuing each product.\n\n&amp;#x200b;\n\n\\*\\*what i have found so far\\*\\* \n\n\\- my issue is that all the recomendation and project that i have found are for 1 product so 1 time line and maybe for multiple features (temperature, revenue, gdp at that time of the country ...) \\[example\\]([https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/))", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 11, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o4tsss/d_multiple_products_time_series_with/',)", "identifyer": 5733282, "year": "2021"}, {"autor": "ejensen031", "date": 1635226328000, "content": "Predicted vs actual scatter plot angle /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/qfzj7h/predicted_vs_actual_scatter_plot_angle/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "predicted vs actual scatter -----> plot !!!  angle /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/qfzj7h/predicted_vs_actual_scatter_plot_angle/',)", "identifyer": 5733989, "year": "2021"}, {"autor": "appliedUltra", "date": 1631106398000, "content": "Staircase in Training Question [P] /!/  \n\nHi All,\n\nI  was hoping someone could help me understand what is happening with my  network. I attached the classification accuracy plot. The black line is  my validation accuracy and the blue line is my training accuracy. As you  can see, the training accuracy appears to jump (like a staircase) from  one epoc to the next. Why would this be happening?\n\nFurthermore,  if I let this train for a long period of time, the training accuracy  approaches 100% and the validation data approaches a high value but is  significantly less than the training accuracy. The validation accuracy  never reduces so I do not believe that the network is over training. If  my validation data is evenly sampled from my data set, shouldn't the  results be on top of each other?\n\nThe  dateset I am using is not exhaustive. I am using 75% (blue line) of the  data set for training and 25% for validation (black line) and testing  (separate test after training is complete).\n\nMy goal of this post is to help recognize the problem my network is facing so that I can further research it.\n\nThank you!", "link": "https://www.reddit.com/r/MachineLearning/comments/pka5g3/staircase_in_training_question_p/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "staircase in training question [p] /!/  \n\nhi all,\n\ni  was hoping someone could help me understand what is happening with my  network. i attached the classification accuracy -----> plot !!! . the black line is  my validation accuracy and the blue line is my training accuracy. as you  can see, the training accuracy appears to jump (like a staircase) from  one epoc to the next. why would this be happening?\n\nfurthermore,  if i let this train for a long period of time, the training accuracy  approaches 100% and the validation data approaches a high value but is  significantly less than the training accuracy. the validation accuracy  never reduces so i do not believe that the network is over training. if  my validation data is evenly sampled from my data set, shouldn't the  results be on top of each other?\n\nthe  dateset i am using is not exhaustive. i am using 75% (blue line) of the  data set for training and 25% for validation (black line) and testing  (separate test after training is complete).\n\nmy goal of this post is to help recognize the problem my network is facing so that i can further research it.\n\nthank you!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pka5g3/staircase_in_training_question_p/',)", "identifyer": 5734207, "year": "2021"}, {"autor": "ComfortableCod", "date": 1613251974000, "content": "[p] How to enumerate 1-D array in order to plot it? matplotlib histogram /!/ Hello everyone,\n\nI have an array like this: A = \\[32, 0.34, 10\\]  \nI want to display it as a histogram and give the first element value 1 on x-axis\n\nfig, axs = plt.subplots(1, 2)  \ncounts, bins1 = np.histogram(A)  \nbins = np.arange(1, 3 1)  \naxs\\[1\\].hist(bins1\\[:-1\\], bins, weights=counts)\n\npython, keras...\n\nI appreciate every help, since I've been looking the whole day for a solution.", "link": "https://www.reddit.com/r/MachineLearning/comments/lj9tqv/p_how_to_enumerate_1d_array_in_order_to_plot_it/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[p] how to enumerate 1-d array in order to -----> plot !!!  it? matplotlib histogram /!/ hello everyone,\n\ni have an array like this: a = \\[32, 0.34, 10\\]  \ni want to display it as a histogram and give the first element value 1 on x-axis\n\nfig, axs = plt.subplots(1, 2)  \ncounts, bins1 = np.histogram(a)  \nbins = np.arange(1, 3 1)  \naxs\\[1\\].hist(bins1\\[:-1\\], bins, weights=counts)\n\npython, keras...\n\ni appreciate every help, since i've been looking the whole day for a solution.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lj9tqv/p_how_to_enumerate_1d_array_in_order_to_plot_it/',)", "identifyer": 5734902, "year": "2021"}, {"autor": "ComfortableCod", "date": 1613250459000, "content": "How to enumerate 1-D array in order to plot it? matplotlib histogram /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/lj9ayd/how_to_enumerate_1d_array_in_order_to_plot_it/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "how to enumerate 1-d array in order to -----> plot !!!  it? matplotlib histogram /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lj9ayd/how_to_enumerate_1d_array_in_order_to_plot_it/',)", "identifyer": 5734904, "year": "2021"}, {"autor": "MaxRek", "date": 1620342257000, "content": "[Project], [Discussion] Do you know any time series annotation platform? /!/ Last many months I am engaged in the generation and study of signal values \u200b\u200bin time series, built on the data of the electronic document flow (electronic documents interchange) of large companies and their contractors, indicating significant drops in the indicators of companies.\n\nI learned how to produce a couple of types of signals with this data, but there is one problem with them - frequent false positives. To combat this feature, I want to add markup.\n\nFor mark up purposes on time series data will be needed in near future annotation mechanism for my work project.\n\nRequirements for functionality:\n* Many-classes labeling\n* In plot labeling or/and labeling by index/value/out of threshold\n* for a large number of time series - the ability to maintain / fill several markup sessions at once\n* editing marked values\n* the ability to work with sub series of the last n values \u200b\u200bof the time series\n* tagged data statistics\n\nIs existing something for covering the requirements?", "link": "https://www.reddit.com/r/MachineLearning/comments/n6kbcy/project_discussion_do_you_know_any_time_series/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[project], [discussion] do you know any time series annotation platform? /!/ last many months i am engaged in the generation and study of signal values \u200b\u200bin time series, built on the data of the electronic document flow (electronic documents interchange) of large companies and their contractors, indicating significant drops in the indicators of companies.\n\ni learned how to produce a couple of types of signals with this data, but there is one problem with them - frequent false positives. to combat this feature, i want to add markup.\n\nfor mark up purposes on time series data will be needed in near future annotation mechanism for my work project.\n\nrequirements for functionality:\n* many-classes labeling\n* in -----> plot !!!  labeling or/and labeling by index/value/out of threshold\n* for a large number of time series - the ability to maintain / fill several markup sessions at once\n* editing marked values\n* the ability to work with sub series of the last n values \u200b\u200bof the time series\n* tagged data statistics\n\nis existing something for covering the requirements?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 9, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n6kbcy/project_discussion_do_you_know_any_time_series/',)", "identifyer": 5735536, "year": "2021"}, {"autor": "jj4646", "date": 1620167156000, "content": "[D] basic questions about linear regression /!/ 1) often we are told that linear regression models with many beta coefficients are \"undesirable\" (e.g. 100 beta coefficients, 100 predictors) - in general, these models are said to be unstable, high variance and likely to perform poorly. Does anyone know why this is?\n\n2) this is a common sense question: suppose you have 3 variables (1 response, 2 predictors). You make a plot of these 3 variables and you notice that the plot of this data is clearly NOT linear. Therefore, you would decide NOT to use a linear regression model. Is there any mathematical logic that shows why a linear regression model is unable to well represent non-linear data? For 3 variables, i guess you could show this visually - but for higher dimensional data, what is the mathematical justification used to understand why a linear model can not capture non linear data?\n\n3) in the previous question, i asked if linear models are \"too rigid\" to capture non linear patterns. But what about the opposite? Suppose you take the same example with the 3 variables : 2 predictors and 1 response. This time you have new data and make a plot, and the data appears to have a strong linear patterns. In this example, if you had still chosen to use a non-linear model : has their been any mathematical research that examines the ability of a non-linear model to capture linear patterns? In this example, would a linear model have some advantage at recognizing and capturing linear patterns compared to a non-linear model? Or in general, are linear patterns completely within the domain of non-linear patterns and as such, non-linear models are not expected to have any disadvantages at recognizing linear patterns (compared to linear models)?\n\n4) Are non-linear patterns more likely to occur in bigger datasets (more columns and more rows)? Could we not say that if there are more data points, there exist more geometric configurations that these data points can be arranged in -  making non-linear arrangements more probable?", "link": "https://www.reddit.com/r/MachineLearning/comments/n5052m/d_basic_questions_about_linear_regression/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] basic questions about linear regression /!/ 1) often we are told that linear regression models with many beta coefficients are \"undesirable\" (e.g. 100 beta coefficients, 100 predictors) - in general, these models are said to be unstable, high variance and likely to perform poorly. does anyone know why this is?\n\n2) this is a common sense question: suppose you have 3 variables (1 response, 2 predictors). you make a -----> plot !!!  of these 3 variables and you notice that the -----> plot !!!  of this data is clearly not linear. therefore, you would decide not to use a linear regression model. is there any mathematical logic that shows why a linear regression model is unable to well represent non-linear data? for 3 variables, i guess you could show this visually - but for higher dimensional data, what is the mathematical justification used to understand why a linear model can not capture non linear data?\n\n3) in the previous question, i asked if linear models are \"too rigid\" to capture non linear patterns. but what about the opposite? suppose you take the same example with the 3 variables : 2 predictors and 1 response. this time you have new data and make a plot, and the data appears to have a strong linear patterns. in this example, if you had still chosen to use a non-linear model : has their been any mathematical research that examines the ability of a non-linear model to capture linear patterns? in this example, would a linear model have some advantage at recognizing and capturing linear patterns compared to a non-linear model? or in general, are linear patterns completely within the domain of non-linear patterns and as such, non-linear models are not expected to have any disadvantages at recognizing linear patterns (compared to linear models)?\n\n4) are non-linear patterns more likely to occur in bigger datasets (more columns and more rows)? could we not say that if there are more data points, there exist more geometric configurations that these data points can be arranged in -  making non-linear arrangements more probable?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n5052m/d_basic_questions_about_linear_regression/',)", "identifyer": 5735591, "year": "2021"}, {"autor": "MassivePellfish", "date": 1631877465000, "content": "[N] Inside DeepMind's secret plot to break away from Google /!/ Article https://www.businessinsider.com/deepmind-secret-plot-break-away-from-google-project-watermelon-mario-2021-9\n\nby Hugh Langley and Martin Coulter\n\n&gt; For a while, some DeepMind employees referred to it as \"Watermelon.\" Later, executives called it \"Mario.\" Both code names meant the same thing: a secret plan to break away from parent company Google.\n&gt; \n&gt; DeepMind feared Google might one day misuse its technology, and executives worked to distance the artificial-intelligence firm from its owner for years, said nine current and former employees who were directly familiar with the plans. \n&gt; \n&gt; This included plans to pursue an independent legal status that would distance the group's work from Google, said the people, who asked not to be identified discussing private matters.\n&gt; \n&gt; One core tension at DeepMind was that it sold the business to people it didn't trust, said one former employee. \"Everything that happened since that point has been about them questioning that decision,\" the person added.\n&gt; \n&gt; Efforts to separate DeepMind from Google ended in April without a deal, The Wall Street Journal reported. The yearslong negotiations, along with recent shake-ups within Google's AI division, raise questions over whether the search giant can maintain control over a technology so crucial to its future.\n&gt; \n&gt; \"DeepMind's close partnership with Google and Alphabet since the acquisition has been extraordinarily successful \u2014 with their support, we've delivered research breakthroughs that transformed the AI field and are now unlocking some of the biggest questions in science,\" a DeepMind spokesperson said in a statement. \"Over the years, of course we've discussed and explored different structures within the Alphabet group to find the optimal way to support our long-term research mission. We could not be prouder to be delivering on this incredible mission, while continuing to have both operational autonomy and Alphabet's full support.\"\n&gt; \n&gt; When Google acquired DeepMind in 2014, the deal was seen as a win-win. Google got a leading AI research organization, and DeepMind, in London, won financial backing for its quest to build AI that can learn different tasks the way humans do, known as artificial general intelligence.\n&gt; \n&gt; But tensions soon emerged. Some employees described a cultural conflict between researchers who saw themselves firstly as academics and the sometimes bloated bureaucracy of Google's colossal business. Others said staff were immediately apprehensive about putting DeepMind's work under the control of a tech giant. For a while, some employees were encouraged to communicate using encrypted messaging apps over the fear of Google spying on their work.\n&gt; \n&gt; At one point, DeepMind's executives discovered that work published by Google's internal AI research group resembled some of DeepMind's codebase without citation, one person familiar with the situation said. \"That pissed off Demis,\" the person added, referring to Demis Hassabis, DeepMind's CEO. \"That was one reason DeepMind started to get more protective of their code.\"\n&gt; \n&gt; After Google restructured as Alphabet in 2015 to give riskier projects more freedom, DeepMind's leadership started to pursue a new status as a separate division under Alphabet, with its own profit and loss statement, The Information reported.\n&gt; \n&gt; DeepMind already enjoyed a high level of operational independence inside Alphabet, but the group wanted legal autonomy too. And it worried about the misuse of its technology, particularly if DeepMind were to ever achieve AGI.\n&gt; \n&gt; Internally, people started referring to the plan to gain more autonomy as \"Watermelon,\" two former employees said. The project was later formally named \"Mario\" among DeepMind's leadership, these people said.\n&gt; \n&gt; \"Their perspective is that their technology would be too powerful to be held by a private company, so it needs to be housed in some other legal entity detached from shareholder interest,\" one former employee who was close to the Alphabet negotiations said. \"They framed it as 'this is better for society.'\"\n&gt; \n&gt; In 2017, at a company retreat at the Macdonald Aviemore Resort in Scotland, DeepMind's leadership disclosed to employees its plan to separate from Google, two people who were present said.\n&gt; \n&gt; At the time, leadership said internally that the company planned to become a \"global interest company,\" three people familiar with the matter said. The title, not an official legal status, was meant to reflect the worldwide ramifications DeepMind believed its technology would have.\n&gt; \n&gt; Later, in negotiations with Google, DeepMind pursued a status as a company limited by guarantee, a corporate structure without shareholders that is sometimes used by nonprofits. The agreement was that Alphabet would continue to bankroll the firm and would get an exclusive license to its technology, two people involved in the discussions said. There was a condition: Alphabet could not cross certain ethical redlines, such as using DeepMind technology for military weapons or surveillance. \n&gt; \n&gt; In 2019, DeepMind registered a new company called DeepMind Labs Limited, as well as a new holding company, filings with the UK's Companies House showed. This was done in anticipation of a separation from Google, two former employees involved in those registrations said.\n&gt; \n&gt; Negotiations with Google went through peaks and valleys over the years but gained new momentum in 2020, one person said. A senior team inside DeepMind started to hold meetings with outside lawyers and Google to hash out details of what this theoretical new formation might mean for the two companies' relationship, including specifics such as whether they would share a codebase, internal performance metrics, and software expenses, two people said.\n&gt; \n&gt; From the start, DeepMind was thinking about potential ethical dilemmas from its deal with Google. Before the 2014 acquisition closed, both companies signed an \"Ethics and Safety Review Agreement\" that would prevent Google from taking control of DeepMind's technology, The Economist reported in 2019. Part of the agreement included the creation of an ethics board that would supervise the research. \n&gt; \n&gt; Despite years of internal discussions about who should sit on this board, and vague promises to the press, this group \"never existed, never convened, and never solved any ethics issues,\" one former employee close to those discussions said. A DeepMind spokesperson declined to comment.\n&gt; \n&gt; DeepMind did pursue a different idea: an independent review board to convene if it were to separate from Google, three people familiar with the plans said. The board would be made up of Google and DeepMind executives, as well as third parties. Former US president Barack Obama was someone DeepMind wanted to approach for this board, said one person who saw a shortlist of candidates.\n&gt; \n&gt; DeepMind also created an ethical charter that included bans on using its technology for military weapons or surveillance, as well as a rule that its technology should be used for ways that benefit society. In 2017, DeepMind started a unit focused on AI ethics research composed of employees and external research fellows. Its stated goal was to \"pave the way for truly beneficial and responsible AI.\" \n&gt; \n&gt; A few months later, a controversial contract between Google and the Pentagon was disclosed, causing an internal uproar in which employees accused Google of getting into \"the business of war.\" \n&gt; \n&gt; Google's Pentagon contract, known as Project Maven, \"set alarm bells ringing\" inside DeepMind, a former employee said. Afterward, Google published a set of principles to govern its work in AI, guidelines that were similar to the ethical charter that DeepMind had already set out internally, rankling some of DeepMind's senior leadership, two former employees said.\n&gt; \n&gt; In April, Hassabis told employees in an all-hands meeting that negotiations to separate from Google had ended. DeepMind would maintain its existing status inside Alphabet. DeepMind's future work would be overseen by Google's Advanced Technology Review Council, which includes two DeepMind executives, Google's AI chief Jeff Dean, and the legal SVP Kent Walker.\n&gt; \n&gt; But the group's yearslong battle to achieve more independence raises questions about its future within Google.\n&gt; \n&gt; Google's commitment to AI research has also come under question, after the company forced out two of its most senior AI ethics researchers. That led to an industry backlash and sowed doubt over whether it could allow truly independent research.\n&gt; \n&gt; Ali Alkhatib, a fellow at the Center for Applied Data Ethics, told Insider that more public accountability was \"desperately needed\" to regulate the pursuit of AI by large tech companies. \n&gt; \n&gt; For Google, its investment in DeepMind may be starting to pay off. Late last year, DeepMind announced a breakthrough to help scientists better understand the behavior of microscopic proteins, which has the potential to revolutionize drug discovery.\n&gt; \n&gt; As for DeepMind, Hassabis is holding on to the belief that AI technology should not be controlled by a single corporation. Speaking at Tortoise's Responsible AI Forum in June, he proposed a \"world institute\" of AI. Such a body might sit under the jurisdiction of the United Nations, Hassabis theorized, and could be filled with top researchers in the field. \n&gt; \n&gt; \"It's much stronger if you lead by example,\" he told the audience, \"and I hope DeepMind can be part of that role-modeling for the industry.\"", "link": "https://www.reddit.com/r/MachineLearning/comments/ppy7k4/n_inside_deepminds_secret_plot_to_break_away_from/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[n] inside deepmind's secret -----> plot !!!  to break away from google /!/ article https://www.businessinsider.com/deepmind-secret-plot-break-away-from-google-project-watermelon-mario-2021-9\n\nby hugh langley and martin coulter\n\n&gt; for a while, some deepmind employees referred to it as \"watermelon.\" later, executives called it \"mario.\" both code names meant the same thing: a secret plan to break away from parent company google.\n&gt; \n&gt; deepmind feared google might one day misuse its technology, and executives worked to distance the artificial-intelligence firm from its owner for years, said nine current and former employees who were directly familiar with the plans. \n&gt; \n&gt; this included plans to pursue an independent legal status that would distance the group's work from google, said the people, who asked not to be identified discussing private matters.\n&gt; \n&gt; one core tension at deepmind was that it sold the business to people it didn't trust, said one former employee. \"everything that happened since that point has been about them questioning that decision,\" the person added.\n&gt; \n&gt; efforts to separate deepmind from google ended in april without a deal, the wall street journal reported. the yearslong negotiations, along with recent shake-ups within google's ai division, raise questions over whether the search giant can maintain control over a technology so crucial to its future.\n&gt; \n&gt; \"deepmind's close partnership with google and alphabet since the acquisition has been extraordinarily successful \u2014 with their support, we've delivered research breakthroughs that transformed the ai field and are now unlocking some of the biggest questions in science,\" a deepmind spokesperson said in a statement. \"over the years, of course we've discussed and explored different structures within the alphabet group to find the optimal way to support our long-term research mission. we could not be prouder to be delivering on this incredible mission, while continuing to have both operational autonomy and alphabet's full support.\"\n&gt; \n&gt; when google acquired deepmind in 2014, the deal was seen as a win-win. google got a leading ai research organization, and deepmind, in london, won financial backing for its quest to build ai that can learn different tasks the way humans do, known as artificial general intelligence.\n&gt; \n&gt; but tensions soon emerged. some employees described a cultural conflict between researchers who saw themselves firstly as academics and the sometimes bloated bureaucracy of google's colossal business. others said staff were immediately apprehensive about putting deepmind's work under the control of a tech giant. for a while, some employees were encouraged to communicate using encrypted messaging apps over the fear of google spying on their work.\n&gt; \n&gt; at one point, deepmind's executives discovered that work published by google's internal ai research group resembled some of deepmind's codebase without citation, one person familiar with the situation said. \"that pissed off demis,\" the person added, referring to demis hassabis, deepmind's ceo. \"that was one reason deepmind started to get more protective of their code.\"\n&gt; \n&gt; after google restructured as alphabet in 2015 to give riskier projects more freedom, deepmind's leadership started to pursue a new status as a separate division under alphabet, with its own profit and loss statement, the information reported.\n&gt; \n&gt; deepmind already enjoyed a high level of operational independence inside alphabet, but the group wanted legal autonomy too. and it worried about the misuse of its technology, particularly if deepmind were to ever achieve agi.\n&gt; \n&gt; internally, people started referring to the plan to gain more autonomy as \"watermelon,\" two former employees said. the project was later formally named \"mario\" among deepmind's leadership, these people said.\n&gt; \n&gt; \"their perspective is that their technology would be too powerful to be held by a private company, so it needs to be housed in some other legal entity detached from shareholder interest,\" one former employee who was close to the alphabet negotiations said. \"they framed it as 'this is better for society.'\"\n&gt; \n&gt; in 2017, at a company retreat at the macdonald aviemore resort in scotland, deepmind's leadership disclosed to employees its plan to separate from google, two people who were present said.\n&gt; \n&gt; at the time, leadership said internally that the company planned to become a \"global interest company,\" three people familiar with the matter said. the title, not an official legal status, was meant to reflect the worldwide ramifications deepmind believed its technology would have.\n&gt; \n&gt; later, in negotiations with google, deepmind pursued a status as a company limited by guarantee, a corporate structure without shareholders that is sometimes used by nonprofits. the agreement was that alphabet would continue to bankroll the firm and would get an exclusive license to its technology, two people involved in the discussions said. there was a condition: alphabet could not cross certain ethical redlines, such as using deepmind technology for military weapons or surveillance. \n&gt; \n&gt; in 2019, deepmind registered a new company called deepmind labs limited, as well as a new holding company, filings with the uk's companies house showed. this was done in anticipation of a separation from google, two former employees involved in those registrations said.\n&gt; \n&gt; negotiations with google went through peaks and valleys over the years but gained new momentum in 2020, one person said. a senior team inside deepmind started to hold meetings with outside lawyers and google to hash out details of what this theoretical new formation might mean for the two companies' relationship, including specifics such as whether they would share a codebase, internal performance metrics, and software expenses, two people said.\n&gt; \n&gt; from the start, deepmind was thinking about potential ethical dilemmas from its deal with google. before the 2014 acquisition closed, both companies signed an \"ethics and safety review agreement\" that would prevent google from taking control of deepmind's technology, the economist reported in 2019. part of the agreement included the creation of an ethics board that would supervise the research. \n&gt; \n&gt; despite years of internal discussions about who should sit on this board, and vague promises to the press, this group \"never existed, never convened, and never solved any ethics issues,\" one former employee close to those discussions said. a deepmind spokesperson declined to comment.\n&gt; \n&gt; deepmind did pursue a different idea: an independent review board to convene if it were to separate from google, three people familiar with the plans said. the board would be made up of google and deepmind executives, as well as third parties. former us president barack obama was someone deepmind wanted to approach for this board, said one person who saw a shortlist of candidates.\n&gt; \n&gt; deepmind also created an ethical charter that included bans on using its technology for military weapons or surveillance, as well as a rule that its technology should be used for ways that benefit society. in 2017, deepmind started a unit focused on ai ethics research composed of employees and external research fellows. its stated goal was to \"pave the way for truly beneficial and responsible ai.\" \n&gt; \n&gt; a few months later, a controversial contract between google and the pentagon was disclosed, causing an internal uproar in which employees accused google of getting into \"the business of war.\" \n&gt; \n&gt; google's pentagon contract, known as project maven, \"set alarm bells ringing\" inside deepmind, a former employee said. afterward, google published a set of principles to govern its work in ai, guidelines that were similar to the ethical charter that deepmind had already set out internally, rankling some of deepmind's senior leadership, two former employees said.\n&gt; \n&gt; in april, hassabis told employees in an all-hands meeting that negotiations to separate from google had ended. deepmind would maintain its existing status inside alphabet. deepmind's future work would be overseen by google's advanced technology review council, which includes two deepmind executives, google's ai chief jeff dean, and the legal svp kent walker.\n&gt; \n&gt; but the group's yearslong battle to achieve more independence raises questions about its future within google.\n&gt; \n&gt; google's commitment to ai research has also come under question, after the company forced out two of its most senior ai ethics researchers. that led to an industry backlash and sowed doubt over whether it could allow truly independent research.\n&gt; \n&gt; ali alkhatib, a fellow at the center for applied data ethics, told insider that more public accountability was \"desperately needed\" to regulate the pursuit of ai by large tech companies. \n&gt; \n&gt; for google, its investment in deepmind may be starting to pay off. late last year, deepmind announced a breakthrough to help scientists better understand the behavior of microscopic proteins, which has the potential to revolutionize drug discovery.\n&gt; \n&gt; as for deepmind, hassabis is holding on to the belief that ai technology should not be controlled by a single corporation. speaking at tortoise's responsible ai forum in june, he proposed a \"world institute\" of ai. such a body might sit under the jurisdiction of the united nations, hassabis theorized, and could be filled with top researchers in the field. \n&gt; \n&gt; \"it's much stronger if you lead by example,\" he told the audience, \"and i hope deepmind can be part of that role-modeling for the industry.\"", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 150, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ppy7k4/n_inside_deepminds_secret_plot_to_break_away_from/',)", "identifyer": 5736003, "year": "2021"}, {"autor": "seven_cl", "date": 1631744854000, "content": "[D] Interpreting lr finder plot for one cycle LR scheduler /!/ I am experimenting with [One Cycle](https://sgugger.github.io/the-1cycle-policy.html#the-1cycle-policy) lr scheduler and I am observing certain trends that I don't see discussed anywhere. I want to share what I have seen in case anyone else has seen something similar or if it is just something specific to the architecture and the dataset I am working on.\n\nRegarding the use of [lr finder](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html#how-do-you-find-a-good-learning-rate) for choosing learning rates. As a rule of thumb for using lr finder, it is suggested to use the point of higher gradient if using a constant value optimization algorithm, when using one cycle it is suggested to use a value near the minimum before divergence as the max lr. But no importance is given to the number of steps.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/sg1lxl6etqn71.png?width=394&amp;format=png&amp;auto=webp&amp;s=341fe2a5297e2e77beeec538df8a7513626897ee\n\nAs you can see in the image the max gradient and divergence points change a lot for different n values. Furthermore, I have been able to increase the max\\_lr as high as 1e3 without issues, and if divergence occurs it can be evaded just by increasing the number of epochs leading to better results, suggesting that what the limitation really is here is the change in the learning rate.\n\nSo how should we really interpret the lr finder plot? Is there a rule of thumb for extrapolating the behavior for a certain number of steps to a certain number of epochs?", "link": "https://www.reddit.com/r/MachineLearning/comments/pp0itx/d_interpreting_lr_finder_plot_for_one_cycle_lr/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] interpreting lr finder -----> plot !!!  for one cycle lr scheduler /!/ i am experimenting with [one cycle](https://sgugger.github.io/the-1cycle-policy.html#the-1cycle-policy) lr scheduler and i am observing certain trends that i don't see discussed anywhere. i want to share what i have seen in case anyone else has seen something similar or if it is just something specific to the architecture and the dataset i am working on.\n\nregarding the use of [lr finder](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html#how-do-you-find-a-good-learning-rate) for choosing learning rates. as a rule of thumb for using lr finder, it is suggested to use the point of higher gradient if using a constant value optimization algorithm, when using one cycle it is suggested to use a value near the minimum before divergence as the max lr. but no importance is given to the number of steps.\n\n&amp;#x200b;\n\nhttps://preview.redd.it/sg1lxl6etqn71.png?width=394&amp;format=png&amp;auto=webp&amp;s=341fe2a5297e2e77beeec538df8a7513626897ee\n\nas you can see in the image the max gradient and divergence points change a lot for different n values. furthermore, i have been able to increase the max\\_lr as high as 1e3 without issues, and if divergence occurs it can be evaded just by increasing the number of epochs leading to better results, suggesting that what the limitation really is here is the change in the learning rate.\n\nso how should we really interpret the lr finder plot? is there a rule of thumb for extrapolating the behavior for a certain number of steps to a certain number of epochs?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pp0itx/d_interpreting_lr_finder_plot_for_one_cycle_lr/',)", "identifyer": 5736080, "year": "2021"}, {"autor": "_saan", "date": 1615545387000, "content": "[D] Forecasting slow changing, square wave like time series /!/ Hello reddit!\n\nI'm  working on a project to forecast the bottom hole pressure of production  wells and the plot in attached figure shows the bottom hole pressure  over a period of roughly 3500 days. As you can see, the pressure changes  somewhat periodically till \\~1500 days and becomes constant afterwards.  So far, I have tried fitting lstm based auto-regressive models with  different window sizes on the first 1500 days in hopes of getting a  similar forecast but every attempt ended up giving a constant line. I  assume it is due to the fact that the variation in data is so low that  the model starts making single number predictions.\n\nPlease note that I am not using time as a feature. \n\nHave you ever come across such a problem? How did you/would you approach it?\n\nThank you!", "link": "https://www.reddit.com/r/MachineLearning/comments/m3eygg/d_forecasting_slow_changing_square_wave_like_time/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] forecasting slow changing, square wave like time series /!/ hello reddit!\n\ni'm  working on a project to forecast the bottom hole pressure of production  wells and the -----> plot !!!  in attached figure shows the bottom hole pressure  over a period of roughly 3500 days. as you can see, the pressure changes  somewhat periodically till \\~1500 days and becomes constant afterwards.  so far, i have tried fitting lstm based auto-regressive models with  different window sizes on the first 1500 days in hopes of getting a  similar forecast but every attempt ended up giving a constant line. i  assume it is due to the fact that the variation in data is so low that  the model starts making single number predictions.\n\nplease note that i am not using time as a feature. \n\nhave you ever come across such a problem? how did you/would you approach it?\n\nthank you!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/m3eygg/d_forecasting_slow_changing_square_wave_like_time/',)", "identifyer": 5736481, "year": "2021"}, {"autor": "jj4646", "date": 1618864084000, "content": "[D] Has anyone ever heard of \"scissor plots\" being used in machine learning? /!/ https://imgur.com/a/d2t6gII\n\nI came across this interesting graph called \"scissors plot\". I have never heard about it before - has anyone else heard about it? Is this a well known plot? \n\nIt would be interesting to know if there was some way to roughly approximate the \"N-o\" point, perhaps the \"N-o\" point could be used to decide if it makes more sense to use \"complex\" models or \"simple\" models.", "link": "https://www.reddit.com/r/MachineLearning/comments/mu9ql7/d_has_anyone_ever_heard_of_scissor_plots_being/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] has anyone ever heard of \"scissor plots\" being used in machine learning? /!/ https://imgur.com/a/d2t6gii\n\ni came across this interesting graph called \"scissors -----> plot !!! \". i have never heard about it before - has anyone else heard about it? is this a well known plot? \n\nit would be interesting to know if there was some way to roughly approximate the \"n-o\" point, perhaps the \"n-o\" point could be used to decide if it makes more sense to use \"complex\" models or \"simple\" models.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mu9ql7/d_has_anyone_ever_heard_of_scissor_plots_being/',)", "identifyer": 5736877, "year": "2021"}, {"autor": "No-Ice-5452", "date": 1625995092000, "content": "Stylegan-2 Ada Loss Interpretation [D] / [P] /!/ &amp;#x200B;\n\nHi! I'm new to generative networks, and recently I've started training a stylegan2-Ada model on video game sprites. I've plotted out the loss of the training using the tf-events file that the code provides for you, however I'm having some trouble interpreting the graphs. Can anyone provide me with some resources that will explain in-depth what each plot means?\n\nLoss Labels in [tf.events](https://tf.events/) file:\n\nloss = \\['Loss/scores/fake',\n\n'Loss/signs/fake',\n\n'Loss/squares/fake',\n\n'Loss/scores/real',\n\n'Loss/signs/real',\n\n'Loss/squares/real',\n\n'Loss/r1\\_penalty',\n\n'Loss/pl\\_penalty',\n\n'Loss/G/loss',\n\n'Loss/D/loss',\n\n'Loss/G/reg',\n\n'Loss/D/reg',\n\n'TrainG/learning\\_rate',\n\n'TrainG/overflow\\_frequency',\n\n'TrainD/learning\\_rate',\n\n'TrainD/overflow\\_frequency',\n\n'RegG/learning\\_rate',\n\n'RegG/overflow\\_frequency',\n\n'RegD/learning\\_rate',\n\n'RegD/overflow\\_frequency',\n\n\\]", "link": "https://www.reddit.com/r/MachineLearning/comments/oi1acr/stylegan2_ada_loss_interpretation_d_p/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "stylegan-2 ada loss interpretation [d] / [p] /!/ &amp;#x200b;\n\nhi! i'm new to generative networks, and recently i've started training a stylegan2-ada model on video game sprites. i've plotted out the loss of the training using the tf-events file that the code provides for you, however i'm having some trouble interpreting the graphs. can anyone provide me with some resources that will explain in-depth what each -----> plot !!!  means?\n\nloss labels in [tf.events](https://tf.events/) file:\n\nloss = \\['loss/scores/fake',\n\n'loss/signs/fake',\n\n'loss/squares/fake',\n\n'loss/scores/real',\n\n'loss/signs/real',\n\n'loss/squares/real',\n\n'loss/r1\\_penalty',\n\n'loss/pl\\_penalty',\n\n'loss/g/loss',\n\n'loss/d/loss',\n\n'loss/g/reg',\n\n'loss/d/reg',\n\n'traing/learning\\_rate',\n\n'traing/overflow\\_frequency',\n\n'traind/learning\\_rate',\n\n'traind/overflow\\_frequency',\n\n'regg/learning\\_rate',\n\n'regg/overflow\\_frequency',\n\n'regd/learning\\_rate',\n\n'regd/overflow\\_frequency',\n\n\\]", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/oi1acr/stylegan2_ada_loss_interpretation_d_p/',)", "identifyer": 5737551, "year": "2021"}, {"autor": "dissonantloos", "date": 1629114786000, "content": "[D] How to analyze and solve faulty GAN training results? /!/ Hi Machine Learning!\n\nI'm trying to train a super resolution model inspired by [WESPE](https://arxiv.org/pdf/1709.01118.pdf), but applied to different data (satellite data). While I partially get there, I am also getting artifacts in the result images of which I find it difficult to explain the source. \n\nDoes anyone have tips on how to analyze training results to know or have hints of what's going wrong? How do you guys commonly approach iterating on training results? Are there articles on 'best practices'? In short how to 'debug' our training runs, but not necessarily the code?\n\nTo make it concrete, I get 'waves' or 'bulbs' the generated satellite data that isn't present in the original low resolution data nor in the target high resolution data.\n\nI of course have a validation set separate from the training set. I also plot graphs from our losses (discriminator loss, perceptual loss, ...) but they don't seem indicative of the source of this pattern.", "link": "https://www.reddit.com/r/MachineLearning/comments/p5eiws/d_how_to_analyze_and_solve_faulty_gan_training/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] how to analyze and solve faulty gan training results? /!/ hi machine learning!\n\ni'm trying to train a super resolution model inspired by [wespe](https://arxiv.org/pdf/1709.01118.pdf), but applied to different data (satellite data). while i partially get there, i am also getting artifacts in the result images of which i find it difficult to explain the source. \n\ndoes anyone have tips on how to analyze training results to know or have hints of what's going wrong? how do you guys commonly approach iterating on training results? are there articles on 'best practices'? in short how to 'debug' our training runs, but not necessarily the code?\n\nto make it concrete, i get 'waves' or 'bulbs' the generated satellite data that isn't present in the original low resolution data nor in the target high resolution data.\n\ni of course have a validation set separate from the training set. i also -----> plot !!!  graphs from our losses (discriminator loss, perceptual loss, ...) but they don't seem indicative of the source of this pattern.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p5eiws/d_how_to_analyze_and_solve_faulty_gan_training/',)", "identifyer": 5738186, "year": "2021"}, {"autor": "thunder_jaxx", "date": 1619136659000, "content": "[D] Attention is All We Want. : A plot of papers mentioning \"self-attention\" on CS ArXiv since 2017. Source of chart comments", "link": "https://www.reddit.com/r/MachineLearning/comments/mwimtc/d_attention_is_all_we_want_a_plot_of_papers/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] attention is all we want. : a -----> plot !!!  of papers mentioning \"self-attention\" on cs arxiv since 2017. source of chart comments", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 3, "media": "('image',)", "medialink": "('https://i.redd.it/iau67onletu61.png',)", "identifyer": 5738281, "year": "2021"}, {"autor": "Lovelifepending", "date": 1614714827000, "content": "[D] theta 1 and theta 0 -what does It all mean? /!/ I'm currently doing one of Andrew Yang's machine Learning courses but I'm stuck on how to plot linear regression functions, especially the theta 1 theta 0 thing. He doesn't really explain it on the course,  and I've checked on Google and I'm not the only person struggling to make sense of it , help.", "link": "https://www.reddit.com/r/MachineLearning/comments/lwaxl2/d_theta_1_and_theta_0_what_does_it_all_mean/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] theta 1 and theta 0 -what does it all mean? /!/ i'm currently doing one of andrew yang's machine learning courses but i'm stuck on how to -----> plot !!!  linear regression functions, especially the theta 1 theta 0 thing. he doesn't really explain it on the course,  and i've checked on google and i'm not the only person struggling to make sense of it , help.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lwaxl2/d_theta_1_and_theta_0_what_does_it_all_mean/',)", "identifyer": 5738562, "year": "2021"}, {"autor": "forthispost96", "date": 1623275989000, "content": "[Discussion] Correlated Outputs from Deep Learning Mutli-Output Regression /!/ I'm dealing with a problem at work right now that involves taking a non-linear signal generated from 5 continuous variables and training a Denoising Autoencoder to reconstruct the signal. Signals were generated by **randomly scanning over the vector space.** All variables are normalized between 0 and 1 and their histograms are flat across this space.\n\nThe main goal is to ensure that the latent representation of any signal is equal to the 5D vector that generated it. I enforce this constraint through a simple weighted sum of two MSE loss functions:\n\n*loss = alpha \\* mse(5D\\_label, latent\\_embedding) + (1 - alpha) \\* mse(signal, reconstructed\\_signal)*\n\nI am able to obtain great reconstructed signals, but I find that I *always* obtain some type of correlation between the latent neurons (as seen in the correlation matrix attached). Furthermore, I find that the same feature always becomes mis-represented (Scatter plot attached shows each feature plotted against its embedding along with the R2 value in the legend)\n\nDoes anyone have any intuition as to why this would be occurring? I've even tried overfitting the model to absolute hell and I cannot for the life of me get close to perfect predictions. I've also tried using a simple (small) dense NN for this and still no luck. Any insight would be insanely appreciated!\n\nhttps://preview.redd.it/kjjcysvpbb471.png?width=864&amp;format=png&amp;auto=webp&amp;s=81f8a8529c16791662233be510b54901d0a46b49\n\nhttps://preview.redd.it/9y3sqo5obb471.png?width=580&amp;format=png&amp;auto=webp&amp;s=9653fa1b1dc48ea0b28af7a8ec7b5e05d51352b6", "link": "https://www.reddit.com/r/MachineLearning/comments/nw7jo2/discussion_correlated_outputs_from_deep_learning/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[discussion] correlated outputs from deep learning mutli-output regression /!/ i'm dealing with a problem at work right now that involves taking a non-linear signal generated from 5 continuous variables and training a denoising autoencoder to reconstruct the signal. signals were generated by **randomly scanning over the vector space.** all variables are normalized between 0 and 1 and their histograms are flat across this space.\n\nthe main goal is to ensure that the latent representation of any signal is equal to the 5d vector that generated it. i enforce this constraint through a simple weighted sum of two mse loss functions:\n\n*loss = alpha \\* mse(5d\\_label, latent\\_embedding) + (1 - alpha) \\* mse(signal, reconstructed\\_signal)*\n\ni am able to obtain great reconstructed signals, but i find that i *always* obtain some type of correlation between the latent neurons (as seen in the correlation matrix attached). furthermore, i find that the same feature always becomes mis-represented (scatter -----> plot !!!  attached shows each feature plotted against its embedding along with the r2 value in the legend)\n\ndoes anyone have any intuition as to why this would be occurring? i've even tried overfitting the model to absolute hell and i cannot for the life of me get close to perfect predictions. i've also tried using a simple (small) dense nn for this and still no luck. any insight would be insanely appreciated!\n\nhttps://preview.redd.it/kjjcysvpbb471.png?width=864&amp;format=png&amp;auto=webp&amp;s=81f8a8529c16791662233be510b54901d0a46b49\n\nhttps://preview.redd.it/9y3sqo5obb471.png?width=580&amp;format=png&amp;auto=webp&amp;s=9653fa1b1dc48ea0b28af7a8ec7b5e05d51352b6", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nw7jo2/discussion_correlated_outputs_from_deep_learning/',)", "identifyer": 5738769, "year": "2021"}, {"autor": "Tsadkiel", "date": 1624115297000, "content": "[D] The PDLT document from Facebook is currently worthless as a scientific text and exemplifies the serious problem we are facing with reproducibility within the community. /!/ https://ai.facebook.com/blog/advancing-ai-theory-with-a-first-principles-understanding-of-deep-neural-networks/\n\n\nFrom the preface:\n\n\n\"\nFirst and foremost, in this book we\u2019ve strived for pedagogy in every choice we\u2019ve\nmade, placing intuition above formality. This doesn\u2019t mean that calculations are incomplete or sloppy; quite the opposite, we\u2019ve tried to provide full details of every calculation\n\u2013 of which there are certainly very many \u2013 and place a particular emphasis on the tools\nneeded to carry out related calculations of interest. In fact, understanding how the calculations are done is as important as knowing their results, and thus often our pedagogical\nfocus is on the details therein.\n\n\nSecond, while we present the details of all our calculations, **we\u2019ve kept the experimental confirmations to the privacy of our own computerized notebooks**. Our reason\nfor this is simple: while there\u2019s much to learn from explaining a derivation, there\u2019s not\nmuch more to learn from printing a verification plot that shows two curves lying on top\nof each other. **Given the simplicity of modern deep-learning codes and the availability\nof compute, it\u2019s easy to verify any formula on your own**; we certainly have thoroughly\nchecked them all this way, so if knowledge of the existence of such plots are comforting\nto you, **know at least that they do exist on our personal and cloud-based hard drives**.\"\n\n\nI can't speak for everyone reading this.  I can only speak for myself. That said, I have a PhD in physics and I currently work as a deep learning research scientist and engineer for a major tech company. I have dedicated my entire life to the study of natural law, science, and the nature of scientific inquiry as a whole. Never once in more than two decades of my time as a graduate student, a scientist, and an engineer have I ever read a text book that began...\n\n\n\"We know you want to see the evidence.  We know you want to know what experiments we ran to appropriately test these theories.  We know you want to know to what degree of significance we have rejected various other hypotheses, and how that was done.  We know you want to know **but we aren't going to tell you.  We leave the verification if this work as an exercise to the reader. Trust  us** \"\n\n\nWhat are we even supposed to do with this?! \n\n\nNo WONDER we have an issue with reproducibility in the field when deep learning \"scientists\" are publishing documents without any actual science in it! No wonder we have literal collusion rings in our peer review process! \n\n\nThere is a full litany of mathematical assumption that form the foundation of the deductions made in this document and the author's claim to their validity stand solely on their trustworthyness.  Need I remind you all that they work for a corporation, Facebook specifically, that isn't exactly known for its honesty.\n\n\nI am reminded of the motto of the Royal Society, one of the most well established scientific institutions in modern history.\n\n\nNullius in verba\n\nWords are empty.\n\n\nTake nobodies word for it", "link": "https://www.reddit.com/r/MachineLearning/comments/o3i4gh/d_the_pdlt_document_from_facebook_is_currently/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] the pdlt document from facebook is currently worthless as a scientific text and exemplifies the serious problem we are facing with reproducibility within the community. /!/ https://ai.facebook.com/blog/advancing-ai-theory-with-a-first-principles-understanding-of-deep-neural-networks/\n\n\nfrom the preface:\n\n\n\"\nfirst and foremost, in this book we\u2019ve strived for pedagogy in every choice we\u2019ve\nmade, placing intuition above formality. this doesn\u2019t mean that calculations are incomplete or sloppy; quite the opposite, we\u2019ve tried to provide full details of every calculation\n\u2013 of which there are certainly very many \u2013 and place a particular emphasis on the tools\nneeded to carry out related calculations of interest. in fact, understanding how the calculations are done is as important as knowing their results, and thus often our pedagogical\nfocus is on the details therein.\n\n\nsecond, while we present the details of all our calculations, **we\u2019ve kept the experimental confirmations to the privacy of our own computerized notebooks**. our reason\nfor this is simple: while there\u2019s much to learn from explaining a derivation, there\u2019s not\nmuch more to learn from printing a verification -----> plot !!!  that shows two curves lying on top\nof each other. **given the simplicity of modern deep-learning codes and the availability\nof compute, it\u2019s easy to verify any formula on your own**; we certainly have thoroughly\nchecked them all this way, so if knowledge of the existence of such plots are comforting\nto you, **know at least that they do exist on our personal and cloud-based hard drives**.\"\n\n\ni can't speak for everyone reading this.  i can only speak for myself. that said, i have a phd in physics and i currently work as a deep learning research scientist and engineer for a major tech company. i have dedicated my entire life to the study of natural law, science, and the nature of scientific inquiry as a whole. never once in more than two decades of my time as a graduate student, a scientist, and an engineer have i ever read a text book that began...\n\n\n\"we know you want to see the evidence.  we know you want to know what experiments we ran to appropriately test these theories.  we know you want to know to what degree of significance we have rejected various other hypotheses, and how that was done.  we know you want to know **but we aren't going to tell you.  we leave the verification if this work as an exercise to the reader. trust  us** \"\n\n\nwhat are we even supposed to do with this?! \n\n\nno wonder we have an issue with reproducibility in the field when deep learning \"scientists\" are publishing documents without any actual science in it! no wonder we have literal collusion rings in our peer review process! \n\n\nthere is a full litany of mathematical assumption that form the foundation of the deductions made in this document and the author's claim to their validity stand solely on their trustworthyness.  need i remind you all that they work for a corporation, facebook specifically, that isn't exactly known for its honesty.\n\n\ni am reminded of the motto of the royal society, one of the most well established scientific institutions in modern history.\n\n\nnullius in verba\n\nwords are empty.\n\n\ntake nobodies word for it", "sortedWord": "None", "removed": "('nan',)", "score": 7, "comments": 42, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o3i4gh/d_the_pdlt_document_from_facebook_is_currently/',)", "identifyer": 5739256, "year": "2021"}, {"autor": "Yettzusk", "date": 1628430574000, "content": "[D] Python plot package commonly used in RL papers /!/ Hi everyone, I was looking at Figure 6 of the QMIX paper and I think that  I probably need to draw a plot similar to this one in the future, i.e. reward curves showing 95% confidence interval. Does anyone which package did the author of this paper used to generate Figure 6? It doesn't seem like Mathplotlib to me or I could be wrong.\n\nThanks in advance.\n\nArVix link: [https://arxiv.org/pdf/1803.11485.pdf](https://arxiv.org/pdf/1803.11485.pdf)", "link": "https://www.reddit.com/r/MachineLearning/comments/p0ez1l/d_python_plot_package_commonly_used_in_rl_papers/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] python -----> plot !!!  package commonly used in rl papers /!/ hi everyone, i was looking at figure 6 of the qmix paper and i think that  i probably need to draw a plot similar to this one in the future, i.e. reward curves showing 95% confidence interval. does anyone which package did the author of this paper used to generate figure 6? it doesn't seem like mathplotlib to me or i could be wrong.\n\nthanks in advance.\n\narvix link: [https://arxiv.org/pdf/1803.11485.pdf](https://arxiv.org/pdf/1803.11485.pdf)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 13, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p0ez1l/d_python_plot_package_commonly_used_in_rl_papers/',)", "identifyer": 5739790, "year": "2021"}, {"autor": "vitokonte", "date": 1621236299000, "content": "[D] Summarising feature importances - best way? /!/ Hi,\n\nI am running a binary classifier and I have a pipeline with 5 or more different type of classifiers such as Random Forest, XGBoost, EasyEnsenmble, etc. I also collect the feature importance of each classifier. \n\nWhat would be the most valid way to summarise feature importance? Can I simply average the feature importance value for each of the classifiers and then plot it? What if my classifiers have different performances, would that still work with feature importance? \n\n&amp;#x200B;\n\n[This is how I do it now](https://preview.redd.it/bme7y756umz61.png?width=1204&amp;format=png&amp;auto=webp&amp;s=2801e1af9d8881f36a33c264943f469032b41992)\n\nThank you", "link": "https://www.reddit.com/r/MachineLearning/comments/ne9kcr/d_summarising_feature_importances_best_way/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "plot", "selectorShort": "plot", "MarkedSent": "[d] summarising feature importances - best way? /!/ hi,\n\ni am running a binary classifier and i have a pipeline with 5 or more different type of classifiers such as random forest, xgboost, easyensenmble, etc. i also collect the feature importance of each classifier. \n\nwhat would be the most valid way to summarise feature importance? can i simply average the feature importance value for each of the classifiers and then -----> plot !!!  it? what if my classifiers have different performances, would that still work with feature importance? \n\n&amp;#x200b;\n\n[this is how i do it now](https://preview.redd.it/bme7y756umz61.png?width=1204&amp;format=png&amp;auto=webp&amp;s=2801e1af9d8881f36a33c264943f469032b41992)\n\nthank you", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 8, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ne9kcr/d_summarising_feature_importances_best_way/',)", "identifyer": 5740855, "year": "2021"}], "name": "plotMachineLearning2021"}