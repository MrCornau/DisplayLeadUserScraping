{"interestingcomments": [{"autor": "ykilcher", "date": 1614443487000, "content": "[D] Paper Explained - GLOM: How to represent part-whole hierarchies in a neural network (by Geoff Hinton, Full Video Analysis) /!/ [https://youtu.be/cllFzkvrYmE](https://youtu.be/cllFzkvrYmE)\n\nGeoffrey Hinton describes GLOM, a Computer Vision model that combines transformers, neural fields, contrastive learning, capsule networks, denoising autoencoders and RNNs. GLOM decomposes an image into a parse tree of objects and their parts. However, unlike previous systems, the parse tree is constructed dynamically and differently for each input, without changing the underlying neural network. This is done by a multi-step consensus algorithm that runs over different levels of abstraction at each location of an image simultaneously. GLOM is just an idea for now but suggests a radically new approach to AI visual scene understanding.\n\n&amp;#x200B;\n\nOUTLINE:\n\n0:00 - Intro &amp; Overview\n\n3:10 - Object Recognition as Parse Trees\n\n5:40 - Capsule Networks\n\n8:00 - GLOM Architecture Overview\n\n13:10 - Top-Down and Bottom-Up communication\n\n18:30 - Emergence of Islands\n\n22:00 - Cross-Column Attention Mechanism\n\n27:10 - My Improvements for the Attention Mechanism\n\n35:25 - Some Design Decisions\n\n43:25 - Training GLOM as a Denoising Autoencoder &amp; Contrastive Learning\n\n52:20 - Coordinate Transformations &amp; Representing Uncertainty\n\n57:05 - How GLOM handles Video\n\n1:01:10 - Conclusion &amp; Comments\n\n&amp;#x200B;\n\nPaper: [https://arxiv.org/abs/2102.12627](https://arxiv.org/abs/2102.12627)", "link": "https://www.reddit.com/r/MachineLearning/comments/ltro4y/d_paper_explained_glom_how_to_represent_partwhole/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] paper explained - glom: how to represent part-whole hierarchies in a neural network (by geoff hinton, full video analysis) /!/ [https://youtu.be/cllfzkvryme](https://youtu.be/cllfzkvryme)\n\ngeoffrey hinton describes glom, a computer vision model that combines transformers, neural fields, contrastive learning, capsule networks, denoising autoencoders and rnns. glom decomposes an image into a parse -----> tree !!!  of objects and their parts. however, unlike previous systems, the parse tree is constructed dynamically and differently for each input, without changing the underlying neural network. this is done by a multi-step consensus algorithm that runs over different levels of abstraction at each location of an image simultaneously. glom is just an idea for now but suggests a radically new approach to ai visual scene understanding.\n\n&amp;#x200b;\n\noutline:\n\n0:00 - intro &amp; overview\n\n3:10 - object recognition as parse trees\n\n5:40 - capsule networks\n\n8:00 - glom architecture overview\n\n13:10 - top-down and bottom-up communication\n\n18:30 - emergence of islands\n\n22:00 - cross-column attention mechanism\n\n27:10 - my improvements for the attention mechanism\n\n35:25 - some design decisions\n\n43:25 - training glom as a denoising autoencoder &amp; contrastive learning\n\n52:20 - coordinate transformations &amp; representing uncertainty\n\n57:05 - how glom handles video\n\n1:01:10 - conclusion &amp; comments\n\n&amp;#x200b;\n\npaper: [https://arxiv.org/abs/2102.12627](https://arxiv.org/abs/2102.12627)", "sortedWord": "None", "removed": "('nan',)", "score": 32, "comments": 6, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ltro4y/d_paper_explained_glom_how_to_represent_partwhole/',)", "identifyer": 5721456, "year": "2021"}, {"autor": "badge", "date": 1617268644000, "content": "[D] Generalized Additive Models\u2026 with trees? /!/ I\u2019m looking at implementing Generalized Additive Models to work as speedily as possible (the entire end-to-end process), so started looking at using [C#\u2019s ML.NET](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.treeextensions.gam).\n\nI haven\u2019t used C# since ~2014 so reading the code is a bit difficult, but it\u2019s part of the FastTree library and is clearly a tree-based implementation. I tested it with a simple `y ~ sin(x)` model and it was dreadful (the FastForest regressor is much better).\n\nDoes anyone have any insight on what\u2019s being used here, or references on the subject? I\u2019ve used GAMs in R and Python and never seen a non-spline-based implementation before.", "link": "https://www.reddit.com/r/MachineLearning/comments/mhrglf/d_generalized_additive_models_with_trees/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] generalized additive models\u2026 with trees? /!/ i\u2019m looking at implementing generalized additive models to work as speedily as possible (the entire end-to-end process), so started looking at using [c#\u2019s ml.net](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.treeextensions.gam).\n\ni haven\u2019t used c# since ~2014 so reading the code is a bit difficult, but it\u2019s part of the fasttree library and is clearly a -----> tree !!! -based implementation. i tested it with a simple `y ~ sin(x)` model and it was dreadful (the fastforest regressor is much better).\n\ndoes anyone have any insight on what\u2019s being used here, or references on the subject? i\u2019ve used gams in r and python and never seen a non-spline-based implementation before.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mhrglf/d_generalized_additive_models_with_trees/',)", "identifyer": 5721602, "year": "2021"}, {"autor": "caraenderson", "date": 1622572321000, "content": "[D] How can C4.5 algorithm split numerical attributr /!/ How can c4.5 algorithm split numerical attributes? I had encountered one journal paper where the c4.5 decision tree has same attribute with different ranges multiple of time in same rules.\n\nFor example: IF age&gt;60 and wealth=poverty and age=&gt;75 then sick\nCan somebody explain?", "link": "https://www.reddit.com/r/MachineLearning/comments/nq0zo3/d_how_can_c45_algorithm_split_numerical_attributr/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] how can c4.5 algorithm split numerical attributr /!/ how can c4.5 algorithm split numerical attributes? i had encountered one journal paper where the c4.5 decision -----> tree !!!  has same attribute with different ranges multiple of time in same rules.\n\nfor example: if age&gt;60 and wealth=poverty and age=&gt;75 then sick\ncan somebody explain?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nq0zo3/d_how_can_c45_algorithm_split_numerical_attributr/',)", "identifyer": 5721849, "year": "2021"}, {"autor": "SQL_beginner", "date": 1622564885000, "content": "[D] Hypothesizing the Ideal Conditions for Neural Networks vs Random Forests /!/ Is it possible to speculate what are the ideal conditions required for a neural network to perform well compared to a random forest? \n\nFor instance, when dealing with image recognition tasks, we know that Convolution Neural Networks are generally favorable, seeing as how the \"convolution operation\" is very effective at \"understanding images\" (e.g. recognizing edges). \n\nNow suppose we look at a standard \"binary classification task\". Suppose we have a smaller sized dataset (e.g. 15 columns, 5000 rows). \n\nIn general terms, we know that a neural network works by approximating small regions of the target function with a collection of \"mini functions\". This is done by calculating a set of weights : in the future, data is passed through this network of weights, and these weights are used to calculate the probability that a new observation belongs to a certain class is calculated. In theory, we could repeatedly pass similar points through the neural network and monitor how the probability of belonging to a certain class incrementally changes.\n\nA random forest is quite different. Look at the decision tree for a second - the decision tree works by randomly making binary partitions in the data. A binary partition is made for a predictor variable, such that this partition tries its best to cleanly separate the classes of the response variable. When a suitable partition is made for the first predictor variable, we move on to the second variable, then the third variable, etc. So in the end, if we imagine our data as a \"big box\", we create these \"mini boxes\" (i.e. terminal nodes) within the \"big box\" : each of these \"mini boxes\" has an \"address\" (i.e. the different partitions, e.g. if var1&gt;5 and var2&lt;10 then \"mini box 1\"). Each of these mini boxes is associated with a response label.\n\nThe random forest improves the decision tree by bootstrap aggregation: thousands of randomized and smaller decision trees are combined together for improved predictive power and less overfitting. All the trees in the forest are used to collectively decide which \"mini box\" a new observation should be placed in.\n\nMy question: based on this very general understanding on how both these algorithms work - can we try to hypothesize what kind of datasets are more suited for neural networks vs random forests? For example, in the random forest algorithm, by using the gini index criteria, it is relatively straightforward to make \"mini boxes\" for categorial predictor variables. However, a neural network would have to one-hot-encode these categorical predictor variables and as a result, deal with more variables (curse of dimensionality) and as well, these one-hot-encoded variables are likely to contain a greater level of sparsity. Furthermore, it might be easier to make general \"mini boxes\" in sparse data compared to using gradient descent with missing values?\n\nI know this is all speculation (and the \"no free lunch theorems\" say that no machine learning algorithm is universally best) - but could we try to speculate and say that certain machine learning algorithms might be better suited for certain types of datasets? Just as Convolution Neural Networks are better for image recognition and LSTM Networks are better at handling sequential data - could we argue that bagging and boosting algorithms (e.g. random forest, gradient boosting) might have an easier time at handling smaller datasets with mixed categorical-continuous variables? \n\nI would be interested in hearing some opinions and thoughts on this.\n\nThanks", "link": "https://www.reddit.com/r/MachineLearning/comments/npy08z/d_hypothesizing_the_ideal_conditions_for_neural/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] hypothesizing the ideal conditions for neural networks vs random forests /!/ is it possible to speculate what are the ideal conditions required for a neural network to perform well compared to a random forest? \n\nfor instance, when dealing with image recognition tasks, we know that convolution neural networks are generally favorable, seeing as how the \"convolution operation\" is very effective at \"understanding images\" (e.g. recognizing edges). \n\nnow suppose we look at a standard \"binary classification task\". suppose we have a smaller sized dataset (e.g. 15 columns, 5000 rows). \n\nin general terms, we know that a neural network works by approximating small regions of the target function with a collection of \"mini functions\". this is done by calculating a set of weights : in the future, data is passed through this network of weights, and these weights are used to calculate the probability that a new observation belongs to a certain class is calculated. in theory, we could repeatedly pass similar points through the neural network and monitor how the probability of belonging to a certain class incrementally changes.\n\na random forest is quite different. look at the decision -----> tree !!!  for a second - the decision -----> tree !!!  works by randomly making binary partitions in the data. a binary partition is made for a predictor variable, such that this partition tries its best to cleanly separate the classes of the response variable. when a suitable partition is made for the first predictor variable, we move on to the second variable, then the third variable, etc. so in the end, if we imagine our data as a \"big box\", we create these \"mini boxes\" (i.e. terminal nodes) within the \"big box\" : each of these \"mini boxes\" has an \"address\" (i.e. the different partitions, e.g. if var1&gt;5 and var2&lt;10 then \"mini box 1\"). each of these mini boxes is associated with a response label.\n\nthe random forest improves the decision tree by bootstrap aggregation: thousands of randomized and smaller decision trees are combined together for improved predictive power and less overfitting. all the trees in the forest are used to collectively decide which \"mini box\" a new observation should be placed in.\n\nmy question: based on this very general understanding on how both these algorithms work - can we try to hypothesize what kind of datasets are more suited for neural networks vs random forests? for example, in the random forest algorithm, by using the gini index criteria, it is relatively straightforward to make \"mini boxes\" for categorial predictor variables. however, a neural network would have to one-hot-encode these categorical predictor variables and as a result, deal with more variables (curse of dimensionality) and as well, these one-hot-encoded variables are likely to contain a greater level of sparsity. furthermore, it might be easier to make general \"mini boxes\" in sparse data compared to using gradient descent with missing values?\n\ni know this is all speculation (and the \"no free lunch theorems\" say that no machine learning algorithm is universally best) - but could we try to speculate and say that certain machine learning algorithms might be better suited for certain types of datasets? just as convolution neural networks are better for image recognition and lstm networks are better at handling sequential data - could we argue that bagging and boosting algorithms (e.g. random forest, gradient boosting) might have an easier time at handling smaller datasets with mixed categorical-continuous variables? \n\ni would be interested in hearing some opinions and thoughts on this.\n\nthanks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/npy08z/d_hypothesizing_the_ideal_conditions_for_neural/',)", "identifyer": 5721858, "year": "2021"}, {"autor": "Better_Cycle_490", "date": 1625100521000, "content": "Productionizing Distributed XGBoost to Train Deep Tree Models with Large Data Sets at Uber", "link": "https://www.reddit.com/r/MachineLearning/comments/obamgd/productionizing_distributed_xgboost_to_train_deep/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "productionizing distributed xgboost to train deep -----> tree !!!  models with large data sets at uber", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('link',)", "medialink": "('https://eng.uber.com/productionizing-distributed-xgboost/',)", "identifyer": 5722025, "year": "2021"}, {"autor": "davideganna", "date": 1627838413000, "content": "[Project] Developed a ML open source software which predicts NBA results. Looking for contributors :) /!/  \n\nHi everyone :)\n\nAs the title says, I've been working on an open source project which aims at predicting the outcome of NBA matches. In its current version, the software (100% written in python):\n\n* Scrapes a website ([https://www.basketball-reference.com/](https://www.basketball-reference.com/)) for new data at fixed times;\n* Features 4 models:  \n\n   * Random Forest\n   * Decision Tree\n   * Ada Boost\n   * Elo\n* Provides a way to backtest each model;\n* Allows Telegram integration (you get a notification on profitable matches directly on Telegram);\n* (*in progress*) Contacts the bookmaker of choice to get the odds for a particular match.\n\nDoes it work?\n\nBy testing the models on the past NBA season, the accuracy of the them are close to 64%.\n\nWhat I am looking for\n\nI am looking for passionate people to contribute to the software, most importantly by improving the models. In my deepest dreams, I would like to reach an accuracy of \\~70%.\n\nPlease note that I am not a software engineer, and despite the code works, that might not be the best code you have ever seen. For this reason, any comments/suggestions are very much appreciated.\n\nI am interested, how can I contribute?\n\nThe software is available at: [https://github.com/davideganna/NBA\\_Bet](https://github.com/davideganna/NBA_Bet)\n\n*Side note:* besides r/MachineLearning, which other subreddits might be suitable for promoting the software?", "link": "https://www.reddit.com/r/MachineLearning/comments/ovw7vm/project_developed_a_ml_open_source_software_which/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[project] developed a ml open source software which predicts nba results. looking for contributors :) /!/  \n\nhi everyone :)\n\nas the title says, i've been working on an open source project which aims at predicting the outcome of nba matches. in its current version, the software (100% written in python):\n\n* scrapes a website ([https://www.basketball-reference.com/](https://www.basketball-reference.com/)) for new data at fixed times;\n* features 4 models:  \n\n   * random forest\n   * decision -----> tree !!! \n   * ada boost\n   * elo\n* provides a way to backtest each model;\n* allows telegram integration (you get a notification on profitable matches directly on telegram);\n* (*in progress*) contacts the bookmaker of choice to get the odds for a particular match.\n\ndoes it work?\n\nby testing the models on the past nba season, the accuracy of the them are close to 64%.\n\nwhat i am looking for\n\ni am looking for passionate people to contribute to the software, most importantly by improving the models. in my deepest dreams, i would like to reach an accuracy of \\~70%.\n\nplease note that i am not a software engineer, and despite the code works, that might not be the best code you have ever seen. for this reason, any comments/suggestions are very much appreciated.\n\ni am interested, how can i contribute?\n\nthe software is available at: [https://github.com/davideganna/nba\\_bet](https://github.com/davideganna/nba_bet)\n\n*side note:* besides r/machinelearning, which other subreddits might be suitable for promoting the software?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ovw7vm/project_developed_a_ml_open_source_software_which/',)", "identifyer": 5722029, "year": "2021"}, {"autor": "omidAR123", "date": 1627771202000, "content": "How to improve decision tree plot? /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/ovgm3r/how_to_improve_decision_tree_plot/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "how to improve decision -----> tree !!!  plot? /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ovgm3r/how_to_improve_decision_tree_plot/',)", "identifyer": 5722057, "year": "2021"}, {"autor": "LucaAmbrogioni", "date": 1613151001000, "content": "[R] Automatic structured variational inference in TensorFlow probability /!/ &amp;#x200B;\n\n*Processing img cp98jshc03h61...*\n\nHappy to share the new version of \"automatic structured variational inference\" (ASVI) (Accepted at AISTATS2021)  Work in collaborations with the Google TensorFlow Probability team.  \n\n[Repository](https://github.com/google-research/google-research/tree/master/automatic_structured_vi)\n\n[Tutorial](https://www.tensorflow.org/probability/examples/TFP_Release_Notebook_0_12_1#build_asvi_surrogate_posterior)\n\n[Preprint](https://arxiv.org/pdf/2002.00643.pdf)\n\nASVI constructs structured variational families by parameterized convex updates:\n\n&amp;#x200B;\n\n*Processing gif dwdzw55uz2h61...*\n\nIn this way we can automatically construct complex structured variational models. here an example of a Brownian motion:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ymzdrbqyz2h61.png?width=529&amp;format=png&amp;auto=webp&amp;s=8d87fe0d70e9df3159a09485e77fd04957e50d41\n\nThis mimics the updates of expectation parameters in conjugate models (e.g. gaussian mean). We provide a generic and fully automatic TFP implementation which takes a probabilistic program as input and returns the convex-update structured variational family.\n\nIt is very easy to use! You just need one line of cose to buld your ASVI posterior in TFP:\n\n&amp;#x200B;\n\n*Processing img i00l6m4703h61...*\n\nThe convex-update ASVI family has both the mean field (MF) family and the prior program as special cases. While it has only twice as many parameters as MF, we showed that it can greatly outperforme very complex normalizing flows in structured inference problems! Here is an example for a Lorentz dynamical system:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/g7c3guma03h61.png?width=588&amp;format=png&amp;auto=webp&amp;s=cf7cbdda232616ac2c418fddcee075d80d760a88", "link": "https://www.reddit.com/r/MachineLearning/comments/lify7a/r_automatic_structured_variational_inference_in/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] automatic structured variational inference in tensorflow probability /!/ &amp;#x200b;\n\n*processing img cp98jshc03h61...*\n\nhappy to share the new version of \"automatic structured variational inference\" (asvi) (accepted at aistats2021)  work in collaborations with the google tensorflow probability team.  \n\n[repository](https://github.com/google-research/google-research/-----> tree !!! /master/automatic_structured_vi)\n\n[tutorial](https://www.tensorflow.org/probability/examples/tfp_release_notebook_0_12_1#build_asvi_surrogate_posterior)\n\n[preprint](https://arxiv.org/pdf/2002.00643.pdf)\n\nasvi constructs structured variational families by parameterized convex updates:\n\n&amp;#x200b;\n\n*processing gif dwdzw55uz2h61...*\n\nin this way we can automatically construct complex structured variational models. here an example of a brownian motion:\n\n&amp;#x200b;\n\nhttps://preview.redd.it/ymzdrbqyz2h61.png?width=529&amp;format=png&amp;auto=webp&amp;s=8d87fe0d70e9df3159a09485e77fd04957e50d41\n\nthis mimics the updates of expectation parameters in conjugate models (e.g. gaussian mean). we provide a generic and fully automatic tfp implementation which takes a probabilistic program as input and returns the convex-update structured variational family.\n\nit is very easy to use! you just need one line of cose to buld your asvi posterior in tfp:\n\n&amp;#x200b;\n\n*processing img i00l6m4703h61...*\n\nthe convex-update asvi family has both the mean field (mf) family and the prior program as special cases. while it has only twice as many parameters as mf, we showed that it can greatly outperforme very complex normalizing flows in structured inference problems! here is an example for a lorentz dynamical system:\n\n&amp;#x200b;\n\nhttps://preview.redd.it/g7c3guma03h61.png?width=588&amp;format=png&amp;auto=webp&amp;s=cf7cbdda232616ac2c418fddcee075d80d760a88", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lify7a/r_automatic_structured_variational_inference_in/',)", "identifyer": 5722479, "year": "2021"}, {"autor": "Chriscbe", "date": 1617135089000, "content": "[R] Please point me in the right direction: decision trees or possibly something better /!/ ML Practitioners:\n\nI am a scientist who studies how to purify recombinant proteins. I am generally proficient with Python. I am looking for ways to fortify decsion making during purification of proteins created in E coli and cell culture. What parts of ML would be best to learn in order to improve planning/ decision making in a decion-tree like format? I have seen some literature on the issue but I'd like to start from a point where I can understand, for example, which parts of (sci-kit learn?) might address the issue, etc.\n\nThanks for any help", "link": "https://www.reddit.com/r/MachineLearning/comments/mgougk/r_please_point_me_in_the_right_direction_decision/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] please point me in the right direction: decision trees or possibly something better /!/ ml practitioners:\n\ni am a scientist who studies how to purify recombinant proteins. i am generally proficient with python. i am looking for ways to fortify decsion making during purification of proteins created in e coli and cell culture. what parts of ml would be best to learn in order to improve planning/ decision making in a decion------> tree !!!  like format? i have seen some literature on the issue but i'd like to start from a point where i can understand, for example, which parts of (sci-kit learn?) might address the issue, etc.\n\nthanks for any help", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mgougk/r_please_point_me_in_the_right_direction_decision/',)", "identifyer": 5722803, "year": "2021"}, {"autor": "princealiiiii", "date": 1610647240000, "content": "[P] DAN Super Resolution - Model of the Day #2 /!/ &amp;#x200B;\n\n[Using the Gradio interface with the Super Resolution model. Tou can try out this interface yourself in the link provided below!](https://i.redd.it/qkln2ubo5cb61.gif)\n\nToday's model will be based on the paper at this arXiv link: [Unfolding the Alternating Optimization for Blind Super Resolution](https://arxiv.org/abs/2010.02631). Repo [here](https://github.com/google-research/google-research/tree/master/slot_attention) and interface shown above [here](https://gradio.app/hub/dawoodkhan82/dan).\n\nSuper resolution ML usually involves two steps: 1) estimating the amount and direction of blur in the input image, aka the blur kernel, and 2) Running a model that can \"undo\" that blur kernel. \n\nInstead of approaching these steps separately, DAN uses an alternating optimization algorithm that accounts for both steps in a single model. Two convolution models are used in conjunction, called the Restorer and the Estimator. The Restorer generates the super resolution image based on predicted kernel, and the Estimator estimates blur kernel with the help of restored SR image. By alternating between these two models repeatedly, DAN creates an end-to-end trainable network. Try it out yourself with in the link above!\n\n\\--------------------------------------\n\nI've been working with a lot of newly researched models lately, and I wanted to share the most interesting models I've worked with here. This is part of a series where I post an interesting model along with a description of the research purpose and an interactive interface generated with Gradio. Previous post (Model of the Day #1) [here](https://www.reddit.com/r/MachineLearning/comments/kmm1ld/p_objectcentric_learning_with_slot_attention/).", "link": "https://www.reddit.com/r/MachineLearning/comments/kxax7w/p_dan_super_resolution_model_of_the_day_2/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] dan super resolution - model of the day #2 /!/ &amp;#x200b;\n\n[using the gradio interface with the super resolution model. tou can try out this interface yourself in the link provided below!](https://i.redd.it/qkln2ubo5cb61.gif)\n\ntoday's model will be based on the paper at this arxiv link: [unfolding the alternating optimization for blind super resolution](https://arxiv.org/abs/2010.02631). repo [here](https://github.com/google-research/google-research/-----> tree !!! /master/slot_attention) and interface shown above [here](https://gradio.app/hub/dawoodkhan82/dan).\n\nsuper resolution ml usually involves two steps: 1) estimating the amount and direction of blur in the input image, aka the blur kernel, and 2) running a model that can \"undo\" that blur kernel. \n\ninstead of approaching these steps separately, dan uses an alternating optimization algorithm that accounts for both steps in a single model. two convolution models are used in conjunction, called the restorer and the estimator. the restorer generates the super resolution image based on predicted kernel, and the estimator estimates blur kernel with the help of restored sr image. by alternating between these two models repeatedly, dan creates an end-to-end trainable network. try it out yourself with in the link above!\n\n\\--------------------------------------\n\ni've been working with a lot of newly researched models lately, and i wanted to share the most interesting models i've worked with here. this is part of a series where i post an interesting model along with a description of the research purpose and an interactive interface generated with gradio. previous post (model of the day #1) [here](https://www.reddit.com/r/machinelearning/comments/kmm1ld/p_objectcentric_learning_with_slot_attention/).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/kxax7w/p_dan_super_resolution_model_of_the_day_2/',)", "identifyer": 5722897, "year": "2021"}, {"autor": "BasedIndividual", "date": 1611988372000, "content": "[D] Concise Definition for the Following Algorithms? /!/ Hello,\n\nI am writing a paper and need help on writing specific algorithm definitions in a concise (preferably one sentence) manner in laymen's terms that non-technical people would understand. The algorithms are:\n\nNaive Bayes\n\nGeneralized Linear Model\n\nLogistic Regression\n\nFast Large Margin\n\nDeep Learning\n\nArtificial Neural Networks\n\nDecision Tree\n\nRandom Forest\n\nGradient Boosted Trees\n\nSupport Vector Machines\n\nThank you in advance!", "link": "https://www.reddit.com/r/MachineLearning/comments/l8fsby/d_concise_definition_for_the_following_algorithms/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] concise definition for the following algorithms? /!/ hello,\n\ni am writing a paper and need help on writing specific algorithm definitions in a concise (preferably one sentence) manner in laymen's terms that non-technical people would understand. the algorithms are:\n\nnaive bayes\n\ngeneralized linear model\n\nlogistic regression\n\nfast large margin\n\ndeep learning\n\nartificial neural networks\n\ndecision -----> tree !!! \n\nrandom forest\n\ngradient boosted trees\n\nsupport vector machines\n\nthank you in advance!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/l8fsby/d_concise_definition_for_the_following_algorithms/',)", "identifyer": 5723227, "year": "2021"}, {"autor": "yiriwer", "date": 1626356233000, "content": "Decision Tree Algorithm, Explained", "link": "https://www.reddit.com/r/MachineLearning/comments/okszuy/decision_tree_algorithm_explained/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "decision -----> tree !!!  algorithm, explained", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.thinkdataanalytics.com/decision-tree-algorithm/',)", "identifyer": 5723580, "year": "2021"}, {"autor": "luisirio", "date": 1623752467000, "content": "[D] Forecating problem /!/ I'm working on a binary classification problem where the goal is to forecast the demand and dispatches powers (encoded as class labels... demand&gt;dispatches encoded as 0, and demand&lt;dispatches encoded as 1).\n\nI have a year dataset every hour. I already selected the features more relevant to the problem, and I tried two methods: decision tree and Random Forest.\n\nThe problem is that when I split the train and test sets randomly (70% for training and 30% for test), I get 80% of accuracy, but when I consider 180 days for training and try to predict the next 24 hours with a sliding window process, I only get 60% of accuracy.\n\nHas anyone solved a similar problem?\n\nThank you!", "link": "https://www.reddit.com/r/MachineLearning/comments/o0b0le/d_forecating_problem/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] forecating problem /!/ i'm working on a binary classification problem where the goal is to forecast the demand and dispatches powers (encoded as class labels... demand&gt;dispatches encoded as 0, and demand&lt;dispatches encoded as 1).\n\ni have a year dataset every hour. i already selected the features more relevant to the problem, and i tried two methods: decision -----> tree !!!  and random forest.\n\nthe problem is that when i split the train and test sets randomly (70% for training and 30% for test), i get 80% of accuracy, but when i consider 180 days for training and try to predict the next 24 hours with a sliding window process, i only get 60% of accuracy.\n\nhas anyone solved a similar problem?\n\nthank you!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 7, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o0b0le/d_forecating_problem/',)", "identifyer": 5723705, "year": "2021"}, {"autor": "bonjarno65", "date": 1631574006000, "content": "[D] Data leakage: Any pitfalls in normalizing the target variable by a feature for any decision tree regression model? /!/ Hello [r/MachineLearning](https://www.reddit.com/r/MachineLearning/) \\- the title says it all. Is there any pitfalls (i.e. overfitting or bias) in training an ML model like:\n\nmethod1: feature1, feature2, ... , featureN -&gt; target\\_Y/feature1\n\nvs\n\nmethod2: feature1, feature2, ..., featureN -&gt; target\\_Y?\n\nOriginally for method1 above that in using feature1 on both input and output it would lead to data leakage, but apparently it does not meet the definition of data leakage, since feature1 will be available during ML model deployment as well:  \n[https://en.wikipedia.org/wiki/Leakage\\_(machine\\_learning)](https://en.wikipedia.org/wiki/Leakage_(machine_learning))  \n\n\nThe other piece of relevant info here is that feature1 is correlated with target\\_Y to within 90%+ with feature1 but not the other features nearly as much.", "link": "https://www.reddit.com/r/MachineLearning/comments/pnqinz/d_data_leakage_any_pitfalls_in_normalizing_the/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] data leakage: any pitfalls in normalizing the target variable by a feature for any decision -----> tree !!!  regression model? /!/ hello [r/machinelearning](https://www.reddit.com/r/machinelearning/) \\- the title says it all. is there any pitfalls (i.e. overfitting or bias) in training an ml model like:\n\nmethod1: feature1, feature2, ... , featuren -&gt; target\\_y/feature1\n\nvs\n\nmethod2: feature1, feature2, ..., featuren -&gt; target\\_y?\n\noriginally for method1 above that in using feature1 on both input and output it would lead to data leakage, but apparently it does not meet the definition of data leakage, since feature1 will be available during ml model deployment as well:  \n[https://en.wikipedia.org/wiki/leakage\\_(machine\\_learning)](https://en.wikipedia.org/wiki/leakage_(machine_learning))  \n\n\nthe other piece of relevant info here is that feature1 is correlated with target\\_y to within 90%+ with feature1 but not the other features nearly as much.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pnqinz/d_data_leakage_any_pitfalls_in_normalizing_the/',)", "identifyer": 5723816, "year": "2021"}, {"autor": "bonjarno65", "date": 1631572948000, "content": "Data leakage: Any pitfalls in normalizing the target variable by a feature for any decision tree regression model? /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/pnq7ra/data_leakage_any_pitfalls_in_normalizing_the/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "data leakage: any pitfalls in normalizing the target variable by a feature for any decision -----> tree !!!  regression model? /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pnq7ra/data_leakage_any_pitfalls_in_normalizing_the/',)", "identifyer": 5723818, "year": "2021"}, {"autor": "Better_Cycle_490", "date": 1625074007000, "content": "Productionizing Distributed XGBoost to Train Deep Tree Models with Large Data Sets at Uber /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/ob22q0/productionizing_distributed_xgboost_to_train_deep/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "productionizing distributed xgboost to train deep -----> tree !!!  models with large data sets at uber /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ob22q0/productionizing_distributed_xgboost_to_train_deep/',)", "identifyer": 5723847, "year": "2021"}, {"autor": "jj4646", "date": 1632838813000, "content": "[D] Globally Optimum Sparse Decision Trees /!/ https://arxiv.org/abs/1904.12847\n\nHas anyone ever heard about this algorithm before? Apparently this supposed to be one of the best \"individual decision tree algorithms\" out there.\n\nHas anyone used it before? What are your thoughts? How was your experience?\n\nThanks!", "link": "https://www.reddit.com/r/MachineLearning/comments/px7fec/d_globally_optimum_sparse_decision_trees/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] globally optimum sparse decision trees /!/ https://arxiv.org/abs/1904.12847\n\nhas anyone ever heard about this algorithm before? apparently this supposed to be one of the best \"individual decision -----> tree !!!  algorithms\" out there.\n\nhas anyone used it before? what are your thoughts? how was your experience?\n\nthanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 9, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/px7fec/d_globally_optimum_sparse_decision_trees/',)", "identifyer": 5724299, "year": "2021"}, {"autor": "Reginald_Martin", "date": 1613649333000, "content": "[D] Free Data Science Foundation Bootcamp /!/ **Free Data Science Foundation Bootcamp**\n\n* Knowledge-packed, project-based intensive program\n* Hands-on practice &amp; live-online learning from the comfort of your home\n* Training and Mentoring from industry experts and super supportive TAs\n* A Certificate on successful completion of the program\n\n**Data Science Foundation Program**\n\nPick up Data Science by actually getting your hands dirty! Wondering whether you should go through all the trouble? Take this Bootcamp if ...\n\n* You are looking forward to start your data science career\n* You're on the fence on whether data science is the right choice\n* You want to see data science in action and talk to industry experts\n* You simply want to take up a data science project\n\n**Ready for a Data Science Career?**\n\nYear after year, the one profession that consistently ranks on top amongst emerging jobs is Data Science. Growing exponentially at more than 25% every year, Data Science finds increasing use in more and more industries by the day, with exciting applications such as self-driving cars, intelligent automation, and dynamic business decision support systems to show for. This is a growing profession whose demand in every industry and sector is increasing by the day.\n\nData Science is without a shadow of doubt, a bright and promising career choice.\n\n**Upcoming Dates:**\n\nOur instructors, mentors, and support team will be there to help keep it interactive, so feel free to ask your doubts, and have fun following along!\n\n**Dates:** March 6, 7 2021\n\n**Time:** 7:00 PM - 11:00 PM IST &amp; 8:30 AM - 12:30 PM ET\n\n**Program Curriculum**\n\nDesigned by our trainers who come with years of industry experience, this bootcamp is a blend of both up-to-date theory and relevant practical application. Broadly, the topics we\u2019ll cover in this program include:\n\n* Introduction to Linear Regression\n* Decision Tree Regression\n* Real-world Project\n\n**Project Overview: Predict the Success of a Startup**\n\nApply your newly gained knowledge on Data Science to predict a startup's success. This project would require everything you have learned throughout the program to effectively build a Decision tree and a Random Forest to predict a startup's success. We will look at the top 50 startup trends and features to predict the success of a startup. This portfolio-worthy project demonstrates your proficiency with the most sought after skills of machine learning in the market.\n\n# [Click here to Register for Free](https://www.eventbrite.com/e/free-data-science-foundation-bootcamp-tickets-136386195783)", "link": "https://www.reddit.com/r/MachineLearning/comments/lml3rj/d_free_data_science_foundation_bootcamp/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] free data science foundation bootcamp /!/ **free data science foundation bootcamp**\n\n* knowledge-packed, project-based intensive program\n* hands-on practice &amp; live-online learning from the comfort of your home\n* training and mentoring from industry experts and super supportive tas\n* a certificate on successful completion of the program\n\n**data science foundation program**\n\npick up data science by actually getting your hands dirty! wondering whether you should go through all the trouble? take this bootcamp if ...\n\n* you are looking forward to start your data science career\n* you're on the fence on whether data science is the right choice\n* you want to see data science in action and talk to industry experts\n* you simply want to take up a data science project\n\n**ready for a data science career?**\n\nyear after year, the one profession that consistently ranks on top amongst emerging jobs is data science. growing exponentially at more than 25% every year, data science finds increasing use in more and more industries by the day, with exciting applications such as self-driving cars, intelligent automation, and dynamic business decision support systems to show for. this is a growing profession whose demand in every industry and sector is increasing by the day.\n\ndata science is without a shadow of doubt, a bright and promising career choice.\n\n**upcoming dates:**\n\nour instructors, mentors, and support team will be there to help keep it interactive, so feel free to ask your doubts, and have fun following along!\n\n**dates:** march 6, 7 2021\n\n**time:** 7:00 pm - 11:00 pm ist &amp; 8:30 am - 12:30 pm et\n\n**program curriculum**\n\ndesigned by our trainers who come with years of industry experience, this bootcamp is a blend of both up-to-date theory and relevant practical application. broadly, the topics we\u2019ll cover in this program include:\n\n* introduction to linear regression\n* decision -----> tree !!!  regression\n* real-world project\n\n**project overview: predict the success of a startup**\n\napply your newly gained knowledge on data science to predict a startup's success. this project would require everything you have learned throughout the program to effectively build a decision tree and a random forest to predict a startup's success. we will look at the top 50 startup trends and features to predict the success of a startup. this portfolio-worthy project demonstrates your proficiency with the most sought after skills of machine learning in the market.\n\n# [click here to register for free](https://www.eventbrite.com/e/free-data-science-foundation-bootcamp-tickets-136386195783)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lml3rj/d_free_data_science_foundation_bootcamp/',)", "identifyer": 5724723, "year": "2021"}, {"autor": "SilurianWenlock", "date": 1614190568000, "content": "[D] Explaining decision tree pruning /!/ Decision tree pruning is not covered well online. Many medium posts are full of shallow waffle and many papers are very dense.\n\nCan anyone explain to me how decision tree pruning works in under a paragraph (say)?", "link": "https://www.reddit.com/r/MachineLearning/comments/lrjh0t/d_explaining_decision_tree_pruning/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] explaining decision -----> tree !!!  pruning /!/ decision -----> tree !!!  pruning is not covered well online. many medium posts are full of shallow waffle and many papers are very dense.\n\ncan anyone explain to me how decision tree pruning works in under a paragraph (say)?", "sortedWord": "None", "removed": "('nan',)", "score": 0, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lrjh0t/d_explaining_decision_tree_pruning/',)", "identifyer": 5724787, "year": "2021"}, {"autor": "[deleted]", "date": 1614190474000, "content": "[D] How to explain bottom up decision tree pruning /!/ [deleted]", "link": "https://www.reddit.com/r/MachineLearning/comments/lrjfon/d_how_to_explain_bottom_up_decision_tree_pruning/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] how to explain bottom up decision -----> tree !!!  pruning /!/ [deleted]", "sortedWord": "None", "removed": "('deleted',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lrjfon/d_how_to_explain_bottom_up_decision_tree_pruning/',)", "identifyer": 5724788, "year": "2021"}, {"autor": "SilurianWenlock", "date": 1614188096000, "content": "[D] Time complexity of fitting a decision tree /!/ What is the time complexity of fitting a decision tree? Does it matter whether the features are continuous or discrete?\n\nThis has been asked before on stack exchange but a lot of the answers look imprecise or are guesses", "link": "https://www.reddit.com/r/MachineLearning/comments/lrigch/d_time_complexity_of_fitting_a_decision_tree/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] time complexity of fitting a decision -----> tree !!!  /!/ what is the time complexity of fitting a decision tree? does it matter whether the features are continuous or discrete?\n\nthis has been asked before on stack exchange but a lot of the answers look imprecise or are guesses", "sortedWord": "None", "removed": "('nan',)", "score": 0, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lrigch/d_time_complexity_of_fitting_a_decision_tree/',)", "identifyer": 5724796, "year": "2021"}, {"autor": "rirhun", "date": 1615162931000, "content": "[D] BentoML's Compatibility with Seldon /!/ I am using BentoML to build the docker container for a BERT model, and then deploy that using Seldon on GKE. The model's REST API endpoint works fine. In terms of compatibility with Seldon, the metrics are being scraped by Prometheus and visualized on Grafana. The only Seldon component that doesn't appear to be working is the request logging, which I have working for other applications that were deployed on Seldon. I am using the elastic stack from [here](https://github.com/SeldonIO/seldon-core/tree/master/examples/centralised-logging). From my understanding, request logging should still be compatible and the only lost functionality should be Seldon's model metadata. Any insight on how to get the centralized request logging working? No errors were shown; it's just that the logs aren't being captured and sent to ElasticSearch. Anyone have any success using BentoML with Seldon and not losing any of Seldon's features?", "link": "https://www.reddit.com/r/MachineLearning/comments/m03gnc/d_bentomls_compatibility_with_seldon/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] bentoml's compatibility with seldon /!/ i am using bentoml to build the docker container for a bert model, and then deploy that using seldon on gke. the model's rest api endpoint works fine. in terms of compatibility with seldon, the metrics are being scraped by prometheus and visualized on grafana. the only seldon component that doesn't appear to be working is the request logging, which i have working for other applications that were deployed on seldon. i am using the elastic stack from [here](https://github.com/seldonio/seldon-core/-----> tree !!! /master/examples/centralised-logging). from my understanding, request logging should still be compatible and the only lost functionality should be seldon's model metadata. any insight on how to get the centralized request logging working? no errors were shown; it's just that the logs aren't being captured and sent to elasticsearch. anyone have any success using bentoml with seldon and not losing any of seldon's features?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/m03gnc/d_bentomls_compatibility_with_seldon/',)", "identifyer": 5724903, "year": "2021"}, {"autor": "WarChampion90", "date": 1615126958000, "content": "[Discussion] Do the mathematical principles behind decision trees (or other ML models) need to be discussed in a publication that used them? /!/ Hi all,\n\nI apologize if this is not the best place to discuss this, but if figured it\u2019s a start.\n\nIn summary, we are publishing a paper in which a number of predictive models were trained and optimized for a number of specific scientific use cases. One of the main ideas was to train a model, in this case a decision tree (DT), to predict a very specific chemical property. \n\nThe project was successful, and the content caught the attention of a few departments interested in collaborating. Yay!\n\nMy question is regarding the soon-to-be-written paper. I am trying to envision the format and wanted to know if DT theory and mathematical principles need to be discussed? Please note that our implementation was directly from Sklearn. \n\nI have looked around to see what others in the field have done, but i see it going both ways in the sense that some authors discuss the math, others simply mention the model by name. \n\nWhat are your thoughts?\n\nThanks!", "link": "https://www.reddit.com/r/MachineLearning/comments/lzrm27/discussion_do_the_mathematical_principles_behind/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[discussion] do the mathematical principles behind decision trees (or other ml models) need to be discussed in a publication that used them? /!/ hi all,\n\ni apologize if this is not the best place to discuss this, but if figured it\u2019s a start.\n\nin summary, we are publishing a paper in which a number of predictive models were trained and optimized for a number of specific scientific use cases. one of the main ideas was to train a model, in this case a decision -----> tree !!!  (dt), to predict a very specific chemical property. \n\nthe project was successful, and the content caught the attention of a few departments interested in collaborating. yay!\n\nmy question is regarding the soon-to-be-written paper. i am trying to envision the format and wanted to know if dt theory and mathematical principles need to be discussed? please note that our implementation was directly from sklearn. \n\ni have looked around to see what others in the field have done, but i see it going both ways in the sense that some authors discuss the math, others simply mention the model by name. \n\nwhat are your thoughts?\n\nthanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 9, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lzrm27/discussion_do_the_mathematical_principles_behind/',)", "identifyer": 5724912, "year": "2021"}, {"autor": "Character-Meat-9176", "date": 1615861739000, "content": "[R] ElegantRL: A Lightweight and Stable Deep Reinforcement Learning Library /!/ Learn to implement deep reinforcement learning algorithms in 24 hours.\n\nThe [ElegantRL](https://github.com/AI4Finance-LLC/ElegantRL) library is featured with \u201celegant\u201d in the following aspects:\n\n* **Lightweight**: core codes have less than 1,000 lines, e.g., [tutorial](https://github.com/AI4Finance-LLC/ElegantRL/tree/master/elegantrl/tutorial).\n* **Efficient**: the performance is comparable with [Ray RLlib](https://github.com/ray-project/ray).\n* **Stable**: more stable than [Stable Baseline 3](https://github.com/DLR-RM/stable-baselines3).\n\nElegantRL supports state-of-the-art DRL algorithms, including discrete and continuous ones, and provides user-friendly tutorials in Jupyter notebooks.\n\nThe ElegantRL implements DRL algorithms under the Actor-Critic framework, where an Agent (a.k.a, a DRL algorithm) consists of an Actor network and a Critic network. Due to the completeness and simplicity of code structure, users are able to easily customize their own agents.\n\n&amp;#x200B;\n\n[Figure 1. An agent in Agent.py uses networks in Net.py and is trained in Run.py by interacting with an environment in Env.py. ](https://preview.redd.it/2fx857swp9n61.png?width=2000&amp;format=png&amp;auto=webp&amp;s=daa87b642b2aaba0958b03daace72206d12a5f3a)\n\nFrom the [medium blog](https://towardsdatascience.com/elegantrl-a-lightweight-and-stable-deep-reinforcement-learning-library-95cef5f3460b).", "link": "https://www.reddit.com/r/MachineLearning/comments/m5yvwz/r_elegantrl_a_lightweight_and_stable_deep/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] elegantrl: a lightweight and stable deep reinforcement learning library /!/ learn to implement deep reinforcement learning algorithms in 24 hours.\n\nthe [elegantrl](https://github.com/ai4finance-llc/elegantrl) library is featured with \u201celegant\u201d in the following aspects:\n\n* **lightweight**: core codes have less than 1,000 lines, e.g., [tutorial](https://github.com/ai4finance-llc/elegantrl/-----> tree !!! /master/elegantrl/tutorial).\n* **efficient**: the performance is comparable with [ray rllib](https://github.com/ray-project/ray).\n* **stable**: more stable than [stable baseline 3](https://github.com/dlr-rm/stable-baselines3).\n\nelegantrl supports state-of-the-art drl algorithms, including discrete and continuous ones, and provides user-friendly tutorials in jupyter notebooks.\n\nthe elegantrl implements drl algorithms under the actor-critic framework, where an agent (a.k.a, a drl algorithm) consists of an actor network and a critic network. due to the completeness and simplicity of code structure, users are able to easily customize their own agents.\n\n&amp;#x200b;\n\n[figure 1. an agent in agent.py uses networks in net.py and is trained in run.py by interacting with an environment in env.py. ](https://preview.redd.it/2fx857swp9n61.png?width=2000&amp;format=png&amp;auto=webp&amp;s=daa87b642b2aaba0958b03daace72206d12a5f3a)\n\nfrom the [medium blog](https://towardsdatascience.com/elegantrl-a-lightweight-and-stable-deep-reinforcement-learning-library-95cef5f3460b).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 18, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/m5yvwz/r_elegantrl_a_lightweight_and_stable_deep/',)", "identifyer": 5724931, "year": "2021"}, {"autor": "everything_vanishes_", "date": 1609955859000, "content": "[D] Curse of Dimensionality seems not to apply to my problem. Why? /!/ I have a small dataset with many features (74 X 3200+). Conventional wisdom states I require 5-10 samples per predictor, so I rather arbitrarily decided to use feature selection and limit the number of selected features to 4. I\u2019m using leave one out cross validation and performing all steps (feature scaling, selection, hyperparameter tuning) within the CV loop. I\u2019ve explored 3 feature selection techniques (correlation with output, mRMR &amp; recursive feature elimination with a linear SVM) and 4 models (Linear SVM, LDA, KNN &amp; AdaBoost with a decision tree). \n\nMy highest LOOCV results that models trained without feature selection (with the exception of KNN) perform 5-10% better than with feature selection. I haven\u2019t inspected the training accuracies but I\u2019m willing to bet when all features are used, it\u2019s 100%, which would suggest overfitting.\n\nHow do I make sense of this finding?", "link": "https://www.reddit.com/r/MachineLearning/comments/krt6dn/d_curse_of_dimensionality_seems_not_to_apply_to/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] curse of dimensionality seems not to apply to my problem. why? /!/ i have a small dataset with many features (74 x 3200+). conventional wisdom states i require 5-10 samples per predictor, so i rather arbitrarily decided to use feature selection and limit the number of selected features to 4. i\u2019m using leave one out cross validation and performing all steps (feature scaling, selection, hyperparameter tuning) within the cv loop. i\u2019ve explored 3 feature selection techniques (correlation with output, mrmr &amp; recursive feature elimination with a linear svm) and 4 models (linear svm, lda, knn &amp; adaboost with a decision -----> tree !!! ). \n\nmy highest loocv results that models trained without feature selection (with the exception of knn) perform 5-10% better than with feature selection. i haven\u2019t inspected the training accuracies but i\u2019m willing to bet when all features are used, it\u2019s 100%, which would suggest overfitting.\n\nhow do i make sense of this finding?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 8, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/krt6dn/d_curse_of_dimensionality_seems_not_to_apply_to/',)", "identifyer": 5725194, "year": "2021"}, {"autor": "CaptainMcThorn", "date": 1617880707000, "content": "[R] Hollow-tree Super: a directional and scalable approach for feature importance in boosted tree models", "link": "https://www.reddit.com/r/MachineLearning/comments/mmpkhp/r_hollowtree_super_a_directional_and_scalable/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] hollow------> tree !!!  super: a directional and scalable approach for feature importance in boosted -----> tree !!!  models", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://arxiv.org/abs/2104.03088',)", "identifyer": 5725246, "year": "2021"}, {"autor": "ChubbyCatto", "date": 1611817987000, "content": "[P] Explosive demolition dog detection pattern classification /!/ Good day all. I wanted to ask for some advice on what ML algorithmic method could be best applied to tackle this project. \n\nA bit of context, military and police explosive detection dogs have certain types of explosives that they struggle with detecting (relating to the type of vapours emitted from the explosive ordnance). They might also pick up a scent that makes them think there is an explosive present when there is none. The trainers for the dogs haven't been able to train them to mitigate this issue due to the vapours causing these problems being unknown. \n\nMy aim is to identify these problem causing vapours in the hopes that it enhances explosive detection dog training. Namely, vapours that cause dogs to falsely identify an explosive (false-positive detection) and vapours that cause dogs to miss and explosive from being identified (false-negative detection).\n\nHow I aim to do this is to develop a sensing apparatus with 20~30 industrial sensors which cover some of the most common precursor (ingredient) chemicals used to manufacture explosives and to also collect behavioural data on the dogs during their training (sensor data is numerical concentration values and canine behaviour will also be numerical ie, detected correctly = 0, false positive = 1, false negative = 2). \n\nI am aiming to collect &gt; 20k measurements with 20~30 attributes (each being the outputs from different sensors). The collected data will then be preprocessed by integrating the recorded dog behavioural data to the sensor data to create an augmented dataset.\n\nNow, this is were I am currently having issues. I have had some experience using decision tree, Bayesian network as well as linear regression related algorithms. However, with this project, I am specifically aiming to collect information on the relevant attributes (vapours) and their specific numerical values that lead to false-positive and false-negative instances. I am not aware of any ML algorithms that are able to provide me with a list of all the instances along with their conditions. I would love it if someone could point me in the direction with some useful classifiers, algorithms that could meet this need.\n\nApologies for the long post. Thank you for reading and any advice would be much appreciated.", "link": "https://www.reddit.com/r/MachineLearning/comments/l6qogw/p_explosive_demolition_dog_detection_pattern/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] explosive demolition dog detection pattern classification /!/ good day all. i wanted to ask for some advice on what ml algorithmic method could be best applied to tackle this project. \n\na bit of context, military and police explosive detection dogs have certain types of explosives that they struggle with detecting (relating to the type of vapours emitted from the explosive ordnance). they might also pick up a scent that makes them think there is an explosive present when there is none. the trainers for the dogs haven't been able to train them to mitigate this issue due to the vapours causing these problems being unknown. \n\nmy aim is to identify these problem causing vapours in the hopes that it enhances explosive detection dog training. namely, vapours that cause dogs to falsely identify an explosive (false-positive detection) and vapours that cause dogs to miss and explosive from being identified (false-negative detection).\n\nhow i aim to do this is to develop a sensing apparatus with 20~30 industrial sensors which cover some of the most common precursor (ingredient) chemicals used to manufacture explosives and to also collect behavioural data on the dogs during their training (sensor data is numerical concentration values and canine behaviour will also be numerical ie, detected correctly = 0, false positive = 1, false negative = 2). \n\ni am aiming to collect &gt; 20k measurements with 20~30 attributes (each being the outputs from different sensors). the collected data will then be preprocessed by integrating the recorded dog behavioural data to the sensor data to create an augmented dataset.\n\nnow, this is were i am currently having issues. i have had some experience using decision -----> tree !!! , bayesian network as well as linear regression related algorithms. however, with this project, i am specifically aiming to collect information on the relevant attributes (vapours) and their specific numerical values that lead to false-positive and false-negative instances. i am not aware of any ml algorithms that are able to provide me with a list of all the instances along with their conditions. i would love it if someone could point me in the direction with some useful classifiers, algorithms that could meet this need.\n\napologies for the long post. thank you for reading and any advice would be much appreciated.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/l6qogw/p_explosive_demolition_dog_detection_pattern/',)", "identifyer": 5725775, "year": "2021"}, {"autor": "RocketknightHF", "date": 1626280356000, "content": "[N] TF, Keras and Transformers /!/ Hi, Tensorflow maintainer at Hugging Face here! We've been working on a fairly extensive TF revamp for the Transformers repo, and we're trying to get the word out about it.\n\n**What's changed?**\n\nThe \"old\" style of writing TF with Transformers was extremely PyTorchy - you could either write eager code with your own training loop, or you could use our `TFTrainer` class, which did the boilerplate stuff for you, much like the `Trainer` class does for PyTorch. This is... fine, I guess, but it still feels like PyTorch code that's been translated into TF. In particular, TF already has a trainer class that abstracts away all the boilerplate training loop stuff for you, and it's called Keras. That wheel doesn't need to be reinvented. Also if you make me maintain that wheel I will be sad, whereas if I can make Fran\u00e7ois Chollet maintain that wheel I will be happy. No more `TFTrainer`, in other words - all of our models are Keras models, and the recommended way to deal with them is through the native Keras API. As of today, `TFTrainer` is deprecated on master, and once that makes it to the next release you'll start getting warnings if you're still using it.\n\n**What's coming next?**\n\nWe're working on other ways to make our integration with TF feel much more idiomatic - in particular, we want a way to get our datasets to automatically convert nicely to `tf.data.Dataset` objects, allowing you get really nice stuff like large dataset streaming without needing to preload the whole thing and variable-length batching to avoid wasted computation during training.\n\n**Sounds cool, how do I use it?**\n\nEasy, just `pip install transformers`! All our TF models are Keras models now - in fact, they have been for a while! I've written up [TF examples for a range of NLP tasks in the new style](https://github.com/huggingface/transformers/tree/master/examples/tensorflow) too, so you can run those as-is or adapt them to your particular needs.\n\n**Your example code is sloppy garbage and I don't want to read a whole script of it.**\n\nYour criticism has been noted. Also that isn't a question.\n\n**Okay fine, can I use this without having to read those example scripts?**\n\nSure! If you're already a TF/Keras developer, the code below should feel very familiar to you - in fact, the only new bit will be the model loading and the tokenization needed to convert input text into integer IDs:\n\n    from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n    import tensorflow as tf\n    \n    model_name = 'bert-base-cased'\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n    \n    texts = [\"I'm a positive example!\", \"I'm a negative example!\"]\n    labels = [1, 0]\n    \n    # Pad the tokenizer outputs to the same length for all samples\n    processed_text = tokenizer(texts, padding='longest', return_tensors='tf')  \n    labels = tf.convert_to_tensor(labels)\n    \n    opt = tf.keras.optimizers.Adam(5e-5)  # Transformers like lower learning rates\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Model outputs raw logits\n    model.compile(optimizer=opt, loss=loss)\n    \n    model.fit(dict(processed_text), labels, epochs=3)\n\nBam. You just fine-tuned a massive pre-trained language model. Swap in your own data for texts and labels, and you can get superb performance on whatever task you want. Call your boss and tell them you're an NLP engineer now and you want a salary review next quarter. We recommend more than two training examples, and maybe a validation set if you're feeling fancy, but we can't force you. Live wild and free. If you want another model, simply replace `bert-base-cased` with your model of choice; there are [plenty to choose from](https://huggingface.co/models).\n\n**I ran that code and it worked but there were some scary warnings!**\n\nThose are purely cosmetic, but they are *very* annoying, especially because it's not like TF needs **more** console spam. They're on my list of things that need fixing in the near future. If you're reading this in a couple of months and they're still there, [tweet insults at me](https://twitter.com/carrigmat) until they aren't.", "link": "https://www.reddit.com/r/MachineLearning/comments/ok81v4/n_tf_keras_and_transformers/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[n] tf, keras and transformers /!/ hi, tensorflow maintainer at hugging face here! we've been working on a fairly extensive tf revamp for the transformers repo, and we're trying to get the word out about it.\n\n**what's changed?**\n\nthe \"old\" style of writing tf with transformers was extremely pytorchy - you could either write eager code with your own training loop, or you could use our `tftrainer` class, which did the boilerplate stuff for you, much like the `trainer` class does for pytorch. this is... fine, i guess, but it still feels like pytorch code that's been translated into tf. in particular, tf already has a trainer class that abstracts away all the boilerplate training loop stuff for you, and it's called keras. that wheel doesn't need to be reinvented. also if you make me maintain that wheel i will be sad, whereas if i can make fran\u00e7ois chollet maintain that wheel i will be happy. no more `tftrainer`, in other words - all of our models are keras models, and the recommended way to deal with them is through the native keras api. as of today, `tftrainer` is deprecated on master, and once that makes it to the next release you'll start getting warnings if you're still using it.\n\n**what's coming next?**\n\nwe're working on other ways to make our integration with tf feel much more idiomatic - in particular, we want a way to get our datasets to automatically convert nicely to `tf.data.dataset` objects, allowing you get really nice stuff like large dataset streaming without needing to preload the whole thing and variable-length batching to avoid wasted computation during training.\n\n**sounds cool, how do i use it?**\n\neasy, just `pip install transformers`! all our tf models are keras models now - in fact, they have been for a while! i've written up [tf examples for a range of nlp tasks in the new style](https://github.com/huggingface/transformers/-----> tree !!! /master/examples/tensorflow) too, so you can run those as-is or adapt them to your particular needs.\n\n**your example code is sloppy garbage and i don't want to read a whole script of it.**\n\nyour criticism has been noted. also that isn't a question.\n\n**okay fine, can i use this without having to read those example scripts?**\n\nsure! if you're already a tf/keras developer, the code below should feel very familiar to you - in fact, the only new bit will be the model loading and the tokenization needed to convert input text into integer ids:\n\n    from transformers import autotokenizer, tfautomodelforsequenceclassification\n    import tensorflow as tf\n    \n    model_name = 'bert-base-cased'\n    tokenizer = autotokenizer.from_pretrained(model_name)\n    model = tfautomodelforsequenceclassification.from_pretrained(model_name, num_labels=2)\n    \n    texts = [\"i'm a positive example!\", \"i'm a negative example!\"]\n    labels = [1, 0]\n    \n    # pad the tokenizer outputs to the same length for all samples\n    processed_text = tokenizer(texts, padding='longest', return_tensors='tf')  \n    labels = tf.convert_to_tensor(labels)\n    \n    opt = tf.keras.optimizers.adam(5e-5)  # transformers like lower learning rates\n    loss = tf.keras.losses.sparsecategoricalcrossentropy(from_logits=true)  # model outputs raw logits\n    model.compile(optimizer=opt, loss=loss)\n    \n    model.fit(dict(processed_text), labels, epochs=3)\n\nbam. you just fine-tuned a massive pre-trained language model. swap in your own data for texts and labels, and you can get superb performance on whatever task you want. call your boss and tell them you're an nlp engineer now and you want a salary review next quarter. we recommend more than two training examples, and maybe a validation set if you're feeling fancy, but we can't force you. live wild and free. if you want another model, simply replace `bert-base-cased` with your model of choice; there are [plenty to choose from](https://huggingface.co/models).\n\n**i ran that code and it worked but there were some scary warnings!**\n\nthose are purely cosmetic, but they are *very* annoying, especially because it's not like tf needs **more** console spam. they're on my list of things that need fixing in the near future. if you're reading this in a couple of months and they're still there, [tweet insults at me](https://twitter.com/carrigmat) until they aren't.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 6, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ok81v4/n_tf_keras_and_transformers/',)", "identifyer": 5725929, "year": "2021"}, {"autor": "p00pl00ps", "date": 1626189874000, "content": "[P] StyleGAN2 for character portraits and style transfer /!/ Hi all!\n\nI've been working on a fun little projects for a while. It's a simple webapp which serves a couple of styleGAN2 models I  trained on a dataset of hand-drawn portraits in the style of classic RPGs.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/96egpvrvyza71.png?width=256&amp;format=png&amp;auto=webp&amp;s=4e52e42cb3710ddaeebd59cd9da735341a9d5a09\n\n&amp;#x200B;\n\n* The first model simply generates a character portrait, and does so using conditional labels allowing you to pick gender and traditional fantasy races.\n* The second model takes real faces, aligns them and [pixel2style2pixel](https://github.com/eladrich/pixel2style2pixel/tree/master/models) invert to the stylegan latent space and thus perform style transfer. The image above is the output of putting in a picture of a certain famous ML figure...see if you can recognise them!\n\nBoth models have their fair share of issues and need more work, but I thought the results were cool enough to share. You can play with th API  [here](https://rp-gen.com) if you're interested (excuse bugs / breakages due to server overloads...)\n\n&amp;#x200B;\n\nEnjoy and le me know what you think!", "link": "https://www.reddit.com/r/MachineLearning/comments/ojhvkl/p_stylegan2_for_character_portraits_and_style/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] stylegan2 for character portraits and style transfer /!/ hi all!\n\ni've been working on a fun little projects for a while. it's a simple webapp which serves a couple of stylegan2 models i  trained on a dataset of hand-drawn portraits in the style of classic rpgs.\n\n&amp;#x200b;\n\nhttps://preview.redd.it/96egpvrvyza71.png?width=256&amp;format=png&amp;auto=webp&amp;s=4e52e42cb3710ddaeebd59cd9da735341a9d5a09\n\n&amp;#x200b;\n\n* the first model simply generates a character portrait, and does so using conditional labels allowing you to pick gender and traditional fantasy races.\n* the second model takes real faces, aligns them and [pixel2style2pixel](https://github.com/eladrich/pixel2style2pixel/-----> tree !!! /master/models) invert to the stylegan latent space and thus perform style transfer. the image above is the output of putting in a picture of a certain famous ml figure...see if you can recognise them!\n\nboth models have their fair share of issues and need more work, but i thought the results were cool enough to share. you can play with th api  [here](https://rp-gen.com) if you're interested (excuse bugs / breakages due to server overloads...)\n\n&amp;#x200b;\n\nenjoy and le me know what you think!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ojhvkl/p_stylegan2_for_character_portraits_and_style/',)", "identifyer": 5726021, "year": "2021"}, {"autor": "greentfrapp", "date": 1629546495000, "content": "[P] Run NeuralHash in your browser! /!/ I got tired of running Terminal commands and built an app that runs the NeuralHash algorithm on browser using Tensorflow.js (only works on desktop for now):\n\n[Link](https://greentfrapp.github.io/compute-your-own-neuralhash)\n\nThe weights had to be converted via [tfjs](https://github.com/tensorflow/tfjs/tree/master/tfjs-converter), which might have resulted in some slight variation.\n\nSome observations:\n\n* As expected, the computed NeuralHashes differed in varying degrees between the browser implementation and the ONNX runtime implementation, likely due to the exporting of weights and floating-point differences\n* Natural images had largely consistent NeuralHashes between the implementations, while differences were most pronounced in adversarial images - many adversarial images didn't work in the browser implementation, which suggests they are fairly brittle for now\n* The ImageNet collisions found [here](https://github.com/roboflow-ai/neuralhash-collisions) can be consistently reproduced in the demo\n\nCredits to u/AsuharietYgvar for their [post](https://www.reddit.com/r/MachineLearning/comments/p6hsoh/p_appleneuralhash2onnx_reverseengineered_apple/) on extracting the ONNX model.", "link": "https://www.reddit.com/r/MachineLearning/comments/p8q27o/p_run_neuralhash_in_your_browser/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] run neuralhash in your browser! /!/ i got tired of running terminal commands and built an app that runs the neuralhash algorithm on browser using tensorflow.js (only works on desktop for now):\n\n[link](https://greentfrapp.github.io/compute-your-own-neuralhash)\n\nthe weights had to be converted via [tfjs](https://github.com/tensorflow/tfjs/-----> tree !!! /master/tfjs-converter), which might have resulted in some slight variation.\n\nsome observations:\n\n* as expected, the computed neuralhashes differed in varying degrees between the browser implementation and the onnx runtime implementation, likely due to the exporting of weights and floating-point differences\n* natural images had largely consistent neuralhashes between the implementations, while differences were most pronounced in adversarial images - many adversarial images didn't work in the browser implementation, which suggests they are fairly brittle for now\n* the imagenet collisions found [here](https://github.com/roboflow-ai/neuralhash-collisions) can be consistently reproduced in the demo\n\ncredits to u/asuharietygvar for their [post](https://www.reddit.com/r/machinelearning/comments/p6hsoh/p_appleneuralhash2onnx_reverseengineered_apple/) on extracting the onnx model.", "sortedWord": "None", "removed": "('nan',)", "score": 3, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p8q27o/p_run_neuralhash_in_your_browser/',)", "identifyer": 5726091, "year": "2021"}, {"autor": "retro_var", "date": 1619635905000, "content": "[D] Books or Articles in Tree Based Methods with Formal Mathematics? /!/ Hi. \n\nI'm searching books or articles explaining Tree Based Methods (Random Forest, Gradient Boost, etc.) with extensive mathematical theory in the background. \n\nBut, the only similar book that i've found was [\"Classification and Regression Tree\" by Brieman, Friedman (1984).](https://www.amazon.com/-/es/Leo-Breiman/dp/0412048418)\n\nI will be glad if you could recommend new information.\n\nThanks.", "link": "https://www.reddit.com/r/MachineLearning/comments/n0lw6l/d_books_or_articles_in_tree_based_methods_with/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] books or articles in -----> tree !!!  based methods with formal mathematics? /!/ hi. \n\ni'm searching books or articles explaining tree based methods (random forest, gradient boost, etc.) with extensive mathematical theory in the background. \n\nbut, the only similar book that i've found was [\"classification and regression tree\" by brieman, friedman (1984).](https://www.amazon.com/-/es/leo-breiman/dp/0412048418)\n\ni will be glad if you could recommend new information.\n\nthanks.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 7, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n0lw6l/d_books_or_articles_in_tree_based_methods_with/',)", "identifyer": 5726447, "year": "2021"}, {"autor": "mlvpj", "date": 1622295854000, "content": "[P] StyleGAN2 implementation with side-by-side notes /!/ Implemented StyleGAN2 model and training loop from paper \"Analyzing and Improving the Image Quality of StyleGAN\".\n\nCode with annotations: [https://nn.labml.ai/gan/stylegan/index.html](https://nn.labml.ai/gan/stylegan/index.html)\n\nThis is a minimalistic implementation with only 425 lines of code and lots of documentations and diagrams explaining the model.\n\n* [Github](https://github.com/lab-ml/annotated_deep_learning_paper_implementations/tree/master/labml_nn/gan/stylegan)\n* [Paper on arXiv](https://arxiv.org/abs/1912.04958)", "link": "https://www.reddit.com/r/MachineLearning/comments/nnnrqb/p_stylegan2_implementation_with_sidebyside_notes/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] stylegan2 implementation with side-by-side notes /!/ implemented stylegan2 model and training loop from paper \"analyzing and improving the image quality of stylegan\".\n\ncode with annotations: [https://nn.labml.ai/gan/stylegan/index.html](https://nn.labml.ai/gan/stylegan/index.html)\n\nthis is a minimalistic implementation with only 425 lines of code and lots of documentations and diagrams explaining the model.\n\n* [github](https://github.com/lab-ml/annotated_deep_learning_paper_implementations/-----> tree !!! /master/labml_nn/gan/stylegan)\n* [paper on arxiv](https://arxiv.org/abs/1912.04958)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nnnrqb/p_stylegan2_implementation_with_sidebyside_notes/',)", "identifyer": 5726744, "year": "2021"}, {"autor": "FormalWolf5", "date": 1623094756000, "content": "[D] Minimum requirements for loading gpt2-xl /!/ Hey! Quick question, First of all, sorry if this is not the right place for this question. I'm a beginner. \n\nSo I'm wondering which would be the minimum requirements for loading the [gpt2-xl](https://huggingface.co/gpt2-xl) PyTorch model, RAM is the key thing here I guess. Note that I am not talking about Fine-Tuning, but rather just load it. \n\nI am using [this](https://github.com/graykode/gpt-2-Pytorch) repo to load the [large](https://huggingface.co/gpt2-large/tree/main) version via Google Colab and it works changing a few parameters. But when trying to load the xl in the RAM the python process is just directly killed. \n\nFor example, would this VPS configuration be enough?\n\n**6 vCPU Cores**\n\n**16 GB RAM**\n\n**400 GB SSD**\n\n**400 Mbit/s Port**\n\n**thanks!!**", "link": "https://www.reddit.com/r/MachineLearning/comments/nulhcw/d_minimum_requirements_for_loading_gpt2xl/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] minimum requirements for loading gpt2-xl /!/ hey! quick question, first of all, sorry if this is not the right place for this question. i'm a beginner. \n\nso i'm wondering which would be the minimum requirements for loading the [gpt2-xl](https://huggingface.co/gpt2-xl) pytorch model, ram is the key thing here i guess. note that i am not talking about fine-tuning, but rather just load it. \n\ni am using [this](https://github.com/graykode/gpt-2-pytorch) repo to load the [large](https://huggingface.co/gpt2-large/-----> tree !!! /main) version via google colab and it works changing a few parameters. but when trying to load the xl in the ram the python process is just directly killed. \n\nfor example, would this vps configuration be enough?\n\n**6 vcpu cores**\n\n**16 gb ram**\n\n**400 gb ssd**\n\n**400 mbit/s port**\n\n**thanks!!**", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nulhcw/d_minimum_requirements_for_loading_gpt2xl/',)", "identifyer": 5726807, "year": "2021"}, {"autor": "lgirl2342", "date": 1623033702000, "content": "[R] How do I know if deep learning is appropriate for my problem? /!/ Hi all,\n\nI'm working on a problem and have tried a few approaches including decision tree approaches that have had some success, but I'm looking to go about my problem differently and beat my previous approach. I can't go into detail about what it is but I only have about 100 features, most of which are categorical. I only have a couple of thousand rows of data available. For data like this, is it possible that neural net (with say, 10+ hidden layers) could be an appropriate approach for my problem? Or if it might just overfit quite a bit because it's a small dataset. I did try a few layers and I'm getting some success but still worse than my other models. I also tried including some dropout layers to regularize/prevent overfitting and it didn't seem to improve performance.\n\nI'd also love any resources on how to develop intuition for deep learning and whether it's a good approach? \n\nThank you so much :)", "link": "https://www.reddit.com/r/MachineLearning/comments/nu222g/r_how_do_i_know_if_deep_learning_is_appropriate/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] how do i know if deep learning is appropriate for my problem? /!/ hi all,\n\ni'm working on a problem and have tried a few approaches including decision -----> tree !!!  approaches that have had some success, but i'm looking to go about my problem differently and beat my previous approach. i can't go into detail about what it is but i only have about 100 features, most of which are categorical. i only have a couple of thousand rows of data available. for data like this, is it possible that neural net (with say, 10+ hidden layers) could be an appropriate approach for my problem? or if it might just overfit quite a bit because it's a small dataset. i did try a few layers and i'm getting some success but still worse than my other models. i also tried including some dropout layers to regularize/prevent overfitting and it didn't seem to improve performance.\n\ni'd also love any resources on how to develop intuition for deep learning and whether it's a good approach? \n\nthank you so much :)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 18, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nu222g/r_how_do_i_know_if_deep_learning_is_appropriate/',)", "identifyer": 5726854, "year": "2021"}, {"autor": "DCL-2021", "date": 1624935889000, "content": "[N][R] A Brief Tutorial for Developing AutoML Tools with Hypernets /!/ # A Brief Tutorial for Developing AutoML Tools with Hypernets\n\n*Please see* [*here*](https://github.com/DataCanvasIO/Hypernets) *for the* `Hypernets` *library.*\n\nParameter tuning is an inevitable step for successfully building a machine learning model. Even for a simple model as K-nearest neighbors(KNN) for the classification task, we need to at least determine the number of the neighbors and the distance metric to be used to predict the label of a given example. Let alone models which have much more tunable parameters and have to be trained multiple times before we can pick suitable values for their parameters. Furthermore, tuning parameters in a brute force approach is inefficient while using an advanced search method takes intensive efforts. Can we focus more on parts of machine learning like designing novel models while only performing procedures like parameter tuning in a simple and happy way?\n\nThe answer is positive.\n\n`Hypernets`, a unified Automated Machine learning(AutoML) framework, offers us a very simple way to solve such problems. Taking the parameter tuning problem of the KNN model as an example, using a `search_param` function from the `Hypernets`, the only required work for us is to define a function serving as the measure of the quality of a set of given parameters.\n\n    from sklearn import neighbors\n    \n    def score_function(X_train, y_train, X_evl, y_evl, \n                       n_neighbors=Choice([3, 5, 6, 10, 20]),\n                       weights=Choice(['uniform', 'distance']),\n                       algorithm=Choice(['auto', 'ball_tree', 'kd_tree', 'brute']),\n                       leaf_size=30,\n                       p=Choice([1, 2])):\n        # The avaliable values for each tunable parameter are those provided by the list\n        # elements of the argument of Choice(). For example, the parameter \"n_neighbors\",\n        # the number of the nearest neighbors used to predict the label of a given example, \n        # can be chosen as 3, 5, 6, 10, and 20. \n        model = neighbors.KNeighborsClassifier(n_neighbors, weights, algorithm, leaf_size, p)\n        model.fit(X_train, y_train)\n        scores = model.score(X_evl, y_evl) #This score is taken as the mean accuracy of the model on (X_evl, y_evl)\n        return scores\n\nCurrently, there is no need to know how the function `search_param` is able to perform parameter tuning by utilizing the above score function--we only manually provide possible values we like to `Choice()` for each tunable parameter. Now let's use the `search_param` function with the gird search algorithm, or other search algorithms such as random search or Monte-Carlo Tree search, to find the suitable parameter values for our KNN model by simply passing the `score_function` defined above as an argument to it:\n\n    import hypernets.utils.param_tuning as pt\n    history = pt.search_params(score_function, 'grid', max_trials=10, optimize_direction='max')\n\nThe best model parameters can be obtained by calling the following method of `history`\n\n    best_param = history.get_best().sample\n\nThis is not the whole story.\n\nParameter tuning is only a fraction of the full-pipeline AutoML process and `Hypernets` is capable of doing far more things than just tuning parameters. In the following sections, we will briefly introduce `Hypernets` as an AutoML framework and wish to clarify:\n\n* the basic building blocks of `Hypernets`;\n* basic procedures to develop an AutoML tool for parameter tuning problem and the more general full-pipeline machine learning modeling;\n* some advanced features of `Hypernets`.\n\n## Parameter tuning for KNN with an AutoML tool built with Hypernets\n\n`Hypernets` is an AutoML framework that allows the users to easily develop various kinds of AutoML and Automated Deep Learning(AutoDL) tools without reinventing some necessary components which are often common to such tools. Before `Hypernets`, there already existed many AutoML tools. However, these tools are usually designed for some specific purposes thus not convenient to be generalized to other ones. As a result, the AutoML community may have to take a lot of efforts to repeatedly develop some common parts before deploying their AutoML models due to the lack of an underlying AutoML framework. \n\nhttps://preview.redd.it/ry1cz7d0f4871.png?width=1029&amp;format=png&amp;auto=webp&amp;s=3142f3f5fffba28e615ebbc6d352038aa31bcc64\n\n`Hypernets` can save such efforts to a large extent while offering more possibilities.\n\n* First, it decouples the basic components of a general [AutoML procedure](#fig_automl) as [four distinct parts](#fig_hypernets): the `HyperSpace`, the `Searcher`, the `HyperModel`, and the `Estimation Strategy`. This idea is motivated by allowing users to manipulate different components of an AutoML tool built with `Hypernets` accordingly for different purposes.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/zs83na02f4871.png?width=1809&amp;format=png&amp;auto=webp&amp;s=0a7c4dbbc443fb7397a3dad6f022f3cfbd7833bd\n\n* Second, the `HyperSpace` is designed to be a powerful search space. The `HyperSpace` consists of three different kinds of space: the **module space**, the **parameter space** and the **connection space**, where the module space is designed to contain various machine learning models, data preprocessing or feature engineerings, the parameter space provides the parameters to be searched for machine learning models and the connection space determines the way how different module spaces connect. These connected module spaces and parameter spaces finally give us a highly comprehensive search space which is able to describe the full-pipeline machine learning modeling ranging from data preprocessing to model ensemble.\n* Third, `Hypernets` provides many search algorithms including simple methods, such as Random Search and Grid Search, and advanced ones such as Monte-Carlo Tree Search. Users can not only simply choose one from these efficient search methods but also similarly design new search algorithms.\n* Finally, `Hypernets` also supports many advanced techniques to further improve performances of the trained machine learning models. For example, users can apply early stopping to accelerate the training process and prevent overfitting; data cleaning can be applied to improve data quality; data drift detection can be enabled to improve the generalization ability of the model, etc.\n\nBased on the above brief introduction, using the `Hypernets` to develop an AutoML tool can now be decomposed as three parts: designing the **Search Space**, an instance of the `Hyperspace`, constructing the **Hypermodel** which will be sampled from the search space using a searcher provided by `Hypernets` during the search process, and building the **Estimator** which receives a sampled Hypermodel, evaluates it and then returns the corresponding rewards such that the searcher can update the Hypermodel to be sampled based on the rewards.\n\nWe will provide a toy example, designing an AutoML tool for KNN, to help the readers walk through all steps of implementing the `Hypernets` to an AutoML task.\n\nTo reveal the core features and ideas of `Hypernets`, we first continue to solve the problem defined in the very beginning--how to perform parameter tuning of KNN automatically using `Hyernets`\\--but in a different manner: we view the parameter tuning problem as a complete AutoML task and develop a complete AutoML tool for this task from scratch using `Hypernets`. For simplicity, we only consider the classification task, and the regression case can be easily generalized. As introduced above, this developing procedure contains 3 steps and we will simply follow these steps. See [here](https://github.com/BochenLv/knn_toy_model/blob/main/hypertoy/param_tuning_v2.py) for details.\n\n* ***Designing the search space.*** In the case of parameter tuning, our search space of the AutoML task, a HyperSpace, is very simple in the sense that there is only one module space which contains only one machine learning model--our KNN model--along with its parameter space. To incorporate these spaces, we first define the ParameterSpace for tunable parameters with different values and then build the whole HyperSpace to include this ParameterSpace so that the search algorithm can search suitable parameters among available ones.\n* ***Constructing the Hypermodel.*** The HyperModel does not require many modifications for our specific task since many core functionalities of the HyperModel have already been well defined in `Hypernets` and are common across different machine learning models and tasks. We only pay attention to two functions, the `_get_estimator`, which returns the corresponding KNN model of the sampled search space, and the `load_estimator`, which loads the configurations of the saved model. The most important method for a HyperModel is the \"search\" method. By calling the `search` method, the search algorithm searches in the search space and returns a sample of the search space to be utilized for the HyperModel. This HyperModel is then evaluated based on the chosen reward metric and updated towards the optimizing direction.\n* ***Building the Estimator.*** Building the Estimator often takes the most effort for developing a new AutoML tool using `Hypernets`. The `Estimators` required by `Hypernets` is in fact a more general notion than the frequently used one in `sklearn`\\--the machine learning model. Fortunately, for our case of parameter tuning of KNN, the `Estimator` is easy to be implemented since the sampled search space only contains one machine learning model which is the only thing that needs to be evaluated by the `Estimator`. Moreover, we emphasize that the actual abilities of the `Estimator` are not restricted to that defined in this section and we refer the readers to the [next section](#sec_eg) for further details.\n\nWith the above AutoML tool, we are now ready to perform a complete automatic parameter tuning for KNN. In general, we only need four lines of codes to complete such implementation after we finish designing the required AutoML tools--not for the specific example presented here but a more general routine. This routine is summarized as follows:\n\n1. Define the search space.\n2. Choose a searcher from those search algorithms provided by `Hypernets`. One required  argument for the searcher is the search space in which the searcher will perform searching.\n3. Construct the HyperModel which receives the searcher as its required argument. In our example, the HyperModel is the `KnnModel`.\n4. The `search` method of our HyperModel is called to automatically perform the search process on the dataset (X\\_train, y\\_train) and record the current best model parameters.\n5. One can get the best model in the following way:\n\nNow we can celebrate the fine-tuned KNN model!\n\nThe convenience of following this procedure lies in that one needs not to develop anything else to perform parameter tuning of the KNN model for other classification task datasets without categorical features. Instead, simply passing these datasets to the `search` method of the `KnnModel` will return us the model with suitable parameters.\n\nHowever, readers will also immediately notice that, before sending the dataset to the model, one has to manually handle the categorical features of some datasets if there exist such things because the KNN model can not treat with categorical features properly. Some users may also want our AutoML tool to be able to perform more things like data cleaning. It is therefore a great idea to extend our AutoML tool for the KNN model to automate the full pipeline of machine learning tasks once for all. These are exactly the topics of the [next section](#sec_eg).\n\n## Building your full-pipeline AutoML tool for KNN&lt;span id=sec_eg&gt;\n\nTypically, the procedures of a full-pipeline machine learning modeling range from data preprocessing to model ensemble. For the purpose of enabling our AutoML tool to automate such full-pipeline modeling, we need to design a more comprehensive search space, which should at least include transformations of the data, feature engineerings, and the machine learning models along with their tunable parameters. Such an AutoML tool will largely relieve us from the headaches of dealing with data and feature issues of datasets.\n\nTherefore, the most important part and the primary work we will do is to extend our search space based on the introduction of the basic building blocks of `Hypernets` in the last section. For clarity, we still follow the 3 steps of developing our AutoML tools for full-pipeline KNN model with `Hypernets` as indicated before.\n\n* ***Designing a search space.*** To enable our AutoML tool to perform procedures like data    preprocessing, we need to encapsulate these procedures into module spaces for our search space, a `HyperSpace` object, and then connect them using the `ConnectionSpace` as introduced above. For this reason, these module spaces are now divided into two kinds: one containing the **preprocessor** and the other for **machine learning model**, i.e. KNN model here. We now devote to wrapping these two kinds of module spaces into our search space respectively for full-pipeline AutoML process.\n* ***Constructing the Hypermodel.*** Similar to the last section of the parameter tuning problem, to construct the HyperModel(named as `KnnModel`) one only needs to define two functions properly: `_get_estimator` and `load_estimator`. Other necessary parts of it have already been well defined in `Hypernets`.\n* ***Building the Estimator.*** One may immediately notice that we nearly did nothing in last step. Is our Hypermodel defined there a unique one? The answer is positive. The uniqueness of `HyperModel` built for a specific machine learning model, e.g. the Hypermodel for KNN or support vector machine, is provided by its associated Estimator through receiving the corresponding search space. As discussed before, the Estimator used in `Hypernets` is a more general notion than the usual one--the machine learning model--which is a fraction of the Estimator but also the origin of the uniqueness of each Estimator because the steps before introducing machine learning models to the full-pipeline modeling are usually common for different cases. As a result, although an Estimator usually includes many arguments and functions to support advanced features of `Hypernets`, fortunately, there is nearly nothing that needs to be rewritten from scratch when we want to extend our procedures to other machine learning models.\n\nThere are extra things need to be noted: our KNN model should be utilized in the form of a `ModuleSpace` in the search space and should automatically adjust itself for the classification or regression task. For these purposes, a `ComplexKnn` is provided to wrap the KNN to the HyperSpace for our full-pipeline machine learning modeling when we designed our search space:\n\n        class ComplexKnn(HyperEstimator):\n            def __init__(self, fit_kwargs, \n                            n_neighbors=2, weights='uniform', algorithm='brute', \n                            leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None,\n                            space=None, name=None, **kwargs\n                        ):\n                ...\n                HyperEstimator.__init__(self, fit_kwargs, space, name, **kwargs)\n    \n            def _build_estimator(self, task, kwargs):\n                if task == 'regression':\n                    knn = KnnRegressorWrapper(**kwargs)\n                else:\n                    knn = KnnClassifierWrapper(**kwargs)\n                return knn     \n\nwhere the `HyperEstimator` inherits from the `ModuleSpace` to transfer our KNN model to a module space in the search space. Please refer [`estimator.py`](https://github.com/BochenLv/knn_toy_model/blob/main/hypertoy/estimator.py) for further details.\n\nWe now have the complete AutoML tool for full-pipeline machine learning modeling with KNN! Let's try to use our extended AutoML tool for an example following the routine discussed in the end of the last section:\n\n    #Load the data and suppose that the task is multi-classification\n    from sklearn.model_selection import train_test_split\n    X, y = load_your_data()\n    X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.1)\n    \n    #Design a search space\n    search_space = get_your_search_space\n    \n    #Choose a searcher from the Hypernets searchers\n    searcher = GridSearcher(search_space)\n    \n    #Pass the searcher as an argument to your model, a Hypermodel object\n    model = KnnModel(searcher, task='multiclass', reward='accuracy')\n    \n    #Call the 'search' method\n    model.search(X_train, y_train, X_eval=X_test, y_eval=y_test)\n\nFor convenience, we also provide an [example](https://github.com/BochenLv/knn_toy_model/blob/main/test_full_pipeline_simple.ipynb). With this kind of AutoML tool, we can simply pass the datasets to our AutoML tools without considering issues regarding the datasets for that our AutoML tool is designed to automate the full-pipeline of machine learning modeling. More importantly, our procedures presented here can be easily generalized to other machine learning models. There are also many techniques such as cross validation which can be further added to our toy tool to improve its performance. We will leave these contents for future discussions.", "link": "https://www.reddit.com/r/MachineLearning/comments/o9zopz/nr_a_brief_tutorial_for_developing_automl_tools/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[n][r] a brief tutorial for developing automl tools with hypernets /!/ # a brief tutorial for developing automl tools with hypernets\n\n*please see* [*here*](https://github.com/datacanvasio/hypernets) *for the* `hypernets` *library.*\n\nparameter tuning is an inevitable step for successfully building a machine learning model. even for a simple model as k-nearest neighbors(knn) for the classification task, we need to at least determine the number of the neighbors and the distance metric to be used to predict the label of a given example. let alone models which have much more tunable parameters and have to be trained multiple times before we can pick suitable values for their parameters. furthermore, tuning parameters in a brute force approach is inefficient while using an advanced search method takes intensive efforts. can we focus more on parts of machine learning like designing novel models while only performing procedures like parameter tuning in a simple and happy way?\n\nthe answer is positive.\n\n`hypernets`, a unified automated machine learning(automl) framework, offers us a very simple way to solve such problems. taking the parameter tuning problem of the knn model as an example, using a `search_param` function from the `hypernets`, the only required work for us is to define a function serving as the measure of the quality of a set of given parameters.\n\n    from sklearn import neighbors\n    \n    def score_function(x_train, y_train, x_evl, y_evl, \n                       n_neighbors=choice([3, 5, 6, 10, 20]),\n                       weights=choice(['uniform', 'distance']),\n                       algorithm=choice(['auto', 'ball_tree', 'kd_tree', 'brute']),\n                       leaf_size=30,\n                       p=choice([1, 2])):\n        # the avaliable values for each tunable parameter are those provided by the list\n        # elements of the argument of choice(). for example, the parameter \"n_neighbors\",\n        # the number of the nearest neighbors used to predict the label of a given example, \n        # can be chosen as 3, 5, 6, 10, and 20. \n        model = neighbors.kneighborsclassifier(n_neighbors, weights, algorithm, leaf_size, p)\n        model.fit(x_train, y_train)\n        scores = model.score(x_evl, y_evl) #this score is taken as the mean accuracy of the model on (x_evl, y_evl)\n        return scores\n\ncurrently, there is no need to know how the function `search_param` is able to perform parameter tuning by utilizing the above score function--we only manually provide possible values we like to `choice()` for each tunable parameter. now let's use the `search_param` function with the gird search algorithm, or other search algorithms such as random search or monte-carlo -----> tree !!!  search, to find the suitable parameter values for our knn model by simply passing the `score_function` defined above as an argument to it:\n\n    import hypernets.utils.param_tuning as pt\n    history = pt.search_params(score_function, 'grid', max_trials=10, optimize_direction='max')\n\nthe best model parameters can be obtained by calling the following method of `history`\n\n    best_param = history.get_best().sample\n\nthis is not the whole story.\n\nparameter tuning is only a fraction of the full-pipeline automl process and `hypernets` is capable of doing far more things than just tuning parameters. in the following sections, we will briefly introduce `hypernets` as an automl framework and wish to clarify:\n\n* the basic building blocks of `hypernets`;\n* basic procedures to develop an automl tool for parameter tuning problem and the more general full-pipeline machine learning modeling;\n* some advanced features of `hypernets`.\n\n## parameter tuning for knn with an automl tool built with hypernets\n\n`hypernets` is an automl framework that allows the users to easily develop various kinds of automl and automated deep learning(autodl) tools without reinventing some necessary components which are often common to such tools. before `hypernets`, there already existed many automl tools. however, these tools are usually designed for some specific purposes thus not convenient to be generalized to other ones. as a result, the automl community may have to take a lot of efforts to repeatedly develop some common parts before deploying their automl models due to the lack of an underlying automl framework. \n\nhttps://preview.redd.it/ry1cz7d0f4871.png?width=1029&amp;format=png&amp;auto=webp&amp;s=3142f3f5fffba28e615ebbc6d352038aa31bcc64\n\n`hypernets` can save such efforts to a large extent while offering more possibilities.\n\n* first, it decouples the basic components of a general [automl procedure](#fig_automl) as [four distinct parts](#fig_hypernets): the `hyperspace`, the `searcher`, the `hypermodel`, and the `estimation strategy`. this idea is motivated by allowing users to manipulate different components of an automl tool built with `hypernets` accordingly for different purposes.\n\n&amp;#x200b;\n\nhttps://preview.redd.it/zs83na02f4871.png?width=1809&amp;format=png&amp;auto=webp&amp;s=0a7c4dbbc443fb7397a3dad6f022f3cfbd7833bd\n\n* second, the `hyperspace` is designed to be a powerful search space. the `hyperspace` consists of three different kinds of space: the **module space**, the **parameter space** and the **connection space**, where the module space is designed to contain various machine learning models, data preprocessing or feature engineerings, the parameter space provides the parameters to be searched for machine learning models and the connection space determines the way how different module spaces connect. these connected module spaces and parameter spaces finally give us a highly comprehensive search space which is able to describe the full-pipeline machine learning modeling ranging from data preprocessing to model ensemble.\n* third, `hypernets` provides many search algorithms including simple methods, such as random search and grid search, and advanced ones such as monte-carlo tree search. users can not only simply choose one from these efficient search methods but also similarly design new search algorithms.\n* finally, `hypernets` also supports many advanced techniques to further improve performances of the trained machine learning models. for example, users can apply early stopping to accelerate the training process and prevent overfitting; data cleaning can be applied to improve data quality; data drift detection can be enabled to improve the generalization ability of the model, etc.\n\nbased on the above brief introduction, using the `hypernets` to develop an automl tool can now be decomposed as three parts: designing the **search space**, an instance of the `hyperspace`, constructing the **hypermodel** which will be sampled from the search space using a searcher provided by `hypernets` during the search process, and building the **estimator** which receives a sampled hypermodel, evaluates it and then returns the corresponding rewards such that the searcher can update the hypermodel to be sampled based on the rewards.\n\nwe will provide a toy example, designing an automl tool for knn, to help the readers walk through all steps of implementing the `hypernets` to an automl task.\n\nto reveal the core features and ideas of `hypernets`, we first continue to solve the problem defined in the very beginning--how to perform parameter tuning of knn automatically using `hyernets`\\--but in a different manner: we view the parameter tuning problem as a complete automl task and develop a complete automl tool for this task from scratch using `hypernets`. for simplicity, we only consider the classification task, and the regression case can be easily generalized. as introduced above, this developing procedure contains 3 steps and we will simply follow these steps. see [here](https://github.com/bochenlv/knn_toy_model/blob/main/hypertoy/param_tuning_v2.py) for details.\n\n* ***designing the search space.*** in the case of parameter tuning, our search space of the automl task, a hyperspace, is very simple in the sense that there is only one module space which contains only one machine learning model--our knn model--along with its parameter space. to incorporate these spaces, we first define the parameterspace for tunable parameters with different values and then build the whole hyperspace to include this parameterspace so that the search algorithm can search suitable parameters among available ones.\n* ***constructing the hypermodel.*** the hypermodel does not require many modifications for our specific task since many core functionalities of the hypermodel have already been well defined in `hypernets` and are common across different machine learning models and tasks. we only pay attention to two functions, the `_get_estimator`, which returns the corresponding knn model of the sampled search space, and the `load_estimator`, which loads the configurations of the saved model. the most important method for a hypermodel is the \"search\" method. by calling the `search` method, the search algorithm searches in the search space and returns a sample of the search space to be utilized for the hypermodel. this hypermodel is then evaluated based on the chosen reward metric and updated towards the optimizing direction.\n* ***building the estimator.*** building the estimator often takes the most effort for developing a new automl tool using `hypernets`. the `estimators` required by `hypernets` is in fact a more general notion than the frequently used one in `sklearn`\\--the machine learning model. fortunately, for our case of parameter tuning of knn, the `estimator` is easy to be implemented since the sampled search space only contains one machine learning model which is the only thing that needs to be evaluated by the `estimator`. moreover, we emphasize that the actual abilities of the `estimator` are not restricted to that defined in this section and we refer the readers to the [next section](#sec_eg) for further details.\n\nwith the above automl tool, we are now ready to perform a complete automatic parameter tuning for knn. in general, we only need four lines of codes to complete such implementation after we finish designing the required automl tools--not for the specific example presented here but a more general routine. this routine is summarized as follows:\n\n1. define the search space.\n2. choose a searcher from those search algorithms provided by `hypernets`. one required  argument for the searcher is the search space in which the searcher will perform searching.\n3. construct the hypermodel which receives the searcher as its required argument. in our example, the hypermodel is the `knnmodel`.\n4. the `search` method of our hypermodel is called to automatically perform the search process on the dataset (x\\_train, y\\_train) and record the current best model parameters.\n5. one can get the best model in the following way:\n\nnow we can celebrate the fine-tuned knn model!\n\nthe convenience of following this procedure lies in that one needs not to develop anything else to perform parameter tuning of the knn model for other classification task datasets without categorical features. instead, simply passing these datasets to the `search` method of the `knnmodel` will return us the model with suitable parameters.\n\nhowever, readers will also immediately notice that, before sending the dataset to the model, one has to manually handle the categorical features of some datasets if there exist such things because the knn model can not treat with categorical features properly. some users may also want our automl tool to be able to perform more things like data cleaning. it is therefore a great idea to extend our automl tool for the knn model to automate the full pipeline of machine learning tasks once for all. these are exactly the topics of the [next section](#sec_eg).\n\n## building your full-pipeline automl tool for knn&lt;span id=sec_eg&gt;\n\ntypically, the procedures of a full-pipeline machine learning modeling range from data preprocessing to model ensemble. for the purpose of enabling our automl tool to automate such full-pipeline modeling, we need to design a more comprehensive search space, which should at least include transformations of the data, feature engineerings, and the machine learning models along with their tunable parameters. such an automl tool will largely relieve us from the headaches of dealing with data and feature issues of datasets.\n\ntherefore, the most important part and the primary work we will do is to extend our search space based on the introduction of the basic building blocks of `hypernets` in the last section. for clarity, we still follow the 3 steps of developing our automl tools for full-pipeline knn model with `hypernets` as indicated before.\n\n* ***designing a search space.*** to enable our automl tool to perform procedures like data    preprocessing, we need to encapsulate these procedures into module spaces for our search space, a `hyperspace` object, and then connect them using the `connectionspace` as introduced above. for this reason, these module spaces are now divided into two kinds: one containing the **preprocessor** and the other for **machine learning model**, i.e. knn model here. we now devote to wrapping these two kinds of module spaces into our search space respectively for full-pipeline automl process.\n* ***constructing the hypermodel.*** similar to the last section of the parameter tuning problem, to construct the hypermodel(named as `knnmodel`) one only needs to define two functions properly: `_get_estimator` and `load_estimator`. other necessary parts of it have already been well defined in `hypernets`.\n* ***building the estimator.*** one may immediately notice that we nearly did nothing in last step. is our hypermodel defined there a unique one? the answer is positive. the uniqueness of `hypermodel` built for a specific machine learning model, e.g. the hypermodel for knn or support vector machine, is provided by its associated estimator through receiving the corresponding search space. as discussed before, the estimator used in `hypernets` is a more general notion than the usual one--the machine learning model--which is a fraction of the estimator but also the origin of the uniqueness of each estimator because the steps before introducing machine learning models to the full-pipeline modeling are usually common for different cases. as a result, although an estimator usually includes many arguments and functions to support advanced features of `hypernets`, fortunately, there is nearly nothing that needs to be rewritten from scratch when we want to extend our procedures to other machine learning models.\n\nthere are extra things need to be noted: our knn model should be utilized in the form of a `modulespace` in the search space and should automatically adjust itself for the classification or regression task. for these purposes, a `complexknn` is provided to wrap the knn to the hyperspace for our full-pipeline machine learning modeling when we designed our search space:\n\n        class complexknn(hyperestimator):\n            def __init__(self, fit_kwargs, \n                            n_neighbors=2, weights='uniform', algorithm='brute', \n                            leaf_size=30, p=2, metric='minkowski', metric_params=none, n_jobs=none,\n                            space=none, name=none, **kwargs\n                        ):\n                ...\n                hyperestimator.__init__(self, fit_kwargs, space, name, **kwargs)\n    \n            def _build_estimator(self, task, kwargs):\n                if task == 'regression':\n                    knn = knnregressorwrapper(**kwargs)\n                else:\n                    knn = knnclassifierwrapper(**kwargs)\n                return knn     \n\nwhere the `hyperestimator` inherits from the `modulespace` to transfer our knn model to a module space in the search space. please refer [`estimator.py`](https://github.com/bochenlv/knn_toy_model/blob/main/hypertoy/estimator.py) for further details.\n\nwe now have the complete automl tool for full-pipeline machine learning modeling with knn! let's try to use our extended automl tool for an example following the routine discussed in the end of the last section:\n\n    #load the data and suppose that the task is multi-classification\n    from sklearn.model_selection import train_test_split\n    x, y = load_your_data()\n    x_train, y_train, x_test, y_test = train_test_split(x, y, test_size=0.1)\n    \n    #design a search space\n    search_space = get_your_search_space\n    \n    #choose a searcher from the hypernets searchers\n    searcher = gridsearcher(search_space)\n    \n    #pass the searcher as an argument to your model, a hypermodel object\n    model = knnmodel(searcher, task='multiclass', reward='accuracy')\n    \n    #call the 'search' method\n    model.search(x_train, y_train, x_eval=x_test, y_eval=y_test)\n\nfor convenience, we also provide an [example](https://github.com/bochenlv/knn_toy_model/blob/main/test_full_pipeline_simple.ipynb). with this kind of automl tool, we can simply pass the datasets to our automl tools without considering issues regarding the datasets for that our automl tool is designed to automate the full-pipeline of machine learning modeling. more importantly, our procedures presented here can be easily generalized to other machine learning models. there are also many techniques such as cross validation which can be further added to our toy tool to improve its performance. we will leave these contents for future discussions.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o9zopz/nr_a_brief_tutorial_for_developing_automl_tools/',)", "identifyer": 5727299, "year": "2021"}, {"autor": "Bugattisport1", "date": 1634836588000, "content": "Tennis Outcome Prediction model rapminer [P] /!/ I am a student using rapidminer to try and put together an ML approach to predict the outcome of tennis games, feeding it data from a few decades of tennis data. Have been running into some issues using decision tree, naive bayes. My main issue is that, although the prediction works, it does not choose out of the 2 players who were actually playing in the match. Instead it picks some player in the whole dataset that it thinks is most likely to win against the said player.\n\nI was wondering if anyone else here had experience using this nocode program and could guide me to getting my prediction to compare the correct players?", "link": "https://www.reddit.com/r/MachineLearning/comments/qcwn24/tennis_outcome_prediction_model_rapminer_p/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "tennis outcome prediction model rapminer [p] /!/ i am a student using rapidminer to try and put together an ml approach to predict the outcome of tennis games, feeding it data from a few decades of tennis data. have been running into some issues using decision -----> tree !!! , naive bayes. my main issue is that, although the prediction works, it does not choose out of the 2 players who were actually playing in the match. instead it picks some player in the whole dataset that it thinks is most likely to win against the said player.\n\ni was wondering if anyone else here had experience using this nocode program and could guide me to getting my prediction to compare the correct players?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/qcwn24/tennis_outcome_prediction_model_rapminer_p/',)", "identifyer": 5727496, "year": "2021"}, {"autor": "Yuqing7", "date": 1633618590000, "content": "[R] Facebook &amp; CMU\u2019s Zero-Shot VideoCLIP Outperforms Fully-Supervised SOTA Methods for Video-Text Understanding /!/ A research team from Facebook AI and CMU presents VideoCLIP, a contrastive approach for pretraining a unified model for zero-shot video and text understanding without requiring annotated data for downstream tasks. \n\nHere is a quick read: [Facebook &amp; CMU\u2019s Zero-Shot VideoCLIP Outperforms Fully-Supervised SOTA Methods for Video-Text Understanding.](https://syncedreview.com/2021/10/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-119/)\n\nThe researchers have open-sourced the VideoCLIP code on the project [GitHub](https://github.com/pytorch/%20fairseq/tree/main/examples/MMPT). The paper *VideoCLIP: Contrastive Pre-Training for Zero-Shot Video-Text Understanding* is on [arXiv](https://arxiv.org/abs/2109.14084).", "link": "https://www.reddit.com/r/MachineLearning/comments/q3avhc/r_facebook_cmus_zeroshot_videoclip_outperforms/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] facebook &amp; cmu\u2019s zero-shot videoclip outperforms fully-supervised sota methods for video-text understanding /!/ a research team from facebook ai and cmu presents videoclip, a contrastive approach for pretraining a unified model for zero-shot video and text understanding without requiring annotated data for downstream tasks. \n\nhere is a quick read: [facebook &amp; cmu\u2019s zero-shot videoclip outperforms fully-supervised sota methods for video-text understanding.](https://syncedreview.com/2021/10/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-119/)\n\nthe researchers have open-sourced the videoclip code on the project [github](https://github.com/pytorch/%20fairseq/-----> tree !!! /main/examples/mmpt). the paper *videoclip: contrastive pre-training for zero-shot video-text understanding* is on [arxiv](https://arxiv.org/abs/2109.14084).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/q3avhc/r_facebook_cmus_zeroshot_videoclip_outperforms/',)", "identifyer": 5727702, "year": "2021"}, {"autor": "chub_chaz123", "date": 1634152342000, "content": "Binary decision tree that maximizes based on only samples where it predicts 1 /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/q7icjy/binary_decision_tree_that_maximizes_based_on_only/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "binary decision -----> tree !!!  that maximizes based on only samples where it predicts 1 /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/q7icjy/binary_decision_tree_that_maximizes_based_on_only/',)", "identifyer": 5727796, "year": "2021"}, {"autor": "blueest", "date": 1628305344000, "content": "[D] Measuring the \"Stability\" of Decision Trees /!/ We all know that there are certain problems in which Decision Trees have their advantages (e.g. smaller datasets in which the goal is interpretability), and other problems where Decision Trees perform poorly (e.g. big and complicated datasets). \n\nFor instance, there is a famous paper published by Bengio et al where they outlined some of these problems with the decision tree algorithm:\n\n https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.323.9955&amp;rep=rep1&amp;type=pdf#:~:text=In%20this%20paper%2C%20we%20study,seen%20in%20the%20training%20set.&amp;text=A%20decision%20tree%20learning%20algorithm,more%20training%20examples%20are%20available.\n\nIn this regard, I had a question about Decision Trees and Cross Validation. Suppose you have some data : you decide to use 70% of this data for a training set and the other 30% for a test set. Thus, the \"decision rules\" will be generated based on the 70%. From here, you can see how well these \"rules\" generalize to the other 30%.\n\nMy question: If your model performs well on the test set, and you are ready to submit your model - often, the model is retrained on the entire data. In the case of decision trees, won't this result in a new set of rules being generated? Is this a problem? Or do you just hope that these new \"rules\" will also generalize well?\n\nThanks", "link": "https://www.reddit.com/r/MachineLearning/comments/ozlebt/d_measuring_the_stability_of_decision_trees/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] measuring the \"stability\" of decision trees /!/ we all know that there are certain problems in which decision trees have their advantages (e.g. smaller datasets in which the goal is interpretability), and other problems where decision trees perform poorly (e.g. big and complicated datasets). \n\nfor instance, there is a famous paper published by bengio et al where they outlined some of these problems with the decision -----> tree !!!  algorithm:\n\n https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.323.9955&amp;rep=rep1&amp;type=pdf#:~:text=in%20this%20paper%2c%20we%20study,seen%20in%20the%20training%20set.&amp;text=a%20decision%20tree%20learning%20algorithm,more%20training%20examples%20are%20available.\n\nin this regard, i had a question about decision trees and cross validation. suppose you have some data : you decide to use 70% of this data for a training set and the other 30% for a test set. thus, the \"decision rules\" will be generated based on the 70%. from here, you can see how well these \"rules\" generalize to the other 30%.\n\nmy question: if your model performs well on the test set, and you are ready to submit your model - often, the model is retrained on the entire data. in the case of decision trees, won't this result in a new set of rules being generated? is this a problem? or do you just hope that these new \"rules\" will also generalize well?\n\nthanks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ozlebt/d_measuring_the_stability_of_decision_trees/',)", "identifyer": 5728024, "year": "2021"}, {"autor": "mgalarny", "date": 1612987080000, "content": "[P] Retrieval Augmented Generation with Huggingface Transformers, PyTorch, and Ray /!/ Hey Everyone,\n\nI wanted to share a new Hugging Face + PyTorch + [Ray](https://github.com/ray-project/ray) integration for Retrieval Augmented Generation (RAG).\n\nSome feature highlights include:\n\n* Speeding up retrieval calls by 2x\n* Improving the scalability RAG distributed [fine tuning](https://github.com/huggingface/transformers/tree/master/examples/research_projects/rag)\n\nThere\u2019s [a blog post](https://medium.com/distributed-computing-with-ray/retrieval-augmented-generation-with-huggingface-transformers-and-ray-b09b56161b1e)\u00a0with code snippets  if you want to learn more!\n\nLinks:\n\n* [Repository](https://github.com/ray-project/ray)\n* [RAG Ray Integration](https://github.com/huggingface/transformers/blob/master/examples/research_projects/rag/finetune_rag_ray.sh)\n\nLet me know if you have any thoughts or questions!", "link": "https://www.reddit.com/r/MachineLearning/comments/lh29a0/p_retrieval_augmented_generation_with_huggingface/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] retrieval augmented generation with huggingface transformers, pytorch, and ray /!/ hey everyone,\n\ni wanted to share a new hugging face + pytorch + [ray](https://github.com/ray-project/ray) integration for retrieval augmented generation (rag).\n\nsome feature highlights include:\n\n* speeding up retrieval calls by 2x\n* improving the scalability rag distributed [fine tuning](https://github.com/huggingface/transformers/-----> tree !!! /master/examples/research_projects/rag)\n\nthere\u2019s [a blog post](https://medium.com/distributed-computing-with-ray/retrieval-augmented-generation-with-huggingface-transformers-and-ray-b09b56161b1e)\u00a0with code snippets  if you want to learn more!\n\nlinks:\n\n* [repository](https://github.com/ray-project/ray)\n* [rag ray integration](https://github.com/huggingface/transformers/blob/master/examples/research_projects/rag/finetune_rag_ray.sh)\n\nlet me know if you have any thoughts or questions!", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 9, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lh29a0/p_retrieval_augmented_generation_with_huggingface/',)", "identifyer": 5728213, "year": "2021"}, {"autor": "ramhemanth3", "date": 1612977636000, "content": "what do you think are some cons or disadvantages of using a Decision tree Algorithm [D] /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/lgyjyr/what_do_you_think_are_some_cons_or_disadvantages/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "what do you think are some cons or disadvantages of using a decision -----> tree !!!  algorithm [d] /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lgyjyr/what_do_you_think_are_some_cons_or_disadvantages/',)", "identifyer": 5728223, "year": "2021"}, {"autor": "ramhemanth3", "date": 1612976485000, "content": "what do you think are some cons or disadvantages of using Decision tree Algorithm /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/lgy3ka/what_do_you_think_are_some_cons_or_disadvantages/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "what do you think are some cons or disadvantages of using decision -----> tree !!!  algorithm /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lgy3ka/what_do_you_think_are_some_cons_or_disadvantages/',)", "identifyer": 5728224, "year": "2021"}, {"autor": "willspcaccount", "date": 1612962739000, "content": "[D] What machine learning algorithm should I use for comparing governments? /!/ Hello to this subreddit. I've never worked with data science or much programming; though I have a friend who could help me with the technical side of things, essentially, I have no knowledge on the topic. \n\nI am doing a research project for school and aim to compare different governing systems. For my methodology, I was thinking of using machine learning. Initially, I was going to use a random forest, but my friend said I might just need a decision tree. I was wondering what the best course of action would be for me. \n\nI want to compare traits like CPI, GDP, # of Nobel Prize laureates, political freedom, etc. For some traits high values would be good; for others, low values would be good. Then I would analyze and say that a country with attributes of s, w, r, t, x, and z (random variables) has the best probability of success.\n\n&amp;#x200B;\n\nThoughts?", "link": "https://www.reddit.com/r/MachineLearning/comments/lgtccc/d_what_machine_learning_algorithm_should_i_use/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] what machine learning algorithm should i use for comparing governments? /!/ hello to this subreddit. i've never worked with data science or much programming; though i have a friend who could help me with the technical side of things, essentially, i have no knowledge on the topic. \n\ni am doing a research project for school and aim to compare different governing systems. for my methodology, i was thinking of using machine learning. initially, i was going to use a random forest, but my friend said i might just need a decision -----> tree !!! . i was wondering what the best course of action would be for me. \n\ni want to compare traits like cpi, gdp, # of nobel prize laureates, political freedom, etc. for some traits high values would be good; for others, low values would be good. then i would analyze and say that a country with attributes of s, w, r, t, x, and z (random variables) has the best probability of success.\n\n&amp;#x200b;\n\nthoughts?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 25, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lgtccc/d_what_machine_learning_algorithm_should_i_use/',)", "identifyer": 5728247, "year": "2021"}, {"autor": "savoga", "date": 1612810992000, "content": "[D] the more features we have, the more accurate is a decision tree (always)? /!/ Ignoring the overfitting issue and having a fixed tree depth, does the accuracy of a decision tree always increase if we add a new feature?\n\nI tend to think the answer is yes because the algorithm recursively looks for the best feature and threshold looping on all possibilities. However I've seen some counter-intuitive behaviors when changing the features.", "link": "https://www.reddit.com/r/MachineLearning/comments/lfj0r5/d_the_more_features_we_have_the_more_accurate_is/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] the more features we have, the more accurate is a decision -----> tree !!!  (always)? /!/ ignoring the overfitting issue and having a fixed tree depth, does the accuracy of a decision tree always increase if we add a new feature?\n\ni tend to think the answer is yes because the algorithm recursively looks for the best feature and threshold looping on all possibilities. however i've seen some counter-intuitive behaviors when changing the features.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 33, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lfj0r5/d_the_more_features_we_have_the_more_accurate_is/',)", "identifyer": 5728274, "year": "2021"}, {"autor": "caraenderson", "date": 1620473798000, "content": "[Discussion] Embedded feature selection /!/ If I make Cart algorithm (decision tree) can I just simply specified to use maximum of 6 features (total 10 features), is this considered embedded feature selection?\n\nCan someone explain, I not understand the concept of embedded ft.", "link": "https://www.reddit.com/r/MachineLearning/comments/n7ndxe/discussion_embedded_feature_selection/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[discussion] embedded feature selection /!/ if i make cart algorithm (decision -----> tree !!! ) can i just simply specified to use maximum of 6 features (total 10 features), is this considered embedded feature selection?\n\ncan someone explain, i not understand the concept of embedded ft.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n7ndxe/discussion_embedded_feature_selection/',)", "identifyer": 5728540, "year": "2021"}, {"autor": "SQL_beginner", "date": 1632686198000, "content": "[D] Decision Trees based on Evolutionary Algorithms /!/ Recently I came across some links in which it's claimed that in certain cases, the performance of the standard CART Decision Tree might be improved by using Evolutionary Algorithms (e.g. the Genetic Algorithm).\n\n- https://www.jstatsoft.org/article/view/v061i01 (R package)\n- https://towardsdatascience.com/evolutionary-decision-trees-when-machine-learning-draws-its-inspiration-from-biology-7d427fa7554b\n\nThe argument being, that standard decision trees only consider a very small search space of the data, and it is quite likely that standard decision trees will produce \"sub-optimal\" decision trees. On the other hand, decision trees that are created using  evolutionary algorithms can search over a far greater space, and thus have the potential to produce better decision trees (e.g. greater predictive power).\n\nHas anyone ever used decision trees based on evolutionary algorithms before? How has your experience been? Did you find that there were any improvements when compared to the standard decision tree?\n\nThanks!", "link": "https://www.reddit.com/r/MachineLearning/comments/pw12pl/d_decision_trees_based_on_evolutionary_algorithms/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] decision trees based on evolutionary algorithms /!/ recently i came across some links in which it's claimed that in certain cases, the performance of the standard cart decision -----> tree !!!  might be improved by using evolutionary algorithms (e.g. the genetic algorithm).\n\n- https://www.jstatsoft.org/article/view/v061i01 (r package)\n- https://towardsdatascience.com/evolutionary-decision-trees-when-machine-learning-draws-its-inspiration-from-biology-7d427fa7554b\n\nthe argument being, that standard decision trees only consider a very small search space of the data, and it is quite likely that standard decision trees will produce \"sub-optimal\" decision trees. on the other hand, decision trees that are created using  evolutionary algorithms can search over a far greater space, and thus have the potential to produce better decision trees (e.g. greater predictive power).\n\nhas anyone ever used decision trees based on evolutionary algorithms before? how has your experience been? did you find that there were any improvements when compared to the standard decision tree?\n\nthanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pw12pl/d_decision_trees_based_on_evolutionary_algorithms/',)", "identifyer": 5728671, "year": "2021"}, {"autor": "ClassicDad-", "date": 1613602180000, "content": "[P] Question about generating stories /!/ I posted this over in /r/learnmachinelearning and /r/MLQuestions with no luck, so hopefully this is allowed here!\n\nI am doing a research project with the goal of generating a choose your own adventure-style story on the fly. I'm sure many of you are familiar with AI Dungeon. I'm using that as inspiration, but rather than creating the text of the story, I want to focus more on the structure. Basically I compile a lot of \"events\" from existing stories, and I need to find a way to build a sort of tree-like structure from them. for the player to traverse.\n\nFor example, consider a player that is in the middle of the story and has the choice between fighting a group of zombies or a group of vampires. If they choose to fight the zombies, the next event that should be presented should be related to zombies as well, and they will be given more choices for where to go from there.\n\nI was hoping for some resources or tips on what machine learning concepts would be most useful here. My ideas have included basically making each stage of the story act as a mini recommender system, and using decision trees.\n\nAny help would be greatly appreciated!", "link": "https://www.reddit.com/r/MachineLearning/comments/lm6zi6/p_question_about_generating_stories/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] question about generating stories /!/ i posted this over in /r/learnmachinelearning and /r/mlquestions with no luck, so hopefully this is allowed here!\n\ni am doing a research project with the goal of generating a choose your own adventure-style story on the fly. i'm sure many of you are familiar with ai dungeon. i'm using that as inspiration, but rather than creating the text of the story, i want to focus more on the structure. basically i compile a lot of \"events\" from existing stories, and i need to find a way to build a sort of -----> tree !!! -like structure from them. for the player to traverse.\n\nfor example, consider a player that is in the middle of the story and has the choice between fighting a group of zombies or a group of vampires. if they choose to fight the zombies, the next event that should be presented should be related to zombies as well, and they will be given more choices for where to go from there.\n\ni was hoping for some resources or tips on what machine learning concepts would be most useful here. my ideas have included basically making each stage of the story act as a mini recommender system, and using decision trees.\n\nany help would be greatly appreciated!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lm6zi6/p_question_about_generating_stories/',)", "identifyer": 5728827, "year": "2021"}, {"autor": "antonio_zeus", "date": 1614112965000, "content": "[D] Adding a fake feature (transformed based on label) to challenge decision tree model. /!/ Hello ML\n\nI have a theoretical question about using the label of a data set, applying a bunch of transformations to this data, and then adding it in as one of the features into a decision tree.\n\nImagine the labels are binary classification (0, 1), and I apply transformations including sin, cos, tanh (at various n steps) to completely disguise the data. This \"new feature\" goes from 0s and 1s, to all sorts of negative and positive continuous values. Correlation (if this matters) goes from 1 to 0.12.\n\nHow come including this \"new feature\" in a decision tree model builds a perfect tree with perfect CV score and confusion matrix? \n\nIs this because I've introduced data leakage, and regardless of what transforms take place, the DT model will find the perfect split and sort of reverse engineer my transforms?\n\nI am perplexed by this and would appreciate some theoretical knowledge as to why this may be the case. My first thoughts are that these models are super efficient at finding the predictable feature (especially knowing I created it out of the label!)", "link": "https://www.reddit.com/r/MachineLearning/comments/lqsi83/d_adding_a_fake_feature_transformed_based_on/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] adding a fake feature (transformed based on label) to challenge decision -----> tree !!!  model. /!/ hello ml\n\ni have a theoretical question about using the label of a data set, applying a bunch of transformations to this data, and then adding it in as one of the features into a decision tree.\n\nimagine the labels are binary classification (0, 1), and i apply transformations including sin, cos, tanh (at various n steps) to completely disguise the data. this \"new feature\" goes from 0s and 1s, to all sorts of negative and positive continuous values. correlation (if this matters) goes from 1 to 0.12.\n\nhow come including this \"new feature\" in a decision tree model builds a perfect tree with perfect cv score and confusion matrix? \n\nis this because i've introduced data leakage, and regardless of what transforms take place, the dt model will find the perfect split and sort of reverse engineer my transforms?\n\ni am perplexed by this and would appreciate some theoretical knowledge as to why this may be the case. my first thoughts are that these models are super efficient at finding the predictable feature (especially knowing i created it out of the label!)", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lqsi83/d_adding_a_fake_feature_transformed_based_on/',)", "identifyer": 5729037, "year": "2021"}, {"autor": "SrPinko", "date": 1614101180000, "content": "[D] Is there any alternative to DL to multivariate time series forecasting? /!/ I am researching the use of Deep Learning models to forecast multivariate time series, and I want to comparate my results with some basics Machine Learning models like a tree or random forest regressors. \n\nI can't use Scikit-learn models because it doesn't accept 3-dimensional data, so I am searching for another way to do it. Some people recommended me to use Weka, but I think that I'll have a similar problem with the dimensions of the data.\n\nSo, what framework, library or tool do you recommend to me?", "link": "https://www.reddit.com/r/MachineLearning/comments/lqnu16/d_is_there_any_alternative_to_dl_to_multivariate/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] is there any alternative to dl to multivariate time series forecasting? /!/ i am researching the use of deep learning models to forecast multivariate time series, and i want to comparate my results with some basics machine learning models like a -----> tree !!!  or random forest regressors. \n\ni can't use scikit-learn models because it doesn't accept 3-dimensional data, so i am searching for another way to do it. some people recommended me to use weka, but i think that i'll have a similar problem with the dimensions of the data.\n\nso, what framework, library or tool do you recommend to me?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 14, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lqnu16/d_is_there_any_alternative_to_dl_to_multivariate/',)", "identifyer": 5729049, "year": "2021"}, {"autor": "beaconofwierd", "date": 1615462528000, "content": "[D] Predicting the middle of a time series to make a strategy towards a goal. /!/ I've been thinking for quite a while about how to use predictive models to formulate a strategy to achieve a certain goal. Much of my thinking has been focused around using predictive models to evaluate a state, much like AlphaGo and similar AI's work. Though these methods are not particularly applicable in settings with a very large search space, such as real time strategy games or real world applications. From my understanding most of the efforts in that area is focused on reinforcement learning. Last night I had an \"epiphany\", There's only one difference between a model predicting the future and a model formulating a strategy, what part of the training data is masked off.\n\nLet me explain what I mean by that. A \"regular\" predictive model is asked to predict future events based on previous events. During training the future is then masked. If we simply move the mask to the middle of the time series we are now asking it to predict what connects the past to the future. That's the same thing as formulating a strategy from one point to another.\n\nExcited about my epiphany I tried to search the internet for more information about this, but I am unable to find much. I'm sure someone has tried  this and I simply don't know the correct terms to search for. All I'm getting are the classic Monte Carlo tree searches using NN to evaluate the states or reinforcement learning. So I'm reaching out here to see if any of you guys have heard about this or know where to find more information.\n\n&amp;#x200B;\n\nI'd also like to discuss the idea a bit with someone to see if my thinking on the subject is flawed. I imagine this system being used in two ways, either simply training the system on vast amounts of data, like GPT, and then specifying your own goal and have it come up with a strategy for you. Or use it similarly to reinforcement learning. The agent is put into a new environment and will output random actions (since it knows nothing about it's environment it has nothing else to do). The agent records everything that's happening and uses this as training data. The agent will then learn to connect future events (such as being to the right of where it was previously) to certain actions (in this case moving right). Over time the agent should learn more and more about its environment.\n\nThings I'm very unsure about is what would happen if you give it an impossible goal, would the system try to reach the goal or conclude that no action can possibly lead to the goal, thus every action is equally valid. In the reinforcement setting I'm interested in ways to learn the environment in a smarter way than simply doing random things, such as using some sort of \"curiosity\" to determine which actions would gain the most amount of new information to the system.\n\nI'd be very interesting in hearing your thoughts about such a system, do you think it would work and be useful or do you think it's simply a primitive reinforcement learning method?", "link": "https://www.reddit.com/r/MachineLearning/comments/m2o75d/d_predicting_the_middle_of_a_time_series_to_make/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] predicting the middle of a time series to make a strategy towards a goal. /!/ i've been thinking for quite a while about how to use predictive models to formulate a strategy to achieve a certain goal. much of my thinking has been focused around using predictive models to evaluate a state, much like alphago and similar ai's work. though these methods are not particularly applicable in settings with a very large search space, such as real time strategy games or real world applications. from my understanding most of the efforts in that area is focused on reinforcement learning. last night i had an \"epiphany\", there's only one difference between a model predicting the future and a model formulating a strategy, what part of the training data is masked off.\n\nlet me explain what i mean by that. a \"regular\" predictive model is asked to predict future events based on previous events. during training the future is then masked. if we simply move the mask to the middle of the time series we are now asking it to predict what connects the past to the future. that's the same thing as formulating a strategy from one point to another.\n\nexcited about my epiphany i tried to search the internet for more information about this, but i am unable to find much. i'm sure someone has tried  this and i simply don't know the correct terms to search for. all i'm getting are the classic monte carlo -----> tree !!!  searches using nn to evaluate the states or reinforcement learning. so i'm reaching out here to see if any of you guys have heard about this or know where to find more information.\n\n&amp;#x200b;\n\ni'd also like to discuss the idea a bit with someone to see if my thinking on the subject is flawed. i imagine this system being used in two ways, either simply training the system on vast amounts of data, like gpt, and then specifying your own goal and have it come up with a strategy for you. or use it similarly to reinforcement learning. the agent is put into a new environment and will output random actions (since it knows nothing about it's environment it has nothing else to do). the agent records everything that's happening and uses this as training data. the agent will then learn to connect future events (such as being to the right of where it was previously) to certain actions (in this case moving right). over time the agent should learn more and more about its environment.\n\nthings i'm very unsure about is what would happen if you give it an impossible goal, would the system try to reach the goal or conclude that no action can possibly lead to the goal, thus every action is equally valid. in the reinforcement setting i'm interested in ways to learn the environment in a smarter way than simply doing random things, such as using some sort of \"curiosity\" to determine which actions would gain the most amount of new information to the system.\n\ni'd be very interesting in hearing your thoughts about such a system, do you think it would work and be useful or do you think it's simply a primitive reinforcement learning method?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 12, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/m2o75d/d_predicting_the_middle_of_a_time_series_to_make/',)", "identifyer": 5729234, "year": "2021"}, {"autor": "CanadianTuero", "date": 1617011308000, "content": "[P] Differentiable Optimizers with Perturbations in PyTorch /!/ After reading [this](https://www.reddit.com/r/MachineLearning/comments/mcdoxs/p_torchsort_fast_differentiable_sorting_and/) post the other day, I learned about using perturbations to create differentiable optimizers ([https://arxiv.org/abs/2002.08676](https://arxiv.org/abs/2002.08676)). There is an official implementation [here](https://github.com/google-research/google-research/tree/master/perturbations), but it is for Tensorflow. \n\nSince I primarily use PyTorch, and these tools are something which I want to play around with for my own research, I have reimplemented it using native PyTorch. Figured I would share here in case others find it useful as well!\n\n[https://github.com/tuero/perturbations-differential-pytorch](https://github.com/tuero/perturbations-differential-pytorch)", "link": "https://www.reddit.com/r/MachineLearning/comments/mflxcf/p_differentiable_optimizers_with_perturbations_in/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] differentiable optimizers with perturbations in pytorch /!/ after reading [this](https://www.reddit.com/r/machinelearning/comments/mcdoxs/p_torchsort_fast_differentiable_sorting_and/) post the other day, i learned about using perturbations to create differentiable optimizers ([https://arxiv.org/abs/2002.08676](https://arxiv.org/abs/2002.08676)). there is an official implementation [here](https://github.com/google-research/google-research/-----> tree !!! /master/perturbations), but it is for tensorflow. \n\nsince i primarily use pytorch, and these tools are something which i want to play around with for my own research, i have reimplemented it using native pytorch. figured i would share here in case others find it useful as well!\n\n[https://github.com/tuero/perturbations-differential-pytorch](https://github.com/tuero/perturbations-differential-pytorch)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mflxcf/p_differentiable_optimizers_with_perturbations_in/',)", "identifyer": 5729390, "year": "2021"}, {"autor": "brianc96", "date": 1616964574000, "content": "[P] Predict size of dog /!/ Hello! I have a task which is to measure the size of a dog (length, height, girth) and the information I will have for each dog is:\n\n\\- Race\n\n\\- Weight\n\n\\- Age (date of birth)\n\n\\- Gender and\n\n\\- Frontal and lateral picture\n\nDo you know any way to conduct this prediction with machine learning? Also, I've tried coding a decision tree to predict the size with scientific data, but I couldn't yet find a dataset.", "link": "https://www.reddit.com/r/MachineLearning/comments/mf9mkt/p_predict_size_of_dog/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] predict size of dog /!/ hello! i have a task which is to measure the size of a dog (length, height, girth) and the information i will have for each dog is:\n\n\\- race\n\n\\- weight\n\n\\- age (date of birth)\n\n\\- gender and\n\n\\- frontal and lateral picture\n\ndo you know any way to conduct this prediction with machine learning? also, i've tried coding a decision -----> tree !!!  to predict the size with scientific data, but i couldn't yet find a dataset.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mf9mkt/p_predict_size_of_dog/',)", "identifyer": 5729426, "year": "2021"}, {"autor": "brianc96", "date": 1616964285000, "content": "[D] Predict size of dog /!/ Hello! I have a task which is to measure the size of a dog (length, height, girth) and the information I will have for each dog is:\n\n\\- Race\n\n\\- Weight\n\n\\- Age (date of birth)\n\n\\- Gender and\n\n\\- Frontal and lateral picture\n\nDo you know any way to conduct this prediction with machine learning? Also, I've tried coding a decision tree to predict the size with scientific data, but I couldn't yet find a dataset.", "link": "https://www.reddit.com/r/MachineLearning/comments/mf9j5a/d_predict_size_of_dog/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] predict size of dog /!/ hello! i have a task which is to measure the size of a dog (length, height, girth) and the information i will have for each dog is:\n\n\\- race\n\n\\- weight\n\n\\- age (date of birth)\n\n\\- gender and\n\n\\- frontal and lateral picture\n\ndo you know any way to conduct this prediction with machine learning? also, i've tried coding a decision -----> tree !!!  to predict the size with scientific data, but i couldn't yet find a dataset.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mf9j5a/d_predict_size_of_dog/',)", "identifyer": 5729427, "year": "2021"}, {"autor": "fanboy-1985", "date": 1609602474000, "content": "[D] During an interview for NLP Researcher, was asked a basic linear regression question, and failed. Who's miss is it? /!/ TLDR: As an experienced NLP researcher, answered very well on questions regarding embeddings, transformers, lstm etc, but failed on variables correlation in linear regression question. Is it the company miss, or is it mine, and I should run and learn linear regression?? \n\n&amp;#x200B;\n\nA little background, I am quite an experienced NPL Researcher and Developer. Currently, I hold quite a good and interesting job in the field. \n\nWas approached by some big company for NLP Researcher position and gave it a try. \n\nDuring the interview was asked about Deep Learning stuff and general nlp stuff which I answered very well (feedback I got from them). But then got this question: \n\nIf I train linear regression and I have a high correlation between some variables, will the algorithm converge? \n\nNow, I didn't know for sure, as someone who works on NLP, I rarely use linear (or logistic) regression and even if I do, I use some high dimensional text representation so it's not really possible to track correlations between variables. So, no, I don't know for sure, never experienced this. If my algorithm doesn't converge, I use another one or try to improve my representation. \n\nSo my question is, who's miss is it? did they miss me (an experienced NLP researcher)? \n\nOr, Is it my miss that I wasn't ready enough for the interview and I should run and improve my basic knowledge of basic things? \n\nIt has to be said, they could also ask some basic stuff regarding tree-based models or SVM, and  I probably could be wrong, so should I know EVERYTHING? \n\n&amp;#x200B;\n\nThanks.", "link": "https://www.reddit.com/r/MachineLearning/comments/kozn25/d_during_an_interview_for_nlp_researcher_was/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] during an interview for nlp researcher, was asked a basic linear regression question, and failed. who's miss is it? /!/ tldr: as an experienced nlp researcher, answered very well on questions regarding embeddings, transformers, lstm etc, but failed on variables correlation in linear regression question. is it the company miss, or is it mine, and i should run and learn linear regression?? \n\n&amp;#x200b;\n\na little background, i am quite an experienced npl researcher and developer. currently, i hold quite a good and interesting job in the field. \n\nwas approached by some big company for nlp researcher position and gave it a try. \n\nduring the interview was asked about deep learning stuff and general nlp stuff which i answered very well (feedback i got from them). but then got this question: \n\nif i train linear regression and i have a high correlation between some variables, will the algorithm converge? \n\nnow, i didn't know for sure, as someone who works on nlp, i rarely use linear (or logistic) regression and even if i do, i use some high dimensional text representation so it's not really possible to track correlations between variables. so, no, i don't know for sure, never experienced this. if my algorithm doesn't converge, i use another one or try to improve my representation. \n\nso my question is, who's miss is it? did they miss me (an experienced nlp researcher)? \n\nor, is it my miss that i wasn't ready enough for the interview and i should run and improve my basic knowledge of basic things? \n\nit has to be said, they could also ask some basic stuff regarding -----> tree !!! -based models or svm, and  i probably could be wrong, so should i know everything? \n\n&amp;#x200b;\n\nthanks.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 290, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/kozn25/d_during_an_interview_for_nlp_researcher_was/',)", "identifyer": 5729546, "year": "2021"}, {"autor": "pp314159", "date": 1609849987000, "content": "[P] MLJAR Automated Machine Learning for Tabular Data (Golden Features, Explanations, and AutoDoc) /!/ I'm working on AutoML since 2016. I think that the latest release (0.7.15) of MLJAR AutoML is amazing. It has a ton of fantastic features that I always want to have in AutoML:\n\n- Operates in three modes: Explain, Perform, Compete.\n\n- `Explain` is for data exploratory and checking the default performance (without HP tuning). It has Automatic Exploratory Data Analysis.\n\n- `Perform` is for building production-ready models (HP tuning + ensembling).\n\n- `Compete` is for solving ML competitions in limited time amount (HP tuning + ensembling + stacking).\n\n- All ML experiments have automatic documentation that creates Markdown reports ready to commit to the repo ([example1](https://github.com/mljar/mljar-examples/blob/master/media/decision_tree_summary.gif), [example2](https://github.com/mljar/mljar-examples/tree/master/Income_classification/AutoML_1#automl-leaderboard)).\n\n- The package produces extensive explanations: decision tree visualization, feature importance, SHAP explanations, advanced metrics values.\n\n- It has advanced feature engineering, like Golden Features, Features Selection, Time and Text Transformations, Categoricals handling with the target, label, or one-hot encodings.\n\nLink to the source code: https://github.com/mljar/mljar-supervised (MIT License)", "link": "https://www.reddit.com/r/MachineLearning/comments/kqxmmf/p_mljar_automated_machine_learning_for_tabular/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] mljar automated machine learning for tabular data (golden features, explanations, and autodoc) /!/ i'm working on automl since 2016. i think that the latest release (0.7.15) of mljar automl is amazing. it has a ton of fantastic features that i always want to have in automl:\n\n- operates in three modes: explain, perform, compete.\n\n- `explain` is for data exploratory and checking the default performance (without hp tuning). it has automatic exploratory data analysis.\n\n- `perform` is for building production-ready models (hp tuning + ensembling).\n\n- `compete` is for solving ml competitions in limited time amount (hp tuning + ensembling + stacking).\n\n- all ml experiments have automatic documentation that creates markdown reports ready to commit to the repo ([example1](https://github.com/mljar/mljar-examples/blob/master/media/decision_tree_summary.gif), [example2](https://github.com/mljar/mljar-examples/-----> tree !!! /master/income_classification/automl_1#automl-leaderboard)).\n\n- the package produces extensive explanations: decision tree visualization, feature importance, shap explanations, advanced metrics values.\n\n- it has advanced feature engineering, like golden features, features selection, time and text transformations, categoricals handling with the target, label, or one-hot encodings.\n\nlink to the source code: https://github.com/mljar/mljar-supervised (mit license)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/kqxmmf/p_mljar_automated_machine_learning_for_tabular/',)", "identifyer": 5729658, "year": "2021"}, {"autor": "timscarfe", "date": 1617499307000, "content": "[D] Christian Szegedy - Formal Reasoning, Program Synthesis [Video Show] /!/ [https://youtu.be/ehNGGYFO6ms](https://youtu.be/ehNGGYFO6ms) \n\nDr. Christian Szegedy from Google Research is a deep learning heavyweight. He invented adversarial examples, one of the first object detection algorithms, the inceptionnet architecture, and co-invented batchnorm. He thinks that if you bet on computers and software in 1990 you would have been as right as if you bet on AI now. But he thinks that we have been programming computers the same way since the 1950s and there has been a huge stagnation ever since. Mathematics is the process of taking a fuzzy thought and formalising it. But could we automate that? Could we create a system which will act like a super human mathematician but you can talk to it in natural language? This is what Christian calls autoformalisation. Christian thinks that automating many of the things we do in mathematics is the first step towards software synthesis and building human-level AGI. Mathematics ability is the litmus test for general reasoning ability. Christian has a fascinating take on transformers too.  \n\nTouching on;\n\nA Promising Path Towards Autoformalization and General Artificial Intelligence \\[Szegedy\\]\n\n[https://link.springer.com/chapter/10.1007/978-3-030-53518-6\\_1](https://link.springer.com/chapter/10.1007/978-3-030-53518-6_1)\n\nLearning to Reason in Large Theories without Imitation \\[Bansal/Szegedy\\]\n\n[https://arxiv.org/pdf/1905.10501.pdf](https://arxiv.org/pdf/1905.10501.pdf)\n\nMATHEMATICAL REASONING VIA SELF-SUPERVISED SKIP-TREE TRAINING \\[Rabe .. Szegedy\\]\n\n[https://openreview.net/pdf?id=YmqAnY0CMEy](https://openreview.net/pdf?id=YmqAnY0CMEy)\n\nLIME: LEARNING INDUCTIVE BIAS FOR PRIMITIVES OF MATHEMATICAL REASONING \\[Wu..Szegedy\\]\n\n[https://arxiv.org/abs/2101.06223v1](https://arxiv.org/abs/2101.06223v1)\n\nDEEP LEARNING FOR SYMBOLIC MATHEMATICS \\[Lample\\]\n\n[https://arxiv.org/pdf/1912.01412.pdf](https://arxiv.org/pdf/1912.01412.pdf)\n\nIt\u2019s Not What Machines Can Learn, It\u2019s What We Cannot Teach \\[Yehuda\\]\n\n[https://arxiv.org/pdf/2002.09398.pdf](https://arxiv.org/pdf/2002.09398.pdf)\n\nInvestigating the Limitations of Transformers with Simple Arithmetic Tasks \\[Nogueira\\]\n\n[https://arxiv.org/pdf/2102.13019.pdf](https://arxiv.org/pdf/2102.13019.pdf)\n\nProvable Bounds for Learning Some Deep Representations \\[Arora\\]\n\n[https://arxiv.org/pdf/1310.6343.pdf](https://arxiv.org/pdf/1310.6343.pdf)\n\nNeural nets learn to program neural nets with fast weights \\[Schmidhuber\\]\n\n[https://people.idsia.ch/\\~juergen/fast-weight-programmer-1991-transformer.html](https://people.idsia.ch/~juergen/fast-weight-programmer-1991-transformer.html)\n\nHow does Batch Normalization Help Optimization? \\[Ilyas\\]\n\n[https://gradientscience.org/batchnorm/](https://gradientscience.org/batchnorm/)\n\nHow to Train Your ResNet 7: Batch Norm\n\n[https://myrtle.ai/learn/how-to-train-your-resnet-7-batch-norm/](https://myrtle.ai/learn/how-to-train-your-resnet-7-batch-norm/)\n\nTraining a ResNet to 94% Accuracy on CIFAR-10 in 26 Seconds on a Single GPU \u2013 \\[KUHN\\]\n\n[https://efficientdl.com/how-to-train-a-resnet-efficiently/#7-batch-norm-does-reducs-internal-covariate-shift](https://efficientdl.com/how-to-train-a-resnet-efficiently/#7-batch-norm-does-reducs-internal-covariate-shift)", "link": "https://www.reddit.com/r/MachineLearning/comments/mjlyfc/d_christian_szegedy_formal_reasoning_program/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] christian szegedy - formal reasoning, program synthesis [video show] /!/ [https://youtu.be/ehnggyfo6ms](https://youtu.be/ehnggyfo6ms) \n\ndr. christian szegedy from google research is a deep learning heavyweight. he invented adversarial examples, one of the first object detection algorithms, the inceptionnet architecture, and co-invented batchnorm. he thinks that if you bet on computers and software in 1990 you would have been as right as if you bet on ai now. but he thinks that we have been programming computers the same way since the 1950s and there has been a huge stagnation ever since. mathematics is the process of taking a fuzzy thought and formalising it. but could we automate that? could we create a system which will act like a super human mathematician but you can talk to it in natural language? this is what christian calls autoformalisation. christian thinks that automating many of the things we do in mathematics is the first step towards software synthesis and building human-level agi. mathematics ability is the litmus test for general reasoning ability. christian has a fascinating take on transformers too.  \n\ntouching on;\n\na promising path towards autoformalization and general artificial intelligence \\[szegedy\\]\n\n[https://link.springer.com/chapter/10.1007/978-3-030-53518-6\\_1](https://link.springer.com/chapter/10.1007/978-3-030-53518-6_1)\n\nlearning to reason in large theories without imitation \\[bansal/szegedy\\]\n\n[https://arxiv.org/pdf/1905.10501.pdf](https://arxiv.org/pdf/1905.10501.pdf)\n\nmathematical reasoning via self-supervised skip------> tree !!!  training \\[rabe .. szegedy\\]\n\n[https://openreview.net/pdf?id=ymqany0cmey](https://openreview.net/pdf?id=ymqany0cmey)\n\nlime: learning inductive bias for primitives of mathematical reasoning \\[wu..szegedy\\]\n\n[https://arxiv.org/abs/2101.06223v1](https://arxiv.org/abs/2101.06223v1)\n\ndeep learning for symbolic mathematics \\[lample\\]\n\n[https://arxiv.org/pdf/1912.01412.pdf](https://arxiv.org/pdf/1912.01412.pdf)\n\nit\u2019s not what machines can learn, it\u2019s what we cannot teach \\[yehuda\\]\n\n[https://arxiv.org/pdf/2002.09398.pdf](https://arxiv.org/pdf/2002.09398.pdf)\n\ninvestigating the limitations of transformers with simple arithmetic tasks \\[nogueira\\]\n\n[https://arxiv.org/pdf/2102.13019.pdf](https://arxiv.org/pdf/2102.13019.pdf)\n\nprovable bounds for learning some deep representations \\[arora\\]\n\n[https://arxiv.org/pdf/1310.6343.pdf](https://arxiv.org/pdf/1310.6343.pdf)\n\nneural nets learn to program neural nets with fast weights \\[schmidhuber\\]\n\n[https://people.idsia.ch/\\~juergen/fast-weight-programmer-1991-transformer.html](https://people.idsia.ch/~juergen/fast-weight-programmer-1991-transformer.html)\n\nhow does batch normalization help optimization? \\[ilyas\\]\n\n[https://gradientscience.org/batchnorm/](https://gradientscience.org/batchnorm/)\n\nhow to train your resnet 7: batch norm\n\n[https://myrtle.ai/learn/how-to-train-your-resnet-7-batch-norm/](https://myrtle.ai/learn/how-to-train-your-resnet-7-batch-norm/)\n\ntraining a resnet to 94% accuracy on cifar-10 in 26 seconds on a single gpu \u2013 \\[kuhn\\]\n\n[https://efficientdl.com/how-to-train-a-resnet-efficiently/#7-batch-norm-does-reducs-internal-covariate-shift](https://efficientdl.com/how-to-train-a-resnet-efficiently/#7-batch-norm-does-reducs-internal-covariate-shift)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 8, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mjlyfc/d_christian_szegedy_formal_reasoning_program/',)", "identifyer": 5729744, "year": "2021"}, {"autor": "-dylansmith", "date": 1617738184000, "content": "[P] My Robotic Self-Controlling Chess AI that Plays Live Chess /!/ Link: [https://www.youtube.com/watch?v=1-ZNOj98ou4&amp;ab\\_channel=DylanSmith](https://www.youtube.com/watch?v=1-ZNOj98ou4&amp;ab_channel=DylanSmith)\n\nDisclaimer: This was never used against real people, only other AI's that don't have any feelings.\n\nSo I got a little carried away with chess a little while ago. Initial interest of building my own chess engine somehow resulted me a deeplearning chess AI that robotically controls itself in live games of online chess. I know - I don't know how it happened either.\n\n&amp;#x200B;\n\n[Computer's Vision](https://preview.redd.it/6n7wmofmulr61.png?width=300&amp;format=png&amp;auto=webp&amp;s=a66e3157a9ac0c64e2a926eec9209b9ca80f52c7)\n\nThe model was trained to learn a value function for board state inputs using a binary representation of the board and its pieces. Training was done in PyTorch using Google Colab GPU's - which I highly recommend as an option for free access to GPU's for quick training.\n\nI wrote a recursive tree-search algorithm for testing all possible move paths to a specified depth - which can certainly be optimized. If you have any ideas for improving the algorithm speed from a tree-search I'd love to hear them!\n\nI used Canny and line detection for detecting the live chess board in a browser window ([chess.com](https://chess.com)), tracking a local board state whenever a move was made. Then the fun part - I used PyAutoGUI to map moves output from the model to screen coordinates which I used to automatically drag and drop pieces. Suddenly we had a robotic chess-playing machine.\n\nIt's incredible to sit back and watch it beat other AI's on it's own. \n\nI made a video about the project for fun, you can see how I made the AI and watch it work at the link - let me know what you think! ([https://www.youtube.com/watch?v=1-ZNOj98ou4&amp;ab\\_channel=DylanSmith](https://www.youtube.com/watch?v=1-ZNOj98ou4&amp;ab_channel=DylanSmith))\n\nHopefully you can learn something from the code: [https://github.com/e-dylan/chessai](https://github.com/e-dylan/chessai)", "link": "https://www.reddit.com/r/MachineLearning/comments/mljydv/p_my_robotic_selfcontrolling_chess_ai_that_plays/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] my robotic self-controlling chess ai that plays live chess /!/ link: [https://www.youtube.com/watch?v=1-znoj98ou4&amp;ab\\_channel=dylansmith](https://www.youtube.com/watch?v=1-znoj98ou4&amp;ab_channel=dylansmith)\n\ndisclaimer: this was never used against real people, only other ai's that don't have any feelings.\n\nso i got a little carried away with chess a little while ago. initial interest of building my own chess engine somehow resulted me a deeplearning chess ai that robotically controls itself in live games of online chess. i know - i don't know how it happened either.\n\n&amp;#x200b;\n\n[computer's vision](https://preview.redd.it/6n7wmofmulr61.png?width=300&amp;format=png&amp;auto=webp&amp;s=a66e3157a9ac0c64e2a926eec9209b9ca80f52c7)\n\nthe model was trained to learn a value function for board state inputs using a binary representation of the board and its pieces. training was done in pytorch using google colab gpu's - which i highly recommend as an option for free access to gpu's for quick training.\n\ni wrote a recursive -----> tree !!! -search algorithm for testing all possible move paths to a specified depth - which can certainly be optimized. if you have any ideas for improving the algorithm speed from a tree-search i'd love to hear them!\n\ni used canny and line detection for detecting the live chess board in a browser window ([chess.com](https://chess.com)), tracking a local board state whenever a move was made. then the fun part - i used pyautogui to map moves output from the model to screen coordinates which i used to automatically drag and drop pieces. suddenly we had a robotic chess-playing machine.\n\nit's incredible to sit back and watch it beat other ai's on it's own. \n\ni made a video about the project for fun, you can see how i made the ai and watch it work at the link - let me know what you think! ([https://www.youtube.com/watch?v=1-znoj98ou4&amp;ab\\_channel=dylansmith](https://www.youtube.com/watch?v=1-znoj98ou4&amp;ab_channel=dylansmith))\n\nhopefully you can learn something from the code: [https://github.com/e-dylan/chessai](https://github.com/e-dylan/chessai)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mljydv/p_my_robotic_selfcontrolling_chess_ai_that_plays/',)", "identifyer": 5729863, "year": "2021"}, {"autor": "opensourcecolumbus", "date": 1625366186000, "content": "[P] Open-source Neural Search framework to implement semantic search &amp; multimedia search. Just released 2.0, seeking your feedback. /!/ I heard your feedback on [1.0 release post](https://www.reddit.com/r/MachineLearning/comments/n0v5jy/project_framework_to_build_ai_powered_search_with/)  on my project [Jina](https://github.com/jina-ai/jina/), many people were keen to use Jina for multimedia search because that's where use of Neural Networks makes significant difference. So I focused on that part and I was able to transform it from 1.0 to 2.0 within 3 months.\n\n[Last post on 1.0 release to give you some idea what this project is about](https://preview.redd.it/wa9hmcg5y3971.png?width=726&amp;format=png&amp;auto=webp&amp;s=47eae65cedd81cec6be1350e04d9c22a2b34541d)\n\nActually, I should say - \"'we' made this\", because there were more than 155 contributors who did it, not just me. The primary changes we made\n\n* We saw MachineLearning beginners struggle in using Jina 1.0, so we separated the codebase where Machine Learning expertise is required([jina-hub](https://github.com/jina-ai/jina-hub)) and the one which MachineLearning beginners can use(the [jina](https://github.com/jina-ai/jina/) core). Now ML beginners don't need to worry about jina-hub and can use jina hub packages directly to implement ML specific tasks without the need to understand advanced ML concepts. While advanced ML users can create their own jina-hub packages.\n* We cut down a lots of abstractions to make it easy to use for beginners\n* Made python APIs more intuitive to use\n* Improved performance(3.6x faster on startup) \n\nHere's [Jina 2.0](https://github.com/jina-ai/jina/) and here's [Jina 1.0](https://github.com/jina-ai/jina/tree/v1.0.0).  I seek feedback from people who are looking at this project for the  first time, as well as people who have tried their hands before but had some challenges in using it. Few questions, I'm seeking answers to\n\n1. Do you feel that we have reduced complexity by a lot of margin?\n2. How easy it is to use for a beginner now?\n3. What questions are still unanswered?", "link": "https://www.reddit.com/r/MachineLearning/comments/odbl3o/p_opensource_neural_search_framework_to_implement/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] open-source neural search framework to implement semantic search &amp; multimedia search. just released 2.0, seeking your feedback. /!/ i heard your feedback on [1.0 release post](https://www.reddit.com/r/machinelearning/comments/n0v5jy/project_framework_to_build_ai_powered_search_with/)  on my project [jina](https://github.com/jina-ai/jina/), many people were keen to use jina for multimedia search because that's where use of neural networks makes significant difference. so i focused on that part and i was able to transform it from 1.0 to 2.0 within 3 months.\n\n[last post on 1.0 release to give you some idea what this project is about](https://preview.redd.it/wa9hmcg5y3971.png?width=726&amp;format=png&amp;auto=webp&amp;s=47eae65cedd81cec6be1350e04d9c22a2b34541d)\n\nactually, i should say - \"'we' made this\", because there were more than 155 contributors who did it, not just me. the primary changes we made\n\n* we saw machinelearning beginners struggle in using jina 1.0, so we separated the codebase where machine learning expertise is required([jina-hub](https://github.com/jina-ai/jina-hub)) and the one which machinelearning beginners can use(the [jina](https://github.com/jina-ai/jina/) core). now ml beginners don't need to worry about jina-hub and can use jina hub packages directly to implement ml specific tasks without the need to understand advanced ml concepts. while advanced ml users can create their own jina-hub packages.\n* we cut down a lots of abstractions to make it easy to use for beginners\n* made python apis more intuitive to use\n* improved performance(3.6x faster on startup) \n\nhere's [jina 2.0](https://github.com/jina-ai/jina/) and here's [jina 1.0](https://github.com/jina-ai/jina/-----> tree !!! /v1.0.0).  i seek feedback from people who are looking at this project for the  first time, as well as people who have tried their hands before but had some challenges in using it. few questions, i'm seeking answers to\n\n1. do you feel that we have reduced complexity by a lot of margin?\n2. how easy it is to use for a beginner now?\n3. what questions are still unanswered?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 9, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/odbl3o/p_opensource_neural_search_framework_to_implement/',)", "identifyer": 5729976, "year": "2021"}, {"autor": "xenotecc", "date": 1625319363000, "content": "[P] EfficientNet-lite in Keras (functional API). /!/ I created a repository with EfficientNet-lite model variants adapted to Keras:\n\n[Github Link](https://github.com/sebastian-sz/efficientnet-lite-keras)\n\nThe goal of the project was to mimic `keras.applications` behavior, as much as possible.\n\nThe lite model variants were previously available in Tensorflow 1.x, adopting them to Keras made them more consistent with existing API and documentation.\n\nAccording to [original repository](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite), the lite variants:\n\n* Use ReLU6 instead of Swish.\n* Do not use SE.\n* Have fixed Stem and Head while scaling the models.\n\nHope that this helps somebody!", "link": "https://www.reddit.com/r/MachineLearning/comments/ocy71x/p_efficientnetlite_in_keras_functional_api/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] efficientnet-lite in keras (functional api). /!/ i created a repository with efficientnet-lite model variants adapted to keras:\n\n[github link](https://github.com/sebastian-sz/efficientnet-lite-keras)\n\nthe goal of the project was to mimic `keras.applications` behavior, as much as possible.\n\nthe lite model variants were previously available in tensorflow 1.x, adopting them to keras made them more consistent with existing api and documentation.\n\naccording to [original repository](https://github.com/tensorflow/tpu/-----> tree !!! /master/models/official/efficientnet/lite), the lite variants:\n\n* use relu6 instead of swish.\n* do not use se.\n* have fixed stem and head while scaling the models.\n\nhope that this helps somebody!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ocy71x/p_efficientnetlite_in_keras_functional_api/',)", "identifyer": 5730018, "year": "2021"}, {"autor": "blueest", "date": 1625265472000, "content": "[D] MSE in Regression Models /!/ Suppose you have two regression models (e.g a linear regression and a regression decision tree) - is the only way to compare them by using their MSE? If one of the model has a MSE of 900, and the other has a MSE of 8065 : you conclude that the model with the lower MSE is \"more accurate\".\n\nBut is it possible to understand how \"bad\" is the model with the lower MSE? E.g. even though 900 is less than 8065 - is it still a good idea to use a model with a MSE of 900?\n\nIn classification, you can compare the accuracy of 2 models: one model can have an accuracy of 51% and the other model can have an accuracy of 56%. Although 56 is bigger than 51, an accuracy of 56 still isn't great.\n\nThe same way, is it possible to understand a MSE of 900? Or is it only understood relative to the MSE of other models?\n\nThanks", "link": "https://www.reddit.com/r/MachineLearning/comments/ocla3e/d_mse_in_regression_models/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] mse in regression models /!/ suppose you have two regression models (e.g a linear regression and a regression decision -----> tree !!! ) - is the only way to compare them by using their mse? if one of the model has a mse of 900, and the other has a mse of 8065 : you conclude that the model with the lower mse is \"more accurate\".\n\nbut is it possible to understand how \"bad\" is the model with the lower mse? e.g. even though 900 is less than 8065 - is it still a good idea to use a model with a mse of 900?\n\nin classification, you can compare the accuracy of 2 models: one model can have an accuracy of 51% and the other model can have an accuracy of 56%. although 56 is bigger than 51, an accuracy of 56 still isn't great.\n\nthe same way, is it possible to understand a mse of 900? or is it only understood relative to the mse of other models?\n\nthanks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ocla3e/d_mse_in_regression_models/',)", "identifyer": 5730050, "year": "2021"}, {"autor": "Ayman27299", "date": 1611602100000, "content": "[P] How can I improve the accuracy of the following classifier algorithim? /!/ Currently the classifier works as follow:\n\nI have a training data set and a testing data set, the classifier trains N ID3 tree, as follows:\n\nsuppose the training data set is of size m, then I sample p(ranges from 0.3 - 0.7)\\*m random samples from the training data set, and I use the samples to create a tree, I do this a total of N times,\n\nfor the random sample I took for each tree I calculate a centroid that is the average of all samples (I take the average for each feature and then I have the centroid example)\n\nthen for each test example, I calculate the Euclidian distance of the test example to each tree centroid I take the closest K tree centroid, and I classify the example according to them, and I return the most common classification\n\np.s. the classification is binary\n\ncurrently iam running with N= 16, K = 9, p = 0.7\n\nwhat can I do that isnt connected to pre-computation to improve upon this algorithm, I thought of giving weights to the decision of each tree according to how \"close\" the euclidian distance is, but it didnt help much thanks :)", "link": "https://www.reddit.com/r/MachineLearning/comments/l4v2r5/p_how_can_i_improve_the_accuracy_of_the_following/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] how can i improve the accuracy of the following classifier algorithim? /!/ currently the classifier works as follow:\n\ni have a training data set and a testing data set, the classifier trains n id3 -----> tree !!! , as follows:\n\nsuppose the training data set is of size m, then i sample p(ranges from 0.3 - 0.7)\\*m random samples from the training data set, and i use the samples to create a -----> tree !!! , i do this a total of n times,\n\nfor the random sample i took for each -----> tree !!!  i calculate a centroid that is the average of all samples (i take the average for each feature and then i have the centroid example)\n\nthen for each test example, i calculate the euclidian distance of the test example to each tree centroid i take the closest k tree centroid, and i classify the example according to them, and i return the most common classification\n\np.s. the classification is binary\n\ncurrently iam running with n= 16, k = 9, p = 0.7\n\nwhat can i do that isnt connected to pre-computation to improve upon this algorithm, i thought of giving weights to the decision of each tree according to how \"close\" the euclidian distance is, but it didnt help much thanks :)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/l4v2r5/p_how_can_i_improve_the_accuracy_of_the_following/',)", "identifyer": 5730120, "year": "2021"}, {"autor": "techsucker", "date": 1629855352000, "content": "[R] DeepMind Open-Sources Perceiver IO Codes, A General-Purpose Deep Learning Model Architecture That Handles A Wide Range of Data and Tasks /!/ Recently, DeepMind has open-sourced Perceiver IO\u2013a general-purpose deep learning model architecture that can handle many different types of inputs and outputs. This \u201cdrop-in\u201d replacement for Transformers is powerful enough to outperform baseline models without being constrained by domain knowledge.\n\nA new [preprint on arXiv describes Perceiver IO](https://arxiv.org/pdf/2107.14795.pdf), a more general version of the AI architecture that can produce many different outputs from multiple inputs. This means it is applicable to real-world domains like language and vision as well as difficult games like StarCraft II. Unlike Perceiver, Perceiver IO is an advanced model that overcomes the limitation of only being able to produce very simple outputs by learning how to flexibly query the latent space.\n\n# [3 Min Read](https://www.marktechpost.com/2021/08/24/deepmind-open-sources-perceiver-io-a-general-purpose-deep-learning-model-architecture-that-handles-a-wide-range-of-data-and-tasks/?_ga=2.49987042.535377308.1626074974-488125022.1618729090) | [Codes](https://github.com/deepmind/deepmind-research/tree/master/perceiver) | [Paper](https://arxiv.org/pdf/2107.14795.pdf)", "link": "https://www.reddit.com/r/MachineLearning/comments/pb16nk/r_deepmind_opensources_perceiver_io_codes_a/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] deepmind open-sources perceiver io codes, a general-purpose deep learning model architecture that handles a wide range of data and tasks /!/ recently, deepmind has open-sourced perceiver io\u2013a general-purpose deep learning model architecture that can handle many different types of inputs and outputs. this \u201cdrop-in\u201d replacement for transformers is powerful enough to outperform baseline models without being constrained by domain knowledge.\n\na new [preprint on arxiv describes perceiver io](https://arxiv.org/pdf/2107.14795.pdf), a more general version of the ai architecture that can produce many different outputs from multiple inputs. this means it is applicable to real-world domains like language and vision as well as difficult games like starcraft ii. unlike perceiver, perceiver io is an advanced model that overcomes the limitation of only being able to produce very simple outputs by learning how to flexibly query the latent space.\n\n# [3 min read](https://www.marktechpost.com/2021/08/24/deepmind-open-sources-perceiver-io-a-general-purpose-deep-learning-model-architecture-that-handles-a-wide-range-of-data-and-tasks/?_ga=2.49987042.535377308.1626074974-488125022.1618729090) | [codes](https://github.com/deepmind/deepmind-research/-----> tree !!! /master/perceiver) | [paper](https://arxiv.org/pdf/2107.14795.pdf)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pb16nk/r_deepmind_opensources_perceiver_io_codes_a/',)", "identifyer": 5730366, "year": "2021"}, {"autor": "EdvardDashD", "date": 1625920428000, "content": "[D] Am I understanding correctly how the Performer Transformer variant should be used for time series data? /!/ Hey all! Sorry in advance for any noobishness in what I'm asking, I'm still fairly new to machine learning.\n\nI'd like to use [Performer networks](https://github.com/google-research/google-research/tree/master/performer/fast_attention) to do time series analysis. While going through the implementation provided, I was having a hard time understanding exactly how the data that gets passed to it should be structured.\n\nAs an example, let's say the input has a shape of (240, 30). 240 being the number of time series steps and 30 being the number of features for each step. In this case, `attention_head_size` would be 30, and `attention_head_count` would be 16 since I want that many attention heads, right? And then the input data needs to be passed with a shape of (240, 480)? 480 being 30 \\* 16. If that's the case, does that mean that I need to duplicate the 30 features 16 times for each time series step so that the tensor is the appropriate size?\n\nThanks in advance for any insight you can provide!", "link": "https://www.reddit.com/r/MachineLearning/comments/ohhvzf/d_am_i_understanding_correctly_how_the_performer/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] am i understanding correctly how the performer transformer variant should be used for time series data? /!/ hey all! sorry in advance for any noobishness in what i'm asking, i'm still fairly new to machine learning.\n\ni'd like to use [performer networks](https://github.com/google-research/google-research/-----> tree !!! /master/performer/fast_attention) to do time series analysis. while going through the implementation provided, i was having a hard time understanding exactly how the data that gets passed to it should be structured.\n\nas an example, let's say the input has a shape of (240, 30). 240 being the number of time series steps and 30 being the number of features for each step. in this case, `attention_head_size` would be 30, and `attention_head_count` would be 16 since i want that many attention heads, right? and then the input data needs to be passed with a shape of (240, 480)? 480 being 30 \\* 16. if that's the case, does that mean that i need to duplicate the 30 features 16 times for each time series step so that the tensor is the appropriate size?\n\nthanks in advance for any insight you can provide!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ohhvzf/d_am_i_understanding_correctly_how_the_performer/',)", "identifyer": 5730897, "year": "2021"}, {"autor": "cmusagete", "date": 1627074656000, "content": "[P] Deep Learning Scheme for predicting interdependent Labels organized as a Hierarchy /!/ I have a dataset where the labels are organized as a tree and are super unbalanced. I am wondering if there is a way to make use of the hierarchy: for example, if label *Z* (first level) is true then all second level labels except for *cxix*, *cxx* and *cxxi* must be false and we only need to decide between those three and so on.\n\nI would appreciate any pointers to papers, ideas and comments.", "link": "https://www.reddit.com/r/MachineLearning/comments/oqbmqn/p_deep_learning_scheme_for_predicting/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] deep learning scheme for predicting interdependent labels organized as a hierarchy /!/ i have a dataset where the labels are organized as a -----> tree !!!  and are super unbalanced. i am wondering if there is a way to make use of the hierarchy: for example, if label *z* (first level) is true then all second level labels except for *cxix*, *cxx* and *cxxi* must be false and we only need to decide between those three and so on.\n\ni would appreciate any pointers to papers, ideas and comments.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/oqbmqn/p_deep_learning_scheme_for_predicting/',)", "identifyer": 5731121, "year": "2021"}, {"autor": "Snoo28889", "date": 1626745570000, "content": "Decision Tree Classification Explained With SciKit Learn in Python", "link": "https://www.reddit.com/r/MachineLearning/comments/onsapx/decision_tree_classification_explained_with/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "decision -----> tree !!!  classification explained with scikit learn in python", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('rich:video',)", "medialink": "('https://youtu.be/vdOz0F6hUFs',)", "identifyer": 5731225, "year": "2021"}, {"autor": "KirillTheMunchKing", "date": 1626706834000, "content": "[D] BYOL explained in 5 minutes: Bootstrap Your Own Latent A New Approach to Self-Supervised Learning by Jean-Bastien Grill et al. /!/ Is it possible to learn good enough image representations for many downstream tasks at once?\n\nA well known approach is to use self-supervised pretraining such as state-of-the art contrastive methods that are trained to reduce the distance between representation of augmented views of the same image (positive pairs) and increasing the distance between representations of augmented views of different images. These methods need careful treatment of negative pairs, whereas **BYOL achieves higher performance than SOTA contrastive methods without using negative pairs** at all. Instead it uses two networks that learn from each other to iteratively bootstrap the representations by forcing one network to use an augmented view of an image to predict the output of the other network for a different augmented view of the same image. Sounds crazy, I know... but it actually works!\n\nRead the [full paper digest](https://t.me/casual_gan/68) and the [blog post](https://www.casualganpapers.com/self-supervised/representation-learning/online-target-networks/2021/07/13/BYOL.html) (reading time \\~5 minutes) to learn about using an online and a target networks to make self-supervised learning work without using any negative pairs during training as well as the general intuition why SSL works in the first place.\n\nMeanwhile, check out the paper digest poster by [Casual GAN Papers](https://www.casualganpapers.com/)!\n\n[BYOL paper poster](https://preview.redd.it/n9nusoxyo6c71.png?width=571&amp;format=png&amp;auto=webp&amp;s=005ec3eb61133c41f909ab19576806530a7a6723)\n\n\\[[Full Explanation Post](https://t.me/casual_gan/68) / [Blog Post](https://www.casualganpapers.com/self-supervised/representation-learning/online-target-networks/2021/07/13/BYOL.html)\\] \\[[Arxiv](https://arxiv.org/pdf/2006.07733.pdf)\\] \\[[Code](https://github.com/deepmind/deepmind-research/tree/master/byol)\\]\n\nMore recent popular computer vision paper breakdowns:\n\n&gt;\\[[Deferred Neural Rendering](https://t.me/casual_gan/66)\\]  \n&gt;  \n&gt;\\[[SimCLR](https://www.casualganpapers.com/self-supervised/representation-learning/online-target-networks/2021/07/13/SimCLR.html)\\]  \n&gt;  \n&gt;\\[[GIRAFFE](https://t.me/casual_gan/63)\\]", "link": "https://www.reddit.com/r/MachineLearning/comments/onfril/d_byol_explained_in_5_minutes_bootstrap_your_own/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] byol explained in 5 minutes: bootstrap your own latent a new approach to self-supervised learning by jean-bastien grill et al. /!/ is it possible to learn good enough image representations for many downstream tasks at once?\n\na well known approach is to use self-supervised pretraining such as state-of-the art contrastive methods that are trained to reduce the distance between representation of augmented views of the same image (positive pairs) and increasing the distance between representations of augmented views of different images. these methods need careful treatment of negative pairs, whereas **byol achieves higher performance than sota contrastive methods without using negative pairs** at all. instead it uses two networks that learn from each other to iteratively bootstrap the representations by forcing one network to use an augmented view of an image to predict the output of the other network for a different augmented view of the same image. sounds crazy, i know... but it actually works!\n\nread the [full paper digest](https://t.me/casual_gan/68) and the [blog post](https://www.casualganpapers.com/self-supervised/representation-learning/online-target-networks/2021/07/13/byol.html) (reading time \\~5 minutes) to learn about using an online and a target networks to make self-supervised learning work without using any negative pairs during training as well as the general intuition why ssl works in the first place.\n\nmeanwhile, check out the paper digest poster by [casual gan papers](https://www.casualganpapers.com/)!\n\n[byol paper poster](https://preview.redd.it/n9nusoxyo6c71.png?width=571&amp;format=png&amp;auto=webp&amp;s=005ec3eb61133c41f909ab19576806530a7a6723)\n\n\\[[full explanation post](https://t.me/casual_gan/68) / [blog post](https://www.casualganpapers.com/self-supervised/representation-learning/online-target-networks/2021/07/13/byol.html)\\] \\[[arxiv](https://arxiv.org/pdf/2006.07733.pdf)\\] \\[[code](https://github.com/deepmind/deepmind-research/-----> tree !!! /master/byol)\\]\n\nmore recent popular computer vision paper breakdowns:\n\n&gt;\\[[deferred neural rendering](https://t.me/casual_gan/66)\\]  \n&gt;  \n&gt;\\[[simclr](https://www.casualganpapers.com/self-supervised/representation-learning/online-target-networks/2021/07/13/simclr.html)\\]  \n&gt;  \n&gt;\\[[giraffe](https://t.me/casual_gan/63)\\]", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/onfril/d_byol_explained_in_5_minutes_bootstrap_your_own/',)", "identifyer": 5731256, "year": "2021"}, {"autor": "jj4646", "date": 1626569394000, "content": "[D] equivalency between regression tree and classification trees /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/omgelx/d_equivalency_between_regression_tree_and/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] equivalency between regression -----> tree !!!  and classification trees /!/ [removed]", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/omgelx/d_equivalency_between_regression_tree_and/',)", "identifyer": 5731305, "year": "2021"}, {"autor": "Daedelus123", "date": 1627297969000, "content": "[D] Regression on noisy observed data /!/ I am working on a project where I'm trying to predict the amount of time spent on a particular stage of the sleep cycle.\n\nThe collection of training data involves segmenting time series of different signals, and then summing up the parts of the series that are labeled as awake.\n\nThen we can construct a table with the features associated with that sleeping session and the number of seconds spent on the particular sleep stage we are interested in predicting. This table can be used to train a tree based model of choice.\n\nThe problem I'm having is that there is no clear cut definition of when a person enters this sleep stage that I'm trying to predict i.e. I'm training my model where the observed y_true contains a lot of noise.\n\nI could obviously try to improve the segmentation such that it is consistent but let us say this is near impossible and I'm left with noisy observed data that I'm trying to train a model on.\n\nI have a vague memory of Kalman filters handling this problem but I'm not sure how it would be used in the context of training something like an xgboost model.\n\nAny help is appreciated!", "link": "https://www.reddit.com/r/MachineLearning/comments/orwkza/d_regression_on_noisy_observed_data/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] regression on noisy observed data /!/ i am working on a project where i'm trying to predict the amount of time spent on a particular stage of the sleep cycle.\n\nthe collection of training data involves segmenting time series of different signals, and then summing up the parts of the series that are labeled as awake.\n\nthen we can construct a table with the features associated with that sleeping session and the number of seconds spent on the particular sleep stage we are interested in predicting. this table can be used to train a -----> tree !!!  based model of choice.\n\nthe problem i'm having is that there is no clear cut definition of when a person enters this sleep stage that i'm trying to predict i.e. i'm training my model where the observed y_true contains a lot of noise.\n\ni could obviously try to improve the segmentation such that it is consistent but let us say this is near impossible and i'm left with noisy observed data that i'm trying to train a model on.\n\ni have a vague memory of kalman filters handling this problem but i'm not sure how it would be used in the context of training something like an xgboost model.\n\nany help is appreciated!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/orwkza/d_regression_on_noisy_observed_data/',)", "identifyer": 5731412, "year": "2021"}, {"autor": "-tangentially", "date": 1626098056000, "content": "What\u2019s the significance of the root node of a decision tree? /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/oirpkb/whats_the_significance_of_the_root_node_of_a/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "what\u2019s the significance of the root node of a decision -----> tree !!! ? /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/oirpkb/whats_the_significance_of_the_root_node_of_a/',)", "identifyer": 5731737, "year": "2021"}, {"autor": "5DollarBurger", "date": 1610525399000, "content": "Automated Decision Making Using Decision Tree Classifier /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/kwc5kc/automated_decision_making_using_decision_tree/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "automated decision making using decision -----> tree !!!  classifier /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/kwc5kc/automated_decision_making_using_decision_tree/',)", "identifyer": 5732170, "year": "2021"}, {"autor": "sk81k", "date": 1622755700000, "content": "Plotting a decision tree where each node is a figure [D] /!/ Does anyone know how I can plot a binary tree where each node is a figure (eg, seaborn graph) *in python*? I know dtreeviz can do something similar, but I\u2019d like to specify what each image will be. Thank you in advance", "link": "https://www.reddit.com/r/MachineLearning/comments/nrohy9/plotting_a_decision_tree_where_each_node_is_a/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "plotting a decision -----> tree !!!  where each node is a figure [d] /!/ does anyone know how i can plot a binary tree where each node is a figure (eg, seaborn graph) *in python*? i know dtreeviz can do something similar, but i\u2019d like to specify what each image will be. thank you in advance", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nrohy9/plotting_a_decision_tree_where_each_node_is_a/',)", "identifyer": 5732396, "year": "2021"}, {"autor": "usrideas", "date": 1630588618000, "content": "[D] Decision tree vs neural nets: challenging AlphaGo at tic-tac-toe /!/ Many experiments suggest that decision trees perform better in terms of classification accuracy than neural networks. There are several papers that record such instances, e.g., [ex1](&lt;http://eureka.teithe.gr/jspui/bitstream/123456789/5343/1/Kirkos_Spathis_Manolopoulos_Support_Vector_Machines.pdf&gt;), [ex2](&lt;https://arxiv.org/pdf/2007.06617&gt;), [ex3](&lt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6253432/pdf/ofy210.1763.pdf&gt;).\n\nThe anecdotal evidence is more manifest for classification problems with categorical attributes.\n\n\nIn section \"Algorithm Converging Equivalence\" of \"[Collapsing the Decision Tree](https://www.researchgate.net/publication/352923117_Collapsing_the_Decision_Tree_the_Concurrent_Data_Predictor)\" there is a theoretical argument that decision tree converge to the ideal accuracy when enough training data is used.\n\nAre there other studies that look into these theoretical aspects?\n\nNeural networks are capable of simulating any function, as stated by the universal approximation theorem. Therefore they are capable of simulating the saturated decision tree. However, no guarantees are given that the neural network training will converge to that solution.\n\nSo, at a game of tic-tac-toe, feeding all possible combinations of the game board as training data, the unpruned decision tree will generate the ideal playing strategy.\nWill a generic neural network always converge to that ideal strategy?\nAnd if so, how many neurons are required? How many layers? How many training epochs?", "link": "https://www.reddit.com/r/MachineLearning/comments/pghp7y/d_decision_tree_vs_neural_nets_challenging/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] decision -----> tree !!!  vs neural nets: challenging alphago at tic-tac-toe /!/ many experiments suggest that decision trees perform better in terms of classification accuracy than neural networks. there are several papers that record such instances, e.g., [ex1](&lt;http://eureka.teithe.gr/jspui/bitstream/123456789/5343/1/kirkos_spathis_manolopoulos_support_vector_machines.pdf&gt;), [ex2](&lt;https://arxiv.org/pdf/2007.06617&gt;), [ex3](&lt;https://www.ncbi.nlm.nih.gov/pmc/articles/pmc6253432/pdf/ofy210.1763.pdf&gt;).\n\nthe anecdotal evidence is more manifest for classification problems with categorical attributes.\n\n\nin section \"algorithm converging equivalence\" of \"[collapsing the decision tree](https://www.researchgate.net/publication/352923117_collapsing_the_decision_tree_the_concurrent_data_predictor)\" there is a theoretical argument that decision tree converge to the ideal accuracy when enough training data is used.\n\nare there other studies that look into these theoretical aspects?\n\nneural networks are capable of simulating any function, as stated by the universal approximation theorem. therefore they are capable of simulating the saturated decision tree. however, no guarantees are given that the neural network training will converge to that solution.\n\nso, at a game of tic-tac-toe, feeding all possible combinations of the game board as training data, the unpruned decision tree will generate the ideal playing strategy.\nwill a generic neural network always converge to that ideal strategy?\nand if so, how many neurons are required? how many layers? how many training epochs?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pghp7y/d_decision_tree_vs_neural_nets_challenging/',)", "identifyer": 5732603, "year": "2021"}, {"autor": "socialanurag", "date": 1623494888000, "content": "Ensemble Learning Part 6 | Sample Scenario | Decision Tree | Machine Learning Tutorial /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/ny419s/ensemble_learning_part_6_sample_scenario_decision/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "ensemble learning part 6 | sample scenario | decision -----> tree !!!  | machine learning tutorial /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ny419s/ensemble_learning_part_6_sample_scenario_decision/',)", "identifyer": 5732751, "year": "2021"}, {"autor": "socialanurag", "date": 1623494818000, "content": "Sample Scenario | Decision Tree | Ensemble Learning Part 6 | Machine Learning Tutorial /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/ny40nc/sample_scenario_decision_tree_ensemble_learning/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "sample scenario | decision -----> tree !!!  | ensemble learning part 6 | machine learning tutorial /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ny40nc/sample_scenario_decision_tree_ensemble_learning/',)", "identifyer": 5732752, "year": "2021"}, {"autor": "Philo167", "date": 1623354546000, "content": "[R] Tabular Data: Deep Learning is Not All You Need /!/ Interesting Paper\n\nA key element of AutoML systems is setting the types of models that will be used for each type of task. For classification and regression problems with tabular data, the use of tree ensemble models (like XGBoost) is usually recommended. However, several deep learning models for tabular data have recently been proposed, claiming to outperform XGBoost for some use-cases. In this paper, we explore whether these deep models should be a recommended option for tabular data, by rigorously comparing the new deep models to XGBoost on a variety of datasets. In addition to systematically comparing their accuracy, we consider the tuning and computation they require. Our study shows that XGBoost outperforms these deep models across the datasets, including datasets used in the papers that proposed the deep models. We also demonstrate that XGBoost requires much less tuning. On the positive side, we show that an ensemble of the deep models and XGBoost performs better on these datasets than XGBoost alone.\n\nby  Ravid Shwartz-Ziv  and  Amitai Armon \n\n&amp;#x200B;\n\nLinkt to Paper: [https://arxiv.org/pdf/2106.03253.pdf](https://arxiv.org/pdf/2106.03253.pdf)", "link": "https://www.reddit.com/r/MachineLearning/comments/nwwnxd/r_tabular_data_deep_learning_is_not_all_you_need/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] tabular data: deep learning is not all you need /!/ interesting paper\n\na key element of automl systems is setting the types of models that will be used for each type of task. for classification and regression problems with tabular data, the use of -----> tree !!!  ensemble models (like xgboost) is usually recommended. however, several deep learning models for tabular data have recently been proposed, claiming to outperform xgboost for some use-cases. in this paper, we explore whether these deep models should be a recommended option for tabular data, by rigorously comparing the new deep models to xgboost on a variety of datasets. in addition to systematically comparing their accuracy, we consider the tuning and computation they require. our study shows that xgboost outperforms these deep models across the datasets, including datasets used in the papers that proposed the deep models. we also demonstrate that xgboost requires much less tuning. on the positive side, we show that an ensemble of the deep models and xgboost performs better on these datasets than xgboost alone.\n\nby  ravid shwartz-ziv  and  amitai armon \n\n&amp;#x200b;\n\nlinkt to paper: [https://arxiv.org/pdf/2106.03253.pdf](https://arxiv.org/pdf/2106.03253.pdf)", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 7, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nwwnxd/r_tabular_data_deep_learning_is_not_all_you_need/',)", "identifyer": 5732781, "year": "2021"}, {"autor": "caraenderson", "date": 1623326561000, "content": "[D] Similarity of decision tree and bagging decision tree /!/ Most of peoples know the advantages of decision tree and bagging decision tree/ random forest. \n\n1)But what is the advantages of decision tree that bagging decision tree/rf still retains after implementation?\n2)What is the similarity in terms of characteristics between the bagging/rf and it base classifiers?", "link": "https://www.reddit.com/r/MachineLearning/comments/nwlw64/d_similarity_of_decision_tree_and_bagging/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] similarity of decision -----> tree !!!  and bagging decision -----> tree !!!  /!/ most of peoples know the advantages of decision tree and bagging decision tree/ random forest. \n\n1)but what is the advantages of decision tree that bagging decision tree/rf still retains after implementation?\n2)what is the similarity in terms of characteristics between the bagging/rf and it base classifiers?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nwlw64/d_similarity_of_decision_tree_and_bagging/',)", "identifyer": 5732825, "year": "2021"}, {"autor": "elcric_krej", "date": 1634728658000, "content": "[D] Boring machine learning is where it's at /!/ *Note: This is a short opinion piece I wrote, which I thought might be relevant to post here given all the \"career\" talk that's been going on, I'd be rather curious to hear if people here think this is a valid perspective, or if I'm glancing over some important stuff.*\n\nIt surprises me that when people think of \"software that brings about the singularity\" they think of text models, or of RL agents. But they sneer at decision tree boosting and the like as boring algorithms for boring problems.\n\nTo me, this seems counter-intuitive, and the fact that most people researching ML are interested in subjects like vision and language is flabergasting. For one, because getting anywhere productive in these fields is really hard, for another, because their usefulness seems relatively minimal.\n\nI've said it before and I'll say it again, human brains are very good at the stuff they've been doing for a long time. This ranges from things like controlling a human-like body to things like writing prose and poetry. Seneca was as good of a philosophy writer as any modern, Shakespear as good of a playwright as any contemporary. That is not to say that new works and diversity in literature isn't useful, both from the perspective of diversity and of updating to language and zeitgeist, but it's not game-changing.\n\nHuman brains are shit at certain tasks, things like finding the strongest correlation with some variables in an n-million times n-million valued matrix. Or heck, even finding the most productive categories to quantify a spreadsheet with a few dozen categorical columns and a few thousand rows. That's not to mention things like optimizing 3d structures under complex constraints or figuring out probabilistic periodicity in a multi-dimensional timeseries.\n\nThe later sort of problem is where machine learning has found the most amount of practical usage, problems that look \"silly\" to a researcher but implacable to a human mind. On the contrary, 10 years in, computer vision is still struggling to find any meaningfully large market fits outside of self-driving. There are a few interesting applications, but they have limited impact and a low market cap. The most interesting applications, related to bioimaging, happen to be things people are quite bad at; They are very divergent from the objective of creating human-like vision capabilities, since the results you want are anything but human-like.\n\nEven worst, there's the problem that human-like \"AI\" will be redundant the moment it's implemented. Self-driving cars are a real challenge precisely until the point when they become viable enough that everybody uses them, afterwards, every car is running on software and we can replace all the fancy CV-based decision making with simple control structures that rely on very constrained and \"sane\" behaviour from all other cars. Google assistant being able to call a restaurant or hospital and make a booking for you, or act as the receptionist taking that call, is relevant right until everyone starts using it, afterwards everything will already be digitized and we can switch to better and much simpler booking APIs.\n\nThat's not to say *all* human-like \"AI\" will be made redundant, but we can say that its applications are mainly well-known and will diminish over time, giving way to simpler automation as people start being replaced with algorithms. I say its applications are \"well known\" because they boil down to \"the stuff that humans can do right now which is boring or hard enough that we'd like to stop doing it\". There's a huge market for this, but it's huge in the same way as the whale oil market was in the 18th century. It's a market without that much growth potential.\n\nOn the other hand, the applications of \"inhuman\" algorithms are boundless, or at least only bounded by imagination. I've argued before that science hasn't yet caught up to the last 40 years of machine learning. People prefer designing equations by hand and validating them with arcane (and easy to fake, misinterpret and misuse) statistics, rather than using algorithmically generate solutions and validating them with simple, rock-solid methods such as CV. People like Horvath are hailed as genius-level polymaths in molecular biology for calling 4 scikit-learn functions on a tiny dataset.\n\n*Note: Horvath's work is great and I in no way want to pick on him specifically, the world would be much worse without him, I hope epigenetic clocks predict he'll live and work well into old age. I don't think he personally ever claimed the ML side of his work is in any way special or impressive, this is just what I've heard other biologists say.*\n\nThis is not to say that the scientific establishment is doomed or anything, it's just slow at using new technologies, especially those that shift the onus of what a researcher ought to be doing. The same goes for industry; A lot of high-paying, high-status positions involve doing work algorithms are better at, precisely because it's extremely difficult for people, and thus you need the smartest people for it.\n\nHowever, market forces and common sense are at work, and there's a constant uptick in usage. While I don't believe this can bring about a singularity so to speak, it will accelerate research and will open up new paradigms (mainly around data gathering and storage) and new problems that will allow ML to take centre stage.\n\nSo in that sense, it seems obvious to postulate a limited and decreasing market for human-like intelligence and a boundless and increasing market for \"inhuman\" intelligence.\n\nThis is mainly why I like to focus my work on the latter, even if it's often less flashy and more boring. One entirely avoidable issue with this is that the bar of doing better than a person is low, and the state of benchmarking is so poor as to make head-to-head competition between techniques difficult. Though this in itself is the problem I'm aiming to help solve.\n\nThat's about it, so I say go grab a spreadsheet and figure out how to get the best result on a boring economics problem with a boring algorithm; Don't worry so much about making a painting or movie with GANs, we're already really good at doing that and enjoy doing it.", "link": "https://www.reddit.com/r/MachineLearning/comments/qbyhlz/d_boring_machine_learning_is_where_its_at/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] boring machine learning is where it's at /!/ *note: this is a short opinion piece i wrote, which i thought might be relevant to post here given all the \"career\" talk that's been going on, i'd be rather curious to hear if people here think this is a valid perspective, or if i'm glancing over some important stuff.*\n\nit surprises me that when people think of \"software that brings about the singularity\" they think of text models, or of rl agents. but they sneer at decision -----> tree !!!  boosting and the like as boring algorithms for boring problems.\n\nto me, this seems counter-intuitive, and the fact that most people researching ml are interested in subjects like vision and language is flabergasting. for one, because getting anywhere productive in these fields is really hard, for another, because their usefulness seems relatively minimal.\n\ni've said it before and i'll say it again, human brains are very good at the stuff they've been doing for a long time. this ranges from things like controlling a human-like body to things like writing prose and poetry. seneca was as good of a philosophy writer as any modern, shakespear as good of a playwright as any contemporary. that is not to say that new works and diversity in literature isn't useful, both from the perspective of diversity and of updating to language and zeitgeist, but it's not game-changing.\n\nhuman brains are shit at certain tasks, things like finding the strongest correlation with some variables in an n-million times n-million valued matrix. or heck, even finding the most productive categories to quantify a spreadsheet with a few dozen categorical columns and a few thousand rows. that's not to mention things like optimizing 3d structures under complex constraints or figuring out probabilistic periodicity in a multi-dimensional timeseries.\n\nthe later sort of problem is where machine learning has found the most amount of practical usage, problems that look \"silly\" to a researcher but implacable to a human mind. on the contrary, 10 years in, computer vision is still struggling to find any meaningfully large market fits outside of self-driving. there are a few interesting applications, but they have limited impact and a low market cap. the most interesting applications, related to bioimaging, happen to be things people are quite bad at; they are very divergent from the objective of creating human-like vision capabilities, since the results you want are anything but human-like.\n\neven worst, there's the problem that human-like \"ai\" will be redundant the moment it's implemented. self-driving cars are a real challenge precisely until the point when they become viable enough that everybody uses them, afterwards, every car is running on software and we can replace all the fancy cv-based decision making with simple control structures that rely on very constrained and \"sane\" behaviour from all other cars. google assistant being able to call a restaurant or hospital and make a booking for you, or act as the receptionist taking that call, is relevant right until everyone starts using it, afterwards everything will already be digitized and we can switch to better and much simpler booking apis.\n\nthat's not to say *all* human-like \"ai\" will be made redundant, but we can say that its applications are mainly well-known and will diminish over time, giving way to simpler automation as people start being replaced with algorithms. i say its applications are \"well known\" because they boil down to \"the stuff that humans can do right now which is boring or hard enough that we'd like to stop doing it\". there's a huge market for this, but it's huge in the same way as the whale oil market was in the 18th century. it's a market without that much growth potential.\n\non the other hand, the applications of \"inhuman\" algorithms are boundless, or at least only bounded by imagination. i've argued before that science hasn't yet caught up to the last 40 years of machine learning. people prefer designing equations by hand and validating them with arcane (and easy to fake, misinterpret and misuse) statistics, rather than using algorithmically generate solutions and validating them with simple, rock-solid methods such as cv. people like horvath are hailed as genius-level polymaths in molecular biology for calling 4 scikit-learn functions on a tiny dataset.\n\n*note: horvath's work is great and i in no way want to pick on him specifically, the world would be much worse without him, i hope epigenetic clocks predict he'll live and work well into old age. i don't think he personally ever claimed the ml side of his work is in any way special or impressive, this is just what i've heard other biologists say.*\n\nthis is not to say that the scientific establishment is doomed or anything, it's just slow at using new technologies, especially those that shift the onus of what a researcher ought to be doing. the same goes for industry; a lot of high-paying, high-status positions involve doing work algorithms are better at, precisely because it's extremely difficult for people, and thus you need the smartest people for it.\n\nhowever, market forces and common sense are at work, and there's a constant uptick in usage. while i don't believe this can bring about a singularity so to speak, it will accelerate research and will open up new paradigms (mainly around data gathering and storage) and new problems that will allow ml to take centre stage.\n\nso in that sense, it seems obvious to postulate a limited and decreasing market for human-like intelligence and a boundless and increasing market for \"inhuman\" intelligence.\n\nthis is mainly why i like to focus my work on the latter, even if it's often less flashy and more boring. one entirely avoidable issue with this is that the bar of doing better than a person is low, and the state of benchmarking is so poor as to make head-to-head competition between techniques difficult. though this in itself is the problem i'm aiming to help solve.\n\nthat's about it, so i say go grab a spreadsheet and figure out how to get the best result on a boring economics problem with a boring algorithm; don't worry so much about making a painting or movie with gans, we're already really good at doing that and enjoy doing it.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 17, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/qbyhlz/d_boring_machine_learning_is_where_its_at/',)", "identifyer": 5733480, "year": "2021"}, {"autor": "wackajala", "date": 1612240676000, "content": "[D] Does anyone use excel when they start in their algorithm design /!/ I'm talking MVP level where you're at a point of heavy discussion with the business team and still figuring out the requirements and framework of the general algorithm design. For example, a business user may have invested effort towards a financial model or decision tree within excel as part of the input of the project.\n\nDo any of you start the conversation in excel or even develop a good part of an initial mvp of your algorithm within excel?\n\nI'm asking primarily because excel obviously is a tool that everyone understands, whereas tools like R, etc. require more specialized knowledge to work in.\n\nCurious - thank you.", "link": "https://www.reddit.com/r/MachineLearning/comments/lank36/d_does_anyone_use_excel_when_they_start_in_their/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] does anyone use excel when they start in their algorithm design /!/ i'm talking mvp level where you're at a point of heavy discussion with the business team and still figuring out the requirements and framework of the general algorithm design. for example, a business user may have invested effort towards a financial model or decision -----> tree !!!  within excel as part of the input of the project.\n\ndo any of you start the conversation in excel or even develop a good part of an initial mvp of your algorithm within excel?\n\ni'm asking primarily because excel obviously is a tool that everyone understands, whereas tools like r, etc. require more specialized knowledge to work in.\n\ncurious - thank you.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 18, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lank36/d_does_anyone_use_excel_when_they_start_in_their/',)", "identifyer": 5733727, "year": "2021"}, {"autor": "datascienceduniya", "date": 1633954036000, "content": "Decision Tree for Regression Models in Machine Learning", "link": "https://www.reddit.com/r/MachineLearning/comments/q5uf7b/decision_tree_for_regression_models_in_machine/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "decision -----> tree !!!  for regression models in machine learning", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('link',)", "medialink": "('https://ashutoshtripathi.com/2021/10/11/decision-tree-for-regression-models-in-machine-learning/',)", "identifyer": 5733917, "year": "2021"}, {"autor": "datascienceduniya", "date": 1633953997000, "content": "Decision Tree for Regression Models in Machine Learning", "link": "https://www.reddit.com/r/MachineLearning/comments/q5uesv/decision_tree_for_regression_models_in_machine/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "decision -----> tree !!!  for regression models in machine learning", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('link',)", "medialink": "('https://ashutoshtripathi.com/2021/10/11/decision-tree-for-regression-models-in-machine-learning/',)", "identifyer": 5733918, "year": "2021"}, {"autor": "Yuqing7", "date": 1635259696000, "content": "[R] Facebook AI\u2019s NormFormer Employs Extra Normalization to Significantly Improve Transformer Pretraining /!/ Facebook AI Research proposes NormFormer, an approach that improves pretraining perplexity and downstream task performance for both causal and masked language models, achieving GPT3-Large (1.3B) zero-shot performance 60 percent faster and improving fine-tuned GLUE performance by 1.9 percent. \n\nHere is a quick read: [Facebook AI\u2019s NormFormer Employs Extra Normalization to Significantly Improve Transformer Pretraining.](https://syncedreview.com/2021/10/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-131/)\n\nThe code to train NormFormer models is available on the project\u2019s [GitHub.](https://github.com/pytorch/fairseq/tree/main/examples/normformer) The paper *NormFormer: Improved Transformer Pretraining with Extra Normalization* is on [arXiv](https://arxiv.org/abs/2110.09456).", "link": "https://www.reddit.com/r/MachineLearning/comments/qg80uf/r_facebook_ais_normformer_employs_extra/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] facebook ai\u2019s normformer employs extra normalization to significantly improve transformer pretraining /!/ facebook ai research proposes normformer, an approach that improves pretraining perplexity and downstream task performance for both causal and masked language models, achieving gpt3-large (1.3b) zero-shot performance 60 percent faster and improving fine-tuned glue performance by 1.9 percent. \n\nhere is a quick read: [facebook ai\u2019s normformer employs extra normalization to significantly improve transformer pretraining.](https://syncedreview.com/2021/10/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-131/)\n\nthe code to train normformer models is available on the project\u2019s [github.](https://github.com/pytorch/fairseq/-----> tree !!! /main/examples/normformer) the paper *normformer: improved transformer pretraining with extra normalization* is on [arxiv](https://arxiv.org/abs/2110.09456).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/qg80uf/r_facebook_ais_normformer_employs_extra/',)", "identifyer": 5733964, "year": "2021"}, {"autor": "techsucker", "date": 1631234922000, "content": "[R] Facebook AI Introduces GSLM (Generative Spoken Language Model), A Textless NLP Model That Breaks Free Completely of The Dependence on Text for Training /!/ The recent advancements in text-based language models, such as BERT, RoBERTa, and GPT-3, have been extremely impressive. Because they can generate realistically written words from a given input, these models can be utilized for various natural language processing applications, including sentiment analysis translation information retrieval inferences summarization, among others using only a few labels or examples (e.g., BART and XLM R). However, these applications have a major limitation: the models are only suitable for languages with very large text data sets.\n\nFacebook AI has introduced the first high-performance NLP model, called Generative Spoken Language Model (GSLM), which leverages state-of-the-art representation learning to work with raw audio signals without labels or text. This can lead to a new era of textless applications for any language spoken on earth, even those without significant text data sets. By using GSLM, you can develop NLP models that incorporate the full range of expressivity found in spoken language.\n\n# [4 Min Read](https://www.marktechpost.com/2021/09/09/facebook-ai-introduces-gslm-generative-spoken-language-model-a-textless-nlp-model-that-breaks-free-completely-of-the-dependence-on-text-for-training/) | [GLSM Paper](https://arxiv.org/abs/2102.01192?) | [Expressive Resynthesis Paper](https://arxiv.org/abs/2104.00355) | [Prosody-Aware GSLM Paper](https://arxiv.org/abs/2109.03264?) | [Code and Pretrained Models](https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/m87hzajepkm71.png?width=1392&amp;format=png&amp;auto=webp&amp;s=beb39d6edacffb7ff44e39f7e48ce618dd76a6d1", "link": "https://www.reddit.com/r/MachineLearning/comments/plajlw/r_facebook_ai_introduces_gslm_generative_spoken/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] facebook ai introduces gslm (generative spoken language model), a textless nlp model that breaks free completely of the dependence on text for training /!/ the recent advancements in text-based language models, such as bert, roberta, and gpt-3, have been extremely impressive. because they can generate realistically written words from a given input, these models can be utilized for various natural language processing applications, including sentiment analysis translation information retrieval inferences summarization, among others using only a few labels or examples (e.g., bart and xlm r). however, these applications have a major limitation: the models are only suitable for languages with very large text data sets.\n\nfacebook ai has introduced the first high-performance nlp model, called generative spoken language model (gslm), which leverages state-of-the-art representation learning to work with raw audio signals without labels or text. this can lead to a new era of textless applications for any language spoken on earth, even those without significant text data sets. by using gslm, you can develop nlp models that incorporate the full range of expressivity found in spoken language.\n\n# [4 min read](https://www.marktechpost.com/2021/09/09/facebook-ai-introduces-gslm-generative-spoken-language-model-a-textless-nlp-model-that-breaks-free-completely-of-the-dependence-on-text-for-training/) | [glsm paper](https://arxiv.org/abs/2102.01192?) | [expressive resynthesis paper](https://arxiv.org/abs/2104.00355) | [prosody-aware gslm paper](https://arxiv.org/abs/2109.03264?) | [code and pretrained models](https://github.com/pytorch/fairseq/-----> tree !!! /master/examples/textless_nlp)\n\n&amp;#x200b;\n\nhttps://preview.redd.it/m87hzajepkm71.png?width=1392&amp;format=png&amp;auto=webp&amp;s=beb39d6edacffb7ff44e39f7e48ce618dd76a6d1", "sortedWord": "None", "removed": "('nan',)", "score": 0, "comments": 15, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/plajlw/r_facebook_ai_introduces_gslm_generative_spoken/',)", "identifyer": 5734114, "year": "2021"}, {"autor": "SQL_beginner", "date": 1623950869000, "content": "[D] history of non-parametric models in machine learning /!/ I have been reading about the use of non-parametric models in machine learning (e.g. kernel methods like svm, kernel regression ... decision trees, gradient boosting, random forest) - and I tried to contextualize the reasons why these methods emerged (in my head). This is the conclusion I reached:\n\n1) Parametric models (like standard regression models) are tricky. Parametric models require certain assumptions about the data to be true, also require the analyst to manually specify interaction terms within variables - but the biggest drawback: regression models tend to require more beta coefficients to capture more complex patterns within the data. A regression model with many beta coefficients behaves similar to a higher order polynomial function: and higher order polynomials are notorious for behaving in very unpredictable ways outside the range of observed data (runge phenomenon) - this basically explains why higher order regression models have a bad reputation of overfitting training data and generalizing poorly to new data. This is all related to the bias-variance tradeoff.\n\n2) Non-parametric models do not require interaction terms between variables to be manually specified (e.g. in a decision tree, you don't need to specify this - the decision tree will try to recover these interactions by itself), and have less stringent assumptions about the data (e.g. choice of kernel). The appeal of non parametric methods was an attempt to defy the bias-variance tradeoff: the idea of trying to make a less complex model with the ability to make predictions comparable to a complex model, with the hope that the lack of explicit complexity leading to better generalization on test data.\n\n3) the popularity of neural networks (a parametric model) is due to the fact that researchers found out ways to make these explicitly complex models generalize to unseen data (e.g. effective regularization methods).\n\nIs my interpretation of the history correct?\n\nThanks", "link": "https://www.reddit.com/r/MachineLearning/comments/o22nxg/d_history_of_nonparametric_models_in_machine/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] history of non-parametric models in machine learning /!/ i have been reading about the use of non-parametric models in machine learning (e.g. kernel methods like svm, kernel regression ... decision trees, gradient boosting, random forest) - and i tried to contextualize the reasons why these methods emerged (in my head). this is the conclusion i reached:\n\n1) parametric models (like standard regression models) are tricky. parametric models require certain assumptions about the data to be true, also require the analyst to manually specify interaction terms within variables - but the biggest drawback: regression models tend to require more beta coefficients to capture more complex patterns within the data. a regression model with many beta coefficients behaves similar to a higher order polynomial function: and higher order polynomials are notorious for behaving in very unpredictable ways outside the range of observed data (runge phenomenon) - this basically explains why higher order regression models have a bad reputation of overfitting training data and generalizing poorly to new data. this is all related to the bias-variance tradeoff.\n\n2) non-parametric models do not require interaction terms between variables to be manually specified (e.g. in a decision -----> tree !!! , you don't need to specify this - the decision -----> tree !!!  will try to recover these interactions by itself), and have less stringent assumptions about the data (e.g. choice of kernel). the appeal of non parametric methods was an attempt to defy the bias-variance tradeoff: the idea of trying to make a less complex model with the ability to make predictions comparable to a complex model, with the hope that the lack of explicit complexity leading to better generalization on test data.\n\n3) the popularity of neural networks (a parametric model) is due to the fact that researchers found out ways to make these explicitly complex models generalize to unseen data (e.g. effective regularization methods).\n\nis my interpretation of the history correct?\n\nthanks", "sortedWord": "None", "removed": "('nan',)", "score": 2, "comments": 5, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o22nxg/d_history_of_nonparametric_models_in_machine/',)", "identifyer": 5734313, "year": "2021"}, {"autor": "techsucker", "date": 1633160667000, "content": "[R] Microsoft AI Unveils \u2018TrOCR\u2019, An End-To-End Transformer-Based OCR Model For Text Recognition With Pre-Trained Models /!/ The problem of text recognition is a long-standing issue in document digitalization. Many current approaches for text recognition are usually built on top of existing convolutional neural network (CNN) models for image understanding and recurrent neural network (RNN) for char-level text generation. There are some latest progress records in text recognition by taking advantage of transformers, but this still needs the CNN as the backbone. Despite various successes by the current hybrid encoder/decoder methods, there is definitely some room to improve with pre-trained CV and NLP models.\n\nMicrosoft research team unveils \u2018[TrOCR](https://arxiv.org/pdf/2109.10282.pdf),\u2019 an end-to-end Transformer-based OCR model for text recognition with pre-trained computer vision (CV) and natural language processing (NLP) models. It is a simple and effective model which is that does not use CNN as the backbone. TrOCR starts with resizing the input text image into 384 \u00d7 384, and then the image is split into a sequence of 16 \u00d7 16 patches used as the input to image Transformers. The research team used standard transformer architecture with the self-attention mechanism on both encoder and decoder parts where word piece units are generated as recognized text from an input image.\n\n# [4 Min Read](https://www.marktechpost.com/2021/10/02/microsoft-ai-unveils-trocr-an-end-to-end-transformer-based-ocr-model-for-text-recognition-with-pre-trained-models/)| [Paper](https://arxiv.org/pdf/2109.10282.pdf) | [Github](https://github.com/microsoft/unilm/tree/master/trocr)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/qwyzdqfmrzq71.png?width=1308&amp;format=png&amp;auto=webp&amp;s=b7cde292a34b76e22526ed6d032def0815b62670", "link": "https://www.reddit.com/r/MachineLearning/comments/pzqruy/r_microsoft_ai_unveils_trocr_an_endtoend/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] microsoft ai unveils \u2018trocr\u2019, an end-to-end transformer-based ocr model for text recognition with pre-trained models /!/ the problem of text recognition is a long-standing issue in document digitalization. many current approaches for text recognition are usually built on top of existing convolutional neural network (cnn) models for image understanding and recurrent neural network (rnn) for char-level text generation. there are some latest progress records in text recognition by taking advantage of transformers, but this still needs the cnn as the backbone. despite various successes by the current hybrid encoder/decoder methods, there is definitely some room to improve with pre-trained cv and nlp models.\n\nmicrosoft research team unveils \u2018[trocr](https://arxiv.org/pdf/2109.10282.pdf),\u2019 an end-to-end transformer-based ocr model for text recognition with pre-trained computer vision (cv) and natural language processing (nlp) models. it is a simple and effective model which is that does not use cnn as the backbone. trocr starts with resizing the input text image into 384 \u00d7 384, and then the image is split into a sequence of 16 \u00d7 16 patches used as the input to image transformers. the research team used standard transformer architecture with the self-attention mechanism on both encoder and decoder parts where word piece units are generated as recognized text from an input image.\n\n# [4 min read](https://www.marktechpost.com/2021/10/02/microsoft-ai-unveils-trocr-an-end-to-end-transformer-based-ocr-model-for-text-recognition-with-pre-trained-models/)| [paper](https://arxiv.org/pdf/2109.10282.pdf) | [github](https://github.com/microsoft/unilm/-----> tree !!! /master/trocr)\n\n&amp;#x200b;\n\nhttps://preview.redd.it/qwyzdqfmrzq71.png?width=1308&amp;format=png&amp;auto=webp&amp;s=b7cde292a34b76e22526ed6d032def0815b62670", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pzqruy/r_microsoft_ai_unveils_trocr_an_endtoend/',)", "identifyer": 5734523, "year": "2021"}, {"autor": "HUNGRYTOAN", "date": 1628545787000, "content": "[D] Re-writing AI algorithm tutorials to be more user-friendly /!/ I was reading a tutorial on Alphazero's Monte-Carlo Tree Search ([https://jonathan-hui.medium.com/monte-carlo-tree-search-mcts-in-alphago-zero-8a403588276a](https://jonathan-hui.medium.com/monte-carlo-tree-search-mcts-in-alphago-zero-8a403588276a)), and I noticed that this tutorial and so many others are very hard for me to read. I've been brainstorming some ideas for how to improve exposition around ML algorithms, and I'd love to hear your suggestions.  \n\n\nOne of the many issues I've run into is that tutorials are written linearly. As I read the text of a tutorial, There are plenty of vocabulary words that I need to re-reference, plenty of pictures I need to scroll back up to see (and then try to find my old place), and so forth. This breaks my reading flow and makes reading much harder than it needs to be.  \n\n\nI've been trying to reimagine how this exposition can be written in a more user friendly way.  See the attached picture for a quick prototype. Here, the algorithm is compactly described in a slide-show with descriptive captions. Vocabulary words are highlighted in green, and the user can mouse-over them to get their definitions. I personally like this format a lot better, as it also shows me a worked example step-by-step.  \n\n\nI'd be curious to hear what folks think of this idea. How can I improve it? Are there better ways to re-write ML tutorials? Am I looking at the wrong resources to learn ML? What are your major bottlenecks in learning a new ML algorithm? I'm an ML noobie, so I'd love to hear what fellow noobie bottlenecks are.", "link": "https://www.reddit.com/r/MachineLearning/comments/p1bdd8/d_rewriting_ai_algorithm_tutorials_to_be_more/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] re-writing ai algorithm tutorials to be more user-friendly /!/ i was reading a tutorial on alphazero's monte-carlo -----> tree !!!  search ([https://jonathan-hui.medium.com/monte-carlo-tree-search-mcts-in-alphago-zero-8a403588276a](https://jonathan-hui.medium.com/monte-carlo-tree-search-mcts-in-alphago-zero-8a403588276a)), and i noticed that this tutorial and so many others are very hard for me to read. i've been brainstorming some ideas for how to improve exposition around ml algorithms, and i'd love to hear your suggestions.  \n\n\none of the many issues i've run into is that tutorials are written linearly. as i read the text of a tutorial, there are plenty of vocabulary words that i need to re-reference, plenty of pictures i need to scroll back up to see (and then try to find my old place), and so forth. this breaks my reading flow and makes reading much harder than it needs to be.  \n\n\ni've been trying to reimagine how this exposition can be written in a more user friendly way.  see the attached picture for a quick prototype. here, the algorithm is compactly described in a slide-show with descriptive captions. vocabulary words are highlighted in green, and the user can mouse-over them to get their definitions. i personally like this format a lot better, as it also shows me a worked example step-by-step.  \n\n\ni'd be curious to hear what folks think of this idea. how can i improve it? are there better ways to re-write ml tutorials? am i looking at the wrong resources to learn ml? what are your major bottlenecks in learning a new ml algorithm? i'm an ml noobie, so i'd love to hear what fellow noobie bottlenecks are.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p1bdd8/d_rewriting_ai_algorithm_tutorials_to_be_more/',)", "identifyer": 5734537, "year": "2021"}, {"autor": "7Seas_ofRyhme", "date": 1628520830000, "content": "[D] base algorithm to use for wrapper methods in feature selection (binary classification) /!/ Hey guys, I'm wondering which algorithm should I use for feature selection in a binary classification problem ? (Wrapper methods)\n\nI plan to perform a RFE, forward/backward selection, and I'm unsure of which algo to use as a base (eg random forest, decision tree) \n\nIs it possible to use SVM or logistic regression here as well? \n\nThanks :)", "link": "https://www.reddit.com/r/MachineLearning/comments/p1311u/d_base_algorithm_to_use_for_wrapper_methods_in/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] base algorithm to use for wrapper methods in feature selection (binary classification) /!/ hey guys, i'm wondering which algorithm should i use for feature selection in a binary classification problem ? (wrapper methods)\n\ni plan to perform a rfe, forward/backward selection, and i'm unsure of which algo to use as a base (eg random forest, decision -----> tree !!! ) \n\nis it possible to use svm or logistic regression here as well? \n\nthanks :)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p1311u/d_base_algorithm_to_use_for_wrapper_methods_in/',)", "identifyer": 5734556, "year": "2021"}, {"autor": "Yuqing7", "date": 1628519815000, "content": "[R] DeepMind's Perceiver IO: A General Architecture for a Wide Variety of Inputs &amp; Outputs /!/ A DeepMind research team proposes Perceiver IO, a single network that can easily integrate and transform arbitrary information for arbitrary tasks while scaling linearly with both input and output sizes. The general architecture achieves outstanding results on tasks with highly structured output spaces, such as natural language and visual understanding. \n\nHere is a quick read: [DeepMind's Perceiver IO: A General Architecture for a Wide Variety of Inputs &amp; Outputs.](https://syncedreview.com/2021/08/09/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-78/)\n\nThe Perceiver IO code is available on the project [GitHub](https://github.com/deepmind/deepmind-research/tree/master/perceiver). The paper *Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs* is on [arXiv](https://arxiv.org/abs/2107.14795).", "link": "https://www.reddit.com/r/MachineLearning/comments/p12pje/r_deepminds_perceiver_io_a_general_architecture/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] deepmind's perceiver io: a general architecture for a wide variety of inputs &amp; outputs /!/ a deepmind research team proposes perceiver io, a single network that can easily integrate and transform arbitrary information for arbitrary tasks while scaling linearly with both input and output sizes. the general architecture achieves outstanding results on tasks with highly structured output spaces, such as natural language and visual understanding. \n\nhere is a quick read: [deepmind's perceiver io: a general architecture for a wide variety of inputs &amp; outputs.](https://syncedreview.com/2021/08/09/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-78/)\n\nthe perceiver io code is available on the project [github](https://github.com/deepmind/deepmind-research/-----> tree !!! /master/perceiver). the paper *perceiver io: a general architecture for structured inputs &amp; outputs* is on [arxiv](https://arxiv.org/abs/2107.14795).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p12pje/r_deepminds_perceiver_io_a_general_architecture/',)", "identifyer": 5734559, "year": "2021"}, {"autor": "mlvpj", "date": 1633787920000, "content": "[P] Denoising Diffusion Probabilistic Models implementation with annotations /!/ We implemented Denoising Diffusion Probabilistic Models (DDPM) paper.\n\nCode with annotations: [https://nn.labml.ai/diffusion/ddpm/index.html](https://nn.labml.ai/diffusion/ddpm/index.html)\n\n* [Github](https://github.com/labmlai/annotated_deep_learning_paper_implementations/tree/master/labml_nn/diffusion/ddpm)\n* [Paper](https://papers.labml.ai/paper/2006.11239)\n* [Conference video](https://slideslive.com/38936172/denoising-diffusion-probabilistic-models)", "link": "https://www.reddit.com/r/MachineLearning/comments/q4lvl5/p_denoising_diffusion_probabilistic_models/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] denoising diffusion probabilistic models implementation with annotations /!/ we implemented denoising diffusion probabilistic models (ddpm) paper.\n\ncode with annotations: [https://nn.labml.ai/diffusion/ddpm/index.html](https://nn.labml.ai/diffusion/ddpm/index.html)\n\n* [github](https://github.com/labmlai/annotated_deep_learning_paper_implementations/-----> tree !!! /master/labml_nn/diffusion/ddpm)\n* [paper](https://papers.labml.ai/paper/2006.11239)\n* [conference video](https://slideslive.com/38936172/denoising-diffusion-probabilistic-models)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/q4lvl5/p_denoising_diffusion_probabilistic_models/',)", "identifyer": 5735159, "year": "2021"}, {"autor": "HushHush4446", "date": 1633784294000, "content": "[Discussion] Fitting new data on an already constructed decision tree [Python] /!/ I wanted to know if there is a way around fitting new data set on an already constructed decision tree, in Python. \n\nI have been searching about it and not able to find anything, maybe I am missing some key terms.", "link": "https://www.reddit.com/r/MachineLearning/comments/q4ktno/discussion_fitting_new_data_on_an_already/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[discussion] fitting new data on an already constructed decision -----> tree !!!  [python] /!/ i wanted to know if there is a way around fitting new data set on an already constructed decision tree, in python. \n\ni have been searching about it and not able to find anything, maybe i am missing some key terms.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/q4ktno/discussion_fitting_new_data_on_an_already/',)", "identifyer": 5735163, "year": "2021"}, {"autor": "helblazer811", "date": 1628013172000, "content": "Decision Tree Classifier Visualization /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/ox8vjo/decision_tree_classifier_visualization/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "decision -----> tree !!!  classifier visualization /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ox8vjo/decision_tree_classifier_visualization/',)", "identifyer": 5735297, "year": "2021"}, {"autor": "vietlinh12hoa", "date": 1628005892000, "content": "[D] Would it make sense to have random forest based-xgboost? /!/ Random forest is the aggregation of random decision trees with random feature selection. Can we just replace decision tree by xgboost. E.g.: Build a random xgboost with random feature selection. Then aggregation those boosted trees to have a forest.", "link": "https://www.reddit.com/r/MachineLearning/comments/ox6agt/d_would_it_make_sense_to_have_random_forest/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] would it make sense to have random forest based-xgboost? /!/ random forest is the aggregation of random decision trees with random feature selection. can we just replace decision -----> tree !!!  by xgboost. e.g.: build a random xgboost with random feature selection. then aggregation those boosted trees to have a forest.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 6, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ox6agt/d_would_it_make_sense_to_have_random_forest/',)", "identifyer": 5735306, "year": "2021"}, {"autor": "vietlinh12hoa", "date": 1628005705000, "content": "[Q] Would it make sense to have random forest based-xgboost? /!/ Random forest is the aggregation of random decision trees with random feature selection. Can we just replace decision tree by xgboost. E.g.: Build a random xgboost with random feature selection. Then aggregation those boosted trees to have a forest.", "link": "https://www.reddit.com/r/MachineLearning/comments/ox684f/q_would_it_make_sense_to_have_random_forest/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[q] would it make sense to have random forest based-xgboost? /!/ random forest is the aggregation of random decision trees with random feature selection. can we just replace decision -----> tree !!!  by xgboost. e.g.: build a random xgboost with random feature selection. then aggregation those boosted trees to have a forest.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ox684f/q_would_it_make_sense_to_have_random_forest/',)", "identifyer": 5735307, "year": "2021"}, {"autor": "Yuqing7", "date": 1628001293000, "content": "[R] DeepMind &amp; Google Use Neural Networks to Solve Mixed Integer Programs /!/ A team from DeepMind and Google Research leverages neural networks to automatically construct effective heuristics from a dataset for mixed integer programming (MIP) problems. The approach significantly outperforms classical MIP solver techniques. \n\nHere is a quick read: [DeepMind &amp; Google Use Neural Networks to Solve Mixed Integer Programs.](https://syncedreview.com/2021/08/03/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-74/)\n\nThe code is available on the project [GitHub](https://github.com/deepmind/deepmind-research/tree/master/neural_mip_solving). The paper *Solving Mixed Integer Programs Using Neural Networks* is on [arXiv](https://arxiv.org/abs/2012.13349).", "link": "https://www.reddit.com/r/MachineLearning/comments/ox4qyv/r_deepmind_google_use_neural_networks_to_solve/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] deepmind &amp; google use neural networks to solve mixed integer programs /!/ a team from deepmind and google research leverages neural networks to automatically construct effective heuristics from a dataset for mixed integer programming (mip) problems. the approach significantly outperforms classical mip solver techniques. \n\nhere is a quick read: [deepmind &amp; google use neural networks to solve mixed integer programs.](https://syncedreview.com/2021/08/03/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-74/)\n\nthe code is available on the project [github](https://github.com/deepmind/deepmind-research/-----> tree !!! /master/neural_mip_solving). the paper *solving mixed integer programs using neural networks* is on [arxiv](https://arxiv.org/abs/2012.13349).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 40, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ox4qyv/r_deepmind_google_use_neural_networks_to_solve/',)", "identifyer": 5735309, "year": "2021"}, {"autor": "this_username_is_tkn", "date": 1620337867000, "content": "[Research] Seeing use of ML for ordinary work puts a smile on my face. /!/ The objective of this paper is to find an alternative to conventional method of concrete mix design. For finding the alternative, 4 machine learning algorithms viz. multi-variable linear regression, Support Vector Regression, Decision Tree Regression and Artificial Neural Network for designing concrete mix of desired properties. \n\n[original Article ](https://dx.doi.org/10.22115/scce.2021.248779.1257)", "link": "https://www.reddit.com/r/MachineLearning/comments/n6iqjz/research_seeing_use_of_ml_for_ordinary_work_puts/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[research] seeing use of ml for ordinary work puts a smile on my face. /!/ the objective of this paper is to find an alternative to conventional method of concrete mix design. for finding the alternative, 4 machine learning algorithms viz. multi-variable linear regression, support vector regression, decision -----> tree !!!  regression and artificial neural network for designing concrete mix of desired properties. \n\n[original article ](https://dx.doi.org/10.22115/scce.2021.248779.1257)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n6iqjz/research_seeing_use_of_ml_for_ordinary_work_puts/',)", "identifyer": 5735539, "year": "2021"}, {"autor": "ottawalanguages", "date": 1620111466000, "content": "[D] Inevitable Manual Work Required in Machine Learning Projects /!/ I have feeling that not many people are willing to admit - but ultimately, is a significant part of many data mining projects (e.g. checking data quality, parsing through data, etc.) still done manually? \n\nFor example here is an example I just made up relating to Supervised NLP (Natural Language Processing) Classification : Suppose I have 1000 medical reports of patients, containing unstructured text made by a doctor during a hospital visit. For a given patient, each report contains all the text notes that the doctor made for that patient, for visits between 2010 and 2020. These reports make mention of the patients bio data (e.g. age, gender, medical history, etc.) and the details of the symptoms that the patient is experiencing over a long period of time (e.g. let's say that these reports are 2000 words on average). The problem is, different doctors have different styles of writing - each of these 1000 reports is different from another. If a human were to read the report, the human could figure out what happened to the patient - did the patient have a serious condition (let's call this \"class 1\") or a non-serious condition (let's call this \"class 0\"). This is what we are interested in predicting for future patients based on the limited medical notes made by doctors for these future patients. \n\nThe problem is - there is no clear and fast way (not that I know of) to take the 1000 medical reports that are available, and label each report as \"class 1\" or \"class 0\". For example, for \"class 0\" : one of the doctors could clearly write at the end of a report \"all medical tests were conducted and the results and were all negative\", and another doctor could end the report by saying \"the patient should seriously consider changing their lifestyle and eat healthier food. benign.\" . \n\nIn this example, how would someone assign labels to all these 1000 cases, without manually reading them and deciding if the information in the report corresponds to a \"serious condition\" or a \"non-serious condition\"? I was thinking of using something like \"sentiment analysis\" to capture the \"mood\" of these reports, and use sentiment analysis a method to informally gauge if the tone of the report is \"dark\" (serious condition) or \"light\" (non serious condition). But I am not sure if this is the best way to approach this problem. Is there a way to do this without reading all the reports and manually deciding labels?\n\nIn the end - this is what I am interested in doing : suppose a new patient comes in and on the first visit, the doctor makes some quick notes (e.g. patient is male, 30 years old, 180 cm, 100 kg, non-smoker, frequently complains of chest pains, no high blood pressure, works a construction worker and takes daily medicine for acid reflex). Just based on these quick notes and the 1000 reports available (NOTE: I am trying to illustrate a point here, that the medical notes for the new patient and the 1000 reports DO NOT have the same format), can a researcher predict (supervised classification, e.g. decision tree) if this patient will have a \"serious\" or a \"non-serious\" condition?\n\nPS: suppose the doctors have a very detailed medical encyclopedia on their computers - can this medical encyclopedia be used alongside the 1000 medical reports to improve the prediction results?", "link": "https://www.reddit.com/r/MachineLearning/comments/n4i1u9/d_inevitable_manual_work_required_in_machine/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] inevitable manual work required in machine learning projects /!/ i have feeling that not many people are willing to admit - but ultimately, is a significant part of many data mining projects (e.g. checking data quality, parsing through data, etc.) still done manually? \n\nfor example here is an example i just made up relating to supervised nlp (natural language processing) classification : suppose i have 1000 medical reports of patients, containing unstructured text made by a doctor during a hospital visit. for a given patient, each report contains all the text notes that the doctor made for that patient, for visits between 2010 and 2020. these reports make mention of the patients bio data (e.g. age, gender, medical history, etc.) and the details of the symptoms that the patient is experiencing over a long period of time (e.g. let's say that these reports are 2000 words on average). the problem is, different doctors have different styles of writing - each of these 1000 reports is different from another. if a human were to read the report, the human could figure out what happened to the patient - did the patient have a serious condition (let's call this \"class 1\") or a non-serious condition (let's call this \"class 0\"). this is what we are interested in predicting for future patients based on the limited medical notes made by doctors for these future patients. \n\nthe problem is - there is no clear and fast way (not that i know of) to take the 1000 medical reports that are available, and label each report as \"class 1\" or \"class 0\". for example, for \"class 0\" : one of the doctors could clearly write at the end of a report \"all medical tests were conducted and the results and were all negative\", and another doctor could end the report by saying \"the patient should seriously consider changing their lifestyle and eat healthier food. benign.\" . \n\nin this example, how would someone assign labels to all these 1000 cases, without manually reading them and deciding if the information in the report corresponds to a \"serious condition\" or a \"non-serious condition\"? i was thinking of using something like \"sentiment analysis\" to capture the \"mood\" of these reports, and use sentiment analysis a method to informally gauge if the tone of the report is \"dark\" (serious condition) or \"light\" (non serious condition). but i am not sure if this is the best way to approach this problem. is there a way to do this without reading all the reports and manually deciding labels?\n\nin the end - this is what i am interested in doing : suppose a new patient comes in and on the first visit, the doctor makes some quick notes (e.g. patient is male, 30 years old, 180 cm, 100 kg, non-smoker, frequently complains of chest pains, no high blood pressure, works a construction worker and takes daily medicine for acid reflex). just based on these quick notes and the 1000 reports available (note: i am trying to illustrate a point here, that the medical notes for the new patient and the 1000 reports do not have the same format), can a researcher predict (supervised classification, e.g. decision -----> tree !!! ) if this patient will have a \"serious\" or a \"non-serious\" condition?\n\nps: suppose the doctors have a very detailed medical encyclopedia on their computers - can this medical encyclopedia be used alongside the 1000 medical reports to improve the prediction results?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 19, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n4i1u9/d_inevitable_manual_work_required_in_machine/',)", "identifyer": 5735645, "year": "2021"}, {"autor": "Vivid_Perception_143", "date": 1612853680000, "content": "[Project] - 9th Grade Machine Learning Library : SeaLion /!/ Hello [r/MachineLearning](https://www.reddit.com/r/MachineLearning/)! I've something I think you'll find very interesting.\n\nRecently during the first semester of my 9th grade I've worked on a library called [SeaLion](https://pypi.org/project/sealion/) (from scratch.) It is for machine learning algorithms, from the basic linear regression up to neural networks.\n\nRecently SeaLion has gained some popularity (77 stars + 4 forks), so I thought I should share it with this subreddit. Some information : SeaLion uses Python and also Cython in the back, and took 3 months to build and is about 5k+ lines. I've currently gone through 80+ releases in the last month, so the library is very well-maintained.\n\nYou can install this library with pip. It's on PyPI : [https://pypi.org/project/sealion/](https://pypi.org/project/sealion/) and GitHub : [SeaLion Repo](https://github.com/anish-lakkapragada/SeaLion)\n\nOkay enough talk, so what is this thing?\n\n**SeaLion is a machine learning library that's extremely comprehensive. Rather than assuming you know the theory behind the algorithms it guides you every step of the way. It mostly deals with regression, unsupervised clustering, bayesian models, dimensionality reduction, neural networks, etc. There are code examples that explain each function in SeaLion, how to use it, and most importantly why and when to use it.**\n\nThe code examples are a set of 12 jupyter notebooks. They tackle real world datasets/problems like breast cancer, iris, moons, titanic, spam classification, MNIST, etc. with SeaLion's algorithms. You can find the code examples here : [SeaLion Example Code](https://github.com/anish-lakkapragada/SeaLion/tree/main/examples)\n\nSeaLion is also incredibly easy to use. The naming of the functions and classes was deliberately made similar to most other ML frameworks so those already with experience can easily pick up SeaLion to give me feedback or use it. None of the actual source code uses any ML frameworks of course.\n\nI think not just beginners, but even those who are familiar with machine learning algorithms would greatly benefit from using it and going through any of the example notebooks. And on a side not, please give the repo a star!\n\n**If you have any feedback, suggestions, or questions please put them in the comments below. I'm really hoping to get feedback from this community. This could be on code practices, how to make the code go faster (I got a really good issue on GitHub for that), more algorithms I could build, etc.**\n\nAs usual thank you for your time! I really hope this is helpful for others.", "link": "https://www.reddit.com/r/MachineLearning/comments/lfwtgb/project_9th_grade_machine_learning_library_sealion/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[project] - 9th grade machine learning library : sealion /!/ hello [r/machinelearning](https://www.reddit.com/r/machinelearning/)! i've something i think you'll find very interesting.\n\nrecently during the first semester of my 9th grade i've worked on a library called [sealion](https://pypi.org/project/sealion/) (from scratch.) it is for machine learning algorithms, from the basic linear regression up to neural networks.\n\nrecently sealion has gained some popularity (77 stars + 4 forks), so i thought i should share it with this subreddit. some information : sealion uses python and also cython in the back, and took 3 months to build and is about 5k+ lines. i've currently gone through 80+ releases in the last month, so the library is very well-maintained.\n\nyou can install this library with pip. it's on pypi : [https://pypi.org/project/sealion/](https://pypi.org/project/sealion/) and github : [sealion repo](https://github.com/anish-lakkapragada/sealion)\n\nokay enough talk, so what is this thing?\n\n**sealion is a machine learning library that's extremely comprehensive. rather than assuming you know the theory behind the algorithms it guides you every step of the way. it mostly deals with regression, unsupervised clustering, bayesian models, dimensionality reduction, neural networks, etc. there are code examples that explain each function in sealion, how to use it, and most importantly why and when to use it.**\n\nthe code examples are a set of 12 jupyter notebooks. they tackle real world datasets/problems like breast cancer, iris, moons, titanic, spam classification, mnist, etc. with sealion's algorithms. you can find the code examples here : [sealion example code](https://github.com/anish-lakkapragada/sealion/-----> tree !!! /main/examples)\n\nsealion is also incredibly easy to use. the naming of the functions and classes was deliberately made similar to most other ml frameworks so those already with experience can easily pick up sealion to give me feedback or use it. none of the actual source code uses any ml frameworks of course.\n\ni think not just beginners, but even those who are familiar with machine learning algorithms would greatly benefit from using it and going through any of the example notebooks. and on a side not, please give the repo a star!\n\n**if you have any feedback, suggestions, or questions please put them in the comments below. i'm really hoping to get feedback from this community. this could be on code practices, how to make the code go faster (i got a really good issue on github for that), more algorithms i could build, etc.**\n\nas usual thank you for your time! i really hope this is helpful for others.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 13, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lfwtgb/project_9th_grade_machine_learning_library_sealion/',)", "identifyer": 5735747, "year": "2021"}, {"autor": "Vivid_Perception_143", "date": 1612853588000, "content": "[Project] - 9th Grade Machine Learning Library : SeaLion /!/ Hello [r/MachineLearning](https://www.reddit.com/r/MachineLearning/)! I've something I think you'll find very interesting.\n\nRecently during the first semester of my 9th grade I've worked on a library called [SeaLion](https://pypi.org/project/sealion/) (from scratch.) It is for machine learning algorithms, from the basic linear regression up to neural networks.\n\nRecently SeaLion has gained some popularity (77 stars + 4 forks), so I thought I should share it with this subreddit. Some information : SeaLion uses Python and also Cython in the back, and took 3 months to build and is about 5k+ lines. I've currently gone through 80+ releases in the last month, so the library is very well-maintained.\n\nYou can install this library with pip. It's on PyPI : [https://pypi.org/project/sealion/](https://pypi.org/project/sealion/) and GitHub : [SeaLion Repo](https://github.com/anish-lakkapragada/SeaLion)\n\nOkay enough talk, so what is this thing?\n\n**SeaLion is a machine learning library that's extremely comprehensive. Rather than assuming you know the theory behind the algorithms it guides you every step of the way. It mostly deals with regression, unsupervised clustering, bayesian models, dimensionality reduction, neural networks, etc. There are code examples that explain each function in SeaLion, how to use it, and most importantly why and when to use it.**\n\nThe code examples are a set of 12 jupyter notebooks. They tackle real world datasets/problems like breast cancer, iris, moons, titanic, spam classification, MNIST, etc. with SeaLion's algorithms. You can find the code examples here : [SeaLion Example Code](https://github.com/anish-lakkapragada/SeaLion/tree/main/examples)\n\nSeaLion is also incredibly easy to use. The naming of the functions and classes was deliberately made similar to most other ML frameworks so those already with experience can easily pick up SeaLion to give me feedback or use it. None of the actual source code uses any ML frameworks of course.\n\nI think not just beginners, but even those who are familiar with machine learning algorithms would greatly benefit from using it and going through any of the example notebooks. And on a side not, please give the repo a star!\n\n**If you have any feedback, suggestions, or questions please put them in the comments below. I'm really hoping to get feedback from this community. This could be on code practices, how to make the code go faster (I got a really good issue on GitHub for that), more algorithms I could build, etc.**\n\nAs usual thank you for your time! I really hope this is helpful for others.", "link": "https://www.reddit.com/r/MachineLearning/comments/lfwsos/project_9th_grade_machine_learning_library_sealion/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[project] - 9th grade machine learning library : sealion /!/ hello [r/machinelearning](https://www.reddit.com/r/machinelearning/)! i've something i think you'll find very interesting.\n\nrecently during the first semester of my 9th grade i've worked on a library called [sealion](https://pypi.org/project/sealion/) (from scratch.) it is for machine learning algorithms, from the basic linear regression up to neural networks.\n\nrecently sealion has gained some popularity (77 stars + 4 forks), so i thought i should share it with this subreddit. some information : sealion uses python and also cython in the back, and took 3 months to build and is about 5k+ lines. i've currently gone through 80+ releases in the last month, so the library is very well-maintained.\n\nyou can install this library with pip. it's on pypi : [https://pypi.org/project/sealion/](https://pypi.org/project/sealion/) and github : [sealion repo](https://github.com/anish-lakkapragada/sealion)\n\nokay enough talk, so what is this thing?\n\n**sealion is a machine learning library that's extremely comprehensive. rather than assuming you know the theory behind the algorithms it guides you every step of the way. it mostly deals with regression, unsupervised clustering, bayesian models, dimensionality reduction, neural networks, etc. there are code examples that explain each function in sealion, how to use it, and most importantly why and when to use it.**\n\nthe code examples are a set of 12 jupyter notebooks. they tackle real world datasets/problems like breast cancer, iris, moons, titanic, spam classification, mnist, etc. with sealion's algorithms. you can find the code examples here : [sealion example code](https://github.com/anish-lakkapragada/sealion/-----> tree !!! /main/examples)\n\nsealion is also incredibly easy to use. the naming of the functions and classes was deliberately made similar to most other ml frameworks so those already with experience can easily pick up sealion to give me feedback or use it. none of the actual source code uses any ml frameworks of course.\n\ni think not just beginners, but even those who are familiar with machine learning algorithms would greatly benefit from using it and going through any of the example notebooks. and on a side not, please give the repo a star!\n\n**if you have any feedback, suggestions, or questions please put them in the comments below. i'm really hoping to get feedback from this community. this could be on code practices, how to make the code go faster (i got a really good issue on github for that), more algorithms i could build, etc.**\n\nas usual thank you for your time! i really hope this is helpful for others.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lfwsos/project_9th_grade_machine_learning_library_sealion/',)", "identifyer": 5735748, "year": "2021"}, {"autor": "axyz1995", "date": 1612843952000, "content": "[D] How does one express a decision tree as an analytic function one can compute gradients for? (gradient boosting) /!/ This has really confused me. Most online explanatjons for Gradient Boosting say that one chooses a model, be it a linear function or a tree etc, does inference, then computes the difference between the predictions and the true value and then fit the data to the derivative of the Loss function with respect to the function chosen earlier.  I understand what derivate with respect to a function means but what does it mean to fit my data to that derivative?\n\nAlso, how does one express a decision tree(weak learner) analytically? \n\nThanks", "link": "https://www.reddit.com/r/MachineLearning/comments/lfuaev/d_how_does_one_express_a_decision_tree_as_an/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] how does one express a decision -----> tree !!!  as an analytic function one can compute gradients for? (gradient boosting) /!/ this has really confused me. most online explanatjons for gradient boosting say that one chooses a model, be it a linear function or a tree etc, does inference, then computes the difference between the predictions and the true value and then fit the data to the derivative of the loss function with respect to the function chosen earlier.  i understand what derivate with respect to a function means but what does it mean to fit my data to that derivative?\n\nalso, how does one express a decision tree(weak learner) analytically? \n\nthanks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 8, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lfuaev/d_how_does_one_express_a_decision_tree_as_an/',)", "identifyer": 5735755, "year": "2021"}, {"autor": "axyz1995", "date": 1612843452000, "content": "How does one express a decision tree as an analytic function that one can compute gradients for ? (gradient boosting) /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/lfu58h/how_does_one_express_a_decision_tree_as_an/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "how does one express a decision -----> tree !!!  as an analytic function that one can compute gradients for ? (gradient boosting) /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lfu58h/how_does_one_express_a_decision_tree_as_an/',)", "identifyer": 5735756, "year": "2021"}, {"autor": "gfursin", "date": 1632401926000, "content": "[N] MLCommons\u2122 releases MLPerf\u2122 Inference v1.1 Results with over 1,800 performance and 350 power results for data centers and edge devices /!/ * [MLCommons press-release](https://mlcommons.org/en/news/mlperf-inference-v11/)\n* [Datacenter results](https://mlcommons.org/en/inference-datacenter-11/)\n* [Edge results](https://mlcommons.org/en/inference-edge-11/)\n* [Reproducibility studies](https://github.com/mlcommons/ck/tree/master/docs/mlperf-automation/reproduce#reproducibility-reports-mlperf-inference-benchmark-v11)", "link": "https://www.reddit.com/r/MachineLearning/comments/ptuon5/n_mlcommons_releases_mlperf_inference_v11_results/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[n] mlcommons\u2122 releases mlperf\u2122 inference v1.1 results with over 1,800 performance and 350 power results for data centers and edge devices /!/ * [mlcommons press-release](https://mlcommons.org/en/news/mlperf-inference-v11/)\n* [datacenter results](https://mlcommons.org/en/inference-datacenter-11/)\n* [edge results](https://mlcommons.org/en/inference-edge-11/)\n* [reproducibility studies](https://github.com/mlcommons/ck/-----> tree !!! /master/docs/mlperf-automation/reproduce#reproducibility-reports-mlperf-inference-benchmark-v11)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ptuon5/n_mlcommons_releases_mlperf_inference_v11_results/',)", "identifyer": 5735843, "year": "2021"}, {"autor": "MrAchillesTurtle", "date": 1632664610000, "content": "[D] Which approaches for hyperparameter optimization with bayesian optimization can handle continuous and discrete variables? /!/ So far it is clear, that one-hot encoding with Gaussian Processes or some surrogate models such as Tree Parzen-estimators and Random Forests can naturally handle categorical as well as real-values variables when used for hyperparameter optimization with Gaussian Processes.\n\nI want to optimize a search space of mixed variables. Which other approaches are there?\n\nFor Gaussian Processes I found the following helpful reference:\n\n[Dealing with categorical and integer-valued variables in Bayesian Optimization with Gaussian Processes](https://www.sciencedirect.com/science/article/abs/pii/S0925231219315619?casa_token=eisknxvQ608AAAAA:UMq0POv1xZiyOmfx3tH1ooiAUBMrWdeU4PUCJJgq9po_ngXs992MvVw-2j5b9POMrfiS22NhrbWb)\n\nBut how about approaches such as Neural Networks?\n\n#", "link": "https://www.reddit.com/r/MachineLearning/comments/pvuboo/d_which_approaches_for_hyperparameter/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] which approaches for hyperparameter optimization with bayesian optimization can handle continuous and discrete variables? /!/ so far it is clear, that one-hot encoding with gaussian processes or some surrogate models such as -----> tree !!!  parzen-estimators and random forests can naturally handle categorical as well as real-values variables when used for hyperparameter optimization with gaussian processes.\n\ni want to optimize a search space of mixed variables. which other approaches are there?\n\nfor gaussian processes i found the following helpful reference:\n\n[dealing with categorical and integer-valued variables in bayesian optimization with gaussian processes](https://www.sciencedirect.com/science/article/abs/pii/s0925231219315619?casa_token=eisknxvq608aaaaa:umq0pov1xziyomfx3th1ooiaubmrwdeu4pucjjgq9po_ngxs992mvvw-2j5b9pomrfis22nhrbwb)\n\nbut how about approaches such as neural networks?\n\n#", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pvuboo/d_which_approaches_for_hyperparameter/',)", "identifyer": 5735889, "year": "2021"}, {"autor": "DineshPiyasamara", "date": 1632661358000, "content": "Decision Tree Algorithm /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/pvtetv/decision_tree_algorithm/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "decision -----> tree !!!  algorithm /!/ [removed]", "sortedWord": "None", "removed": "('reddit',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pvtetv/decision_tree_algorithm/',)", "identifyer": 5735893, "year": "2021"}, {"autor": "poppear", "date": 1631806797000, "content": "[P] easyopt: zero-code hyperparameters optimization framework /!/ I got tired of writing over and over again the same boilerplate code to do hyperparameters optimization so i built [easyopt](https://github.com/galatolofederico/easyopt)\n\nIt is basically an [optuna](https://optuna.org/) wrapper that does all the boring stuff for you.\n\nYou just have to write a simple YAML file and run `easyopt create` to create a study and `easyopt agent &lt;study_name&gt;` to run the optimization agent.\n\nIt supports all the optuna nice features such as:\n\n&amp;#x200B;\n\n* Distributed Parallel Optimization\n* Real Time Pruning\n* A wide variety of sampling strategies  \n   * Tree-structured Parzen Estimator\n   * CMA-ES\n   * Grid Search\n   * Random Search\n* A wide variety of pruning strategies  \n   * Asynchronous Successive Halving Pruning\n   * Hyperband Pruning\n   * Median Pruning\n   * Threshold Pruning\n* A wide variety of DBMSs  \n   * Redis\n   * SQLite\n   * PostgreSQL\n   * MySQL\n   * Oracle\n   * And many [more](https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine)\n\n&amp;#x200B;\n\nWith some bonuses like:\n\n* YAML Configuration\n* Experiments Monitoring and Crash Recovering\n* Experiments Replicas\n\n&amp;#x200B;\n\nYou can find the project here: [https://github.com/galatolofederico/easyopt](https://github.com/galatolofederico/easyopt)\n\n&amp;#x200B;\n\nI would love to hear some feedback!", "link": "https://www.reddit.com/r/MachineLearning/comments/ppfqlr/p_easyopt_zerocode_hyperparameters_optimization/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] easyopt: zero-code hyperparameters optimization framework /!/ i got tired of writing over and over again the same boilerplate code to do hyperparameters optimization so i built [easyopt](https://github.com/galatolofederico/easyopt)\n\nit is basically an [optuna](https://optuna.org/) wrapper that does all the boring stuff for you.\n\nyou just have to write a simple yaml file and run `easyopt create` to create a study and `easyopt agent &lt;study_name&gt;` to run the optimization agent.\n\nit supports all the optuna nice features such as:\n\n&amp;#x200b;\n\n* distributed parallel optimization\n* real time pruning\n* a wide variety of sampling strategies  \n   * -----> tree !!! -structured parzen estimator\n   * cma-es\n   * grid search\n   * random search\n* a wide variety of pruning strategies  \n   * asynchronous successive halving pruning\n   * hyperband pruning\n   * median pruning\n   * threshold pruning\n* a wide variety of dbmss  \n   * redis\n   * sqlite\n   * postgresql\n   * mysql\n   * oracle\n   * and many [more](https://docs.sqlalchemy.org/en/14/core/engines.html#sqlalchemy.create_engine)\n\n&amp;#x200b;\n\nwith some bonuses like:\n\n* yaml configuration\n* experiments monitoring and crash recovering\n* experiments replicas\n\n&amp;#x200b;\n\nyou can find the project here: [https://github.com/galatolofederico/easyopt](https://github.com/galatolofederico/easyopt)\n\n&amp;#x200b;\n\ni would love to hear some feedback!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ppfqlr/p_easyopt_zerocode_hyperparameters_optimization/',)", "identifyer": 5736041, "year": "2021"}, {"autor": "jesuswr", "date": 1632094877000, "content": "[D] Question about text classification without labeled data /!/ Hello!\n\nI am working on a text classifier but at the moment im quite lost on what to do.\n\nThe classes form a tree with three levels, for example: class A (level 1), class A.1 (level 2, subclass of A) and class A.1.a (level 3, subclass of A.1).\n\nI have a lot of texts but without labels, also its hard to create a set of labeled data because of the big number of classes.\n\nI've looked at word embeddings, clustering algorithms, topic modeling, keyword extraction algorithms and other approaches but im not sure whats would be a good way to proceed.\n\nAlso im not sure how to evaluate the success of the classifier, maybe i could build a small dataset but i wanted to know if there was any other option\n\nAt the moment the idea that i like most is classifying by the level of the class, for example: given a text t, get the first level class of t, lets say B, then get the second level class of t (only taking the subclasses of B), lets say B.4, and finally get the third level class of t (only taking the subclasses of B.4), lets say B.4.c, and finally we could say that the class of t is B.4.c.\n\nSo i wanted to ask here for advices to continue on this classifier and evaluate its success, thanks! :)", "link": "https://www.reddit.com/r/MachineLearning/comments/prj734/d_question_about_text_classification_without/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] question about text classification without labeled data /!/ hello!\n\ni am working on a text classifier but at the moment im quite lost on what to do.\n\nthe classes form a -----> tree !!!  with three levels, for example: class a (level 1), class a.1 (level 2, subclass of a) and class a.1.a (level 3, subclass of a.1).\n\ni have a lot of texts but without labels, also its hard to create a set of labeled data because of the big number of classes.\n\ni've looked at word embeddings, clustering algorithms, topic modeling, keyword extraction algorithms and other approaches but im not sure whats would be a good way to proceed.\n\nalso im not sure how to evaluate the success of the classifier, maybe i could build a small dataset but i wanted to know if there was any other option\n\nat the moment the idea that i like most is classifying by the level of the class, for example: given a text t, get the first level class of t, lets say b, then get the second level class of t (only taking the subclasses of b), lets say b.4, and finally get the third level class of t (only taking the subclasses of b.4), lets say b.4.c, and finally we could say that the class of t is b.4.c.\n\nso i wanted to ask here for advices to continue on this classifier and evaluate its success, thanks! :)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/prj734/d_question_about_text_classification_without/',)", "identifyer": 5736100, "year": "2021"}, {"autor": "7Seas_ofRyhme", "date": 1632066906000, "content": "[D] Examples of tree based machine learning algorithms? /!/ Aside from Decision Tree and Random Forest, what are the other options I can consider to make a comparison ?", "link": "https://www.reddit.com/r/MachineLearning/comments/prajtb/d_examples_of_tree_based_machine_learning/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] examples of -----> tree !!!  based machine learning algorithms? /!/ aside from decision tree and random forest, what are the other options i can consider to make a comparison ?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 3, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/prajtb/d_examples_of_tree_based_machine_learning/',)", "identifyer": 5736123, "year": "2021"}, {"autor": "JoyBannerG", "date": 1615549233000, "content": "[D] Looking for CART/ML model that works with relative data. /!/ I am a beginner at AI and ML. I have been given a dataset, where I have noticed the columns are relative to one another. So is there any CART or ML model that can work with relative data ?\n\nFor example in Decision Tree, the tree looks like :\n\n    if X[0]&lt;192:      \n        if X[1]&gt;24:        \n          if X[2]&lt;12:        \n            ... \n\nI'm looking for a Decision Tree, that works like this :\n\n     if X[0]&gt;X[1]:    \n        if X[1]&lt;X[2]:       \n          ... \n\nIs there any such Machine Learning Model ?", "link": "https://www.reddit.com/r/MachineLearning/comments/m3ftmc/d_looking_for_cartml_model_that_works_with/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] looking for cart/ml model that works with relative data. /!/ i am a beginner at ai and ml. i have been given a dataset, where i have noticed the columns are relative to one another. so is there any cart or ml model that can work with relative data ?\n\nfor example in decision -----> tree !!! , the -----> tree !!!  looks like :\n\n    if x[0]&lt;192:      \n        if x[1]&gt;24:        \n          if x[2]&lt;12:        \n            ... \n\ni'm looking for a decision tree, that works like this :\n\n     if x[0]&gt;x[1]:    \n        if x[1]&lt;x[2]:       \n          ... \n\nis there any such machine learning model ?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/m3ftmc/d_looking_for_cartml_model_that_works_with/',)", "identifyer": 5736478, "year": "2021"}, {"autor": "Techbiason", "date": 1609475331000, "content": "Decision Tree Algorithm in Machine Learning", "link": "https://www.reddit.com/r/MachineLearning/comments/ko4yx5/decision_tree_algorithm_in_machine_learning/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "decision -----> tree !!!  algorithm in machine learning", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('image',)", "medialink": "('https://i.redd.it/iu6sypxl1n861.jpg',)", "identifyer": 5736526, "year": "2021"}, {"autor": "SamiHaijaML", "date": 1614079246000, "content": "[R] TensorFlow Functional Implementation of Singular Value Decomposition (SVD) /!/ We have developed and open-sourced Singular Value Decomposition (SVD) Functional for TensorFlow ([tf-fsvd](https://github.com/samihaija/tf-fsvd)) that computes SVD of a matrix **M**, without requiring explicit computation of **M**.\n\nYou might find our implementation useful if:\n\n* You want to run SVD on a sparse matrix in TensorFlow (our code, out of the box, provides a specialization of tf.linalg.svd onto sparse matrices)\n* You want to run SVD on a dense matrix **M** (that is expensive to compute). However, your matrix **M** is structured (e.g. geometric sum of sparse matrices), such that, multiplying **M** by vectors is much cheaper than explicitly constructing **M**.\n\n# Application on Graphs\n\nWe applied our practical implementation on a handful of graph learning problems, allowing us to obtain closed-form solutions to *link prediction* and *node classification* tasks. Our [implementations](https://github.com/samihaija/tf-fsvd/tree/main/implementations) (over tf-fsvd) are **simple** per method (handful of lines per implementation, less hyperparameters) with significant **training speedups**, and **strong performance metrics** (on test sets, setting competitive or state-of-the-art results).\n\nThere are many amazing powerful GNNs out there (GCN, GIN, GAT, JKN, MixHop, and the list only goes longer) that could take a long time to train (sometimes many minutes, even on tiny datasets, and only grows with dataset size). Tuning hyperparameters could also take time (dozens of runs with various layer dimensions, learning rates, regularizations coefficients, etc). Our method provides a way for making strong baselines (that also happened to set the SOTA on Drug-Drug Interactions network), again, while training much faster (in a tiny fraction of training time, compared to other strong-performing methods)\n\nWe hope you find our implementation useful and our paper interesting. The [full paper is on ArXiv](https://arxiv.org/abs/2102.08530).", "link": "https://www.reddit.com/r/MachineLearning/comments/lqg3z9/r_tensorflow_functional_implementation_of/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] tensorflow functional implementation of singular value decomposition (svd) /!/ we have developed and open-sourced singular value decomposition (svd) functional for tensorflow ([tf-fsvd](https://github.com/samihaija/tf-fsvd)) that computes svd of a matrix **m**, without requiring explicit computation of **m**.\n\nyou might find our implementation useful if:\n\n* you want to run svd on a sparse matrix in tensorflow (our code, out of the box, provides a specialization of tf.linalg.svd onto sparse matrices)\n* you want to run svd on a dense matrix **m** (that is expensive to compute). however, your matrix **m** is structured (e.g. geometric sum of sparse matrices), such that, multiplying **m** by vectors is much cheaper than explicitly constructing **m**.\n\n# application on graphs\n\nwe applied our practical implementation on a handful of graph learning problems, allowing us to obtain closed-form solutions to *link prediction* and *node classification* tasks. our [implementations](https://github.com/samihaija/tf-fsvd/-----> tree !!! /main/implementations) (over tf-fsvd) are **simple** per method (handful of lines per implementation, less hyperparameters) with significant **training speedups**, and **strong performance metrics** (on test sets, setting competitive or state-of-the-art results).\n\nthere are many amazing powerful gnns out there (gcn, gin, gat, jkn, mixhop, and the list only goes longer) that could take a long time to train (sometimes many minutes, even on tiny datasets, and only grows with dataset size). tuning hyperparameters could also take time (dozens of runs with various layer dimensions, learning rates, regularizations coefficients, etc). our method provides a way for making strong baselines (that also happened to set the sota on drug-drug interactions network), again, while training much faster (in a tiny fraction of training time, compared to other strong-performing methods)\n\nwe hope you find our implementation useful and our paper interesting. the [full paper is on arxiv](https://arxiv.org/abs/2102.08530).", "sortedWord": "None", "removed": "('nan',)", "score": 26, "comments": 8, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lqg3z9/r_tensorflow_functional_implementation_of/',)", "identifyer": 5736762, "year": "2021"}, {"autor": "Aggressive-Cookie-64", "date": 1613984313000, "content": "[R] Classification problem/ Inbalanced data /!/ I have been banging my head over on a classification problem.\n\nMy outcome is a presence/ absence of disease with presence representing 7% of my data. I'm looking at multiple categorical predictors. Dataset consists of 4500 observations\n\nI used the SMOTE and Tomek link combo to balance my training data. After an initial filtering step to keep the most important variables ( Extra tree classifier), I looked at different classifiers and chose Random Forest as it provided better results. I chose the f1 as a scoring method and 5 folds to run my model on balanced training data and unbiased testing data (unbalanced). With all that, my model is still very good at detecting the majority class and pretty crappy at detecting my outcome of choice which is the presence of disease.\n\nDesperate to make this work. Thanks\n\n&amp;#x200B;\n\n*Processing img z1r95px2uzi61...*", "link": "https://www.reddit.com/r/MachineLearning/comments/lpjgqp/r_classification_problem_inbalanced_data/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] classification problem/ inbalanced data /!/ i have been banging my head over on a classification problem.\n\nmy outcome is a presence/ absence of disease with presence representing 7% of my data. i'm looking at multiple categorical predictors. dataset consists of 4500 observations\n\ni used the smote and tomek link combo to balance my training data. after an initial filtering step to keep the most important variables ( extra -----> tree !!!  classifier), i looked at different classifiers and chose random forest as it provided better results. i chose the f1 as a scoring method and 5 folds to run my model on balanced training data and unbiased testing data (unbalanced). with all that, my model is still very good at detecting the majority class and pretty crappy at detecting my outcome of choice which is the presence of disease.\n\ndesperate to make this work. thanks\n\n&amp;#x200b;\n\n*processing img z1r95px2uzi61...*", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lpjgqp/r_classification_problem_inbalanced_data/',)", "identifyer": 5736857, "year": "2021"}, {"autor": "CraftBeerMountaineer", "date": 1618876846000, "content": "[P] [D] Advice and suggestions on grouping estimates of individuals to produce better estimates with constraints. /!/ I am attempting to use different ML techniques from Python packages to improve Roger Cooke's method of assigning weights to individual estimates within a group. Each estimate is made by a different individual of which I have 20 attributes. Each estimate is a range with a 90% confidence interval. The goal is to assign weights in a way that minimizes the range interval (upper bound - lower bound) with the constraint that 90% of the group estimates contain the correct answer.\n\nI'm currently pursuing a decision tree regression to create a score for each individual that will later be used to assign weights. However, I have limited experience with ML in general and was wondering if anyone could provide advice on a better method.", "link": "https://www.reddit.com/r/MachineLearning/comments/mue268/p_d_advice_and_suggestions_on_grouping_estimates/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] [d] advice and suggestions on grouping estimates of individuals to produce better estimates with constraints. /!/ i am attempting to use different ml techniques from python packages to improve roger cooke's method of assigning weights to individual estimates within a group. each estimate is made by a different individual of which i have 20 attributes. each estimate is a range with a 90% confidence interval. the goal is to assign weights in a way that minimizes the range interval (upper bound - lower bound) with the constraint that 90% of the group estimates contain the correct answer.\n\ni'm currently pursuing a decision -----> tree !!!  regression to create a score for each individual that will later be used to assign weights. however, i have limited experience with ml in general and was wondering if anyone could provide advice on a better method.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mue268/p_d_advice_and_suggestions_on_grouping_estimates/',)", "identifyer": 5736868, "year": "2021"}, {"autor": "CKL-IT", "date": 1621528312000, "content": "[N] 1 line to visualizations for dependency trees, entity relationships, resolution, assertion, NER and new models for Afrikaans, Welsh, Maltese, Tamil, and Vietnamese - John Snow Labs NLU 3.0.1 for Python /!/ # NLU 3.0.1 Release Notes\nWe are very excited to announce NLU 3.0.1 has been released!\nThis is one of the most visually appealing releases, with the integration of the [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) library and visualizations for `dependency trees`, `entity resolution`, `entity assertion`, `relationship between entities` and `named\nentity recognition`. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+\nFinally, new multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese` are now available.\n\n\n\n\n# New Features and Enhancements\n- 1 line to visualization for `NER`, `Dependency`, `Resolution`, `Assertion` and `Relation` via [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) integration\n- Improved column naming schema\n- [Over 140 + NLU tutorial Notebooks updated](https://github.com/JohnSnowLabs/nlu/tree/master/examples) and improved to reflect latest changes in NLU 3.0.0 +\n- New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`\n- Enhanced offline loading\n\n\n## NLU visualization\nThe latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if\nSpark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don't need to worry about anything!\n\nSee the [visualization tutorial notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/visualization/NLU_visualizations_tutorial.ipynb)  and [visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples) for more info.\n\n![Cheat Sheet visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/cheat_sheet.png)\n\n## NER visualization\nApplicable to any of the [100+ NER models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition)\n```python\nnlu.load('ner').viz(\"Donald Trump from America and Angela Merkel from Germany don't share many oppinions.\")\n```\n![NER visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/NER.png)\n\n## Dependency tree visualization\nVisualizes the structure of the labeled dependency tree and part of speech tags\n```python\nnlu.load('dep.typed').viz(\"Billy went to the mall\")\n```\n\n![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP.png)\n\n```python\n#Bigger Example\nnlu.load('dep.typed').viz(\"Donald Trump from America and Angela Merkel from Germany don't share many oppinions but they both love John Snow Labs software\")\n```\n![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP_big.png)\n\n## Assertion status visualization\nVisualizes asserted statuses and entities.        \nApplicable to any of the [10 + Assertion models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Assertion+Status)\n```python\nnlu.load('med_ner.clinical assert').viz(\"The MRI scan showed no signs of cancer in the left lung\")\n```\n\n\n![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion.png)\n\n```python\n#bigger example\ndata ='This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.'\nnlu.load('med_ner.clinical assert').viz(data)\n```\n![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion_big.png)\n\n\n## Relationship between entities visualization\nVisualizes the extracted entities between relationship.    \nApplicable to any of the [20 + Relation Extractor models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Relation+Extraction)\n```python\nnlu.load('med_ner.jsl.wip.clinical relation.temporal_events').viz('The patient developed cancer after a mercury poisoning in 1999 ')\n```\n![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation.png)\n\n```python\n# bigger example\ndata = 'This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed'\npipe = nlu.load('med_ner.jsl.wip.clinical relation.clinical').viz(data)\n```\n![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation_big.png)\n\n\n## Entity Resolution visualization for chunks\nVisualizes resolutions of entities\nApplicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)\n```python\nnlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(\"He took Prevacid 30 mg  daily\")\n```\n![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk.png)\n\n```python\n# bigger example\ndata = \"This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\\'s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .\"\nnlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(data)\n```\n\n![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk_big.png)\n\n\n## Entity Resolution visualization for sentences\nVisualizes resolutions of entities in sentences\nApplicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)\n```python\nnlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz('She was diagnosed with a respiratory congestion')\n```\n![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence.png)\n\n```python\n# bigger example\ndata = 'The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion'\nnlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz(data)\n```\n![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence_big.png)\n\n## Configure visualizations\n### Define custom colors for labels\nSome entity and relation labels will be highlighted with a pre-defined color, which you [can find here](https://github.com/JohnSnowLabs/spark-nlp-display/tree/main/sparknlp_display/label_colors).    \nFor labels that have no color defined, a random color will be generated.     \nYou can define colors for labels manually, by specifying via the `viz_colors` parameter\nand defining `hex color codes` in a dictionary that maps `labels` to `colors` .\n```python\ndata = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'\n# Define custom colors for labels\nviz_colors={'STRENGTH':'#800080', 'DRUG_BRANDNAME':'#77b5fe', 'GENDER':'#77ffe'}\nnlu.load('med_ner.jsl.wip.clinical').viz(data,viz_colors =viz_colors)\n```\n![define colors labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/define_colors.png)\n\n\n### Filter entities that get highlighted\nBy default every entity class will be visualized.    \nThe `labels_to_viz` can be used to define a set of labels to highlight.       \nApplicable for ner, resolution and assert.\n```python\ndata = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'\n# Filter wich NER label to viz\nlabels_to_viz=['SYMPTOM']\nnlu.load('med_ner.jsl.wip.clinical').viz(data,labels_to_viz=labels_to_viz)\n```\n![filter labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/filter_labels.png)\n\n\n## New models\nNew multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`\n\n| nlu.load() Refrence                                          | Spark NLP Refrence                                           |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| [vi.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) |\n| [mt.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) |\n| [ta.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) |\n| [af.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) |\n| [af.pos](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) | [pos_afribooms](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) |\n| [cy.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) |\n\n## Reworked and updated NLU tutorial notebooks\n\nAll of the [140+ NLU tutorial Notebooks](https://github.com/JohnSnowLabs/nlu/tree/master/examples) have been updated and reworked to reflect the latest changes in NLU 3.0.0+\n\n\n## Improved Column Name generation\n- NLU categorized each internal component now with boolean labels for `name_deductable` and `always_name_deductable` .\n- Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the\n  pipe and there are multiple components of same type, i.e. multiple `NER` models, NLU will deduct a base name for the final output columns from the\n  NLU reference each NER model is pointing to.\n- If on the other hand, there is only one `NER` model in the pipeline, only the default `ner` column prefixed will be generated.\n- For some components, like `embeddings` and `classifiers` are now defined as `always_name_deductable`, for those NLU will always try to infer a meaningful base name for the output columns.\n- Newly trained component output columns will now be prefixed with `trained_&lt;type&gt;` , for types `pos` , `ner`, `cLassifier`, `sentiment` and `multi_classifier`\n\n## Enhanced offline mode\n- You can still load a model from a path as usual with `nlu.load(path=model_path)` and output columns will be suffixed with `from_disk`\n- You can now optionally also specify `request` parameter during  load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of `from_disk`, i.e. by calling `nlu.load(request ='en.embed_sentence.biobert.pubmed_pmc_base_cased', path=model_path)`\n\n\n### Bugfixes\n- Fixed a bug that caused  resolution algorithms output level to be inferred incorrectly\n- Fixed a bug that caused stranger cols got dropped\n- Fixed a bug that caused endings to miss when  .predict(position=True) was specified\n- Fixed a bug that caused pd.Series to be converted incorrectly internally\n- Fixed a bug that caused output level transformations to crash\n- Fixed a bug that caused verbose mode not to turn of properly after turning it on.\n- fixed a bug that caused some models to crash when loaded for HDD\n\n# Additional NLU resources\n* [140+ updates tutorials](https://github.com/JohnSnowLabs/nlu/tree/master/examples)\n* [Updated visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples)\n* [Models Hub](https://nlp.johnsnowlabs.com/models) with new models\n* [Spark NLP publications](https://medium.com/spark-nlp)\n* [NLU in Action](https://nlp.johnsnowlabs.com/demo)\n* [NLU documentation](https://nlu.johnsnowlabs.com/docs/en/install)\n* [Discussions](https://github.com/JohnSnowLabs/spark-nlp/discussions) Engage with other community members, share ideas, and show off how you use Spark NLP and NLU!\n\n# 1 line Install NLU on Google Colab\n```!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash```\n# 1 line Install NLU on Kaggle\n```!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash```\n# Install via PIP\n```! pip install nlu pyspark==3.0.1```", "link": "https://www.reddit.com/r/MachineLearning/comments/nh4rys/n_1_line_to_visualizations_for_dependency_trees/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[n] 1 line to visualizations for dependency trees, entity relationships, resolution, assertion, ner and new models for afrikaans, welsh, maltese, tamil, and vietnamese - john snow labs nlu 3.0.1 for python /!/ # nlu 3.0.1 release notes\nwe are very excited to announce nlu 3.0.1 has been released!\nthis is one of the most visually appealing releases, with the integration of the [spark-nlp-display](https://nlp.johnsnowlabs.com/docs/en/display) library and visualizations for `dependency trees`, `entity resolution`, `entity assertion`, `relationship between entities` and `named\nentity recognition`. in addition to this, the schema of how columns are named by nlu has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in nlu 3.0.0+\nfinally, new multilingual models for `afrikaans`, `welsh`, `maltese`, `tamil`, and`vietnamese` are now available.\n\n\n\n\n# new features and enhancements\n- 1 line to visualization for `ner`, `dependency`, `resolution`, `assertion` and `relation` via [spark-nlp-display](https://nlp.johnsnowlabs.com/docs/en/display) integration\n- improved column naming schema\n- [over 140 + nlu tutorial notebooks updated](https://github.com/johnsnowlabs/nlu/-----> tree !!! /master/examples) and improved to reflect latest changes in nlu 3.0.0 +\n- new multilingual models for `afrikaans`, `welsh`, `maltese`, `tamil`, and`vietnamese`\n- enhanced offline loading\n\n\n## nlu visualization\nthe latest nlu release integrated the beautiful spark-nlp-display package visualizations. you do not need to worry about installing it, when you try to visualize something, nlu will check if\nspark-nlp-display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don't need to worry about anything!\n\nsee the [visualization tutorial notebook](https://github.com/johnsnowlabs/nlu/blob/master/examples/colab/visualization/nlu_visualizations_tutorial.ipynb)  and [visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples) for more info.\n\n![cheat sheet visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/cheat_sheet.png)\n\n## ner visualization\napplicable to any of the [100+ ner models! see here for an overview](https://nlp.johnsnowlabs.com/models?task=named+entity+recognition)\n```python\nnlu.load('ner').viz(\"donald trump from america and angela merkel from germany don't share many oppinions.\")\n```\n![ner visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/ner.png)\n\n## dependency tree visualization\nvisualizes the structure of the labeled dependency tree and part of speech tags\n```python\nnlu.load('dep.typed').viz(\"billy went to the mall\")\n```\n\n![dependency tree visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/dep.png)\n\n```python\n#bigger example\nnlu.load('dep.typed').viz(\"donald trump from america and angela merkel from germany don't share many oppinions but they both love john snow labs software\")\n```\n![dependency tree visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/dep_big.png)\n\n## assertion status visualization\nvisualizes asserted statuses and entities.        \napplicable to any of the [10 + assertion models! see here for an overview](https://nlp.johnsnowlabs.com/models?task=assertion+status)\n```python\nnlu.load('med_ner.clinical assert').viz(\"the mri scan showed no signs of cancer in the left lung\")\n```\n\n\n![assert visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/assertion.png)\n\n```python\n#bigger example\ndata ='this is the case of a very pleasant 46-year-old caucasian female, seen in clinic on 12/11/07 during which time mri of the left shoulder showed no evidence of rotator cuff tear. she did have a previous mri of the cervical spine that did show an osteophyte on the left c6-c7 level. based on this, negative mri of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at c6-c7 level. operation, expected outcome, risks, and benefits were discussed with her. risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. there is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. however, the patient may develop deeper-seated infection, which may require return to the operating room. should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. there is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. there is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. she understood all of these risks and agreed to have the procedure performed.'\nnlu.load('med_ner.clinical assert').viz(data)\n```\n![assert visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/assertion_big.png)\n\n\n## relationship between entities visualization\nvisualizes the extracted entities between relationship.    \napplicable to any of the [20 + relation extractor models see here for an overview](https://nlp.johnsnowlabs.com/models?task=relation+extraction)\n```python\nnlu.load('med_ner.jsl.wip.clinical relation.temporal_events').viz('the patient developed cancer after a mercury poisoning in 1999 ')\n```\n![entity relation visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/relation.png)\n\n```python\n# bigger example\ndata = 'this is the case of a very pleasant 46-year-old caucasian female, seen in clinic on 12/11/07 during which time mri of the left shoulder showed no evidence of rotator cuff tear. she did have a previous mri of the cervical spine that did show an osteophyte on the left c6-c7 level. based on this, negative mri of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at c6-c7 level. operation, expected outcome, risks, and benefits were discussed with her. risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. there is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. however, the patient may develop deeper-seated infection, which may require return to the operating room. should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. there is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. there is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. she understood all of these risks and agreed to have the procedure performed'\npipe = nlu.load('med_ner.jsl.wip.clinical relation.clinical').viz(data)\n```\n![entity relation visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/relation_big.png)\n\n\n## entity resolution visualization for chunks\nvisualizes resolutions of entities\napplicable to any of the [100+ resolver models see here for an overview](https://nlp.johnsnowlabs.com/models?task=entity+resolution)\n```python\nnlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(\"he took prevacid 30 mg  daily\")\n```\n![chunk resolution visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/resolve_chunk.png)\n\n```python\n# bigger example\ndata = \"this is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , copd , gastritis , and tia who initially presented to braintree with a non-st elevation mi and guaiac positive stools , transferred to st . margaret\\'s center for women &amp; infants for cardiac catheterization with ptca to mid lad lesion complicated by hypotension and bradycardia requiring atropine , iv fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to ccu for close monitoring , hemodynamically stable at the time of admission to the ccu .\"\nnlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(data)\n```\n\n![chunk resolution visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/resolve_chunk_big.png)\n\n\n## entity resolution visualization for sentences\nvisualizes resolutions of entities in sentences\napplicable to any of the [100+ resolver models see here for an overview](https://nlp.johnsnowlabs.com/models?task=entity+resolution)\n```python\nnlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz('she was diagnosed with a respiratory congestion')\n```\n![sentence resolution visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/resolve_sentence.png)\n\n```python\n# bigger example\ndata = 'the patient is a 5-month-old infant who presented initially on monday with a cold, cough, and runny nose for 2 days. mom states she had no fever. her appetite was good but she was spitting up a lot. she had no difficulty breathing and her cough was described as dry and hacky. at that time, physical exam showed a right tm, which was red. left tm was okay. she was fairly congested but looked happy and playful. she was started on amoxil and aldex and we told to recheck in 2 weeks to recheck her ear. mom returned to clinic again today because she got much worse overnight. she was having difficulty breathing. she was much more congested and her appetite had decreased significantly today. she also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion'\nnlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz(data)\n```\n![sentence resolution visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/resolve_sentence_big.png)\n\n## configure visualizations\n### define custom colors for labels\nsome entity and relation labels will be highlighted with a pre-defined color, which you [can find here](https://github.com/johnsnowlabs/spark-nlp-display/tree/main/sparknlp_display/label_colors).    \nfor labels that have no color defined, a random color will be generated.     \nyou can define colors for labels manually, by specifying via the `viz_colors` parameter\nand defining `hex color codes` in a dictionary that maps `labels` to `colors` .\n```python\ndata = 'dr. john snow suggested that fritz takes 5mg penicilin for his cough'\n# define custom colors for labels\nviz_colors={'strength':'#800080', 'drug_brandname':'#77b5fe', 'gender':'#77ffe'}\nnlu.load('med_ner.jsl.wip.clinical').viz(data,viz_colors =viz_colors)\n```\n![define colors labels](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/define_colors.png)\n\n\n### filter entities that get highlighted\nby default every entity class will be visualized.    \nthe `labels_to_viz` can be used to define a set of labels to highlight.       \napplicable for ner, resolution and assert.\n```python\ndata = 'dr. john snow suggested that fritz takes 5mg penicilin for his cough'\n# filter wich ner label to viz\nlabels_to_viz=['symptom']\nnlu.load('med_ner.jsl.wip.clinical').viz(data,labels_to_viz=labels_to_viz)\n```\n![filter labels](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/filter_labels.png)\n\n\n## new models\nnew multilingual models for `afrikaans`, `welsh`, `maltese`, `tamil`, and`vietnamese`\n\n| nlu.load() refrence                                          | spark nlp refrence                                           |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| [vi.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) |\n| [mt.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) |\n| [ta.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) |\n| [af.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) |\n| [af.pos](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) | [pos_afribooms](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) |\n| [cy.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) |\n\n## reworked and updated nlu tutorial notebooks\n\nall of the [140+ nlu tutorial notebooks](https://github.com/johnsnowlabs/nlu/tree/master/examples) have been updated and reworked to reflect the latest changes in nlu 3.0.0+\n\n\n## improved column name generation\n- nlu categorized each internal component now with boolean labels for `name_deductable` and `always_name_deductable` .\n- before generating column names, nlu checks wether each component is of unique in the pipeline or not. if a component is not unique in the\n  pipe and there are multiple components of same type, i.e. multiple `ner` models, nlu will deduct a base name for the final output columns from the\n  nlu reference each ner model is pointing to.\n- if on the other hand, there is only one `ner` model in the pipeline, only the default `ner` column prefixed will be generated.\n- for some components, like `embeddings` and `classifiers` are now defined as `always_name_deductable`, for those nlu will always try to infer a meaningful base name for the output columns.\n- newly trained component output columns will now be prefixed with `trained_&lt;type&gt;` , for types `pos` , `ner`, `classifier`, `sentiment` and `multi_classifier`\n\n## enhanced offline mode\n- you can still load a model from a path as usual with `nlu.load(path=model_path)` and output columns will be suffixed with `from_disk`\n- you can now optionally also specify `request` parameter during  load a model from hdd, it will be used to deduct more meaningful column name suffixes, instead of `from_disk`, i.e. by calling `nlu.load(request ='en.embed_sentence.biobert.pubmed_pmc_base_cased', path=model_path)`\n\n\n### bugfixes\n- fixed a bug that caused  resolution algorithms output level to be inferred incorrectly\n- fixed a bug that caused stranger cols got dropped\n- fixed a bug that caused endings to miss when  .predict(position=true) was specified\n- fixed a bug that caused pd.series to be converted incorrectly internally\n- fixed a bug that caused output level transformations to crash\n- fixed a bug that caused verbose mode not to turn of properly after turning it on.\n- fixed a bug that caused some models to crash when loaded for hdd\n\n# additional nlu resources\n* [140+ updates tutorials](https://github.com/johnsnowlabs/nlu/tree/master/examples)\n* [updated visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples)\n* [models hub](https://nlp.johnsnowlabs.com/models) with new models\n* [spark nlp publications](https://medium.com/spark-nlp)\n* [nlu in action](https://nlp.johnsnowlabs.com/demo)\n* [nlu documentation](https://nlu.johnsnowlabs.com/docs/en/install)\n* [discussions](https://github.com/johnsnowlabs/spark-nlp/discussions) engage with other community members, share ideas, and show off how you use spark nlp and nlu!\n\n# 1 line install nlu on google colab\n```!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -o - | bash```\n# 1 line install nlu on kaggle\n```!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -o - | bash```\n# install via pip\n```! pip install nlu pyspark==3.0.1```", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nh4rys/n_1_line_to_visualizations_for_dependency_trees/',)", "identifyer": 5737169, "year": "2021"}, {"autor": "atif_hassan", "date": 1618641825000, "content": "[P] PyImpetus - A Markov Blanket based new SOTA feature selection algorithm for python /!/  PyImpetus is a Markov Blanket based **feature selection algorithm** that selects a subset of features by considering their performance both individually as well as a group. This allows the algorithm to not only select the best set of features but also select the **best set of features that play well with each other**. For example, the best performing feature might not play well with others while the remaining features, when taken together could out-perform the best feature. PyImpetus takes this into account and produces the best possible combination. Thus, the algorithm provides a minimal feature subset. So, **you do not have to decide on how many features to take. PyImpetus selects the optimal set for you.**\n\nPyImpetus has been completely revamped and now supports **binary classification, multi-class classification and regression** tasks. It has been tested on 14 datasets and outperformed state-of-the-art Markov Blanket learning algorithms on all of them along with traditional feature selection algorithms such as Forward Feature Selection, Backward Feature Elimination and Recursive Feature Elimination.\n\n&amp;#x200B;\n\nPerformance Comparison:\n\nFor classification tasks, Accuracy as a metric (higher score is better) has been used while for Regression tasks, Mean Squared Error as a metric (lower score is better) has been used. The final model used for comparison on all tasks is a decision tree with scores being reported on 5-fold cross validation.\n\n|**Dataset**|**# of samples**|**# of features**|**Task Type**|**Score using all features**|**Score using PyImpetus**|**# of features selected**|**% of features selected** |\n|:-|:-|:-|:-|:-|:-|:-|:-|\n|Ionosphere|351|34|Classification|88.01%|92.86%|14|42.42%|\n|Arcene|100|10000|Classification|82%|84.72%|304|3.04%|\n|AlonDS2000|62|2000|Classification|80.55%|88.49%|75|3.75%|\n|slice\\_localization\\_data|53500|384|Regression|6.54|5.69|259|67.45%|\n\n&amp;#x200B;\n\n[Link to the GitHub repo](https://github.com/atif-hassan/PyImpetus)\n\n[Link to pypi](https://pypi.org/project/PyImpetus/)\n\n&amp;#x200B;\n\nPyImpetus already has over 15K+ downloads so do check it out and please let me know how it worked out for you in your Machine Learning project. Don't forget to pen down your feedback and doubts in the comment section.\n\nAnd of course, don't forget to star the GitHub repo!!\n\nThank you and have an amazing day!", "link": "https://www.reddit.com/r/MachineLearning/comments/mslslg/p_pyimpetus_a_markov_blanket_based_new_sota/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] pyimpetus - a markov blanket based new sota feature selection algorithm for python /!/  pyimpetus is a markov blanket based **feature selection algorithm** that selects a subset of features by considering their performance both individually as well as a group. this allows the algorithm to not only select the best set of features but also select the **best set of features that play well with each other**. for example, the best performing feature might not play well with others while the remaining features, when taken together could out-perform the best feature. pyimpetus takes this into account and produces the best possible combination. thus, the algorithm provides a minimal feature subset. so, **you do not have to decide on how many features to take. pyimpetus selects the optimal set for you.**\n\npyimpetus has been completely revamped and now supports **binary classification, multi-class classification and regression** tasks. it has been tested on 14 datasets and outperformed state-of-the-art markov blanket learning algorithms on all of them along with traditional feature selection algorithms such as forward feature selection, backward feature elimination and recursive feature elimination.\n\n&amp;#x200b;\n\nperformance comparison:\n\nfor classification tasks, accuracy as a metric (higher score is better) has been used while for regression tasks, mean squared error as a metric (lower score is better) has been used. the final model used for comparison on all tasks is a decision -----> tree !!!  with scores being reported on 5-fold cross validation.\n\n|**dataset**|**# of samples**|**# of features**|**task type**|**score using all features**|**score using pyimpetus**|**# of features selected**|**% of features selected** |\n|:-|:-|:-|:-|:-|:-|:-|:-|\n|ionosphere|351|34|classification|88.01%|92.86%|14|42.42%|\n|arcene|100|10000|classification|82%|84.72%|304|3.04%|\n|alonds2000|62|2000|classification|80.55%|88.49%|75|3.75%|\n|slice\\_localization\\_data|53500|384|regression|6.54|5.69|259|67.45%|\n\n&amp;#x200b;\n\n[link to the github repo](https://github.com/atif-hassan/pyimpetus)\n\n[link to pypi](https://pypi.org/project/pyimpetus/)\n\n&amp;#x200b;\n\npyimpetus already has over 15k+ downloads so do check it out and please let me know how it worked out for you in your machine learning project. don't forget to pen down your feedback and doubts in the comment section.\n\nand of course, don't forget to star the github repo!!\n\nthank you and have an amazing day!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mslslg/p_pyimpetus_a_markov_blanket_based_new_sota/',)", "identifyer": 5737264, "year": "2021"}, {"autor": "lorenzkuhn", "date": 1611498904000, "content": "[D] Training 10x Larger Models and Accelerating Training with ZeRO-Offloading /!/ *I've been reading up on ZeRO-Offload* [since the paper](https://arxiv.org/abs/2101.06840) *was published last week \u2013 here are a few introductory notes on what it is, when it's useful, how it can be used and how it works. Let me know if I forgot anything important or got something wrong.*\n\n### What is ZeRO-Offloading?\n\nZeRO-Offloading is a way of reducing GPU memory usage during neural network training by offloading data and compute from the GPU(s) to CPU. Crucially this is done in a way that provides high training throughput and that avoids major slow-downs from moving the data and doing computations on CPU.\n\nZeRO-offloading makes it possible to train models that are up to 10x larger than previously possible with the same hardware \u2013 even on a single GPU. You could for instance train GPT-2 (\\~10 billion parameters) on a single V100 GPU with 32GB RAM.  Lastly, it promises almost-linear scaling in multi-GPU settings. \n\n### When is this going to be useful for you?\n\n* If you want to train larger models or if you want to train your current models faster since ZeRO-offloading allows you to train with larger batch sizes.\n* If you're working with PyTorch and are willing/able to work with Microsoft's [DeepSpeed library](https://www.deepspeed.ai/tutorials/zero-offload/) (other ZeRO-Offloading implementations are on the horizon but not available for now). Alternatively you could try to adapt [the official implementation ](https://github.com/microsoft/DeepSpeed/blob/6e65c2cc084ecfc393c67a2f64639e8d08d325f6/deepspeed/runtime/zero/stage2.py)yourself.\n* If you're willing to take on some modelling constraints. The current version of ZeRO-Offloading is tied to mixed precision training with Adam, for instance.\n\n### How can you use it?\n\nZeRO-Offloading [is implemented in Microsoft's DeepSpeed](https://www.deepspeed.ai/tutorials/zero-offload/) library. A [native PyTorch ZeRO implementation is ](https://github.com/pytorch/pytorch/pull/46750)being developed but offloading is not supported at this point. The [official implementation available](https://github.com/microsoft/DeepSpeed/blob/6e65c2cc084ecfc393c67a2f64639e8d08d325f6/deepspeed/runtime/zero/stage2.py), so you could try to work directly with that.\n\nOnce you're set up within DeepSpeed, the additional effort required to use ZeRO-Offloading seems to be quite small, [essentially it's just modifying a few flags and a configuration file.](https://www.deepspeed.ai/tutorials/zero-offload/)\n\n[Hugging Face's transformers library ](https://huggingface.co/transformers/)has an experimental integration with DeepSpeed. [Stas Bekman has a nice blog](https://huggingface.co/blog/zero-deepspeed-fairscale) post describing how to use it and what kind of results you can expect on a few benchmarks.\n\n[Facebook Research's fairscale](https://www.google.com/search?q=fairscale&amp;oq=fairscale&amp;aqs=chrome.0.69i59l4j69i60l4.1744j1j4&amp;sourceid=chrome&amp;ie=UTF-8) has a partial [implementation of ZeRO,](https://github.com/facebookresearch/fairscale) the multi-GPU memory optimization method on top of which ZeRO-Offloading is built. CPU-offloading does not to seem to be supported at this point.\n\n### How does it work?\n\nZeRO-Offloading is based on the Zero Redundancy Optimizer (ZeRO), so let's quickly review what ZeRO is and how it works. \n\n**The Zero Redundancy Optimizer**\n\nZeRO-Offloading is based on the [Zero Redundancy Optimizer (ZeRO)](https://arxiv.org/pdf/1910.02054.pdf).\n\nZeRO, in a nutshell, is a memory optimization method for data-parallel model-parallel training in which gradients, parameters and optimizer state are distributed across the memory of multiple GPUs without any redundancy. This is done in a way that keeps the communication overhead between GPUs relatively low.\n\nI recommend reading this [introductory blog post](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/) \u2013 especially watching the animation \u2013 and then [reading the paper](https://arxiv.org/pdf/1910.02054.pdf) if you want to go deeper. The official [implementation of ZeRO can be found here.](https://github.com/microsoft/DeepSpeed/tree/master/deepspeed)\n\nHere's a figure that illustrates the distribution of parameters, gradients and optimizer states across GPUs ([source](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/)):\n\nhttps://preview.redd.it/ge885b7tead61.png?width=951&amp;format=png&amp;auto=webp&amp;s=e7f65f53068062f98a5293123d360db09efe1bbd\n\n**ZeRO-Offloading**\n\nQuoting directly from[ a](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/#toc-heading-3)[ blog post](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/#toc-heading-3) on ZeRO-Offloading (I've added the Figure that is being referred to below):\n\n&gt;(...) , ZeRO-Offload inherits the optimizer state and gradient partitioning from ZeRO-2. Unlike ZeRO-2, instead of having each GPU keep a partition of the optimizer state and gradients, ZeRO-Offload offloads both to host CPU memory. Optimizer states are kept in CPU memory for the entire training. Gradients, on the other hand, are computed and averaged using reduce-scatter on the GPUs during the backward pass, and each data-parallel process then offloads the averaged gradients belonging to its partition to the CPU memory (*g offload* in Figure 7) while discarding the rest. Once the gradients are available on the CPU, optimizer state partitions are updated in parallel by each data parallel process directly on the CPU (*p update* in Figure 7). After the update, parameter partitions are moved back to GPU followed by an all-gather operation on the GPU to gather all the updated parameters (*g swap* in Figure 7). ZeRO-Offload also exploits overlapping between communication (such as *g offload* and *g swap*) and computation (such as the backward pass and *p update*) using separate CUDA streams to maximize training efficiency.\n\nThis process is illustrated in this figure from the blog post:\n\n&amp;#x200B;\n\nhttps://preview.redd.it/6iqno8fzead61.png?width=1024&amp;format=png&amp;auto=webp&amp;s=7a3ac623bfc516de12adf328a6ed430929f1f93f\n\nOne thing to note here is that ZeRO-Offloading is designed specifically for *mixed precision training with Adam.* In particular, the current version of ZeRO-Offloading uses [DeepCPUAdam](https://github.com/microsoft/DeepSpeed/tree/master/deepspeed/ops/adam), an optimized version of Adam.  The main reason for using this optimizer is to avoid the CPU computation becoming a bottleneck in the whole process. This version of Adam seems to be about 6x faster than the PyTorch implementation.\n\nLastly, here are some of the results from the [ZeRO-Offload paper](https://arxiv.org/pdf/2101.06840.pdf) I found particularly interesting:\n\n1. The largest models that can be trained with ZeRO-Offload:\n\nhttps://preview.redd.it/yrwi68a4fad61.png?width=2000&amp;format=png&amp;auto=webp&amp;s=5e41832858584c8758872643a9a9120f46db80a6\n\n2. Near linear scaling of throughput per GPU as the number of GPUs is increased \u2013 when used in combination with ZeRO:\n\nhttps://preview.redd.it/9srlst07fad61.png?width=2000&amp;format=png&amp;auto=webp&amp;s=a91984cbf4175d313ccc4d1485291dc717df641e\n\n3. Throughput per GPU of PyTorch, L2L and ZeRO-Offload as a function of the model size:\n\nhttps://preview.redd.it/rg65lrr8fad61.png?width=2000&amp;format=png&amp;auto=webp&amp;s=8177ae16f8de12a5f6c2136e659b237fbab64579\n\nHere's the paper:[ ZeRO-Offload: Democratizing Billion-Scale Model Training](https://arxiv.org/pdf/2101.06840.pdf).", "link": "https://www.reddit.com/r/MachineLearning/comments/l40jdh/d_training_10x_larger_models_and_accelerating/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] training 10x larger models and accelerating training with zero-offloading /!/ *i've been reading up on zero-offload* [since the paper](https://arxiv.org/abs/2101.06840) *was published last week \u2013 here are a few introductory notes on what it is, when it's useful, how it can be used and how it works. let me know if i forgot anything important or got something wrong.*\n\n### what is zero-offloading?\n\nzero-offloading is a way of reducing gpu memory usage during neural network training by offloading data and compute from the gpu(s) to cpu. crucially this is done in a way that provides high training throughput and that avoids major slow-downs from moving the data and doing computations on cpu.\n\nzero-offloading makes it possible to train models that are up to 10x larger than previously possible with the same hardware \u2013 even on a single gpu. you could for instance train gpt-2 (\\~10 billion parameters) on a single v100 gpu with 32gb ram.  lastly, it promises almost-linear scaling in multi-gpu settings. \n\n### when is this going to be useful for you?\n\n* if you want to train larger models or if you want to train your current models faster since zero-offloading allows you to train with larger batch sizes.\n* if you're working with pytorch and are willing/able to work with microsoft's [deepspeed library](https://www.deepspeed.ai/tutorials/zero-offload/) (other zero-offloading implementations are on the horizon but not available for now). alternatively you could try to adapt [the official implementation ](https://github.com/microsoft/deepspeed/blob/6e65c2cc084ecfc393c67a2f64639e8d08d325f6/deepspeed/runtime/zero/stage2.py)yourself.\n* if you're willing to take on some modelling constraints. the current version of zero-offloading is tied to mixed precision training with adam, for instance.\n\n### how can you use it?\n\nzero-offloading [is implemented in microsoft's deepspeed](https://www.deepspeed.ai/tutorials/zero-offload/) library. a [native pytorch zero implementation is ](https://github.com/pytorch/pytorch/pull/46750)being developed but offloading is not supported at this point. the [official implementation available](https://github.com/microsoft/deepspeed/blob/6e65c2cc084ecfc393c67a2f64639e8d08d325f6/deepspeed/runtime/zero/stage2.py), so you could try to work directly with that.\n\nonce you're set up within deepspeed, the additional effort required to use zero-offloading seems to be quite small, [essentially it's just modifying a few flags and a configuration file.](https://www.deepspeed.ai/tutorials/zero-offload/)\n\n[hugging face's transformers library ](https://huggingface.co/transformers/)has an experimental integration with deepspeed. [stas bekman has a nice blog](https://huggingface.co/blog/zero-deepspeed-fairscale) post describing how to use it and what kind of results you can expect on a few benchmarks.\n\n[facebook research's fairscale](https://www.google.com/search?q=fairscale&amp;oq=fairscale&amp;aqs=chrome.0.69i59l4j69i60l4.1744j1j4&amp;sourceid=chrome&amp;ie=utf-8) has a partial [implementation of zero,](https://github.com/facebookresearch/fairscale) the multi-gpu memory optimization method on top of which zero-offloading is built. cpu-offloading does not to seem to be supported at this point.\n\n### how does it work?\n\nzero-offloading is based on the zero redundancy optimizer (zero), so let's quickly review what zero is and how it works. \n\n**the zero redundancy optimizer**\n\nzero-offloading is based on the [zero redundancy optimizer (zero)](https://arxiv.org/pdf/1910.02054.pdf).\n\nzero, in a nutshell, is a memory optimization method for data-parallel model-parallel training in which gradients, parameters and optimizer state are distributed across the memory of multiple gpus without any redundancy. this is done in a way that keeps the communication overhead between gpus relatively low.\n\ni recommend reading this [introductory blog post](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/) \u2013 especially watching the animation \u2013 and then [reading the paper](https://arxiv.org/pdf/1910.02054.pdf) if you want to go deeper. the official [implementation of zero can be found here.](https://github.com/microsoft/deepspeed/-----> tree !!! /master/deepspeed)\n\nhere's a figure that illustrates the distribution of parameters, gradients and optimizer states across gpus ([source](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/)):\n\nhttps://preview.redd.it/ge885b7tead61.png?width=951&amp;format=png&amp;auto=webp&amp;s=e7f65f53068062f98a5293123d360db09efe1bbd\n\n**zero-offloading**\n\nquoting directly from[ a](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/#toc-heading-3)[ blog post](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/#toc-heading-3) on zero-offloading (i've added the figure that is being referred to below):\n\n&gt;(...) , zero-offload inherits the optimizer state and gradient partitioning from zero-2. unlike zero-2, instead of having each gpu keep a partition of the optimizer state and gradients, zero-offload offloads both to host cpu memory. optimizer states are kept in cpu memory for the entire training. gradients, on the other hand, are computed and averaged using reduce-scatter on the gpus during the backward pass, and each data-parallel process then offloads the averaged gradients belonging to its partition to the cpu memory (*g offload* in figure 7) while discarding the rest. once the gradients are available on the cpu, optimizer state partitions are updated in parallel by each data parallel process directly on the cpu (*p update* in figure 7). after the update, parameter partitions are moved back to gpu followed by an all-gather operation on the gpu to gather all the updated parameters (*g swap* in figure 7). zero-offload also exploits overlapping between communication (such as *g offload* and *g swap*) and computation (such as the backward pass and *p update*) using separate cuda streams to maximize training efficiency.\n\nthis process is illustrated in this figure from the blog post:\n\n&amp;#x200b;\n\nhttps://preview.redd.it/6iqno8fzead61.png?width=1024&amp;format=png&amp;auto=webp&amp;s=7a3ac623bfc516de12adf328a6ed430929f1f93f\n\none thing to note here is that zero-offloading is designed specifically for *mixed precision training with adam.* in particular, the current version of zero-offloading uses [deepcpuadam](https://github.com/microsoft/deepspeed/tree/master/deepspeed/ops/adam), an optimized version of adam.  the main reason for using this optimizer is to avoid the cpu computation becoming a bottleneck in the whole process. this version of adam seems to be about 6x faster than the pytorch implementation.\n\nlastly, here are some of the results from the [zero-offload paper](https://arxiv.org/pdf/2101.06840.pdf) i found particularly interesting:\n\n1. the largest models that can be trained with zero-offload:\n\nhttps://preview.redd.it/yrwi68a4fad61.png?width=2000&amp;format=png&amp;auto=webp&amp;s=5e41832858584c8758872643a9a9120f46db80a6\n\n2. near linear scaling of throughput per gpu as the number of gpus is increased \u2013 when used in combination with zero:\n\nhttps://preview.redd.it/9srlst07fad61.png?width=2000&amp;format=png&amp;auto=webp&amp;s=a91984cbf4175d313ccc4d1485291dc717df641e\n\n3. throughput per gpu of pytorch, l2l and zero-offload as a function of the model size:\n\nhttps://preview.redd.it/rg65lrr8fad61.png?width=2000&amp;format=png&amp;auto=webp&amp;s=8177ae16f8de12a5f6c2136e659b237fbab64579\n\nhere's the paper:[ zero-offload: democratizing billion-scale model training](https://arxiv.org/pdf/2101.06840.pdf).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/l40jdh/d_training_10x_larger_models_and_accelerating/',)", "identifyer": 5737377, "year": "2021"}, {"autor": "thatguydr", "date": 1629676130000, "content": "[P] Tree compiler that speeds up LightGBM model inference by ~30x", "link": "https://www.reddit.com/r/MachineLearning/comments/p9nv0c/p_tree_compiler_that_speeds_up_lightgbm_model/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] -----> tree !!!  compiler that speeds up lightgbm model inference by ~30x", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 2, "media": "('link',)", "medialink": "('/r/dataengineering/comments/p9c647/tree_compiler_that_speeds_up_lightgbm_model/',)", "identifyer": 5737445, "year": "2021"}, {"autor": "StochasticSolver", "date": 1629323394000, "content": "[P] [N] Open-sourcing Bridge \ud83c\udf89 /!/ (disclosure, I am a maintainer)\n\nTl;dr: get high performance inference APIs straight from the model versions you create in your registry/experiment tracker during training\n\nThe [Domino](https://www.dominodatalab.com/) R&amp;D team is open-sourcing [Bridge](https://github.com/dominodatalab/domino-research/tree/main/bridge), a tool that turns your model registry into the declarative source-of-truth for model deployment and hosting.\n\nWith Bridge, you manage the lifecycle of models from dev to prod exclusively through the UI/API of your existing Model Registry (like [MLflow](https://www.mlflow.org/docs/latest/index.html)). Bridge deploys and updates your target hosting infra to make your models available for inference. To update staging, just add the staging label to the model, that's it.\n\nOur [quick start](https://github.com/dominodatalab/domino-research/tree/main/bridge#quick-start) will have you deploying from your existing registry (or a new one) in under 10 minutes.\n\nWe've also published the [research](https://medium.com/domino-research/bridge-bridging-the-gap-between-model-registries-and-production-hosting-4c3424fadba4) insights behind the design and why we think 'RegistryOps' is the only paradigm that makes sense for taking models from development to production.", "link": "https://www.reddit.com/r/MachineLearning/comments/p712n8/p_n_opensourcing_bridge/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] [n] open-sourcing bridge \ud83c\udf89 /!/ (disclosure, i am a maintainer)\n\ntl;dr: get high performance inference apis straight from the model versions you create in your registry/experiment tracker during training\n\nthe [domino](https://www.dominodatalab.com/) r&amp;d team is open-sourcing [bridge](https://github.com/dominodatalab/domino-research/-----> tree !!! /main/bridge), a tool that turns your model registry into the declarative source-of-truth for model deployment and hosting.\n\nwith bridge, you manage the lifecycle of models from dev to prod exclusively through the ui/api of your existing model registry (like [mlflow](https://www.mlflow.org/docs/latest/index.html)). bridge deploys and updates your target hosting infra to make your models available for inference. to update staging, just add the staging label to the model, that's it.\n\nour [quick start](https://github.com/dominodatalab/domino-research/tree/main/bridge#quick-start) will have you deploying from your existing registry (or a new one) in under 10 minutes.\n\nwe've also published the [research](https://medium.com/domino-research/bridge-bridging-the-gap-between-model-registries-and-production-hosting-4c3424fadba4) insights behind the design and why we think 'registryops' is the only paradigm that makes sense for taking models from development to production.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/p712n8/p_n_opensourcing_bridge/',)", "identifyer": 5737486, "year": "2021"}, {"autor": "Better_Cycle_490", "date": 1626033512000, "content": "[D] Productionizing Distributed XGBoost to Train Deep Tree Models with Large Data Sets at Uber", "link": "https://www.reddit.com/r/MachineLearning/comments/oibfws/d_productionizing_distributed_xgboost_to_train/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] productionizing distributed xgboost to train deep -----> tree !!!  models with large data sets at uber", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('link',)", "medialink": "('https://eng.uber.com/productionizing-distributed-xgboost/',)", "identifyer": 5737530, "year": "2021"}, {"autor": "brandojazz", "date": 1621351536000, "content": "How to transform an Abstract Syntax Tree (AST) to an Abstract Binding Tree (ABT)? (for machine learning fo theorem proving)", "link": "https://www.reddit.com/r/MachineLearning/comments/nfdk13/how_to_transform_an_abstract_syntax_tree_ast_to/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "how to transform an abstract syntax -----> tree !!!  (ast) to an abstract binding -----> tree !!!  (abt)? (for machine learning fo theorem proving)", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('link',)", "medialink": "('https://cs.stackexchange.com/questions/140463/how-to-transform-an-abstract-syntax-tree-ast-to-an-abstract-binding-tree-abt',)", "identifyer": 5737624, "year": "2021"}, {"autor": "dholiveira85", "date": 1626458768000, "content": "[Research] Looking for help with C4.5 algorithm /!/ I'm looking for a paper or guide to understand the algorithm for decision tree generator C4.5. Does anyone have a good sugestion? I do need to understand it properly because I'll need to implement it by myself for an academic project. (my research it's not about ML, but I'll use this algorithm indirectly).", "link": "https://www.reddit.com/r/MachineLearning/comments/olmeu0/research_looking_for_help_with_c45_algorithm/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[research] looking for help with c4.5 algorithm /!/ i'm looking for a paper or guide to understand the algorithm for decision -----> tree !!!  generator c4.5. does anyone have a good sugestion? i do need to understand it properly because i'll need to implement it by myself for an academic project. (my research it's not about ml, but i'll use this algorithm indirectly).", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/olmeu0/research_looking_for_help_with_c45_algorithm/',)", "identifyer": 5737799, "year": "2021"}, {"autor": "dholiveira85", "date": 1626446773000, "content": "Help with C 4.5 (decision tree generator) /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/olia5w/help_with_c_45_decision_tree_generator/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "help with c 4.5 (decision -----> tree !!!  generator) /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/olia5w/help_with_c_45_decision_tree_generator/',)", "identifyer": 5737813, "year": "2021"}, {"autor": "SQL_beginner", "date": 1622590731000, "content": "[D] Depth In Tree Based Algorithms vs Neural Networks (\"On the Expressive Power of Deep Architectures\" , 2007, Bengio and Delalleau) /!/ I am reading this paper over here \"On the Expressive Power of Deep Architectures\" (2007, Bengio and Delalleau, http://www.iro.umontreal.ca/~lisa/bib/pub_subject/finance/pointeurs/ALT2011.pdf).\n\nIn this paper, they make a statement : \"\nOne of the characteristics that has spurred much interest and research in\nrecent years is depth of the architecture. In the case of a multi-layer neural\nnetwork, depth corresponds to the number of (hidden and output) layers. A\nfixed-kernel Support Vector Machine is considered to have depth 2 (Bengio and\nLeCun, 2007a) and boosted decision trees to have depth 3 (Bengio et al., 2010).\"\n\nIf I understand this correctly, a neural network is said to have the same \"depth\" as the number of layers (e.g. a n-layered decision tree will have a depth of \"n\"), whereas boosted decision trees are said to have a fixed depth of 3 - no matter how splits the boosted decision tree is said to have. \n\nDoes anyone know why this is? Why does a really deep boosted decision tree still only have a depth of 3?\n\nThanks", "link": "https://www.reddit.com/r/MachineLearning/comments/nq7w2f/d_depth_in_tree_based_algorithms_vs_neural/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] depth in -----> tree !!!  based algorithms vs neural networks (\"on the expressive power of deep architectures\" , 2007, bengio and delalleau) /!/ i am reading this paper over here \"on the expressive power of deep architectures\" (2007, bengio and delalleau, http://www.iro.umontreal.ca/~lisa/bib/pub_subject/finance/pointeurs/alt2011.pdf).\n\nin this paper, they make a statement : \"\none of the characteristics that has spurred much interest and research in\nrecent years is depth of the architecture. in the case of a multi-layer neural\nnetwork, depth corresponds to the number of (hidden and output) layers. a\nfixed-kernel support vector machine is considered to have depth 2 (bengio and\nlecun, 2007a) and boosted decision trees to have depth 3 (bengio et al., 2010).\"\n\nif i understand this correctly, a neural network is said to have the same \"depth\" as the number of layers (e.g. a n-layered decision tree will have a depth of \"n\"), whereas boosted decision trees are said to have a fixed depth of 3 - no matter how splits the boosted decision tree is said to have. \n\ndoes anyone know why this is? why does a really deep boosted decision tree still only have a depth of 3?\n\nthanks", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 5, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nq7w2f/d_depth_in_tree_based_algorithms_vs_neural/',)", "identifyer": 5737950, "year": "2021"}, {"autor": "balajivenky06", "date": 1617718414000, "content": "Pocket Interview Guide on Decision Tree ML Algorithm /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/mlclgy/pocket_interview_guide_on_decision_tree_ml/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "pocket interview guide on decision -----> tree !!!  ml algorithm /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mlclgy/pocket_interview_guide_on_decision_tree_ml/',)", "identifyer": 5738058, "year": "2021"}, {"autor": "LoyalSol", "date": 1617643684000, "content": "[R] \"Learning in Continuous Action Space for Determination of HighDimensional Potential Energy Surfaces\" Monte Carlo Tree Search applied to physical force-field development in continuous action spaces.", "link": "https://www.reddit.com/r/MachineLearning/comments/mkq0ip/r_learning_in_continuous_action_space_for/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] \"learning in continuous action space for determination of highdimensional potential energy surfaces\" monte carlo -----> tree !!!  search applied to physical force-field development in continuous action spaces.", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://assets.researchsquare.com/files/rs-284625/v1_stamped.pdf',)", "identifyer": 5738132, "year": "2021"}, {"autor": "Rohit901", "date": 1619201120000, "content": "[D] PyTorch LSTM: Sine Wave Prediction using Adam and batches /!/ Hey, all\n\nI have been trying to understand the PyTorch sine wave example given here: [example](https://github.com/pytorch/examples/tree/master/time_sequence_prediction)\n\nIt took me some time to digest what actually is happening and how the input/output pair is made in this.  \nThey have used LBFGS and have fed all the batches at once which might not be feasible in every case, thus I was trying to implement the same example using batched way and using Adam Optimizer.\n\nI have also tweaked the Model structure a bit, now my model is like this:\n\n    class Sequence(nn.Module):\n        def __init__(self):\n            super(Sequence, self).__init__()\n            self.lstm1 = nn.LSTMCell(1, 50) #only 1 feature in input, 51 is no of features in hidden_state\n            self.lstm2 = nn.LSTMCell(50, 50) #prev cell outputs 51, so this input is 51, and it outputs 51 (hidden_dim)\n            self.linear = nn.Linear(50, 36) #takes 51 dim to predict 1 value\n            self.relu = nn.ReLU()\n            self.linear2 = nn.Linear(36, 24)\n            self.linear3 = nn.Linear(24, 1)\n            \n        def forward(self, input, future = 0):\n            outputs = []\n            h_t = torch.zeros(input.size(0), 50, dtype = torch.double) #shape is 97x51 (batch,hidden_size)\n            c_t = torch.zeros(input.size(0), 50, dtype = torch.double) #shape is 97x51 (batch,hidden_size)\n            h_t2 = torch.zeros(input.size(0), 50, dtype = torch.double)\n            c_t2 = torch.zeros(input.size(0), 50, dtype = torch.double)\n            \n            #hidden state and cell state are set to 0 in every new \"batch\" of examples\n            \n            for input_t in input.split(1, dim = 1): # input_t is of shape [batch_size,1], loop always runs for 999 times\n                h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n                h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n                output = self.linear3(self.relu(self.linear2(self.relu(self.linear(h_t2))))) #output is of shape [batch_size, 1], for every time step t, output has (t+1)th value prediction for all sine waves\n                outputs += [output]\n            for i in range(future):\n                h_t, c_t = self.lstm1(output, (h_t, c_t)) #\n                h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n                output = self.linear3(self.relu(self.linear2(self.relu(self.linear(h_t2)))))\n                #output = self.linear(h_t2)\n                outputs += [output]\n            outputs = torch.cat(outputs, dim = 1) #concat predictions across all timesteps from t1 to t999, and future\n            return outputs\n\nOptimizer:\n\n`optim = torch.optim.Adam(seq.parameters(), lr = 0.08)`\n\nDataset:\n\n    class seqDS(Dataset):\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n            self.len = x.shape[0]\n        def __getitem__(self, idx):\n            return self.x[idx], self.y[idx]\n        def __len__(self):\n            return self.len\n        \n    ds = seqDS(input, target)\n\nLoader:\n\n`train_loader = DataLoader(ds, shuffle = False, batch_size = 16)`\n\nTraining Loop:\n\n    for i in range(50):\n        loss = 0.0\n        num_len = 0\n        seq.train()\n        for x,y in train_loader:\n            batch_size = x.shape[0]\n            y_pred = seq(x)\n            optim.zero_grad()\n            loss = criterion(y_pred, y)\n            loss.backward()\n            optim.step()\n            num_len += batch_size\n            loss += (batch_size * loss.item())\n        loss = loss / (num_len)\n        print(f\"Epoch {i+1}, Loss: {loss}\")\n        \n        with torch.no_grad():\n            future = 1000\n            pred = seq(test_input, future=future)\n            loss = criterion(pred[:, :-future], test_target)\n            print('test loss:', loss.item())\n            print(\"==========================\")\n            y = pred.detach().numpy()\n        \n        plt.figure(figsize=(30,10))\n        plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n        plt.xlabel('x', fontsize=20)\n        plt.ylabel('y', fontsize=20)\n        plt.xticks(fontsize=20)\n        plt.yticks(fontsize=20)\n        def draw(yi, color):\n            plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n            plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n        draw(y[0], 'r')\n        draw(y[1], 'g')\n        draw(y[2], 'b')\n        plt.savefig('predict%d.pdf'%i)\n        plt.close()\n\nNow, as you can see from this plot below, the results are very disappointing and the model is not able to predict future values properly and even is not very accurate on predicting test set values that have the real ground truth labels.\n\nI really want to go deep into this and understand what is actually happening and how can I fix this, LSTM is supposed to have a memory element due to cell state that\u2019s what I know, and since the cell state used at time t = 0 is propagated to time t = 999, why it's still failing to predict the sine wave values for future times (after t = 1000) on the test set data?\n\nThank you so much for your time.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[LSTM Results](https://preview.redd.it/fqvkzdglqyu61.png?width=1918&amp;format=png&amp;auto=webp&amp;s=4c4a9cb3804a6ebabd245d8e0adc90108c49d235)", "link": "https://www.reddit.com/r/MachineLearning/comments/mx1aa3/d_pytorch_lstm_sine_wave_prediction_using_adam/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] pytorch lstm: sine wave prediction using adam and batches /!/ hey, all\n\ni have been trying to understand the pytorch sine wave example given here: [example](https://github.com/pytorch/examples/-----> tree !!! /master/time_sequence_prediction)\n\nit took me some time to digest what actually is happening and how the input/output pair is made in this.  \nthey have used lbfgs and have fed all the batches at once which might not be feasible in every case, thus i was trying to implement the same example using batched way and using adam optimizer.\n\ni have also tweaked the model structure a bit, now my model is like this:\n\n    class sequence(nn.module):\n        def __init__(self):\n            super(sequence, self).__init__()\n            self.lstm1 = nn.lstmcell(1, 50) #only 1 feature in input, 51 is no of features in hidden_state\n            self.lstm2 = nn.lstmcell(50, 50) #prev cell outputs 51, so this input is 51, and it outputs 51 (hidden_dim)\n            self.linear = nn.linear(50, 36) #takes 51 dim to predict 1 value\n            self.relu = nn.relu()\n            self.linear2 = nn.linear(36, 24)\n            self.linear3 = nn.linear(24, 1)\n            \n        def forward(self, input, future = 0):\n            outputs = []\n            h_t = torch.zeros(input.size(0), 50, dtype = torch.double) #shape is 97x51 (batch,hidden_size)\n            c_t = torch.zeros(input.size(0), 50, dtype = torch.double) #shape is 97x51 (batch,hidden_size)\n            h_t2 = torch.zeros(input.size(0), 50, dtype = torch.double)\n            c_t2 = torch.zeros(input.size(0), 50, dtype = torch.double)\n            \n            #hidden state and cell state are set to 0 in every new \"batch\" of examples\n            \n            for input_t in input.split(1, dim = 1): # input_t is of shape [batch_size,1], loop always runs for 999 times\n                h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n                h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n                output = self.linear3(self.relu(self.linear2(self.relu(self.linear(h_t2))))) #output is of shape [batch_size, 1], for every time step t, output has (t+1)th value prediction for all sine waves\n                outputs += [output]\n            for i in range(future):\n                h_t, c_t = self.lstm1(output, (h_t, c_t)) #\n                h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n                output = self.linear3(self.relu(self.linear2(self.relu(self.linear(h_t2)))))\n                #output = self.linear(h_t2)\n                outputs += [output]\n            outputs = torch.cat(outputs, dim = 1) #concat predictions across all timesteps from t1 to t999, and future\n            return outputs\n\noptimizer:\n\n`optim = torch.optim.adam(seq.parameters(), lr = 0.08)`\n\ndataset:\n\n    class seqds(dataset):\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n            self.len = x.shape[0]\n        def __getitem__(self, idx):\n            return self.x[idx], self.y[idx]\n        def __len__(self):\n            return self.len\n        \n    ds = seqds(input, target)\n\nloader:\n\n`train_loader = dataloader(ds, shuffle = false, batch_size = 16)`\n\ntraining loop:\n\n    for i in range(50):\n        loss = 0.0\n        num_len = 0\n        seq.train()\n        for x,y in train_loader:\n            batch_size = x.shape[0]\n            y_pred = seq(x)\n            optim.zero_grad()\n            loss = criterion(y_pred, y)\n            loss.backward()\n            optim.step()\n            num_len += batch_size\n            loss += (batch_size * loss.item())\n        loss = loss / (num_len)\n        print(f\"epoch {i+1}, loss: {loss}\")\n        \n        with torch.no_grad():\n            future = 1000\n            pred = seq(test_input, future=future)\n            loss = criterion(pred[:, :-future], test_target)\n            print('test loss:', loss.item())\n            print(\"==========================\")\n            y = pred.detach().numpy()\n        \n        plt.figure(figsize=(30,10))\n        plt.title('predict future values for time sequences\\n(dashlines are predicted values)', fontsize=30)\n        plt.xlabel('x', fontsize=20)\n        plt.ylabel('y', fontsize=20)\n        plt.xticks(fontsize=20)\n        plt.yticks(fontsize=20)\n        def draw(yi, color):\n            plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n            plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n        draw(y[0], 'r')\n        draw(y[1], 'g')\n        draw(y[2], 'b')\n        plt.savefig('predict%d.pdf'%i)\n        plt.close()\n\nnow, as you can see from this plot below, the results are very disappointing and the model is not able to predict future values properly and even is not very accurate on predicting test set values that have the real ground truth labels.\n\ni really want to go deep into this and understand what is actually happening and how can i fix this, lstm is supposed to have a memory element due to cell state that\u2019s what i know, and since the cell state used at time t = 0 is propagated to time t = 999, why it's still failing to predict the sine wave values for future times (after t = 1000) on the test set data?\n\nthank you so much for your time.\n\n&amp;#x200b;\n\n&amp;#x200b;\n\n[lstm results](https://preview.redd.it/fqvkzdglqyu61.png?width=1918&amp;format=png&amp;auto=webp&amp;s=4c4a9cb3804a6ebabd245d8e0adc90108c49d235)", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/mx1aa3/d_pytorch_lstm_sine_wave_prediction_using_adam/',)", "identifyer": 5738222, "year": "2021"}, {"autor": "bminixhofer", "date": 1610975094000, "content": "[P] I made NLPRule: A library for fast grammatical error correction /!/ Hi!\n\nNLPRule does fast grammatical error correction for English and German by checking thousands of rules. It is written in Rust and has bindings for Python. \n\nRepository: [https://github.com/bminixhofer/nlprule](https://github.com/bminixhofer/nlprule)\n\n**Synopsis**\n\n    from nlprule import Tokenizer, Rules, SplitOn\n    \n    tokenizer = Tokenizer.load(\"en\")\n    rules = Rules.load(\"en\", tokenizer, SplitOn([\".\", \"?\", \"!\"]))\n    \n    rules.correct(\"He wants that you send him an email.\")\n    # returns: 'He wants you to send him an email.'\n    \n    rules.correct(\"I can due his homework.\")\n    # returns: 'I can do his homework.'\n    \n    rules.correct(\"It is enough for all intensive purposes.\")\n    # returns: 'It is enough for all intents and purposes.'\n    \n    \n    suggestions = rules.suggest(\"She was not been here since Monday.\")\n    for s in suggestions:\n      print(s.start, s.end, s.text, s.source, s.message)\n    # prints:\n    # 4 16 ['was not', 'has not been'] WAS_BEEN.1 Did you mean was not or has not been?\n\n**Background**\n\nI've been interested in grammatical error correction for a while and came across [LanguageTool](https://github.com/languagetool-org/languagetool) which is based on [thousands of rules for error correction in an XML file](https://raw.githubusercontent.com/languagetool-org/languagetool/master/languagetool-language-modules/en/src/main/resources/org/languagetool/rules/en/grammar.xml). You can think of the rule syntax as a restricted form of Regex where the atoms are words annotated with lemmas, part-of-speech tags, and chunks.\n\nI'm not a big fan of Java, wanted to improve my Rust and was interested in how these rules are parsed so I made a proof of concept reverse-engineering the LanguageTool logic in Rust. I had this lying around for quite some time and decided to finish it up and make it into a usable library now during the holidays.\n\n**Relation to more sophisticated GEC approaches**\n\nThere's lots of research in using Neural Networks for Grammatical Error Correction and [there are some exciting recent approaches](https://github.com/grammarly/gector) which capture many more errors than a rule-based approach could. Still, for me there are two reasons to use rules:\n\n1. **Speed.** On my machine with an 8th Gen Intel CPU it takes less than 1ms to correct a sentence.\n2. **Dealing with extreme data sparsity of some errors.** The above example \"It is enough for all intensive purposes.\" contains a [well known error](https://www.merriam-webster.com/words-at-play/usage-for-all-intensive-purposes-intents). Yet, I would be surprised if a current ML model corrects this error unless specifically accounted for since it will almost never have appeared in its training data. This is even more true for similarly rare errors in other languages where there is less data available than for English. So I believe rules are especially useful in conjunction with a more powerful ML model. \n\nI think of NLPRule as a kind of \"sanity-check\" for text.\n\n**Rule-based postprocessing for NLG**\n\nTwo areas where NLPRule might be interesting are preprocessing for NLP and postprocessing for NLG. I've tried the latter with texts generated from GPT2. Applying NLPRule yields a significant amount of suggestions:\n\n    Generated 192300 tokens.\n    misspelling:    35 suggestions  (0.18 per 1000 tokens)\n    style:          53 suggestions  (0.28 per 1000 tokens)\n    typographical:  112 suggestions (0.58 per 1000 tokens)\n    grammar:        29 suggestions  (0.15 per 1000 tokens)\n    none:           3 suggestions   (0.02 per 1000 tokens)\n    inconsistency:  2 suggestions   (0.01 per 1000 tokens)\n\nNot all of these are errors, some are just suggestions for improvement. More information [here](https://github.com/bminixhofer/nlprule/tree/master/examples).\n\nAlthough strictly speaking this project is not about Machine Learning I thought people here might be interested. I'm happy to discuss anything in the comments!", "link": "https://www.reddit.com/r/MachineLearning/comments/kzuaie/p_i_made_nlprule_a_library_for_fast_grammatical/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] i made nlprule: a library for fast grammatical error correction /!/ hi!\n\nnlprule does fast grammatical error correction for english and german by checking thousands of rules. it is written in rust and has bindings for python. \n\nrepository: [https://github.com/bminixhofer/nlprule](https://github.com/bminixhofer/nlprule)\n\n**synopsis**\n\n    from nlprule import tokenizer, rules, spliton\n    \n    tokenizer = tokenizer.load(\"en\")\n    rules = rules.load(\"en\", tokenizer, spliton([\".\", \"?\", \"!\"]))\n    \n    rules.correct(\"he wants that you send him an email.\")\n    # returns: 'he wants you to send him an email.'\n    \n    rules.correct(\"i can due his homework.\")\n    # returns: 'i can do his homework.'\n    \n    rules.correct(\"it is enough for all intensive purposes.\")\n    # returns: 'it is enough for all intents and purposes.'\n    \n    \n    suggestions = rules.suggest(\"she was not been here since monday.\")\n    for s in suggestions:\n      print(s.start, s.end, s.text, s.source, s.message)\n    # prints:\n    # 4 16 ['was not', 'has not been'] was_been.1 did you mean was not or has not been?\n\n**background**\n\ni've been interested in grammatical error correction for a while and came across [languagetool](https://github.com/languagetool-org/languagetool) which is based on [thousands of rules for error correction in an xml file](https://raw.githubusercontent.com/languagetool-org/languagetool/master/languagetool-language-modules/en/src/main/resources/org/languagetool/rules/en/grammar.xml). you can think of the rule syntax as a restricted form of regex where the atoms are words annotated with lemmas, part-of-speech tags, and chunks.\n\ni'm not a big fan of java, wanted to improve my rust and was interested in how these rules are parsed so i made a proof of concept reverse-engineering the languagetool logic in rust. i had this lying around for quite some time and decided to finish it up and make it into a usable library now during the holidays.\n\n**relation to more sophisticated gec approaches**\n\nthere's lots of research in using neural networks for grammatical error correction and [there are some exciting recent approaches](https://github.com/grammarly/gector) which capture many more errors than a rule-based approach could. still, for me there are two reasons to use rules:\n\n1. **speed.** on my machine with an 8th gen intel cpu it takes less than 1ms to correct a sentence.\n2. **dealing with extreme data sparsity of some errors.** the above example \"it is enough for all intensive purposes.\" contains a [well known error](https://www.merriam-webster.com/words-at-play/usage-for-all-intensive-purposes-intents). yet, i would be surprised if a current ml model corrects this error unless specifically accounted for since it will almost never have appeared in its training data. this is even more true for similarly rare errors in other languages where there is less data available than for english. so i believe rules are especially useful in conjunction with a more powerful ml model. \n\ni think of nlprule as a kind of \"sanity-check\" for text.\n\n**rule-based postprocessing for nlg**\n\ntwo areas where nlprule might be interesting are preprocessing for nlp and postprocessing for nlg. i've tried the latter with texts generated from gpt2. applying nlprule yields a significant amount of suggestions:\n\n    generated 192300 tokens.\n    misspelling:    35 suggestions  (0.18 per 1000 tokens)\n    style:          53 suggestions  (0.28 per 1000 tokens)\n    typographical:  112 suggestions (0.58 per 1000 tokens)\n    grammar:        29 suggestions  (0.15 per 1000 tokens)\n    none:           3 suggestions   (0.02 per 1000 tokens)\n    inconsistency:  2 suggestions   (0.01 per 1000 tokens)\n\nnot all of these are errors, some are just suggestions for improvement. more information [here](https://github.com/bminixhofer/nlprule/-----> tree !!! /master/examples).\n\nalthough strictly speaking this project is not about machine learning i thought people here might be interested. i'm happy to discuss anything in the comments!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 24, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/kzuaie/p_i_made_nlprule_a_library_for_fast_grammatical/',)", "identifyer": 5738677, "year": "2021"}, {"autor": "AmanJain27", "date": 1621848945000, "content": "[R] Differential Privacy /!/ I have recently decided to look into this topic and it seems pretty amazing. The basic idea is to anonymize the dataset and add random noise to the database queries outputs. The anonymization includes generalizing the dataset with each attribute's specific taxonomy tree.  I think, decision tree can come in handy with its information gain at each level, I can find a best split and produce the tree from there. \n\nThe problem is I unable to produce such taxonomy. The numeric attributes such as 40, 45, 47 will be generalized in a range like \\[40-50\\]. I don't how to produce such ranges and also, I don't know how to find a way to merge into the dataset as after replacing the values with the generalized one, I will be left with strings of the ranges .\n\nAlso, I can't find any way to produce a taxonomy for string attributes like jobs such as engineer, teacher, etc. If anyone knows the way around feel free to help.", "link": "https://www.reddit.com/r/MachineLearning/comments/njtz1m/r_differential_privacy/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] differential privacy /!/ i have recently decided to look into this topic and it seems pretty amazing. the basic idea is to anonymize the dataset and add random noise to the database queries outputs. the anonymization includes generalizing the dataset with each attribute's specific taxonomy -----> tree !!! .  i think, decision tree can come in handy with its information gain at each level, i can find a best split and produce the tree from there. \n\nthe problem is i unable to produce such taxonomy. the numeric attributes such as 40, 45, 47 will be generalized in a range like \\[40-50\\]. i don't how to produce such ranges and also, i don't know how to find a way to merge into the dataset as after replacing the values with the generalized one, i will be left with strings of the ranges .\n\nalso, i can't find any way to produce a taxonomy for string attributes like jobs such as engineer, teacher, etc. if anyone knows the way around feel free to help.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 4, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/njtz1m/r_differential_privacy/',)", "identifyer": 5739091, "year": "2021"}, {"autor": "data_driven_approach", "date": 1633899856000, "content": "[D] Help a newbie learn :) WGAN implementation with Custom Dataset /!/ Hello all!\n\nSo I started last week looking into GANs. I want to reach a point in which I feed it images and styles that I like and hopefully it will generate other things I like \ud83d\ude42\n\nThe entry was a simple GAN which worked (I guess?) until it reached a point that it generated the same image again and again, until I discovered something called \\`mode collapse\\`  [cGAN/gan at master \u00b7 czioutas/cGAN (github.com)](https://github.com/czioutas/cGAN/tree/master/gan)\n\nOff I was to implement WGAN which should tackle this problem!\n\nWGAN has definitely more complexity that is probably too deep for my understanding.\n\nI progressed by googling and ended up with  [cGAN/wgan at master \u00b7 czioutas/cGAN (github.com)](https://github.com/czioutas/cGAN/tree/master/wgan)The problem being in the end that the input images do not match the needs of the model but I do not know how to fix em.\n\nI added a stack trace of the output and the error line that points to the issue  [cGAN/model.py at master \u00b7 czioutas/cGAN (github.com)](https://github.com/czioutas/cGAN/blob/master/wgan/model.py#L144)\n\nIf anyone is willing to help out, comment, contact me anywhere you want (twitter is linked on github)\n\nThank you all in advance and its time to go hit the bed \ud83d\udca4  \n\n\nP.S Did not know if I should put \\[P\\] or \\[D\\] on the title :/", "link": "https://www.reddit.com/r/MachineLearning/comments/q5gqll/d_help_a_newbie_learn_wgan_implementation_with/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] help a newbie learn :) wgan implementation with custom dataset /!/ hello all!\n\nso i started last week looking into gans. i want to reach a point in which i feed it images and styles that i like and hopefully it will generate other things i like \ud83d\ude42\n\nthe entry was a simple gan which worked (i guess?) until it reached a point that it generated the same image again and again, until i discovered something called \\`mode collapse\\`  [cgan/gan at master \u00b7 czioutas/cgan (github.com)](https://github.com/czioutas/cgan/-----> tree !!! /master/gan)\n\noff i was to implement wgan which should tackle this problem!\n\nwgan has definitely more complexity that is probably too deep for my understanding.\n\ni progressed by googling and ended up with  [cgan/wgan at master \u00b7 czioutas/cgan (github.com)](https://github.com/czioutas/cgan/tree/master/wgan)the problem being in the end that the input images do not match the needs of the model but i do not know how to fix em.\n\ni added a stack trace of the output and the error line that points to the issue  [cgan/model.py at master \u00b7 czioutas/cgan (github.com)](https://github.com/czioutas/cgan/blob/master/wgan/model.py#l144)\n\nif anyone is willing to help out, comment, contact me anywhere you want (twitter is linked on github)\n\nthank you all in advance and its time to go hit the bed \ud83d\udca4  \n\n\np.s did not know if i should put \\[p\\] or \\[d\\] on the title :/", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/q5gqll/d_help_a_newbie_learn_wgan_implementation_with/',)", "identifyer": 5739411, "year": "2021"}, {"autor": "pp314159", "date": 1613227889000, "content": "[D] Compare AutoML on 10 Tabular Kaggle competitions /!/ I'm working on an AutoML system for tabular datasets. It is called MLJAR and is available as open-source with code on github: https://github.com/mljar/mljar-supervised\n\nI think that my AutoML system is quite advanced compared to other AutoML systems:\n- it can generate new features with [K-Means](https://mljar.com/automated-machine-learning/k-means-features/) or [Golden Features Search](https://mljar.com/automated-machine-learning/golden-features/)\n- it has many ML algorithms available, can tune them and train (with early stopping if applicable), in selected time regime,\n- can stack models in complex ensembles\n- creates interpretations for ML models: SHAP plots, permutation-based importance, decision tree visualizations ...\n- automatically generates documentation to Markdown or HTML (works like a dream in Jupyter notebook)\n\nI've compared my AutoML with other systems on 10 tabular datasets from Kaggle. The final result is the Percentile Rank in the Private Leaderboard (evaluated internally by Kaggle). The results other than MLJAR systems are from AutoGluon paper. Below is the summary of the comparison presented:\n\n| Dataset      | Auto-WEKA | auto-sklearn | TPOT  | H2O AutoML | GCP-Tables | AutoGluon | MLJAR |\n|--------------|-----------|--------------|-------|------------|------------|-----------|-------|\n| ieee-fraud   | 0.119     | 0.349        |       |            | 0.119      | 0.322     | 0.172 |\n| value        | 0.114     | 0.319        | 0.325 | 0.377      |            | 0.415     | 0.445 |\n| walmart      |           | 0.39         | 0.379 |            | 0.398      | 0.384     | 0.423 |\n| transaction  | 0.131     | 0.329        | 0.326 |            | 0.404      | 0.406     | 0.463 |\n| porto        | 0.158     | 0.331        | 0.315 | 0.406      | 0.434      | 0.462     | 0.54  |\n| allstate     | 0.124     | 0.31         | 0.237 | 0.352      | 0.74       | 0.706     | 0.764 |\n| mercedes     | 0.16      | 0.444        | 0.547 | 0.363      | 0.658      | 0.169     | 0.879 |\n| otto         | 0.145     | 0.717        | 0.597 | 0.729      | 0.821      | 0.988     | 0.924 |\n| satisfaction | 0.235     | 0.408        | 0.495 | 0.74       | 0.763      | 0.823     | 0.975 |\n| bnp-paribas  | 0.193     | 0.412        | 0.46  | 0.417      | 0.44       | 0.986     | 0.986 |\n\nI hope that many data scientists will benefit from my AutoML system. I put a lot of effort into it. I'm very interested in your opinion and feedback about my AutoML, and AutoML in general.", "link": "https://www.reddit.com/r/MachineLearning/comments/lj1vnh/d_compare_automl_on_10_tabular_kaggle_competitions/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] compare automl on 10 tabular kaggle competitions /!/ i'm working on an automl system for tabular datasets. it is called mljar and is available as open-source with code on github: https://github.com/mljar/mljar-supervised\n\ni think that my automl system is quite advanced compared to other automl systems:\n- it can generate new features with [k-means](https://mljar.com/automated-machine-learning/k-means-features/) or [golden features search](https://mljar.com/automated-machine-learning/golden-features/)\n- it has many ml algorithms available, can tune them and train (with early stopping if applicable), in selected time regime,\n- can stack models in complex ensembles\n- creates interpretations for ml models: shap plots, permutation-based importance, decision -----> tree !!!  visualizations ...\n- automatically generates documentation to markdown or html (works like a dream in jupyter notebook)\n\ni've compared my automl with other systems on 10 tabular datasets from kaggle. the final result is the percentile rank in the private leaderboard (evaluated internally by kaggle). the results other than mljar systems are from autogluon paper. below is the summary of the comparison presented:\n\n| dataset      | auto-weka | auto-sklearn | tpot  | h2o automl | gcp-tables | autogluon | mljar |\n|--------------|-----------|--------------|-------|------------|------------|-----------|-------|\n| ieee-fraud   | 0.119     | 0.349        |       |            | 0.119      | 0.322     | 0.172 |\n| value        | 0.114     | 0.319        | 0.325 | 0.377      |            | 0.415     | 0.445 |\n| walmart      |           | 0.39         | 0.379 |            | 0.398      | 0.384     | 0.423 |\n| transaction  | 0.131     | 0.329        | 0.326 |            | 0.404      | 0.406     | 0.463 |\n| porto        | 0.158     | 0.331        | 0.315 | 0.406      | 0.434      | 0.462     | 0.54  |\n| allstate     | 0.124     | 0.31         | 0.237 | 0.352      | 0.74       | 0.706     | 0.764 |\n| mercedes     | 0.16      | 0.444        | 0.547 | 0.363      | 0.658      | 0.169     | 0.879 |\n| otto         | 0.145     | 0.717        | 0.597 | 0.729      | 0.821      | 0.988     | 0.924 |\n| satisfaction | 0.235     | 0.408        | 0.495 | 0.74       | 0.763      | 0.823     | 0.975 |\n| bnp-paribas  | 0.193     | 0.412        | 0.46  | 0.417      | 0.44       | 0.986     | 0.986 |\n\ni hope that many data scientists will benefit from my automl system. i put a lot of effort into it. i'm very interested in your opinion and feedback about my automl, and automl in general.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 23, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/lj1vnh/d_compare_automl_on_10_tabular_kaggle_competitions/',)", "identifyer": 5739567, "year": "2021"}, {"autor": "Key-Government-3157", "date": 1624483168000, "content": "Randon forest - can I identify the best tree? [R] /!/ So I have a large database of patients with long follow-up and high mortality. I ran random forest and obviously it performs better than conventional clinical score for mortality prediction. In addition to area under roc curve and importance of variables, can I identify the best tree that predicts the best the outcome?\n\nIf not, what other tangible result could I get using RF? I need more materials to add to a paper I plan on writing.\nMany thanks!", "link": "https://www.reddit.com/r/MachineLearning/comments/o6m9bf/randon_forest_can_i_identify_the_best_tree_r/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "randon forest - can i identify the best -----> tree !!! ? [r] /!/ so i have a large database of patients with long follow-up and high mortality. i ran random forest and obviously it performs better than conventional clinical score for mortality prediction. in addition to area under roc curve and importance of variables, can i identify the best tree that predicts the best the outcome?\n\nif not, what other tangible result could i get using rf? i need more materials to add to a paper i plan on writing.\nmany thanks!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 7, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o6m9bf/randon_forest_can_i_identify_the_best_tree_r/',)", "identifyer": 5739687, "year": "2021"}, {"autor": "Key-Government-3157", "date": 1624483127000, "content": "Random forest - can I identify the best tree? /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/o6m8uk/random_forest_can_i_identify_the_best_tree/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "random forest - can i identify the best -----> tree !!! ? /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o6m8uk/random_forest_can_i_identify_the_best_tree/',)", "identifyer": 5739688, "year": "2021"}, {"autor": "Key-Government-3157", "date": 1624482981000, "content": "Random forest - can I identify the best tree?! /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/o6m75k/random_forest_can_i_identify_the_best_tree/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "random forest - can i identify the best -----> tree !!! ?! /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o6m75k/random_forest_can_i_identify_the_best_tree/',)", "identifyer": 5739689, "year": "2021"}, {"autor": "HushHush4446", "date": 1633105357000, "content": "[Discussion] Deleting/Removing Nodes from a decision tree [Python] /!/  I have constructed a decision tree and I want to check the effects on the accuracy after removing a particular node from it.\n\nI have an classifier object as clf = DecisionTreeClassifier()\n\nWhat operations could I do on 'clf' to achieve my goal?\n\nI searched on the internet but couldn't find how to actually achieve this.", "link": "https://www.reddit.com/r/MachineLearning/comments/pzbgxi/discussion_deletingremoving_nodes_from_a_decision/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[discussion] deleting/removing nodes from a decision -----> tree !!!  [python] /!/  i have constructed a decision tree and i want to check the effects on the accuracy after removing a particular node from it.\n\ni have an classifier object as clf = decisiontreeclassifier()\n\nwhat operations could i do on 'clf' to achieve my goal?\n\ni searched on the internet but couldn't find how to actually achieve this.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pzbgxi/discussion_deletingremoving_nodes_from_a_decision/',)", "identifyer": 5739779, "year": "2021"}, {"autor": "HushHush4446", "date": 1633105051000, "content": "Deleting/Removing Nodes from a decision tree [Python] /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/pzbd6z/deletingremoving_nodes_from_a_decision_tree_python/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "deleting/removing nodes from a decision -----> tree !!!  [python] /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pzbd6z/deletingremoving_nodes_from_a_decision_tree_python/',)", "identifyer": 5739780, "year": "2021"}, {"autor": "EscapedLaughter", "date": 1620289418000, "content": "[N] Music Demixing (Audio Source Separation) Competition by Sony | ISMIR 2021 /!/ The [competition](https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021?utm_source=reddit&amp;utm_medium=ml&amp;utm_campaign=sony) features 2 baselines:\n\nOpen-Unmix: [Code](https://github.com/sigsep/open-unmix-pytorch) | Paper: [https://www.theoj.org/joss-papers/joss.01667/10.21105.joss.01667.pdf](https://www.theoj.org/joss-papers/joss.01667/10.21105.joss.01667.pdf)\n\nCrossNet-UMX: [Code](https://github.com/sony/ai-research-code/tree/master/x-umx) | Paper: [https://arxiv.org/pdf/2010.04228.pdf](https://arxiv.org/pdf/2010.04228.pdf)\n\nThe competition can hopefully serve as a benchmark for various source separation models. Participants can get together during the ISMIR Workshop and share their learnings. Sony is also offering 10,000 CHF cash prize for top participants on the leaderboard.\n\n\\------------------------------------\n\n[Example](https://d2cowzs755i94n.cloudfront.net/) of music demixing:\n\n*Processing video t8orzh8rmgx61...*\n\nPS: This is my first post on the subreddit, so if I have transgressed any norms, I do apologize.", "link": "https://www.reddit.com/r/MachineLearning/comments/n62hli/n_music_demixing_audio_source_separation/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[n] music demixing (audio source separation) competition by sony | ismir 2021 /!/ the [competition](https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021?utm_source=reddit&amp;utm_medium=ml&amp;utm_campaign=sony) features 2 baselines:\n\nopen-unmix: [code](https://github.com/sigsep/open-unmix-pytorch) | paper: [https://www.theoj.org/joss-papers/joss.01667/10.21105.joss.01667.pdf](https://www.theoj.org/joss-papers/joss.01667/10.21105.joss.01667.pdf)\n\ncrossnet-umx: [code](https://github.com/sony/ai-research-code/-----> tree !!! /master/x-umx) | paper: [https://arxiv.org/pdf/2010.04228.pdf](https://arxiv.org/pdf/2010.04228.pdf)\n\nthe competition can hopefully serve as a benchmark for various source separation models. participants can get together during the ismir workshop and share their learnings. sony is also offering 10,000 chf cash prize for top participants on the leaderboard.\n\n\\------------------------------------\n\n[example](https://d2cowzs755i94n.cloudfront.net/) of music demixing:\n\n*processing video t8orzh8rmgx61...*\n\nps: this is my first post on the subreddit, so if i have transgressed any norms, i do apologize.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n62hli/n_music_demixing_audio_source_separation/',)", "identifyer": 5739980, "year": "2021"}, {"autor": "EscapedLaughter", "date": 1620289242000, "content": "[N Music Demixing (Audio Source Separation) Competition by Sony | ISMIR 2021 /!/ The [competition](https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021?utm_source=reddit&amp;utm_medium=ml&amp;utm_campaign=sony) features 2 baselines:\n\nOpen-Unmix: [Code](https://github.com/sigsep/open-unmix-pytorch) | Paper: [https://www.theoj.org/joss-papers/joss.01667/10.21105.joss.01667.pdf](https://www.theoj.org/joss-papers/joss.01667/10.21105.joss.01667.pdf)\n\nCrossNet-UMX: [Code](https://github.com/sony/ai-research-code/tree/master/x-umx) | Paper: [https://arxiv.org/pdf/2010.04228.pdf](https://arxiv.org/pdf/2010.04228.pdf)\n\nThe competition can hopefully serve as a benchmark for various source separation models. Participants can get together during the ISMIR Workshop and share their learnings. Sony is also offering 10,000 CHF cash prize for top participants on the leaderboard.\n\n\\------------------------------------\n\n[Example](https://d2cowzs755i94n.cloudfront.net/) of music demixing:\n\n![video](g8trsas6jgx61)\n\nPS: This is my first post on the subreddit, so if I have transgressed any norms, I do apologize.", "link": "https://www.reddit.com/r/MachineLearning/comments/n62g7v/n_music_demixing_audio_source_separation/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[n music demixing (audio source separation) competition by sony | ismir 2021 /!/ the [competition](https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021?utm_source=reddit&amp;utm_medium=ml&amp;utm_campaign=sony) features 2 baselines:\n\nopen-unmix: [code](https://github.com/sigsep/open-unmix-pytorch) | paper: [https://www.theoj.org/joss-papers/joss.01667/10.21105.joss.01667.pdf](https://www.theoj.org/joss-papers/joss.01667/10.21105.joss.01667.pdf)\n\ncrossnet-umx: [code](https://github.com/sony/ai-research-code/-----> tree !!! /master/x-umx) | paper: [https://arxiv.org/pdf/2010.04228.pdf](https://arxiv.org/pdf/2010.04228.pdf)\n\nthe competition can hopefully serve as a benchmark for various source separation models. participants can get together during the ismir workshop and share their learnings. sony is also offering 10,000 chf cash prize for top participants on the leaderboard.\n\n\\------------------------------------\n\n[example](https://d2cowzs755i94n.cloudfront.net/) of music demixing:\n\n![video](g8trsas6jgx61)\n\nps: this is my first post on the subreddit, so if i have transgressed any norms, i do apologize.", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n62g7v/n_music_demixing_audio_source_separation/',)", "identifyer": 5739981, "year": "2021"}, {"autor": "CKL-IT", "date": 1620223534000, "content": "[N] 1 line to visualizations for dependency trees, entity relationships, resolution, assertion, NER and new models for Afrikaans, Welsh, Maltese, Tamil, and Vietnamese - John Snow Labs NLU 3.0.1 for Python /!/ # NLU 3.0.1 Release Notes\nWe are very excited to announce NLU 3.0.1 has been released!\nThis is one of the most visually appealing releases, with the integration of the [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) library and visualizations for `dependency trees`, `entity resolution`, `entity assertion`, `relationship between entities` and `named\nentity recognition`. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+\nFinally, new multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese` are now available.\n\n\n\n\n# New Features and Enhancements\n- 1 line to visualization for `NER`, `Dependency`, `Resolution`, `Assertion` and `Relation` via [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) integration\n- Improved column naming schema\n- [Over 140 + NLU tutorial Notebooks updated](https://github.com/JohnSnowLabs/nlu/tree/master/examples) and improved to reflect latest changes in NLU 3.0.0 +\n- New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`\n- Enhanced offline loading\n\n\n## NLU visualization\nThe latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if\nSpark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don't need to worry about anything!\n\nSee the [visualization tutorial notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/visualization/NLU_visualizations_tutorial.ipynb)  and [visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples) for more info.\n\n![Cheat Sheet visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/cheat_sheet.png)\n\n## NER visualization\nApplicable to any of the [100+ NER models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition)\n```python\nnlu.load('ner').viz(\"Donald Trump from America and Angela Merkel from Germany don't share many oppinions.\")\n```\n![NER visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/NER.png)\n\n## Dependency tree visualization\nVisualizes the structure of the labeled dependency tree and part of speech tags\n```python\nnlu.load('dep.typed').viz(\"Billy went to the mall\")\n```\n\n![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP.png)\n\n```python\n#Bigger Example\nnlu.load('dep.typed').viz(\"Donald Trump from America and Angela Merkel from Germany don't share many oppinions but they both love John Snow Labs software\")\n```\n![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP_big.png)\n\n## Assertion status visualization\nVisualizes asserted statuses and entities.        \nApplicable to any of the [10 + Assertion models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Assertion+Status)\n```python\nnlu.load('med_ner.clinical assert').viz(\"The MRI scan showed no signs of cancer in the left lung\")\n```\n\n\n![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion.png)\n\n```python\n#bigger example\ndata ='This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.'\nnlu.load('med_ner.clinical assert').viz(data)\n```\n![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion_big.png)\n\n\n## Relationship between entities visualization\nVisualizes the extracted entities between relationship.    \nApplicable to any of the [20 + Relation Extractor models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Relation+Extraction)\n```python\nnlu.load('med_ner.jsl.wip.clinical relation.temporal_events').viz('The patient developed cancer after a mercury poisoning in 1999 ')\n```\n![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation.png)\n\n```python\n# bigger example\ndata = 'This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed'\npipe = nlu.load('med_ner.jsl.wip.clinical relation.clinical').viz(data)\n```\n![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation_big.png)\n\n\n## Entity Resolution visualization for chunks\nVisualizes resolutions of entities\nApplicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)\n```python\nnlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(\"He took Prevacid 30 mg  daily\")\n```\n![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk.png)\n\n```python\n# bigger example\ndata = \"This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\\'s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .\"\nnlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(data)\n```\n\n![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk_big.png)\n\n\n## Entity Resolution visualization for sentences\nVisualizes resolutions of entities in sentences\nApplicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)\n```python\nnlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz('She was diagnosed with a respiratory congestion')\n```\n![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence.png)\n\n```python\n# bigger example\ndata = 'The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion'\nnlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz(data)\n```\n![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence_big.png)\n\n## Configure visualizations\n### Define custom colors for labels\nSome entity and relation labels will be highlighted with a pre-defined color, which you [can find here](https://github.com/JohnSnowLabs/spark-nlp-display/tree/main/sparknlp_display/label_colors).    \nFor labels that have no color defined, a random color will be generated.     \nYou can define colors for labels manually, by specifying via the `viz_colors` parameter\nand defining `hex color codes` in a dictionary that maps `labels` to `colors` .\n```python\ndata = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'\n# Define custom colors for labels\nviz_colors={'STRENGTH':'#800080', 'DRUG_BRANDNAME':'#77b5fe', 'GENDER':'#77ffe'}\nnlu.load('med_ner.jsl.wip.clinical').viz(data,viz_colors =viz_colors)\n```\n![define colors labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/define_colors.png)\n\n\n### Filter entities that get highlighted\nBy default every entity class will be visualized.    \nThe `labels_to_viz` can be used to define a set of labels to highlight.       \nApplicable for ner, resolution and assert.\n```python\ndata = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'\n# Filter wich NER label to viz\nlabels_to_viz=['SYMPTOM']\nnlu.load('med_ner.jsl.wip.clinical').viz(data,labels_to_viz=labels_to_viz)\n```\n![filter labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/filter_labels.png)\n\n\n## New models\nNew multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`\n\n| nlu.load() Refrence                                          | Spark NLP Refrence                                           |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| [vi.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) |\n| [mt.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) |\n| [ta.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) |\n| [af.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) |\n| [af.pos](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) | [pos_afribooms](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) |\n| [cy.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) |\n\n## Reworked and updated NLU tutorial notebooks\n\nAll of the [140+ NLU tutorial Notebooks](https://github.com/JohnSnowLabs/nlu/tree/master/examples) have been updated and reworked to reflect the latest changes in NLU 3.0.0+\n\n\n## Improved Column Name generation\n- NLU categorized each internal component now with boolean labels for `name_deductable` and `always_name_deductable` .\n- Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the\n  pipe and there are multiple components of same type, i.e. multiple `NER` models, NLU will deduct a base name for the final output columns from the\n  NLU reference each NER model is pointing to.\n- If on the other hand, there is only one `NER` model in the pipeline, only the default `ner` column prefixed will be generated.\n- For some components, like `embeddings` and `classifiers` are now defined as `always_name_deductable`, for those NLU will always try to infer a meaningful base name for the output columns.\n- Newly trained component output columns will now be prefixed with `trained_&lt;type&gt;` , for types `pos` , `ner`, `cLassifier`, `sentiment` and `multi_classifier`\n\n## Enhanced offline mode\n- You can still load a model from a path as usual with `nlu.load(path=model_path)` and output columns will be suffixed with `from_disk`\n- You can now optionally also specify `request` parameter during  load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of `from_disk`, i.e. by calling `nlu.load(request ='en.embed_sentence.biobert.pubmed_pmc_base_cased', path=model_path)`\n\n\n### Bugfixes\n- Fixed a bug that caused  resolution algorithms output level to be inferred incorrectly\n- Fixed a bug that caused stranger cols got dropped\n- Fixed a bug that caused endings to miss when  .predict(position=True) was specified\n- Fixed a bug that caused pd.Series to be converted incorrectly internally\n- Fixed a bug that caused output level transformations to crash\n- Fixed a bug that caused verbose mode not to turn of properly after turning it on.\n- fixed a bug that caused some models to crash when loaded for HDD\n\n# Additional NLU resources\n* [140+ updates tutorials](https://github.com/JohnSnowLabs/nlu/tree/master/examples)\n* [Updated visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples)\n* [Models Hub](https://nlp.johnsnowlabs.com/models) with new models\n* [Spark NLP publications](https://medium.com/spark-nlp)\n* [NLU in Action](https://nlp.johnsnowlabs.com/demo)\n* [NLU documentation](https://nlu.johnsnowlabs.com/docs/en/install)\n* [Discussions](https://github.com/JohnSnowLabs/spark-nlp/discussions) Engage with other community members, share ideas, and show off how you use Spark NLP and NLU!\n\n# 1 line Install NLU on Google Colab\n```!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash```\n# 1 line Install NLU on Kaggle\n```!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash```\n# Install via PIP\n```! pip install nlu pyspark==3.0.1```", "link": "https://www.reddit.com/r/MachineLearning/comments/n5gpg4/n_1_line_to_visualizations_for_dependency_trees/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[n] 1 line to visualizations for dependency trees, entity relationships, resolution, assertion, ner and new models for afrikaans, welsh, maltese, tamil, and vietnamese - john snow labs nlu 3.0.1 for python /!/ # nlu 3.0.1 release notes\nwe are very excited to announce nlu 3.0.1 has been released!\nthis is one of the most visually appealing releases, with the integration of the [spark-nlp-display](https://nlp.johnsnowlabs.com/docs/en/display) library and visualizations for `dependency trees`, `entity resolution`, `entity assertion`, `relationship between entities` and `named\nentity recognition`. in addition to this, the schema of how columns are named by nlu has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in nlu 3.0.0+\nfinally, new multilingual models for `afrikaans`, `welsh`, `maltese`, `tamil`, and`vietnamese` are now available.\n\n\n\n\n# new features and enhancements\n- 1 line to visualization for `ner`, `dependency`, `resolution`, `assertion` and `relation` via [spark-nlp-display](https://nlp.johnsnowlabs.com/docs/en/display) integration\n- improved column naming schema\n- [over 140 + nlu tutorial notebooks updated](https://github.com/johnsnowlabs/nlu/-----> tree !!! /master/examples) and improved to reflect latest changes in nlu 3.0.0 +\n- new multilingual models for `afrikaans`, `welsh`, `maltese`, `tamil`, and`vietnamese`\n- enhanced offline loading\n\n\n## nlu visualization\nthe latest nlu release integrated the beautiful spark-nlp-display package visualizations. you do not need to worry about installing it, when you try to visualize something, nlu will check if\nspark-nlp-display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don't need to worry about anything!\n\nsee the [visualization tutorial notebook](https://github.com/johnsnowlabs/nlu/blob/master/examples/colab/visualization/nlu_visualizations_tutorial.ipynb)  and [visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples) for more info.\n\n![cheat sheet visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/cheat_sheet.png)\n\n## ner visualization\napplicable to any of the [100+ ner models! see here for an overview](https://nlp.johnsnowlabs.com/models?task=named+entity+recognition)\n```python\nnlu.load('ner').viz(\"donald trump from america and angela merkel from germany don't share many oppinions.\")\n```\n![ner visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/ner.png)\n\n## dependency tree visualization\nvisualizes the structure of the labeled dependency tree and part of speech tags\n```python\nnlu.load('dep.typed').viz(\"billy went to the mall\")\n```\n\n![dependency tree visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/dep.png)\n\n```python\n#bigger example\nnlu.load('dep.typed').viz(\"donald trump from america and angela merkel from germany don't share many oppinions but they both love john snow labs software\")\n```\n![dependency tree visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/dep_big.png)\n\n## assertion status visualization\nvisualizes asserted statuses and entities.        \napplicable to any of the [10 + assertion models! see here for an overview](https://nlp.johnsnowlabs.com/models?task=assertion+status)\n```python\nnlu.load('med_ner.clinical assert').viz(\"the mri scan showed no signs of cancer in the left lung\")\n```\n\n\n![assert visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/assertion.png)\n\n```python\n#bigger example\ndata ='this is the case of a very pleasant 46-year-old caucasian female, seen in clinic on 12/11/07 during which time mri of the left shoulder showed no evidence of rotator cuff tear. she did have a previous mri of the cervical spine that did show an osteophyte on the left c6-c7 level. based on this, negative mri of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at c6-c7 level. operation, expected outcome, risks, and benefits were discussed with her. risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. there is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. however, the patient may develop deeper-seated infection, which may require return to the operating room. should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. there is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. there is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. she understood all of these risks and agreed to have the procedure performed.'\nnlu.load('med_ner.clinical assert').viz(data)\n```\n![assert visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/assertion_big.png)\n\n\n## relationship between entities visualization\nvisualizes the extracted entities between relationship.    \napplicable to any of the [20 + relation extractor models see here for an overview](https://nlp.johnsnowlabs.com/models?task=relation+extraction)\n```python\nnlu.load('med_ner.jsl.wip.clinical relation.temporal_events').viz('the patient developed cancer after a mercury poisoning in 1999 ')\n```\n![entity relation visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/relation.png)\n\n```python\n# bigger example\ndata = 'this is the case of a very pleasant 46-year-old caucasian female, seen in clinic on 12/11/07 during which time mri of the left shoulder showed no evidence of rotator cuff tear. she did have a previous mri of the cervical spine that did show an osteophyte on the left c6-c7 level. based on this, negative mri of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at c6-c7 level. operation, expected outcome, risks, and benefits were discussed with her. risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. there is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. however, the patient may develop deeper-seated infection, which may require return to the operating room. should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. there is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. there is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. she understood all of these risks and agreed to have the procedure performed'\npipe = nlu.load('med_ner.jsl.wip.clinical relation.clinical').viz(data)\n```\n![entity relation visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/relation_big.png)\n\n\n## entity resolution visualization for chunks\nvisualizes resolutions of entities\napplicable to any of the [100+ resolver models see here for an overview](https://nlp.johnsnowlabs.com/models?task=entity+resolution)\n```python\nnlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(\"he took prevacid 30 mg  daily\")\n```\n![chunk resolution visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/resolve_chunk.png)\n\n```python\n# bigger example\ndata = \"this is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , copd , gastritis , and tia who initially presented to braintree with a non-st elevation mi and guaiac positive stools , transferred to st . margaret\\'s center for women &amp; infants for cardiac catheterization with ptca to mid lad lesion complicated by hypotension and bradycardia requiring atropine , iv fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to ccu for close monitoring , hemodynamically stable at the time of admission to the ccu .\"\nnlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(data)\n```\n\n![chunk resolution visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/resolve_chunk_big.png)\n\n\n## entity resolution visualization for sentences\nvisualizes resolutions of entities in sentences\napplicable to any of the [100+ resolver models see here for an overview](https://nlp.johnsnowlabs.com/models?task=entity+resolution)\n```python\nnlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz('she was diagnosed with a respiratory congestion')\n```\n![sentence resolution visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/resolve_sentence.png)\n\n```python\n# bigger example\ndata = 'the patient is a 5-month-old infant who presented initially on monday with a cold, cough, and runny nose for 2 days. mom states she had no fever. her appetite was good but she was spitting up a lot. she had no difficulty breathing and her cough was described as dry and hacky. at that time, physical exam showed a right tm, which was red. left tm was okay. she was fairly congested but looked happy and playful. she was started on amoxil and aldex and we told to recheck in 2 weeks to recheck her ear. mom returned to clinic again today because she got much worse overnight. she was having difficulty breathing. she was much more congested and her appetite had decreased significantly today. she also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion'\nnlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz(data)\n```\n![sentence resolution visualization](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/resolve_sentence_big.png)\n\n## configure visualizations\n### define custom colors for labels\nsome entity and relation labels will be highlighted with a pre-defined color, which you [can find here](https://github.com/johnsnowlabs/spark-nlp-display/tree/main/sparknlp_display/label_colors).    \nfor labels that have no color defined, a random color will be generated.     \nyou can define colors for labels manually, by specifying via the `viz_colors` parameter\nand defining `hex color codes` in a dictionary that maps `labels` to `colors` .\n```python\ndata = 'dr. john snow suggested that fritz takes 5mg penicilin for his cough'\n# define custom colors for labels\nviz_colors={'strength':'#800080', 'drug_brandname':'#77b5fe', 'gender':'#77ffe'}\nnlu.load('med_ner.jsl.wip.clinical').viz(data,viz_colors =viz_colors)\n```\n![define colors labels](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/define_colors.png)\n\n\n### filter entities that get highlighted\nby default every entity class will be visualized.    \nthe `labels_to_viz` can be used to define a set of labels to highlight.       \napplicable for ner, resolution and assert.\n```python\ndata = 'dr. john snow suggested that fritz takes 5mg penicilin for his cough'\n# filter wich ner label to viz\nlabels_to_viz=['symptom']\nnlu.load('med_ner.jsl.wip.clinical').viz(data,labels_to_viz=labels_to_viz)\n```\n![filter labels](https://raw.githubusercontent.com/johnsnowlabs/nlu/master/docs/assets/images/nlu/vizexamples/viz_module/filter_labels.png)\n\n\n## new models\nnew multilingual models for `afrikaans`, `welsh`, `maltese`, `tamil`, and`vietnamese`\n\n| nlu.load() refrence                                          | spark nlp refrence                                           |\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\n| [vi.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) |\n| [mt.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) |\n| [ta.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) |\n| [af.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) |\n| [af.pos](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) | [pos_afribooms](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) |\n| [cy.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) |\n\n## reworked and updated nlu tutorial notebooks\n\nall of the [140+ nlu tutorial notebooks](https://github.com/johnsnowlabs/nlu/tree/master/examples) have been updated and reworked to reflect the latest changes in nlu 3.0.0+\n\n\n## improved column name generation\n- nlu categorized each internal component now with boolean labels for `name_deductable` and `always_name_deductable` .\n- before generating column names, nlu checks wether each component is of unique in the pipeline or not. if a component is not unique in the\n  pipe and there are multiple components of same type, i.e. multiple `ner` models, nlu will deduct a base name for the final output columns from the\n  nlu reference each ner model is pointing to.\n- if on the other hand, there is only one `ner` model in the pipeline, only the default `ner` column prefixed will be generated.\n- for some components, like `embeddings` and `classifiers` are now defined as `always_name_deductable`, for those nlu will always try to infer a meaningful base name for the output columns.\n- newly trained component output columns will now be prefixed with `trained_&lt;type&gt;` , for types `pos` , `ner`, `classifier`, `sentiment` and `multi_classifier`\n\n## enhanced offline mode\n- you can still load a model from a path as usual with `nlu.load(path=model_path)` and output columns will be suffixed with `from_disk`\n- you can now optionally also specify `request` parameter during  load a model from hdd, it will be used to deduct more meaningful column name suffixes, instead of `from_disk`, i.e. by calling `nlu.load(request ='en.embed_sentence.biobert.pubmed_pmc_base_cased', path=model_path)`\n\n\n### bugfixes\n- fixed a bug that caused  resolution algorithms output level to be inferred incorrectly\n- fixed a bug that caused stranger cols got dropped\n- fixed a bug that caused endings to miss when  .predict(position=true) was specified\n- fixed a bug that caused pd.series to be converted incorrectly internally\n- fixed a bug that caused output level transformations to crash\n- fixed a bug that caused verbose mode not to turn of properly after turning it on.\n- fixed a bug that caused some models to crash when loaded for hdd\n\n# additional nlu resources\n* [140+ updates tutorials](https://github.com/johnsnowlabs/nlu/tree/master/examples)\n* [updated visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples)\n* [models hub](https://nlp.johnsnowlabs.com/models) with new models\n* [spark nlp publications](https://medium.com/spark-nlp)\n* [nlu in action](https://nlp.johnsnowlabs.com/demo)\n* [nlu documentation](https://nlu.johnsnowlabs.com/docs/en/install)\n* [discussions](https://github.com/johnsnowlabs/spark-nlp/discussions) engage with other community members, share ideas, and show off how you use spark nlp and nlu!\n\n# 1 line install nlu on google colab\n```!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -o - | bash```\n# 1 line install nlu on kaggle\n```!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -o - | bash```\n# install via pip\n```! pip install nlu pyspark==3.0.1```", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n5gpg4/n_1_line_to_visualizations_for_dependency_trees/',)", "identifyer": 5740055, "year": "2021"}, {"autor": "Wide-Surround-7279", "date": 1620785333000, "content": "[P] Binary Survey Data Imputation /!/ Thanks is advance. Developing a ML model from multi-year survey data and am having trouble trying to determine the best way to impute missing values. All the data features have been binarized except year. What adds to my trouble is that not all questions were asked every year leading to consistent missing values for some years. Here are some of the options I came up with:\n\n1. I don't want to simply remove items with missing data as that would remove a significant portion of the data where questions were not available for that year. So I could take that data as-is and utilize a decision tree based approach similar to XGBoost that handles missing data.\n2. I could fill the missing nan values with a large constant (i.e. -9999) which would never appear in my binary data (1/0). Then I can use any classification based approached.\n3. Search for a data imputation technique for binary survey data?\n\nAm I missing anything? Are there other options available and what about the options that I have proposed above. Thanks again!!", "link": "https://www.reddit.com/r/MachineLearning/comments/nadxkq/p_binary_survey_data_imputation/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] binary survey data imputation /!/ thanks is advance. developing a ml model from multi-year survey data and am having trouble trying to determine the best way to impute missing values. all the data features have been binarized except year. what adds to my trouble is that not all questions were asked every year leading to consistent missing values for some years. here are some of the options i came up with:\n\n1. i don't want to simply remove items with missing data as that would remove a significant portion of the data where questions were not available for that year. so i could take that data as-is and utilize a decision -----> tree !!!  based approach similar to xgboost that handles missing data.\n2. i could fill the missing nan values with a large constant (i.e. -9999) which would never appear in my binary data (1/0). then i can use any classification based approached.\n3. search for a data imputation technique for binary survey data?\n\nam i missing anything? are there other options available and what about the options that i have proposed above. thanks again!!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 6, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nadxkq/p_binary_survey_data_imputation/',)", "identifyer": 5740153, "year": "2021"}, {"autor": "True_Armadillo_4590", "date": 1623942075000, "content": "Youtube Discussion Tree API [P] /!/ Hey there!\n\n\nThis last days, i've been working on a python API that allows you to obtain the discussion that occurs in the comments of a YouTube video as a tree structure.\n\n\nYouTube Data API doesn't give enough information in order to construct the full conversation tree, because when you enter a reply to a comment that is a reply to another comment, YouTube doesn't match the parent reply Id as the one that you are replying to. Instead, it automatically puts the Id of the top level comment!\n\n\nSo I made a library that, using YouTube Data API and an algorithm that automatically resolve this kind of conflicts,  let you download the full discussion tree that happens on a YouTube video.\n\n\nThis has been made as my Final Degree Project for a Research Group of my Uni, as a module of one of his projects that is about analyzing the argumentative and the discussions that take place on Social Media. I thought that could be cool posting it here in case there is someone looking for something like this.\n\n\nYou can go check it out at:\n\n\n[https://github.com/quimpm/youtube_discussion_tree](https://github.com/quimpm/youtube_discussion_tree)\n\n\nor:\n\n\n[https://pypi.org/project/youtube-discussion-tree-api/](https://pypi.org/project/youtube-discussion-tree-api/)\n\n\nIf you have any comment on the implementation, or you want to share some features that can be added to de library, hit me up! Any kind of feedback will be pleasantly accepted!", "link": "https://www.reddit.com/r/MachineLearning/comments/o1zbyf/youtube_discussion_tree_api_p/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "youtube discussion -----> tree !!!  api [p] /!/ hey there!\n\n\nthis last days, i've been working on a python api that allows you to obtain the discussion that occurs in the comments of a youtube video as a tree structure.\n\n\nyoutube data api doesn't give enough information in order to construct the full conversation tree, because when you enter a reply to a comment that is a reply to another comment, youtube doesn't match the parent reply id as the one that you are replying to. instead, it automatically puts the id of the top level comment!\n\n\nso i made a library that, using youtube data api and an algorithm that automatically resolve this kind of conflicts,  let you download the full discussion tree that happens on a youtube video.\n\n\nthis has been made as my final degree project for a research group of my uni, as a module of one of his projects that is about analyzing the argumentative and the discussions that take place on social media. i thought that could be cool posting it here in case there is someone looking for something like this.\n\n\nyou can go check it out at:\n\n\n[https://github.com/quimpm/youtube_discussion_tree](https://github.com/quimpm/youtube_discussion_tree)\n\n\nor:\n\n\n[https://pypi.org/project/youtube-discussion-tree-api/](https://pypi.org/project/youtube-discussion-tree-api/)\n\n\nif you have any comment on the implementation, or you want to share some features that can be added to de library, hit me up! any kind of feedback will be pleasantly accepted!", "sortedWord": "None", "removed": "('nan',)", "score": 3, "comments": 3, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o1zbyf/youtube_discussion_tree_api_p/',)", "identifyer": 5740185, "year": "2021"}, {"autor": "[deleted]", "date": 1623941769000, "content": "Youtube Discusion Tree API", "link": "https://www.reddit.com/r/MachineLearning/comments/o1z7l7/youtube_discusion_tree_api/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "youtube discusion -----> tree !!!  api", "sortedWord": "None", "removed": "('deleted',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o1z7l7/youtube_discusion_tree_api/',)", "identifyer": 5740187, "year": "2021"}, {"autor": "mavavilj", "date": 1623922989000, "content": "[D] Morphological operations that use template shapes to find \"desired shapes\" from voxel spaces? How to? /!/ I was reading this paper that discusses methods to extract tree stems from LIDAR point clouds.\n\n[https://pdfs.semanticscholar.org/c01c/cfadd6ea4afb283493fd45f0766710e4079b.pdf](https://pdfs.semanticscholar.org/c01c/cfadd6ea4afb283493fd45f0766710e4079b.pdf)\n\nAround page 9 they discuss \"morphological operations\" applied on voxelized point cloud that use \"template shapes\" in order to figure out what shapes to look for.\n\nThis seems intuitive, but I'm unable to grasp, what the method of \"matching to a template\" means. It sounds like doing a model on the templates and then maybe inputting parts of the cloud there. But I am not sure.\n\nDoes one compare the entire cloud to the template or parts of it? What kinds of parts, how does one get them?", "link": "https://www.reddit.com/r/MachineLearning/comments/o1tb2x/d_morphological_operations_that_use_template/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] morphological operations that use template shapes to find \"desired shapes\" from voxel spaces? how to? /!/ i was reading this paper that discusses methods to extract -----> tree !!!  stems from lidar point clouds.\n\n[https://pdfs.semanticscholar.org/c01c/cfadd6ea4afb283493fd45f0766710e4079b.pdf](https://pdfs.semanticscholar.org/c01c/cfadd6ea4afb283493fd45f0766710e4079b.pdf)\n\naround page 9 they discuss \"morphological operations\" applied on voxelized point cloud that use \"template shapes\" in order to figure out what shapes to look for.\n\nthis seems intuitive, but i'm unable to grasp, what the method of \"matching to a template\" means. it sounds like doing a model on the templates and then maybe inputting parts of the cloud there. but i am not sure.\n\ndoes one compare the entire cloud to the template or parts of it? what kinds of parts, how does one get them?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/o1tb2x/d_morphological_operations_that_use_template/',)", "identifyer": 5740209, "year": "2021"}, {"autor": "qwertz_guy", "date": 1632487159000, "content": "[D] Libraries and ML Algorithms to build and learn from Tree-structured data? /!/ I have a dataset and part of the data reflects decisions made at different times, a series of decisions basically, and different kind of outcomes that indicate how good **the whole chain of decisions** was in the end.\n\nI'm interested in 2 things:\n\n- Build (and maybe visualize) these trees from the data\n- Understand the best decisions and series of decisions, so for example what series of decisions had on average the best outcome and in what scenarios (so conditioned on the rest of the data) were the best decisions made\n\nI'm aware of different ML/DL models and techniques but I can't fit this problem into anything I know yet. Can someone point me to a direction? Are there any Python libraries that could help me with this?", "link": "https://www.reddit.com/r/MachineLearning/comments/puivi3/d_libraries_and_ml_algorithms_to_build_and_learn/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[d] libraries and ml algorithms to build and learn from -----> tree !!! -structured data? /!/ i have a dataset and part of the data reflects decisions made at different times, a series of decisions basically, and different kind of outcomes that indicate how good **the whole chain of decisions** was in the end.\n\ni'm interested in 2 things:\n\n- build (and maybe visualize) these trees from the data\n- understand the best decisions and series of decisions, so for example what series of decisions had on average the best outcome and in what scenarios (so conditioned on the rest of the data) were the best decisions made\n\ni'm aware of different ml/dl models and techniques but i can't fit this problem into anything i know yet. can someone point me to a direction? are there any python libraries that could help me with this?", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 1, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/puivi3/d_libraries_and_ml_algorithms_to_build_and_learn/',)", "identifyer": 5740432, "year": "2021"}, {"autor": "NiceYolo", "date": 1632331736000, "content": "[P][R] Mentor needed for a Machine Learning project for the Regeneron Science Talent Search competition /!/ Hello, my son, Michael, a highly motivated senior at a CT high school, is working on a machine learning project for the 2022 Regeneron Science Talent Search. He got started and done some research and some simulations using Tensorflow, but he needs a mentor to provide guidance, review, and feedback on his project. \n\nHis project focuses on creating a machine learning model to predict financial market behavior and automatically execute buy/sell day trades to maximize gains. His model produces a price prediction using an RCNN, feeding in OCHL and Volume data and some technical indicators such as Momentum, RSI, EMA, and Bollinger Bands. Then the prediction is fed with important trade indicators into a decision tree algorithm to determine the optimal entry and exit points to trade in order to maximize profit.\n\nThe project is due by November 10th 2021. The commitment from a mentor would be 2 hours per week (via Zoom), and probably a little more time during the final 2 weeks in November. \n\nMichael is a very hardworking individual with a strong math and science background with several national competitions honor. \n\nThe ideal mentor would be a professor or anyone with strong experience in machine learning design and implementation. The mentor will be included in the project report, and will receive full credit for his/her guidance and support.\n\nMichael can share his project detail and his credentials for your consideration. \n\nThank you for your kind consideration!", "link": "https://www.reddit.com/r/MachineLearning/comments/ptchtz/pr_mentor_needed_for_a_machine_learning_project/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p][r] mentor needed for a machine learning project for the regeneron science talent search competition /!/ hello, my son, michael, a highly motivated senior at a ct high school, is working on a machine learning project for the 2022 regeneron science talent search. he got started and done some research and some simulations using tensorflow, but he needs a mentor to provide guidance, review, and feedback on his project. \n\nhis project focuses on creating a machine learning model to predict financial market behavior and automatically execute buy/sell day trades to maximize gains. his model produces a price prediction using an rcnn, feeding in ochl and volume data and some technical indicators such as momentum, rsi, ema, and bollinger bands. then the prediction is fed with important trade indicators into a decision -----> tree !!!  algorithm to determine the optimal entry and exit points to trade in order to maximize profit.\n\nthe project is due by november 10th 2021. the commitment from a mentor would be 2 hours per week (via zoom), and probably a little more time during the final 2 weeks in november. \n\nmichael is a very hardworking individual with a strong math and science background with several national competitions honor. \n\nthe ideal mentor would be a professor or anyone with strong experience in machine learning design and implementation. the mentor will be included in the project report, and will receive full credit for his/her guidance and support.\n\nmichael can share his project detail and his credentials for your consideration. \n\nthank you for your kind consideration!", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 19, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/ptchtz/pr_mentor_needed_for_a_machine_learning_project/',)", "identifyer": 5740485, "year": "2021"}, {"autor": "rohit08kumar", "date": 1621318275000, "content": "How does a split happen in tree model, if information gain for 2 or more criterion are same? /!/ [removed]", "link": "https://www.reddit.com/r/MachineLearning/comments/nf2y47/how_does_a_split_happen_in_tree_model_if/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "how does a split happen in -----> tree !!!  model, if information gain for 2 or more criterion are same? /!/ [removed]", "sortedWord": "None", "removed": "('moderator',)", "score": 1, "comments": 2, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nf2y47/how_does_a_split_happen_in_tree_model_if/',)", "identifyer": 5740786, "year": "2021"}, {"autor": "TopValue4", "date": 1620190079000, "content": "[P] What are some good models/papers for searching a tree based on a natural language query? /!/ [deleted]", "link": "https://www.reddit.com/r/MachineLearning/comments/n57li7/p_what_are_some_good_modelspapers_for_searching_a/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] what are some good models/papers for searching a -----> tree !!!  based on a natural language query? /!/ [deleted]", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/n57li7/p_what_are_some_good_modelspapers_for_searching_a/',)", "identifyer": 5740995, "year": "2021"}, {"autor": "techsucker", "date": 1631948931000, "content": "[R] Google AI Introduces Two New Families of Neural Networks Called \u2018EfficientNetV2\u2019 and \u2018CoAtNet\u2019 For Image Recognition /!/ Training efficiency has become a significant factor for deep learning as the neural network models, and training data size grows. [GPT-3](https://arxiv.org/abs/2005.14165) is an excellent example to show how critical training efficiency factor could be as it takes weeks of training with thousands of GPUs to demonstrate remarkable capabilities in few-shot learning.\n\nTo address this problem, the Google AI team introduce two families of neural networks for image recognition. First is\u00a0[EfficientNetV2](https://arxiv.org/abs/2104.00298), consisting of CNN (Convolutional neural networks) with a small-scale dataset for faster training efficiency such as\u00a0[ImageNet1k](https://www.image-net.org/)\u00a0(with 1.28 million images). Second is a hybrid model called\u00a0[CoAtNet](https://arxiv.org/abs/2106.04803), which combines\u00a0[convolution](https://en.wikipedia.org/wiki/Convolution)\u00a0and\u00a0[self-attention](https://en.wikipedia.org/wiki/Self-attention)\u00a0to achieve higher accuracy on large-scale datasets such as\u00a0[ImageNet21](https://www.image-net.org/)\u00a0(with 13 million images) and\u00a0[JFT](https://ai.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html)\u00a0(with billions of images). As per the research report by Google,\u00a0[EfficientNetV2](https://arxiv.org/abs/2104.00298)\u00a0and\u00a0[CoAtNet](https://arxiv.org/abs/2106.04803)\u00a0both are 4 to 10 times faster while achieving state-of-the-art and 90.88% top-1 accuracy on the well-established\u00a0[ImageNet](https://www.image-net.org/)\u00a0dataset.\n\n# [7 Min Read](https://www.marktechpost.com/2021/09/17/google-ai-introduces-two-new-families-of-neural-networks-called-efficientnetv2-and-coatnet-for-image-recognition/) | [Paper (CoAtNet)](https://arxiv.org/abs/2106.04803) | [Paper (EfficientNetV2)](https://arxiv.org/abs/2104.00298) | [Google blog](https://ai.googleblog.com/2021/09/toward-fast-and-accurate-neural.html) | [Code](https://github.com/google/automl/tree/master/efficientnetv2)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ipmkyt7eo7o71.png?width=1392&amp;format=png&amp;auto=webp&amp;s=22764f4268a6c12acb85b8b71a7331cc6446d984", "link": "https://www.reddit.com/r/MachineLearning/comments/pqhqjv/r_google_ai_introduces_two_new_families_of_neural/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[r] google ai introduces two new families of neural networks called \u2018efficientnetv2\u2019 and \u2018coatnet\u2019 for image recognition /!/ training efficiency has become a significant factor for deep learning as the neural network models, and training data size grows. [gpt-3](https://arxiv.org/abs/2005.14165) is an excellent example to show how critical training efficiency factor could be as it takes weeks of training with thousands of gpus to demonstrate remarkable capabilities in few-shot learning.\n\nto address this problem, the google ai team introduce two families of neural networks for image recognition. first is\u00a0[efficientnetv2](https://arxiv.org/abs/2104.00298), consisting of cnn (convolutional neural networks) with a small-scale dataset for faster training efficiency such as\u00a0[imagenet1k](https://www.image-net.org/)\u00a0(with 1.28 million images). second is a hybrid model called\u00a0[coatnet](https://arxiv.org/abs/2106.04803), which combines\u00a0[convolution](https://en.wikipedia.org/wiki/convolution)\u00a0and\u00a0[self-attention](https://en.wikipedia.org/wiki/self-attention)\u00a0to achieve higher accuracy on large-scale datasets such as\u00a0[imagenet21](https://www.image-net.org/)\u00a0(with 13 million images) and\u00a0[jft](https://ai.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html)\u00a0(with billions of images). as per the research report by google,\u00a0[efficientnetv2](https://arxiv.org/abs/2104.00298)\u00a0and\u00a0[coatnet](https://arxiv.org/abs/2106.04803)\u00a0both are 4 to 10 times faster while achieving state-of-the-art and 90.88% top-1 accuracy on the well-established\u00a0[imagenet](https://www.image-net.org/)\u00a0dataset.\n\n# [7 min read](https://www.marktechpost.com/2021/09/17/google-ai-introduces-two-new-families-of-neural-networks-called-efficientnetv2-and-coatnet-for-image-recognition/) | [paper (coatnet)](https://arxiv.org/abs/2106.04803) | [paper (efficientnetv2)](https://arxiv.org/abs/2104.00298) | [google blog](https://ai.googleblog.com/2021/09/toward-fast-and-accurate-neural.html) | [code](https://github.com/google/automl/-----> tree !!! /master/efficientnetv2)\n\n&amp;#x200b;\n\nhttps://preview.redd.it/ipmkyt7eo7o71.png?width=1392&amp;format=png&amp;auto=webp&amp;s=22764f4268a6c12acb85b8b71a7331cc6446d984", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 13, "media": "('nan',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/pqhqjv/r_google_ai_introduces_two_new_families_of_neural/',)", "identifyer": 5741001, "year": "2021"}, {"autor": "Successful-Forever12", "date": 1622046327000, "content": "[P] Need help deploying Teachable Machine model to TFLite Micro on Arduino Nano BLE 33 /!/ Hi all, \n\nI'm trying to use the [Person Detection TFLite Micro](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/person_detection) example project as a template and insert my own model that I've created using [TeachableMachine.](https://teachablemachine.withgoogle.com/) However, it's not working as expected, and giving a \"Invoke Failed()\" error in the serial monitor when I run the script on my Nano 33 BLE. Can someone please take a look and tell me what I did wrong?\n\nHere is how I approached it:\n\n1) Create a model with [Teachable Machine](https://teachablemachine.withgoogle.com/)\n\n2) Download my model as a keras file\n\n3) Convert from Keras model to tflite model, and then integer quantize the model using the code here: [https://colab.research.google.com/drive/12O9qO6bAI72B0RTt88sQPkcHkC16Mb8O#scrollTo=cKTbVvb2Vsyo](https://colab.research.google.com/drive/12O9qO6bAI72B0RTt88sQPkcHkC16Mb8O#scrollTo=cKTbVvb2Vsyo)\n\n4) Convert from tflite to .cc using : `xxd -i converted_model.tflite &gt; model_data.cc`\n\n5) Replace value of g\\_person\\_detect\\_model\\_data\\_len with new value from my model\\_data.cc\n\n6) Replace model\\_data with new model data from my model\\_data.cc\n\n7) Use [https://netron.app/](https://netron.app/) to visualize the network and see what MicroOpsResolvers need to be included. Include as necessary.\n\nThe only two files in the project that I touch at all are person\\_detection.ino and person\\_detection\\_model\\_data.cpp. Please help me figure out why it's not working!!!\n\nHere is my person\\_detection.ino file for you to look at:\n\n    /* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n    \n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n    \n        http://www.apache.org/licenses/LICENSE-2.0\n    \n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n    ==============================================================================*/\n    \n    #include &lt;TensorFlowLite.h&gt;\n    \n    #include \"main_functions.h\"\n    \n    #include \"detection_responder.h\"\n    #include \"image_provider.h\"\n    #include \"model_settings.h\"\n    #include \"person_detect_model_data.h\"\n    #include \"tensorflow/lite/micro/micro_error_reporter.h\"\n    #include \"tensorflow/lite/micro/micro_interpreter.h\"\n    #include \"tensorflow/lite/micro/micro_mutable_op_resolver.h\"\n    #include \"tensorflow/lite/schema/schema_generated.h\"\n    #include \"tensorflow/lite/version.h\"\n    \n    // Globals, used for compatibility with Arduino-style sketches.\n    namespace {\n    tflite::ErrorReporter* error_reporter = nullptr;\n    const tflite::Model* model = nullptr;\n    tflite::MicroInterpreter* interpreter = nullptr;\n    TfLiteTensor* input = nullptr;\n    \n    // In order to use optimized tensorflow lite kernels, a signed int8_t quantized\n    // model is preferred over the legacy unsigned model format. This means that\n    // throughout this project, input images must be converted from unisgned to\n    // signed format. The easiest and quickest way to convert from unsigned to\n    // signed 8-bit integers is to subtract 128 from the unsigned value to get a\n    // signed value.\n    \n    // An area of memory to use for input, output, and intermediate arrays.\n    constexpr int kTensorArenaSize = 136 * 1024;\n    static uint8_t tensor_arena[kTensorArenaSize];\n    }  // namespace\n    \n    // The name of this function is important for Arduino compatibility.\n    void setup() {\n      // Set up logging. Google style is to avoid globals or statics because of\n      // lifetime uncertainty, but since this has a trivial destructor it's okay.\n      // NOLINTNEXTLINE(runtime-global-variables)\n      static tflite::MicroErrorReporter micro_error_reporter;\n      error_reporter = &amp;micro_error_reporter;\n    \n      // Map the model into a usable data structure. This doesn't involve any\n      // copying or parsing, it's a very lightweight operation.\n      model = tflite::GetModel(g_person_detect_model_data);\n      if (model-&gt;version() != TFLITE_SCHEMA_VERSION) {\n        TF_LITE_REPORT_ERROR(error_reporter,\n                             \"Model provided is schema version %d not equal \"\n                             \"to supported version %d.\",\n                             model-&gt;version(), TFLITE_SCHEMA_VERSION);\n        return;\n      }\n    \n      // Pull in only the operation implementations we need.\n      // This relies on a complete list of all the ops needed by this graph.\n      // An easier approach is to just use the AllOpsResolver, but this will\n      // incur some penalty in code space for op implementations that are not\n      // needed by this graph.\n      //\n      // tflite::AllOpsResolver resolver;\n      // NOLINTNEXTLINE(runtime-global-variables)\n      static tflite::MicroMutableOpResolver&lt;10&gt; micro_op_resolver;\n    \n      micro_op_resolver.AddPad();\n      micro_op_resolver.AddConv2D();\n      micro_op_resolver.AddDepthwiseConv2D();\n      micro_op_resolver.AddSoftmax();\n      micro_op_resolver.AddRelu6();\n      micro_op_resolver.AddRelu();\n      micro_op_resolver.AddAdd();\n      micro_op_resolver.AddMean();\n      micro_op_resolver.AddFullyConnected();\n      micro_op_resolver.AddQuantize();\n    \n      // Build an interpreter to run the model with.\n      // NOLINTNEXTLINE(runtime-global-variables)\n      static tflite::MicroInterpreter static_interpreter(\n          model, micro_op_resolver, tensor_arena, kTensorArenaSize, error_reporter);\n      interpreter = &amp;static_interpreter;\n    \n      // Allocate memory from the tensor_arena for the model's tensors.\n      TfLiteStatus allocate_status = interpreter-&gt;AllocateTensors();\n      if (allocate_status != kTfLiteOk) {\n        TF_LITE_REPORT_ERROR(error_reporter, \"AllocateTensors() failed\");\n        return;\n      }\n    \n      // Get information about the memory area to use for the model's input.\n      input = interpreter-&gt;input(0);\n    }\n    \n    // The name of this function is important for Arduino compatibility.\n    void loop() {\n      // Get image from provider.\n      if (kTfLiteOk != GetImage(error_reporter, kNumCols, kNumRows, kNumChannels,\n                                input-&gt;data.int8)) {\n        TF_LITE_REPORT_ERROR(error_reporter, \"Image capture failed.\");\n      }\n    \n      // Run the model on this input and make sure it succeeds.\n      if (kTfLiteOk != interpreter-&gt;Invoke()) {\n        TF_LITE_REPORT_ERROR(error_reporter, \"Invoke failed.\");\n      }\n    \n      TfLiteTensor* output = interpreter-&gt;output(0);\n    \n      // Process the inference results.\n      int8_t person_score = output-&gt;data.uint8[kPersonIndex];\n      int8_t no_person_score = output-&gt;data.uint8[kNotAPersonIndex];\n      RespondToDetection(error_reporter, person_score, no_person_score);\n    }", "link": "https://www.reddit.com/r/MachineLearning/comments/nll1ey/p_need_help_deploying_teachable_machine_model_to/", "origin": "Reddit", "suborigin": "MachineLearning", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "[p] need help deploying teachable machine model to tflite micro on arduino nano ble 33 /!/ hi all, \n\ni'm trying to use the [person detection tflite micro](https://github.com/tensorflow/tensorflow/-----> tree !!! /master/tensorflow/lite/micro/examples/person_detection) example project as a template and insert my own model that i've created using [teachablemachine.](https://teachablemachine.withgoogle.com/) however, it's not working as expected, and giving a \"invoke failed()\" error in the serial monitor when i run the script on my nano 33 ble. can someone please take a look and tell me what i did wrong?\n\nhere is how i approached it:\n\n1) create a model with [teachable machine](https://teachablemachine.withgoogle.com/)\n\n2) download my model as a keras file\n\n3) convert from keras model to tflite model, and then integer quantize the model using the code here: [https://colab.research.google.com/drive/12o9qo6bai72b0rtt88sqpkchkc16mb8o#scrollto=cktbvvb2vsyo](https://colab.research.google.com/drive/12o9qo6bai72b0rtt88sqpkchkc16mb8o#scrollto=cktbvvb2vsyo)\n\n4) convert from tflite to .cc using : `xxd -i converted_model.tflite &gt; model_data.cc`\n\n5) replace value of g\\_person\\_detect\\_model\\_data\\_len with new value from my model\\_data.cc\n\n6) replace model\\_data with new model data from my model\\_data.cc\n\n7) use [https://netron.app/](https://netron.app/) to visualize the network and see what microopsresolvers need to be included. include as necessary.\n\nthe only two files in the project that i touch at all are person\\_detection.ino and person\\_detection\\_model\\_data.cpp. please help me figure out why it's not working!!!\n\nhere is my person\\_detection.ino file for you to look at:\n\n    /* copyright 2019 the tensorflow authors. all rights reserved.\n    \n    licensed under the apache license, version 2.0 (the \"license\");\n    you may not use this file except in compliance with the license.\n    you may obtain a copy of the license at\n    \n        http://www.apache.org/licenses/license-2.0\n    \n    unless required by applicable law or agreed to in writing, software\n    distributed under the license is distributed on an \"as is\" basis,\n    without warranties or conditions of any kind, either express or implied.\n    see the license for the specific language governing permissions and\n    limitations under the license.\n    ==============================================================================*/\n    \n    #include &lt;tensorflowlite.h&gt;\n    \n    #include \"main_functions.h\"\n    \n    #include \"detection_responder.h\"\n    #include \"image_provider.h\"\n    #include \"model_settings.h\"\n    #include \"person_detect_model_data.h\"\n    #include \"tensorflow/lite/micro/micro_error_reporter.h\"\n    #include \"tensorflow/lite/micro/micro_interpreter.h\"\n    #include \"tensorflow/lite/micro/micro_mutable_op_resolver.h\"\n    #include \"tensorflow/lite/schema/schema_generated.h\"\n    #include \"tensorflow/lite/version.h\"\n    \n    // globals, used for compatibility with arduino-style sketches.\n    namespace {\n    tflite::errorreporter* error_reporter = nullptr;\n    const tflite::model* model = nullptr;\n    tflite::microinterpreter* interpreter = nullptr;\n    tflitetensor* input = nullptr;\n    \n    // in order to use optimized tensorflow lite kernels, a signed int8_t quantized\n    // model is preferred over the legacy unsigned model format. this means that\n    // throughout this project, input images must be converted from unisgned to\n    // signed format. the easiest and quickest way to convert from unsigned to\n    // signed 8-bit integers is to subtract 128 from the unsigned value to get a\n    // signed value.\n    \n    // an area of memory to use for input, output, and intermediate arrays.\n    constexpr int ktensorarenasize = 136 * 1024;\n    static uint8_t tensor_arena[ktensorarenasize];\n    }  // namespace\n    \n    // the name of this function is important for arduino compatibility.\n    void setup() {\n      // set up logging. google style is to avoid globals or statics because of\n      // lifetime uncertainty, but since this has a trivial destructor it's okay.\n      // nolintnextline(runtime-global-variables)\n      static tflite::microerrorreporter micro_error_reporter;\n      error_reporter = &amp;micro_error_reporter;\n    \n      // map the model into a usable data structure. this doesn't involve any\n      // copying or parsing, it's a very lightweight operation.\n      model = tflite::getmodel(g_person_detect_model_data);\n      if (model-&gt;version() != tflite_schema_version) {\n        tf_lite_report_error(error_reporter,\n                             \"model provided is schema version %d not equal \"\n                             \"to supported version %d.\",\n                             model-&gt;version(), tflite_schema_version);\n        return;\n      }\n    \n      // pull in only the operation implementations we need.\n      // this relies on a complete list of all the ops needed by this graph.\n      // an easier approach is to just use the allopsresolver, but this will\n      // incur some penalty in code space for op implementations that are not\n      // needed by this graph.\n      //\n      // tflite::allopsresolver resolver;\n      // nolintnextline(runtime-global-variables)\n      static tflite::micromutableopresolver&lt;10&gt; micro_op_resolver;\n    \n      micro_op_resolver.addpad();\n      micro_op_resolver.addconv2d();\n      micro_op_resolver.adddepthwiseconv2d();\n      micro_op_resolver.addsoftmax();\n      micro_op_resolver.addrelu6();\n      micro_op_resolver.addrelu();\n      micro_op_resolver.addadd();\n      micro_op_resolver.addmean();\n      micro_op_resolver.addfullyconnected();\n      micro_op_resolver.addquantize();\n    \n      // build an interpreter to run the model with.\n      // nolintnextline(runtime-global-variables)\n      static tflite::microinterpreter static_interpreter(\n          model, micro_op_resolver, tensor_arena, ktensorarenasize, error_reporter);\n      interpreter = &amp;static_interpreter;\n    \n      // allocate memory from the tensor_arena for the model's tensors.\n      tflitestatus allocate_status = interpreter-&gt;allocatetensors();\n      if (allocate_status != ktfliteok) {\n        tf_lite_report_error(error_reporter, \"allocatetensors() failed\");\n        return;\n      }\n    \n      // get information about the memory area to use for the model's input.\n      input = interpreter-&gt;input(0);\n    }\n    \n    // the name of this function is important for arduino compatibility.\n    void loop() {\n      // get image from provider.\n      if (ktfliteok != getimage(error_reporter, knumcols, knumrows, knumchannels,\n                                input-&gt;data.int8)) {\n        tf_lite_report_error(error_reporter, \"image capture failed.\");\n      }\n    \n      // run the model on this input and make sure it succeeds.\n      if (ktfliteok != interpreter-&gt;invoke()) {\n        tf_lite_report_error(error_reporter, \"invoke failed.\");\n      }\n    \n      tflitetensor* output = interpreter-&gt;output(0);\n    \n      // process the inference results.\n      int8_t person_score = output-&gt;data.uint8[kpersonindex];\n      int8_t no_person_score = output-&gt;data.uint8[knotapersonindex];\n      respondtodetection(error_reporter, person_score, no_person_score);\n    }", "sortedWord": "None", "removed": "('nan',)", "score": 1, "comments": 0, "media": "('self',)", "medialink": "('https://www.reddit.com/r/MachineLearning/comments/nll1ey/p_need_help_deploying_teachable_machine_model_to/',)", "identifyer": 5741032, "year": "2021"}], "name": "treeMachineLearning2021"}