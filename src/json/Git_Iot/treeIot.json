{"interestingcomments": [{"Unnamed: 0": 16, "autor": 16, "date": null, "content": "Mongoose - Embedded Web Server / Embedded Networking Library\nMongoose is a networking library for C/C++. It implements event-driven non-blocking APIs for TCP, UDP, HTTP, WebSocket, MQTT. It is designed for connecting devices and bringing them online. On the market since 2004, used by vast number of open source and commercial products - it even runs on the International Space Station! Mongoose makes embedded network programming fast, robust, and easy. Features include:\nCross-platform: works on Linux/UNIX, MacOS, Windows, Android, FreeRTOS, etc.\nSupported embedded architectures: ESP32, NRF52, STM32, NXP, and more\nBuilt-in protocols: plain TCP/UDP, HTTP, MQTT, Websocket\nSSL/TLS support: mbedTLS, OpenSSL or custom (via API)\nAsynchronous DNS resolver\nTiny static and run-time footprint\nSource code is both ISO C and ISO C++ compliant\nWorks with any network stack with socket API, like LwIP or FreeRTOS-Plus-TCP\nVery easy to integrate: just copy mongoose.c and mongoose.h files to your build tree\nDetailed documentation and tutorials\nCommercial use\nMongoose is used by hundreds of businesses, from Fortune500 giants like Siemens, Schneider Electric, Broadcom, Bosch, Google, Samsung, Qualcomm, Caterpillar to the small businesses\nUsed to solve a wide range of business needs, like implementing Web UI interface on devices, RESTful API services, telemetry data exchange, remote control for a product, remote software updates, remote monitoring, and others\nDeployed to hundreds of millions devices in production environment worldwide\nSee Case Studies from our respected customers like Schneider Electric (industrial automation), Broadcom (semiconductors), Pilz (industrial automation), and others\nSee Testimonials from engineers that integrated Mongoose in their commercial products\nWe provide commercial licensing, support, consultancy and integration assistance - don't hesitate to contact us\nSecurity\nWe take security seriously:\nMongoose repository runs a continuous integration test powered by GitHub, which runs through hundreds of unit tests on every commit to the repository. Our unit tests are built with modern address sanitizer technologies, which help to find security vulnerabilities early\nMongoose repository is integrated into Google's oss-fuzz continuous fuzzer which scans for potential vulnerabilities continuously\nWe receive periodic vulnerability reports from the independent security groups like Cisco Talos, Microsoft Security Response Center, MITRE Corporation, Compass Security and others. In case of the vulnerability found, we act according to the industry best practice: hold on to the publication, fix the software and notify all our customers that have an appropriate subscription\nSome of our customers (for example NASA) have specific security requirements and run independent security audits, of which we get notified and in case of any issue, act similar to (3).\nSupplement software\nThis software is often used together with Mongoose:\nmjson - a JSON parser, emitter and JSON-RPC engine. Used to implement RESTful APIs that use JSON, or implement data exchange (e.g. over MQTT or Websocket) that use JSON for data encapsulation\nelk - a tiny JavaScript engine. Used to implement scripting support\nContributions\nContributions are welcome! Please follow the guidelines below:\nSign Cesanta CLA and send GitHub pull request\nMake sure that PRs have only one commit, and deal with one issue only", "link": "https://github.com/cesanta/mongoose", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "mongoose - embedded web server / embedded networking library\nmongoose is a networking library for c/c++. it implements event-driven non-blocking apis for tcp, udp, http, websocket, mqtt. it is designed for connecting devices and bringing them online. on the market since 2004, used by vast number of open source and commercial products - it even runs on the international space station! mongoose makes embedded network programming fast, robust, and easy. features include:\ncross-platform: works on linux/unix, macos, windows, android, freertos, etc.\nsupported embedded architectures: esp32, nrf52, stm32, nxp, and more\nbuilt-in protocols: plain tcp/udp, http, mqtt, websocket\nssl/tls support: mbedtls, openssl or custom (via api)\nasynchronous dns resolver\ntiny static and run-time footprint\nsource code is both iso c and iso c++ compliant\nworks with any network stack with socket api, like lwip or freertos-plus-tcp\nvery easy to integrate: just copy mongoose.c and mongoose.h files to your build -----> tree !!! \ndetailed documentation and tutorials\ncommercial use\nmongoose is used by hundreds of businesses, from fortune500 giants like siemens, schneider electric, broadcom, bosch, google, samsung, qualcomm, caterpillar to the small businesses\nused to solve a wide range of business needs, like implementing web ui interface on devices, restful api services, telemetry data exchange, remote control for a product, remote software updates, remote monitoring, and others\ndeployed to hundreds of millions devices in production environment worldwide\nsee case studies from our respected customers like schneider electric (industrial automation), broadcom (semiconductors), pilz (industrial automation), and others\nsee testimonials from engineers that integrated mongoose in their commercial products\nwe provide commercial licensing, support, consultancy and integration assistance - don't hesitate to contact us\nsecurity\nwe take security seriously:\nmongoose repository runs a continuous integration test powered by github, which runs through hundreds of unit tests on every commit to the repository. our unit tests are built with modern address sanitizer technologies, which help to find security vulnerabilities early\nmongoose repository is integrated into google's oss-fuzz continuous fuzzer which scans for potential vulnerabilities continuously\nwe receive periodic vulnerability reports from the independent security groups like cisco talos, microsoft security response center, mitre corporation, compass security and others. in case of the vulnerability found, we act according to the industry best practice: hold on to the publication, fix the software and notify all our customers that have an appropriate subscription\nsome of our customers (for example nasa) have specific security requirements and run independent security audits, of which we get notified and in case of any issue, act similar to (3).\nsupplement software\nthis software is often used together with mongoose:\nmjson - a json parser, emitter and json-rpc engine. used to implement restful apis that use json, or implement data exchange (e.g. over mqtt or websocket) that use json for data encapsulation\nelk - a tiny javascript engine. used to implement scripting support\ncontributions\ncontributions are welcome! please follow the guidelines below:\nsign cesanta cla and send github pull request\nmake sure that prs have only one commit, and deal with one issue only", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000016, "year": null}, {"Unnamed: 0": 20, "autor": 20, "date": null, "content": "Full Repository Status\n\ud83c\udfc6 The Complete FAANG Preparation \ud83c\udfc6\nThis repository contains all the DSA (Data-Structures, Algorithms, 450 DSA by Love Babbar Bhaiya, FAANG Questions), Technical Subjects (OS + DBMS + SQL + CN + OOPs) Theory+Questions,FAANG Interview questions and Miscellaneous Stuff (Programming MCQs, Puzzles, Aptitude, Reasoning). The Programming languages used for demonstration are the C++, Python, and Java.\nApplying to internships?\nAutofill all your applications in a single click.\nStop manually re-entering your information. Simplify\u2019s extension helps you autofill internship applications on millions of sites.\nTable of Contents \ud83d\udccb\nSNo. Contents\n1. Miscellaneous Stuff\n2. DSA\n3. Competitive Programming\n4. Technical Subject\n5. Low Level Design\n6. Projects\n7. Important Books and Resources\n8. Behavioural Interview Questions\nTree of Index \ud83d\ude80\n.\n\u251c\u2500\u2500 ...\n\u251c\u2500\u2500 \ud835\udc74\ud835\udc8a\ud835\udc94\ud835\udc84\ud835\udc86\ud835\udc8d\ud835\udc8d\ud835\udc82\ud835\udc8f\ud835\udc86\ud835\udc90\ud835\udc96\ud835\udc94 \ud835\udc7a\ud835\udc95\ud835\udc96\ud835\udc87\ud835\udc87\n| \u251c\u2500\u2500 Aptitude & Reasoning\n| | \u251c\u2500\u2500 Quantitative Analysis\n| | \u251c\u2500\u2500 Logical and Verbal Reasoning\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Basic Programming+Technical MCQs\n| | \u251c\u2500\u2500 C Programming\n| | \u251c\u2500\u2500 C++ Programming\n| | \u251c\u2500\u2500 Python Programming\n| | \u251c\u2500\u2500 Java Programming\n| | \u251c\u2500\u2500 Object Oriented Programming (OOP)\n| | \u251c\u2500\u2500 Operating System (OS)\n| | \u251c\u2500\u2500 Database Management System (DBMS)\n| | \u251c\u2500\u2500 Structured Query Language (SQL)\n| | \u251c\u2500\u2500 Computer Network (CN)\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Puzzles\n| | \u2514\u2500\u2500 ...\n| |\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc6b\ud835\udc7a\ud835\udc68\n| \u251c\u2500\u2500 Data Structures\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Algorithms\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 450 DSA by Love Babbar\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Striver Series\n| | \u251c\u2500\u2500 30 Days of SDE Sheet\n| | \u251c\u2500\u2500 Algorithms for Coding Round Sheet\n| | \u251c\u2500\u2500 Competitive Programming Sheet\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 FAANG Interview Questions\n| | \u251c\u2500\u2500 Facebook\n| | \u251c\u2500\u2500 Amazon\n| | \u251c\u2500\u2500 Apple\n| | \u251c\u2500\u2500 Netflix\n| | \u251c\u2500\u2500 Google\n| | \u251c\u2500\u2500 Others\n| | \u2514\u2500\u2500 ...\n| |\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc6a\ud835\udc90\ud835\udc8e\ud835\udc91\ud835\udc86\ud835\udc95\ud835\udc8a\ud835\udc95\ud835\udc8a\ud835\udc97\ud835\udc86 \ud835\udc77\ud835\udc93\ud835\udc90\ud835\udc88\ud835\udc93\ud835\udc82\ud835\udc8e\ud835\udc8e\ud835\udc8a\ud835\udc8f\ud835\udc88\n| \u251c\u2500\u2500 Google\n| | \u251c\u2500\u2500 Code Jam\n| | | \u251c\u2500\u2500 2017\n| | | \u251c\u2500\u2500 2018\n| | | \u251c\u2500\u2500 2019\n| | | \u251c\u2500\u2500 2020\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Hash Code\n| | | \u251c\u2500\u2500 2016\n| | | \u251c\u2500\u2500 2017\n| | | \u251c\u2500\u2500 2018\n| | | \u251c\u2500\u2500 2019\n| | | \u251c\u2500\u2500 2020\n| | | \u251c\u2500\u2500 2021\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Kick Start\n| | | \u251c\u2500\u2500 2017\n| | | \u251c\u2500\u2500 2018\n| | | \u251c\u2500\u2500 2019\n| | | \u251c\u2500\u2500 2020\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Facebook\n| | \u251c\u2500\u2500 Hacker Cup\n| | | \u251c\u2500\u2500 2011\n| | | \u251c\u2500\u2500 2012\n| | | \u251c\u2500\u2500 2013\n| | | \u251c\u2500\u2500 2014\n| | | \u251c\u2500\u2500 2015\n| | | \u251c\u2500\u2500 2016\n| | | \u251c\u2500\u2500 2017\n| | | \u251c\u2500\u2500 2018\n| | | \u251c\u2500\u2500 2019\n| | | \u251c\u2500\u2500 2020\n| | | \u251c\u2500\u2500 2021\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 FB Hack\n| | | \u251c\u2500\u2500 2020\n| | | \u251c\u2500\u2500 2021\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 GeeksforGeeks\n| | \u251c\u2500\u2500 Data Structures\n| | \u251c\u2500\u2500 Algorithms\n| | \u251c\u2500\u2500 Must Do Coding Questions\n| | \u251c\u2500\u2500 Competitive Programming \u2013 A Complete Guide\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 LeetCode\n| | \u251c\u2500\u2500 Problems\n| | \u251c\u2500\u2500 Contests\n| | | \u251c\u2500\u2500 Weekly Contests\n| | | \u251c\u2500\u2500 Biweekly Contests\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 HackerRank\n| | \u251c\u2500\u2500 Practice\n| | | \u251c\u2500\u2500 C\n| | | \u251c\u2500\u2500 C++\n| | | \u251c\u2500\u2500 Python\n| | | \u251c\u2500\u2500 Java\n| | | \u251c\u2500\u2500 SQL\n| | | \u251c\u2500\u2500 Database\n| | | \u251c\u2500\u2500 Interview Preparation Kit\n| | | \u251c\u2500\u2500 Problem Solving\n| | | | \u251c\u2500\u2500 Data Structures\n| | | | \u2514\u2500\u2500 Algorithms\n| | | \u251c\u2500\u2500 Mathematics\n| | | \u251c\u2500\u2500 30 Days of Code\n| | | \u251c\u2500\u2500 10 Days of JavaScript\n| | | \u251c\u2500\u2500 10 Days of Statistics\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Compete\n| | | \u251c\u2500\u2500 ProjectEuler+\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 HackerEarth\n| | \u251c\u2500\u2500 Practice\n| | | \u251c\u2500\u2500 Basic Programming\n| | | \u251c\u2500\u2500 Data Structures\n| | | \u251c\u2500\u2500 Algorithms\n| | | \u251c\u2500\u2500 Math\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Compete\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 CodeChef\n| | \u251c\u2500\u2500 PRACTICE & LEARN\n| | | \u251c\u2500\u2500 Beginner\n| | | \u251c\u2500\u2500 Easy\n| | | \u251c\u2500\u2500 Medium\n| | | \u251c\u2500\u2500 Hard\n| | | \u251c\u2500\u2500 Challenge\n| | | \u2514\u2500\u2500 Peer\n| | |\n| | \u251c\u2500\u2500 Compete\n| | | \u251c\u2500\u2500 Long Challenge\n| | | | \u251c\u2500\u2500 Div-1\n| | | | \u251c\u2500\u2500 Div-2\n| | | | \u251c\u2500\u2500 Div-3\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 Cook-off\n| | | | \u251c\u2500\u2500 Div-1\n| | | | \u251c\u2500\u2500 Div-2\n| | | | \u251c\u2500\u2500 Div-3\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 Lunch Time\n| | | | \u251c\u2500\u2500 Div-1\n| | | | \u251c\u2500\u2500 Div-2\n| | | | \u251c\u2500\u2500 Div-3\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 CodeForces\n| | \u251c\u2500\u2500 Problem_Set\n| | | \u251c\u2500\u2500 Levels\n| | | | \u251c\u2500\u2500 A\n| | | | \u251c\u2500\u2500 B\n| | | | \u251c\u2500\u2500 C\n| | | | \u251c\u2500\u2500 D\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Contests\n| | | \u251c\u2500\u2500 Rounds\n| | | | \u251c\u2500\u2500 Div-1\n| | | | \u251c\u2500\u2500 Div-2\n| | | | \u251c\u2500\u2500 Div-3\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 InterviewBit\n| | \u251c\u2500\u2500 Programming\n| | | \u251c\u2500\u2500 Time Complexity Problems\n| | | \u251c\u2500\u2500 Arrays\n| | | \u251c\u2500\u2500 Math\n| | | \u251c\u2500\u2500 Binary Search\n| | | \u251c\u2500\u2500 String\n| | | \u251c\u2500\u2500 Bit Manipulation\n| | | \u251c\u2500\u2500 Two Pointers\n| | | \u251c\u2500\u2500 Linked List\n| | | \u251c\u2500\u2500 Stack & Queue\n| | | \u251c\u2500\u2500 Backtracking\n| | | \u251c\u2500\u2500 Hashing\n| | | \u251c\u2500\u2500 Heap & Map\n| | | \u251c\u2500\u2500 Tree Data Structure\n| | | \u251c\u2500\u2500 Dynamic Programming\n| | | \u251c\u2500\u2500 Greedy Algorithm\n| | | \u251c\u2500\u2500 Graph Data Structure & Algorithms\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Contests\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc7b\ud835\udc86\ud835\udc84\ud835\udc89\ud835\udc8f\ud835\udc8a\ud835\udc84\ud835\udc82\ud835\udc8d \ud835\udc7a\ud835\udc96\ud835\udc83\ud835\udc8b\ud835\udc86\ud835\udc84\ud835\udc95\n| \u251c\u2500\u2500 Object Oriented Programming (OOP)\n| | \u251c\u2500\u2500 OOP.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Operating System (OS)\n| | \u251c\u2500\u2500 OS.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Database Management System (DBMS)\n| | \u251c\u2500\u2500 DBMS.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Structured Query Language (SQL)\n| | \u251c\u2500\u2500 SQL.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Computer Network (CN)\n| | \u251c\u2500\u2500 CN.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Interview Questions\n| | \u251c\u2500\u2500 OOP\n| | \u251c\u2500\u2500 OS\n| | \u251c\u2500\u2500 DBMS\n| | \u251c\u2500\u2500 SQL\n| | \u251c\u2500\u2500 CN\n| | \u2514\u2500\u2500 ...\n| |\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc73\ud835\udc90\ud835\udc98 \ud835\udc73\ud835\udc86\ud835\udc97\ud835\udc86\ud835\udc8d \ud835\udc6b\ud835\udc86\ud835\udc94\ud835\udc8a\ud835\udc88\ud835\udc8f\n| \u251c\u2500\u2500 Object Oriented Design\n| | \u251c\u2500\u2500 Introduciton to Classes and Objects\n| | \u251c\u2500\u2500 Software Development Process\n| | \u251c\u2500\u2500 Introduction to UML\n| | \u251c\u2500\u2500 Class Diagrams and Object Diagrams\n| | \u251c\u2500\u2500 Use Case Diagrams\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Case Study\n| | \u2514\u2500\u2500 ...\n| |\n\u2502 \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc77\ud835\udc93\ud835\udc90\ud835\udc8b\ud835\udc86\ud835\udc84\ud835\udc95\ud835\udc94\n| \u251c\u2500\u2500 Machine Learning & Data Science\n| | \u251c\u2500\u2500 Data Analysis\n| | \u251c\u2500\u2500 Deep Learning\n| | | \u251c\u2500\u2500 Computer Vision\n| | | \u251c\u2500\u2500 Natural Language Processing\n| | | \u2514\u2500\u2500 ...\n| | \u251c\u2500\u2500 Machine Learning\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Internet of Things (IoT)\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Web Development\n| | \u251c\u2500\u2500 JavaScript Projects\n| | \u251c\u2500\u2500 ReactJS Projects\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Mobile Development\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Desktop Development\n| | \u251c\u2500\u2500 Console Projects\n| | \u251c\u2500\u2500 GUI Projects\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Blockchain Development\n| | \u2514\u2500\u2500 ...\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc70\ud835\udc8e\ud835\udc91\ud835\udc90\ud835\udc93\ud835\udc95\ud835\udc82\ud835\udc8f\ud835\udc95 \ud835\udc69\ud835\udc90\ud835\udc90\ud835\udc8c\ud835\udc94 \ud835\udc82\ud835\udc8f\ud835\udc85 \ud835\udc79\ud835\udc86\ud835\udc94\ud835\udc90\ud835\udc96\ud835\udc93\ud835\udc84\ud835\udc86\ud835\udc94\n| \u251c\u2500\u2500 Important Books\n| | \u251c\u2500\u2500 Programming Language\n| | | \u251c\u2500\u2500 C\n| | | | \u251c\u2500\u2500 Let Us C by Yashwant P. Kanetkar\n| | | | \u251c\u2500\u2500 C in Depth by S. K. Srivastava\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 C++\n| | | | \u251c\u2500\u2500 Let Us C++ by Yashwant P. Kanetkar\n| | | | \u251c\u2500\u2500 C++: The Complete Reference by Herbert Schildt\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 Python\n| | | | \u251c\u2500\u2500 Core Python by R. Nageswara Rao\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 Java\n| | | | \u251c\u2500\u2500 Core Java - Black Book by R. Nageswara Rao\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Data Structures\n| | | \u251c\u2500\u2500 Data Structures and Algorithms by Narasimha Karumanchi\n| | | \u251c\u2500\u2500 Data Structures and Algorithms in Python by Michael T. Goodrich\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Algorithms\n| | | \u251c\u2500\u2500 Introduction to Algorithms by Thomas H. Cormen\n| | | \u251c\u2500\u2500 Algorithms by Robert Sedgewick and Kevin Wayne\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Competitive Programming\n| | | \u251c\u2500\u2500 Guide to Competitive Programming by Antti Laaksonen\n| | | \u251c\u2500\u2500 Competitive Programmer\u2019s Handbook by Antti Laaksonen\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Coding Interviews\n| | | \u251c\u2500\u2500 Cracking the Coding Interview by GAYLE LAAKMANN MCDOWELL\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Technical Subjects\n| | | \u251c\u2500\u2500 OOP\n| | | | \u251c\u2500\u2500 Object Oriented Programming with C++ by E. Balagurusamy\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 OS\n| | | | \u251c\u2500\u2500 Operating System Concepts by Abraham Silberschatz\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 DBMS\n| | | | \u251c\u2500\u2500 Database System Concepts by Abraham Silberschatz\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 CN\n| | | | \u251c\u2500\u2500 Computer Networking - A Top-Down Approach by James F. Kurose\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Aptitude & Reasoning\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Low Level Design\n| | | \u251c\u2500\u2500 Object Oriented Design\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Important Resources\n| | \u251c\u2500\u2500 Youtube Playlist\n| | | \u251c\u2500\u2500 DSA Series\n| | | \u251c\u2500\u2500 Technical Series\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 Interview Preparation\n| | | \u251c\u2500\u2500 HR Interview Questions\n| | | \u251c\u2500\u2500 Interview Experience\n| | | \u251c\u2500\u2500 Must DO questions\n| | | \u251c\u2500\u2500 Practise Platform\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 Computer Science Preparation\n| | \u251c\u2500\u2500 Computer Science Basics\n| | \u251c\u2500\u2500 Programming\n| | \u251c\u2500\u2500 Math\n| | \u251c\u2500\u2500 Systems\n| | \u251c\u2500\u2500 Theory\n| | \u251c\u2500\u2500 Applications\n| | \u251c\u2500\u2500 Unix\n| | \u2514\u2500\u2500 ...\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc69\ud835\udc86\ud835\udc89\ud835\udc82\ud835\udc97\ud835\udc8a\ud835\udc90\ud835\udc96\ud835\udc93\ud835\udc82\ud835\udc8d \ud835\udc70\ud835\udc8f\ud835\udc95\ud835\udc86\ud835\udc93\ud835\udc97\ud835\udc8a\ud835\udc86\ud835\udc98 \ud835\udc78\ud835\udc96\ud835\udc86\ud835\udc94\ud835\udc95\ud835\udc8a\ud835\udc90\ud835\udc8f\ud835\udc94\n| \u2514\u2500\u2500 ...\n|\n\u2514\u2500\u2500 ...\nDomain \ud83d\udd30\n1. Miscellaneous Stuff\nAptitude & Reasoning\nBasic Programming MCQs\nPuzzles\n2. DSA\nData Structures\nAlgorithms\n450 DSA by @Love Babbar\nStriver Series\n30 Days of SDE Sheet\nAlgorithms for Coding Round Sheet\nCompetitive Programming Sheet\nFAANG Interview Questions\nFacebook\nAmazon\nApple\nNetflix\nGoogle\nOthers\n3. Competitive Programming\nGoogle\nCode Jam\nHash Code\nKick Start\nFacebook\nHacker Cup\nFB Hack\nHackerRank\nPractice\nCompete\nGeeksforGeeks\nData Structures\nAlgorithms\nMust Do Coding Questions\nHackerEarth\nPractice\nCompete\nCodeChef\nPRACTICE & LEARN\nCompete\nCodeForces\nProblem Set\nContests\nLeetCode\nProblems\nContests\nInterviewBit\nProgramming\nContests\n4. Technical Subject\nObject Oriented Programming (OOPs)\nOOP.md\nOperating System (OS)\nOS.md\nDatabase Management System (DBMS)\nDBMS.md\nStructured Query Language (SQL)\nSQL.md\nComputer Network (CN)\nCN.md\nInterview Questions\n5. Low Level Design\nObject Oriented Design\nCase Study\n6. Projects\nMachine Learning & Data Science\nData Analysis Projects\nDeep Learning Projects\nComputer Vision\nNatural Language Processing\nMachine Learning Projects\nInternet of Things (IOT)\nWeb Development\nJavaScript Projects\nReactJS Projects\nMobile Development\nDesktop Development\nConsole Projects\nGUI Projects\n7. Important Books and Resources\nImportant Books\nProgramming Language\nData Structures\nAlgorithms\nCompetitive Programming\nCoding Interviews\nTechnical Subjects\nAptitude & Reasoning\nLow Level Design\nImportant Resources\nYoutube Playlist\nInterview Preparation\nComputer Science Preparation\nComputer Science Basics\nProgramming\nMath\nSystems\nTheory\nApplications\nUnix\n8. Behavioural Interview Questions\n\ud83c\udfc6 Project Admin\nAkash Singh\nAwesome Contributors \u2728\ud83c\udf89 61\nThanks goes to these Wonderful People \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb:\nAkashSingh3031\n\ud83d\udcbb \u270d\ufe0f\nAnuradha0501\n\ud83d\udcbb \u270d\ufe0f\nRishikaGhosh\n\ud83d\udcbb \u270d\ufe0f\nthecoder8890\n\ud83d\udcbb \u270d\ufe0f\nAsh515\n\ud83d\udcbb \u270d\ufe0f\nfame2105\n\ud83d\udcbb \u270d\ufe0f\nsaikiran20002102\n\ud83d\udcbb \u270d\ufe0f\nRAUNAK-PANDEY\n\ud83d\udcbb \u270d\ufe0f\ncodeaholic-shub\n\ud83d\udcbb \u270d\ufe0f\naroravansh\n\ud83d\udcbb \u270d\ufe0f\ntanmayChakrawarty\n\ud83d\udcbb \u270d\ufe0f\nonlykingKD\n\ud83d\udcbb \u270d\ufe0f\nparajshah\n\ud83d\udcbb \u270d\ufe0f\nPranjal-bisht\n\ud83d\udcbb \u270d\ufe0f\nSanandhKumar02\n\ud83d\udcbb \u270d\ufe0f\nsainikhil1605\n\ud83d\udcbb \u270d\ufe0f\nwork-mohit\n\ud83d\udcbb \u270d\ufe0f\nAyush7614\n\ud83d\udcbb \u270d\ufe0f\nsayeedajmal\n\ud83d\udcbb \u270d\ufe0f\nWenodh\n\ud83d\udcbb \u270d\ufe0f\ndevraj4522\n\ud83d\udcbb \u270d\ufe0f\nRounakNeogy\n\ud83d\udcbb \u270d\ufe0f\nashwin3082002\n\ud83d\udcbb \u270d\ufe0f\nVishnuSastryHK\n\ud83d\udcbb \u270d\ufe0f\nmuhiqsimui\n\ud83d\udcbb \u270d\ufe0f\nadityagi02\n\ud83d\udcbb \u270d\ufe0f\nSatyamchaubey07\n\ud83d\udcbb \u270d\ufe0f\nvedudx\n\ud83d\udcbb \u270d\ufe0f\nsheetalneeraj\n\ud83d\udcbb \u270d\ufe0f\namandewatnitrr\n\ud83d\udcbb \u270d\ufe0f\nsamnoon1971\n\ud83d\udcbb \u270d\ufe0f\ndraciel58\n\ud83d\udcbb \u270d\ufe0f\nGJuceviciute\n\ud83d\udcbb \u270d\ufe0f\nSukhendra523\n\ud83d\udcbb \u270d\ufe0f\nRanjul-Arumadi\n\ud83d\udcbb \u270d\ufe0f\nGouravRusiya30\n\ud83d\udcbb \u270d\ufe0f\nAkashkhandelwal191\n\ud83d\udcbb \u270d\ufe0f\nRahulSurana123\n\ud83d\udcbb \u270d\ufe0f\nimsoumen\n\ud83d\udcbb \u270d\ufe0f\nthisisbillall\n\ud83d\udcbb \u270d\ufe0f\nnixmaldonado\n\ud83d\udcbb \u270d\ufe0f\nthefool76\n\ud83d\udcbb \u270d\ufe0f\nsuniti0804\n\ud83d\udcbb \u270d\ufe0f\nharish3124\n\ud83d\udcbb \u270d\ufe0f\npoojitha2002\n\ud83d\udcbb \u270d\ufe0f\nvk-2501\n\ud83d\udcbb \u270d\ufe0f\nmgazdovic\n\ud83d\udcbb \u270d\ufe0f\nAnshir08\n\ud83d\udcbb \u270d\ufe0f\nharshil202\n\ud83d\udcbb \u270d\ufe0f\nRei-x\n\ud83d\udcbb \u270d\ufe0f\nmaanasvi999\n\ud83d\udcbb \u270d\ufe0f\nmansijain980\n\ud83d\udcbb \u270d\ufe0f\ntanyagupta0201\n\ud83d\udcbb \u270d\ufe0f\nsaikrithik\n\ud83d\udcbb \u270d\ufe0f\nankit200490\n\ud83d\udcbb \u270d\ufe0f\nSumit4482\n\ud83d\udcbb \u270d\ufe0f\nGSAUC3\n\ud83d\udcbb \u270d\ufe0f\niamsinghashutosh\n\ud83d\udcbb \u270d\ufe0f\nUchiha-Itachi0\n\ud83d\udcbb \u270d\ufe0f\nyan-michael\n\ud83d\udcbb \u270d\ufe0f\nabhistark007\n\ud83d\udcbb \u270d\ufe0f\nContributing\nWe'd love your contributions! Kindly follow the steps below to get started:\nStar this repository.\nFork this repository.\nClone the forked repository.\ngit clone https://github.com/<your-github-username>/The-Complete-FAANG-Preparation\nNavigate to the project directory.\ncd The-Complete-FAANG-Preparation\nCreate a new branch.\ngit checkout -b <your_branch_name>\nMake changes.\nStage your changes and commit\ngit add -A\ngit commit -m \"<your_commit_message>\"\nPush your local commits to the remote repo.\ngit push -u origin <your_branch_name>\nCreate a Pull-Request to develop !\nCongratulations! \ud83c\udf89 Sit and relax, you've made your contribution to The Complete FAANG Preparation. \u270c\ufe0f \u2764\ufe0f \ud83d\udca5\nStargazers Over Time \ud83d\udcca\ud83d\udcc8\nMIT LICENSE \ud83d\udcdc\nMIT License\nCopyright (c) 2021 Akash Singh\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.", "link": "https://github.com/AkashSingh3031/The-Complete-FAANG-Preparation", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "full repository status\n\ud83c\udfc6 the complete faang preparation \ud83c\udfc6\nthis repository contains all the dsa (data-structures, algorithms, 450 dsa by love babbar bhaiya, faang questions), technical subjects (os + dbms + sql + cn + oops) theory+questions,faang interview questions and miscellaneous stuff (programming mcqs, puzzles, aptitude, reasoning). the programming languages used for demonstration are the c++, python, and java.\napplying to internships?\nautofill all your applications in a single click.\nstop manually re-entering your information. simplify\u2019s extension helps you autofill internship applications on millions of sites.\ntable of contents \ud83d\udccb\nsno. contents\n1. miscellaneous stuff\n2. dsa\n3. competitive programming\n4. technical subject\n5. low level design\n6. projects\n7. important books and resources\n8. behavioural interview questions\n-----> tree !!!  of index \ud83d\ude80\n.\n\u251c\u2500\u2500 ...\n\u251c\u2500\u2500 \ud835\udc74\ud835\udc8a\ud835\udc94\ud835\udc84\ud835\udc86\ud835\udc8d\ud835\udc8d\ud835\udc82\ud835\udc8f\ud835\udc86\ud835\udc90\ud835\udc96\ud835\udc94 \ud835\udc7a\ud835\udc95\ud835\udc96\ud835\udc87\ud835\udc87\n| \u251c\u2500\u2500 aptitude & reasoning\n| | \u251c\u2500\u2500 quantitative analysis\n| | \u251c\u2500\u2500 logical and verbal reasoning\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 basic programming+technical mcqs\n| | \u251c\u2500\u2500 c programming\n| | \u251c\u2500\u2500 c++ programming\n| | \u251c\u2500\u2500 python programming\n| | \u251c\u2500\u2500 java programming\n| | \u251c\u2500\u2500 object oriented programming (oop)\n| | \u251c\u2500\u2500 operating system (os)\n| | \u251c\u2500\u2500 database management system (dbms)\n| | \u251c\u2500\u2500 structured query language (sql)\n| | \u251c\u2500\u2500 computer network (cn)\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 puzzles\n| | \u2514\u2500\u2500 ...\n| |\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc6b\ud835\udc7a\ud835\udc68\n| \u251c\u2500\u2500 data structures\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 algorithms\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 450 dsa by love babbar\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 striver series\n| | \u251c\u2500\u2500 30 days of sde sheet\n| | \u251c\u2500\u2500 algorithms for coding round sheet\n| | \u251c\u2500\u2500 competitive programming sheet\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 faang interview questions\n| | \u251c\u2500\u2500 facebook\n| | \u251c\u2500\u2500 amazon\n| | \u251c\u2500\u2500 apple\n| | \u251c\u2500\u2500 netflix\n| | \u251c\u2500\u2500 google\n| | \u251c\u2500\u2500 others\n| | \u2514\u2500\u2500 ...\n| |\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc6a\ud835\udc90\ud835\udc8e\ud835\udc91\ud835\udc86\ud835\udc95\ud835\udc8a\ud835\udc95\ud835\udc8a\ud835\udc97\ud835\udc86 \ud835\udc77\ud835\udc93\ud835\udc90\ud835\udc88\ud835\udc93\ud835\udc82\ud835\udc8e\ud835\udc8e\ud835\udc8a\ud835\udc8f\ud835\udc88\n| \u251c\u2500\u2500 google\n| | \u251c\u2500\u2500 code jam\n| | | \u251c\u2500\u2500 2017\n| | | \u251c\u2500\u2500 2018\n| | | \u251c\u2500\u2500 2019\n| | | \u251c\u2500\u2500 2020\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 hash code\n| | | \u251c\u2500\u2500 2016\n| | | \u251c\u2500\u2500 2017\n| | | \u251c\u2500\u2500 2018\n| | | \u251c\u2500\u2500 2019\n| | | \u251c\u2500\u2500 2020\n| | | \u251c\u2500\u2500 2021\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 kick start\n| | | \u251c\u2500\u2500 2017\n| | | \u251c\u2500\u2500 2018\n| | | \u251c\u2500\u2500 2019\n| | | \u251c\u2500\u2500 2020\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 facebook\n| | \u251c\u2500\u2500 hacker cup\n| | | \u251c\u2500\u2500 2011\n| | | \u251c\u2500\u2500 2012\n| | | \u251c\u2500\u2500 2013\n| | | \u251c\u2500\u2500 2014\n| | | \u251c\u2500\u2500 2015\n| | | \u251c\u2500\u2500 2016\n| | | \u251c\u2500\u2500 2017\n| | | \u251c\u2500\u2500 2018\n| | | \u251c\u2500\u2500 2019\n| | | \u251c\u2500\u2500 2020\n| | | \u251c\u2500\u2500 2021\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 fb hack\n| | | \u251c\u2500\u2500 2020\n| | | \u251c\u2500\u2500 2021\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 geeksforgeeks\n| | \u251c\u2500\u2500 data structures\n| | \u251c\u2500\u2500 algorithms\n| | \u251c\u2500\u2500 must do coding questions\n| | \u251c\u2500\u2500 competitive programming \u2013 a complete guide\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 leetcode\n| | \u251c\u2500\u2500 problems\n| | \u251c\u2500\u2500 contests\n| | | \u251c\u2500\u2500 weekly contests\n| | | \u251c\u2500\u2500 biweekly contests\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 hackerrank\n| | \u251c\u2500\u2500 practice\n| | | \u251c\u2500\u2500 c\n| | | \u251c\u2500\u2500 c++\n| | | \u251c\u2500\u2500 python\n| | | \u251c\u2500\u2500 java\n| | | \u251c\u2500\u2500 sql\n| | | \u251c\u2500\u2500 database\n| | | \u251c\u2500\u2500 interview preparation kit\n| | | \u251c\u2500\u2500 problem solving\n| | | | \u251c\u2500\u2500 data structures\n| | | | \u2514\u2500\u2500 algorithms\n| | | \u251c\u2500\u2500 mathematics\n| | | \u251c\u2500\u2500 30 days of code\n| | | \u251c\u2500\u2500 10 days of javascript\n| | | \u251c\u2500\u2500 10 days of statistics\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 compete\n| | | \u251c\u2500\u2500 projecteuler+\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 hackerearth\n| | \u251c\u2500\u2500 practice\n| | | \u251c\u2500\u2500 basic programming\n| | | \u251c\u2500\u2500 data structures\n| | | \u251c\u2500\u2500 algorithms\n| | | \u251c\u2500\u2500 math\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 compete\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 codechef\n| | \u251c\u2500\u2500 practice & learn\n| | | \u251c\u2500\u2500 beginner\n| | | \u251c\u2500\u2500 easy\n| | | \u251c\u2500\u2500 medium\n| | | \u251c\u2500\u2500 hard\n| | | \u251c\u2500\u2500 challenge\n| | | \u2514\u2500\u2500 peer\n| | |\n| | \u251c\u2500\u2500 compete\n| | | \u251c\u2500\u2500 long challenge\n| | | | \u251c\u2500\u2500 div-1\n| | | | \u251c\u2500\u2500 div-2\n| | | | \u251c\u2500\u2500 div-3\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 cook-off\n| | | | \u251c\u2500\u2500 div-1\n| | | | \u251c\u2500\u2500 div-2\n| | | | \u251c\u2500\u2500 div-3\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 lunch time\n| | | | \u251c\u2500\u2500 div-1\n| | | | \u251c\u2500\u2500 div-2\n| | | | \u251c\u2500\u2500 div-3\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 codeforces\n| | \u251c\u2500\u2500 problem_set\n| | | \u251c\u2500\u2500 levels\n| | | | \u251c\u2500\u2500 a\n| | | | \u251c\u2500\u2500 b\n| | | | \u251c\u2500\u2500 c\n| | | | \u251c\u2500\u2500 d\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 contests\n| | | \u251c\u2500\u2500 rounds\n| | | | \u251c\u2500\u2500 div-1\n| | | | \u251c\u2500\u2500 div-2\n| | | | \u251c\u2500\u2500 div-3\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 interviewbit\n| | \u251c\u2500\u2500 programming\n| | | \u251c\u2500\u2500 time complexity problems\n| | | \u251c\u2500\u2500 arrays\n| | | \u251c\u2500\u2500 math\n| | | \u251c\u2500\u2500 binary search\n| | | \u251c\u2500\u2500 string\n| | | \u251c\u2500\u2500 bit manipulation\n| | | \u251c\u2500\u2500 two pointers\n| | | \u251c\u2500\u2500 linked list\n| | | \u251c\u2500\u2500 stack & queue\n| | | \u251c\u2500\u2500 backtracking\n| | | \u251c\u2500\u2500 hashing\n| | | \u251c\u2500\u2500 heap & map\n| | | \u251c\u2500\u2500 tree data structure\n| | | \u251c\u2500\u2500 dynamic programming\n| | | \u251c\u2500\u2500 greedy algorithm\n| | | \u251c\u2500\u2500 graph data structure & algorithms\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 contests\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc7b\ud835\udc86\ud835\udc84\ud835\udc89\ud835\udc8f\ud835\udc8a\ud835\udc84\ud835\udc82\ud835\udc8d \ud835\udc7a\ud835\udc96\ud835\udc83\ud835\udc8b\ud835\udc86\ud835\udc84\ud835\udc95\n| \u251c\u2500\u2500 object oriented programming (oop)\n| | \u251c\u2500\u2500 oop.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 operating system (os)\n| | \u251c\u2500\u2500 os.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 database management system (dbms)\n| | \u251c\u2500\u2500 dbms.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 structured query language (sql)\n| | \u251c\u2500\u2500 sql.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 computer network (cn)\n| | \u251c\u2500\u2500 cn.md\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 interview questions\n| | \u251c\u2500\u2500 oop\n| | \u251c\u2500\u2500 os\n| | \u251c\u2500\u2500 dbms\n| | \u251c\u2500\u2500 sql\n| | \u251c\u2500\u2500 cn\n| | \u2514\u2500\u2500 ...\n| |\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc73\ud835\udc90\ud835\udc98 \ud835\udc73\ud835\udc86\ud835\udc97\ud835\udc86\ud835\udc8d \ud835\udc6b\ud835\udc86\ud835\udc94\ud835\udc8a\ud835\udc88\ud835\udc8f\n| \u251c\u2500\u2500 object oriented design\n| | \u251c\u2500\u2500 introduciton to classes and objects\n| | \u251c\u2500\u2500 software development process\n| | \u251c\u2500\u2500 introduction to uml\n| | \u251c\u2500\u2500 class diagrams and object diagrams\n| | \u251c\u2500\u2500 use case diagrams\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 case study\n| | \u2514\u2500\u2500 ...\n| |\n\u2502 \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc77\ud835\udc93\ud835\udc90\ud835\udc8b\ud835\udc86\ud835\udc84\ud835\udc95\ud835\udc94\n| \u251c\u2500\u2500 machine learning & data science\n| | \u251c\u2500\u2500 data analysis\n| | \u251c\u2500\u2500 deep learning\n| | | \u251c\u2500\u2500 computer vision\n| | | \u251c\u2500\u2500 natural language processing\n| | | \u2514\u2500\u2500 ...\n| | \u251c\u2500\u2500 machine learning\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 internet of things (iot)\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 web development\n| | \u251c\u2500\u2500 javascript projects\n| | \u251c\u2500\u2500 reactjs projects\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 mobile development\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 desktop development\n| | \u251c\u2500\u2500 console projects\n| | \u251c\u2500\u2500 gui projects\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 blockchain development\n| | \u2514\u2500\u2500 ...\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc70\ud835\udc8e\ud835\udc91\ud835\udc90\ud835\udc93\ud835\udc95\ud835\udc82\ud835\udc8f\ud835\udc95 \ud835\udc69\ud835\udc90\ud835\udc90\ud835\udc8c\ud835\udc94 \ud835\udc82\ud835\udc8f\ud835\udc85 \ud835\udc79\ud835\udc86\ud835\udc94\ud835\udc90\ud835\udc96\ud835\udc93\ud835\udc84\ud835\udc86\ud835\udc94\n| \u251c\u2500\u2500 important books\n| | \u251c\u2500\u2500 programming language\n| | | \u251c\u2500\u2500 c\n| | | | \u251c\u2500\u2500 let us c by yashwant p. kanetkar\n| | | | \u251c\u2500\u2500 c in depth by s. k. srivastava\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 c++\n| | | | \u251c\u2500\u2500 let us c++ by yashwant p. kanetkar\n| | | | \u251c\u2500\u2500 c++: the complete reference by herbert schildt\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 python\n| | | | \u251c\u2500\u2500 core python by r. nageswara rao\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 java\n| | | | \u251c\u2500\u2500 core java - black book by r. nageswara rao\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 data structures\n| | | \u251c\u2500\u2500 data structures and algorithms by narasimha karumanchi\n| | | \u251c\u2500\u2500 data structures and algorithms in python by michael t. goodrich\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 algorithms\n| | | \u251c\u2500\u2500 introduction to algorithms by thomas h. cormen\n| | | \u251c\u2500\u2500 algorithms by robert sedgewick and kevin wayne\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 competitive programming\n| | | \u251c\u2500\u2500 guide to competitive programming by antti laaksonen\n| | | \u251c\u2500\u2500 competitive programmer\u2019s handbook by antti laaksonen\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 coding interviews\n| | | \u251c\u2500\u2500 cracking the coding interview by gayle laakmann mcdowell\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 technical subjects\n| | | \u251c\u2500\u2500 oop\n| | | | \u251c\u2500\u2500 object oriented programming with c++ by e. balagurusamy\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 os\n| | | | \u251c\u2500\u2500 operating system concepts by abraham silberschatz\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 dbms\n| | | | \u251c\u2500\u2500 database system concepts by abraham silberschatz\n| | | | \u2514\u2500\u2500 ...\n| | | \u251c\u2500\u2500 cn\n| | | | \u251c\u2500\u2500 computer networking - a top-down approach by james f. kurose\n| | | | \u2514\u2500\u2500 ...\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 aptitude & reasoning\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 low level design\n| | | \u251c\u2500\u2500 object oriented design\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 important resources\n| | \u251c\u2500\u2500 youtube playlist\n| | | \u251c\u2500\u2500 dsa series\n| | | \u251c\u2500\u2500 technical series\n| | | \u2514\u2500\u2500 ...\n| | |\n| | \u251c\u2500\u2500 interview preparation\n| | | \u251c\u2500\u2500 hr interview questions\n| | | \u251c\u2500\u2500 interview experience\n| | | \u251c\u2500\u2500 must do questions\n| | | \u251c\u2500\u2500 practise platform\n| | | \u2514\u2500\u2500 ...\n| | \u2514\u2500\u2500 ...\n| |\n| \u251c\u2500\u2500 computer science preparation\n| | \u251c\u2500\u2500 computer science basics\n| | \u251c\u2500\u2500 programming\n| | \u251c\u2500\u2500 math\n| | \u251c\u2500\u2500 systems\n| | \u251c\u2500\u2500 theory\n| | \u251c\u2500\u2500 applications\n| | \u251c\u2500\u2500 unix\n| | \u2514\u2500\u2500 ...\n| \u2514\u2500\u2500 ...\n|\n|\n\u2514\u2500\u2500 \ud835\udc69\ud835\udc86\ud835\udc89\ud835\udc82\ud835\udc97\ud835\udc8a\ud835\udc90\ud835\udc96\ud835\udc93\ud835\udc82\ud835\udc8d \ud835\udc70\ud835\udc8f\ud835\udc95\ud835\udc86\ud835\udc93\ud835\udc97\ud835\udc8a\ud835\udc86\ud835\udc98 \ud835\udc78\ud835\udc96\ud835\udc86\ud835\udc94\ud835\udc95\ud835\udc8a\ud835\udc90\ud835\udc8f\ud835\udc94\n| \u2514\u2500\u2500 ...\n|\n\u2514\u2500\u2500 ...\ndomain \ud83d\udd30\n1. miscellaneous stuff\naptitude & reasoning\nbasic programming mcqs\npuzzles\n2. dsa\ndata structures\nalgorithms\n450 dsa by @love babbar\nstriver series\n30 days of sde sheet\nalgorithms for coding round sheet\ncompetitive programming sheet\nfaang interview questions\nfacebook\namazon\napple\nnetflix\ngoogle\nothers\n3. competitive programming\ngoogle\ncode jam\nhash code\nkick start\nfacebook\nhacker cup\nfb hack\nhackerrank\npractice\ncompete\ngeeksforgeeks\ndata structures\nalgorithms\nmust do coding questions\nhackerearth\npractice\ncompete\ncodechef\npractice & learn\ncompete\ncodeforces\nproblem set\ncontests\nleetcode\nproblems\ncontests\ninterviewbit\nprogramming\ncontests\n4. technical subject\nobject oriented programming (oops)\noop.md\noperating system (os)\nos.md\ndatabase management system (dbms)\ndbms.md\nstructured query language (sql)\nsql.md\ncomputer network (cn)\ncn.md\ninterview questions\n5. low level design\nobject oriented design\ncase study\n6. projects\nmachine learning & data science\ndata analysis projects\ndeep learning projects\ncomputer vision\nnatural language processing\nmachine learning projects\ninternet of things (iot)\nweb development\njavascript projects\nreactjs projects\nmobile development\ndesktop development\nconsole projects\ngui projects\n7. important books and resources\nimportant books\nprogramming language\ndata structures\nalgorithms\ncompetitive programming\ncoding interviews\ntechnical subjects\naptitude & reasoning\nlow level design\nimportant resources\nyoutube playlist\ninterview preparation\ncomputer science preparation\ncomputer science basics\nprogramming\nmath\nsystems\ntheory\napplications\nunix\n8. behavioural interview questions\n\ud83c\udfc6 project admin\nakash singh\nawesome contributors \u2728\ud83c\udf89 61\nthanks goes to these wonderful people \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb:\nakashsingh3031\n\ud83d\udcbb \u270d\ufe0f\nanuradha0501\n\ud83d\udcbb \u270d\ufe0f\nrishikaghosh\n\ud83d\udcbb \u270d\ufe0f\nthecoder8890\n\ud83d\udcbb \u270d\ufe0f\nash515\n\ud83d\udcbb \u270d\ufe0f\nfame2105\n\ud83d\udcbb \u270d\ufe0f\nsaikiran20002102\n\ud83d\udcbb \u270d\ufe0f\nraunak-pandey\n\ud83d\udcbb \u270d\ufe0f\ncodeaholic-shub\n\ud83d\udcbb \u270d\ufe0f\naroravansh\n\ud83d\udcbb \u270d\ufe0f\ntanmaychakrawarty\n\ud83d\udcbb \u270d\ufe0f\nonlykingkd\n\ud83d\udcbb \u270d\ufe0f\nparajshah\n\ud83d\udcbb \u270d\ufe0f\npranjal-bisht\n\ud83d\udcbb \u270d\ufe0f\nsanandhkumar02\n\ud83d\udcbb \u270d\ufe0f\nsainikhil1605\n\ud83d\udcbb \u270d\ufe0f\nwork-mohit\n\ud83d\udcbb \u270d\ufe0f\nayush7614\n\ud83d\udcbb \u270d\ufe0f\nsayeedajmal\n\ud83d\udcbb \u270d\ufe0f\nwenodh\n\ud83d\udcbb \u270d\ufe0f\ndevraj4522\n\ud83d\udcbb \u270d\ufe0f\nrounakneogy\n\ud83d\udcbb \u270d\ufe0f\nashwin3082002\n\ud83d\udcbb \u270d\ufe0f\nvishnusastryhk\n\ud83d\udcbb \u270d\ufe0f\nmuhiqsimui\n\ud83d\udcbb \u270d\ufe0f\nadityagi02\n\ud83d\udcbb \u270d\ufe0f\nsatyamchaubey07\n\ud83d\udcbb \u270d\ufe0f\nvedudx\n\ud83d\udcbb \u270d\ufe0f\nsheetalneeraj\n\ud83d\udcbb \u270d\ufe0f\namandewatnitrr\n\ud83d\udcbb \u270d\ufe0f\nsamnoon1971\n\ud83d\udcbb \u270d\ufe0f\ndraciel58\n\ud83d\udcbb \u270d\ufe0f\ngjuceviciute\n\ud83d\udcbb \u270d\ufe0f\nsukhendra523\n\ud83d\udcbb \u270d\ufe0f\nranjul-arumadi\n\ud83d\udcbb \u270d\ufe0f\ngouravrusiya30\n\ud83d\udcbb \u270d\ufe0f\nakashkhandelwal191\n\ud83d\udcbb \u270d\ufe0f\nrahulsurana123\n\ud83d\udcbb \u270d\ufe0f\nimsoumen\n\ud83d\udcbb \u270d\ufe0f\nthisisbillall\n\ud83d\udcbb \u270d\ufe0f\nnixmaldonado\n\ud83d\udcbb \u270d\ufe0f\nthefool76\n\ud83d\udcbb \u270d\ufe0f\nsuniti0804\n\ud83d\udcbb \u270d\ufe0f\nharish3124\n\ud83d\udcbb \u270d\ufe0f\npoojitha2002\n\ud83d\udcbb \u270d\ufe0f\nvk-2501\n\ud83d\udcbb \u270d\ufe0f\nmgazdovic\n\ud83d\udcbb \u270d\ufe0f\nanshir08\n\ud83d\udcbb \u270d\ufe0f\nharshil202\n\ud83d\udcbb \u270d\ufe0f\nrei-x\n\ud83d\udcbb \u270d\ufe0f\nmaanasvi999\n\ud83d\udcbb \u270d\ufe0f\nmansijain980\n\ud83d\udcbb \u270d\ufe0f\ntanyagupta0201\n\ud83d\udcbb \u270d\ufe0f\nsaikrithik\n\ud83d\udcbb \u270d\ufe0f\nankit200490\n\ud83d\udcbb \u270d\ufe0f\nsumit4482\n\ud83d\udcbb \u270d\ufe0f\ngsauc3\n\ud83d\udcbb \u270d\ufe0f\niamsinghashutosh\n\ud83d\udcbb \u270d\ufe0f\nuchiha-itachi0\n\ud83d\udcbb \u270d\ufe0f\nyan-michael\n\ud83d\udcbb \u270d\ufe0f\nabhistark007\n\ud83d\udcbb \u270d\ufe0f\ncontributing\nwe'd love your contributions! kindly follow the steps below to get started:\nstar this repository.\nfork this repository.\nclone the forked repository.\ngit clone https://github.com/<your-github-username>/the-complete-faang-preparation\nnavigate to the project directory.\ncd the-complete-faang-preparation\ncreate a new branch.\ngit checkout -b <your_branch_name>\nmake changes.\nstage your changes and commit\ngit add -a\ngit commit -m \"<your_commit_message>\"\npush your local commits to the remote repo.\ngit push -u origin <your_branch_name>\ncreate a pull-request to develop !\ncongratulations! \ud83c\udf89 sit and relax, you've made your contribution to the complete faang preparation. \u270c\ufe0f \u2764\ufe0f \ud83d\udca5\nstargazers over time \ud83d\udcca\ud83d\udcc8\nmit license \ud83d\udcdc\nmit license\ncopyright (c) 2021 akash singh\npermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"software\"), to deal\nin the software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the software, and to permit persons to whom the software is\nfurnished to do so, subject to the following conditions:\nthe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the software.\nthe software is provided \"as is\", without warranty of any kind, express or\nimplied, including but not limited to the warranties of merchantability,\nfitness for a particular purpose and noninfringement. in no event shall the\nauthors or copyright holders be liable for any claim, damages or other\nliability, whether in an action of contract, tort or otherwise, arising from,\nout of or in connection with the software or the use or other dealings in the\nsoftware.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000020, "year": null}, {"Unnamed: 0": 48, "autor": 48, "date": null, "content": "VerneMQ: A Distributed MQTT Broker\nOld Docker Repo New Docker Repo\nNew: VerneMQ can now use Github Discussions! To join the discussion on features and roadmap, and be part of the VerneMQ Community Team on Github, send us your Github username for an invite! (on Twitter, Slack etc.)\nMake sure to visit the new VerneMQ Forum hosted on Erlang Forums. We're happy to discuss any of your questions and ideas around VerneMQ on the Forum too!\nVerneMQ is known to be deployed and used in: \ud83c\uddfa\ud83c\uddf8 \ud83c\udde8\ud83c\udde6 \ud83c\udde7\ud83c\uddf7 \ud83c\uddf2\ud83c\uddfd \ud83c\udde9\ud83c\uddea \ud83c\uddeb\ud83c\uddf7 \ud83c\udde8\ud83c\udded \ud83c\udde9\ud83c\uddf0 \ud83c\uddf3\ud83c\uddf1 \ud83c\udde7\ud83c\uddea \ud83c\uddee\ud83c\uddf9 \ud83c\uddea\ud83c\uddf8 \ud83c\uddf7\ud83c\uddf4 \ud83c\uddf5\ud83c\uddf9 \ud83c\uddf7\ud83c\uddfa \ud83c\uddf1\ud83c\uddf9 \ud83c\udde8\ud83c\uddff \ud83c\uddf8\ud83c\uddf0 \ud83c\udde6\ud83c\uddf9 \ud83c\uddf5\ud83c\uddf1 \ud83c\uddf3\ud83c\uddf4 \ud83c\uddf8\ud83c\uddea \ud83c\uddee\ud83c\uddf3 \ud83c\uddef\ud83c\uddf5 \ud83c\uddee\ud83c\udde9 \ud83c\uddfb\ud83c\uddf3 \ud83c\uddf0\ud83c\uddf7 \ud83c\uddff\ud83c\udde6 \ud83c\uddf0\ud83c\uddea \ud83c\uddf7\ud83c\uddf8 \ud83c\udded\ud83c\uddf7 \ud83c\uddec\ud83c\uddf7 \ud83c\uddec\ud83c\udde7 \ud83c\uddfa\ud83c\udde6 \ud83c\udde6\ud83c\uddfa \ud83c\uddf3\ud83c\uddff \ud83c\udde8\ud83c\uddf3 \ud83c\uddea\ud83c\uddec \ud83c\uddeb\ud83c\uddee \ud83c\udded\ud83c\uddfa \ud83c\uddee\ud83c\uddf1 \ud83c\uddf8\ud83c\uddec \ud83c\uddf1\ud83c\udde7 \ud83c\uddf5\ud83c\udded \ud83c\uddf5\ud83c\uddf0 \ud83c\uddf2\ud83c\uddfe \ud83c\uddf9\ud83c\uddf7 \ud83c\uddf9\ud83c\uddfc \ud83c\uddee\ud83c\uddf7 \u2601\ufe0f\nVerneMQ is a high-performance, distributed MQTT message broker. It scales horizontally and vertically on commodity hardware to support a high number of concurrent publishers and consumers while maintaining low latency and fault tolerance. VerneMQ is the reliable message hub for your IoT platform or smart products.\nVerneMQ is an Apache2 licensed distributed MQTT broker, developed in Erlang.\nMQTT used to stand for MQ Telemetry Transport, but it no longer is an acronym. It is an extremely simple and lightweight publish/subscribe messaging protocol, that was invented at IBM and Arcom (now Eurotech) to connect restricted devices in low bandwidth, high-latency or unreliable networks.\nVerneMQ implements the MQTT 3.1, 3.1.1 and 5.0 specifications. Currently the following features are implemented and delivered as part of VerneMQ:\nQoS 0, QoS 1, QoS 2\nBasic Authentication and Authorization\nBridge Support\n$SYS Tree for monitoring and reporting\nTLS (SSL) Encryption\nWebsockets Support\nCluster Support\nLogging (Console, Files, Syslog)\nReporting to Graphite\nExtensible Plugin architecture\nMultiple Sessions per ClientId\nSession Balancing\nShared subscriptions\nMessage load regulation\nMessage load shedding (for system protection)\nOffline Message Storage (based on LevelDB)\nQueue can handle messages FIFO or LIFO style.\nMongoDB auth & integration\nRedis auth & integration\nMySQL auth & integration\nPostgreSQL auth & integration\nCockroachDB auth & integration\nMemcached integration\nHTTP Webhooks\nPROXY Protocol v2\nAdministration HTTP API\nReal-time MQTT session tracing\nFull multitenancy\nCluster status web page\nThe following features are also applies to MQTT 5.0 clients:\nEnhanced authentication schemes (AUTH)\nMessage expiration\nLast Will and Testament delay\nShared subscriptions\nRequest/response flow\nTopic aliases\nFlow control\nSubscription flags (Retain as Published, No Local, Retain Handling)\nSubscriber identifiers\nAll property types are supported: user properties, reason strings, content types etc.\nCommercial Support. Binary Packages. Documentation\nBelow you'll find a basic introduction to building and starting VerneMQ. For more information about the binary package installation, configuration, and administration of VerneMQ, please visit our documentation at VerneMQ Documentation or checkout the product page VerneMQ if you require more information on the available commercial support options.\nCommunity Release Schedule\nNext major release: not yet scheduled.\nMinor releases: At the end of March, July and November (every 4th month).\nBugfix releases: Usually a bugfix release is released between minor releases or if there's an urgent bugfix pending.\nCustom release cycles and releases are available for commercial users.\nQuick Start\nThis section assumes that you have a copy of the VerneMQ source tree. To get started, you need to first build VerneMQ.\nBuilding VerneMQ\nNote: VerneMQ requires Erlang/OTP 22-24 and libsnappy-dev installed in your system. You'll also need a C compiler for Eleveldb. (on Debian, you install build-essential, as an example).\nAssuming you have a working Erlang installation, building VerneMQ should be as simple as:\n$ cd $VERNEMQ\n$ make rel\nStarting VerneMQ\nOnce you've successfully built VerneMQ, you can start the server with the following commands:\n$ cd $VERNEMQ/_build/default/rel/vernemq\n$ bin/vernemq start\nIf VerneMQ is running it is possible to check the status on http://localhost:8888/status and it should look something like:\nNote that the $VERNEMQ/_build/default/rel/vernemq directory is a complete, self-contained instance of VerneMQ and Erlang. It is strongly suggested that you move this directory outside the source tree if you plan to run a production instance.\nImportant links\nVerneMQ Documentation", "link": "https://github.com/vernemq/vernemq", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "vernemq: a distributed mqtt broker\nold docker repo new docker repo\nnew: vernemq can now use github discussions! to join the discussion on features and roadmap, and be part of the vernemq community team on github, send us your github username for an invite! (on twitter, slack etc.)\nmake sure to visit the new vernemq forum hosted on erlang forums. we're happy to discuss any of your questions and ideas around vernemq on the forum too!\nvernemq is known to be deployed and used in: \ud83c\uddfa\ud83c\uddf8 \ud83c\udde8\ud83c\udde6 \ud83c\udde7\ud83c\uddf7 \ud83c\uddf2\ud83c\uddfd \ud83c\udde9\ud83c\uddea \ud83c\uddeb\ud83c\uddf7 \ud83c\udde8\ud83c\udded \ud83c\udde9\ud83c\uddf0 \ud83c\uddf3\ud83c\uddf1 \ud83c\udde7\ud83c\uddea \ud83c\uddee\ud83c\uddf9 \ud83c\uddea\ud83c\uddf8 \ud83c\uddf7\ud83c\uddf4 \ud83c\uddf5\ud83c\uddf9 \ud83c\uddf7\ud83c\uddfa \ud83c\uddf1\ud83c\uddf9 \ud83c\udde8\ud83c\uddff \ud83c\uddf8\ud83c\uddf0 \ud83c\udde6\ud83c\uddf9 \ud83c\uddf5\ud83c\uddf1 \ud83c\uddf3\ud83c\uddf4 \ud83c\uddf8\ud83c\uddea \ud83c\uddee\ud83c\uddf3 \ud83c\uddef\ud83c\uddf5 \ud83c\uddee\ud83c\udde9 \ud83c\uddfb\ud83c\uddf3 \ud83c\uddf0\ud83c\uddf7 \ud83c\uddff\ud83c\udde6 \ud83c\uddf0\ud83c\uddea \ud83c\uddf7\ud83c\uddf8 \ud83c\udded\ud83c\uddf7 \ud83c\uddec\ud83c\uddf7 \ud83c\uddec\ud83c\udde7 \ud83c\uddfa\ud83c\udde6 \ud83c\udde6\ud83c\uddfa \ud83c\uddf3\ud83c\uddff \ud83c\udde8\ud83c\uddf3 \ud83c\uddea\ud83c\uddec \ud83c\uddeb\ud83c\uddee \ud83c\udded\ud83c\uddfa \ud83c\uddee\ud83c\uddf1 \ud83c\uddf8\ud83c\uddec \ud83c\uddf1\ud83c\udde7 \ud83c\uddf5\ud83c\udded \ud83c\uddf5\ud83c\uddf0 \ud83c\uddf2\ud83c\uddfe \ud83c\uddf9\ud83c\uddf7 \ud83c\uddf9\ud83c\uddfc \ud83c\uddee\ud83c\uddf7 \u2601\ufe0f\nvernemq is a high-performance, distributed mqtt message broker. it scales horizontally and vertically on commodity hardware to support a high number of concurrent publishers and consumers while maintaining low latency and fault tolerance. vernemq is the reliable message hub for your iot platform or smart products.\nvernemq is an apache2 licensed distributed mqtt broker, developed in erlang.\nmqtt used to stand for mq telemetry transport, but it no longer is an acronym. it is an extremely simple and lightweight publish/subscribe messaging protocol, that was invented at ibm and arcom (now eurotech) to connect restricted devices in low bandwidth, high-latency or unreliable networks.\nvernemq implements the mqtt 3.1, 3.1.1 and 5.0 specifications. currently the following features are implemented and delivered as part of vernemq:\nqos 0, qos 1, qos 2\nbasic authentication and authorization\nbridge support\n$sys -----> tree !!!  for monitoring and reporting\ntls (ssl) encryption\nwebsockets support\ncluster support\nlogging (console, files, syslog)\nreporting to graphite\nextensible plugin architecture\nmultiple sessions per clientid\nsession balancing\nshared subscriptions\nmessage load regulation\nmessage load shedding (for system protection)\noffline message storage (based on leveldb)\nqueue can handle messages fifo or lifo style.\nmongodb auth & integration\nredis auth & integration\nmysql auth & integration\npostgresql auth & integration\ncockroachdb auth & integration\nmemcached integration\nhttp webhooks\nproxy protocol v2\nadministration http api\nreal-time mqtt session tracing\nfull multitenancy\ncluster status web page\nthe following features are also applies to mqtt 5.0 clients:\nenhanced authentication schemes (auth)\nmessage expiration\nlast will and testament delay\nshared subscriptions\nrequest/response flow\ntopic aliases\nflow control\nsubscription flags (retain as published, no local, retain handling)\nsubscriber identifiers\nall property types are supported: user properties, reason strings, content types etc.\ncommercial support. binary packages. documentation\nbelow you'll find a basic introduction to building and starting vernemq. for more information about the binary package installation, configuration, and administration of vernemq, please visit our documentation at vernemq documentation or checkout the product page vernemq if you require more information on the available commercial support options.\ncommunity release schedule\nnext major release: not yet scheduled.\nminor releases: at the end of march, july and november (every 4th month).\nbugfix releases: usually a bugfix release is released between minor releases or if there's an urgent bugfix pending.\ncustom release cycles and releases are available for commercial users.\nquick start\nthis section assumes that you have a copy of the vernemq source tree. to get started, you need to first build vernemq.\nbuilding vernemq\nnote: vernemq requires erlang/otp 22-24 and libsnappy-dev installed in your system. you'll also need a c compiler for eleveldb. (on debian, you install build-essential, as an example).\nassuming you have a working erlang installation, building vernemq should be as simple as:\n$ cd $vernemq\n$ make rel\nstarting vernemq\nonce you've successfully built vernemq, you can start the server with the following commands:\n$ cd $vernemq/_build/default/rel/vernemq\n$ bin/vernemq start\nif vernemq is running it is possible to check the status on http://localhost:8888/status and it should look something like:\nnote that the $vernemq/_build/default/rel/vernemq directory is a complete, self-contained instance of vernemq and erlang. it is strongly suggested that you move this directory outside the source tree if you plan to run a production instance.\nimportant links\nvernemq documentation", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000048, "year": null}, {"Unnamed: 0": 100, "autor": 100, "date": null, "content": "Eclipse Paho C Client Library for the MQTT Protocol\nThis repository contains the source code for the Eclipse Paho MQTT C client library.\nThis code builds libraries which enable applications to connect to an MQTT broker to publish messages, and to subscribe to topics and receive published messages.\nSynchronous and various asynchronous programming models are supported.\nInformation About MQTT\nMQTT website\nThe MQTT 3.1.1 standard\nThe MQTT 5.0 standard\nHiveMQ introduction to MQTT\nOASIS Introduction to MQTT presentation\nLibraries\nThe Paho C client comprises four variant libraries, shared or static:\npaho-mqtt3a - asynchronous (MQTTAsync)\npaho-mqtt3as - asynchronous with SSL (MQTTAsync)\npaho-mqtt3c - \"classic\" / synchronous (MQTTClient)\npaho-mqtt3cs - \"classic\" / synchronous with SSL (MQTTClient)\nWhich Paho C API to use, with some history, for context\nUsage and API\nDetailed API documentation is available online. It is also available by building the Doxygen docs in the doc directory.\nSamples are available in the Doxygen docs and also in src/samples for reference. These are:\npaho_c_pub.c and paho_c_sub.c: command line utilities to publish and subscribe, -h will give help\npaho_cs_pub.c paho_cs_sub.c: command line utilities using MQTTClient to publish and subscribe\nMQTTClient_publish.c, MQTTClient_subscribe.c and MQTTClient_publish_async.c: MQTTClient simple code examples\nMQTTAsync_publish.c and MQTTAsync_subscribe.c: MQTTAsync simple code examples\nSome potentially useful blog posts:\nPaho client MQTT 5.0 support and command line utilities\nMQTT, QoS and persistence\nA story of MQTT 5.0\nVarious MQTT and MQTT-SN talks I've given.\nRuntime tracing\nA number of environment variables control runtime tracing of the C library.\nTracing is switched on using MQTT_C_CLIENT_TRACE (a value of ON traces to stdout, any other value should specify a file to trace to).\nThe verbosity of the output is controlled using the MQTT_C_CLIENT_TRACE_LEVEL environment variable - valid values are ERROR, PROTOCOL, MINIMUM, MEDIUM and MAXIMUM (from least to most verbose).\nThe variable MQTT_C_CLIENT_TRACE_MAX_LINES limits the number of lines of trace that are output.\nexport MQTT_C_CLIENT_TRACE=ON\nexport MQTT_C_CLIENT_TRACE_LEVEL=PROTOCOL\nReporting bugs\nPlease open issues in the Github project: https://github.com/eclipse/paho.mqtt.c/issues.\nMore information\nDiscussion of the Paho clients takes place on the Eclipse paho-dev mailing list.\nGeneral questions about the MQTT protocol are discussed in the MQTT Google Group.\nThere is more information available via the MQTT community site.\nBuild instructions for GNU Make\nEnsure the OpenSSL development package is installed. Then from the client library base directory run:\nmake\nsudo make install\nThis will build and install the libraries. To uninstall:\nsudo make uninstall\nTo build the documentation requires doxygen and optionally graphviz.\nmake html\nThe provided GNU Makefile is intended to perform all build steps in the build directory within the source-tree of Eclipse Paho. Generated binares, libraries, and the documentation can be found in the build/output directory after completion.\nOptions that are passed to the compiler/linker can be specified by typical Unix build variables:\nVariable Description\nCC Path to the C compiler\nCFLAGS Flags passed to compiler calls\nLDFLAGS Flags passed to linker calls\nBuild requirements / compilation using CMake\nThe build process currently supports a number of Linux \"flavors\" including ARM and s390, OS X, AIX and Solaris as well as the Windows operating system. The build process requires the following tools:\nCMake (http://cmake.org)\nNinja (https://martine.github.io/ninja/) or GNU Make (https://www.gnu.org/software/make/), and\ngcc (https://gcc.gnu.org/).\nOn Debian based systems this would mean that the following packages have to be installed:\napt-get install build-essential gcc make cmake cmake-gui cmake-curses-gui\nAlso, in order to build a debian package from the source code, the following packages have to be installed\napt-get install fakeroot fakeroot devscripts dh-make lsb-release\nNinja can be downloaded from its github project page in the \"releases\" section. Optionally it is possible to build binaries with SSL support. This requires the OpenSSL libraries and includes to be available. E. g. on Debian:\napt-get install libssl-dev\nThe documentation requires doxygen and optionally graphviz:\napt-get install doxygen graphviz\nBefore compiling, determine the value of some variables in order to configure features, library locations, and other options:\nVariable Default Value Description\nPAHO_BUILD_SHARED TRUE Build a shared version of the libraries\nPAHO_BUILD_STATIC FALSE Build a static version of the libraries\nPAHO_HIGH_PERFORMANCE FALSE When set to true, the debugging aids internal tracing and heap tracking are not included.\nPAHO_WITH_SSL FALSE Flag that defines whether to build ssl-enabled binaries too.\nOPENSSL_ROOT_DIR \"\" (system default) Directory containing your OpenSSL installation (i.e. /usr/local when headers are in /usr/local/include and libraries are in /usr/local/lib)\nPAHO_BUILD_DOCUMENTATION FALSE Create and install the HTML based API documentation (requires Doxygen)\nPAHO_BUILD_SAMPLES FALSE Build sample programs\nMQTT_TEST_BROKER tcp://localhost:1883 MQTT connection URL for a broker to use during test execution\nMQTT_TEST_PROXY tcp://localhost:1883 Hostname of the test proxy to use\nMQTT_SSL_HOSTNAME localhost Hostname of a test SSL MQTT broker to use\nPAHO_BUILD_DEB_PACKAGE FALSE Build debian package\nUsing these variables CMake can be used to generate your Ninja or Make files. Using CMake, building out-of-source is the default. Therefore it is recommended to invoke all build commands inside your chosen build directory but outside of the source tree.\nAn example build session targeting the build platform could look like this:\nmkdir /tmp/build.paho\ncd /tmp/build.paho\ncmake -GNinja -DPAHO_WITH_SSL=TRUE -DPAHO_BUILD_DOCUMENTATION=TRUE -DPAHO_BUILD_SAMPLES=TRUE ~/git/org.eclipse.paho.mqtt.c\nInvoking cmake and specifying build options can also be performed using cmake-gui or ccmake (see https://cmake.org/runningcmake/). For example:\nccmake -GNinja ~/git/org.eclipse.paho.mqtt.c\nTo compile/link the binaries and to generate packages, simply invoke ninja package or make -j <number-of-cores-to-use> package after CMake. To simply compile/link invoke ninja or make -j <number-of-cores-to-use>.\nDebug builds\nDebug builds can be performed by defining the value of the CMAKE_BUILD_TYPE option to Debug. For example:\ncmake -GNinja -DCMAKE_BUILD_TYPE=Debug git/org.eclipse.paho.mqtt.c\nRunning the tests\nTest code is available in the test directory. The tests can be built and executed with the CMake build system. The test execution requires a MQTT broker running. By default, the build system uses localhost, however it is possible to configure the build to use an external broker. These parameters are documented in the Build Requirements section above.\nAfter ensuring a MQTT broker is available, it is possible to execute the tests by starting the proxy and running ctest as described below:\npython ../test/mqttsas2.py &\nctest -VV\nCross compilation\nCross compilation using CMake is performed by using so called \"toolchain files\" (see: http://www.vtk.org/Wiki/CMake_Cross_Compiling).\nThe path to the toolchain file can be specified by using CMake's -DCMAKE_TOOLCHAIN_FILE option. In case no toolchain file is specified, the build is performed for the native build platform.\nFor your convenience toolchain files for the following platforms can be found in the cmake directory of Eclipse Paho:\nLinux x86\nLinux ARM11 (a.k.a. the Raspberry Pi)\nWindows x86_64\nWindows x86\nThe provided toolchain files assume that required compilers/linkers are to be found in the environment, i. e. the PATH-Variable of your user or system. If you prefer, you can also specify the absolute location of your compilers in the toolchain files.\nExample invocation for the Raspberry Pi:\ncmake -GNinja -DPAHO_WITH_SSL=TRUE -DPAHO_BUILD_SAMPLES=TRUE -DPAHO_BUILD_DOCUMENTATION=TRUE -DOPENSSL_LIB_SEARCH_PATH=/tmp/libssl-dev/usr/lib/arm-linux-gnueabihf -DOPENSSL_INC_SEARCH_PATH=\"/tmp/libssl-dev/usr/include/openssl;/tmp/libssl-dev/usr/include/arm-linux-gnueabihf\" -DCMAKE_TOOLCHAIN_FILE=~/git/org.eclipse.paho.mqtt.c/cmake/toolchain.linux-arm11.cmake ~/git/org.eclipse.paho.mqtt.c\nCompilers for the Raspberry Pi can be obtained from e. g. Linaro (see: http://releases.linaro.org/15.06/components/toolchain/binaries/4.8/arm-linux-gnueabihf/). This example assumes that OpenSSL-libraries and includes have been installed in the /tmp/libssl-dev directory.\nExample invocation for Windows 64 bit:\ncmake -GNinja -DPAHO_BUILD_SAMPLES=TRUE -DCMAKE_TOOLCHAIN_FILE=~/git/org.eclipse.paho.mqtt.c/cmake/toolchain.win64.cmake ~/git/org.eclipse.paho.mqtt.c\nIn this case the libraries and executable are not linked against OpenSSL Libraries. Cross compilers for the Windows platform can be installed on Debian like systems like this:\napt-get install gcc-mingw-w64-x86-64 gcc-mingw-w64-i686\nMicrosoft Windows\nCalling convention\nAs is normal for C programs on Windows, the calling convention is __cdecl. See the Microsoft documentation here:\nhttps://docs.microsoft.com/en-us/cpp/cpp/cdecl?view=vs-2019\nIf you call this library from another language, you may need to take this into account.", "link": "https://github.com/eclipse/paho.mqtt.c", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "eclipse paho c client library for the mqtt protocol\nthis repository contains the source code for the eclipse paho mqtt c client library.\nthis code builds libraries which enable applications to connect to an mqtt broker to publish messages, and to subscribe to topics and receive published messages.\nsynchronous and various asynchronous programming models are supported.\ninformation about mqtt\nmqtt website\nthe mqtt 3.1.1 standard\nthe mqtt 5.0 standard\nhivemq introduction to mqtt\noasis introduction to mqtt presentation\nlibraries\nthe paho c client comprises four variant libraries, shared or static:\npaho-mqtt3a - asynchronous (mqttasync)\npaho-mqtt3as - asynchronous with ssl (mqttasync)\npaho-mqtt3c - \"classic\" / synchronous (mqttclient)\npaho-mqtt3cs - \"classic\" / synchronous with ssl (mqttclient)\nwhich paho c api to use, with some history, for context\nusage and api\ndetailed api documentation is available online. it is also available by building the doxygen docs in the doc directory.\nsamples are available in the doxygen docs and also in src/samples for reference. these are:\npaho_c_pub.c and paho_c_sub.c: command line utilities to publish and subscribe, -h will give help\npaho_cs_pub.c paho_cs_sub.c: command line utilities using mqttclient to publish and subscribe\nmqttclient_publish.c, mqttclient_subscribe.c and mqttclient_publish_async.c: mqttclient simple code examples\nmqttasync_publish.c and mqttasync_subscribe.c: mqttasync simple code examples\nsome potentially useful blog posts:\npaho client mqtt 5.0 support and command line utilities\nmqtt, qos and persistence\na story of mqtt 5.0\nvarious mqtt and mqtt-sn talks i've given.\nruntime tracing\na number of environment variables control runtime tracing of the c library.\ntracing is switched on using mqtt_c_client_trace (a value of on traces to stdout, any other value should specify a file to trace to).\nthe verbosity of the output is controlled using the mqtt_c_client_trace_level environment variable - valid values are error, protocol, minimum, medium and maximum (from least to most verbose).\nthe variable mqtt_c_client_trace_max_lines limits the number of lines of trace that are output.\nexport mqtt_c_client_trace=on\nexport mqtt_c_client_trace_level=protocol\nreporting bugs\nplease open issues in the github project: https://github.com/eclipse/paho.mqtt.c/issues.\nmore information\ndiscussion of the paho clients takes place on the eclipse paho-dev mailing list.\ngeneral questions about the mqtt protocol are discussed in the mqtt google group.\nthere is more information available via the mqtt community site.\nbuild instructions for gnu make\nensure the openssl development package is installed. then from the client library base directory run:\nmake\nsudo make install\nthis will build and install the libraries. to uninstall:\nsudo make uninstall\nto build the documentation requires doxygen and optionally graphviz.\nmake html\nthe provided gnu makefile is intended to perform all build steps in the build directory within the source------> tree !!!  of eclipse paho. generated binares, libraries, and the documentation can be found in the build/output directory after completion.\noptions that are passed to the compiler/linker can be specified by typical unix build variables:\nvariable description\ncc path to the c compiler\ncflags flags passed to compiler calls\nldflags flags passed to linker calls\nbuild requirements / compilation using cmake\nthe build process currently supports a number of linux \"flavors\" including arm and s390, os x, aix and solaris as well as the windows operating system. the build process requires the following tools:\ncmake (http://cmake.org)\nninja (https://martine.github.io/ninja/) or gnu make (https://www.gnu.org/software/make/), and\ngcc (https://gcc.gnu.org/).\non debian based systems this would mean that the following packages have to be installed:\napt-get install build-essential gcc make cmake cmake-gui cmake-curses-gui\nalso, in order to build a debian package from the source code, the following packages have to be installed\napt-get install fakeroot fakeroot devscripts dh-make lsb-release\nninja can be downloaded from its github project page in the \"releases\" section. optionally it is possible to build binaries with ssl support. this requires the openssl libraries and includes to be available. e. g. on debian:\napt-get install libssl-dev\nthe documentation requires doxygen and optionally graphviz:\napt-get install doxygen graphviz\nbefore compiling, determine the value of some variables in order to configure features, library locations, and other options:\nvariable default value description\npaho_build_shared true build a shared version of the libraries\npaho_build_static false build a static version of the libraries\npaho_high_performance false when set to true, the debugging aids internal tracing and heap tracking are not included.\npaho_with_ssl false flag that defines whether to build ssl-enabled binaries too.\nopenssl_root_dir \"\" (system default) directory containing your openssl installation (i.e. /usr/local when headers are in /usr/local/include and libraries are in /usr/local/lib)\npaho_build_documentation false create and install the html based api documentation (requires doxygen)\npaho_build_samples false build sample programs\nmqtt_test_broker tcp://localhost:1883 mqtt connection url for a broker to use during test execution\nmqtt_test_proxy tcp://localhost:1883 hostname of the test proxy to use\nmqtt_ssl_hostname localhost hostname of a test ssl mqtt broker to use\npaho_build_deb_package false build debian package\nusing these variables cmake can be used to generate your ninja or make files. using cmake, building out-of-source is the default. therefore it is recommended to invoke all build commands inside your chosen build directory but outside of the source tree.\nan example build session targeting the build platform could look like this:\nmkdir /tmp/build.paho\ncd /tmp/build.paho\ncmake -gninja -dpaho_with_ssl=true -dpaho_build_documentation=true -dpaho_build_samples=true ~/git/org.eclipse.paho.mqtt.c\ninvoking cmake and specifying build options can also be performed using cmake-gui or ccmake (see https://cmake.org/runningcmake/). for example:\nccmake -gninja ~/git/org.eclipse.paho.mqtt.c\nto compile/link the binaries and to generate packages, simply invoke ninja package or make -j <number-of-cores-to-use> package after cmake. to simply compile/link invoke ninja or make -j <number-of-cores-to-use>.\ndebug builds\ndebug builds can be performed by defining the value of the cmake_build_type option to debug. for example:\ncmake -gninja -dcmake_build_type=debug git/org.eclipse.paho.mqtt.c\nrunning the tests\ntest code is available in the test directory. the tests can be built and executed with the cmake build system. the test execution requires a mqtt broker running. by default, the build system uses localhost, however it is possible to configure the build to use an external broker. these parameters are documented in the build requirements section above.\nafter ensuring a mqtt broker is available, it is possible to execute the tests by starting the proxy and running ctest as described below:\npython ../test/mqttsas2.py &\nctest -vv\ncross compilation\ncross compilation using cmake is performed by using so called \"toolchain files\" (see: http://www.vtk.org/wiki/cmake_cross_compiling).\nthe path to the toolchain file can be specified by using cmake's -dcmake_toolchain_file option. in case no toolchain file is specified, the build is performed for the native build platform.\nfor your convenience toolchain files for the following platforms can be found in the cmake directory of eclipse paho:\nlinux x86\nlinux arm11 (a.k.a. the raspberry pi)\nwindows x86_64\nwindows x86\nthe provided toolchain files assume that required compilers/linkers are to be found in the environment, i. e. the path-variable of your user or system. if you prefer, you can also specify the absolute location of your compilers in the toolchain files.\nexample invocation for the raspberry pi:\ncmake -gninja -dpaho_with_ssl=true -dpaho_build_samples=true -dpaho_build_documentation=true -dopenssl_lib_search_path=/tmp/libssl-dev/usr/lib/arm-linux-gnueabihf -dopenssl_inc_search_path=\"/tmp/libssl-dev/usr/include/openssl;/tmp/libssl-dev/usr/include/arm-linux-gnueabihf\" -dcmake_toolchain_file=~/git/org.eclipse.paho.mqtt.c/cmake/toolchain.linux-arm11.cmake ~/git/org.eclipse.paho.mqtt.c\ncompilers for the raspberry pi can be obtained from e. g. linaro (see: http://releases.linaro.org/15.06/components/toolchain/binaries/4.8/arm-linux-gnueabihf/). this example assumes that openssl-libraries and includes have been installed in the /tmp/libssl-dev directory.\nexample invocation for windows 64 bit:\ncmake -gninja -dpaho_build_samples=true -dcmake_toolchain_file=~/git/org.eclipse.paho.mqtt.c/cmake/toolchain.win64.cmake ~/git/org.eclipse.paho.mqtt.c\nin this case the libraries and executable are not linked against openssl libraries. cross compilers for the windows platform can be installed on debian like systems like this:\napt-get install gcc-mingw-w64-x86-64 gcc-mingw-w64-i686\nmicrosoft windows\ncalling convention\nas is normal for c programs on windows, the calling convention is __cdecl. see the microsoft documentation here:\nhttps://docs.microsoft.com/en-us/cpp/cpp/cdecl?view=vs-2019\nif you call this library from another language, you may need to take this into account.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000100, "year": null}, {"Unnamed: 0": 111, "autor": 111, "date": null, "content": "onoff\nGPIO access and interrupt detection with Node.js on Linux boards like the Raspberry Pi or BeagleBone.\nonoff supports Node.js versions 10, 12, 14, 15 and 16.\nContents\nInstallation\nUsage\nLEDs and Buttons\nDebouncing Buttons\nBlink an LED Using the Synchronous API\nBlink an LED Using the Asynchronous API and Completion Callbacks\nBlink an LED Using the Asynchronous API and Promises\nAPI\nHow Does onoff Work?\nConfiguring Pullup and Pulldown Resistors\nBenchmarks\nRelated Packages\nAdditional Information\nInstallation\nnpm install onoff\nNote that although it's possible to install onoff on non-Linux systems the functionality offered by onoff is only available on Linux systems.\nUsage\nLEDs and Buttons\nAssume that there's an LED connected to GPIO17 and a momentary push button connected to GPIO4.\nWhen the button is pressed the LED should turn on, when it's released the LED should turn off. This can be achieved with the following code:\nconst Gpio = require('onoff').Gpio;\nconst led = new Gpio(17, 'out');\nconst button = new Gpio(4, 'in', 'both');\nbutton.watch((err, value) => led.writeSync(value));\nHere two Gpio objects are being created. One called led for the LED connected to GPIO17 which is an output, and one called button for the momentary push button connected to GPIO4 which is an input. In addition to specifying that the button is an input, the constructors optional third argument is used to specify that 'both' rising and falling interrupt edges should be configured for the button GPIO as both button presses and releases should be handled.\nAfter everything has been setup correctly, the buttons watch method is used to specify a callback function to execute every time the button is pressed or released. The value argument passed to the callback function represents the state of the button which will be 1 for pressed and 0 for released. This value is used by the callback to turn the LED on or off using its writeSync method.\nWhen the above program is running it can be terminated with ctrl-c. However, it doesn't free its resources. It also ignores the err argument passed to the callback. Here's a slightly modified variant of the program that handles ctrl-c gracefully and bails out on error. The resources used by the led and button Gpio objects are released by invoking their unexport method.\nconst Gpio = require('onoff').Gpio;\nconst led = new Gpio(17, 'out');\nconst button = new Gpio(4, 'in', 'both');\nbutton.watch((err, value) => {\nif (err) {\nthrow err;\n}\nled.writeSync(value);\n});\nprocess.on('SIGINT', _ => {\nled.unexport();\nbutton.unexport();\n});\nDebouncing Buttons\nWhen working with buttons there will often be button bounce issues which result in the hardware thinking that a button was pressed several times although it was only pressed once. onoff provides a software debouncing solution for resolving bounce issues.\nAssume again that there's an LED connected to GPIO17 and a momentary push button connected to GPIO4.\nWhen the button is pressed the LED should toggle its state. This is a typical example of a situation where there will be button bounce issues. The issue can be resolved by using the debounceTimeout option when creating the Gpio object for the button. In the below program the debounceTimeout is set to 10 milliseconds. This delays invoking the watch callback for the button while the button is bouncing. The watch callback will not be invoked until the button stops bouncing and has been in a stable state for 10 milliseconds.\nconst Gpio = require('onoff').Gpio;\nconst led = new Gpio(17, 'out');\nconst button = new Gpio(4, 'in', 'rising', {debounceTimeout: 10});\nbutton.watch((err, value) => {\nif (err) {\nthrow err;\n}\nled.writeSync(led.readSync() ^ 1);\n});\nprocess.on('SIGINT', _ => {\nled.unexport();\nbutton.unexport();\n});\nBlink an LED Using the Synchronous API\nBlink an LED connected to GPIO17 for 5 seconds using the synchronous readSync and writeSync methods.\nconst Gpio = require('../onoff').Gpio; // Gpio class\nconst led = new Gpio(17, 'out'); // Export GPIO17 as an output\n// Toggle the state of the LED connected to GPIO17 every 200ms\nconst iv = setInterval(_ => led.writeSync(led.readSync() ^ 1), 200);\n// Stop blinking the LED after 5 seconds\nsetTimeout(_ => {\nclearInterval(iv); // Stop blinking\nled.unexport(); // Unexport GPIO and free resources\n}, 5000);\nBlink an LED Using the Asynchronous API and Completion Callbacks\nBlink an LED connected to GPIO17 for 5 seconds using the asynchronous read and write methods and completion callbacks.\nconst Gpio = require('../onoff').Gpio; // Gpio class\nconst led = new Gpio(17, 'out'); // Export GPIO17 as an output\nlet stopBlinking = false;\n// Toggle the state of the LED connected to GPIO17 every 200ms\nconst blinkLed = _ => {\nif (stopBlinking) {\nreturn led.unexport();\n}\nled.read((err, value) => { // Asynchronous read\nif (err) {\nthrow err;\n}\nled.write(value ^ 1, err => { // Asynchronous write\nif (err) {\nthrow err;\n}\n});\n});\nsetTimeout(blinkLed, 200);\n};\nblinkLed();\n// Stop blinking the LED after 5 seconds\nsetTimeout(_ => stopBlinking = true, 5000);\nBlink an LED Using the Asynchronous API and Promises\nBlink an LED connected to GPIO17 for 5 seconds using the asynchronous read and write methods and Promises.\nconst Gpio = require('../onoff').Gpio; // Gpio class\nconst led = new Gpio(17, 'out'); // Export GPIO17 as an output\nlet stopBlinking = false;\n// Toggle the state of the LED connected to GPIO17 every 200ms\nconst blinkLed = _ => {\nif (stopBlinking) {\nreturn led.unexport();\n}\nled.read()\n.then(value => led.write(value ^ 1))\n.then(_ => setTimeout(blinkLed, 200))\n.catch(err => console.log(err));\n};\nblinkLed();\n// Stop blinking the LED after 5 seconds\nsetTimeout(_ => stopBlinking = true, 5000);\nCheck accessibility\nSometimes it may be necessary to determine if the current system supports GPIOs programmatically and mock functionality if it doesn't. Gpio.accessible can be used to achieve this.\nconst Gpio = require('onoff').Gpio;\nconst useLed = (led, value) => led.writeSync(value);\nlet led;\nif (Gpio.accessible) {\nled = new Gpio(17, 'out');\n// more real code here\n} else {\nled = {\nwriteSync: value => {\nconsole.log('virtual led now uses value: ' + value);\n}\n};\n}\nuseLed(led, 1);\nAPI\nClass Gpio\nGpio(gpio, direction [, edge] [, options]) - Constructor\nread([callback]) - Read GPIO value asynchronously\nreadSync() - Read GPIO value synchronously\nwrite(value[, callback]) - Write GPIO value asynchronously\nwriteSync(value) - Write GPIO value synchronously\nwatch(callback) - Watch for hardware interrupts on the GPIO\nunwatch([callback]) - Stop watching for hardware interrupts on the GPIO\nunwatchAll() - Remove all watchers for the GPIO\ndirection() - Get GPIO direction\nsetDirection(direction) - Set GPIO direction\nedge() - Get GPIO interrupt generating edge\nsetEdge(edge) - Set GPIO interrupt generating edge\nactiveLow() - Get GPIO activeLow setting\nsetActiveLow(invert) - Set GPIO activeLow setting\nunexport() - Reverse the effect of exporting the GPIO to userspace\nstatic accessible - Determine whether or not GPIO access is possible\nHIGH / LOW - Constants used when reading or writing a GPIO value\nGpio(gpio, direction [, edge] [, options])\ngpio - An unsigned integer specifying the GPIO number.\ndirection - A string specifying whether the GPIO should be configured as an input or output. The valid values are: 'in', 'out', 'high', and 'low'. If 'out' is specified the GPIO will be configured as an output and the value of the GPIO will be set to 0. 'high' and 'low' are variants of 'out' that configure the GPIO as an output with an initial level of 1 or 0 respectively.\n[edge] - An optional string specifying the interrupt generating edge or edges for an input GPIO. The valid values are: 'none', 'rising', 'falling' or 'both'. The default value is 'none' indicating that the GPIO will not generate interrupts. Whether or not interrupts are supported by an input GPIO is GPIO specific. If interrupts are not supported by a GPIO the edge argument should not be specified. The edge argument is ignored for output GPIOs.\n[options] - An optional options object.\nConfigures the GPIO based on the passed arguments and returns a new Gpio object that can be used to access the GPIO.\nThe following options are supported:\ndebounceTimeout - An unsigned integer specifying a millisecond delay. Delays invoking the watch callback for an interrupt generating input GPIO while the input is bouncing. The watch callback will not be invoked until the input stops bouncing and has been in a stable state for debounceTimeout milliseconds. Optional, if unspecified the input GPIO will not be debounced.\nactiveLow - A boolean value specifying whether the values read from or written to the GPIO should be inverted. The interrupt generating edge for the GPIO also follow this this setting. The valid values for activeLow are true and false. Setting activeLow to true inverts. Optional, the default value is false.\nreconfigureDirection - A boolean value specifying whether the direction for the GPIO should be reconfigured even though the direction is already configured correctly. When an application starts, the direction of a GPIO used by that application may already be configured correctly, for example, from a previous run of the application. Reconfiguring the direction of that GPIO can result in unwanted side effects. For example, if a GPIO is already configured as an output and it is reconfigured as an output by passing 'out' to the constructor, the value of that output will be set to 0. In some applications this is not desirable and the value of the output should not be modified. The reconfigureDirection option can help here. If reconfigureDirection is set to false the direction of a GPIO that is already correctly configured will not be reconfigured. Optional, the default value is true.\nGPIOs on Linux are identified by unsigned integers. These are the numbers that should be passed to the onoff Gpio constructor when exporting GPIOs to userspace. For example, pin 11 on the Raspberry Pi expansion header corresponds to GPIO17 in Raspbian Linux. 17 is therefore the number to pass to the onoff Gpio constructor when using pin 11 on the expansion header.\nread([callback])\n[callback] - An optional completion callback that gets two arguments (err, value), where err is reserved for an Error object and value is the number 0 or 1 and represents the state of the GPIO.\nRead GPIO value asynchronously. If no completion callback is specified read returns a Promise which resolves to the value of the GPIO on success or rejects with an Error object on failure.\nNote that most systems support readback of GPIOs configured as outputs. The read method can therefore be invoked for any GPIO, irrespective of whether it was configured as an input or an output. The Raspberry Pi and BeagleBone are examples of such systems.\nreadSync()\nRead GPIO value synchronously. Returns the number 0 or 1 to represent the state of the GPIO.\nNote that most systems support readback of GPIOs configured as outputs. The readSync method can therefore be invoked for any GPIO, irrespective of whether it was configured as an input or an output. The Raspberry Pi and BeagleBone are examples of such systems.\nwrite(value[, callback])\nvalue - The number 0 or 1.\n[callback] - An optional completion callback that gets one argument (err), where err is reserved for an error object.\nWrite GPIO value asynchronously. If no completion callback is specified write returns a Promise that resolves with no value on success or rejects with an Error object on failure.\nNote that on most systems invoking write for a GPIO configured as an input will result in an EPERM error indicating that the operation is not permitted. The Raspberry Pi and BeagleBone are examples of such systems.\nwriteSync(value)\nvalue - The number 0 or 1.\nWrite GPIO value synchronously.\nNote that on most systems invoking writeSync for a GPIO configured as an input will result in an EPERM error indicating that the operation is not permitted. The Raspberry Pi and BeagleBone are examples of such systems.\nwatch(callback)\ncallback - A callback that gets two arguments (err, value), where err is reserved for an error object and value is the number 0 or 1 and represents the state of the GPIO. The value can also be used to determine whether the interrupt occurred on a rising or falling edge. A value of 0 implies a falling edge interrupt and a value of 1 implies a rising edge interrupt.\nWatch for hardware interrupts on the GPIO. The edge argument that was passed to the constructor determines which hardware interrupts to watch for.\nunwatch([callback])\n[callback] - The callback to remove.\nStop watching for hardware interrupts on the GPIO. If callback is specified, only that particular callback is removed. Otherwise all callbacks are removed.\nunwatchAll()\nRemove all hardware interrupt watchers for the GPIO.\ndirection()\nReturns the string 'in' or 'out' indicating whether the GPIO is an input or output.\nsetDirection(direction)\ndirection - A string specifying whether the GPIO should be configured as an input or output. The valid values are 'in', 'out', 'high', and 'low'. If 'out' is specified the GPIO will be configured as an output and the value of the GPIO will be set to 0. 'high' and 'low' are variants of 'out' that configure the GPIO as an output with an initial level of 1 or 0 respectively.\nSet GPIO direction.\nedge()\nReturns the string 'none', 'falling', 'rising', or 'both' indicating the interrupt generating edge or edges for the GPIO. Whether or not interrupts are supported by an input GPIO is GPIO specific. If interrupts are not supported the edge method should not be used. Interrupts are not supported by output GPIOs.\nsetEdge(edge)\nedge - A string specifying the interrupt generating edge or edges for an input GPIO. The valid values are: 'none', 'rising', 'falling' or 'both'. Whether or not interrupts are supported by an input GPIO is GPIO specific. If interrupts are not supported the setEdge method should not be used. Interrupts are not supported by output GPIOs.\nSet GPIO interrupt generating edge.\nactiveLow()\nReturns true or false indicating whether or not the values read from or written to the GPIO are inverted.\nsetActiveLow(invert)\ninvert - A boolean value specifying whether the values read from or written to the GPIO should be inverted. The interrupt generating edge for the GPIO also follow this this setting. The valid values for invert are true and false. Setting activeLow to true inverts.\nSet GPIO activeLow setting.\nunexport()\nReverse the effect of exporting the GPIO to userspace. A Gpio object should not be used after invoking its unexport method.\nstatic accessible\nDetermine whether or not GPIO access is possible. true if the current process has the permissions required to export GPIOs to userspace. false otherwise. Loosely speaking, if this property is true it should be possible for the current process to create Gpio objects.\nIt is notable that while this property may be false indicating that the current process does not have the permissions required to export GPIOs to userspace, existing exported GPIOs may still be accessible.\nThis property is useful for mocking functionality on computers used for development that do not provide access to GPIOs.\nThis is a static property and should be accessed as Gpio.accessible.\nstatic HIGH / LOW\nConstants used when reading or writing a GPIO value. Gpio.HIGH and Gpio.LOW can be used in place of the numeric constants 1 and 0.\nHow Does onoff Work?\nInternally onoff uses sysfs files located at /sys/class/gpio to access GPIOs and the epoll package to detect hardware interrupts. The Linux GPIO sysfs interface for userspace is documented here. It's a relatively simple interface which can be used to ask the Linux kernel to export control of a GPIO to userspace. After control of a GPIO has been exported to userspace, the GPIO can be configured as an input or output. Thereafter, the state of an input can be read, and the state of an output can be written. Some systems will also allow the state of a output to be read. The GPIO sysfs interface can also be used for interrupt detection. onoff can detect several thousand interrupts per second on both the BeagleBone and the Raspberry Pi.\nConfiguring Pullup and Pulldown Resistors\nAs mentioned in section How Does onoff Work the sysfs interface is used to access GPIOs. The sysfs interface doesn't offer support for configuring pullup and pulldown resistors on GPIOs.\nThere are however many platform specific mechanisms for configuring pullup and pulldown resistors that are compatible with onoff. onoff itself doesn't use these mechanisms as one of the goals of onoff is to be platform independent.\nHere we'll take a look at two mechanisms available on the Raspberry Pi for configuring pullup and pulldown resistors.\nThe first point to be aware of is that most GPIOs on a Raspberry Pi have either their pullup or pulldown resistor activated by default. The defaults can be seen in Table 6-31 on pages 102 and 103 of the BCM2835 ARM Peripherals documentation.\nUsing the gpio Command in /boot/config.txt\nOn Raspbian 2018-04-18 or later the gpio configuration command can be used in /boot/config.txt to configure pullup and pulldown resistors. Further information is available at New \"gpio\" config command.\nUsing Device Tree Overlays\nDevice tree overlays can also be used to configure pullup and pulldown resistors. The Wiki page Enabling Pullup and Pulldown Resistors on The Raspberry Pi describes this mechanism in more detail.\nBenchmarks\nThree of the onoff tests are used to monitor performance.\nperformance-async.js - determine max. no. of write ops per seconds\nperformance-sync.js - determine max. no. of writeSync ops per second\nperformance-interrupt.js - determine max. no. of interrupts per second\nThe results of these tests are shown in the following tables.\nRaspberry Pi 4 B, 1.5GHz, Raspberry Pi OS (March 4th 2021, Buster 10.8)\nnode onoff kernel write / sec writeSync / sec interrupts / sec\nv16.0.0 v6.0.3 5.10.17-v7l+ 25124 280417 20240\nv15.14.0 v6.0.3 5.10.17-v7l+ 24055 271149 20488\nv14.16.1 v6.0.3 5.10.17-v7l+ 21669 254705 19703\nv12.22.1 v6.0.3 5.10.17-v7l+ 22618 318417 21122\nv10.24.1 v6.0.3 5.10.17-v7l+ 22405 329927 19583\nRaspberry Pi 3 B, 1.2GHz, Raspbian Buster 10.1\nnode onoff kernel write / sec writeSync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.75-v7l+ 21670 207222 18328\nv10.18.0 v5.0.0 4.19.75-v7l+ 23661 225758 20741\nRaspberry Pi 2 B, 900MHz, Raspbian Buster 10.1\nnode onoff kernel write / sec writeSync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.75-v7l+ 10769 113107 10373\nv10.18.0 v5.0.0 4.19.75-v7l+ 11843 129086 10536\nRaspberry Pi 1 B, 700MHz, Raspbian Buster 10.1\nnode onoff kernel write / sec writeSync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.75+ 2316 26696 2112\nv10.18.0 v5.0.0 4.19.75+ 2613 33129 2225\nBeagleBone Black, 1GHz, Debian Buster 10.2\nnode onoff kernel write / sec writeSync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.79-ti-r30 6855 70535 5911\nv10.18.0 v5.0.0 4.19.79-ti-r30 7564 79133 5920\nBeagleBone, 720MHz, Debian Buster 10.2\nnode onoff kernel write / sec writeSync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.79-ti-r30 5013 49741 4297\nv10.18.0 v5.0.0 4.19.79-ti-r30 5400 57157 4371\nRelated Packages\nHere are a few links to other hardware specific Node.js packages that may be of interest.\npigpio - Fast GPIO, PWM, servo control, state change notification and interrupt handling on the Raspberry Pi\ni2c-bus - I2C serial bus access\nspi-device - SPI serial bus access\nmcp-spi-adc - Analog to digital conversion with the MCP3002/4/8, MCP3202/4/8 and MCP3304\nAdditional Information\nonoff was tested on the following platforms:\nRaspberry Pi 1, 2, 3 and 4\nRaspbian or Raspberry Pi OS\nBeagleBone, BeagleBone Black and PocketBeagle\nDebian\nThe suitability of onoff for a particular Linux board is highly dependent on how GPIO interfaces are made available on that board. The GPIO interfaces documentation describes GPIO access conventions rather than standards that must be followed so GPIO can vary from platform to platform. For example, onoff relies on sysfs files located at /sys/class/gpio being available. However, these sysfs files for userspace GPIO are optional and may not be available on a particular platform.", "link": "https://github.com/fivdi/onoff", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "onoff\ngpio access and interrupt detection with node.js on linux boards like the raspberry pi or beaglebone.\nonoff supports node.js versions 10, 12, 14, 15 and 16.\ncontents\ninstallation\nusage\nleds and buttons\ndebouncing buttons\nblink an led using the synchronous api\nblink an led using the asynchronous api and completion callbacks\nblink an led using the asynchronous api and promises\napi\nhow does onoff work?\nconfiguring pullup and pulldown resistors\nbenchmarks\nrelated packages\nadditional information\ninstallation\nnpm install onoff\nnote that although it's possible to install onoff on non-linux systems the functionality offered by onoff is only available on linux systems.\nusage\nleds and buttons\nassume that there's an led connected to gpio17 and a momentary push button connected to gpio4.\nwhen the button is pressed the led should turn on, when it's released the led should turn off. this can be achieved with the following code:\nconst gpio = require('onoff').gpio;\nconst led = new gpio(17, 'out');\nconst button = new gpio(4, 'in', 'both');\nbutton.watch((err, value) => led.writesync(value));\nhere two gpio objects are being created. one called led for the led connected to gpio17 which is an output, and one called button for the momentary push button connected to gpio4 which is an input. in addition to specifying that the button is an input, the constructors optional third argument is used to specify that 'both' rising and falling interrupt edges should be configured for the button gpio as both button presses and releases should be handled.\nafter everything has been setup correctly, the buttons watch method is used to specify a callback function to execute every time the button is pressed or released. the value argument passed to the callback function represents the state of the button which will be 1 for pressed and 0 for released. this value is used by the callback to turn the led on or off using its writesync method.\nwhen the above program is running it can be terminated with ctrl-c. however, it doesn't free its resources. it also ignores the err argument passed to the callback. here's a slightly modified variant of the program that handles ctrl-c gracefully and bails out on error. the resources used by the led and button gpio objects are released by invoking their unexport method.\nconst gpio = require('onoff').gpio;\nconst led = new gpio(17, 'out');\nconst button = new gpio(4, 'in', 'both');\nbutton.watch((err, value) => {\nif (err) {\nthrow err;\n}\nled.writesync(value);\n});\nprocess.on('sigint', _ => {\nled.unexport();\nbutton.unexport();\n});\ndebouncing buttons\nwhen working with buttons there will often be button bounce issues which result in the hardware thinking that a button was pressed several times although it was only pressed once. onoff provides a software debouncing solution for resolving bounce issues.\nassume again that there's an led connected to gpio17 and a momentary push button connected to gpio4.\nwhen the button is pressed the led should toggle its state. this is a typical example of a situation where there will be button bounce issues. the issue can be resolved by using the debouncetimeout option when creating the gpio object for the button. in the below program the debouncetimeout is set to 10 milliseconds. this delays invoking the watch callback for the button while the button is bouncing. the watch callback will not be invoked until the button stops bouncing and has been in a stable state for 10 milliseconds.\nconst gpio = require('onoff').gpio;\nconst led = new gpio(17, 'out');\nconst button = new gpio(4, 'in', 'rising', {debouncetimeout: 10});\nbutton.watch((err, value) => {\nif (err) {\nthrow err;\n}\nled.writesync(led.readsync() ^ 1);\n});\nprocess.on('sigint', _ => {\nled.unexport();\nbutton.unexport();\n});\nblink an led using the synchronous api\nblink an led connected to gpio17 for 5 seconds using the synchronous readsync and writesync methods.\nconst gpio = require('../onoff').gpio; // gpio class\nconst led = new gpio(17, 'out'); // export gpio17 as an output\n// toggle the state of the led connected to gpio17 every 200ms\nconst iv = setinterval(_ => led.writesync(led.readsync() ^ 1), 200);\n// stop blinking the led after 5 seconds\nsettimeout(_ => {\nclearinterval(iv); // stop blinking\nled.unexport(); // unexport gpio and free resources\n}, 5000);\nblink an led using the asynchronous api and completion callbacks\nblink an led connected to gpio17 for 5 seconds using the asynchronous read and write methods and completion callbacks.\nconst gpio = require('../onoff').gpio; // gpio class\nconst led = new gpio(17, 'out'); // export gpio17 as an output\nlet stopblinking = false;\n// toggle the state of the led connected to gpio17 every 200ms\nconst blinkled = _ => {\nif (stopblinking) {\nreturn led.unexport();\n}\nled.read((err, value) => { // asynchronous read\nif (err) {\nthrow err;\n}\nled.write(value ^ 1, err => { // asynchronous write\nif (err) {\nthrow err;\n}\n});\n});\nsettimeout(blinkled, 200);\n};\nblinkled();\n// stop blinking the led after 5 seconds\nsettimeout(_ => stopblinking = true, 5000);\nblink an led using the asynchronous api and promises\nblink an led connected to gpio17 for 5 seconds using the asynchronous read and write methods and promises.\nconst gpio = require('../onoff').gpio; // gpio class\nconst led = new gpio(17, 'out'); // export gpio17 as an output\nlet stopblinking = false;\n// toggle the state of the led connected to gpio17 every 200ms\nconst blinkled = _ => {\nif (stopblinking) {\nreturn led.unexport();\n}\nled.read()\n.then(value => led.write(value ^ 1))\n.then(_ => settimeout(blinkled, 200))\n.catch(err => console.log(err));\n};\nblinkled();\n// stop blinking the led after 5 seconds\nsettimeout(_ => stopblinking = true, 5000);\ncheck accessibility\nsometimes it may be necessary to determine if the current system supports gpios programmatically and mock functionality if it doesn't. gpio.accessible can be used to achieve this.\nconst gpio = require('onoff').gpio;\nconst useled = (led, value) => led.writesync(value);\nlet led;\nif (gpio.accessible) {\nled = new gpio(17, 'out');\n// more real code here\n} else {\nled = {\nwritesync: value => {\nconsole.log('virtual led now uses value: ' + value);\n}\n};\n}\nuseled(led, 1);\napi\nclass gpio\ngpio(gpio, direction [, edge] [, options]) - constructor\nread([callback]) - read gpio value asynchronously\nreadsync() - read gpio value synchronously\nwrite(value[, callback]) - write gpio value asynchronously\nwritesync(value) - write gpio value synchronously\nwatch(callback) - watch for hardware interrupts on the gpio\nunwatch([callback]) - stop watching for hardware interrupts on the gpio\nunwatchall() - remove all watchers for the gpio\ndirection() - get gpio direction\nsetdirection(direction) - set gpio direction\nedge() - get gpio interrupt generating edge\nsetedge(edge) - set gpio interrupt generating edge\nactivelow() - get gpio activelow setting\nsetactivelow(invert) - set gpio activelow setting\nunexport() - reverse the effect of exporting the gpio to userspace\nstatic accessible - determine whether or not gpio access is possible\nhigh / low - constants used when reading or writing a gpio value\ngpio(gpio, direction [, edge] [, options])\ngpio - an unsigned integer specifying the gpio number.\ndirection - a string specifying whether the gpio should be configured as an input or output. the valid values are: 'in', 'out', 'high', and 'low'. if 'out' is specified the gpio will be configured as an output and the value of the gpio will be set to 0. 'high' and 'low' are variants of 'out' that configure the gpio as an output with an initial level of 1 or 0 respectively.\n[edge] - an optional string specifying the interrupt generating edge or edges for an input gpio. the valid values are: 'none', 'rising', 'falling' or 'both'. the default value is 'none' indicating that the gpio will not generate interrupts. whether or not interrupts are supported by an input gpio is gpio specific. if interrupts are not supported by a gpio the edge argument should not be specified. the edge argument is ignored for output gpios.\n[options] - an optional options object.\nconfigures the gpio based on the passed arguments and returns a new gpio object that can be used to access the gpio.\nthe following options are supported:\ndebouncetimeout - an unsigned integer specifying a millisecond delay. delays invoking the watch callback for an interrupt generating input gpio while the input is bouncing. the watch callback will not be invoked until the input stops bouncing and has been in a stable state for debouncetimeout milliseconds. optional, if unspecified the input gpio will not be debounced.\nactivelow - a boolean value specifying whether the values read from or written to the gpio should be inverted. the interrupt generating edge for the gpio also follow this this setting. the valid values for activelow are true and false. setting activelow to true inverts. optional, the default value is false.\nreconfiguredirection - a boolean value specifying whether the direction for the gpio should be reconfigured even though the direction is already configured correctly. when an application starts, the direction of a gpio used by that application may already be configured correctly, for example, from a previous run of the application. reconfiguring the direction of that gpio can result in unwanted side effects. for example, if a gpio is already configured as an output and it is reconfigured as an output by passing 'out' to the constructor, the value of that output will be set to 0. in some applications this is not desirable and the value of the output should not be modified. the reconfiguredirection option can help here. if reconfiguredirection is set to false the direction of a gpio that is already correctly configured will not be reconfigured. optional, the default value is true.\ngpios on linux are identified by unsigned integers. these are the numbers that should be passed to the onoff gpio constructor when exporting gpios to userspace. for example, pin 11 on the raspberry pi expansion header corresponds to gpio17 in raspbian linux. 17 is therefore the number to pass to the onoff gpio constructor when using pin 11 on the expansion header.\nread([callback])\n[callback] - an optional completion callback that gets two arguments (err, value), where err is reserved for an error object and value is the number 0 or 1 and represents the state of the gpio.\nread gpio value asynchronously. if no completion callback is specified read returns a promise which resolves to the value of the gpio on success or rejects with an error object on failure.\nnote that most systems support readback of gpios configured as outputs. the read method can therefore be invoked for any gpio, irrespective of whether it was configured as an input or an output. the raspberry pi and beaglebone are examples of such systems.\nreadsync()\nread gpio value synchronously. returns the number 0 or 1 to represent the state of the gpio.\nnote that most systems support readback of gpios configured as outputs. the readsync method can therefore be invoked for any gpio, irrespective of whether it was configured as an input or an output. the raspberry pi and beaglebone are examples of such systems.\nwrite(value[, callback])\nvalue - the number 0 or 1.\n[callback] - an optional completion callback that gets one argument (err), where err is reserved for an error object.\nwrite gpio value asynchronously. if no completion callback is specified write returns a promise that resolves with no value on success or rejects with an error object on failure.\nnote that on most systems invoking write for a gpio configured as an input will result in an eperm error indicating that the operation is not permitted. the raspberry pi and beaglebone are examples of such systems.\nwritesync(value)\nvalue - the number 0 or 1.\nwrite gpio value synchronously.\nnote that on most systems invoking writesync for a gpio configured as an input will result in an eperm error indicating that the operation is not permitted. the raspberry pi and beaglebone are examples of such systems.\nwatch(callback)\ncallback - a callback that gets two arguments (err, value), where err is reserved for an error object and value is the number 0 or 1 and represents the state of the gpio. the value can also be used to determine whether the interrupt occurred on a rising or falling edge. a value of 0 implies a falling edge interrupt and a value of 1 implies a rising edge interrupt.\nwatch for hardware interrupts on the gpio. the edge argument that was passed to the constructor determines which hardware interrupts to watch for.\nunwatch([callback])\n[callback] - the callback to remove.\nstop watching for hardware interrupts on the gpio. if callback is specified, only that particular callback is removed. otherwise all callbacks are removed.\nunwatchall()\nremove all hardware interrupt watchers for the gpio.\ndirection()\nreturns the string 'in' or 'out' indicating whether the gpio is an input or output.\nsetdirection(direction)\ndirection - a string specifying whether the gpio should be configured as an input or output. the valid values are 'in', 'out', 'high', and 'low'. if 'out' is specified the gpio will be configured as an output and the value of the gpio will be set to 0. 'high' and 'low' are variants of 'out' that configure the gpio as an output with an initial level of 1 or 0 respectively.\nset gpio direction.\nedge()\nreturns the string 'none', 'falling', 'rising', or 'both' indicating the interrupt generating edge or edges for the gpio. whether or not interrupts are supported by an input gpio is gpio specific. if interrupts are not supported the edge method should not be used. interrupts are not supported by output gpios.\nsetedge(edge)\nedge - a string specifying the interrupt generating edge or edges for an input gpio. the valid values are: 'none', 'rising', 'falling' or 'both'. whether or not interrupts are supported by an input gpio is gpio specific. if interrupts are not supported the setedge method should not be used. interrupts are not supported by output gpios.\nset gpio interrupt generating edge.\nactivelow()\nreturns true or false indicating whether or not the values read from or written to the gpio are inverted.\nsetactivelow(invert)\ninvert - a boolean value specifying whether the values read from or written to the gpio should be inverted. the interrupt generating edge for the gpio also follow this this setting. the valid values for invert are true and false. setting activelow to true inverts.\nset gpio activelow setting.\nunexport()\nreverse the effect of exporting the gpio to userspace. a gpio object should not be used after invoking its unexport method.\nstatic accessible\ndetermine whether or not gpio access is possible. true if the current process has the permissions required to export gpios to userspace. false otherwise. loosely speaking, if this property is true it should be possible for the current process to create gpio objects.\nit is notable that while this property may be false indicating that the current process does not have the permissions required to export gpios to userspace, existing exported gpios may still be accessible.\nthis property is useful for mocking functionality on computers used for development that do not provide access to gpios.\nthis is a static property and should be accessed as gpio.accessible.\nstatic high / low\nconstants used when reading or writing a gpio value. gpio.high and gpio.low can be used in place of the numeric constants 1 and 0.\nhow does onoff work?\ninternally onoff uses sysfs files located at /sys/class/gpio to access gpios and the epoll package to detect hardware interrupts. the linux gpio sysfs interface for userspace is documented here. it's a relatively simple interface which can be used to ask the linux kernel to export control of a gpio to userspace. after control of a gpio has been exported to userspace, the gpio can be configured as an input or output. thereafter, the state of an input can be read, and the state of an output can be written. some systems will also allow the state of a output to be read. the gpio sysfs interface can also be used for interrupt detection. onoff can detect several thousand interrupts per second on both the beaglebone and the raspberry pi.\nconfiguring pullup and pulldown resistors\nas mentioned in section how does onoff work the sysfs interface is used to access gpios. the sysfs interface doesn't offer support for configuring pullup and pulldown resistors on gpios.\nthere are however many platform specific mechanisms for configuring pullup and pulldown resistors that are compatible with onoff. onoff itself doesn't use these mechanisms as one of the goals of onoff is to be platform independent.\nhere we'll take a look at two mechanisms available on the raspberry pi for configuring pullup and pulldown resistors.\nthe first point to be aware of is that most gpios on a raspberry pi have either their pullup or pulldown resistor activated by default. the defaults can be seen in table 6-31 on pages 102 and 103 of the bcm2835 arm peripherals documentation.\nusing the gpio command in /boot/config.txt\non raspbian 2018-04-18 or later the gpio configuration command can be used in /boot/config.txt to configure pullup and pulldown resistors. further information is available at new \"gpio\" config command.\nusing device -----> tree !!!  overlays\ndevice -----> tree !!!  overlays can also be used to configure pullup and pulldown resistors. the wiki page enabling pullup and pulldown resistors on the raspberry pi describes this mechanism in more detail.\nbenchmarks\nthree of the onoff tests are used to monitor performance.\nperformance-async.js - determine max. no. of write ops per seconds\nperformance-sync.js - determine max. no. of writesync ops per second\nperformance-interrupt.js - determine max. no. of interrupts per second\nthe results of these tests are shown in the following tables.\nraspberry pi 4 b, 1.5ghz, raspberry pi os (march 4th 2021, buster 10.8)\nnode onoff kernel write / sec writesync / sec interrupts / sec\nv16.0.0 v6.0.3 5.10.17-v7l+ 25124 280417 20240\nv15.14.0 v6.0.3 5.10.17-v7l+ 24055 271149 20488\nv14.16.1 v6.0.3 5.10.17-v7l+ 21669 254705 19703\nv12.22.1 v6.0.3 5.10.17-v7l+ 22618 318417 21122\nv10.24.1 v6.0.3 5.10.17-v7l+ 22405 329927 19583\nraspberry pi 3 b, 1.2ghz, raspbian buster 10.1\nnode onoff kernel write / sec writesync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.75-v7l+ 21670 207222 18328\nv10.18.0 v5.0.0 4.19.75-v7l+ 23661 225758 20741\nraspberry pi 2 b, 900mhz, raspbian buster 10.1\nnode onoff kernel write / sec writesync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.75-v7l+ 10769 113107 10373\nv10.18.0 v5.0.0 4.19.75-v7l+ 11843 129086 10536\nraspberry pi 1 b, 700mhz, raspbian buster 10.1\nnode onoff kernel write / sec writesync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.75+ 2316 26696 2112\nv10.18.0 v5.0.0 4.19.75+ 2613 33129 2225\nbeaglebone black, 1ghz, debian buster 10.2\nnode onoff kernel write / sec writesync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.79-ti-r30 6855 70535 5911\nv10.18.0 v5.0.0 4.19.79-ti-r30 7564 79133 5920\nbeaglebone, 720mhz, debian buster 10.2\nnode onoff kernel write / sec writesync / sec interrupts / sec\nv12.14.0 v5.0.0 4.19.79-ti-r30 5013 49741 4297\nv10.18.0 v5.0.0 4.19.79-ti-r30 5400 57157 4371\nrelated packages\nhere are a few links to other hardware specific node.js packages that may be of interest.\npigpio - fast gpio, pwm, servo control, state change notification and interrupt handling on the raspberry pi\ni2c-bus - i2c serial bus access\nspi-device - spi serial bus access\nmcp-spi-adc - analog to digital conversion with the mcp3002/4/8, mcp3202/4/8 and mcp3304\nadditional information\nonoff was tested on the following platforms:\nraspberry pi 1, 2, 3 and 4\nraspbian or raspberry pi os\nbeaglebone, beaglebone black and pocketbeagle\ndebian\nthe suitability of onoff for a particular linux board is highly dependent on how gpio interfaces are made available on that board. the gpio interfaces documentation describes gpio access conventions rather than standards that must be followed so gpio can vary from platform to platform. for example, onoff relies on sysfs files located at /sys/class/gpio being available. however, these sysfs files for userspace gpio are optional and may not be available on a particular platform.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000111, "year": null}, {"Unnamed: 0": 121, "autor": 121, "date": null, "content": "Overview\nMy personal Home Assistant Container configurations with 300+ automations. These are my active automations and configurations that I use every day. Updated frequently as I add more devices and come up with more and more complicated ways to do simple tasks.\nMenu\n| Hubs | Lighting | Climate| Outlets & Switches| Locks | Security | Voice Assistant | Media | Sensors | Cameras | Garage | Vacuum | Blinds | Appliances | Network | Other Hardware| Software | Retired Devices | Screenshots |\nHubs\n| Go to Menu |\nDevice Quantity Connection Home Assistant Notes\nAeotec Z-Stick 7 1 USB Z-Wave JS Used to control all Z-Wave Devices. Integrated via zwavejs2mqtt container\nHue Hub v2 1 Ethernet Philips Hue Used to control all Zigbee smart bulbs\nLutron Smart Bridge 2 Pro 1 Ethernet Lutron Caseta Pro (Custom Component) Controls Lutron Caseta light switches, dimmers, and Pico remotes\nIKEA TR\u00c5DFRI 1 Ethernet IKEA TR\u00c5DFRI Currently only used to support the IKEA line of blinds\nBond Home 1 Wi-Fi Bond Home Controls ceiling fans and lights via RF remote control commands. Existing fans are each wired to a single switch that controls both power and light with fan and light controls done via a physical remote. The Bond Home Hub allowed for sending of those RF remote commands via the hub and the local API makes it possible to send said commands from Home Assistant.\nRelevant hub configurations can be found within configuration.yaml\nLighting\n| Go to Menu | Home Screenshot |\nDevice Quantity Connection Home Assistant Notes\nPhilips Hue White and Color Ambiance 9 Ethernet Philips Hue Light Color changing smart bulbs\nPhilips Hue White and Color Ambiance LightStrip Plus Dimmable 1 Hue Hub (Zigbee) Philips Hue Light Color changing smart led strip. Used as accent lighting\nPhilips Hue White 8 Hue Hub (Zigbee) Philips Hue Light Non color changing smart bulbs\nCree Connected 9 Hue Hub (Zigbee) Philips Hue Light Non color changing smart bulbs\nLutron Caseta Wireless Dimmer 17 Lutron Clear Connect Lutron Caseta Pro (Custom Component) Smart dimmer switches that do not require a neutral wire\nLutron Caseta Wireless Lighting Switch 2 Lutron Clear Connect Lutron Caseta Pro (Custom Component) Smart on / off light switches\nLutron Caseta Pico Wireless Dimmer Switch 6 Lutron Clear Connect Lutron Caseta Pro (Custom Component) Decora wall mountable remote (that looks like a dimmer switch). Controls various lights\nLutron Aurora Smart Bulb Dimmer 4 Hue Hub (Zigbee) Philips Hue Light Smart Dimmer that attaches to existing Toggle light Switch.\nLIFX Mini White 1 Wi-Fi LIFX Non color changing Wi-Fi smart bulbs. Used in places where Zigbee is not reliable (detached garage)\nLUMIMAN LM530 1 Wi-Fi Tuya Color changing Wi-Fi smart bulbs. Used as a lamp for a 3D Printed Moon Globe\nMany of my automations rely on some form of lighting but many examples can be found in lights.yaml and location.yaml.\nLights are grouped via light_group.yaml\nClimate\n| Go to Menu | Weather Screenshot |\nDevice Quantity Connection Home Assistant Notes\nEcobee 3 1 Wi-Fi ecobee / Ecobee Thermostat Used as primary thermostat\nEcobee Room Sensor 9 Ecobee3 Ecobee Binary Sensor Provides room temperature and room occupancy.\nDyson Pure Hot + Cool Link 1 Wi-Fi Dyson (Custom Component) Dyson Fan with Heater and Air Purifier\nTemp Sensor Probe DS18b20 1 4 Relay ESP32 ESPHome Waterproof Temperature sensor, connected directly to ESPHome module\nI utilize a number of automations that adjust climate controls. Mostly they can be found in climate.yaml. Ecobee room sensors are heavily used in occupancy.yaml and as conditions in many automations\nMore detailed information on the ESPhome configuration can be found in here\nOutlets & Switches\n| Go to Menu | Home Screenshot |\nDevice Quantity Connection Home Assistant Notes\nWemo Mini Smart Plug 4 Wi-Fi Belkin WeMo Smart outlets utilized to control various devices via powering the outlet on/off (fans, Christmas Tree, etc)\nWemo Insight Smart Plug 2 Wi-Fi Belkin WeMo Smart outlet utilized to monitor power to washing machine and dryer\nZooz Power Switch ZEN15 2 Z-Wave Z-Wave JS Smart outlet utilized to monitor power to sump pump\nGE Z-Wave Wireless Smart Lighting Control Outdoor Module 4 Z-Wave Z-Wave JS Used to control low voltage outdoor lighting transformers, bug zapper, and Christmas lights (Holiday time only)\nRemotec Zwave Dry Contact Fixture Module 1 Z-Wave Z-Wave JS Used to control gas fireplace\nDome Home Automation Water Shut-Off Valve 1 Z-Wave Z-Wave JS Used to shut off Water Main Supply to House in the event of water leak detected or while on Vacation\nSwitches and outlets are used in various capacities, some are for lighting and some are for fans type devices. lights.yaml and occupancy.yaml should have some good examples.\nWashing machine is automated around the Wemo Insight Plug. This outlet can monitor power consumption, I created a sensor based on the power reading that shows a simple status of running or not running thus automating around that sensor.\nLocks\n| Go to Menu | Alarm Screenshot |\nDevice Quantity Connection Home Assistant Notes\nSchlage Connect Touchscreen Deadbolt 3 Z-Wave Z-Wave JS Smart locks used in automations to auto lock / unlock doors\nLocks are used mostly as a way to lock / unlock doors based on locations, see location.yaml and locks.yaml for some examples\nSecurity\n| Go to Menu | Alarm Screenshot |\nDevice Quantity Connection Home Assistant Notes\nGoControl Door/Window Sensor 3 Z-Wave Z-Wave JS Door sensors to detect if exterior doors have been opened / closed\nGoControl Siren and Strobe 1 Z-Wave Z-Wave JS Alarm used for when alarm is triggered or when you want to get someone's attention\nDoor sensors, motion sensors, and the alarm siren are used in many different ways via alarm.yaml. I've also implemented some of the alarm functions as part of water_sensors.yaml.\nVoice Assistant\n| Go to Menu |\nDevice Quantity Connection Home Assistant Notes\nAmazon Echo 1 Wi-Fi Home Assistant Cloud Audio only Voice Assistant\nAmazon Echo Dot 7 Wi-Fi Home Assistant Cloud Audio only Voice Assistant\nAmazon Echo Spot 1 Wi-Fi Home Assistant Cloud Voice Assistant with small display\nAmazon Echo Show 1 Wi-Fi Home Assistant Cloud Voice Assistant with display\nAmazon Echo Show 5 1 Wi-Fi Home Assistant Cloud Voice Assistant with display\nI go for native Echo integration wherever possible, but a few devices are not currently supported where I've had to implement some work arounds via Home Assistant Cloud (previously Emulated Hue). Most of these are just exposed via an input_boolean and customize.yaml. This allows the ability to have echo turn on or off an input_boolean in turn triggering an automation.\nMedia\n| Go to Menu | Media Screenshot |\nDevice Quantity Connection Home Assistant Notes\nApple TV 4k 4 Wi-Fi Apple TV Used for media playback on 4k TVs\nApple TV 4 2 Wi-Fi Apple TV Used for media playback on TVs\nSonos Arc 1 Ethernet Sonos TV Soundbar for audio playback and Home Assistant TTS.\nSonos Sub 1 Ethernet Sonos Audio playback and Home Assistant TTS\nSonos Play:1 10 Wi-Fi Sonos Audio playback and Home Assistant TTS\nSonos One SL 2 Wi-Fi Sonos Audio playback and Home Assistant TTS\nSonos Move 2 Wi-Fi Sonos Portable Audio playback and Home Assistant TTS\nSonos Roam 1 Wi-Fi Sonos Portable Audio playback and Home Assistant TTS\nSonos Beam 2 Wi-Fi Sonos TV Soundbar for Audio playback and Home Assistant TTS\nSonos Port 1 Ethernet Sonos Audio playback and Home Assistant TTS. Connects Sonos to existing surround sound system\nSonos Connect:AMP 1 Wi-Fi Sonos Audio playback and Home Assistant TTS. Connects Sonos to outdoor speakers\nLutron Caseta Pico Remote Control for Audio 3 Lutron Clear Connect Lutron Caseta Pro (Custom Component) Decora wall mountable remote. Used to control Sonos\nLogitech Harmony Hub 3 Wi-Fi Harmony Hub Remote Controls various AV equipment and other devices that utilize infrared remotes\nSamsung QN75Q80TA 1 Wi-Fi Samsung Smart TV 75\" 4K QLED TV\nLG OLED55BXPUA 1 Wi-Fi LG webOS Smart TV 55\" 4K OLED TV\nPlex Media Server 1 Ethernet Plex / Plex Activity Monitor Media Server\nMost media player based automations can be found in media.yaml and some Text to Speech (TTS) based automation in various automations.\nHarmony Hubs work via a combination of input_selects, scripts, and automations in media.yaml.\nSensors\n| Go to Menu | System Screenshot |\nDevice Quantity Connection Home Assistant Notes\nNest Protect v2 Battery 6 Wi-Fi Nest Smoke Alarm and CO Alarm. I realized most of my Smoke Alarms had long suprased the 10 year mark and it was time for some replacements. I usually avoid Google owned products for various reasons, but the Nest Protect line has high praise.\nDome Motion Detector - Light Sensor 8 Z-Wave Z-Wave JS Motion and Light Level sensor used to automate around motion events and current room brightness.\nGoControl PIR Motion Detector 1 Z-Wave Z-Wave JS Motion sensor used to automate around motion events.\nZOOZ 4-in-1 Sensor ZSE40 5 Z-Wave Z-Wave JS Motion,temperature, humidity, and light level sensor used to automate around motion events.\nDome Home Automation Leak Sensor 8 Z-Wave Z-Wave JS Water sensors used to detect the pressence of water as a preventive measure\nAeon Labs Water Sensor 2 Z-Wave Z-Wave JS Water sensors used to detect the pressence of water as a preventive measure\nEcolink Door/Window Sensor 2 Z-Wave Z-Wave JS Trial run on Window sensors to stop my blinds from closing when a Window is Open. Starting small but we all know how that will end up. ALL THE WINDOWS!\nWater sensors serve one major function, to alert me to the presence of water. Almost all of those automations can be fond via water_works.yaml\nSmoke detectors, like the water sensors, have one real function to alert me of smoke or CO2. Almost all of those automations can be fond via smoke_alarm.yaml\nCameras\n| Go to Menu | Cameras Screenshot |\nDevice Quantity Connection Home Assistant Notes\nRing Video Doorbell 3 Plus 1 Wi-Fi Ring / Ring Binary Sensor Automated around binary sensors via motion or doorbell button press\nUbiquiti Unifi Protect G4 Pro 1 Ethernet Unifi Protect(Custom Component) 4K POE Camera.\nUbiquiti Unifi G4 Bullet 1 Ethernet Unifi Protect(Custom Component) 1440p POE Camera.\nUbiquiti UniFi Video G3 Flex 6 Ethernet Unifi Protect(Custom Component) 1080p POE Camera.\nUnifi Network Video Recorder (UNVR) 1 Ethernet Unifi Protect(Custom Component) Unifi Protect NVR.\nNothing is currently automated around cameras, just a UI element. The Ring doorbell is used in a number of ways to trigger an action based on motion detection or someone ringing the doorbell. Examples can be found in doorbell.yaml\nI also send camera feeds as a payload on a few iOS notifications, those can mostly be found in notification_text.yaml\nGarage\n| Go to Menu | Garage Screenshot |\nDevice Quantity Connection Home Assistant Notes\n4 Relay ESP32 1 Wi-Fi ESPHome Automated to open / close garage door on location and auto close after specific time intervals\nHoneywell Ademco 958 Overhead Door Contacts 1 4 Relay ESP32 ESPHome Door Sensor used with ESPHome Relay\nSimilar to locks, the Garage door is mostly automated to open / close based on location and after a set amount of time. Examples can be found in location.yaml and garage.yaml\nMore detailed information on the ESPhome configuration can be found in here\nVacuum\n| Go to Menu | Home Screenshot |\nDevice Quantity Connection Home Assistant Notes\niRobot i7+ 1 Wi-Fi iRobot Roomba Automated to run at specific times based on presence detection\niRobot Roomba 980 2 Wi-Fi iRobot Roomba Automated to run at specific times based on presence detection\niRobot Braava jet 240 1 Bluetooth NA Currently not integrated into Home Assistant. Unknown if this can ever be automated\nAll Roomba related automations can be found in roomba.yaml\nBlinds\n| Go to Menu | Home Screenshot |\nDevice Quantity Connection Home Assistant Notes\nIkea FYRTUR 10 Zigbee IKEA TR\u00c5DFRI Automated to open and close blinds based on motion, location, and sun elevation\nAll Blinds related automations can be found in blinds.yaml\nAppliances\n| Go to Menu | Basement Screenshot |\nDevice Quantity Connection Home Assistant Notes\nLG Washer WT7300CW 1 Wi-Fi LG ThinQ Automated for notifications and remaining run time. Currently using a custom component for testing purposes\nLG Dryer DLGX7801WE 1 Wi-Fi LG ThinQ Automated for notifications and remaining run time. Currently using a custom component for testing purposes\nAll laundry related automations can be found in laundry.yaml\nNetwork\n| Go to Menu | System Screenshot |\nDevice Quantity Connection Home Assistant Notes\nUbiquiti UniFi Cloud Key Gen2 Plus 1 Ethernet Ubiquiti Unifi Unifi Controller. Presence detection for non household members and devices\nUbiquiti Networks Unifi Security Gateway (USG) 1 Ethernet Ubiquiti Unifi Primary Router. Presence detection for non household members and devices\nUbiquiti Networks UniFi Switch PRO PoE - 24 Ports (USW-Pro-24-POE) 1 Ethernet Ubiquiti Unifi WAP Primary Network Switch. Presence detection for non household members and devices\nUbiquiti Networks UniFi Switch - 24 Ports (US-24-250W) 1 Ethernet Ubiquiti Unifi Secondary Network Switch. Presence detection for non household members and devices\nUbiquiti Networks 8-Port UniFi Switch (US-8-150W) 2 Ethernet Ubiquiti Unifi Additional Network Switches. Presence detection for non household members and devices\nUbiquiti Networks UniFi Access Point WiFi 6 Long-Range (U6-LR-US) 2 Ethernet Ubiquiti Unifi Wireless Access Point for interior and exterior use. Presence detection for non household members and devices.\nUbiquiti Networks Unifi AP PRO (UAP-AC-PRO-US) 1 Ethernet Ubiquiti Unifi Wireless Access Point for interior and exterior use. Presence detection for non household members and devices.\nUbiquiti Networks Unifi Access Point WiFi 6 Lite (U6-Lite-US) 2 Ethernet Ubiquiti Unifi Wireless Access Point for interior use. Presence detection for non household members and devices.\nUbiquiti Networks Unifi Mesh AP (UAP-AC-M-US) 1 Ethernet Ubiquiti Unifi Wireless Mesh Access Point for exterior use. Used in detached garage to provide internet and network traffic for cameras and devices. Presence detection for non household members and devices.\nSince I don\u2019t use the network equipment as my primary presence detection method most of the automation is around house guests via house_guest.yaml. The main function of the network equipment is to be network equipment for my fiber internet service.\nOther Hardware\n| Go to Menu | System Screenshot |\nDevice Quantity Connection Home Assistant Notes\nIntel NUC NUC8i5BEH 1 Ethernet NA Primary Linux server. Docker Containers and Plex media server run off this device.\nQNAP TS-453 Pro 1 Ethernet QNAP Sensor Main storage array. Configured with 4x WD Red Pro 4TB NAS Hard Disk Drives\nPrusa i3 MK3S+ 1 Wi-Fi OctoPrint 3D Printer connected to Home Assitant via OctoPrint running on a Raspberry Pi 4 B. Sometimes I make neat objects to help with Home Automation, but mostly useless stuff for fun.\nPrusa Mini+ 1 Wi-Fi OctoPrint 3D Printer connected to Home Assitant via OctoPrint running on a Raspberry Pi 4 B. Because if you're going to make useless non-sense, might as well double down.\nHP OfficeJet Pro 8025 1 Wi-Fi Internet Printing Protocol (IPP) Regualr inkjet printer that works whenever it feels like because it's a printer.\nAPC 1500VA Back-Up UPS 1 USB / Ethernet NUT Sensor Primary Uninterruptible Power Supply (UPS). Connected via the NUT component utlizing the QNAP NAS native UPS server component\nSoftware\n| Go to Menu |\nDevice Quantity Connection Home Assistant Notes\niOS App 2 NA iOS Used as Home Assistant interface on mobile devices and primary method of presence detection.\nLocative iOS App 2 NA Locative Brought out of retirement and used in conjunction with native iOS app via person integration\nDocker 1 Ethernet Installation on Docker Home Assistant install runs as a Docker Container\nPi-hole 2 Ethernet / Wi-Fi Pi-Hole Sensor Ad blocking. Primary instance runs within a Docker container and the secondary runs on a Raspberry-pi Zero W\nHome Assistant Management Tool 1 Ethernet NA Custom Shell script for managing Home Assistant\nThe iOS app is used for some notifications within various automations. The native iOS app is the main method of doing any location based automations via location.yaml and many of the conditions I use are based on presence detection of household members.\nMore detailed information on the custom Home Assistant Managment Tools can be found here.\nRetired\n| Go to Menu |\nDevice Quantity Connection Home Assistant Notes\nVera Plus 1 Ethernet Vera Used as a dumb hub to connect Z-Wave devices. Replaced by a Z-Wave Stick\nWink Hub v1 1 Wi-Fi Wink Semi retired, using it as a z-wave repeater for Vera. Once upon a time I really loved Wink, but when you don't stock hardware for almost a year and your buisness model is selling hardware... time for that slow ride to the Cloud API in the sky. Not to mention the massive outages when staff clock out and don't fix until morning (forget to renew an expired certificate anyone). It was a fun ride Wink, hopefully your death will not be to slow and painful, but i.am+ wants to watch the world burn... probably.\nQuirky + GE Aros Smart Window Air Conditioner 1 Wi-Fi Wink Climate No longer used after new HVAC system installed. Cooling effieceny had dropped and was more of an energy hog than actually making a difference in temprature comfort.\nFrigidaire Cool Connect Smart Portable Air Conditioner 1 Wi-Fi Harmony Hub Remote No longer in daily use after new HVAC system installed. May be brought back into service as needed.\niHome WiFI Smart Plug 2 Wink Hub (Wi-Fi) Wink Switch Not using these anymore due to overall poor reliability\nFoscam FI9800P 1 Wi-Fi Foscam IP Camera Replaced by Unifi G3 Flex\nUbiquiti UniFi Cloud Key 1 Ethernet Ubiquiti Unifi WAP Unifi Controller. Replaced by CloudKey gen2 Plus\nUbiquiti UVC-G3 UniFi Video Camera 2 Ethernet Unifi Protect(Custom Component) 1080p POE Camera. Replaced with G4 versions\nMyQ Smart Garage Door Opener 1 Wi-Fi MyQ Cover Got fed up with the sheer disrepect this device had for reliability. Would work great for months, then decide it had enough and work when it felt like.\nMyQ Home Bridge 1 Wi-Fi MyQ Cover See Above\nTP-Link Smart Plug HS100 1 Wi-Fi TP-Link Switch No longer needed, might re-use at some point\nWink Relay 2 Wi-Fi Wink Wall mounted touch screen. Wink interface was rubbish and was replaced with the Home Assistant dashboard. It provides binary sensors for the two push buttons, temperature, and humidity sensors. Doesn't get used much but looks cool. Turns out it was just rubbish and decided to go into an endless reboot loop, on top of the screen already having burn in problems even when not on all the time. Retired to the trash can.\nUbiquiti Networks airGateway LR Wireless AP 1 Wi-Fi NA Was used to connect Ubiquiti UVC-G3 UniFi Video Camera to the wireless network where running an ethernet cable wasn't feasible. Connects to POE injector. Replaced by Mesh AP and Switch\nSonos Connect 1 Ethernet Sonos Audio playback and Home Assistant TTS. Connects Sonos to existing surround sound system. Now considered a legacy Sonos device\nUbiquiti Networks Unifi AP PRO (UAP-AC-PRO-US) 1 Ethernet Ubiquiti Unifi WAP Wireless Access Point for interior and exterior use. Replaced by the Unifi NanoHD.\nUbiquiti Networks Unifi AP Long Range (UAP-AC-LR-US) 1 Ethernet Ubiquiti Unifi WAP Wireless Access Point for interior use. Presence detection for non household members and devices.\nInsignia - Wi-Fi Garage Door Controller 1 Wi-Fi HomeKit Controller Automated to open / close garage door on location and auto close after specific time intervals\nRing Video Doorbell 1 Wi-Fi Ring / Ring Binary Sensor Automated around binary sensors via motion or doorbell button press. Replaced with a Version 3 Plus.\niRobot Roomba 650 1 NA NA Currently not integrated into Home Assistant. Investigating options for future integration\nLutron Smart Bridge 2 1 Ethernet Lutron Caseta Replaced with a Lutron Smart Bridge 2 Pro\nCreality Ender 3 V2 1 Wi-Fi OctoPrint 3D Printer connected to Home Assitant via OctoPrint running on a Raspberry Pi 3 B+. Got tired of messing around with it, I just want to print useless objects with ease\nYamaha RX-V483BL 1 Wi-Fi Yamaha Network Receivers Surround Sound Receiver. Works in conjunction with the Sonos Connect, Harmony Hub, Apple TV 4k and various other media devices. Replaced with Sonos Arc System\nUbiquiti Networks UniFi nanoHD (UAP-NANOHD-US) 2 Ethernet Ubiquiti Unifi Wireless Access Point for interior and exterior use. Presence detection for non household members and devices. Replaced by WiFi 6 Models\nUbiquiti Networks Unifi AP Lite (UAP-AC-LITE) 1 Ethernet Ubiquiti Unifi Wireless Access Point for interior use. Presence detection for non household members and devices. Replaced by WiFi 6 Models\nScreenshots\n| Go to Menu |\n| Go to Menu |", "link": "https://github.com/geekofweek/homeassistant", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "overview\nmy personal home assistant container configurations with 300+ automations. these are my active automations and configurations that i use every day. updated frequently as i add more devices and come up with more and more complicated ways to do simple tasks.\nmenu\n| hubs | lighting | climate| outlets & switches| locks | security | voice assistant | media | sensors | cameras | garage | vacuum | blinds | appliances | network | other hardware| software | retired devices | screenshots |\nhubs\n| go to menu |\ndevice quantity connection home assistant notes\naeotec z-stick 7 1 usb z-wave js used to control all z-wave devices. integrated via zwavejs2mqtt container\nhue hub v2 1 ethernet philips hue used to control all zigbee smart bulbs\nlutron smart bridge 2 pro 1 ethernet lutron caseta pro (custom component) controls lutron caseta light switches, dimmers, and pico remotes\nikea tr\u00e5dfri 1 ethernet ikea tr\u00e5dfri currently only used to support the ikea line of blinds\nbond home 1 wi-fi bond home controls ceiling fans and lights via rf remote control commands. existing fans are each wired to a single switch that controls both power and light with fan and light controls done via a physical remote. the bond home hub allowed for sending of those rf remote commands via the hub and the local api makes it possible to send said commands from home assistant.\nrelevant hub configurations can be found within configuration.yaml\nlighting\n| go to menu | home screenshot |\ndevice quantity connection home assistant notes\nphilips hue white and color ambiance 9 ethernet philips hue light color changing smart bulbs\nphilips hue white and color ambiance lightstrip plus dimmable 1 hue hub (zigbee) philips hue light color changing smart led strip. used as accent lighting\nphilips hue white 8 hue hub (zigbee) philips hue light non color changing smart bulbs\ncree connected 9 hue hub (zigbee) philips hue light non color changing smart bulbs\nlutron caseta wireless dimmer 17 lutron clear connect lutron caseta pro (custom component) smart dimmer switches that do not require a neutral wire\nlutron caseta wireless lighting switch 2 lutron clear connect lutron caseta pro (custom component) smart on / off light switches\nlutron caseta pico wireless dimmer switch 6 lutron clear connect lutron caseta pro (custom component) decora wall mountable remote (that looks like a dimmer switch). controls various lights\nlutron aurora smart bulb dimmer 4 hue hub (zigbee) philips hue light smart dimmer that attaches to existing toggle light switch.\nlifx mini white 1 wi-fi lifx non color changing wi-fi smart bulbs. used in places where zigbee is not reliable (detached garage)\nlumiman lm530 1 wi-fi tuya color changing wi-fi smart bulbs. used as a lamp for a 3d printed moon globe\nmany of my automations rely on some form of lighting but many examples can be found in lights.yaml and location.yaml.\nlights are grouped via light_group.yaml\nclimate\n| go to menu | weather screenshot |\ndevice quantity connection home assistant notes\necobee 3 1 wi-fi ecobee / ecobee thermostat used as primary thermostat\necobee room sensor 9 ecobee3 ecobee binary sensor provides room temperature and room occupancy.\ndyson pure hot + cool link 1 wi-fi dyson (custom component) dyson fan with heater and air purifier\ntemp sensor probe ds18b20 1 4 relay esp32 esphome waterproof temperature sensor, connected directly to esphome module\ni utilize a number of automations that adjust climate controls. mostly they can be found in climate.yaml. ecobee room sensors are heavily used in occupancy.yaml and as conditions in many automations\nmore detailed information on the esphome configuration can be found in here\noutlets & switches\n| go to menu | home screenshot |\ndevice quantity connection home assistant notes\nwemo mini smart plug 4 wi-fi belkin wemo smart outlets utilized to control various devices via powering the outlet on/off (fans, christmas -----> tree !!! , etc)\nwemo insight smart plug 2 wi-fi belkin wemo smart outlet utilized to monitor power to washing machine and dryer\nzooz power switch zen15 2 z-wave z-wave js smart outlet utilized to monitor power to sump pump\nge z-wave wireless smart lighting control outdoor module 4 z-wave z-wave js used to control low voltage outdoor lighting transformers, bug zapper, and christmas lights (holiday time only)\nremotec zwave dry contact fixture module 1 z-wave z-wave js used to control gas fireplace\ndome home automation water shut-off valve 1 z-wave z-wave js used to shut off water main supply to house in the event of water leak detected or while on vacation\nswitches and outlets are used in various capacities, some are for lighting and some are for fans type devices. lights.yaml and occupancy.yaml should have some good examples.\nwashing machine is automated around the wemo insight plug. this outlet can monitor power consumption, i created a sensor based on the power reading that shows a simple status of running or not running thus automating around that sensor.\nlocks\n| go to menu | alarm screenshot |\ndevice quantity connection home assistant notes\nschlage connect touchscreen deadbolt 3 z-wave z-wave js smart locks used in automations to auto lock / unlock doors\nlocks are used mostly as a way to lock / unlock doors based on locations, see location.yaml and locks.yaml for some examples\nsecurity\n| go to menu | alarm screenshot |\ndevice quantity connection home assistant notes\ngocontrol door/window sensor 3 z-wave z-wave js door sensors to detect if exterior doors have been opened / closed\ngocontrol siren and strobe 1 z-wave z-wave js alarm used for when alarm is triggered or when you want to get someone's attention\ndoor sensors, motion sensors, and the alarm siren are used in many different ways via alarm.yaml. i've also implemented some of the alarm functions as part of water_sensors.yaml.\nvoice assistant\n| go to menu |\ndevice quantity connection home assistant notes\namazon echo 1 wi-fi home assistant cloud audio only voice assistant\namazon echo dot 7 wi-fi home assistant cloud audio only voice assistant\namazon echo spot 1 wi-fi home assistant cloud voice assistant with small display\namazon echo show 1 wi-fi home assistant cloud voice assistant with display\namazon echo show 5 1 wi-fi home assistant cloud voice assistant with display\ni go for native echo integration wherever possible, but a few devices are not currently supported where i've had to implement some work arounds via home assistant cloud (previously emulated hue). most of these are just exposed via an input_boolean and customize.yaml. this allows the ability to have echo turn on or off an input_boolean in turn triggering an automation.\nmedia\n| go to menu | media screenshot |\ndevice quantity connection home assistant notes\napple tv 4k 4 wi-fi apple tv used for media playback on 4k tvs\napple tv 4 2 wi-fi apple tv used for media playback on tvs\nsonos arc 1 ethernet sonos tv soundbar for audio playback and home assistant tts.\nsonos sub 1 ethernet sonos audio playback and home assistant tts\nsonos play:1 10 wi-fi sonos audio playback and home assistant tts\nsonos one sl 2 wi-fi sonos audio playback and home assistant tts\nsonos move 2 wi-fi sonos portable audio playback and home assistant tts\nsonos roam 1 wi-fi sonos portable audio playback and home assistant tts\nsonos beam 2 wi-fi sonos tv soundbar for audio playback and home assistant tts\nsonos port 1 ethernet sonos audio playback and home assistant tts. connects sonos to existing surround sound system\nsonos connect:amp 1 wi-fi sonos audio playback and home assistant tts. connects sonos to outdoor speakers\nlutron caseta pico remote control for audio 3 lutron clear connect lutron caseta pro (custom component) decora wall mountable remote. used to control sonos\nlogitech harmony hub 3 wi-fi harmony hub remote controls various av equipment and other devices that utilize infrared remotes\nsamsung qn75q80ta 1 wi-fi samsung smart tv 75\" 4k qled tv\nlg oled55bxpua 1 wi-fi lg webos smart tv 55\" 4k oled tv\nplex media server 1 ethernet plex / plex activity monitor media server\nmost media player based automations can be found in media.yaml and some text to speech (tts) based automation in various automations.\nharmony hubs work via a combination of input_selects, scripts, and automations in media.yaml.\nsensors\n| go to menu | system screenshot |\ndevice quantity connection home assistant notes\nnest protect v2 battery 6 wi-fi nest smoke alarm and co alarm. i realized most of my smoke alarms had long suprased the 10 year mark and it was time for some replacements. i usually avoid google owned products for various reasons, but the nest protect line has high praise.\ndome motion detector - light sensor 8 z-wave z-wave js motion and light level sensor used to automate around motion events and current room brightness.\ngocontrol pir motion detector 1 z-wave z-wave js motion sensor used to automate around motion events.\nzooz 4-in-1 sensor zse40 5 z-wave z-wave js motion,temperature, humidity, and light level sensor used to automate around motion events.\ndome home automation leak sensor 8 z-wave z-wave js water sensors used to detect the pressence of water as a preventive measure\naeon labs water sensor 2 z-wave z-wave js water sensors used to detect the pressence of water as a preventive measure\necolink door/window sensor 2 z-wave z-wave js trial run on window sensors to stop my blinds from closing when a window is open. starting small but we all know how that will end up. all the windows!\nwater sensors serve one major function, to alert me to the presence of water. almost all of those automations can be fond via water_works.yaml\nsmoke detectors, like the water sensors, have one real function to alert me of smoke or co2. almost all of those automations can be fond via smoke_alarm.yaml\ncameras\n| go to menu | cameras screenshot |\ndevice quantity connection home assistant notes\nring video doorbell 3 plus 1 wi-fi ring / ring binary sensor automated around binary sensors via motion or doorbell button press\nubiquiti unifi protect g4 pro 1 ethernet unifi protect(custom component) 4k poe camera.\nubiquiti unifi g4 bullet 1 ethernet unifi protect(custom component) 1440p poe camera.\nubiquiti unifi video g3 flex 6 ethernet unifi protect(custom component) 1080p poe camera.\nunifi network video recorder (unvr) 1 ethernet unifi protect(custom component) unifi protect nvr.\nnothing is currently automated around cameras, just a ui element. the ring doorbell is used in a number of ways to trigger an action based on motion detection or someone ringing the doorbell. examples can be found in doorbell.yaml\ni also send camera feeds as a payload on a few ios notifications, those can mostly be found in notification_text.yaml\ngarage\n| go to menu | garage screenshot |\ndevice quantity connection home assistant notes\n4 relay esp32 1 wi-fi esphome automated to open / close garage door on location and auto close after specific time intervals\nhoneywell ademco 958 overhead door contacts 1 4 relay esp32 esphome door sensor used with esphome relay\nsimilar to locks, the garage door is mostly automated to open / close based on location and after a set amount of time. examples can be found in location.yaml and garage.yaml\nmore detailed information on the esphome configuration can be found in here\nvacuum\n| go to menu | home screenshot |\ndevice quantity connection home assistant notes\nirobot i7+ 1 wi-fi irobot roomba automated to run at specific times based on presence detection\nirobot roomba 980 2 wi-fi irobot roomba automated to run at specific times based on presence detection\nirobot braava jet 240 1 bluetooth na currently not integrated into home assistant. unknown if this can ever be automated\nall roomba related automations can be found in roomba.yaml\nblinds\n| go to menu | home screenshot |\ndevice quantity connection home assistant notes\nikea fyrtur 10 zigbee ikea tr\u00e5dfri automated to open and close blinds based on motion, location, and sun elevation\nall blinds related automations can be found in blinds.yaml\nappliances\n| go to menu | basement screenshot |\ndevice quantity connection home assistant notes\nlg washer wt7300cw 1 wi-fi lg thinq automated for notifications and remaining run time. currently using a custom component for testing purposes\nlg dryer dlgx7801we 1 wi-fi lg thinq automated for notifications and remaining run time. currently using a custom component for testing purposes\nall laundry related automations can be found in laundry.yaml\nnetwork\n| go to menu | system screenshot |\ndevice quantity connection home assistant notes\nubiquiti unifi cloud key gen2 plus 1 ethernet ubiquiti unifi unifi controller. presence detection for non household members and devices\nubiquiti networks unifi security gateway (usg) 1 ethernet ubiquiti unifi primary router. presence detection for non household members and devices\nubiquiti networks unifi switch pro poe - 24 ports (usw-pro-24-poe) 1 ethernet ubiquiti unifi wap primary network switch. presence detection for non household members and devices\nubiquiti networks unifi switch - 24 ports (us-24-250w) 1 ethernet ubiquiti unifi secondary network switch. presence detection for non household members and devices\nubiquiti networks 8-port unifi switch (us-8-150w) 2 ethernet ubiquiti unifi additional network switches. presence detection for non household members and devices\nubiquiti networks unifi access point wifi 6 long-range (u6-lr-us) 2 ethernet ubiquiti unifi wireless access point for interior and exterior use. presence detection for non household members and devices.\nubiquiti networks unifi ap pro (uap-ac-pro-us) 1 ethernet ubiquiti unifi wireless access point for interior and exterior use. presence detection for non household members and devices.\nubiquiti networks unifi access point wifi 6 lite (u6-lite-us) 2 ethernet ubiquiti unifi wireless access point for interior use. presence detection for non household members and devices.\nubiquiti networks unifi mesh ap (uap-ac-m-us) 1 ethernet ubiquiti unifi wireless mesh access point for exterior use. used in detached garage to provide internet and network traffic for cameras and devices. presence detection for non household members and devices.\nsince i don\u2019t use the network equipment as my primary presence detection method most of the automation is around house guests via house_guest.yaml. the main function of the network equipment is to be network equipment for my fiber internet service.\nother hardware\n| go to menu | system screenshot |\ndevice quantity connection home assistant notes\nintel nuc nuc8i5beh 1 ethernet na primary linux server. docker containers and plex media server run off this device.\nqnap ts-453 pro 1 ethernet qnap sensor main storage array. configured with 4x wd red pro 4tb nas hard disk drives\nprusa i3 mk3s+ 1 wi-fi octoprint 3d printer connected to home assitant via octoprint running on a raspberry pi 4 b. sometimes i make neat objects to help with home automation, but mostly useless stuff for fun.\nprusa mini+ 1 wi-fi octoprint 3d printer connected to home assitant via octoprint running on a raspberry pi 4 b. because if you're going to make useless non-sense, might as well double down.\nhp officejet pro 8025 1 wi-fi internet printing protocol (ipp) regualr inkjet printer that works whenever it feels like because it's a printer.\napc 1500va back-up ups 1 usb / ethernet nut sensor primary uninterruptible power supply (ups). connected via the nut component utlizing the qnap nas native ups server component\nsoftware\n| go to menu |\ndevice quantity connection home assistant notes\nios app 2 na ios used as home assistant interface on mobile devices and primary method of presence detection.\nlocative ios app 2 na locative brought out of retirement and used in conjunction with native ios app via person integration\ndocker 1 ethernet installation on docker home assistant install runs as a docker container\npi-hole 2 ethernet / wi-fi pi-hole sensor ad blocking. primary instance runs within a docker container and the secondary runs on a raspberry-pi zero w\nhome assistant management tool 1 ethernet na custom shell script for managing home assistant\nthe ios app is used for some notifications within various automations. the native ios app is the main method of doing any location based automations via location.yaml and many of the conditions i use are based on presence detection of household members.\nmore detailed information on the custom home assistant managment tools can be found here.\nretired\n| go to menu |\ndevice quantity connection home assistant notes\nvera plus 1 ethernet vera used as a dumb hub to connect z-wave devices. replaced by a z-wave stick\nwink hub v1 1 wi-fi wink semi retired, using it as a z-wave repeater for vera. once upon a time i really loved wink, but when you don't stock hardware for almost a year and your buisness model is selling hardware... time for that slow ride to the cloud api in the sky. not to mention the massive outages when staff clock out and don't fix until morning (forget to renew an expired certificate anyone). it was a fun ride wink, hopefully your death will not be to slow and painful, but i.am+ wants to watch the world burn... probably.\nquirky + ge aros smart window air conditioner 1 wi-fi wink climate no longer used after new hvac system installed. cooling effieceny had dropped and was more of an energy hog than actually making a difference in temprature comfort.\nfrigidaire cool connect smart portable air conditioner 1 wi-fi harmony hub remote no longer in daily use after new hvac system installed. may be brought back into service as needed.\nihome wifi smart plug 2 wink hub (wi-fi) wink switch not using these anymore due to overall poor reliability\nfoscam fi9800p 1 wi-fi foscam ip camera replaced by unifi g3 flex\nubiquiti unifi cloud key 1 ethernet ubiquiti unifi wap unifi controller. replaced by cloudkey gen2 plus\nubiquiti uvc-g3 unifi video camera 2 ethernet unifi protect(custom component) 1080p poe camera. replaced with g4 versions\nmyq smart garage door opener 1 wi-fi myq cover got fed up with the sheer disrepect this device had for reliability. would work great for months, then decide it had enough and work when it felt like.\nmyq home bridge 1 wi-fi myq cover see above\ntp-link smart plug hs100 1 wi-fi tp-link switch no longer needed, might re-use at some point\nwink relay 2 wi-fi wink wall mounted touch screen. wink interface was rubbish and was replaced with the home assistant dashboard. it provides binary sensors for the two push buttons, temperature, and humidity sensors. doesn't get used much but looks cool. turns out it was just rubbish and decided to go into an endless reboot loop, on top of the screen already having burn in problems even when not on all the time. retired to the trash can.\nubiquiti networks airgateway lr wireless ap 1 wi-fi na was used to connect ubiquiti uvc-g3 unifi video camera to the wireless network where running an ethernet cable wasn't feasible. connects to poe injector. replaced by mesh ap and switch\nsonos connect 1 ethernet sonos audio playback and home assistant tts. connects sonos to existing surround sound system. now considered a legacy sonos device\nubiquiti networks unifi ap pro (uap-ac-pro-us) 1 ethernet ubiquiti unifi wap wireless access point for interior and exterior use. replaced by the unifi nanohd.\nubiquiti networks unifi ap long range (uap-ac-lr-us) 1 ethernet ubiquiti unifi wap wireless access point for interior use. presence detection for non household members and devices.\ninsignia - wi-fi garage door controller 1 wi-fi homekit controller automated to open / close garage door on location and auto close after specific time intervals\nring video doorbell 1 wi-fi ring / ring binary sensor automated around binary sensors via motion or doorbell button press. replaced with a version 3 plus.\nirobot roomba 650 1 na na currently not integrated into home assistant. investigating options for future integration\nlutron smart bridge 2 1 ethernet lutron caseta replaced with a lutron smart bridge 2 pro\ncreality ender 3 v2 1 wi-fi octoprint 3d printer connected to home assitant via octoprint running on a raspberry pi 3 b+. got tired of messing around with it, i just want to print useless objects with ease\nyamaha rx-v483bl 1 wi-fi yamaha network receivers surround sound receiver. works in conjunction with the sonos connect, harmony hub, apple tv 4k and various other media devices. replaced with sonos arc system\nubiquiti networks unifi nanohd (uap-nanohd-us) 2 ethernet ubiquiti unifi wireless access point for interior and exterior use. presence detection for non household members and devices. replaced by wifi 6 models\nubiquiti networks unifi ap lite (uap-ac-lite) 1 ethernet ubiquiti unifi wireless access point for interior use. presence detection for non household members and devices. replaced by wifi 6 models\nscreenshots\n| go to menu |\n| go to menu |", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000121, "year": null}, {"Unnamed: 0": 142, "autor": 142, "date": null, "content": ".dom\nA tiny (512 byte) virtual DOM template engine for embedded projects\nIE / Edge Firefox Chrome Safari Opera iOS Safari Chrome for Android\nEdge 14+ 45+ 49+ 10+ 37+ 10.2+ 55+\n.dom borrows some concepts from React.js (such as the re-usable Components and the Virtual DOM) and tries to replicate them with the smallest possible footprint, exploiting the ES6 javascript features.\nWhy? Because with such library you can create powerful GUIs in tight space environments, such as IoT devices, where saving even an extra byte actually matters!\nFeatures\nTiny by design : The library should never exceed the 512 bytes in size. The goal is not to have yet another template engine, but to have as many features as possible in 512 bytes. If a new feature is needed, an other must be sacraficed or the scope must be reduced.\nBuilt for the future : The library is heavily exploiting the ES6 specifications, meaning that it's not supported by older browsers. Currently it's supported by the 90% of the browsers in the market, but expect this to be close to 100% within the next year.\nDeclarative : Describe your HTML DOM in a structured, natural manner, helping you create powerful yet readable user interfaces.\nComponent-Oriented : Just like React.js, .dom promotes the use of functional components.\n\"Write less\" accelerators : The library API is designed specifically to have short function names and accelerators, allowing you to describe your views with less code.\nProjects Using .dom\nOpen Graph Image as a Service - demo\nAre you using .dom in your project? Fork this repository and add yours on the list!\nInstallation\nFor minimum footprint, include dotdom.min.js.gz (512b) to your project.\n<script src=\"dotdom.min.js.gz\" />\nAlternatively you can just include the minified version of the library directly before your script. Just copy-paste the minified code.\nExamples\nIf you already know React.js, the following examples can help you understand how the .dom primitives relate to React.\n1. Plain DOM\nRendering a very simple DOM structure.\nReact .dom\nReactDOM.render(\nReact.createElement('div', null, 'Hello world'),\ndocument.body\n);\nR(\nH('div', 'Hello world'),\ndocument.body\n)\n2. Stateless Component\nCreating a component on which you can pass properties.\nReact .dom\nfunction Hello(props) {\nreturn React.createElement(\n'div', null, `Hello ${props.toWhat}`\n);\n}\nReactDOM.render(\nReact.createElement(\nHello, {toWhat: 'World'}, null\n),\ndocument.body\n);\nfunction Hello(props) {\nreturn H('div', `Hello ${props.toWhat}`);\n}\nR(\nH(Hello, {toWhat: 'World'}),\ndocument.body\n)\n3. Stateful Component\nCreating components that can maintain their own state.\nReact .dom\nclass Clickable extends React.Component {\nconstructor() {\nsuper(...arguments);\nthis.state = {\nclicks: 0\n};\n}\nrender() {\nconst {clicks} = this.state;\nreturn React.createElement(\n'button', {\nonClick() {\nthis.setState({clicks: clicks+1})\n}\n}, `Clicked ${clicks} times`\n);\n}\n}\nReactDOM.render(\nReact.createElement('div', null,\nReact.createElement(Clickable, null, null),\nReact.createElement(Clickable, null, null)\n),\ndocument.body\n);\nfunction Clickable(props, state, setState) {\nconst {clicks=0} = state;\nreturn H('button',\n{\nonclick() {\nsetState({clicks: clicks+1})\n}\n},\n`Clicked ${clicks} times`\n);\n}\nR(\nH('div',\nH(Clickable),\nH(Clickable)\n),\ndocument.body\n)\n4. Life-Cycle Component Events\nThe component can also subscribe to life-cycle events:\nReact .dom\nclass WithLifeCycle extends React.Component {\nconstructor() {\nsuper(...arguments);\nthis.state = {\nmounted: \"no\"\n};\n}\ncomponentDidMount() {\nthis.setState({ mounted: \"yes\" })\n}\nrender() {\nconst {mounted} = this.state;\nreturn React.createElement(\n'div', null, `mounted = ${mounted}`\n);\n}\n}\nReactDOM.render(\nReact.createElement('div', null,\nReact.createElement(WithLifeCycle, null, null),\n),\ndocument.body\n);\nfunction WithLifeCycle(props, state, setState, hooks) {\nconst {mounted = \"no\"} = state;\nhooks.m.push(() => {\nsetState({ mounted: \"yes\" })\n});\nreturn H('div',\n`mounted = ${mounted}`\n);\n}\nR(\nH('div', H(WithLifeCycle)),\ndocument.body\n)\n5. Keyed Updates\nKeyed updates is a useful reconciliation feature from React that enables the rendering engine to take smart decisions on which elements to update.\nA particularly useful case is when you are rendering a dynamic list of elements. Since the rendering engine does not understand which element has changed, it ends-up with wrong updates.\nTo solve this issue, the VDOM engines use a key property that uniquely identifies an element in the tree. However .dom solves it, by keeping a copy of the element state in the VDom element instance itself.\nThis means that you don't need any key property, just make sure you return the same VDom instance as before.\nIf you are creating dynamic elements (eg. an array of vdom elements), .dom might have trouble detecting the correct update order.\nReact .dom\nclass Clickable extends React.Component {\nconstructor() {\nsuper(...arguments);\nthis.state = {\nclicks: 0\n};\n}\nrender() {\nconst {clicks} = this.state;\nconst {ket} = this.props;\nreturn React.createElement(\n'button', {\nonClick() {\nthis.setState({clicks: clicks+1})\n}\n}, `clicks=${clicks}, key=${key}`\n);\n}\n}\nconst list = [\"first\", \"second\", \"third\"];\nconst components = list.map(key =>\nReact.createElement(Clickable, {key}, null);\nReactDOM.render(\nReact.createElement('div', null,\ncomponents\n),\ndocument.body\n);\nfunction Clickable(props, state, setState) {\nconst {clicks=0} = state;\nconst {key} = props;\nreturn H('button',\n{\nonclick() {\nsetState({clicks: clicks+1})\n}\n},\n`clicks=${clicks}, key=${key}`\n);\n}\nconst list = [\"first\", \"second\", \"third\"];\nconst components = list.map(key =>\nH(Clickable, {key});\nR(\nH('div', components),\ndocument.body\n)\nNote that the solution above will correctly update the stateful components, even if their order has changed. However, if you want the complete, React-Like functionality that updates individual keys, you can use the Keyed plug-in.\nfunction Container(props, state) {\nconst {components} = props;\n// The function `K` accepts the component state and an array of components that\n// contain the `key` property, and returns the same array of components, with their\n// state correctly manipulated.\nreturn H(\"div\", K(state, components));\n}\n6. Raw (Unreconciled) Nodes\nYou can create raw (unreconciled) VDom nodes (eg. that carry an arbitrary HTML content) by setting the .r property of the hooks object to any truthy value.\nThis will disable further reconciliation to the child nodes, and therefore keep your contents intact.\nfunction Description(props, state, setState, hooks) {\nconst { html } = props;\nhooks.r = 1; // Enable raw mode\nreturn H('div', {\ninnerHTML: html\n})\n}\nAPI Reference\nRender R( VNode, DOMElement )\nR( H('div', 'Hello'), document.body )\nRenders the given VNode tree to the given DOM element. Further updates from stateful components will only occur on their immediate children.\nCreate Element H( tagName | function, [properties], [children ...])\nH( 'tag' )\nH( 'tag', {prop: \"value\"})\nH( 'tag', H( 'child' ))\nH( 'tag', {prop: \"value\"}, H( 'child' ))\nH( Component, {prop: \"value\"} )\nCreates a VNode element. If a string is passed as the first argument, it will create a HTML element. If a function is given, it will create a stateful component.\nProperties and children are optional and they can be omitted.\nFunctional Components\nInstead of a tag name you can provide a function that returns a Virtual DOM according to some higher-level logic. Such function have the following signature:\nconst Component = (props, state, setState, hooks) {\n// Return your Virtual DOM\nreturn div( ... )\n}\nThe props property contains the properties object as given when the component was created.\nThe state is initialized to an empty object {} and it's updated by calling the setState({ newState }) method. The latter will also trigger an update to the component and it's children.\nYou can also assign properties to the state object directly if you don't want to cause an update.\nThe hooks object can be used when you want to register handlers to the component life-cycle methods.\nComponent Life-Cycle\nSimilar to React, the .dom components have a life-cycle:\nThey are mounted when their root DOM element is placed on the document.\nThey are unmounted when their root DOM element is removed from the document.\nThe yare updated when the state, the properties, or the rendered DOM has changed.\nTo access the life-cycle methods you need to use the fourth argument on your component function. More specifically you have to push your handling function in either of the following fields:\nconst Component = (props, state, setState, hooks) {\nhooks.m.push((domElement) => {\n// '.m' is called when the component is mounted\n});\nhooks.u.push(() => {\n// `.u` is called when the component is unmounted\n});\nhooks.d.push((domElement, previousDomElement) => {\n// `.d` is called when the component is updated\n});\n...\n}\nTag Shorthand tag( [properties], [children ...] )\nconst {div, span, a} = H;\ndiv( 'hello', span( 'world' ) )\ndiv( 'click', a({href: '#'}, 'Here'), 'to continue')\nA shorthand function can be extracted as a property from the H function. Such shorthands behave exactly like H, but with the tag name already populated.\nIt's recommended to use a deconstructuring assignment in the beginning of your script in order to help javascript minifiers further optimize the result:\nconst {div, span, a, button} = H;\nTag + Class Shorthand tag.class( [properties], [children ...] )\nconst {h1, span, p} = H;\nh1.short( 'short header', span.strong( 'strong text' ) )\nbutton.primary({onclick: handleClick}, 'Primary Action')\np.bold.italic( twitterPost )\nInstead of providing the className as a property, you can use the .className shorthand in combination with the shorthand tag methods.\nThis is the same as calling div({className: 'className'}) and the function interface is exactly the same as above.\nNote: You can add more than one class by concatenating more than one .class to the tag. For example: div.foo.bar is the same as div({className: 'foo bar'}).\nCaveats\nSince the project's focus is the small size, it is lacking sanity checks. This makes it susceptible to errors. Be very careful with the following caveats:\nYou cannot trigger an update with a property removal. You must set the new property to an empty value instead. For example:\n// Wrong\nR(div({className: 'foo'}), document.body);\nR(div({}), document.body);\n// Correct\nR(div({className: 'foo'}), document.body);\nR(div({className: ''}), document.body);\nYou must never use a property named $ in your components. Doing so, will make the property object to be considered as a Virtual DOM Node and will lead to unexpected results.\n// *NEVER* do this!\nR(H(MyComponent, {$: 'Foo'}), document.body)\nPlugin Reference\nKeyed Update List K(state, components)\nIn plugin-keyed.min.js\nEnsures the state of the components in the list is synchronized, according to their key property. This enables you to do react-like keyed updates like so:\nfunction ValueRenderer(...) {\n...\n}\nfunction MyComponent(props, state) {\nconst { values } = props;\nconst components = values.map(value => {\nH(ValueRenderer, {\nkey: value,\nvalue: value\n});\n})\n// Synchronize state of components, based on their key\nreturn H('div', K(state, components))\n}\nContribution\nAre you interested in contributing to .dom? You are more than welcome! Just be sure to follow the guidelines:\nInstall a local development environment (you will need node.js 6.x or later)\nnpm install\nAlways run the following when you think you are ready for a pull request:\nnpm test && npm run build && ls -l dotdom.min.js.gz\nIf tests pass and the size of dotdom.min.js.gz is smaller than or equal to 512 bytes, create a pull request. Otherwise reduce your scope or think of another implementation in order to bring it back down to 512 bytes.\nMake sure to properly comments your code, since you will most probably have to do some extreme javascript hacking. The gudeliens are the following:\n/**\n* Functions are commented as JSDoc blocks\n*\n* @param {VNode|Array<VNode>} vnodes - The node on an array of nodes to render\n* ...\n*/\nglobal.R = render = (\nvnodes, // Flat-code comments start on column 70 and\ndom, // wrap after column 120.\n/* Logical separations can be commented like this */\n...\nLicense\nLicensed under the Apache License, Version 2.0", "link": "https://github.com/wavesoft/dot-dom", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": ".dom\na tiny (512 byte) virtual dom template engine for embedded projects\nie / edge firefox chrome safari opera ios safari chrome for android\nedge 14+ 45+ 49+ 10+ 37+ 10.2+ 55+\n.dom borrows some concepts from react.js (such as the re-usable components and the virtual dom) and tries to replicate them with the smallest possible footprint, exploiting the es6 javascript features.\nwhy? because with such library you can create powerful guis in tight space environments, such as iot devices, where saving even an extra byte actually matters!\nfeatures\ntiny by design : the library should never exceed the 512 bytes in size. the goal is not to have yet another template engine, but to have as many features as possible in 512 bytes. if a new feature is needed, an other must be sacraficed or the scope must be reduced.\nbuilt for the future : the library is heavily exploiting the es6 specifications, meaning that it's not supported by older browsers. currently it's supported by the 90% of the browsers in the market, but expect this to be close to 100% within the next year.\ndeclarative : describe your html dom in a structured, natural manner, helping you create powerful yet readable user interfaces.\ncomponent-oriented : just like react.js, .dom promotes the use of functional components.\n\"write less\" accelerators : the library api is designed specifically to have short function names and accelerators, allowing you to describe your views with less code.\nprojects using .dom\nopen graph image as a service - demo\nare you using .dom in your project? fork this repository and add yours on the list!\ninstallation\nfor minimum footprint, include dotdom.min.js.gz (512b) to your project.\n<script src=\"dotdom.min.js.gz\" />\nalternatively you can just include the minified version of the library directly before your script. just copy-paste the minified code.\nexamples\nif you already know react.js, the following examples can help you understand how the .dom primitives relate to react.\n1. plain dom\nrendering a very simple dom structure.\nreact .dom\nreactdom.render(\nreact.createelement('div', null, 'hello world'),\ndocument.body\n);\nr(\nh('div', 'hello world'),\ndocument.body\n)\n2. stateless component\ncreating a component on which you can pass properties.\nreact .dom\nfunction hello(props) {\nreturn react.createelement(\n'div', null, `hello ${props.towhat}`\n);\n}\nreactdom.render(\nreact.createelement(\nhello, {towhat: 'world'}, null\n),\ndocument.body\n);\nfunction hello(props) {\nreturn h('div', `hello ${props.towhat}`);\n}\nr(\nh(hello, {towhat: 'world'}),\ndocument.body\n)\n3. stateful component\ncreating components that can maintain their own state.\nreact .dom\nclass clickable extends react.component {\nconstructor() {\nsuper(...arguments);\nthis.state = {\nclicks: 0\n};\n}\nrender() {\nconst {clicks} = this.state;\nreturn react.createelement(\n'button', {\nonclick() {\nthis.setstate({clicks: clicks+1})\n}\n}, `clicked ${clicks} times`\n);\n}\n}\nreactdom.render(\nreact.createelement('div', null,\nreact.createelement(clickable, null, null),\nreact.createelement(clickable, null, null)\n),\ndocument.body\n);\nfunction clickable(props, state, setstate) {\nconst {clicks=0} = state;\nreturn h('button',\n{\nonclick() {\nsetstate({clicks: clicks+1})\n}\n},\n`clicked ${clicks} times`\n);\n}\nr(\nh('div',\nh(clickable),\nh(clickable)\n),\ndocument.body\n)\n4. life-cycle component events\nthe component can also subscribe to life-cycle events:\nreact .dom\nclass withlifecycle extends react.component {\nconstructor() {\nsuper(...arguments);\nthis.state = {\nmounted: \"no\"\n};\n}\ncomponentdidmount() {\nthis.setstate({ mounted: \"yes\" })\n}\nrender() {\nconst {mounted} = this.state;\nreturn react.createelement(\n'div', null, `mounted = ${mounted}`\n);\n}\n}\nreactdom.render(\nreact.createelement('div', null,\nreact.createelement(withlifecycle, null, null),\n),\ndocument.body\n);\nfunction withlifecycle(props, state, setstate, hooks) {\nconst {mounted = \"no\"} = state;\nhooks.m.push(() => {\nsetstate({ mounted: \"yes\" })\n});\nreturn h('div',\n`mounted = ${mounted}`\n);\n}\nr(\nh('div', h(withlifecycle)),\ndocument.body\n)\n5. keyed updates\nkeyed updates is a useful reconciliation feature from react that enables the rendering engine to take smart decisions on which elements to update.\na particularly useful case is when you are rendering a dynamic list of elements. since the rendering engine does not understand which element has changed, it ends-up with wrong updates.\nto solve this issue, the vdom engines use a key property that uniquely identifies an element in the -----> tree !!! . however .dom solves it, by keeping a copy of the element state in the vdom element instance itself.\nthis means that you don't need any key property, just make sure you return the same vdom instance as before.\nif you are creating dynamic elements (eg. an array of vdom elements), .dom might have trouble detecting the correct update order.\nreact .dom\nclass clickable extends react.component {\nconstructor() {\nsuper(...arguments);\nthis.state = {\nclicks: 0\n};\n}\nrender() {\nconst {clicks} = this.state;\nconst {ket} = this.props;\nreturn react.createelement(\n'button', {\nonclick() {\nthis.setstate({clicks: clicks+1})\n}\n}, `clicks=${clicks}, key=${key}`\n);\n}\n}\nconst list = [\"first\", \"second\", \"third\"];\nconst components = list.map(key =>\nreact.createelement(clickable, {key}, null);\nreactdom.render(\nreact.createelement('div', null,\ncomponents\n),\ndocument.body\n);\nfunction clickable(props, state, setstate) {\nconst {clicks=0} = state;\nconst {key} = props;\nreturn h('button',\n{\nonclick() {\nsetstate({clicks: clicks+1})\n}\n},\n`clicks=${clicks}, key=${key}`\n);\n}\nconst list = [\"first\", \"second\", \"third\"];\nconst components = list.map(key =>\nh(clickable, {key});\nr(\nh('div', components),\ndocument.body\n)\nnote that the solution above will correctly update the stateful components, even if their order has changed. however, if you want the complete, react-like functionality that updates individual keys, you can use the keyed plug-in.\nfunction container(props, state) {\nconst {components} = props;\n// the function `k` accepts the component state and an array of components that\n// contain the `key` property, and returns the same array of components, with their\n// state correctly manipulated.\nreturn h(\"div\", k(state, components));\n}\n6. raw (unreconciled) nodes\nyou can create raw (unreconciled) vdom nodes (eg. that carry an arbitrary html content) by setting the .r property of the hooks object to any truthy value.\nthis will disable further reconciliation to the child nodes, and therefore keep your contents intact.\nfunction description(props, state, setstate, hooks) {\nconst { html } = props;\nhooks.r = 1; // enable raw mode\nreturn h('div', {\ninnerhtml: html\n})\n}\napi reference\nrender r( vnode, domelement )\nr( h('div', 'hello'), document.body )\nrenders the given vnode tree to the given dom element. further updates from stateful components will only occur on their immediate children.\ncreate element h( tagname | function, [properties], [children ...])\nh( 'tag' )\nh( 'tag', {prop: \"value\"})\nh( 'tag', h( 'child' ))\nh( 'tag', {prop: \"value\"}, h( 'child' ))\nh( component, {prop: \"value\"} )\ncreates a vnode element. if a string is passed as the first argument, it will create a html element. if a function is given, it will create a stateful component.\nproperties and children are optional and they can be omitted.\nfunctional components\ninstead of a tag name you can provide a function that returns a virtual dom according to some higher-level logic. such function have the following signature:\nconst component = (props, state, setstate, hooks) {\n// return your virtual dom\nreturn div( ... )\n}\nthe props property contains the properties object as given when the component was created.\nthe state is initialized to an empty object {} and it's updated by calling the setstate({ newstate }) method. the latter will also trigger an update to the component and it's children.\nyou can also assign properties to the state object directly if you don't want to cause an update.\nthe hooks object can be used when you want to register handlers to the component life-cycle methods.\ncomponent life-cycle\nsimilar to react, the .dom components have a life-cycle:\nthey are mounted when their root dom element is placed on the document.\nthey are unmounted when their root dom element is removed from the document.\nthe yare updated when the state, the properties, or the rendered dom has changed.\nto access the life-cycle methods you need to use the fourth argument on your component function. more specifically you have to push your handling function in either of the following fields:\nconst component = (props, state, setstate, hooks) {\nhooks.m.push((domelement) => {\n// '.m' is called when the component is mounted\n});\nhooks.u.push(() => {\n// `.u` is called when the component is unmounted\n});\nhooks.d.push((domelement, previousdomelement) => {\n// `.d` is called when the component is updated\n});\n...\n}\ntag shorthand tag( [properties], [children ...] )\nconst {div, span, a} = h;\ndiv( 'hello', span( 'world' ) )\ndiv( 'click', a({href: '#'}, 'here'), 'to continue')\na shorthand function can be extracted as a property from the h function. such shorthands behave exactly like h, but with the tag name already populated.\nit's recommended to use a deconstructuring assignment in the beginning of your script in order to help javascript minifiers further optimize the result:\nconst {div, span, a, button} = h;\ntag + class shorthand tag.class( [properties], [children ...] )\nconst {h1, span, p} = h;\nh1.short( 'short header', span.strong( 'strong text' ) )\nbutton.primary({onclick: handleclick}, 'primary action')\np.bold.italic( twitterpost )\ninstead of providing the classname as a property, you can use the .classname shorthand in combination with the shorthand tag methods.\nthis is the same as calling div({classname: 'classname'}) and the function interface is exactly the same as above.\nnote: you can add more than one class by concatenating more than one .class to the tag. for example: div.foo.bar is the same as div({classname: 'foo bar'}).\ncaveats\nsince the project's focus is the small size, it is lacking sanity checks. this makes it susceptible to errors. be very careful with the following caveats:\nyou cannot trigger an update with a property removal. you must set the new property to an empty value instead. for example:\n// wrong\nr(div({classname: 'foo'}), document.body);\nr(div({}), document.body);\n// correct\nr(div({classname: 'foo'}), document.body);\nr(div({classname: ''}), document.body);\nyou must never use a property named $ in your components. doing so, will make the property object to be considered as a virtual dom node and will lead to unexpected results.\n// *never* do this!\nr(h(mycomponent, {$: 'foo'}), document.body)\nplugin reference\nkeyed update list k(state, components)\nin plugin-keyed.min.js\nensures the state of the components in the list is synchronized, according to their key property. this enables you to do react-like keyed updates like so:\nfunction valuerenderer(...) {\n...\n}\nfunction mycomponent(props, state) {\nconst { values } = props;\nconst components = values.map(value => {\nh(valuerenderer, {\nkey: value,\nvalue: value\n});\n})\n// synchronize state of components, based on their key\nreturn h('div', k(state, components))\n}\ncontribution\nare you interested in contributing to .dom? you are more than welcome! just be sure to follow the guidelines:\ninstall a local development environment (you will need node.js 6.x or later)\nnpm install\nalways run the following when you think you are ready for a pull request:\nnpm test && npm run build && ls -l dotdom.min.js.gz\nif tests pass and the size of dotdom.min.js.gz is smaller than or equal to 512 bytes, create a pull request. otherwise reduce your scope or think of another implementation in order to bring it back down to 512 bytes.\nmake sure to properly comments your code, since you will most probably have to do some extreme javascript hacking. the gudeliens are the following:\n/**\n* functions are commented as jsdoc blocks\n*\n* @param {vnode|array<vnode>} vnodes - the node on an array of nodes to render\n* ...\n*/\nglobal.r = render = (\nvnodes, // flat-code comments start on column 70 and\ndom, // wrap after column 120.\n/* logical separations can be commented like this */\n...\nlicense\nlicensed under the apache license, version 2.0", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000142, "year": null}, {"Unnamed: 0": 159, "autor": 159, "date": null, "content": "The Pycopy project\nWeb site | Documentation\nPycopy aims to develop and maintain a minimalist, lightweight, and extensible implementation of Python(-compatible) language. Pycopy to CPython is a similar thing as Scheme to Common Lisp. Pycopy works similarly well in the cloud, on desktop systems, on small embedded systems, and scales all the way down to microcontrollers. The project is developed and maintained by Paul Sokolovsky and is originally based on MicroPython, developed by Damien George, Paul Sokolovsky and contributors. Names \"Pycopy\" and \"MicroPython\" are used interchangeably in the project documentation and source code.\nWARNING: this project is in beta stage and is subject to changes of the code-base, including project-wide name changes and API changes.\nPycopy implements the entire Python 3.4 syntax (including exceptions, with, yield from, etc., and additionally async/await keywords from Python 3.5). The following core datatypes are provided: str (including basic Unicode support), bytes, bytearray, tuple, list, dict, set, frozenset, array.array, collections.namedtuple, classes and instances. Builtin modules include sys, time, and struct, etc. Select ports have support for _thread module (multithreading). Note that only a subset of Python 3 functionality is implemented for the data types and modules.\nPycopy can execute scripts in textual source form or from precompiled bytecode, in both cases either from an on-device filesystem or \"frozen\" into the executable.\nPycopy is highly portable, and the main repository includes support for POSIX operating systems (Linux, MacOSX, FreeBSD, etc.), Windows, Android, and a number of bare-metal microcontroller systems (see below). Ports to other systems can be implemented easily. POSIX port (nicknamed \"Unix port\") is the reference port of Pycopy.\nThe Pycopy Zen\nJust as \"big Python\", Pycopy has its \"Zen\". The main principles of Pycopy are simplicity, minimalism, and light-weightedness.\nAt the same time, Pycopy strives to be a full-stack language and be compatible with wider Python ecosystem. The Pycopy project resolves these seemingly conflicting goals in a well-known and elegant way: by being a multi-level project, and by providing flexible configuration options. Specifically, there's a well-defined lightweight core written in C, defining the \"native Pycopy language\". Above it, a number of options are provided, implementing additional functionality (oftentimes offering more CPython compatibility). For example, on top of the core, \"native Pycopy builtin modules\" are provided, defining the native Pycopy API, which provides a subset of CPython's modules functionality, and at the same time, some extensions to it (driven by Pycopy's goal to be efficient). These native Pycopy modules are clearly namespaced, to allow to implement modules fully compatible with CPython API without any changes to the main project.\nOn top of this primary project, there are separate projects to further extend Pycopy functionality and achieve full-stack ecosystem. For example, there's a pycopy-lib project (see below) to implement a fully compatible CPython standard library for Pycopy.\nFinally, on top of that infrastructure, there is an ecosystem of third-party packages, which are managed by the Pycopy users themselves.\nThe art of working with Pycopy is to understand where a particular feature belongs. Just as with CPython, it's almost never the core project, and almost always users' third party packages.\nContributors' Guidelines further elaborate on some points touched above.\nSource tree layout\nMajor components in this repository:\npy/ -- the core Python implementation, including compiler, runtime, and core library.\nmpy-cross/ -- the bytecode (cross)compiler which is used to turn scripts into precompiled bytecode.\nports/unix/ -- a version of Pycopy that runs on Unix (which includes Android).\nports/windows/ -- a version for Windows.\nports/stm32/ -- a version of Pycopy that runs on the PyBoard and similar STM32 boards (using ST's Cube HAL drivers).\nports/minimal/ -- a minimal port. Start with this if you want to port the project to another microcontroller.\ntests/ -- test framework and test scripts.\ndocs/ -- user documentation in Sphinx reStructuredText format. Rendered HTML documentation is available at http://pycopy.readthedocs.io/ .\nAdditional components:\nports/bare-arm/ -- a bare minimum version for ARM MCUs. Used mostly to control code size.\nports/teensy/ -- a version that runs on the Teensy 3.1 (preliminary but functional).\nports/pic16bit/ -- a version for 16-bit PIC microcontrollers.\nports/cc3200/ -- a version that runs on the CC3200 from TI.\nports/esp8266/ -- a version that runs on Espressif's ESP8266 SoC.\nports/esp32/ -- a version that runs on Espressif's ESP32 SoC.\nports/nrf/ -- a version that runs on Nordic's nRF51 and nRF52 MCUs.\nextmod/ -- additional (non-core) modules implemented in C.\ntools/ -- various tools, including the pyboard.py module.\nexamples/ -- various example scripts.\nThe subdirectories above may include READMEs with additional info.\n\"make\" is used to build the components, or \"gmake\" on BSD-based systems. You will also need bash, gcc, and Python 3.3+ available as the command python3 (if your system only has Python 2.7 then invoke make with the additional option PYTHON=python2).\nThe cross-compiler, pycopy-cross\nMost ports require the Pycopy cross-compiler to be built first. This program, called pycopy-cross, is used to pre-compile Python scripts to .mpy files which can then be included (frozen) into the firmware/executable for a port. To build pycopy-cross use:\n$ cd mpy-cross\n$ make\nThe Unix version\nThe \"unix\" port requires a standard Unix environment with gcc and GNU make. x86 and x64 architectures are supported (i.e. x86 32- and 64-bit), as well as ARM and MIPS. Making full-featured port to another architecture requires writing some assembly code for the exception handling and garbage collection. Alternatively, fallback implementation based on setjmp/longjmp can be used.\nTo build (see section below for required dependencies):\n$ make -C mpy-cross\n$ cd ports/unix\n$ make submodules\n$ make\nThen to give it a try:\n$ ./pycopy\n>>> list(5 * x + y for x in range(10) for y in [4, 2, 1])\nUse CTRL-D (i.e. EOF) to exit the shell. Learn about command-line options (in particular, how to increase heap size which may be needed for larger applications):\n$ ./pycopy --help\nRun complete testsuite:\n$ make test\nUnix version comes with a builtin package manager called upip, e.g.:\n$ ./pycopy -m upip install pycopy-pystone\n$ ./pycopy -m pystone\nBrowse available modules on PyPI. Standard library modules come from pycopy-lib project.\npycopy executable built following the instructions above is a \"production\" executable for native Pycopy software. It's also possible to build pycop-dev executable which provides additional reflection, diagnostics, and extensibility capabilities, at the expense of code size and memory usage efficiency. In particular, pycopy-dev is more compatible with software written for CPython. To build the pycopy-dev variant, run make dev.\nExternal dependencies\nBuilding Pycopy ports may require some dependencies installed.\nFor Unix port, libffi library and pkg-config tool are required. On Debian/Ubuntu/Mint derivative Linux distros, install build-essential (includes toolchain and make), libffi-dev, and pkg-config packages.\nOther dependencies can be built together with Pycopy. This may be required to enable extra features or capabilities, and in recent versions, these may be enabled by default. To build these additional dependencies, first fetch git submodules for them:\n$ make submodules\nThis will fetch all the relevant git submodules (sub repositories) that the port needs. Use the same command to get the latest versions of submodules as they are updated from time to time. After that execute:\n$ make deplibs\nThis will build all available dependencies (regardless whether they are used or not). If you intend to build Pycopy with additional options (like cross-compiling), the same set of options should be passed to make deplibs. To actually enable/disable use of dependencies, edit ports/unix/mpconfigport.mk file, which has inline descriptions of the options. For example, to build SSL module (required for upip tool described above, and so enabled by default), MICROPY_PY_USSL should be set to 1.\nFor some ports, building required dependences is transparent, and happens automatically. But they still need to be fetched with the make submodules command.\nContributing\nPycopy is an open-source project and welcomes contributions which are aligned with its paradigm and work process. To be productive, please be sure to follow the Contributors' Guidelines and the Code Conventions. Note that Pycopy is licenced under the MIT license, and all contributions should follow this license.\nProject FAQ\nQ: How Pycopy differs from other Python implementations?\nA: Pycopy is intended to be a small, minimalist implementation of the \"core of the Python language\" (in some definition of the \"core\"). Beyond that, the aim is to be extensible, to be able to support features of other Python implementations. Pycopy is particularly intended to write software (and extensions just mentioned) in Python. This may sounds as oxymoron, but it's a matter of fact that other implementations have too much of their functionality implemented in other languages (e.g., in C for CPython). This is a discouraged approach for Pycopy. Instead, for interfacing with non-Python libraries, it encourages the use of FFI (Foreign Function Interface) and flexible import extensions.\nQ: How Pycopy differs from other small Python implementations?\nA: Please see previous question for general information on how Pycopy differs from other Python implementations. Regarding small Python implementations specifically, a common issue with them is that they structure and represent themselves as niche, special-purpose systems, and oftentimes implement very bare subset of Python. Pycopy isn't just \"Python for microcontrollers\" or \"Python to embed in other application\". First and foremost, Pycopy is a general, and general-purpose, language, suitable for developing any kind of software. Which can be even used on microcontrollers and embedded in other applications (without growing them too much), but it's not limited to that in any way. Pycopy strives to cover as many systems as possible - from clouds down to tiny IoT devices. And project's attention and focus is also shared among them according to the functionality and value particular areas may offer. For example, microcontrollers are neat cute things, but you can do only so much with them, so they represent maybe 20% of the project focus.\nQ: Current focus of the project?\nA:\nCode optimizations.\nContinue to develop inplace, buffer and stream operations allowing to write highly memory effiicient applications.\nGarbage collection experiments.\nReflection features (ultimately allowing to develop optimizing compilers, etc. in Python).\nMore CPython features implemented (configurable).\n\"Development/Testing\" version with improved program analysis features.\netc.", "link": "https://github.com/pfalcon/pycopy", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "the pycopy project\nweb site | documentation\npycopy aims to develop and maintain a minimalist, lightweight, and extensible implementation of python(-compatible) language. pycopy to cpython is a similar thing as scheme to common lisp. pycopy works similarly well in the cloud, on desktop systems, on small embedded systems, and scales all the way down to microcontrollers. the project is developed and maintained by paul sokolovsky and is originally based on micropython, developed by damien george, paul sokolovsky and contributors. names \"pycopy\" and \"micropython\" are used interchangeably in the project documentation and source code.\nwarning: this project is in beta stage and is subject to changes of the code-base, including project-wide name changes and api changes.\npycopy implements the entire python 3.4 syntax (including exceptions, with, yield from, etc., and additionally async/await keywords from python 3.5). the following core datatypes are provided: str (including basic unicode support), bytes, bytearray, tuple, list, dict, set, frozenset, array.array, collections.namedtuple, classes and instances. builtin modules include sys, time, and struct, etc. select ports have support for _thread module (multithreading). note that only a subset of python 3 functionality is implemented for the data types and modules.\npycopy can execute scripts in textual source form or from precompiled bytecode, in both cases either from an on-device filesystem or \"frozen\" into the executable.\npycopy is highly portable, and the main repository includes support for posix operating systems (linux, macosx, freebsd, etc.), windows, android, and a number of bare-metal microcontroller systems (see below). ports to other systems can be implemented easily. posix port (nicknamed \"unix port\") is the reference port of pycopy.\nthe pycopy zen\njust as \"big python\", pycopy has its \"zen\". the main principles of pycopy are simplicity, minimalism, and light-weightedness.\nat the same time, pycopy strives to be a full-stack language and be compatible with wider python ecosystem. the pycopy project resolves these seemingly conflicting goals in a well-known and elegant way: by being a multi-level project, and by providing flexible configuration options. specifically, there's a well-defined lightweight core written in c, defining the \"native pycopy language\". above it, a number of options are provided, implementing additional functionality (oftentimes offering more cpython compatibility). for example, on top of the core, \"native pycopy builtin modules\" are provided, defining the native pycopy api, which provides a subset of cpython's modules functionality, and at the same time, some extensions to it (driven by pycopy's goal to be efficient). these native pycopy modules are clearly namespaced, to allow to implement modules fully compatible with cpython api without any changes to the main project.\non top of this primary project, there are separate projects to further extend pycopy functionality and achieve full-stack ecosystem. for example, there's a pycopy-lib project (see below) to implement a fully compatible cpython standard library for pycopy.\nfinally, on top of that infrastructure, there is an ecosystem of third-party packages, which are managed by the pycopy users themselves.\nthe art of working with pycopy is to understand where a particular feature belongs. just as with cpython, it's almost never the core project, and almost always users' third party packages.\ncontributors' guidelines further elaborate on some points touched above.\nsource -----> tree !!!  layout\nmajor components in this repository:\npy/ -- the core python implementation, including compiler, runtime, and core library.\nmpy-cross/ -- the bytecode (cross)compiler which is used to turn scripts into precompiled bytecode.\nports/unix/ -- a version of pycopy that runs on unix (which includes android).\nports/windows/ -- a version for windows.\nports/stm32/ -- a version of pycopy that runs on the pyboard and similar stm32 boards (using st's cube hal drivers).\nports/minimal/ -- a minimal port. start with this if you want to port the project to another microcontroller.\ntests/ -- test framework and test scripts.\ndocs/ -- user documentation in sphinx restructuredtext format. rendered html documentation is available at http://pycopy.readthedocs.io/ .\nadditional components:\nports/bare-arm/ -- a bare minimum version for arm mcus. used mostly to control code size.\nports/teensy/ -- a version that runs on the teensy 3.1 (preliminary but functional).\nports/pic16bit/ -- a version for 16-bit pic microcontrollers.\nports/cc3200/ -- a version that runs on the cc3200 from ti.\nports/esp8266/ -- a version that runs on espressif's esp8266 soc.\nports/esp32/ -- a version that runs on espressif's esp32 soc.\nports/nrf/ -- a version that runs on nordic's nrf51 and nrf52 mcus.\nextmod/ -- additional (non-core) modules implemented in c.\ntools/ -- various tools, including the pyboard.py module.\nexamples/ -- various example scripts.\nthe subdirectories above may include readmes with additional info.\n\"make\" is used to build the components, or \"gmake\" on bsd-based systems. you will also need bash, gcc, and python 3.3+ available as the command python3 (if your system only has python 2.7 then invoke make with the additional option python=python2).\nthe cross-compiler, pycopy-cross\nmost ports require the pycopy cross-compiler to be built first. this program, called pycopy-cross, is used to pre-compile python scripts to .mpy files which can then be included (frozen) into the firmware/executable for a port. to build pycopy-cross use:\n$ cd mpy-cross\n$ make\nthe unix version\nthe \"unix\" port requires a standard unix environment with gcc and gnu make. x86 and x64 architectures are supported (i.e. x86 32- and 64-bit), as well as arm and mips. making full-featured port to another architecture requires writing some assembly code for the exception handling and garbage collection. alternatively, fallback implementation based on setjmp/longjmp can be used.\nto build (see section below for required dependencies):\n$ make -c mpy-cross\n$ cd ports/unix\n$ make submodules\n$ make\nthen to give it a try:\n$ ./pycopy\n>>> list(5 * x + y for x in range(10) for y in [4, 2, 1])\nuse ctrl-d (i.e. eof) to exit the shell. learn about command-line options (in particular, how to increase heap size which may be needed for larger applications):\n$ ./pycopy --help\nrun complete testsuite:\n$ make test\nunix version comes with a builtin package manager called upip, e.g.:\n$ ./pycopy -m upip install pycopy-pystone\n$ ./pycopy -m pystone\nbrowse available modules on pypi. standard library modules come from pycopy-lib project.\npycopy executable built following the instructions above is a \"production\" executable for native pycopy software. it's also possible to build pycop-dev executable which provides additional reflection, diagnostics, and extensibility capabilities, at the expense of code size and memory usage efficiency. in particular, pycopy-dev is more compatible with software written for cpython. to build the pycopy-dev variant, run make dev.\nexternal dependencies\nbuilding pycopy ports may require some dependencies installed.\nfor unix port, libffi library and pkg-config tool are required. on debian/ubuntu/mint derivative linux distros, install build-essential (includes toolchain and make), libffi-dev, and pkg-config packages.\nother dependencies can be built together with pycopy. this may be required to enable extra features or capabilities, and in recent versions, these may be enabled by default. to build these additional dependencies, first fetch git submodules for them:\n$ make submodules\nthis will fetch all the relevant git submodules (sub repositories) that the port needs. use the same command to get the latest versions of submodules as they are updated from time to time. after that execute:\n$ make deplibs\nthis will build all available dependencies (regardless whether they are used or not). if you intend to build pycopy with additional options (like cross-compiling), the same set of options should be passed to make deplibs. to actually enable/disable use of dependencies, edit ports/unix/mpconfigport.mk file, which has inline descriptions of the options. for example, to build ssl module (required for upip tool described above, and so enabled by default), micropy_py_ussl should be set to 1.\nfor some ports, building required dependences is transparent, and happens automatically. but they still need to be fetched with the make submodules command.\ncontributing\npycopy is an open-source project and welcomes contributions which are aligned with its paradigm and work process. to be productive, please be sure to follow the contributors' guidelines and the code conventions. note that pycopy is licenced under the mit license, and all contributions should follow this license.\nproject faq\nq: how pycopy differs from other python implementations?\na: pycopy is intended to be a small, minimalist implementation of the \"core of the python language\" (in some definition of the \"core\"). beyond that, the aim is to be extensible, to be able to support features of other python implementations. pycopy is particularly intended to write software (and extensions just mentioned) in python. this may sounds as oxymoron, but it's a matter of fact that other implementations have too much of their functionality implemented in other languages (e.g., in c for cpython). this is a discouraged approach for pycopy. instead, for interfacing with non-python libraries, it encourages the use of ffi (foreign function interface) and flexible import extensions.\nq: how pycopy differs from other small python implementations?\na: please see previous question for general information on how pycopy differs from other python implementations. regarding small python implementations specifically, a common issue with them is that they structure and represent themselves as niche, special-purpose systems, and oftentimes implement very bare subset of python. pycopy isn't just \"python for microcontrollers\" or \"python to embed in other application\". first and foremost, pycopy is a general, and general-purpose, language, suitable for developing any kind of software. which can be even used on microcontrollers and embedded in other applications (without growing them too much), but it's not limited to that in any way. pycopy strives to cover as many systems as possible - from clouds down to tiny iot devices. and project's attention and focus is also shared among them according to the functionality and value particular areas may offer. for example, microcontrollers are neat cute things, but you can do only so much with them, so they represent maybe 20% of the project focus.\nq: current focus of the project?\na:\ncode optimizations.\ncontinue to develop inplace, buffer and stream operations allowing to write highly memory effiicient applications.\ngarbage collection experiments.\nreflection features (ultimately allowing to develop optimizing compilers, etc. in python).\nmore cpython features implemented (configurable).\n\"development/testing\" version with improved program analysis features.\netc.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000159, "year": null}, {"Unnamed: 0": 239, "autor": 239, "date": null, "content": "EMUX (formerly ARMX) Firmware Emulation Framework\nby Saumil Shah @therealsaumil\nOctober 2021\nWelcome, MIPS!\nWith the addition of MIPS, ARMX has changed its name to EMUX! Try out the Damn Vulnerable MIPS Router exercises included with the new EMUX Docker image.\nA brand new Docker container running EMUX. Going ahead, all official EMUX releases shall be released as Docker images. Lightweight, Compact, Easy.\nShut up and give me the g00diez\nGithub: https://github.com/therealsaumil/emux\nA brand new EMUX Docker image is ready for use! The old \"Preview VM\" is now discontinued in favour of the Docker image.\nQUICK INSTALL STEPS\nStep 1 - Clone this repository\ngit clone --depth 1 --single-branch https://github.com/therealsaumil/emux.git\nStep 2 - Build the docker volume and image\ncd emux\n./build-emux-volume\n./build-emux-docker\nStep 3 - Run EMUX!\nOpen a terminal, and start the emux-docker container:\n./run-emux-docker\nYou will be greeted with a purple shell prompt [EMUX-DOCKER \ud83d\udc33:~$]. After a while, it is common to have many terminals attached to the container. Coloured shell prompts makes it easy to remember where you are.\nNext, start the EMUX launcher:\n[EMUX-DOCKER \ud83d\udc33:~$] launcher\nand select any emulated device that you wish to run.\nStep 4 - Launch the emulated device's userland processes.\nNext, open a new terminal and attach to the running emux-docker container:\n./emux-docker-shell\nAll attached container shells have a blue shell prompt. Invoke the userspace command to bring up the userland processes of the emulated target:\n[emux-docker shell \ud83d\udc1a:~$] userspace\nRead the documentation for more details.\nINTRODUCING\nThe EMUX Firmware Emulation Framework is a collection of scripts, kernels and filesystems to be used with QEMU to emulate ARM and MIPS Linux IoT devices. EMUX is aimed to facilitate IoT research by virtualising as much of the physical device as possible. It is the closest we can get to an actual IoT VM.\nDevices successfully emulated with EMUX so far:\nDamn Vulnerable ARM Router\nDamn Vulnerable MIPS Router (Little Endian) [NEW!]\nDamn Vulnerable MIPS Router (Big Endian) [NEW!]\nTrivision NC227WF Wireless IP Camera\nTenda AC15 Wi-Fi Router (Github Docs)\nArcher C9 Wi-Fi Router\nThe following devices are not included with the public release, however they have been successfully emulated and used in training:\nD-Link DIR-880L Wi-Fi Router\nNetgear Nighthawk R6250 Wi-Fi Router\nNetgear Nighthawk R6400 Wi-Fi Router\nNEW! Netgear Nighthawk R6700v3 Wi-Fi Router\nCisco RV130 Wi-Fi Router\nCOMfortel 1200 VoIP Phone\nLinksys EA9500 Wi-Fi Router\nPrecursors of EMUX have been used in Saumil Shah's popular ARM IoT Exploit Laboratory training classes where students have found four several 0-day vulnerabilities in various ARM/Linux IoT devices.\nEMUX Architecture\nEMUX is a collection of scripts, kernels and filesystems residing in the /emux directory. It uses qemu-system-arm, qemu-system-mips and qemu-system-mipsel to boot up virtual ARM and MIPS Linux environments. The /emux directory is exported over NFS to also make the contents available within the QEMU guest.\nThe host system running qemu-system-arm|mips|mipsel is assigned the IP address 192.168.100.1 and the QEMU guest is assigned 192.168.100.2 via tap0 interface.\nEMUX is packaged as a Docker image. The diagram below shows how the docker container is organised:\nThe docker image consists of:\nVolume harambe containing the /emux directory tree. (\ud83e\udd8d Harambe be praised!)\nContainer emux-docker.\nDirectory workspace on the host bind mounted as /home/r0/workspace in the container, to share files.\nNFS server running inside the container serving the /emux directory tree to emulated images running under QEMU\nPort forwarding from the host to QEMU running inside the container is done using socat.\nThe /emux directory\nThe /emux directory is organised as follows:\ndevices: This file contains device definitions, one per line.\ndevices-extra: Contains additional emulated devices not included in the general release. It is recommended that you add your own emulated devices to devices-extra.\nqemuopts: Abstracted QEMU options definitions for various types of QEMU Machines.\nrun/: This folder contains scripts necessary to parse the device configuration, preload nvram contents and eventually invoke the userland processes of the device being emulated.\nrun/launcher: The main script. launcher parses the devices file and displays a menu of registered devices. Selecting one of the devices will in turn invoke qemu-system-arm with the pre-defined QEMU options, corresponding Linux kernel and extracted root file system registered with the device.\nrun/userspace: Start the userspace processes of an emulated device, once the kernel is booted up from the launcher.\ndebuglogs: If present, it indicates the location where EMUX debugging logs will be written to. Extremely helpful in troubleshooting while creating a new emulated device.\ntemplate/: Sample configuration and layout for a new device. Make a copy of the template when beginning to emulate a new IoT device.\nThe run/ directory also contains a few commands that can be used from the host to interact with processes running within an EMUX emulated device.\nemuxhalt: Cleanly shut down the emulated device, and unmount all NFS mounts. Without a clean shutdown, there's always the risk of stale NFS handles.\nemuxps: Remotely enumerate processes running within EMUX.\nemuxmaps: Remotely dump the process memory layout of a process running within EMUX.\nemuxnetstat: Enumerate network sockets within EMUX.\nemuxkill: Remotely terminate a process running within EMUX.\nemuxgdb: Attach gdb to a process running within EMUX.\nmonitor: Attach to the QEMU monitor.\nemuxps, emuxmaps and emuxgdb are explained in detail in the Debugging With EMUX tutorial.\nContents of an emulated device\nEach emulated device contains the following files/directories:\nconfig: Contains the device's name and description, ASLR settings, location of its root file system and commands to issue after the kernel has booted up and transferred control to the userland.\nnvram.ini: Contents of the device's non volatile memory, used for storing configuration settings. Contents of nvram.ini are preloaded into the emulated nvram before invoking the userland init scripts.\nkernel/: Contains a Linux kernel compiled (mostly via Buildroot) to closely match the properties of the emulated device such as kernel version, CPU support, VM_SPLIT, supported peripherals, etc.\nrootfs.tar.bz2: A compressed archive containing the Root File System extracted from the target device. The name rootfs.tar.bz2 is configurable from within the config file. EMUX will automatically unpack the Root File System the first time it is invoked.\nflashmem/flash.tar.bz2: A compressed archive containing two 64MB memory dump files flash0.bin and flash1.bin. These will be visible as a unified 128MB MTD Flash device.\nRunning an emulated device in EMUX\nThe diagram below describes each stage of EMUX:\nThere are five steps in running an emulated device:\nLauncher - choose from a list of available emulated devices\nSelect a device and boot its kernel and its hostfs\nUserspace - choose from a list of available userspace actions\nStart the devices' userspace processes\nOptionally drop into the hostfs shell\nStep 1: The Launcher\nInvoke launcher.\nThis will display a menu as shown below. In this example, we select the Trivision TRI227WF Wireless IP Camera.\nStep 2: Start a device\nSelecting one of the devices will launch it under QEMU. The kernel which is included in the kernel/ directory of the Trivision IP Camera's device configuration, is booted in qemu-system-arm and uses a pre-built Buildroot filesystem, which is referred to as hostfs.ext2. Host and guest IP addresses are assigned to 192.168.100.1 and 192.168.100.2 respectively.\nhostfs-arm.ext2, hostfs-mips.ext2 and hostfs-mipsel.ext2 contain several scripts and tools useful for running and dynamic analysis of the emulated device. The init scripts in hostfs mount the /emux directory over NFS. Thus, the contents of /emux are shared by both the host and the QEMU guest.\nStep 3: Userspace\nYou will need to attach to the running emux-docker container and invoke the userspace command at the shell prompt.\nInternally the userspace command simply connects to the QEMU guest using SSH ssh root@192.168.100.2. This brings up a menu as shown below:\nStep 4: Start the userspace processes\nSelecting the option to launch the userspace processes of the device results in run-init being invoked from the corresponding device configuration directory within /emux. First, the contents of nvram.ini are loaded into the kernel's emulated nvram driver. Next, a chroot jail is created using the rootfs of the device. Lastly, the registered initialisation commands are invoked in the newly chrooted rootfs, bringing up the device's services and init scripts.\nStep 5: Device booted up and ready\nOnce the device has fully \"booted up\" in EMUX, it is available for testing and analysis. The image below shows the administration interface of the IP Camera loaded in a browser. Note, to access the internal ports on 192.168.100.2 we will rely on port forwarding performed by socat. By default, the following ports are forwarded:\nlocalhost:20080 -> 192.168.100.2:80\nlocalhost:20443 -> 192.168.100.2:443\nlocalhost:28080 -> 192.168.100.2:8080\nTo access the web administration interface for the booted up device, open a browser and navigate to localhost:28000. This in turn will forward your request to 192.168.100.2:80 inside the emux-docker container.\nOverriding the forwarded ports\nEMUX port forwarding is controlled by the PORTFWD environment variable. It is a comma separated list containing FORWARDED_PORT:INTERNAL_PORT pairs. To override the default port forwarding, simply set the contents of PORTFWD before invoking run-emux-docker:\nexport PORTFWD=\"28000:8000,25800:5800\"\n./run-emux-docker\nCreating your own emulated IoT Device\nBefore you begin to emulate an IoT device, you will need the following:\nDetailed analysis of the IoT device\nCPU (ARMv5/ARMv6/ARMv7/MIPS)\nLinux Kernel version\nContents of the extracted flash memory (optional)\nExtracted Root File System from the flash memory\nContents of nvram (optional)\nGenerate a compatible kernel using Buildroot or Linux Kernel sources\nA week for troubleshooting!\nThe following diagram outlines the overall process of IoT device emulation.\nSteps involved:\nCopy the template directory to make a new device configuration.\nCompile a matching kernel from source, and place it in the kernel/ directory. You may also symlink an existing kernel if you wish to.\nCopy the extracted rootfs from the device's firmware into the rootfs/ directory. Typically these would be SquashFS or CramFS filesystems, uncompressed using binwalk or unsquashfs or cramfsck. Optionally you may also create a compressed tar.bz2 archive of the root file system.\nPlace the contents of extracted nvram in nvram.ini\nIf you wish to emulate MTD flash, dump the contents of your device's flash memory and create two 64MB files named flash0.bin and flash1.bin and place them in the flashmem/ directory. Optionally you may also compress them in a tar.bz2 archive. You will then need to define the MTD partition layout to be passed to the kernel in the mtdparts file.\nPlace any shared libraries that you wish to inject using LD_PRELOAD in the preload/ directory. Usually these shared libraries contain hooked functions necessary for certain emulated binaries to work properly.\nEdit the config file with the newly populated device firmware contents.\nCreate a new device record in the devices-extra file. Pay close attention to QEMU command line options.\nThe following sample kernels are provided with the template.\nzImage-2.6.39.4-vexpress ARMv7 CPU on a vexpress-a9 board.\nzImage-2.6.31.14-realview-rv130-nothumb ARMv6 CPU on a realview-eb board.\nzImage-2.6.31-versatile-nothumb ARMv5 CPU on a versatilepb board.\nzImage-2.6.29.6-versatile ARMv5 CPU on a versatilepb board.\nzImage-2.6.28-versatile-nothumb ARMv5 CPU on a versatilepb board.\nvmlinux-3.18.109-malta-be MIPS32 CPU (big endian) on a malta board. [NEW!]\nvmlinux-3.18.109-malta-le MIPS32 CPU (little endian) on a malta board. [NEW!]\nHowever, it is encouraged to build a compatible kernel from source.\nThe EMUX Activity Log File\nThe June 2021 release of EMUX comes with a feature to enable activity logs. This comes in very handy in troubleshooting errors when adding a new device to EMUX. To enable logging, edit the /emux/debuglogs file:\n# Uncomment logpath= to enable EMUX and QEMU console output logging.\n# Only one logpath= should be uncommented.\n#\nlogpath=/home/r0/workspace/logs/\n#logpath=/emux/logs/\nIt is recommended to use /home/r0/workspace/logs since the workspace directory is shared between the container and the host.\nEMUX (ARMX) In The Public\nPresentation at Countermeasure 2019 on 7 November 2019. \ud83d\udc47\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/6P5quK19YMwYQ5\" width=\"595\" height=\"485\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;\" > </iframe>\nINSIDE EMUX - Countermeasure 2019 from Saumil Shah\nRelease presentation at HITB+Cyberweek on 16 October 2019. \ud83d\udc47\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/9FqUwLVZaoLaxO\" width=\"595\" height=\"485\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;\" > </iframe>\nIntroducing EMUX from Saumil Shah\nAnnouncing EMUX Docker on 15 June 2021. \ud83d\udc47\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/dMzOpTu1gfAriw\" width=\"595\" height=\"485\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;\" > </iframe>\nAnnouncing EMUX Docker - DC11332 from Saumil Shah\nThe ARM IoT Firmware Laboratory - NEW TRAINING\nAn all new class where the ARM IoT EXPLOIT LABORATORY leaves off. The ARM IoT Firmware Laboratory dives into analysis, extraction and emulation of IoT device firmware, using a variety of techniques. Students shall be given ample hands on practice in emulating a variety of IoT devices. Lab exercises feature firmware extraction directly from the hardware, building a custom kernel and buildroot environment, extracting contents of nvram and emulating the device under EMUX. The class also goes on to fuzzing and exploit development exercises for the emulated devices.\nUpcoming classes:\nRingzer0 #VirtualVegas August 2021, Online Remote Training: (4 day class) https://ringzer0.training/arm-iot-exploitlab.html\nDownloads\nThe pre-built EMUX PREVIEW VM is now discontinued. You are encouraged to use EMUX on Docker\nEMUX Code\nGithub: https://github.com/therealsaumil/emux/\nEMUX Documentation\nTutorial: Debugging With EMUX (Github Doc)\nCase Study: Emulating the Tenda AC15 Router (Github Doc)\nCase Study: Extracting the Tenda AC15 Firmware (Github Doc)\nNEW! Install guide: Installing EMUX on Kali (Github Doc)\nEND\nEMUX is licensed under the Mozilla Public License v2.0 (MPLv2).\nv0.9 22-October-2019, Preview Release\nv1.0 19-November-2019\nv1.1 12-March-2020\nv1.2 05-May-2020\nv1.2 20-May-2020 (minor update)\nv1.3 02-June-2020\nv1.4 11-September-2020\nv2.0 17-June-2021\nv2.1 21-October-2021 Welcome, MIPS! ARMX -> EMUX", "link": "https://github.com/therealsaumil/emux", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "emux (formerly armx) firmware emulation framework\nby saumil shah @therealsaumil\noctober 2021\nwelcome, mips!\nwith the addition of mips, armx has changed its name to emux! try out the damn vulnerable mips router exercises included with the new emux docker image.\na brand new docker container running emux. going ahead, all official emux releases shall be released as docker images. lightweight, compact, easy.\nshut up and give me the g00diez\ngithub: https://github.com/therealsaumil/emux\na brand new emux docker image is ready for use! the old \"preview vm\" is now discontinued in favour of the docker image.\nquick install steps\nstep 1 - clone this repository\ngit clone --depth 1 --single-branch https://github.com/therealsaumil/emux.git\nstep 2 - build the docker volume and image\ncd emux\n./build-emux-volume\n./build-emux-docker\nstep 3 - run emux!\nopen a terminal, and start the emux-docker container:\n./run-emux-docker\nyou will be greeted with a purple shell prompt [emux-docker \ud83d\udc33:~$]. after a while, it is common to have many terminals attached to the container. coloured shell prompts makes it easy to remember where you are.\nnext, start the emux launcher:\n[emux-docker \ud83d\udc33:~$] launcher\nand select any emulated device that you wish to run.\nstep 4 - launch the emulated device's userland processes.\nnext, open a new terminal and attach to the running emux-docker container:\n./emux-docker-shell\nall attached container shells have a blue shell prompt. invoke the userspace command to bring up the userland processes of the emulated target:\n[emux-docker shell \ud83d\udc1a:~$] userspace\nread the documentation for more details.\nintroducing\nthe emux firmware emulation framework is a collection of scripts, kernels and filesystems to be used with qemu to emulate arm and mips linux iot devices. emux is aimed to facilitate iot research by virtualising as much of the physical device as possible. it is the closest we can get to an actual iot vm.\ndevices successfully emulated with emux so far:\ndamn vulnerable arm router\ndamn vulnerable mips router (little endian) [new!]\ndamn vulnerable mips router (big endian) [new!]\ntrivision nc227wf wireless ip camera\ntenda ac15 wi-fi router (github docs)\narcher c9 wi-fi router\nthe following devices are not included with the public release, however they have been successfully emulated and used in training:\nd-link dir-880l wi-fi router\nnetgear nighthawk r6250 wi-fi router\nnetgear nighthawk r6400 wi-fi router\nnew! netgear nighthawk r6700v3 wi-fi router\ncisco rv130 wi-fi router\ncomfortel 1200 voip phone\nlinksys ea9500 wi-fi router\nprecursors of emux have been used in saumil shah's popular arm iot exploit laboratory training classes where students have found four several 0-day vulnerabilities in various arm/linux iot devices.\nemux architecture\nemux is a collection of scripts, kernels and filesystems residing in the /emux directory. it uses qemu-system-arm, qemu-system-mips and qemu-system-mipsel to boot up virtual arm and mips linux environments. the /emux directory is exported over nfs to also make the contents available within the qemu guest.\nthe host system running qemu-system-arm|mips|mipsel is assigned the ip address 192.168.100.1 and the qemu guest is assigned 192.168.100.2 via tap0 interface.\nemux is packaged as a docker image. the diagram below shows how the docker container is organised:\nthe docker image consists of:\nvolume harambe containing the /emux directory -----> tree !!! . (\ud83e\udd8d harambe be praised!)\ncontainer emux-docker.\ndirectory workspace on the host bind mounted as /home/r0/workspace in the container, to share files.\nnfs server running inside the container serving the /emux directory tree to emulated images running under qemu\nport forwarding from the host to qemu running inside the container is done using socat.\nthe /emux directory\nthe /emux directory is organised as follows:\ndevices: this file contains device definitions, one per line.\ndevices-extra: contains additional emulated devices not included in the general release. it is recommended that you add your own emulated devices to devices-extra.\nqemuopts: abstracted qemu options definitions for various types of qemu machines.\nrun/: this folder contains scripts necessary to parse the device configuration, preload nvram contents and eventually invoke the userland processes of the device being emulated.\nrun/launcher: the main script. launcher parses the devices file and displays a menu of registered devices. selecting one of the devices will in turn invoke qemu-system-arm with the pre-defined qemu options, corresponding linux kernel and extracted root file system registered with the device.\nrun/userspace: start the userspace processes of an emulated device, once the kernel is booted up from the launcher.\ndebuglogs: if present, it indicates the location where emux debugging logs will be written to. extremely helpful in troubleshooting while creating a new emulated device.\ntemplate/: sample configuration and layout for a new device. make a copy of the template when beginning to emulate a new iot device.\nthe run/ directory also contains a few commands that can be used from the host to interact with processes running within an emux emulated device.\nemuxhalt: cleanly shut down the emulated device, and unmount all nfs mounts. without a clean shutdown, there's always the risk of stale nfs handles.\nemuxps: remotely enumerate processes running within emux.\nemuxmaps: remotely dump the process memory layout of a process running within emux.\nemuxnetstat: enumerate network sockets within emux.\nemuxkill: remotely terminate a process running within emux.\nemuxgdb: attach gdb to a process running within emux.\nmonitor: attach to the qemu monitor.\nemuxps, emuxmaps and emuxgdb are explained in detail in the debugging with emux tutorial.\ncontents of an emulated device\neach emulated device contains the following files/directories:\nconfig: contains the device's name and description, aslr settings, location of its root file system and commands to issue after the kernel has booted up and transferred control to the userland.\nnvram.ini: contents of the device's non volatile memory, used for storing configuration settings. contents of nvram.ini are preloaded into the emulated nvram before invoking the userland init scripts.\nkernel/: contains a linux kernel compiled (mostly via buildroot) to closely match the properties of the emulated device such as kernel version, cpu support, vm_split, supported peripherals, etc.\nrootfs.tar.bz2: a compressed archive containing the root file system extracted from the target device. the name rootfs.tar.bz2 is configurable from within the config file. emux will automatically unpack the root file system the first time it is invoked.\nflashmem/flash.tar.bz2: a compressed archive containing two 64mb memory dump files flash0.bin and flash1.bin. these will be visible as a unified 128mb mtd flash device.\nrunning an emulated device in emux\nthe diagram below describes each stage of emux:\nthere are five steps in running an emulated device:\nlauncher - choose from a list of available emulated devices\nselect a device and boot its kernel and its hostfs\nuserspace - choose from a list of available userspace actions\nstart the devices' userspace processes\noptionally drop into the hostfs shell\nstep 1: the launcher\ninvoke launcher.\nthis will display a menu as shown below. in this example, we select the trivision tri227wf wireless ip camera.\nstep 2: start a device\nselecting one of the devices will launch it under qemu. the kernel which is included in the kernel/ directory of the trivision ip camera's device configuration, is booted in qemu-system-arm and uses a pre-built buildroot filesystem, which is referred to as hostfs.ext2. host and guest ip addresses are assigned to 192.168.100.1 and 192.168.100.2 respectively.\nhostfs-arm.ext2, hostfs-mips.ext2 and hostfs-mipsel.ext2 contain several scripts and tools useful for running and dynamic analysis of the emulated device. the init scripts in hostfs mount the /emux directory over nfs. thus, the contents of /emux are shared by both the host and the qemu guest.\nstep 3: userspace\nyou will need to attach to the running emux-docker container and invoke the userspace command at the shell prompt.\ninternally the userspace command simply connects to the qemu guest using ssh ssh root@192.168.100.2. this brings up a menu as shown below:\nstep 4: start the userspace processes\nselecting the option to launch the userspace processes of the device results in run-init being invoked from the corresponding device configuration directory within /emux. first, the contents of nvram.ini are loaded into the kernel's emulated nvram driver. next, a chroot jail is created using the rootfs of the device. lastly, the registered initialisation commands are invoked in the newly chrooted rootfs, bringing up the device's services and init scripts.\nstep 5: device booted up and ready\nonce the device has fully \"booted up\" in emux, it is available for testing and analysis. the image below shows the administration interface of the ip camera loaded in a browser. note, to access the internal ports on 192.168.100.2 we will rely on port forwarding performed by socat. by default, the following ports are forwarded:\nlocalhost:20080 -> 192.168.100.2:80\nlocalhost:20443 -> 192.168.100.2:443\nlocalhost:28080 -> 192.168.100.2:8080\nto access the web administration interface for the booted up device, open a browser and navigate to localhost:28000. this in turn will forward your request to 192.168.100.2:80 inside the emux-docker container.\noverriding the forwarded ports\nemux port forwarding is controlled by the portfwd environment variable. it is a comma separated list containing forwarded_port:internal_port pairs. to override the default port forwarding, simply set the contents of portfwd before invoking run-emux-docker:\nexport portfwd=\"28000:8000,25800:5800\"\n./run-emux-docker\ncreating your own emulated iot device\nbefore you begin to emulate an iot device, you will need the following:\ndetailed analysis of the iot device\ncpu (armv5/armv6/armv7/mips)\nlinux kernel version\ncontents of the extracted flash memory (optional)\nextracted root file system from the flash memory\ncontents of nvram (optional)\ngenerate a compatible kernel using buildroot or linux kernel sources\na week for troubleshooting!\nthe following diagram outlines the overall process of iot device emulation.\nsteps involved:\ncopy the template directory to make a new device configuration.\ncompile a matching kernel from source, and place it in the kernel/ directory. you may also symlink an existing kernel if you wish to.\ncopy the extracted rootfs from the device's firmware into the rootfs/ directory. typically these would be squashfs or cramfs filesystems, uncompressed using binwalk or unsquashfs or cramfsck. optionally you may also create a compressed tar.bz2 archive of the root file system.\nplace the contents of extracted nvram in nvram.ini\nif you wish to emulate mtd flash, dump the contents of your device's flash memory and create two 64mb files named flash0.bin and flash1.bin and place them in the flashmem/ directory. optionally you may also compress them in a tar.bz2 archive. you will then need to define the mtd partition layout to be passed to the kernel in the mtdparts file.\nplace any shared libraries that you wish to inject using ld_preload in the preload/ directory. usually these shared libraries contain hooked functions necessary for certain emulated binaries to work properly.\nedit the config file with the newly populated device firmware contents.\ncreate a new device record in the devices-extra file. pay close attention to qemu command line options.\nthe following sample kernels are provided with the template.\nzimage-2.6.39.4-vexpress armv7 cpu on a vexpress-a9 board.\nzimage-2.6.31.14-realview-rv130-nothumb armv6 cpu on a realview-eb board.\nzimage-2.6.31-versatile-nothumb armv5 cpu on a versatilepb board.\nzimage-2.6.29.6-versatile armv5 cpu on a versatilepb board.\nzimage-2.6.28-versatile-nothumb armv5 cpu on a versatilepb board.\nvmlinux-3.18.109-malta-be mips32 cpu (big endian) on a malta board. [new!]\nvmlinux-3.18.109-malta-le mips32 cpu (little endian) on a malta board. [new!]\nhowever, it is encouraged to build a compatible kernel from source.\nthe emux activity log file\nthe june 2021 release of emux comes with a feature to enable activity logs. this comes in very handy in troubleshooting errors when adding a new device to emux. to enable logging, edit the /emux/debuglogs file:\n# uncomment logpath= to enable emux and qemu console output logging.\n# only one logpath= should be uncommented.\n#\nlogpath=/home/r0/workspace/logs/\n#logpath=/emux/logs/\nit is recommended to use /home/r0/workspace/logs since the workspace directory is shared between the container and the host.\nemux (armx) in the public\npresentation at countermeasure 2019 on 7 november 2019. \ud83d\udc47\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/6p5quk19ymwyq5\" width=\"595\" height=\"485\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #ccc; border-width:1px; margin-bottom:5px; max-width: 100%;\" > </iframe>\ninside emux - countermeasure 2019 from saumil shah\nrelease presentation at hitb+cyberweek on 16 october 2019. \ud83d\udc47\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/9fquwlvzaolaxo\" width=\"595\" height=\"485\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #ccc; border-width:1px; margin-bottom:5px; max-width: 100%;\" > </iframe>\nintroducing emux from saumil shah\nannouncing emux docker on 15 june 2021. \ud83d\udc47\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/dmzoptu1gfariw\" width=\"595\" height=\"485\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #ccc; border-width:1px; margin-bottom:5px; max-width: 100%;\" > </iframe>\nannouncing emux docker - dc11332 from saumil shah\nthe arm iot firmware laboratory - new training\nan all new class where the arm iot exploit laboratory leaves off. the arm iot firmware laboratory dives into analysis, extraction and emulation of iot device firmware, using a variety of techniques. students shall be given ample hands on practice in emulating a variety of iot devices. lab exercises feature firmware extraction directly from the hardware, building a custom kernel and buildroot environment, extracting contents of nvram and emulating the device under emux. the class also goes on to fuzzing and exploit development exercises for the emulated devices.\nupcoming classes:\nringzer0 #virtualvegas august 2021, online remote training: (4 day class) https://ringzer0.training/arm-iot-exploitlab.html\ndownloads\nthe pre-built emux preview vm is now discontinued. you are encouraged to use emux on docker\nemux code\ngithub: https://github.com/therealsaumil/emux/\nemux documentation\ntutorial: debugging with emux (github doc)\ncase study: emulating the tenda ac15 router (github doc)\ncase study: extracting the tenda ac15 firmware (github doc)\nnew! install guide: installing emux on kali (github doc)\nend\nemux is licensed under the mozilla public license v2.0 (mplv2).\nv0.9 22-october-2019, preview release\nv1.0 19-november-2019\nv1.1 12-march-2020\nv1.2 05-may-2020\nv1.2 20-may-2020 (minor update)\nv1.3 02-june-2020\nv1.4 11-september-2020\nv2.0 17-june-2021\nv2.1 21-october-2021 welcome, mips! armx -> emux", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000239, "year": null}, {"Unnamed: 0": 275, "autor": 275, "date": null, "content": "Node.js Fullstack\u300a\u5f9e\u96f6\u5230\u4e00\u7684\u9032\u6483\u300b\n\u672c\u66f8\u6b63\u5728\u9032\u884c\u7b2c 3 \u7248\u7684\u6539\u7248\u5de5\u7a0b\n\u95dc\u65bc\u672c\u66f8\n\u9019\u662f\u4e00\u672c Node.js Fullstack \u7684\u5165\u9580\u96fb\u5b50\u66f8\uff0c\u5b83\u7684\u76ee\u6a19\u662f\u6210\u70ba\u512a\u8cea\u7684 Beginner to Beginner \u6559\u6750\u3002\n\u672c\u66f8\u5167\u5bb9\u5b9a\u4f4d\u70ba\u300a\u5f9e\u96f6\u5230\u4e00\u300b\u7684\u57fa\u790e\u6559\u5b78\uff0c\u4e26\u4f7f\u7528\u5728\u6211\u7684 Node.js Fullstack \u57f9\u8a13\u8ab2\u7a0b\u3002\u9019\u66f4\u662f\u4e00\u672c\u300c\u521d\u5b78\u8005\u5beb\u7d66\u521d\u5b78\u8005\u300d\u7684\u6559\u6750\uff1a\n\u6bcf\u500b\u4e3b\u984c\u90fd\u5f9e\u57fa\u672c\u89c0\u5ff5\uff08Zero\uff09\u958b\u59cb\u8b1b\u8ff0\uff0c\u4e26\u4ecb\u7d39\u5230\u80fd\u64b0\u5beb\u7c21\u55ae\u7684\u7a0b\u5f0f\u70ba\u6b62\uff08One\uff09\n\u5e0c\u671b\u5728\u5b78\u7fd2\u7684\u904e\u7a0b\u4e2d\uff0c\u57f9\u990a\u540c\u5b78\u300c\u5beb\u7a0b\u5f0f\u7684\u4fee\u7149\u300d\nLearn to Think\n\u5beb\u7a0b\u5f0f\u7684\u4fee\u7149\u662f\u672c\u66f8\u7684\u5b97\u65e8\uff0c\u4e5f\u662f\u4e00\u76f4\u4ee5\u4f86\u6211\u505a\u57f9\u8a13\u7684\u7406\u5ff5\u3002\u9019\u4efd\u6559\u6750\u4f7f\u7528\u5728\u6211\u7684\u57f9\u8a13\u8ab2\u7a0b\uff0c\u5167\u5bb9\u591a\u4ee5\u6b65\u9a5f\u5316\u65b9\u5f0f\u5f15\u5c0e\u5165\u9580\uff0c\u4f46\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5e0c\u671b\u5728 zero-to-one \u7684\u904e\u7a0b\uff0c\u57f9\u990a\u300cThinking\u300d\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u662f\u53ea\u5b78\u7fd2\u5982\u4f55\u7167\u672c\u5ba3\u79d1\u5730\u5beb\u7a0b\u5f0f\u3002\u6709\u4e86 Thinking \u7684\u80fd\u529b\u5f8c\uff0c\u6703\u6709\u53e6\u4e00\u500b\u91cd\u8981\u7684\u6536\u7372\uff1a\u80fd\u958b\u59cb\u95b1\u8b80\u8c50\u5bcc\u7684\u7db2\u8def\u6587\u4ef6\uff0c\u9084\u80fd\u5728\u62dc\u8b80\u512a\u8cea\u96fb\u5b50\u66f8\u7684\u904e\u7a0b\u4e2d\uff0c\u5c0d\u5927\u795e\u5206\u4eab\u7684\u5167\u5bb9\u7522\u751f\u5171\u9cf4\u3002\n\u95dc\u65bc\u4f5c\u8005\nJollen\uff08\u9673\u4fca\u5b8f\uff09\uff0cMoko365 Inc \u5275\u8fa6\u4eba\u66a8\u8b1b\u5e2b\u3001Mokoversity Inc \u958b\u653e\u5275\u65b0\u5b78\u9662\u5275\u8fa6\u4eba\u8207 Devify Inc \u767c\u8d77\u4eba\u3002\u8208\u8da3\u662f Web Fullstack \u6280\u8853\u3001Android Framework\u3001Linux \u9a45\u52d5\u7a0b\u5f0f\u3001\u8edf\u9ad4\u67b6\u69cb\u8a2d\u8a08\u3001\u7814\u767c\u7ba1\u7406\u8207\u7522\u54c1\u898f\u5283\u3002\u8fd1\u671f\u7684\u7814\u7a76\u8a08\u756b\u6709 WoT.City\u3001DevifyPlatform \u8207 Flowchain\uff0c\u76ee\u524d\u53c3\u8207 2 \u500b Blockchain \u76f8\u95dc\u65b0\u5275\u5718\u968a\u3002\nEmail\uff1ajollen@jollen.org\nBlog\uff1ahttp://www.jollen.org/blog\nGithub\uff1ahttps://github.com/jollen\nRoadmap (2016 Q4)\n\u79fb\u9664 ARM mbed \u6559\u5b78\n\u52a0\u5165 MediaTek LinkIt Smart 7688 \u6559\u5b78\n\u52a0\u5165 Serverless \u6559\u5b78\n\u52a0\u5165 P2P \u6559\u5b78\n\u7b2c 1~13 \u7ae0\u9032\u884c\u5b63\u5ea6\u6821\u5c0d\n\u52a0\u5165 IoT \u521d\u9ad4\u9a57\n\u516c\u958b\u6642\u686f\n\u9810\u8a08\u5728\u5b8c\u6210 Roadmap \u5f8c\u6b63\u5f0f\u516c\u958b\u767c\u4f48\u672c\u66f8 (\u76ee\u524d\u672c\u66f8\u70ba\u8a66\u8b80\u968e\u6bb5)\n\u9810\u8a08 2017.1.1 \u767c\u8868\n\u767c\u884c\u7d00\u9304\n2016-10-04\uff1a\u958b\u59cb\u9032\u884c\u7b2c 3 \u7248\u6539\u7248\u5de5\u7a0b\n2015-12-23\uff1a\u958b\u59cb\u9032\u884c\u7b2c 2 \u7248\u6539\u7248\u5de5\u7a0b\n\u76ee\u9304\nPart 0\uff1aFundamentals\n\u7b2c 1 \u7ae0\uff1aJavaScript \u8a2d\u8a08\u6a21\u5f0f\n1.1 Object\n1.2 \u5ba3\u544a Class\n1.3 \u4f7f\u7528 Factory Pattern\n1.4 Constructor Pattern\n1.5 Design Pattern for Front-End\n1.6 Module Pattern\n1.7 jQuery Pattern\n1.8 \u9078\u64c7\u5668\u6a21\u5f0f\n1.9 Prototype Pattern\n1.10 \u5176\u5b83\u6a21\u5f0f\n\u7b2c 2 \u7ae0\uff1aHTML5 \u8edf\u9ad4\u958b\u767c\u7684\u6982\u5ff5\n2.1 HTML5 \u7684 Runtime \u662f\u700f\u89bd\u5668\n2.2 \u5f9e Chrome \u700f\u89bd\u5668\u8ac7\u8d77\n2.3 Web Fullstack \u8edf\u9ad4\u958b\u767c\u7684\u6982\u5ff5\n2.4 JavaScript \u4e5f\u80fd\u958b\u767c\u96f2\u7aef\u670d\u52d9\n2.5 Data Push \u8a2d\u8a08\u6a21\u5f0f\n2.6 Device API \u7684\u9769\u547d\u6642\u4ee3\n2.7 \u91cd\u8981\u7684\u8cc7\u8a0a\u4ea4\u63db\u683c\u5f0f\uff1aJSON\n\u7b2c 3 \u7ae0\uff1aNode.js \u5165\u9580 - URL Routing \u7bc7\n3.1 Hello, World\n3.2 \u88fd\u4f5c Node.js \u6a21\u7d44\n3.3 URL Routing\n3.4 \u8a2d\u8a08 HTTP API\n3.5 \u89e3\u6790 Query String\n\u7b2c 4 \u7ae0\uff1aNode.js \u5165\u9580 - WebSocket \u8207 JSON \u7bc7\n4.1 \u7b2c\u4e00\u500b WebSocket \u4f3a\u670d\u5668\n4.2 \u5b78\u7fd2 JSON \u683c\u5f0f\n4.3 \u88fd\u4f5c WebSocket \u7528\u6236\u7aef\n4.4 \u4f7f\u7528 jQuery \u6a21\u5f0f\n4.5 \u4f7f\u7528 this \u7269\u4ef6\nPart 1\uff1aBasic Concepts\n\u7b2c 5 \u7ae0\uff1a\u8edf\u9ad4\u601d\u60df - Lambda \u7bc7\n5.1 Lambda\n5.2 Callback Function\n5.3 \u5f9e TypeScript \u8ac7\u8d77\n5.4 Arrow Function \u521d\u9ad4\u9a57\n\u7b2c 6 \u7ae0\uff1a\u8edf\u9ad4\u601d\u60df - Web Service \u7bc7\n6.1 \u518d\u63a2 HTTP API\n6.2 REST\n6.3 \u8a8d\u8b58 HTTP \u5354\u5b9a\n\u7b2c 7 \u7ae0\uff1a\u8edf\u9ad4\u601d\u60df - Non-blocking IO \u7bc7\n7.1 \u8a8d\u8b58 Non-blocking IO\n7.2 \u975e\u540c\u6b65\u5f0f\u8b80\u53d6\u591a\u500b\u6a94\u6848\n7.3 \u6df1\u5165\u6dfa\u51fa Asynchronous\n7.4 \u6dfa\u8ac7 Callback Hell \u8207 Promise\n7.5 Promise \u521d\u9ad4\u9a57\nPart 2\uff1aGetting Started\n\u7b2c 8 \u7ae0\uff1aNode.js \u61c9\u7528 - Express.js \u5165\u9580\n8.1 Express.js \u521d\u9ad4\u9a57\n8.2 MVC \u8207 HTML Template Engine\n8.3 \u89e3\u6790 app.js\n8.4 Express URL Routing\n8.5 Middleware \u7684\u89c0\u5ff5\n\u7b2c 9 \u7ae0\uff1aExpress.js \u61c9\u7528 - Middleware\n9.1 Express.js \u521d\u9ad4\u9a57\n9.2 MVC \u8207 HTML Template Engine\n9.3 \u89e3\u6790 app.js\n\u7b2c 10 \u7ae0\uff1aREST API \u67b6\u69cb - \u4f7f\u7528 Express.js\n10.1 \u670d\u52d9\u5c0e\u5411\u67b6\u69cb\n10.2 \u95dc\u65bc SOA \u8207 3-Tier \u67b6\u69cb\n10.3 Presenetation \u5728 Client \u7aef\n10.4 Express.js \u8207 REST API\n10.5 Node.js Chat Client\n10.6 CORS \u8207 Preflight Request\nPart 3\uff1aFullstack Beginner\n\u7b2c 11 \u7ae0\uff1aREST API \u61c9\u7528 - \u4f7f\u7528 jQuery\n11.1 \u547c\u53eb REST API - \u4f7f\u7528 jQuery\n11.2 \u8a8d\u8b58 Key-Value Pairs \u89c0\u5ff5\n\u7b2c 12 \u7ae0\uff1aMVC \u67b6\u69cb\u5be6\u4f5c - Backbone.js \u5165\u9580\n12.1 Backbone Way\n12.2 \u8a8d\u8b58 View.$el\n12.3 \u8a8d\u8b58 Backbone.Model\n12.4 \u8a8d\u8b58 Backbone.Model.fetch\n12.5 \u8a8d\u8b58 Backbone.Model.save\n\u7b2c 13 \u7ae0\uff1aNoSQL \u8cc7\u6599\u5eab\u61c9\u7528 - \u4f7f\u7528 MongoDB\n13.1 \u95dc\u65bc MongoDB\n13.2 \u5b89\u88dd MongoDB \u8cc7\u6599\u5eab\u4f3a\u670d\u5668\n13.3 \u4f7f\u7528 Mongoose Driver\n13.4 CRUD \u5be6\u4f5c\nPart 4\uff1aIoT Beginner\n\u7b2c 14 \u7ae0\uff1aNode.js \u7269\u806f\u7db2\u6982\u8ad6 - \u4f7f\u7528 Web of Things\n14.1 \u6dfa\u8ac7 Web of Things\n14.2 Constrained Device\n14.3 Physical Object\n14.4 \u9081\u5411 Open \u7684 IoT \u6642\u4ee3\n\u7b2c 15 \u7ae0\uff1aNode.js \u7269\u806f\u7db2\u5165\u9580 - \u4f7f\u7528 ARM mbed\n15.1 \u7269\u806f\u7db2\u5b78\u7fd2\u9ad4\u7cfb\n15.2 ARM mbed \u4f5c\u696d\u7cfb\u7d71\n15.3 ARM mbed Networking\n15.4 \u4f7f\u7528 NTP\uff0dNetwork Time Protocol\n15.5 WoT \u88dd\u7f6e\u7684 Use Case\n\u7b2c 16 \u7ae0\uff1aNode.js \u8207\u524d\u7aef - \u4e32\u63a5 WebSocket\n16.1 \u524d\u5f8c\u7aef\u6574\u5408\u521d\u9ad4\u9a57\n16.2 \u6dfa\u8ac7 Flux \u67b6\u69cb\u6a21\u5f0f\n16.3 \u524d\u7aef\u5165\u9580\u521d\u9ad4\u9a57 - \u4f7f\u7528 React.js\n\u7b2c 17 \u7ae0\uff1aNode.js \u8207 MCS Lite\n17.1 \u5b89\u88dd MCS Lite \u79c1\u6709\u96f2\u74b0\u5883\n\u7b2c 18 \u7ae0\uff1aNode.js \u8207 Web of Things \u7269\u806f\u7db2\n18.1 Broker \u7269\u806f\u7db2\u67b6\u69cb\u5c0e\u8ad6\n18.2 CoAP \u89c0\u5ff5\u521d\u9ad4\u9a57\nPart 5\uff1aBlockchain Beginner\n\u7b2c 19 \u7ae0\uff1aNode.js \u8207 Blockchain \u5165\u9580\n19.1 \u8a8d\u8b58 Merkle Tree\n19.2 SHA256 \u8207 Genesis Block\n19.3 \u5efa\u7acb Merkle Tree\n\u7b2c 20 \u7ae0\uff1aNode.js \u8207 Blockchain \u61c9\u7528\n20.1 \u70ba\u4ec0\u9ebc\u8981 Mining\uff1f\n20.2 \u7c21\u55ae\u6613\u61c2\u7684 Mining \u6f14\u7b97\u6cd5\u8a2d\u8a08\n20.3 Transaction \u5be6\u4f5c\u521d\u9ad4\u9a57\n20.4 \u8a8d\u8b58 OP_RETURN\n\u9644\u9304\nA \u7df4\u7fd2\u7528\u5c08\u6848\n\u57f9\u8a13\u8ab2\u7a0b\nMokoversity Fullstack IoT 2017\nContributors\n\u611f\u8b1d @Hierom\u3001@benshiue \u63d0\u4ea4\u7684\u8ca2\u737b\u8207\u5354\u52a9\u932f\u8aa4\u4fee\u6b63\u3002\n\u6388\u6b0a\u65b9\u5f0f\n<img alt=\u201c\u5275\u7528 CC \u6388\u6b0a\u689d\u6b3e\u201d style=\u201cborder-width:0\u201d src=\u201chttps://i.creativecommons.org/l/by-nc/4.0/88x31.png\u201d />\n\u672c\u8457\u4f5c\u4fc2\u63a1\u7528\u5275\u7528 CC \u59d3\u540d\u6a19\u793a-\u975e\u5546\u696d\u6027 4.0 \u570b\u969b \u6388\u6b0a\u689d\u6b3e\u6388\u6b0a", "link": "https://github.com/jollen/nodejs-fullstack-book", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "node.js fullstack\u300a\u5f9e\u96f6\u5230\u4e00\u7684\u9032\u6483\u300b\n\u672c\u66f8\u6b63\u5728\u9032\u884c\u7b2c 3 \u7248\u7684\u6539\u7248\u5de5\u7a0b\n\u95dc\u65bc\u672c\u66f8\n\u9019\u662f\u4e00\u672c node.js fullstack \u7684\u5165\u9580\u96fb\u5b50\u66f8\uff0c\u5b83\u7684\u76ee\u6a19\u662f\u6210\u70ba\u512a\u8cea\u7684 beginner to beginner \u6559\u6750\u3002\n\u672c\u66f8\u5167\u5bb9\u5b9a\u4f4d\u70ba\u300a\u5f9e\u96f6\u5230\u4e00\u300b\u7684\u57fa\u790e\u6559\u5b78\uff0c\u4e26\u4f7f\u7528\u5728\u6211\u7684 node.js fullstack \u57f9\u8a13\u8ab2\u7a0b\u3002\u9019\u66f4\u662f\u4e00\u672c\u300c\u521d\u5b78\u8005\u5beb\u7d66\u521d\u5b78\u8005\u300d\u7684\u6559\u6750\uff1a\n\u6bcf\u500b\u4e3b\u984c\u90fd\u5f9e\u57fa\u672c\u89c0\u5ff5\uff08zero\uff09\u958b\u59cb\u8b1b\u8ff0\uff0c\u4e26\u4ecb\u7d39\u5230\u80fd\u64b0\u5beb\u7c21\u55ae\u7684\u7a0b\u5f0f\u70ba\u6b62\uff08one\uff09\n\u5e0c\u671b\u5728\u5b78\u7fd2\u7684\u904e\u7a0b\u4e2d\uff0c\u57f9\u990a\u540c\u5b78\u300c\u5beb\u7a0b\u5f0f\u7684\u4fee\u7149\u300d\nlearn to think\n\u5beb\u7a0b\u5f0f\u7684\u4fee\u7149\u662f\u672c\u66f8\u7684\u5b97\u65e8\uff0c\u4e5f\u662f\u4e00\u76f4\u4ee5\u4f86\u6211\u505a\u57f9\u8a13\u7684\u7406\u5ff5\u3002\u9019\u4efd\u6559\u6750\u4f7f\u7528\u5728\u6211\u7684\u57f9\u8a13\u8ab2\u7a0b\uff0c\u5167\u5bb9\u591a\u4ee5\u6b65\u9a5f\u5316\u65b9\u5f0f\u5f15\u5c0e\u5165\u9580\uff0c\u4f46\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5e0c\u671b\u5728 zero-to-one \u7684\u904e\u7a0b\uff0c\u57f9\u990a\u300cthinking\u300d\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u662f\u53ea\u5b78\u7fd2\u5982\u4f55\u7167\u672c\u5ba3\u79d1\u5730\u5beb\u7a0b\u5f0f\u3002\u6709\u4e86 thinking \u7684\u80fd\u529b\u5f8c\uff0c\u6703\u6709\u53e6\u4e00\u500b\u91cd\u8981\u7684\u6536\u7372\uff1a\u80fd\u958b\u59cb\u95b1\u8b80\u8c50\u5bcc\u7684\u7db2\u8def\u6587\u4ef6\uff0c\u9084\u80fd\u5728\u62dc\u8b80\u512a\u8cea\u96fb\u5b50\u66f8\u7684\u904e\u7a0b\u4e2d\uff0c\u5c0d\u5927\u795e\u5206\u4eab\u7684\u5167\u5bb9\u7522\u751f\u5171\u9cf4\u3002\n\u95dc\u65bc\u4f5c\u8005\njollen\uff08\u9673\u4fca\u5b8f\uff09\uff0cmoko365 inc \u5275\u8fa6\u4eba\u66a8\u8b1b\u5e2b\u3001mokoversity inc \u958b\u653e\u5275\u65b0\u5b78\u9662\u5275\u8fa6\u4eba\u8207 devify inc \u767c\u8d77\u4eba\u3002\u8208\u8da3\u662f web fullstack \u6280\u8853\u3001android framework\u3001linux \u9a45\u52d5\u7a0b\u5f0f\u3001\u8edf\u9ad4\u67b6\u69cb\u8a2d\u8a08\u3001\u7814\u767c\u7ba1\u7406\u8207\u7522\u54c1\u898f\u5283\u3002\u8fd1\u671f\u7684\u7814\u7a76\u8a08\u756b\u6709 wot.city\u3001devifyplatform \u8207 flowchain\uff0c\u76ee\u524d\u53c3\u8207 2 \u500b blockchain \u76f8\u95dc\u65b0\u5275\u5718\u968a\u3002\nemail\uff1ajollen@jollen.org\nblog\uff1ahttp://www.jollen.org/blog\ngithub\uff1ahttps://github.com/jollen\nroadmap (2016 q4)\n\u79fb\u9664 arm mbed \u6559\u5b78\n\u52a0\u5165 mediatek linkit smart 7688 \u6559\u5b78\n\u52a0\u5165 serverless \u6559\u5b78\n\u52a0\u5165 p2p \u6559\u5b78\n\u7b2c 1~13 \u7ae0\u9032\u884c\u5b63\u5ea6\u6821\u5c0d\n\u52a0\u5165 iot \u521d\u9ad4\u9a57\n\u516c\u958b\u6642\u686f\n\u9810\u8a08\u5728\u5b8c\u6210 roadmap \u5f8c\u6b63\u5f0f\u516c\u958b\u767c\u4f48\u672c\u66f8 (\u76ee\u524d\u672c\u66f8\u70ba\u8a66\u8b80\u968e\u6bb5)\n\u9810\u8a08 2017.1.1 \u767c\u8868\n\u767c\u884c\u7d00\u9304\n2016-10-04\uff1a\u958b\u59cb\u9032\u884c\u7b2c 3 \u7248\u6539\u7248\u5de5\u7a0b\n2015-12-23\uff1a\u958b\u59cb\u9032\u884c\u7b2c 2 \u7248\u6539\u7248\u5de5\u7a0b\n\u76ee\u9304\npart 0\uff1afundamentals\n\u7b2c 1 \u7ae0\uff1ajavascript \u8a2d\u8a08\u6a21\u5f0f\n1.1 object\n1.2 \u5ba3\u544a class\n1.3 \u4f7f\u7528 factory pattern\n1.4 constructor pattern\n1.5 design pattern for front-end\n1.6 module pattern\n1.7 jquery pattern\n1.8 \u9078\u64c7\u5668\u6a21\u5f0f\n1.9 prototype pattern\n1.10 \u5176\u5b83\u6a21\u5f0f\n\u7b2c 2 \u7ae0\uff1ahtml5 \u8edf\u9ad4\u958b\u767c\u7684\u6982\u5ff5\n2.1 html5 \u7684 runtime \u662f\u700f\u89bd\u5668\n2.2 \u5f9e chrome \u700f\u89bd\u5668\u8ac7\u8d77\n2.3 web fullstack \u8edf\u9ad4\u958b\u767c\u7684\u6982\u5ff5\n2.4 javascript \u4e5f\u80fd\u958b\u767c\u96f2\u7aef\u670d\u52d9\n2.5 data push \u8a2d\u8a08\u6a21\u5f0f\n2.6 device api \u7684\u9769\u547d\u6642\u4ee3\n2.7 \u91cd\u8981\u7684\u8cc7\u8a0a\u4ea4\u63db\u683c\u5f0f\uff1ajson\n\u7b2c 3 \u7ae0\uff1anode.js \u5165\u9580 - url routing \u7bc7\n3.1 hello, world\n3.2 \u88fd\u4f5c node.js \u6a21\u7d44\n3.3 url routing\n3.4 \u8a2d\u8a08 http api\n3.5 \u89e3\u6790 query string\n\u7b2c 4 \u7ae0\uff1anode.js \u5165\u9580 - websocket \u8207 json \u7bc7\n4.1 \u7b2c\u4e00\u500b websocket \u4f3a\u670d\u5668\n4.2 \u5b78\u7fd2 json \u683c\u5f0f\n4.3 \u88fd\u4f5c websocket \u7528\u6236\u7aef\n4.4 \u4f7f\u7528 jquery \u6a21\u5f0f\n4.5 \u4f7f\u7528 this \u7269\u4ef6\npart 1\uff1abasic concepts\n\u7b2c 5 \u7ae0\uff1a\u8edf\u9ad4\u601d\u60df - lambda \u7bc7\n5.1 lambda\n5.2 callback function\n5.3 \u5f9e typescript \u8ac7\u8d77\n5.4 arrow function \u521d\u9ad4\u9a57\n\u7b2c 6 \u7ae0\uff1a\u8edf\u9ad4\u601d\u60df - web service \u7bc7\n6.1 \u518d\u63a2 http api\n6.2 rest\n6.3 \u8a8d\u8b58 http \u5354\u5b9a\n\u7b2c 7 \u7ae0\uff1a\u8edf\u9ad4\u601d\u60df - non-blocking io \u7bc7\n7.1 \u8a8d\u8b58 non-blocking io\n7.2 \u975e\u540c\u6b65\u5f0f\u8b80\u53d6\u591a\u500b\u6a94\u6848\n7.3 \u6df1\u5165\u6dfa\u51fa asynchronous\n7.4 \u6dfa\u8ac7 callback hell \u8207 promise\n7.5 promise \u521d\u9ad4\u9a57\npart 2\uff1agetting started\n\u7b2c 8 \u7ae0\uff1anode.js \u61c9\u7528 - express.js \u5165\u9580\n8.1 express.js \u521d\u9ad4\u9a57\n8.2 mvc \u8207 html template engine\n8.3 \u89e3\u6790 app.js\n8.4 express url routing\n8.5 middleware \u7684\u89c0\u5ff5\n\u7b2c 9 \u7ae0\uff1aexpress.js \u61c9\u7528 - middleware\n9.1 express.js \u521d\u9ad4\u9a57\n9.2 mvc \u8207 html template engine\n9.3 \u89e3\u6790 app.js\n\u7b2c 10 \u7ae0\uff1arest api \u67b6\u69cb - \u4f7f\u7528 express.js\n10.1 \u670d\u52d9\u5c0e\u5411\u67b6\u69cb\n10.2 \u95dc\u65bc soa \u8207 3-tier \u67b6\u69cb\n10.3 presenetation \u5728 client \u7aef\n10.4 express.js \u8207 rest api\n10.5 node.js chat client\n10.6 cors \u8207 preflight request\npart 3\uff1afullstack beginner\n\u7b2c 11 \u7ae0\uff1arest api \u61c9\u7528 - \u4f7f\u7528 jquery\n11.1 \u547c\u53eb rest api - \u4f7f\u7528 jquery\n11.2 \u8a8d\u8b58 key-value pairs \u89c0\u5ff5\n\u7b2c 12 \u7ae0\uff1amvc \u67b6\u69cb\u5be6\u4f5c - backbone.js \u5165\u9580\n12.1 backbone way\n12.2 \u8a8d\u8b58 view.$el\n12.3 \u8a8d\u8b58 backbone.model\n12.4 \u8a8d\u8b58 backbone.model.fetch\n12.5 \u8a8d\u8b58 backbone.model.save\n\u7b2c 13 \u7ae0\uff1anosql \u8cc7\u6599\u5eab\u61c9\u7528 - \u4f7f\u7528 mongodb\n13.1 \u95dc\u65bc mongodb\n13.2 \u5b89\u88dd mongodb \u8cc7\u6599\u5eab\u4f3a\u670d\u5668\n13.3 \u4f7f\u7528 mongoose driver\n13.4 crud \u5be6\u4f5c\npart 4\uff1aiot beginner\n\u7b2c 14 \u7ae0\uff1anode.js \u7269\u806f\u7db2\u6982\u8ad6 - \u4f7f\u7528 web of things\n14.1 \u6dfa\u8ac7 web of things\n14.2 constrained device\n14.3 physical object\n14.4 \u9081\u5411 open \u7684 iot \u6642\u4ee3\n\u7b2c 15 \u7ae0\uff1anode.js \u7269\u806f\u7db2\u5165\u9580 - \u4f7f\u7528 arm mbed\n15.1 \u7269\u806f\u7db2\u5b78\u7fd2\u9ad4\u7cfb\n15.2 arm mbed \u4f5c\u696d\u7cfb\u7d71\n15.3 arm mbed networking\n15.4 \u4f7f\u7528 ntp\uff0dnetwork time protocol\n15.5 wot \u88dd\u7f6e\u7684 use case\n\u7b2c 16 \u7ae0\uff1anode.js \u8207\u524d\u7aef - \u4e32\u63a5 websocket\n16.1 \u524d\u5f8c\u7aef\u6574\u5408\u521d\u9ad4\u9a57\n16.2 \u6dfa\u8ac7 flux \u67b6\u69cb\u6a21\u5f0f\n16.3 \u524d\u7aef\u5165\u9580\u521d\u9ad4\u9a57 - \u4f7f\u7528 react.js\n\u7b2c 17 \u7ae0\uff1anode.js \u8207 mcs lite\n17.1 \u5b89\u88dd mcs lite \u79c1\u6709\u96f2\u74b0\u5883\n\u7b2c 18 \u7ae0\uff1anode.js \u8207 web of things \u7269\u806f\u7db2\n18.1 broker \u7269\u806f\u7db2\u67b6\u69cb\u5c0e\u8ad6\n18.2 coap \u89c0\u5ff5\u521d\u9ad4\u9a57\npart 5\uff1ablockchain beginner\n\u7b2c 19 \u7ae0\uff1anode.js \u8207 blockchain \u5165\u9580\n19.1 \u8a8d\u8b58 merkle -----> tree !!! \n19.2 sha256 \u8207 genesis block\n19.3 \u5efa\u7acb merkle -----> tree !!! \n\u7b2c 20 \u7ae0\uff1anode.js \u8207 blockchain \u61c9\u7528\n20.1 \u70ba\u4ec0\u9ebc\u8981 mining\uff1f\n20.2 \u7c21\u55ae\u6613\u61c2\u7684 mining \u6f14\u7b97\u6cd5\u8a2d\u8a08\n20.3 transaction \u5be6\u4f5c\u521d\u9ad4\u9a57\n20.4 \u8a8d\u8b58 op_return\n\u9644\u9304\na \u7df4\u7fd2\u7528\u5c08\u6848\n\u57f9\u8a13\u8ab2\u7a0b\nmokoversity fullstack iot 2017\ncontributors\n\u611f\u8b1d @hierom\u3001@benshiue \u63d0\u4ea4\u7684\u8ca2\u737b\u8207\u5354\u52a9\u932f\u8aa4\u4fee\u6b63\u3002\n\u6388\u6b0a\u65b9\u5f0f\n<img alt=\u201c\u5275\u7528 cc \u6388\u6b0a\u689d\u6b3e\u201d style=\u201cborder-width:0\u201d src=\u201chttps://i.creativecommons.org/l/by-nc/4.0/88x31.png\u201d />\n\u672c\u8457\u4f5c\u4fc2\u63a1\u7528\u5275\u7528 cc \u59d3\u540d\u6a19\u793a-\u975e\u5546\u696d\u6027 4.0 \u570b\u969b \u6388\u6b0a\u689d\u6b3e\u6388\u6b0a", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000275, "year": null}, {"Unnamed: 0": 336, "autor": 336, "date": null, "content": "https://kitspace.org\nWatch a 5 minute lightning-talk about Kitspace from the 35th Chaos Communication Congress (35C3).\nKitspace (formerly Kitnic) is a registry of open source hardware electronics projects that are ready to order and build. It could be described as a \"Thingiverse for electronics\". The most important elements of a Kit Space project page are what allow a design to be manufactured:\nA preview of the printed circuit board and prominent link to download the Gerber manufacturing files\nThe ability to quickly add the required components to a distributor shopping cart (using our browser extension)\nHelp us build an open hardware repository of useful electronics projects!\nGet in touch\nSubscribe to the Kitspace newsletter\nFollow Kitspace on Twitter\nJoin our chatroom: choose your preferred platform, they are bridged so we can all talk across platforms\nDiscord\nMatrix.org\nIRC: irc.libera.chat#kitspace (e.g. via Kiwi IRC)\nHow many people visit the site?\nOur visitor stats are public on plausible.io.\nTracespace\nThe renderings of the PCB files are made using Tracespace tools. You can get similar renderings and also inspect invdividual layers, using the Tracespace Gerber viewer.\nAdding your project\nCheck out kitspace.org/submit which will guide you through the process.\nkitspace.yaml format\nCurrently the kitspace.yaml makes use of the following fields:\nsummary: A description for your project\nsite: https://example.com # A site you would like to link to (include http:// or https://)\ncolor: purple # for example\n# The solder resist color of the preview rendering. If left undefined \"green\" is used. Can be one of:\n# - green\n# - red\n# - blue\n# - black\n# - white\n# - orange\n# - purple\n# - yellow\nbom: my-bom.xlsx\n# A path to your 1-click-bom in case it isn't `1-click-bom.tsv`. Supported extensions are:\n# - .tsv\n# - .csv\n# - .ods\n# - .xlsx\n# Check out https://github.com/kitspace/1clickBOM#readme for more details\ngerbers: my/gerber/folder # A path to your folder of gerbers in case it isn't `gerbers/`.\neda:\ntype: kicad # or eagle\npcb: path/to/your/file.kicad_pcb # your/eagle.brd\nreadme: my/special/readme.md # A path to your README file in case it isn't in the repository root directory.\npcb-services: [aisler, pcbway, oshpark, jlcpcb]\n# A list of the PCB services you would like to have included on your\n# page. If left undefined all are included. Otherwise ust be a list of Kitspace\n# sponsors, possible values are:\n# - aisler\n# - pcbway\n# - oshpark\n# - jlcpcb\nmulti: # Identifier field only used if the repository contains multiple projects. See below for details.\nPaths should be in UNIX style (i.e. use / not \\) and relative to the root of your repository. The YAML format is pretty straight forward but if you need to know more check the example below and the YAML website. Use this YAML validator to be extra sure that your kitspace.yaml is valid.\nKiCad PCB\nIf you you used KiCad for your design you can also specify a KiCad PCB file to use by adding an eda field.\neda:\ntype: kicad\npcb: path/to/your/file.kicad_pcb\nIf your project has a KiCad PCB file, and interactive assembly guide for the board will be created using the Interactive HTML BOM plugin from the Open Scope Project.\nIf both eda and gerbers are present the Gerber files will be used.\nSome examples\nCheck out the repo links of the projects listed on kitspace.org already. The minimum required file tree is something like :\n.\n\u251c\u2500\u2500 1-click-bom.tsv\n\u2514\u2500\u2500 gerbers\n\u251c\u2500\u2500 example.cmp\n\u251c\u2500\u2500 example.drd\n\u251c\u2500\u2500 example.dri\n\u251c\u2500\u2500 example.gko\n\u251c\u2500\u2500 example.gpi\n\u251c\u2500\u2500 example.gto\n\u251c\u2500\u2500 example.plc\n\u251c\u2500\u2500 example.sol\n\u251c\u2500\u2500 example.stc\n\u2514\u2500\u2500 example.sts\nA more advanced example could be something like:\n.\n\u251c\u2500\u2500 kitspace.yaml\n\u2514\u2500\u2500 manufacture\n\u251c\u2500\u2500 advanced-example-BOM.tsv\n\u2514\u2500\u2500 gerbers-and-drills\n\u251c\u2500\u2500 advanced-example-B_Adhes.gba\n\u251c\u2500\u2500 advanced-example-B_CrtYd.gbr\n\u251c\u2500\u2500 advanced-example-B_Cu.gbl\n\u251c\u2500\u2500 advanced-example-B_Fab.gbr\n\u251c\u2500\u2500 advanced-example-B_Mask.gbs\n\u251c\u2500\u2500 advanced-example-B_Paste.gbp\n\u251c\u2500\u2500 advanced-example-B_SilkS.gbo\n\u251c\u2500\u2500 advanced-example.drl\n\u251c\u2500\u2500 advanced-example-Edge_Cuts.gbr\n\u251c\u2500\u2500 advanced-example-F_Adhes.gta\n\u251c\u2500\u2500 advanced-example-F_CrtYd.gbr\n\u251c\u2500\u2500 advanced-example-F_Cu.gtl\n\u251c\u2500\u2500 advanced-example-F_Fab.gbr\n\u251c\u2500\u2500 advanced-example-F_Mask.gts\n\u251c\u2500\u2500 advanced-example-F_Paste.gtp\n\u2514\u2500\u2500 advanced-example-F_SilkS.gto\nwith kitspace.yaml containing:\nsummary: A more advanced example\nsite: https://example.com\ncolor: red\nbom: manufacture/advanced-example-BOM.tsv\ngerbers: manufacture/gerbers-and-drills\nThe multi field\nNOTE: multi doesn't yet work with the kitspace.org/submit preview tool. See issue #182.\nKitspace supports multiple projects in one repository with the multi field. When multiple projects exist, multi will always be the first field in the kitspace.yaml, with the paths to your projects folder nested underneath.\n\u251c\u2500\u2500 kitspace.yaml\n\u251c\u2500\u2500 project_one\n\u2502 \u251c\u2500\u2500 1-click-bom.tsv\n\u2502 \u251c\u2500\u2500 README.md\n\u2502 \u2514\u2500\u2500 gerbers\n\u2502 \u251c\u2500\u2500 example.cmp\n\u2502 \u251c\u2500\u2500 example.drd\n\u2502 \u251c\u2500\u2500 example.dri\n\u2502 ...\n\u2502 \u251c\u2500\u2500 example.stc\n\u2502 \u2514\u2500\u2500 example.sts\n\u2514\u2500\u2500 project_two\n\u251c\u2500\u2500 1-click-bom.tsv\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 gerbers\n\u251c\u2500\u2500 example.cmp\n\u251c\u2500\u2500 example.drd\n\u251c\u2500\u2500 example.dri\n...\n\u251c\u2500\u2500 example.stc\n\u2514\u2500\u2500 example.sts\nwith kitspace.yaml containing:\nmulti:\nproject_one:\nsummary: First project in a repository.\ncolor: blue\nsite: https://example-one.com\nproject_two:\nsummary: Second project in a repository.\ncolor: red\nsite: https://example-two.com\nIf you want to use custom paths for the readme, bom, or gerbers then note that these are from the root of the repository.\nE.g.\n\u251c\u2500\u2500 kitspace.yaml\n\u251c\u2500\u2500 manufacturing_outputs\n\u2502 \u2514\u2500\u2500 project_one_gerbers\n\u2502 \u251c\u2500\u2500 example.cmp\n\u2502 \u251c\u2500\u2500 example.drd\n\u2502 \u251c\u2500\u2500 example.dri\n\u2502 ...\n\u2502 \u251c\u2500\u2500 example.stc\n\u2502 \u2514\u2500\u2500 example.sts\n\u251c\u2500\u2500 project_one\n\u2502 \u251c\u2500\u2500 documentation\n\u2502 \u2502 \u2514\u2500\u2500 README.md\n\u2514\u2500\u2500 BOM.csv\n\u2514\u2500\u2500 project_two\n...\nmulti:\nproject_one:\nreadme: project_one/documentation/README.md\nbom: project_one/BOM.csv\ngerbers: manufacturing_outputs/project_one_gerbers\nproject_two:\n...\nTerms and Conditions for Adding a Project\nWe (Kitspace developers) do not claim any ownership over your work, it remains yours.\nBy submitting your project you give us permission to host copies of your files for other people to download.\nIf you change your mind, you can remove your project any time by removing the public git repository, sending a pull-request to remove it from boards.txt or notifying @kasbah in some other way.\nDevelopment\nArchitecture\nThis repository is the Kitspace front-end. The contents including all project data are currently pre-compiled into a static site. The main part of the site that requires server side components is the submission preview (/submit). Pages also use freegeoip lookup to decide what sites to link to for people that do not have the 1-click BOM browser extension. This roughly illustrates the main data flow when someone is browsing the site.\nWe have two services running for the submission preview.\ngit-clone-server for serving up files from git repositories.\npartinfo for getting part information for the BOM.\nAnd one for the geo ip lookup on pages.\nfreegeoip\nRequirements\nNodejs version 10 or higher\nfswatch on OSX/Windows or inotify-tools on Linux\nNinja Build >= 1.5.1\nInkscape (v0.92) for converting SVGs to PNGs\nYarn to ensure the correct dependencies are installed\nThe rest of the dependencies can be retrieved via yarn install\nQuick start for Debian/Ubuntu\ncurl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -\necho \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\nsudo apt update && sudo apt install git nodejs inotify-tools ninja-build inkscape yarn\ngit clone https://github.com/kitspace/kitspace && cd kitspace\nyarn install\nRunning a local dev server\nGet requirements above then:\nyarn install # retrieves dependencies\nyarn get-boards # gets the test projects and puts them into boards/\nyarn build # generates a build.ninja file using the ./configure script\n# and calls ninja to execute the build.ninja file which builds everything (similar to how make executes a makefile)\nyarn serve # starts a development server to preview the site\nVisit http://127.0.0.1:8080 in your browser to see your local development site.\nCode of Conduct\nWe are committed to making working on Kitspace an inclusive and welcoming environment. All contributors are expected to abide by our code of conduct. It's just common sense.\nContributors\nThis project exists thanks to all the people who contribute.\nBackers\nThank you to all our backers! \ud83d\ude4f [Become a backer]\nSponsors\nSupport this project by becoming a sponsor. Your logo will show up here with a link to your website. [Become a sponsor]", "link": "https://github.com/kitspace/kitspace", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "https://kitspace.org\nwatch a 5 minute lightning-talk about kitspace from the 35th chaos communication congress (35c3).\nkitspace (formerly kitnic) is a registry of open source hardware electronics projects that are ready to order and build. it could be described as a \"thingiverse for electronics\". the most important elements of a kit space project page are what allow a design to be manufactured:\na preview of the printed circuit board and prominent link to download the gerber manufacturing files\nthe ability to quickly add the required components to a distributor shopping cart (using our browser extension)\nhelp us build an open hardware repository of useful electronics projects!\nget in touch\nsubscribe to the kitspace newsletter\nfollow kitspace on twitter\njoin our chatroom: choose your preferred platform, they are bridged so we can all talk across platforms\ndiscord\nmatrix.org\nirc: irc.libera.chat#kitspace (e.g. via kiwi irc)\nhow many people visit the site?\nour visitor stats are public on plausible.io.\ntracespace\nthe renderings of the pcb files are made using tracespace tools. you can get similar renderings and also inspect invdividual layers, using the tracespace gerber viewer.\nadding your project\ncheck out kitspace.org/submit which will guide you through the process.\nkitspace.yaml format\ncurrently the kitspace.yaml makes use of the following fields:\nsummary: a description for your project\nsite: https://example.com # a site you would like to link to (include http:// or https://)\ncolor: purple # for example\n# the solder resist color of the preview rendering. if left undefined \"green\" is used. can be one of:\n# - green\n# - red\n# - blue\n# - black\n# - white\n# - orange\n# - purple\n# - yellow\nbom: my-bom.xlsx\n# a path to your 1-click-bom in case it isn't `1-click-bom.tsv`. supported extensions are:\n# - .tsv\n# - .csv\n# - .ods\n# - .xlsx\n# check out https://github.com/kitspace/1clickbom#readme for more details\ngerbers: my/gerber/folder # a path to your folder of gerbers in case it isn't `gerbers/`.\neda:\ntype: kicad # or eagle\npcb: path/to/your/file.kicad_pcb # your/eagle.brd\nreadme: my/special/readme.md # a path to your readme file in case it isn't in the repository root directory.\npcb-services: [aisler, pcbway, oshpark, jlcpcb]\n# a list of the pcb services you would like to have included on your\n# page. if left undefined all are included. otherwise ust be a list of kitspace\n# sponsors, possible values are:\n# - aisler\n# - pcbway\n# - oshpark\n# - jlcpcb\nmulti: # identifier field only used if the repository contains multiple projects. see below for details.\npaths should be in unix style (i.e. use / not \\) and relative to the root of your repository. the yaml format is pretty straight forward but if you need to know more check the example below and the yaml website. use this yaml validator to be extra sure that your kitspace.yaml is valid.\nkicad pcb\nif you you used kicad for your design you can also specify a kicad pcb file to use by adding an eda field.\neda:\ntype: kicad\npcb: path/to/your/file.kicad_pcb\nif your project has a kicad pcb file, and interactive assembly guide for the board will be created using the interactive html bom plugin from the open scope project.\nif both eda and gerbers are present the gerber files will be used.\nsome examples\ncheck out the repo links of the projects listed on kitspace.org already. the minimum required file -----> tree !!!  is something like :\n.\n\u251c\u2500\u2500 1-click-bom.tsv\n\u2514\u2500\u2500 gerbers\n\u251c\u2500\u2500 example.cmp\n\u251c\u2500\u2500 example.drd\n\u251c\u2500\u2500 example.dri\n\u251c\u2500\u2500 example.gko\n\u251c\u2500\u2500 example.gpi\n\u251c\u2500\u2500 example.gto\n\u251c\u2500\u2500 example.plc\n\u251c\u2500\u2500 example.sol\n\u251c\u2500\u2500 example.stc\n\u2514\u2500\u2500 example.sts\na more advanced example could be something like:\n.\n\u251c\u2500\u2500 kitspace.yaml\n\u2514\u2500\u2500 manufacture\n\u251c\u2500\u2500 advanced-example-bom.tsv\n\u2514\u2500\u2500 gerbers-and-drills\n\u251c\u2500\u2500 advanced-example-b_adhes.gba\n\u251c\u2500\u2500 advanced-example-b_crtyd.gbr\n\u251c\u2500\u2500 advanced-example-b_cu.gbl\n\u251c\u2500\u2500 advanced-example-b_fab.gbr\n\u251c\u2500\u2500 advanced-example-b_mask.gbs\n\u251c\u2500\u2500 advanced-example-b_paste.gbp\n\u251c\u2500\u2500 advanced-example-b_silks.gbo\n\u251c\u2500\u2500 advanced-example.drl\n\u251c\u2500\u2500 advanced-example-edge_cuts.gbr\n\u251c\u2500\u2500 advanced-example-f_adhes.gta\n\u251c\u2500\u2500 advanced-example-f_crtyd.gbr\n\u251c\u2500\u2500 advanced-example-f_cu.gtl\n\u251c\u2500\u2500 advanced-example-f_fab.gbr\n\u251c\u2500\u2500 advanced-example-f_mask.gts\n\u251c\u2500\u2500 advanced-example-f_paste.gtp\n\u2514\u2500\u2500 advanced-example-f_silks.gto\nwith kitspace.yaml containing:\nsummary: a more advanced example\nsite: https://example.com\ncolor: red\nbom: manufacture/advanced-example-bom.tsv\ngerbers: manufacture/gerbers-and-drills\nthe multi field\nnote: multi doesn't yet work with the kitspace.org/submit preview tool. see issue #182.\nkitspace supports multiple projects in one repository with the multi field. when multiple projects exist, multi will always be the first field in the kitspace.yaml, with the paths to your projects folder nested underneath.\n\u251c\u2500\u2500 kitspace.yaml\n\u251c\u2500\u2500 project_one\n\u2502 \u251c\u2500\u2500 1-click-bom.tsv\n\u2502 \u251c\u2500\u2500 readme.md\n\u2502 \u2514\u2500\u2500 gerbers\n\u2502 \u251c\u2500\u2500 example.cmp\n\u2502 \u251c\u2500\u2500 example.drd\n\u2502 \u251c\u2500\u2500 example.dri\n\u2502 ...\n\u2502 \u251c\u2500\u2500 example.stc\n\u2502 \u2514\u2500\u2500 example.sts\n\u2514\u2500\u2500 project_two\n\u251c\u2500\u2500 1-click-bom.tsv\n\u251c\u2500\u2500 readme.md\n\u2514\u2500\u2500 gerbers\n\u251c\u2500\u2500 example.cmp\n\u251c\u2500\u2500 example.drd\n\u251c\u2500\u2500 example.dri\n...\n\u251c\u2500\u2500 example.stc\n\u2514\u2500\u2500 example.sts\nwith kitspace.yaml containing:\nmulti:\nproject_one:\nsummary: first project in a repository.\ncolor: blue\nsite: https://example-one.com\nproject_two:\nsummary: second project in a repository.\ncolor: red\nsite: https://example-two.com\nif you want to use custom paths for the readme, bom, or gerbers then note that these are from the root of the repository.\ne.g.\n\u251c\u2500\u2500 kitspace.yaml\n\u251c\u2500\u2500 manufacturing_outputs\n\u2502 \u2514\u2500\u2500 project_one_gerbers\n\u2502 \u251c\u2500\u2500 example.cmp\n\u2502 \u251c\u2500\u2500 example.drd\n\u2502 \u251c\u2500\u2500 example.dri\n\u2502 ...\n\u2502 \u251c\u2500\u2500 example.stc\n\u2502 \u2514\u2500\u2500 example.sts\n\u251c\u2500\u2500 project_one\n\u2502 \u251c\u2500\u2500 documentation\n\u2502 \u2502 \u2514\u2500\u2500 readme.md\n\u2514\u2500\u2500 bom.csv\n\u2514\u2500\u2500 project_two\n...\nmulti:\nproject_one:\nreadme: project_one/documentation/readme.md\nbom: project_one/bom.csv\ngerbers: manufacturing_outputs/project_one_gerbers\nproject_two:\n...\nterms and conditions for adding a project\nwe (kitspace developers) do not claim any ownership over your work, it remains yours.\nby submitting your project you give us permission to host copies of your files for other people to download.\nif you change your mind, you can remove your project any time by removing the public git repository, sending a pull-request to remove it from boards.txt or notifying @kasbah in some other way.\ndevelopment\narchitecture\nthis repository is the kitspace front-end. the contents including all project data are currently pre-compiled into a static site. the main part of the site that requires server side components is the submission preview (/submit). pages also use freegeoip lookup to decide what sites to link to for people that do not have the 1-click bom browser extension. this roughly illustrates the main data flow when someone is browsing the site.\nwe have two services running for the submission preview.\ngit-clone-server for serving up files from git repositories.\npartinfo for getting part information for the bom.\nand one for the geo ip lookup on pages.\nfreegeoip\nrequirements\nnodejs version 10 or higher\nfswatch on osx/windows or inotify-tools on linux\nninja build >= 1.5.1\ninkscape (v0.92) for converting svgs to pngs\nyarn to ensure the correct dependencies are installed\nthe rest of the dependencies can be retrieved via yarn install\nquick start for debian/ubuntu\ncurl -ss https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -\necho \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\nsudo apt update && sudo apt install git nodejs inotify-tools ninja-build inkscape yarn\ngit clone https://github.com/kitspace/kitspace && cd kitspace\nyarn install\nrunning a local dev server\nget requirements above then:\nyarn install # retrieves dependencies\nyarn get-boards # gets the test projects and puts them into boards/\nyarn build # generates a build.ninja file using the ./configure script\n# and calls ninja to execute the build.ninja file which builds everything (similar to how make executes a makefile)\nyarn serve # starts a development server to preview the site\nvisit http://127.0.0.1:8080 in your browser to see your local development site.\ncode of conduct\nwe are committed to making working on kitspace an inclusive and welcoming environment. all contributors are expected to abide by our code of conduct. it's just common sense.\ncontributors\nthis project exists thanks to all the people who contribute.\nbackers\nthank you to all our backers! \ud83d\ude4f [become a backer]\nsponsors\nsupport this project by becoming a sponsor. your logo will show up here with a link to your website. [become a sponsor]", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000336, "year": null}, {"Unnamed: 0": 379, "autor": 379, "date": null, "content": "Introduction\nPolyMCU has been designed from the beginning to be as flexible as possible: host OS independent (support Linux, Windows, MacOS), support any toolchain (GCC, LLVM), any RTOS (ARM RTX, FreeRTOS), any micro-controller vendor SDK (Nordic Semiconductor, NXP, Freescale, ST).\nEnabling such flexibility provides by the same time better software quality by testing the same piece of software in various configurations. It supports C and C++ languages.\nThe framework is based on CMake. It provides some examples to build baremetal and RTOS-based projects. In opposition to ARM mBed that provides its own library, PolyMCU used Newlib. No new interface layout has been introduced in the framework. The abstraction layout for ARM architecture is driven by ARM CMSIS v3.0.\nQuick start\nFor AppNearMe's MicroNFCBoard: here\nTo port a new vendor SDK to PolyMCU: here\nBuild & Install CMSIS RTOS Conformance test: here\nSupport\nCMake - version 2.8\nToolchains:\nGCC: 4.9-2014: https://launchpad.net/gcc-arm-embedded/4.9/4.9-2014-q4-major\nClang: 3.6.0-2ubuntu1~trusty1 (tags/RELEASE_360/final) (based on LLVM 3.6.0)\nRTOS:\nARM RTX: V4.79\nFreeRTOS V8.2.3\nRioT-OS 2015.09\nBoards:\nAppNearMe MicroNFCBoard\nFreescale Freedom KL25\nNordic nRF52 Preview DK\nNXP LP1768 mbed\nST STM32L476 Nucleo\nFeatures:\nThe application defined by APPLICATION can live out of the PolyMCU tree if APPLICATION defined an absolute path.\nStatus\nThe latest test results are available at http://labapart.com/products/polymcu/test_results.\nToolchain / Host\nBoard Linux - GCC Linux - LLVM Windows\nAppNearMe MicroNFCBoard Pass Pass Pass\nFreescale Freedom KL25 Pass Pass Pass\nNordic nRF52 Preview DK Pass Pass Pass\nNXP LP1768 mbed Pass Pass Pass\nST STM32L476 Nucleo Pass Pass Not Tested\nApplication\nBoard Baremetal CMSIS RTOS FreeRTOS\nAppNearMe MicroNFCBoard Pass Pass Fail\nFreescale Freedom KL25 Pass Pass Pass\nNordic nRF52 Preview DK Pass Pass Pass\nNXP LP1768 mbed Pass Pass Pass\nST STM32L476 Nucleo Pass Pass Pass\nBuilding on Linux\nThe cross compilation toolchain is either in your PATH or defined by the environment variable CROSS_COMPILE. The latest cross-compilation toolchain for ARM Cortex-M can be found at https://launchpad.net/gcc-arm-embedded.\nIt is recommended to build out of tree. To do that, create a new directory:\nmkdir Build && cd Build\nCase when the application can support multiple board:\ncmake -DAPPLICATION=<application_vendor/application_name> -DBOARD=<board_vendor/board_name> ../ && make\nCase when the application targets only a specific board:\ncmake -DAPPLICATION=<application_vendor/application_name> ../ && make\nTo build a release build:\ncmake -DAPPLICATION=<application_vendor/application_name> -DCMAKE_BUILD_TYPE=Release ../ && make\nTo make the build verbose:\ncmake -DAPPLICATION=<application_vendor/application_name> ../ && make VERBOSE=1\nTo build with Clang:\nCC=<path-to-clang> cmake -DAPPLICATION=<application_vendor/application_name> ../ && make\nBuilding on Windows\nRequirements\nInstall CMake: https://cmake.org/download/\nInstall the latest GCC v4.9 2015q3 for ARM Cortex M: https://launchpad.net/gcc-arm-embedded/4.9/4.9-2015-q3-update/+download/gcc-arm-none-eabi-4_9-2015q3-20150921-win32.zip\nInstall MinGW: http://sourceforge.net/projects/mingw/files/Installer/mingw-get-setup.exe/download (mingw32-base, mingw32-gcc-g++)\nBuild\nDownload the latest sources of PolyMCU at https://github.com/labapart/polymcu/archive/master.zip\nUn-archive master.zip\nStart a command line shell (ie: cmd.exe)\nAdd CMake and MinGW to your PATH if it is not already done. For instance:\nSET PATH=\"c:\\Program Files (x86)\\CMake\\bin\";%PATH%\nSET PATH=C:\\MinGW\\bin;%PATH%\nAdd your toolchain into the CROSS_COMPILE. For instance:\nSET CROSS_COMPILE=c:\\Users\\Olivier\\gcc-arm-none-eabi-4_9-2015q3-20150921-win32\\bin\\arm-none-eabi-\nCreate the Build directory into PolyMCU root\ncd <PolyMCU Root>\nmkdir Build\ncd Build\n[Optional] To build with LLVM\nset PATH=\"C:\\Program Files (x86)\\LLVM\\bin\";%PATH%\nset CC=clang.exe\nBuild the project\ncmake -G \"MinGW Makefiles\" -DAPPLICATION=<application_vendor/application_name> -DBOARD=<board_vendor/board_name> ..\nmingw32-make\nTo make the build verbose: mingw32-make VERBOSE=1\nSupport\nAll CMake variables that do not start with CMAKE_ and _ are defined in ${CMAKE_BINARY_DIR}/polymcu_config.h which is generated at build time.\nThis include file can be included in your project to access CMake configuration variables.\nBasic variables\nCMake variable Value Description\nFIRMWARE_HEAP integer Size in bytes of the firmware heap\nFIRMWARE_STACK integer Size in bytes of the firmware stack\nSUPPORT_RUN_FROM_RAM (0|1) Define the firmware must be built to run from RAM\nEXTERNAL_PROJECT_IN_BINARY_DIR (0|1) Build the external project into the binary directory instead of the source directory\nSUPPORT_DEBUG_UART (none|itm|usb|1) Define which UART support to use for debugging\nDEBUG_UART_BAUDRATE integer Debug UART Baud Rate (default: 115200)\nSUPPORT_TIMER (0|1) Add PolyMCU Timer API\nSUPPORT_TIMER_SYSTICK (0|1) Use SysTick for PolyMCU Timer API (default:1)\nTIMER_TASK_MAX integer Number maximum of PolyMCU Timer tasks (default: 5)\nSUPPORT_RTOS string Enable RTOS support with the name of specified RTOS\nSUPPORT_WATCHDOG (0|1) Add PolyMCU Watchdog API\nSUPPORT_RAM_VECTOR_TABLE (0|1) Tell if the Vector Table lives in RAM\nDevice variables\nCMake variable Value Description\nSUPPORT_DEVICE_USB (0|1) Add USB Device support\nSUPPORT_DEVICE_USB_SERIAL (0|1) Add Serial USB Device support\nSUPPORT_DEVICE_USB_HID (0|1) Add HID USB Device support\nSUPPORT_DEVICE_USB_DFU (0|1) Add DFU USB Device support\nSUPPORT_DEVICE_USB_MSC (0|1) Add MSC USB Device support\nSUPPORT_BLE_CENTRAL (0|1) Add Bluetooth Low Energy (BLE) Central support\nSUPPORT_BLE_PERIPHERAL (0|1) Add Bluetooth Low Energy (BLE) Peripheral support\nSUPPORT_I2C (0|1) Add I2C support\nSUPPORT_SPI (0|1) Add SPI support\nUSB Specific Variables\nCMake variable Value Description\nDEVICE_USB_VENDOR_ID integer USB Vendor ID\nDEVICE_USB_PRODUCT_ID integer USB Product ID\nDEVICE_USB_DEVICE_REVISION integer USB Device Revision\nDEVICE_USB_DEVICE_MANUFACTURER string USB Device Manufacturer string\nDEVICE_USB_DEVICE_PRODUCT string USB Device Product string\nDEVICE_USB_DEVICE_SERIAL string USB Device Serial Number string\nDEVICE_USB_HID_INPUT_REPORT_SIZE integer Size of the USB HID Input Report\nDEVICE_USB_HID_OUTPUT_REPORT_SIZE integer Size of the USB HID Output Report\nDEVICE_USB_HID_FEATURE_REPORT_SIZE integer Size of the USB HID Feature Report\nRTOS variables\nCMake variable Value Description\nSUPPORT_RTOS_NO_CMSIS (0|1) Disable CMSIS wrapper of the RTOS.\nRTOS_CLOCK integer Frequency in Hz of the processor\nRTOS_TICK integer When OS_SYSTICK is not set we might need to provide a different tick\nRTOS_TASK_COUNT integer Number of RTOS task\nRTOS_TASK_STACK_SIZE integer Size in bytes of the task (excluding the main and private tasks)\nRTOS_MAIN_STACK_SIZE integer Size in bytes of the main task\nRTOS_IDLE_STACK_SIZE integer Size in bytes of the idle task\nRTOS_TIMER_STACK_SIZE integer Size in bytes of the timer task\nRTOS_TIMER_CALLBACK_COUNT integer Number of concurrent active timer callback functions\nRTOS_TASK_PRIVATE_STACK_COUNT integer Number of private tasks\nRTOS_TASK_PRIVATE_STACK_SIZE integer Size in bytes of the private task\nRTOS_STACK_WATERMARK (0|1) Disable/Enable the stack watermark\nDevice Specific variables\nCMake variable Value Description\nSUPPORT_NXP_USE_XTAL (0|1) Use external oscillator instead of the internal one\nDebug\nRun an application from RAM\nTo build the firmware to run from RAM:\ncmake -DAPPLICATION=<application_vendor/application_name> -DSUPPORT_RUN_FROM_RAM=1 .. && make\nDebug with GDB\nStart the debugger server\npyocd-gdbserver\nStart the GDB client\narm-none-eabi-gdb <filepath_of_the_ELF_application>\ntarget remote localhost:3333\ncontinue\nExamples of some GDB commands:\n(gdb) print $pc\n$1 = (void (*)()) 0x200000d8\n(gdb) print $sp\n$2 = (void *) 0x1fffff58\n(gdb) print/x *0x400\n$3 = 0x21004692\n(gdb) set {int}0x20000000 = 1\n(gdb) set arm force-mode thumb\n(gdb) display /10i 0x0\n1: x/10i 0x0\n0x0 <__Vectors>:strhr0, [r0, #0]\n0x2 <__Vectors+2>:movsr0, #0\n0x4 <__Vectors+4>:lslsr1, r1, #24\n0x6 <__Vectors+6>:movsr0, r0\n0x8 <__Vectors+8>:lslsr1, r7, #24\n0xa <__Vectors+10>:movsr0, r0\n0xc <__Vectors+12>:addsr0, #37; 0x25\n0xe <__Vectors+14>:movsr0, r0\n0x10 <__Vectors+16>:movsr0, r0\n0x12 <__Vectors+18>:movsr0, r0\n(gdb) display /10i $pc\n2: x/10i $pc\n=> 0x1a96 <ARM_USART_Send+18>:ldrr3, [sp, #16]\n0x1a98 <ARM_USART_Send+20>:ldrbr3, [r3, #0]\n0x1a9a <ARM_USART_Send+22>:movr0, r3\n0x1a9c <ARM_USART_Send+24>:bl0x2da8 <app_uart_put>\n0x1aa0 <ARM_USART_Send+28>:strr0, [sp, #12]\n0x1aa2 <ARM_USART_Send+30>:ldrr3, [sp, #12]\n0x1aa4 <ARM_USART_Send+32>:cmpr3, #0\n0x1aa6 <ARM_USART_Send+34>:bne.n0x1a96 <ARM_USART_Send+18>\n0x1aa8 <ARM_USART_Send+36>:ldrr3, [sp, #16]\n0x1aaa <ARM_USART_Send+38>:addsr3, #1\nDump memory into a file:\n(gdb) dump binary memory /tmp/gdb.bin 0x0 0x1000\nDebug UART Settings\nAll the board UARTs are set with the following settings:\nBaud Rate: 115200\nData Bits: 8\nStop Bits: 1\nParity: None\nFlow Control: None", "link": "https://github.com/labapart/polymcu", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "introduction\npolymcu has been designed from the beginning to be as flexible as possible: host os independent (support linux, windows, macos), support any toolchain (gcc, llvm), any rtos (arm rtx, freertos), any micro-controller vendor sdk (nordic semiconductor, nxp, freescale, st).\nenabling such flexibility provides by the same time better software quality by testing the same piece of software in various configurations. it supports c and c++ languages.\nthe framework is based on cmake. it provides some examples to build baremetal and rtos-based projects. in opposition to arm mbed that provides its own library, polymcu used newlib. no new interface layout has been introduced in the framework. the abstraction layout for arm architecture is driven by arm cmsis v3.0.\nquick start\nfor appnearme's micronfcboard: here\nto port a new vendor sdk to polymcu: here\nbuild & install cmsis rtos conformance test: here\nsupport\ncmake - version 2.8\ntoolchains:\ngcc: 4.9-2014: https://launchpad.net/gcc-arm-embedded/4.9/4.9-2014-q4-major\nclang: 3.6.0-2ubuntu1~trusty1 (tags/release_360/final) (based on llvm 3.6.0)\nrtos:\narm rtx: v4.79\nfreertos v8.2.3\nriot-os 2015.09\nboards:\nappnearme micronfcboard\nfreescale freedom kl25\nnordic nrf52 preview dk\nnxp lp1768 mbed\nst stm32l476 nucleo\nfeatures:\nthe application defined by application can live out of the polymcu -----> tree !!!  if application defined an absolute path.\nstatus\nthe latest test results are available at http://labapart.com/products/polymcu/test_results.\ntoolchain / host\nboard linux - gcc linux - llvm windows\nappnearme micronfcboard pass pass pass\nfreescale freedom kl25 pass pass pass\nnordic nrf52 preview dk pass pass pass\nnxp lp1768 mbed pass pass pass\nst stm32l476 nucleo pass pass not tested\napplication\nboard baremetal cmsis rtos freertos\nappnearme micronfcboard pass pass fail\nfreescale freedom kl25 pass pass pass\nnordic nrf52 preview dk pass pass pass\nnxp lp1768 mbed pass pass pass\nst stm32l476 nucleo pass pass pass\nbuilding on linux\nthe cross compilation toolchain is either in your path or defined by the environment variable cross_compile. the latest cross-compilation toolchain for arm cortex-m can be found at https://launchpad.net/gcc-arm-embedded.\nit is recommended to build out of tree. to do that, create a new directory:\nmkdir build && cd build\ncase when the application can support multiple board:\ncmake -dapplication=<application_vendor/application_name> -dboard=<board_vendor/board_name> ../ && make\ncase when the application targets only a specific board:\ncmake -dapplication=<application_vendor/application_name> ../ && make\nto build a release build:\ncmake -dapplication=<application_vendor/application_name> -dcmake_build_type=release ../ && make\nto make the build verbose:\ncmake -dapplication=<application_vendor/application_name> ../ && make verbose=1\nto build with clang:\ncc=<path-to-clang> cmake -dapplication=<application_vendor/application_name> ../ && make\nbuilding on windows\nrequirements\ninstall cmake: https://cmake.org/download/\ninstall the latest gcc v4.9 2015q3 for arm cortex m: https://launchpad.net/gcc-arm-embedded/4.9/4.9-2015-q3-update/+download/gcc-arm-none-eabi-4_9-2015q3-20150921-win32.zip\ninstall mingw: http://sourceforge.net/projects/mingw/files/installer/mingw-get-setup.exe/download (mingw32-base, mingw32-gcc-g++)\nbuild\ndownload the latest sources of polymcu at https://github.com/labapart/polymcu/archive/master.zip\nun-archive master.zip\nstart a command line shell (ie: cmd.exe)\nadd cmake and mingw to your path if it is not already done. for instance:\nset path=\"c:\\program files (x86)\\cmake\\bin\";%path%\nset path=c:\\mingw\\bin;%path%\nadd your toolchain into the cross_compile. for instance:\nset cross_compile=c:\\users\\olivier\\gcc-arm-none-eabi-4_9-2015q3-20150921-win32\\bin\\arm-none-eabi-\ncreate the build directory into polymcu root\ncd <polymcu root>\nmkdir build\ncd build\n[optional] to build with llvm\nset path=\"c:\\program files (x86)\\llvm\\bin\";%path%\nset cc=clang.exe\nbuild the project\ncmake -g \"mingw makefiles\" -dapplication=<application_vendor/application_name> -dboard=<board_vendor/board_name> ..\nmingw32-make\nto make the build verbose: mingw32-make verbose=1\nsupport\nall cmake variables that do not start with cmake_ and _ are defined in ${cmake_binary_dir}/polymcu_config.h which is generated at build time.\nthis include file can be included in your project to access cmake configuration variables.\nbasic variables\ncmake variable value description\nfirmware_heap integer size in bytes of the firmware heap\nfirmware_stack integer size in bytes of the firmware stack\nsupport_run_from_ram (0|1) define the firmware must be built to run from ram\nexternal_project_in_binary_dir (0|1) build the external project into the binary directory instead of the source directory\nsupport_debug_uart (none|itm|usb|1) define which uart support to use for debugging\ndebug_uart_baudrate integer debug uart baud rate (default: 115200)\nsupport_timer (0|1) add polymcu timer api\nsupport_timer_systick (0|1) use systick for polymcu timer api (default:1)\ntimer_task_max integer number maximum of polymcu timer tasks (default: 5)\nsupport_rtos string enable rtos support with the name of specified rtos\nsupport_watchdog (0|1) add polymcu watchdog api\nsupport_ram_vector_table (0|1) tell if the vector table lives in ram\ndevice variables\ncmake variable value description\nsupport_device_usb (0|1) add usb device support\nsupport_device_usb_serial (0|1) add serial usb device support\nsupport_device_usb_hid (0|1) add hid usb device support\nsupport_device_usb_dfu (0|1) add dfu usb device support\nsupport_device_usb_msc (0|1) add msc usb device support\nsupport_ble_central (0|1) add bluetooth low energy (ble) central support\nsupport_ble_peripheral (0|1) add bluetooth low energy (ble) peripheral support\nsupport_i2c (0|1) add i2c support\nsupport_spi (0|1) add spi support\nusb specific variables\ncmake variable value description\ndevice_usb_vendor_id integer usb vendor id\ndevice_usb_product_id integer usb product id\ndevice_usb_device_revision integer usb device revision\ndevice_usb_device_manufacturer string usb device manufacturer string\ndevice_usb_device_product string usb device product string\ndevice_usb_device_serial string usb device serial number string\ndevice_usb_hid_input_report_size integer size of the usb hid input report\ndevice_usb_hid_output_report_size integer size of the usb hid output report\ndevice_usb_hid_feature_report_size integer size of the usb hid feature report\nrtos variables\ncmake variable value description\nsupport_rtos_no_cmsis (0|1) disable cmsis wrapper of the rtos.\nrtos_clock integer frequency in hz of the processor\nrtos_tick integer when os_systick is not set we might need to provide a different tick\nrtos_task_count integer number of rtos task\nrtos_task_stack_size integer size in bytes of the task (excluding the main and private tasks)\nrtos_main_stack_size integer size in bytes of the main task\nrtos_idle_stack_size integer size in bytes of the idle task\nrtos_timer_stack_size integer size in bytes of the timer task\nrtos_timer_callback_count integer number of concurrent active timer callback functions\nrtos_task_private_stack_count integer number of private tasks\nrtos_task_private_stack_size integer size in bytes of the private task\nrtos_stack_watermark (0|1) disable/enable the stack watermark\ndevice specific variables\ncmake variable value description\nsupport_nxp_use_xtal (0|1) use external oscillator instead of the internal one\ndebug\nrun an application from ram\nto build the firmware to run from ram:\ncmake -dapplication=<application_vendor/application_name> -dsupport_run_from_ram=1 .. && make\ndebug with gdb\nstart the debugger server\npyocd-gdbserver\nstart the gdb client\narm-none-eabi-gdb <filepath_of_the_elf_application>\ntarget remote localhost:3333\ncontinue\nexamples of some gdb commands:\n(gdb) print $pc\n$1 = (void (*)()) 0x200000d8\n(gdb) print $sp\n$2 = (void *) 0x1fffff58\n(gdb) print/x *0x400\n$3 = 0x21004692\n(gdb) set {int}0x20000000 = 1\n(gdb) set arm force-mode thumb\n(gdb) display /10i 0x0\n1: x/10i 0x0\n0x0 <__vectors>:strhr0, [r0, #0]\n0x2 <__vectors+2>:movsr0, #0\n0x4 <__vectors+4>:lslsr1, r1, #24\n0x6 <__vectors+6>:movsr0, r0\n0x8 <__vectors+8>:lslsr1, r7, #24\n0xa <__vectors+10>:movsr0, r0\n0xc <__vectors+12>:addsr0, #37; 0x25\n0xe <__vectors+14>:movsr0, r0\n0x10 <__vectors+16>:movsr0, r0\n0x12 <__vectors+18>:movsr0, r0\n(gdb) display /10i $pc\n2: x/10i $pc\n=> 0x1a96 <arm_usart_send+18>:ldrr3, [sp, #16]\n0x1a98 <arm_usart_send+20>:ldrbr3, [r3, #0]\n0x1a9a <arm_usart_send+22>:movr0, r3\n0x1a9c <arm_usart_send+24>:bl0x2da8 <app_uart_put>\n0x1aa0 <arm_usart_send+28>:strr0, [sp, #12]\n0x1aa2 <arm_usart_send+30>:ldrr3, [sp, #12]\n0x1aa4 <arm_usart_send+32>:cmpr3, #0\n0x1aa6 <arm_usart_send+34>:bne.n0x1a96 <arm_usart_send+18>\n0x1aa8 <arm_usart_send+36>:ldrr3, [sp, #16]\n0x1aaa <arm_usart_send+38>:addsr3, #1\ndump memory into a file:\n(gdb) dump binary memory /tmp/gdb.bin 0x0 0x1000\ndebug uart settings\nall the board uarts are set with the following settings:\nbaud rate: 115200\ndata bits: 8\nstop bits: 1\nparity: none\nflow control: none", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000379, "year": null}, {"Unnamed: 0": 442, "autor": 442, "date": null, "content": "Syscoin Core integration/staging tree\nFor an immediately usable, binary version of the Syscoin Core software, see https://syscoincore.org/en/download/.\nFurther information about Syscoin Core is available in the doc folder.\nWhat is Syscoin?\nSyscoin is an experimental digital currency that enables instant payments to anyone, anywhere in the world. Syscoin uses peer-to-peer technology to operate with no central authority: managing transactions and issuing money are carried out collectively by the network. Syscoin Core is the name of open source software which enables the use of this currency.\nFor more information, as well as an immediately useable, binary version of the Syscoin Core software, see https://syscoin.org/, or read the original whitepaper.\nSyscoin is a merge-minable SHA256 coin which provides an array of useful services which leverage the bitcoin protocol and blockchain technology.\nHybrid layer 2 PoW/PoS consensus with bonded validator system (masternodes) ZDAG technology for point-of-sale speeds and probabilistic confirmations useful for microtransactions Trustless sidechain access to NEVM and back through a custom permissionless/trustless sidechain technology (SYSX bridge) https://github.com/syscoin/sysethereum Decentralized governance (blockchain pays for work via proposals and masternode votes) Digital asset creation and management. ZDAG is open-source and developed over the course of 12 months by Blockchain Foundry Inc, with external audit done over 6 months by Whiteblock. Performance report can be found here.\nGovernance formula: We have implemented a % decline schedule \u2014 starting the first month with 1500000 SYS and ending on the 24th month with 196708 SYS. After that period, the superblock starts with 151767 SYS a month and will decline 5% every year. Read more about it here: https://medium.com/@syscoin/syscoin-4-0-rewards-specifications-a3dc01d85adf.\nInteroptibility between UTXO assets and ERC20 NEVM account model through a trust-less, zero custodian, zero counterparty internal bridge. Documentation can be found here.\nFor more information, as well as an immediately useable, binary version of the Syscoin Core software, see https://syscoin.org/, or read the original whitepaper.\nSyscoin is a merge-minable SHA256 coin which provides an array of useful services which leverage the bitcoin protocol and blockchain technology. It enables turing complete smart contracts running in an NEVM (Network-enhanced Virtual Machine) to leverage bitcoin security through merged-mining. Scaling the technology will happen on layer 2 (zkRollups for NEVM and Lightning Networks for UTXO assets).\nBlock time: 150 seconds target\nHalving interval: 210240 (~1 year)\nRewards: 96.25 Syscoins per block deflated 5 percent per year\n10 percent to governance proposals\n90 percent split with miner/masternode of which:\n25 percent to miner\n75 percent to masternode\n50 percent of the transaction fees paid to masternode\nMasternode minimum subsidy(before seniority): 5.275 Syscoins (can not go below this amount even accounting for deflation)\nNEVM subsidy (EIP1559): 10.55 Syscoins (static, not deflating)\nSHA256 Proof of Work\nMineable either exclusively or via merge-mining any SHA256 PoW coin\nMasternode collateral requirement: 100000 Syscoins\nMasternode seniority: 35 percent increase after 210240 blocks (~1 year), 100 percent increase after 525600 blocks (~2.5 years)\nGovernance proposals payout schedule: every 17520 blocks (~1 month)\nGovernance funding per round (Approx. 2m Syscoins per month to start)\nGovernance funding gets 5% deflation per round (superblock). See formula below\nCodebase based off of latest Bitcoin Core (https://github.com/bitcoin/bitcoin)\nFor more information read the Syscoin whitepaper.\nLicense\nSyscoin Core is released under the terms of the MIT license. See COPYING for more information or see https://opensource.org/licenses/MIT.\nDevelopment Process\nThe master branch is regularly built (see doc/build-*.md for instructions) and tested, but it is not guaranteed to be completely stable. Tags are created regularly from release branches to indicate new official, stable release versions of Syscoin Core.\nThe https://github.com/syscoin-core/gui repository is used exclusively for the development of the GUI. Its master branch is identical in all monotree repositories. Release branches and tags do not exist, so please do not fork that repository unless it is for development reasons.\nThe contribution workflow is described in CONTRIBUTING.md and useful hints for developers can be found in doc/developer-notes.md.\nTesting\nTesting and code review is the bottleneck for development; we get more pull requests than we can review and test on short notice. Please be patient and help out by testing other people's pull requests, and remember this is a security-critical project where any mistake might cost people lots of money.\nAutomated Testing\nDevelopers are strongly encouraged to write unit tests for new code, and to submit new unit tests for old code. Unit tests can be compiled and run (assuming they weren't disabled in configure) with: make check. Further details on running and extending unit tests can be found in /src/test/README.md.\nThere are also regression and integration tests, written in Python. These tests can be run (if the test dependencies are installed) with: test/functional/test_runner.py\nThe CI (Continuous Integration) systems make sure that every pull request is built for Windows, Linux, and macOS, and that unit/sanity tests are run automatically.\nManual Quality Assurance (QA) Testing\nChanges should be tested by somebody other than the developer who wrote the code. This is especially important for large or high-risk changes. It is useful to add a test plan to the pull request description if testing the changes is not straightforward.\nTranslations\nChanges to translations as well as new translations can be submitted to Syscoin Core's Transifex page.\nTranslations are periodically pulled from Transifex and merged into the git repository. See the translation process for details on how this works.\nImportant: We do not accept translation changes as GitHub pull requests because the next pull from Transifex would automatically overwrite them again.", "link": "https://github.com/syscoin/syscoin", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "syscoin core integration/staging -----> tree !!! \nfor an immediately usable, binary version of the syscoin core software, see https://syscoincore.org/en/download/.\nfurther information about syscoin core is available in the doc folder.\nwhat is syscoin?\nsyscoin is an experimental digital currency that enables instant payments to anyone, anywhere in the world. syscoin uses peer-to-peer technology to operate with no central authority: managing transactions and issuing money are carried out collectively by the network. syscoin core is the name of open source software which enables the use of this currency.\nfor more information, as well as an immediately useable, binary version of the syscoin core software, see https://syscoin.org/, or read the original whitepaper.\nsyscoin is a merge-minable sha256 coin which provides an array of useful services which leverage the bitcoin protocol and blockchain technology.\nhybrid layer 2 pow/pos consensus with bonded validator system (masternodes) zdag technology for point-of-sale speeds and probabilistic confirmations useful for microtransactions trustless sidechain access to nevm and back through a custom permissionless/trustless sidechain technology (sysx bridge) https://github.com/syscoin/sysethereum decentralized governance (blockchain pays for work via proposals and masternode votes) digital asset creation and management. zdag is open-source and developed over the course of 12 months by blockchain foundry inc, with external audit done over 6 months by whiteblock. performance report can be found here.\ngovernance formula: we have implemented a % decline schedule \u2014 starting the first month with 1500000 sys and ending on the 24th month with 196708 sys. after that period, the superblock starts with 151767 sys a month and will decline 5% every year. read more about it here: https://medium.com/@syscoin/syscoin-4-0-rewards-specifications-a3dc01d85adf.\ninteroptibility between utxo assets and erc20 nevm account model through a trust-less, zero custodian, zero counterparty internal bridge. documentation can be found here.\nfor more information, as well as an immediately useable, binary version of the syscoin core software, see https://syscoin.org/, or read the original whitepaper.\nsyscoin is a merge-minable sha256 coin which provides an array of useful services which leverage the bitcoin protocol and blockchain technology. it enables turing complete smart contracts running in an nevm (network-enhanced virtual machine) to leverage bitcoin security through merged-mining. scaling the technology will happen on layer 2 (zkrollups for nevm and lightning networks for utxo assets).\nblock time: 150 seconds target\nhalving interval: 210240 (~1 year)\nrewards: 96.25 syscoins per block deflated 5 percent per year\n10 percent to governance proposals\n90 percent split with miner/masternode of which:\n25 percent to miner\n75 percent to masternode\n50 percent of the transaction fees paid to masternode\nmasternode minimum subsidy(before seniority): 5.275 syscoins (can not go below this amount even accounting for deflation)\nnevm subsidy (eip1559): 10.55 syscoins (static, not deflating)\nsha256 proof of work\nmineable either exclusively or via merge-mining any sha256 pow coin\nmasternode collateral requirement: 100000 syscoins\nmasternode seniority: 35 percent increase after 210240 blocks (~1 year), 100 percent increase after 525600 blocks (~2.5 years)\ngovernance proposals payout schedule: every 17520 blocks (~1 month)\ngovernance funding per round (approx. 2m syscoins per month to start)\ngovernance funding gets 5% deflation per round (superblock). see formula below\ncodebase based off of latest bitcoin core (https://github.com/bitcoin/bitcoin)\nfor more information read the syscoin whitepaper.\nlicense\nsyscoin core is released under the terms of the mit license. see copying for more information or see https://opensource.org/licenses/mit.\ndevelopment process\nthe master branch is regularly built (see doc/build-*.md for instructions) and tested, but it is not guaranteed to be completely stable. tags are created regularly from release branches to indicate new official, stable release versions of syscoin core.\nthe https://github.com/syscoin-core/gui repository is used exclusively for the development of the gui. its master branch is identical in all monotree repositories. release branches and tags do not exist, so please do not fork that repository unless it is for development reasons.\nthe contribution workflow is described in contributing.md and useful hints for developers can be found in doc/developer-notes.md.\ntesting\ntesting and code review is the bottleneck for development; we get more pull requests than we can review and test on short notice. please be patient and help out by testing other people's pull requests, and remember this is a security-critical project where any mistake might cost people lots of money.\nautomated testing\ndevelopers are strongly encouraged to write unit tests for new code, and to submit new unit tests for old code. unit tests can be compiled and run (assuming they weren't disabled in configure) with: make check. further details on running and extending unit tests can be found in /src/test/readme.md.\nthere are also regression and integration tests, written in python. these tests can be run (if the test dependencies are installed) with: test/functional/test_runner.py\nthe ci (continuous integration) systems make sure that every pull request is built for windows, linux, and macos, and that unit/sanity tests are run automatically.\nmanual quality assurance (qa) testing\nchanges should be tested by somebody other than the developer who wrote the code. this is especially important for large or high-risk changes. it is useful to add a test plan to the pull request description if testing the changes is not straightforward.\ntranslations\nchanges to translations as well as new translations can be submitted to syscoin core's transifex page.\ntranslations are periodically pulled from transifex and merged into the git repository. see the translation process for details on how this works.\nimportant: we do not accept translation changes as github pull requests because the next pull from transifex would automatically overwrite them again.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000442, "year": null}, {"Unnamed: 0": 468, "autor": 468, "date": null, "content": "tcMenu - A menu library and designer for Arduino and mbed with IoT capabilities\nA menu library and designer UI for Arduino and mbed that is modular enough to support different input methods, display modules and IoT / remote control methods. TcMenu is more than just an Arduino menu library, think of it as a framework for building IoT applications that includes the ability to render menus locally onto a display.\nInitially, you can use the menu designer UI that is packaged with every release, and available for Windows, macOS, and Linux. The designer UI takes care of building the core menu code and putting any callback functions into your sketch file. Think of the designer like a form designer in the desktop domain. Furthermore, It's non destructive on the sketch file, so can be round tripped during development.\nTheCodersCorner.com invest a lot of time and resources into making this open source product which is used by literally thousands of users. We don't presently sell hardware or have any other income streams from it, we ask that especially commercial users consider making a voluntary contribution to help keep us going using the sponsor button.\nIn any fork, please ensure all text up to here is left unaltered.\nDocumentation\nUI user guide, getting started and other documentation\nFull API embedded documentation\nQuestions, community forum and support\nThere is a forum where questions can be asked, but the rules of engagement are: this is my hobby, I make it available because it helps others. Don't expect immediate answers, make sure you've recreated the problem in a simple sketch that you can send to me. Please consider making at least a one time donation using the sponsor link above before using the forum.\nTCC Libraries community discussion forum\nConsultancy pages on the coders corner\nI also monitor the Arduino forum [https://forum.arduino.cc/], Arduino related questions can be asked there too.\nPackaged installation for Windows, Linux, and MacOS.\nReleases are directly available from the releases page, there is a signed Windows version, notarized macOS version, and a package for Linux:\nGet the latest TcMenu Designer release\nAlthough most will use the above packages, it's also possible to build from source, full instructions are in the tcMenuGenerator folder. We ask that you only build from source for your own use.\nHere's a couple of screen-shots of the designer UI - runs on Windows, macOS and Linux:\nand embedCONTROL desktop that can control menu based apps - runs on Windows, macOS and Linux:\nGenerating a menu from the UI for the impatient\nIf you don't want to read the above documentation this gives a very quick start. Open the tcMenu Designer UI and set up your Arduino directory in \"Edit -> General Settings\", then check the \"Library Versions\" tab to ensure the embedded libraries are installed / up to date.\nOnce the tcMenu library directory is located, the \"File -> Examples\" menu will load with all the exmaples. Load the example closest to the hardware you have. Once it's open, you'll see the menu tree structure on the left, and the details for each menu when selected on the right. Below the menu tree are buttons that manage items in the menu tree.\nOnce you've arranged your menu using the UI how you'd like it, choose Code -> ID & Eeprom analyser from the menu to check that you've not got any overlapping ranges, then choose Code -> Generate from the menu, choose appropriate hardware arrangements and hit generate.\nThe Generator is capable of round trip development too - most of the code is offloaded into associated CPP and Header files.\nWhere's all the source live\nThe designer UI code base and plugins for 2.0 onwards are located in this repository, the 1.7 plugins were here [https://github.com/davetcc/tcMenuXmlPlugins]. The tcMenu library is in [https://github.com/davetcc/tcMenuLib]. The designer, library and shipped plugins are all Apache licensed.\nTcMenu still supports Uno with LiquidCrystal dfRobot shield or Ssd1306Ascii\nWe try to keep Uno viable for tcMenu. However, there are limitations to what we can do. You can run a full menu on an Uno, but it's unlikely that the remote Ethernet support will fit. For anything that includes remote control support, we recommend at least 64K of flash memory. We store the menu items in static RAM where it's supported by the hardware, to further reduce memory on the board.\nInput and display technologies\nHere are a few examples of how the menu can look with version 2.0 of our menu library on Arduino, ESP, and mbed:\nSupport for rotary encoders, digital/analog joysticks and touch buttons\nWe fully support rotary encoder based input with no need for any additional components in many cases. You can even connect your rotary encoder on a PCF8574 or MCP23017. Further, we even support more than one encoder.\nYou can configure 3 or more buttons to work like a digital joystick using button based rotary encoder emulation (Up, Down and OK buttons with optional left and right) on either board pins, i2c expander, shift register. DfRobot analog input style buttons. Either DfRobot, or other analog ladder (configurable in code).\nWe also support the ESP32 touch pad interface, allowing up to 9 touch buttons to be used for menu input, they currently configure as per digital joystick.\nSupport for matrix keyboards\nMatrix Keyboards of configurable size and key combination. Pre-canned options for 4x3 and 4x4 layouts. Most of the core functions work with a matrix keyboard.\nSupport for touch screens\nFrom 2.0 onwards we'll support touch screen interfaces. We have built the support so that we can add many devices later, but to start with we will support resistive touch screens using 4 inputs, and the STM32 BSP provided touch screen interface.\nDrawing to LiquidCrystal (i2c or direct)\nWe have a fork LiquidCrystal for 20x4 or 16x2 displays - can be either directly connected, over an i2c sheild (PCF8574, MCP23017) or on a shift register. Our version of the library integrates better with task manager, yielding frequently.\nAdafruit_GFX integration for many displays\nMost libraries that are compatible with Adafruit_GFX will work with tcMenu, we've tested with the following TFT's ILI9341, ST7735 and also Nokia 5110 display. We even have a quick start option that helps you get started with this option.\nFor mbed RTOS 5/6 we have a custom Adafruit_GFX OLED driver https://github.com/davetcc/Adafruit-GFX-mbed-fork that supports SSD1306, SH1106.\nU8G2 integration for mono display\nWe can render onto most buffered displays using this library. Tested with OLED devices such as SSD1306 and SH1106. We can even provide a custom I2C byte function that yields to task manager frequently, making it work better with task manager, and correctly yield on ESP boards too.\nTFT_eSPI and STM32 LTDC framebuffer integration\nFrom 2.0 onwards we'll support TFT_eSPI and STM32 LTDC framebuffer based BSP functions to provide very high performance display rendering, we've tested with these two options on both ESP32 and STM32F429, the results were highly impressive.\nNo local input or display techonologies\nShould your app not need any local display or input technologies, you can set up tcMenu so that it does not have local input or display, or you could have a single switch or LED on the device and manage it manually. In this case you'd use the below IoT support to manage the device remotely.\nRemote IoT support on Ethernet, WiFi, Serial and Bluetooth/BLE\nThis menu library provides complete IoT remote control, presently over serial and ethernet. We've tested the serial support with both USB serial and Bluetooth, both work acceptably well. The full menu structure is sent over the wire and the Java API provides it as a tree that can be manipulated. There is also a defined protocol for other languages. In addition to this the menu can be programatically manipulated very easily on the device.\nRS232 endpoint that supports full control of the menu items using a Java API - example app included.\nEthernet endpoint that supports either Ethernet2 library or UipEthernet.\nEthernet endpoint for mbed that supports the mbed socket implementation.\nESP8266 and ESP32 based WiFi both supported.\nReady built remote control for tcMenu - embedCONTROL\nWe are transitioning to a new IoT control UI where the core product is based on an OpenSource framework called embedCONTROL within this repository. It will be released in stages, firstly for desktop Windows, MacOS, Linux, then for mobile, Android first followed by iOS. While this transition is complete you can continue to use the old Windows App store version.\n[https://www.thecoderscorner.com/products/arduino-libraries/tc-menu/tcmenu-remote-connection-arduino-desktop/]\nAccessing TcMenu remotely using an API\nJava / JVM API\nThere is a java API for accessing the menu remotely, source includes JavaDoc to help getting started. There is an example JavaFX UI built with it within the above Repo. Include the following into your maven build file:\n<dependency>\n<groupId>com.thecoderscorner.tcmenu</groupId>\n<artifactId>tcMenuJavaAPI</artifactId>\n<version>2.2.4</version>\n</dependency>\nWorking with menus using the CLI\nThe most recent builds of TcMenu Designer include a CLI that has support for creating projects, adding and removing items, verifying and generating menus. Building and Generating menus from the CLI\nComing Soon C# / .NET API\nWe are currently quite far along on a C# port of the API. There's an issue in the issue track for the port and we'll let you know when it's further along.\nLoading and saving menu items\ntcMenu can also save menu item state to EEPROM storage. On AVR that will generally be internal EEPROM, on 32 bit boards generally an AT24 i2c EEPROM.", "link": "https://github.com/davetcc/tcMenu", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "tcmenu - a menu library and designer for arduino and mbed with iot capabilities\na menu library and designer ui for arduino and mbed that is modular enough to support different input methods, display modules and iot / remote control methods. tcmenu is more than just an arduino menu library, think of it as a framework for building iot applications that includes the ability to render menus locally onto a display.\ninitially, you can use the menu designer ui that is packaged with every release, and available for windows, macos, and linux. the designer ui takes care of building the core menu code and putting any callback functions into your sketch file. think of the designer like a form designer in the desktop domain. furthermore, it's non destructive on the sketch file, so can be round tripped during development.\nthecoderscorner.com invest a lot of time and resources into making this open source product which is used by literally thousands of users. we don't presently sell hardware or have any other income streams from it, we ask that especially commercial users consider making a voluntary contribution to help keep us going using the sponsor button.\nin any fork, please ensure all text up to here is left unaltered.\ndocumentation\nui user guide, getting started and other documentation\nfull api embedded documentation\nquestions, community forum and support\nthere is a forum where questions can be asked, but the rules of engagement are: this is my hobby, i make it available because it helps others. don't expect immediate answers, make sure you've recreated the problem in a simple sketch that you can send to me. please consider making at least a one time donation using the sponsor link above before using the forum.\ntcc libraries community discussion forum\nconsultancy pages on the coders corner\ni also monitor the arduino forum [https://forum.arduino.cc/], arduino related questions can be asked there too.\npackaged installation for windows, linux, and macos.\nreleases are directly available from the releases page, there is a signed windows version, notarized macos version, and a package for linux:\nget the latest tcmenu designer release\nalthough most will use the above packages, it's also possible to build from source, full instructions are in the tcmenugenerator folder. we ask that you only build from source for your own use.\nhere's a couple of screen-shots of the designer ui - runs on windows, macos and linux:\nand embedcontrol desktop that can control menu based apps - runs on windows, macos and linux:\ngenerating a menu from the ui for the impatient\nif you don't want to read the above documentation this gives a very quick start. open the tcmenu designer ui and set up your arduino directory in \"edit -> general settings\", then check the \"library versions\" tab to ensure the embedded libraries are installed / up to date.\nonce the tcmenu library directory is located, the \"file -> examples\" menu will load with all the exmaples. load the example closest to the hardware you have. once it's open, you'll see the menu -----> tree !!!  structure on the left, and the details for each menu when selected on the right. below the menu tree are buttons that manage items in the menu tree.\nonce you've arranged your menu using the ui how you'd like it, choose code -> id & eeprom analyser from the menu to check that you've not got any overlapping ranges, then choose code -> generate from the menu, choose appropriate hardware arrangements and hit generate.\nthe generator is capable of round trip development too - most of the code is offloaded into associated cpp and header files.\nwhere's all the source live\nthe designer ui code base and plugins for 2.0 onwards are located in this repository, the 1.7 plugins were here [https://github.com/davetcc/tcmenuxmlplugins]. the tcmenu library is in [https://github.com/davetcc/tcmenulib]. the designer, library and shipped plugins are all apache licensed.\ntcmenu still supports uno with liquidcrystal dfrobot shield or ssd1306ascii\nwe try to keep uno viable for tcmenu. however, there are limitations to what we can do. you can run a full menu on an uno, but it's unlikely that the remote ethernet support will fit. for anything that includes remote control support, we recommend at least 64k of flash memory. we store the menu items in static ram where it's supported by the hardware, to further reduce memory on the board.\ninput and display technologies\nhere are a few examples of how the menu can look with version 2.0 of our menu library on arduino, esp, and mbed:\nsupport for rotary encoders, digital/analog joysticks and touch buttons\nwe fully support rotary encoder based input with no need for any additional components in many cases. you can even connect your rotary encoder on a pcf8574 or mcp23017. further, we even support more than one encoder.\nyou can configure 3 or more buttons to work like a digital joystick using button based rotary encoder emulation (up, down and ok buttons with optional left and right) on either board pins, i2c expander, shift register. dfrobot analog input style buttons. either dfrobot, or other analog ladder (configurable in code).\nwe also support the esp32 touch pad interface, allowing up to 9 touch buttons to be used for menu input, they currently configure as per digital joystick.\nsupport for matrix keyboards\nmatrix keyboards of configurable size and key combination. pre-canned options for 4x3 and 4x4 layouts. most of the core functions work with a matrix keyboard.\nsupport for touch screens\nfrom 2.0 onwards we'll support touch screen interfaces. we have built the support so that we can add many devices later, but to start with we will support resistive touch screens using 4 inputs, and the stm32 bsp provided touch screen interface.\ndrawing to liquidcrystal (i2c or direct)\nwe have a fork liquidcrystal for 20x4 or 16x2 displays - can be either directly connected, over an i2c sheild (pcf8574, mcp23017) or on a shift register. our version of the library integrates better with task manager, yielding frequently.\nadafruit_gfx integration for many displays\nmost libraries that are compatible with adafruit_gfx will work with tcmenu, we've tested with the following tft's ili9341, st7735 and also nokia 5110 display. we even have a quick start option that helps you get started with this option.\nfor mbed rtos 5/6 we have a custom adafruit_gfx oled driver https://github.com/davetcc/adafruit-gfx-mbed-fork that supports ssd1306, sh1106.\nu8g2 integration for mono display\nwe can render onto most buffered displays using this library. tested with oled devices such as ssd1306 and sh1106. we can even provide a custom i2c byte function that yields to task manager frequently, making it work better with task manager, and correctly yield on esp boards too.\ntft_espi and stm32 ltdc framebuffer integration\nfrom 2.0 onwards we'll support tft_espi and stm32 ltdc framebuffer based bsp functions to provide very high performance display rendering, we've tested with these two options on both esp32 and stm32f429, the results were highly impressive.\nno local input or display techonologies\nshould your app not need any local display or input technologies, you can set up tcmenu so that it does not have local input or display, or you could have a single switch or led on the device and manage it manually. in this case you'd use the below iot support to manage the device remotely.\nremote iot support on ethernet, wifi, serial and bluetooth/ble\nthis menu library provides complete iot remote control, presently over serial and ethernet. we've tested the serial support with both usb serial and bluetooth, both work acceptably well. the full menu structure is sent over the wire and the java api provides it as a tree that can be manipulated. there is also a defined protocol for other languages. in addition to this the menu can be programatically manipulated very easily on the device.\nrs232 endpoint that supports full control of the menu items using a java api - example app included.\nethernet endpoint that supports either ethernet2 library or uipethernet.\nethernet endpoint for mbed that supports the mbed socket implementation.\nesp8266 and esp32 based wifi both supported.\nready built remote control for tcmenu - embedcontrol\nwe are transitioning to a new iot control ui where the core product is based on an opensource framework called embedcontrol within this repository. it will be released in stages, firstly for desktop windows, macos, linux, then for mobile, android first followed by ios. while this transition is complete you can continue to use the old windows app store version.\n[https://www.thecoderscorner.com/products/arduino-libraries/tc-menu/tcmenu-remote-connection-arduino-desktop/]\naccessing tcmenu remotely using an api\njava / jvm api\nthere is a java api for accessing the menu remotely, source includes javadoc to help getting started. there is an example javafx ui built with it within the above repo. include the following into your maven build file:\n<dependency>\n<groupid>com.thecoderscorner.tcmenu</groupid>\n<artifactid>tcmenujavaapi</artifactid>\n<version>2.2.4</version>\n</dependency>\nworking with menus using the cli\nthe most recent builds of tcmenu designer include a cli that has support for creating projects, adding and removing items, verifying and generating menus. building and generating menus from the cli\ncoming soon c# / .net api\nwe are currently quite far along on a c# port of the api. there's an issue in the issue track for the port and we'll let you know when it's further along.\nloading and saving menu items\ntcmenu can also save menu item state to eeprom storage. on avr that will generally be internal eeprom, on 32 bit boards generally an at24 i2c eeprom.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000468, "year": null}, {"Unnamed: 0": 544, "autor": 544, "date": null, "content": "Mobius\noneM2M IoT Server Platform\nVersion\n2.4.x (2.4.42)\nIntroduction\nMobius is the open source IoT server platform based on the oneM2M (http://www.oneM2M.org) standard. As oneM2M specifies, Mobius provides common services functions (e.g. registration, data management, subscription/notification, security) as middleware to IoT applications of different service domains. Not just oneM2M devices, but also non-oneM2M devices (i.e. by oneM2M interworking specifications and KETI TAS) can connect to Mobius.\nCertification\nMobius has been received certification of \u2018oneM2M standard\u2019 by TTA (Telecommunications Technology Association). oneM2M Certification guarantees that oneM2M products meet oneM2M Specification and Test requirements which ensure interoperability. As Mobius is certified, it will be used as a golden sample to validate test cases and testing system.\nTRSL (Test Requirements Status List) is available on oneM2M certification website (http://www.onem2mcert.com/sub/sub05_01.php).\nSystem Stucture\nIn oneM2M architecture, Mobius implements the IN-CSE which is the cloud server in the infrastructure domain. IoT applications communicate with field domain IoT gateways/devices via Mobius.\nConnectivity Stucture\nTo enable Internet of Things, things are connected to &Cube via TAS (Thing Adaptation Software), then &Cube communicate with Mobius over oneM2M standard APIs. Also IoT applications use oneM2M standard APIs to retrieve thing data control things of Mobius.\nSoftware Architecture\nSupported Protocol Bindings\nHTTP\nCoAP\nMQTT\nWebSocket\nInstallation\nThe Mobius is based on Node.js framework and uses MySQL for database.\nMySQL Server\nThe MySQL is an open source RDB database so that it is free and ligth. And RDB is very suitable for storing tree data just like oneM2M resource stucture. Most of nCube-Rosemary will work in a restricted hardware environment and the MySQL can work in most of embeded devices.\nNode.js\nNode.js\u00ae is a JavaScript runtime built on Chrome's V8 JavaScript engine. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient. Node.js' package ecosystem, npm, is the largest ecosystem of open source libraries in the world. Node.js is very powerful in service impelementation because it provide a rich and free web service API. So, we use it to make RESTful API base on the oneM2M standard.\nMosquitto\nEclipse Mosquitto\u2122 is an open source (EPL/EDL licensed) message broker that implements the MQTT protocol versions 3.1 and 3.1.1. MQTT provides a lightweight method of carrying out messaging using a publish/subscribe model. This makes it suitable for \"Internet of Things\" messaging such as with low power sensors or mobile devices such as phones, embedded computers or microcontrollers like the Arduino.\nMobius\nMobius source codes are written in javascript. So they don't need any compilation or installation before running.\nMobius Docker Version\nWe deploy Mobius as a Docker image using the virtualization open source tool Docker.\nMobius_Docker\nConfiguration\nImport SQL script\nAfter installation of MySQL server, you need the DB Schema for storing oneM2M resources in Mobius. You can find this file in the following Mobius source directory.\n[Mobius home]/mobius/mobiusdb.sql\nRun Mosquitto MQTT broker\nmosquitto -v\nOpen the Mobius source home directory\nInstall dependent libraries as below\nnpm install\nModify the configuration file \"conf.json\" per your setting\n{\n\"csebaseport\": \"7579\", //Mobius HTTP hosting port\n\"dbpass\": \"*******\" //MySQL root password\n}\nRun\nUse node.js application execution command as below\nnode mobius.js\nLibrary Dependencies\nThis is the list of library dependencies for Mobius\nbody-parser\ncbor\ncoap\ncrypto\nevents\nexpress\nfile-stream-rotator\nfs\nhttp\nhttps\nip\njs2xmlparser\nmerge\nmorgan\nmqtt\nmysql\nshortid\nurl\nutil\nwebsocket\nxml2js\nxmlbuilder\nDocument\nIf you want more details please download the full installation guide document.\nAuthor\nJaeho Kim (jhkim@keti.re.kr) Il Yeup Ahn (iyahn@keti.re.kr)", "link": "https://github.com/IoTKETI/Mobius", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "mobius\nonem2m iot server platform\nversion\n2.4.x (2.4.42)\nintroduction\nmobius is the open source iot server platform based on the onem2m (http://www.onem2m.org) standard. as onem2m specifies, mobius provides common services functions (e.g. registration, data management, subscription/notification, security) as middleware to iot applications of different service domains. not just onem2m devices, but also non-onem2m devices (i.e. by onem2m interworking specifications and keti tas) can connect to mobius.\ncertification\nmobius has been received certification of \u2018onem2m standard\u2019 by tta (telecommunications technology association). onem2m certification guarantees that onem2m products meet onem2m specification and test requirements which ensure interoperability. as mobius is certified, it will be used as a golden sample to validate test cases and testing system.\ntrsl (test requirements status list) is available on onem2m certification website (http://www.onem2mcert.com/sub/sub05_01.php).\nsystem stucture\nin onem2m architecture, mobius implements the in-cse which is the cloud server in the infrastructure domain. iot applications communicate with field domain iot gateways/devices via mobius.\nconnectivity stucture\nto enable internet of things, things are connected to &cube via tas (thing adaptation software), then &cube communicate with mobius over onem2m standard apis. also iot applications use onem2m standard apis to retrieve thing data control things of mobius.\nsoftware architecture\nsupported protocol bindings\nhttp\ncoap\nmqtt\nwebsocket\ninstallation\nthe mobius is based on node.js framework and uses mysql for database.\nmysql server\nthe mysql is an open source rdb database so that it is free and ligth. and rdb is very suitable for storing -----> tree !!!  data just like onem2m resource stucture. most of ncube-rosemary will work in a restricted hardware environment and the mysql can work in most of embeded devices.\nnode.js\nnode.js\u00ae is a javascript runtime built on chrome's v8 javascript engine. node.js uses an event-driven, non-blocking i/o model that makes it lightweight and efficient. node.js' package ecosystem, npm, is the largest ecosystem of open source libraries in the world. node.js is very powerful in service impelementation because it provide a rich and free web service api. so, we use it to make restful api base on the onem2m standard.\nmosquitto\neclipse mosquitto\u2122 is an open source (epl/edl licensed) message broker that implements the mqtt protocol versions 3.1 and 3.1.1. mqtt provides a lightweight method of carrying out messaging using a publish/subscribe model. this makes it suitable for \"internet of things\" messaging such as with low power sensors or mobile devices such as phones, embedded computers or microcontrollers like the arduino.\nmobius\nmobius source codes are written in javascript. so they don't need any compilation or installation before running.\nmobius docker version\nwe deploy mobius as a docker image using the virtualization open source tool docker.\nmobius_docker\nconfiguration\nimport sql script\nafter installation of mysql server, you need the db schema for storing onem2m resources in mobius. you can find this file in the following mobius source directory.\n[mobius home]/mobius/mobiusdb.sql\nrun mosquitto mqtt broker\nmosquitto -v\nopen the mobius source home directory\ninstall dependent libraries as below\nnpm install\nmodify the configuration file \"conf.json\" per your setting\n{\n\"csebaseport\": \"7579\", //mobius http hosting port\n\"dbpass\": \"*******\" //mysql root password\n}\nrun\nuse node.js application execution command as below\nnode mobius.js\nlibrary dependencies\nthis is the list of library dependencies for mobius\nbody-parser\ncbor\ncoap\ncrypto\nevents\nexpress\nfile-stream-rotator\nfs\nhttp\nhttps\nip\njs2xmlparser\nmerge\nmorgan\nmqtt\nmysql\nshortid\nurl\nutil\nwebsocket\nxml2js\nxmlbuilder\ndocument\nif you want more details please download the full installation guide document.\nauthor\njaeho kim (jhkim@keti.re.kr) il yeup ahn (iyahn@keti.re.kr)", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000544, "year": null}, {"Unnamed: 0": 553, "autor": 553, "date": null, "content": "Nordic nRF51 & nRF52 product line\nEHAL (Embedded Hardware Abstraction Library)\nNOTE : This library is now replaced by https://github.com/IOsonata/IOsonata\nThis is a multi-archtecture multi-platform Hardware Abstraction Library. The main purpose is to create a layer of generic peripherals and devices interface (drivers) that is common across MCU architectures and platforms. This will allow creation of more reusable and portable applications (firmware for most part) that can be moved form on MCU to an other with minimal changes.\nSee https://embeddedsoftdev.blogspot.ca/p/h.html for more detail installation and setup of development environment.\nLibrary online documentation located here https://www.i-syst.com/docs/EHAL/\nLibrary source code on GitHub at https://github.com/I-SYST/EHAL\nNeed to port a specific driver or MCU ? Put your request in issues. It will get done eventually. If you want to have it faster, a fee based port is available.\nexternal vendors' SDK and library required :\nCMSIS : ARM CMSIS SDK for all ARM platform\nnRF5_SDK : Nordic nRF5x Bluetooth Low Energy\nnrf5_SDK_Mesh : Nordic nRF5 SDK for Bluetoth Mesh\nMicro-ECC : Encryption library\nICM-20948 Motion_Driver : Create a user at https://www.invensense.com/developers. Under \"Downloads\" download \"DK-20948 eMD-SmartMotion ...\". Unzip the downloaded file and navigate to EMD-Core/sources. Copy the folder Invn to external/Invn as indected in the folder tree bellow.\nKSDK : Kinetis SDK\nBSEC : Bosch Sensortec Environmental Cluster (BSEC) Software for #BME680 environmental sensor. BSEC is needed for calculating Air Quality Index. Go to https://www.bosch-sensortec.com/bst/products/all_products/bsec at the end of the page. Select checkbox to accept license terms to download. Unzip the the downloaded file. Rename the extracted folder BSEC and copy the whole folder to external as indicated in the folder tree bellow.\nBLYST Nano sensor board\nEHAL folder structure\nThe way the EHAL folder is structure is simple. The deeper you go inside the more it is specific the the architecture or platform. The parent folder contains all that is commonly available to the child folder. Which means, source file from child folder can access any source in the upper parent folder but not the other way around. This is the way to keep the abstraction separated from implementation and easier to keep track of things.\nThere are 2 main libraries in the EHAL for each ARM based MCU.\nCMSIS : This contains the startup code, main interrupt vector and RTOS if available. This lib is required for all firmware\nEHAL : This is the main hardware abstraction library. It contains all peripheral drivers, SPI, I2C, UART, Timer, BLE,...\n/your_root - Development root directory\n|-- external - Contains downloaded SDKs from silicon vendors\n| |-- CMSIS - ARM CMSIS SDK for all ARM platform (https://github.com/ARM-software/CMSIS_5)\n| |-- nRF5_SDK - Latest Nordic SDK (https://developer.nordicsemi.com)\n| |-- nrf5_SDK_Mesh - Latest Nordic SDK for Mesh (https://www.nordicsemi.com/eng/nordic/Products/nRF5-SDK-for-Mesh/nRF5-SDK-for-Mesh/62377)\n| |---nRF5_SDK_12 - Last version of Nordick SDK12 for nRF51 series\n| |-- Micro-ECC - Micro-ECC (download from https://github.com/kmackay/micro-ecc)\n| |-- KSDK - Kinetis SDK\n| |-- BSEC - Bosch Sensortec Environmental Cluster (BSEC) Software (https://www.bosch-sensortec.com/bst/products/all_products/bsec) for #BME680\n| |-- MPL - Invensense Motion Driver (download https://www.invensense.com/developers)\n| | |-- core - Copy core from motion_driver_6.12/arm/STM32F4_MD6/Projects/eMD6 here\n| | |-- lib\n| | | |-- m0 - Unzip the liblibmplmpu_m0.zip, copy liblibmplmpu.a here\n| | | |-- m3 - Unzip the liblibmplmpu_m3.zip, copy liblibmplmpu.a here\n| | | |-- m4hfp - Unzip the liblibmplmpu_m4_hardfp.zip, copy liblibmplmpu.a here\n| | | |-- m4nfp - Unzip the liblibmplmpu_m4_npfp.zip, copy liblibmplmpu.a here\n| | | |-- m4sfp - Unzip the liblibmplmpu_m4_softfp.zip, copy liblibmplmpu.a here\n| |-- Invn - Invensense SmartMotion Driver (download https://www.invensense.com/developers)\n| | |-- Devices\n| | |...\n| |...\n| |\n|-- EHAL - Put the EHAL here\n| |-- docs - Contains EHAL Doxygen documentations. (https://i-syst.github.io/docs/EHAL/)\n| |-- include - Generic include common to all platform\n| | |-- bluetooth - Generic definition for Bluetooth\n| | |-- converters - Generic definition for ADV, DAC, etc...\n| | |-- coredev - Generic core processor builtin devices such as i2c, uart, spi, timer, etc...\n| | |-- miscdev - Generic definition for other non categorized devices\n| | |-- sensors - Generic definition for al sort of sensors (environmental, motion, etc...)\n| | |-- usb - Generic definition for USB\n| |-- src - Generic implementation source common to all platform\n| |\n| |-- ARM - Cortex-M series based MCU\n| | |-- include - Common include for all ARM platform\n| | |-- src - Common source for all ARM platform\n| | |\n| | |-- NXP - NXP based MCU\n| | | |-- LPC11xx - LPC11xx processor workspace\n| | | | |-- CMSIS - Static library containing startup code, interrupt vector, etc...\n| | | | |-- EHAL - Embedded Hardware Abstraction Library project for NXP\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - Example code\n| | | | |\n| | | |-- LPC17xx - LPC17xx processor workspace\n| | | | |-- CMSIS - Static library containing startup code, interrupt vector, etc...\n| | | | |-- EHAL - Embedded Hardware Abstraction Library project for NXP\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - Example code\n| | |\n| | |-- Nordic - Nordic Semiconductor based MCU\n| | | |-- nRF51 - nRF51 processor workspace\n| | | | |-- CMSIS - Static library containing startup code, interrupt vector, etc...\n| | | | |-- EHAL - Embedded Hardware Abstraction Library project for Nordic\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - exemple projects\n| | | |-- nRF52 - nRF52 processor workspace\n| | | | |-- CMSIS - Static library containing startup code, interrupt vector, etc...\n| | | | |-- EHAL - Embedded Hardware Abstraction Library project for Nordic\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - exemple projects\n| | |\n| | |-- ST - ST based MCU\n| | | |-- STM32F0xx\n| | | |-- STM32F4xx\n| | | |-- STM32L0xx\n| | |\n| | |-- TI - Texas Instruments based MCU\n| | | |-- CC3200\n| | | | |-- CMSIS\n| | | | |-- EHAL\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - Example code\n| | |\n| | |-- Freescale - Freescale based MCU\n| | | |-- MKL\n| | | | |-- CMSIS\n| | | | |-- EHAL\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - Example code\n| |...\n| |-- Linux\n| | |...\n| |-- OSX\n| | |...\n| |-- Win\n| | |...\n| ...\nAll EHAL projects are Eclipse native project with GCC compiler. For Eclipse & Gcc installations, follow this blog page http://embeddedsoftdev.blogspot.ca/p/eclipse.html.", "link": "https://github.com/I-SYST/EHAL", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "nordic nrf51 & nrf52 product line\nehal (embedded hardware abstraction library)\nnote : this library is now replaced by https://github.com/iosonata/iosonata\nthis is a multi-archtecture multi-platform hardware abstraction library. the main purpose is to create a layer of generic peripherals and devices interface (drivers) that is common across mcu architectures and platforms. this will allow creation of more reusable and portable applications (firmware for most part) that can be moved form on mcu to an other with minimal changes.\nsee https://embeddedsoftdev.blogspot.ca/p/h.html for more detail installation and setup of development environment.\nlibrary online documentation located here https://www.i-syst.com/docs/ehal/\nlibrary source code on github at https://github.com/i-syst/ehal\nneed to port a specific driver or mcu ? put your request in issues. it will get done eventually. if you want to have it faster, a fee based port is available.\nexternal vendors' sdk and library required :\ncmsis : arm cmsis sdk for all arm platform\nnrf5_sdk : nordic nrf5x bluetooth low energy\nnrf5_sdk_mesh : nordic nrf5 sdk for bluetoth mesh\nmicro-ecc : encryption library\nicm-20948 motion_driver : create a user at https://www.invensense.com/developers. under \"downloads\" download \"dk-20948 emd-smartmotion ...\". unzip the downloaded file and navigate to emd-core/sources. copy the folder invn to external/invn as indected in the folder -----> tree !!!  bellow.\nksdk : kinetis sdk\nbsec : bosch sensortec environmental cluster (bsec) software for #bme680 environmental sensor. bsec is needed for calculating air quality index. go to https://www.bosch-sensortec.com/bst/products/all_products/bsec at the end of the page. select checkbox to accept license terms to download. unzip the the downloaded file. rename the extracted folder bsec and copy the whole folder to external as indicated in the folder tree bellow.\nblyst nano sensor board\nehal folder structure\nthe way the ehal folder is structure is simple. the deeper you go inside the more it is specific the the architecture or platform. the parent folder contains all that is commonly available to the child folder. which means, source file from child folder can access any source in the upper parent folder but not the other way around. this is the way to keep the abstraction separated from implementation and easier to keep track of things.\nthere are 2 main libraries in the ehal for each arm based mcu.\ncmsis : this contains the startup code, main interrupt vector and rtos if available. this lib is required for all firmware\nehal : this is the main hardware abstraction library. it contains all peripheral drivers, spi, i2c, uart, timer, ble,...\n/your_root - development root directory\n|-- external - contains downloaded sdks from silicon vendors\n| |-- cmsis - arm cmsis sdk for all arm platform (https://github.com/arm-software/cmsis_5)\n| |-- nrf5_sdk - latest nordic sdk (https://developer.nordicsemi.com)\n| |-- nrf5_sdk_mesh - latest nordic sdk for mesh (https://www.nordicsemi.com/eng/nordic/products/nrf5-sdk-for-mesh/nrf5-sdk-for-mesh/62377)\n| |---nrf5_sdk_12 - last version of nordick sdk12 for nrf51 series\n| |-- micro-ecc - micro-ecc (download from https://github.com/kmackay/micro-ecc)\n| |-- ksdk - kinetis sdk\n| |-- bsec - bosch sensortec environmental cluster (bsec) software (https://www.bosch-sensortec.com/bst/products/all_products/bsec) for #bme680\n| |-- mpl - invensense motion driver (download https://www.invensense.com/developers)\n| | |-- core - copy core from motion_driver_6.12/arm/stm32f4_md6/projects/emd6 here\n| | |-- lib\n| | | |-- m0 - unzip the liblibmplmpu_m0.zip, copy liblibmplmpu.a here\n| | | |-- m3 - unzip the liblibmplmpu_m3.zip, copy liblibmplmpu.a here\n| | | |-- m4hfp - unzip the liblibmplmpu_m4_hardfp.zip, copy liblibmplmpu.a here\n| | | |-- m4nfp - unzip the liblibmplmpu_m4_npfp.zip, copy liblibmplmpu.a here\n| | | |-- m4sfp - unzip the liblibmplmpu_m4_softfp.zip, copy liblibmplmpu.a here\n| |-- invn - invensense smartmotion driver (download https://www.invensense.com/developers)\n| | |-- devices\n| | |...\n| |...\n| |\n|-- ehal - put the ehal here\n| |-- docs - contains ehal doxygen documentations. (https://i-syst.github.io/docs/ehal/)\n| |-- include - generic include common to all platform\n| | |-- bluetooth - generic definition for bluetooth\n| | |-- converters - generic definition for adv, dac, etc...\n| | |-- coredev - generic core processor builtin devices such as i2c, uart, spi, timer, etc...\n| | |-- miscdev - generic definition for other non categorized devices\n| | |-- sensors - generic definition for al sort of sensors (environmental, motion, etc...)\n| | |-- usb - generic definition for usb\n| |-- src - generic implementation source common to all platform\n| |\n| |-- arm - cortex-m series based mcu\n| | |-- include - common include for all arm platform\n| | |-- src - common source for all arm platform\n| | |\n| | |-- nxp - nxp based mcu\n| | | |-- lpc11xx - lpc11xx processor workspace\n| | | | |-- cmsis - static library containing startup code, interrupt vector, etc...\n| | | | |-- ehal - embedded hardware abstraction library project for nxp\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - example code\n| | | | |\n| | | |-- lpc17xx - lpc17xx processor workspace\n| | | | |-- cmsis - static library containing startup code, interrupt vector, etc...\n| | | | |-- ehal - embedded hardware abstraction library project for nxp\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - example code\n| | |\n| | |-- nordic - nordic semiconductor based mcu\n| | | |-- nrf51 - nrf51 processor workspace\n| | | | |-- cmsis - static library containing startup code, interrupt vector, etc...\n| | | | |-- ehal - embedded hardware abstraction library project for nordic\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - exemple projects\n| | | |-- nrf52 - nrf52 processor workspace\n| | | | |-- cmsis - static library containing startup code, interrupt vector, etc...\n| | | | |-- ehal - embedded hardware abstraction library project for nordic\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - exemple projects\n| | |\n| | |-- st - st based mcu\n| | | |-- stm32f0xx\n| | | |-- stm32f4xx\n| | | |-- stm32l0xx\n| | |\n| | |-- ti - texas instruments based mcu\n| | | |-- cc3200\n| | | | |-- cmsis\n| | | | |-- ehal\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - example code\n| | |\n| | |-- freescale - freescale based mcu\n| | | |-- mkl\n| | | | |-- cmsis\n| | | | |-- ehal\n| | | | | |-- include\n| | | | | |-- src\n| | | | |-- exemples - example code\n| |...\n| |-- linux\n| | |...\n| |-- osx\n| | |...\n| |-- win\n| | |...\n| ...\nall ehal projects are eclipse native project with gcc compiler. for eclipse & gcc installations, follow this blog page http://embeddedsoftdev.blogspot.ca/p/eclipse.html.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000553, "year": null}, {"Unnamed: 0": 557, "autor": 557, "date": null, "content": "This repository is deprecated, please take a look at the new version of WyliodrinSTUDIO at the new reposository\nWyliodrin STUDIO\nWyliodrin STUDIO is a Chrome based IDE for software and hardware development for IoT and Embedded Linux systems.\nConnect to devices using TCP/IP or serial port\nDevelop software and firmware for IoT in several programming languages\nShell access to the device\nImport and export Wyliodrin STUDIO projects\nVisual dashboard for displaying sensor data\nDisplay the hardware schematics\nManage packages for Python and Javascript\nTask manager for managing the device\nNetwork connection manager for the device (Ethernet and WiFi)\nInteractive electronics documentation (resistor color code)\nExample projects and firmware\nWyliodrin API documentation in C/C++, Python and Javascript\nSupported devices:\nRaspberry Pi and Arduino\nUDOO Neo\nBeagleBone Black\nArduino Yun\nSupported languages\nVisual Programming (translates to Python)\nJavascript\nPython\nStreams (node-red)\nShell Script (bash)\nInstall\nYou may find Wyliodrin STUDIO on the Chrome Store\nDevice\nThe device needs to run\nwyliodrin-app-server\nwyliodrin-server\nlibwyliodrin\nYou may download device images that have them installed from Wyliodrin.\nUDOO Neo Download Image\nRaspberry Pi and Arduino Download Image\nBeagleBone Black Download Image\nArduino Yun\nBuild\nYou will need\nNodeJS version 4 or higher.\ngrunt\nyarn (optional)\nBuild Instructions for Windows users\nBuild using the provided script\nJust run the build.cmd script as administrator.\nor\nYou may build Wyliodrin STUDIO yourself\ngit clone https://www.github.com/Wyliodrin/WyliodrinSTUDIO\ncd WyliodrinSTUDIO\nyarn & REM npm install works slow\ncd patches\npatch.exe ../node_modules/highcharts-ng/dist/highcharts-ng.js highcharts-ng.patch\npatch.exe ../node_modules/angular-tree-control/css/tree-control-attribute.css tree-control-attribute.patch\npatch.exe ../node_modules/marked/lib/marked.js marked.patch\npatch.exe ../node_modules/angular-ui-ace/src/ui-ace.js angular-ui-ace.patch\ncd ..\ngrunt\nInstall grunt\nnpm install -g grunt-cli\nBuild Instructions for Linux users\nBuild using the provided script\nJust run the build.sh script.\nor\nYou may build Wyliodrin STUDIO yourself\ngit clone https://www.github.com/Wyliodrin/WyliodrinSTUDIO\ncd WyliodrinSTUDIO\nyarn # npm install works slow\npatch node_modules/highcharts-ng/dist/highcharts-ng.js patches/highcharts-ng.patch\npatch node_modules/angular-tree-control/css/tree-control-attribute.css patches/tree-control-attribute.patch\npatch node_modules/marked/lib/marked.js patches/marked.patch\npatch node_modules/angular-ui-ace/src/ui-ace.js patches/angular-ui-ace.patch\ngrunt\nInstall grunt\nsudo npm install -g grunt-cli\nThe build is in the build folder\nParameters\nDEBUG_WYLIODRIN='wyliodrin.*' - enable debug messages (this will have a performance impact)\nMIXPANEL_WYLIODRIN='' - mixpanel token for anonymous statistics sending\nLoading the app\nFirst step in loading the app is to install chrome explorer if you haven't already installed it Download chrome\nAfter the installation:\nopen the options tab (the 3 dots button in the top-right corner)\ngo to More tools\nin the More tools menu choose the Extensions option\ncheck the developer mode box (top of the page)\nanother three options will appear including one called 'Load unpacked extension'\nSelect 'Load unpacked extension', go to the the folder where you have built the project and open the folder called 'build', then press open.\nContribute\nWe would love your help. Click here to find out how to contribute.\nAuthors\nWyliodrin STUDIO is a product of Wyliodrin\nAlexandru Radovici - Maintainer\nRazvan Serban - Developer\nAlexandru Neculai - Developer\nIoana Culic - Developer\nOvidiu Stoica - UX / UI\nCatalin Dabuleanu - Developer\nContributions\nPaula Margarit - Developer\nDaniel Dosaru - Developer\nMihai Popescu - Developer\nWyliodrin is a trademark of Wyliodrin SRL. All rights reserved.\nLicense\nGPLv3 for private, non profit and educational use.\nPlease consider contacting us at office@wyliodrin.com if you plan to use it in a commercial software. This license allows you to write/distribute/sell an applications written in Wyliodrin STUDIO. If does not allow you to sell Wyliodrin STUDIO or any derived products.", "link": "https://github.com/Wyliodrin/WyliodrinSTUDIO", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "this repository is deprecated, please take a look at the new version of wyliodrinstudio at the new reposository\nwyliodrin studio\nwyliodrin studio is a chrome based ide for software and hardware development for iot and embedded linux systems.\nconnect to devices using tcp/ip or serial port\ndevelop software and firmware for iot in several programming languages\nshell access to the device\nimport and export wyliodrin studio projects\nvisual dashboard for displaying sensor data\ndisplay the hardware schematics\nmanage packages for python and javascript\ntask manager for managing the device\nnetwork connection manager for the device (ethernet and wifi)\ninteractive electronics documentation (resistor color code)\nexample projects and firmware\nwyliodrin api documentation in c/c++, python and javascript\nsupported devices:\nraspberry pi and arduino\nudoo neo\nbeaglebone black\narduino yun\nsupported languages\nvisual programming (translates to python)\njavascript\npython\nstreams (node-red)\nshell script (bash)\ninstall\nyou may find wyliodrin studio on the chrome store\ndevice\nthe device needs to run\nwyliodrin-app-server\nwyliodrin-server\nlibwyliodrin\nyou may download device images that have them installed from wyliodrin.\nudoo neo download image\nraspberry pi and arduino download image\nbeaglebone black download image\narduino yun\nbuild\nyou will need\nnodejs version 4 or higher.\ngrunt\nyarn (optional)\nbuild instructions for windows users\nbuild using the provided script\njust run the build.cmd script as administrator.\nor\nyou may build wyliodrin studio yourself\ngit clone https://www.github.com/wyliodrin/wyliodrinstudio\ncd wyliodrinstudio\nyarn & rem npm install works slow\ncd patches\npatch.exe ../node_modules/highcharts-ng/dist/highcharts-ng.js highcharts-ng.patch\npatch.exe ../node_modules/angular------> tree !!! -control/css/-----> tree !!! -control-attribute.css tree-control-attribute.patch\npatch.exe ../node_modules/marked/lib/marked.js marked.patch\npatch.exe ../node_modules/angular-ui-ace/src/ui-ace.js angular-ui-ace.patch\ncd ..\ngrunt\ninstall grunt\nnpm install -g grunt-cli\nbuild instructions for linux users\nbuild using the provided script\njust run the build.sh script.\nor\nyou may build wyliodrin studio yourself\ngit clone https://www.github.com/wyliodrin/wyliodrinstudio\ncd wyliodrinstudio\nyarn # npm install works slow\npatch node_modules/highcharts-ng/dist/highcharts-ng.js patches/highcharts-ng.patch\npatch node_modules/angular-tree-control/css/tree-control-attribute.css patches/tree-control-attribute.patch\npatch node_modules/marked/lib/marked.js patches/marked.patch\npatch node_modules/angular-ui-ace/src/ui-ace.js patches/angular-ui-ace.patch\ngrunt\ninstall grunt\nsudo npm install -g grunt-cli\nthe build is in the build folder\nparameters\ndebug_wyliodrin='wyliodrin.*' - enable debug messages (this will have a performance impact)\nmixpanel_wyliodrin='' - mixpanel token for anonymous statistics sending\nloading the app\nfirst step in loading the app is to install chrome explorer if you haven't already installed it download chrome\nafter the installation:\nopen the options tab (the 3 dots button in the top-right corner)\ngo to more tools\nin the more tools menu choose the extensions option\ncheck the developer mode box (top of the page)\nanother three options will appear including one called 'load unpacked extension'\nselect 'load unpacked extension', go to the the folder where you have built the project and open the folder called 'build', then press open.\ncontribute\nwe would love your help. click here to find out how to contribute.\nauthors\nwyliodrin studio is a product of wyliodrin\nalexandru radovici - maintainer\nrazvan serban - developer\nalexandru neculai - developer\nioana culic - developer\novidiu stoica - ux / ui\ncatalin dabuleanu - developer\ncontributions\npaula margarit - developer\ndaniel dosaru - developer\nmihai popescu - developer\nwyliodrin is a trademark of wyliodrin srl. all rights reserved.\nlicense\ngplv3 for private, non profit and educational use.\nplease consider contacting us at office@wyliodrin.com if you plan to use it in a commercial software. this license allows you to write/distribute/sell an applications written in wyliodrin studio. if does not allow you to sell wyliodrin studio or any derived products.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000557, "year": null}, {"Unnamed: 0": 563, "autor": 563, "date": null, "content": "PWPAE-Concept-Drift-Detection-and-Adaptation\nThis is the code for the paper entitled \"PWPAE: An Ensemble Framework for Concept Drift Adaptation in IoT Data Streams\" published in 2021 IEEE Global Communications Conference (GLOBECOM).\nAuthors: Li Yang, Dimitrios Michael Manias, and Abdallah Shami\nOrganization: The Optimized Computing and Communications (OC2) Lab, ECE Department, Western University\nThis repository also introduces concept drift definitions and online machine learning methods for data stream analytics using the River library.\nAnother tutorial code for concept drift, online machine learning, and data stream analytics can be found in: OASW-Concept-Drift-Detection-and-Adaptation\nConcept Drift\nIn non-stationary and dynamical environments, such as IoT environments, the distribution of input data often changes over time, known as concept drift. The occurrence of concept drift will result in the performance degradation of the current trained data analytics model. Traditional offline machine learning (ML) models cannot deal with concept drift, making it necessary to develop online adaptive analytics models that can adapt to the predictable and unpredictable changes in data streams.\nTo address concept drift, effective methods should be able to detect concept drift and adapt to the changes accordingly. Therefore, concept drift detection and adaptation are the two major steps for online learning on data streams.\nDrift Detection\nAdaptive Windowing (ADWIN) is a distribution-based method that uses an adaptive sliding window to detect concept drift based on data distribution changes. ADWIN identifies concept drift by calculating and analyzing the average of certain statistics over the two sub-windows of the adaptive window. The occurrence of concept drift is indicated by a large difference between the averages of the two sub-windows. Once a drift point is detected, all the old data samples before that drift time point are discarded.\nAlbert Bifet and Ricard Gavalda. \"Learning from time-changing data with adaptive windowing.\" In Proceedings of the 2007 SIAM international conference on data mining, pp. 443-448. Society for Industrial and Applied Mathematics, 2007.\nfrom river.drift import ADWIN\nadwin = ADWIN()\nDrift Detection Method (DDM) is a popular model performance-based method that defines two thresholds, a warning level and a drift level, to monitor model's error rate and standard deviation changes for drift detection.\nJo\u00e3o Gama, Pedro Medas, Gladys Castillo, Pedro Pereira Rodrigues: Learning with Drift Detection. SBIA 2004: 286-295\nfrom river.drift import DDM\nddm = DDM()\nDrift Adaptation\nHoeffding tree (HT) is a type of decision tree (DT) that uses the Hoeffding bound to incrementally adapt to data streams. Compared to a DT that chooses the best split, the HT uses the Hoeffding bound to calculate the number of necessary samples to select the split node. Thus, the HT can update its node to adapt to newly incoming samples.\nG. Hulten, L. Spencer, and P. Domingos. Mining time-changing data streams. In KDD\u201901, pages 97\u2013106, San Francisco, CA, 2001. ACM Press.\nfrom river import tree\nmodel = tree.HoeffdingTreeClassifier(\ngrace_period=100,\nsplit_confidence=1e-5,\n...\n)\nExtremely Fast Decision Tree (EFDT), also named Hoeffding Anytime Tree (HATT), is an improved version of the HT that splits nodes as soon as it reaches the confidence level instead of detecting the best split in the HT.\nC. Manapragada, G. Webb, and M. Salehi. Extremely Fast Decision Tree. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD '18). ACM, New York, NY, USA, 1953-1962, 2018.\nfrom river import tree\nmodel = tree.ExtremelyFastDecisionTreeClassifier(\ngrace_period=100,\nsplit_confidence=1e-5,\nmin_samples_reevaluate=100,\n...\n)\nAdaptive random forest (ARF) algorithm uses HTs as base learners and ADWIN as the drift detector for each tree to address concept drift. Through the drift detection process, the poor-performing base trees are replaced by new trees to fit the new concept.\nHeitor Murilo Gomes, Albert Bifet, Jesse Read, Jean Paul Barddal, Fabricio Enembreck, Bernhard Pfharinger, Geoff Holmes, Talel Abdessalem. Adaptive random forests for evolving data stream classification. In Machine Learning, DOI: 10.1007/s10994-017-5642-8, Springer, 2017.\nfrom river import ensemble\nmodel = ensemble.AdaptiveRandomForestClassifier(\nn_models=3,\ndrift_detector=ADWIN(),\n...\n)\nStreaming Random Patches (SRP) uses the similar technology of ARF, but it uses the global subspace randomization strategy, instead of the local subspace randomization technique used by ARF. The global subspace randomization is a more flexible method that improves the diversity of base learners.\nHeitor Murilo Gomes, Jesse Read, Albert Bifet. Streaming Random Patches for Evolving Data Stream Classification. IEEE International Conference on Data Mining (ICDM), 2019.\nfrom river import ensemble\nbase_model = tree.HoeffdingTreeClassifier(\ngrace_period=50, split_confidence=0.01,\n...\n)\nmodel = ensemble.SRPClassifier(\nmodel=base_model, n_models=3, drift_detector=ADWIN(),\n...\n)\nLeverage bagging (LB) is another popular online ensemble that uses bootstrap samples to construct base learners. It uses Poisson distribution to increase the data diversity and leverage the bagging performance.\nBifet A., Holmes G., Pfahringer B. (2010) Leveraging Bagging for Evolving Data Streams. In: Balc\u00e1zar J.L., Bonchi F., Gionis A., Sebag M. (eds) Machine Learning and Knowledge Discovery in Databases. ECML PKDD 2010. Lecture Notes in Computer Science, vol 6321. Springer, Berlin, Heidelberg.\nfrom river import ensemble\nfrom river import linear_model\nfrom river import preprocessing\nmodel = ensemble.LeveragingBaggingClassifier(\nmodel=(\npreprocessing.StandardScaler() |\nlinear_model.LogisticRegression()\n),\nn_models=3,\n...\n)\nAbstract of The Paper\nAs the number of Internet of Things (IoT) devices and systems have surged, IoT data analytics techniques have been developed to detect malicious cyber-attacks and secure IoT systems; however, concept drift issues often occur in IoT data analytics, as IoT data is often dynamic data streams that change over time, causing model degradation and attack detection failure. This is because traditional data analytics models are static models that cannot adapt to data distribution changes. In this paper, we propose a Performance Weighted Probability Averaging Ensemble (PWPAE) framework for drift adaptive IoT anomaly detection through IoT data stream analytics. Experiments on two public datasets show the effectiveness of our proposed PWPAE method compared against state-of-the-art methods.\nImplementation\nOnline Learning/Concept Drift Adaptation Algorithms\nAdaptive Random Forest (ARF)\nStreaming Random Patches (SRP)\nExtremely Fast Decision Tree (EFDT)\nHoeffding Tree (HT)\nLeveraging Bagging (LB)\nPerformance Weighted Probability Averaging Ensemble (PWPAE)\nProposed Method\nDrift Detection Algorithms\nAdaptive Windowing (ADWIN)\nDrift Detection Method (DDM)\nDataset\nIoTID20 dataset, a novel IoT botnet dataset\nPublicly available at: https://sites.google.com/view/iot-network-intrusion-dataset/home\nCICIDS2017 dataset, a popular network traffic dataset for intrusion detection problems\nPublicly available at: https://www.unb.ca/cic/datasets/ids-2017.html\nFor the purpose of displaying the experimental results in Jupyter Notebook, the sampled subsets of the two datasets are used in the sample code. The subsets are in the \"data\" folder.\nCode\nglobecom2021_PWPAE_IoTID20.ipynb: code for the sampled IoTID20 dataset.\nglobecom2021_PWPAE_CICIDS2017.ipynb: code for the sampled CICIDS2017 dataset.\nRequirements & Libraries\nPython 3.6+\nScikit-learn\nLightGBM\nRiver\nContact-Info\nPlease feel free to contact us for any questions or cooperation opportunities. We will be happy to help.\nEmail: liyanghart@gmail.com or Abdallah.Shami@uwo.ca\nGitHub: LiYangHart and Western OC2 Lab\nLinkedIn: Li Yang\nGoogle Scholar: Li Yang and OC2 Lab\nCitation\nIf you find this repository useful in your research, please cite this article as:\nL. Yang, D. M. Manias, and A. Shami, \u201cPWPAE: An Ensemble Framework for Concept Drift Adaptation in IoT Data Streams,\u201d in 2021 IEEE Glob. Commun. Conf. (GLOBECOM), Madrid, Spain, Dec. 2021.\n@INPROCEEDINGS{1570723427,\nauthor={Yang, Li and Manias, Dimitrios Michael and Shami, Abdallah},\nbooktitle={2021 IEEE Global Communications Conference (GLOBECOM)},\ntitle={PWPAE: An Ensemble Framework for Concept Drift Adaptation in IoT Data Streams},\nyear={2021},\npages={1-6},\ndoi={}\n}", "link": "https://github.com/Western-OC2-Lab/PWPAE-Concept-Drift-Detection-and-Adaptation", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "pwpae-concept-drift-detection-and-adaptation\nthis is the code for the paper entitled \"pwpae: an ensemble framework for concept drift adaptation in iot data streams\" published in 2021 ieee global communications conference (globecom).\nauthors: li yang, dimitrios michael manias, and abdallah shami\norganization: the optimized computing and communications (oc2) lab, ece department, western university\nthis repository also introduces concept drift definitions and online machine learning methods for data stream analytics using the river library.\nanother tutorial code for concept drift, online machine learning, and data stream analytics can be found in: oasw-concept-drift-detection-and-adaptation\nconcept drift\nin non-stationary and dynamical environments, such as iot environments, the distribution of input data often changes over time, known as concept drift. the occurrence of concept drift will result in the performance degradation of the current trained data analytics model. traditional offline machine learning (ml) models cannot deal with concept drift, making it necessary to develop online adaptive analytics models that can adapt to the predictable and unpredictable changes in data streams.\nto address concept drift, effective methods should be able to detect concept drift and adapt to the changes accordingly. therefore, concept drift detection and adaptation are the two major steps for online learning on data streams.\ndrift detection\nadaptive windowing (adwin) is a distribution-based method that uses an adaptive sliding window to detect concept drift based on data distribution changes. adwin identifies concept drift by calculating and analyzing the average of certain statistics over the two sub-windows of the adaptive window. the occurrence of concept drift is indicated by a large difference between the averages of the two sub-windows. once a drift point is detected, all the old data samples before that drift time point are discarded.\nalbert bifet and ricard gavalda. \"learning from time-changing data with adaptive windowing.\" in proceedings of the 2007 siam international conference on data mining, pp. 443-448. society for industrial and applied mathematics, 2007.\nfrom river.drift import adwin\nadwin = adwin()\ndrift detection method (ddm) is a popular model performance-based method that defines two thresholds, a warning level and a drift level, to monitor model's error rate and standard deviation changes for drift detection.\njo\u00e3o gama, pedro medas, gladys castillo, pedro pereira rodrigues: learning with drift detection. sbia 2004: 286-295\nfrom river.drift import ddm\nddm = ddm()\ndrift adaptation\nhoeffding -----> tree !!!  (ht) is a type of decision -----> tree !!!  (dt) that uses the hoeffding bound to incrementally adapt to data streams. compared to a dt that chooses the best split, the ht uses the hoeffding bound to calculate the number of necessary samples to select the split node. thus, the ht can update its node to adapt to newly incoming samples.\ng. hulten, l. spencer, and p. domingos. mining time-changing data streams. in kdd\u201901, pages 97\u2013106, san francisco, ca, 2001. acm press.\nfrom river import tree\nmodel = tree.hoeffdingtreeclassifier(\ngrace_period=100,\nsplit_confidence=1e-5,\n...\n)\nextremely fast decision tree (efdt), also named hoeffding anytime tree (hatt), is an improved version of the ht that splits nodes as soon as it reaches the confidence level instead of detecting the best split in the ht.\nc. manapragada, g. webb, and m. salehi. extremely fast decision tree. in proceedings of the 24th acm sigkdd international conference on knowledge discovery & data mining (kdd '18). acm, new york, ny, usa, 1953-1962, 2018.\nfrom river import tree\nmodel = tree.extremelyfastdecisiontreeclassifier(\ngrace_period=100,\nsplit_confidence=1e-5,\nmin_samples_reevaluate=100,\n...\n)\nadaptive random forest (arf) algorithm uses hts as base learners and adwin as the drift detector for each tree to address concept drift. through the drift detection process, the poor-performing base trees are replaced by new trees to fit the new concept.\nheitor murilo gomes, albert bifet, jesse read, jean paul barddal, fabricio enembreck, bernhard pfharinger, geoff holmes, talel abdessalem. adaptive random forests for evolving data stream classification. in machine learning, doi: 10.1007/s10994-017-5642-8, springer, 2017.\nfrom river import ensemble\nmodel = ensemble.adaptiverandomforestclassifier(\nn_models=3,\ndrift_detector=adwin(),\n...\n)\nstreaming random patches (srp) uses the similar technology of arf, but it uses the global subspace randomization strategy, instead of the local subspace randomization technique used by arf. the global subspace randomization is a more flexible method that improves the diversity of base learners.\nheitor murilo gomes, jesse read, albert bifet. streaming random patches for evolving data stream classification. ieee international conference on data mining (icdm), 2019.\nfrom river import ensemble\nbase_model = tree.hoeffdingtreeclassifier(\ngrace_period=50, split_confidence=0.01,\n...\n)\nmodel = ensemble.srpclassifier(\nmodel=base_model, n_models=3, drift_detector=adwin(),\n...\n)\nleverage bagging (lb) is another popular online ensemble that uses bootstrap samples to construct base learners. it uses poisson distribution to increase the data diversity and leverage the bagging performance.\nbifet a., holmes g., pfahringer b. (2010) leveraging bagging for evolving data streams. in: balc\u00e1zar j.l., bonchi f., gionis a., sebag m. (eds) machine learning and knowledge discovery in databases. ecml pkdd 2010. lecture notes in computer science, vol 6321. springer, berlin, heidelberg.\nfrom river import ensemble\nfrom river import linear_model\nfrom river import preprocessing\nmodel = ensemble.leveragingbaggingclassifier(\nmodel=(\npreprocessing.standardscaler() |\nlinear_model.logisticregression()\n),\nn_models=3,\n...\n)\nabstract of the paper\nas the number of internet of things (iot) devices and systems have surged, iot data analytics techniques have been developed to detect malicious cyber-attacks and secure iot systems; however, concept drift issues often occur in iot data analytics, as iot data is often dynamic data streams that change over time, causing model degradation and attack detection failure. this is because traditional data analytics models are static models that cannot adapt to data distribution changes. in this paper, we propose a performance weighted probability averaging ensemble (pwpae) framework for drift adaptive iot anomaly detection through iot data stream analytics. experiments on two public datasets show the effectiveness of our proposed pwpae method compared against state-of-the-art methods.\nimplementation\nonline learning/concept drift adaptation algorithms\nadaptive random forest (arf)\nstreaming random patches (srp)\nextremely fast decision tree (efdt)\nhoeffding tree (ht)\nleveraging bagging (lb)\nperformance weighted probability averaging ensemble (pwpae)\nproposed method\ndrift detection algorithms\nadaptive windowing (adwin)\ndrift detection method (ddm)\ndataset\niotid20 dataset, a novel iot botnet dataset\npublicly available at: https://sites.google.com/view/iot-network-intrusion-dataset/home\ncicids2017 dataset, a popular network traffic dataset for intrusion detection problems\npublicly available at: https://www.unb.ca/cic/datasets/ids-2017.html\nfor the purpose of displaying the experimental results in jupyter notebook, the sampled subsets of the two datasets are used in the sample code. the subsets are in the \"data\" folder.\ncode\nglobecom2021_pwpae_iotid20.ipynb: code for the sampled iotid20 dataset.\nglobecom2021_pwpae_cicids2017.ipynb: code for the sampled cicids2017 dataset.\nrequirements & libraries\npython 3.6+\nscikit-learn\nlightgbm\nriver\ncontact-info\nplease feel free to contact us for any questions or cooperation opportunities. we will be happy to help.\nemail: liyanghart@gmail.com or abdallah.shami@uwo.ca\ngithub: liyanghart and western oc2 lab\nlinkedin: li yang\ngoogle scholar: li yang and oc2 lab\ncitation\nif you find this repository useful in your research, please cite this article as:\nl. yang, d. m. manias, and a. shami, \u201cpwpae: an ensemble framework for concept drift adaptation in iot data streams,\u201d in 2021 ieee glob. commun. conf. (globecom), madrid, spain, dec. 2021.\n@inproceedings{1570723427,\nauthor={yang, li and manias, dimitrios michael and shami, abdallah},\nbooktitle={2021 ieee global communications conference (globecom)},\ntitle={pwpae: an ensemble framework for concept drift adaptation in iot data streams},\nyear={2021},\npages={1-6},\ndoi={}\n}", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000563, "year": null}, {"Unnamed: 0": 640, "autor": 640, "date": null, "content": "An Elixir library for Z-Wave\nInstallation\ndef deps do\n[\n{:grizzly, \"~> 0.22.7\"}\n]\nend\nHardware Requirements\nZ-Wave Bridge Controller\nZ-Wave 500\nZ-Wave 700\nCompatible System\nNerves Compatible System\nzipgateway-env\nSilicon Labs zipgateway binary\nThe zipgateway binary allows Grizzly to use Z-Wave over IP or Z/IP. Using the zipgateway binary provided by Silicon labs allows Grizzly to support the full range of Z-Wave features quickly and reliability. Some of the more advanced features like S2 security and smart start are already supported in Grizzly.\nSee instructions below for compiling the zipgateway binary and/or running locally.\nIf you want a quick reference to common uses of Grizzly see the cookbook docs.\nBasic Usage\nGrizzly exposes a supervisor Grizzly.Supervisor for the consuming application to add to its supervisor tree. This gives the most flexibility and control over when Grizzly's processes start. Common ways to start Grizzly can look like:\n# all the default options are fine\nGrizzly.Supervisor.start_link()\n# using custom hardware where the serial port is different than the default\n# the default serial port is /dev/ttyUSB0.\nGrizzly.Supervisor.start_link(serial_port: \"/dev/ttyS4\")\n# if your system is using zipgateway-env and/or something other than Grizzly\n# will start and manage running the zipgateway binary\nGrizzly.Supervisor.start_link(run_zipgateway: false)\nThere are other configuration options you can pass to Grizzly but the above are most common options. The Grizzly.Supervisor docs explains all the options in more detail.\nTo use a device you have to add it to the Z-Wave network. This is \"called including a device\" or \"starting an inclusion.\" While most of the Grizzly's API is synchronous the process of adding a node is not. So, if you are working from the IEx console you can use flush to see the newly add device. Here's how this process roughly goes.\niex> Grizzly.Inclusions.add_node()\n:ok\niex> flush\n{:grizzly, :report, %Grizzly.Report{\ncommand: %Grizzly.ZWave.Command{\nname: :node_add_status,\nparams: [<node info in here>]\n}\n}}\nTo remove a device we have to do an exclusion. Z-Wave uses the umbrella term \"inclusions\" for both adding a removing a device, but an \"inclusion\" is only about device pairing and \"exclusion\" is only about device removal. The way to remove the device from your network in IEx:\niex> Grizzly.Inclusions.remove_node()\n:ok\niex> flush\n{:grizzly, :report, %Grizzly.Report{\ncommand: %Grizzly.ZWave.Command{\nname: :node_remove_status,\nparams: [<node info in here>]\n}\n}}\nThere are more details about this process and how to better tie into the Grizzly runtime for this events in Grizzly.Inclusions.\nAfter you included a node it will be given a node id that you can use to send Z-Wave commands to it. Say for example we added an on off switch to our network, in Z-Wave this will be called a binary switch, and it was given the id of 5. Turning it off and on would look like this in IEx:\niex> Grizzly.send_command(5, :switch_binary_set, target_value: :on)\n{:ok, %Grizzly.Report{}}\niex> Grizzly.send_command(5, :switch_binary_set, target_value: :off)\n{:ok, %Grizzly.Report{}}\nFor more documentation on what Grizzly.send_command/4 can return see the Grizzly and Grizzly.Report module documentation.\nSuccessful Commands\n{:ok, %Grizzly.Report{type: :ack_response}} - normally for setting things on a device or changing the device's state\n{:ok, %Grizzly.Report{type: :command}} - this is normally returned when asking for a device state or about some information about a device or Z-Wave network. The command be access by the :command field field of the report.\n{:ok, %Grizzly.Report{type: :queued}} - some devices sleep, so sending a command to it will be queued for some amount of type that can be access in the :queued_delay field. Once a device wakes up the calling process will receive the messages in this form: {:grizzly, :report, %Grizzly.Report{}} where the type can either be :queued_ping or :command. To check if the report you receive was queued you can check the :queued field in the report.\n{:ok, %Grizzly.Report{type: :timeout}} - the command was sent but for some reason this commanded timed out.\nWhen things go wrong\n{:error, :nack_response} - for when the node is not responding to the command. Grizzly has automatic retries, so if you got this message that might mean the node is reachable, your Z-Wave network is experiencing a of traffic, or the node has recently been hit with a lot of commands and cannot handle anymore at this moment.\n{:error, :including} - the Z-Wave controller is currently in the inclusion state and the controller cannot send any commands currently\n{:error, :firmware_updating} - the Z-Wave controller is currently in the process of having it's firmware updated and is not able to send commands\nMore information about Grizzly.send_command/4 and the options like timeouts and retries that can be passed to see the Grizzly module.\nMore information about reports see the documentation in the Grizzly.Report module.\nUnsolicited Messages\nWhen reports are sent from the Z-Wave network to the controller without the controller asking for a report these are called unsolicited messages. A concrete example of this is when you manually unlock a lock, the controller will receive a message from the device if the associations are setup correctly (see Grizzly.Node.set_lifeline_association/2 for more information). You can listen for these reports using either Grizzly.subscribe_command/1 or Grizzly.subscribe_commands/1.\nGrizzly.subscribe_command(:door_lock_operation_report)\n# manually unlock a lock\nflush\n{:grizzly, :report, %Grizzly.Report{type: :unsolicited}}\nTo know what reports a device sends please see the device's user manual as these events will be outlined by the manufacture in the manual.\nCompile and Configure zipgateway\nQuick and Fast running locally\nIf you want to run Grizzly locally for development and/or learning before going through the challenge of compiling and running in Nerves we recommend the zipgateway-env project. This provides a docker container and CLI for compiling and running different versions of zipgateway.\nNerves Devices (WIP)\nFirst download the Z/IP GW SDK from Silicon Labs. You'll need to create an account with them to do this, but the download is free.\nThe default binaries that come with the download will not work by default in Nerves system, so you will need to compile the source for your target. The source code can be found in the Source directory.\nThis can be tricky and the instructions are a work in progress, so for now please contact us if you any troubles.\nConnecting zipgateway to Grizzly\nzipgateway runs as a separate server, accessed over a DTLS (UDP over SSL) connection. Grizzly will automatically start this server. It assumes the executable is in /usr/sbin/zipgateway. If this is not the case, you can specify the actual location with\nconfig :grizzly,\nzipgateway_path: \"\u00abpath\u00bb\"\nGrizzly uses the taptun module to manage the TCP connection: it checks that this is loaded as it starts.\nConfiguring zipgateway\nThe zipgateway binary is passed a configuration file named zipgateway.cfg. This has configuration parameters around networking and setting device specific information. Most of these configuration settings are static, so Grizzly can handle those for you in a reliable way. However, there are few exposed configuration options to allow some customization around device specific information, logging, and network interface set up.\nSupported configuration fields are:\n:tun_script - a path to the .tun script (default priv dir of Grizzly)\n:manufacturer_id: Id to set in the version report (default 0)\n:hardware_version - Hardware version to set in the version report (default 1)\n:product_id - Id to set in the version report (default 1)\n:product_type - Id to set in the version report (default 1)\n:serial_log - Log file for serial communication. Used for debugging. If this option is not set the no logging is done (default none)\nFor the most part if you are using Grizzly to run zipgateway the defaults should just work.\nWhen going through certification you will need provide some device specific information:\nconfig :grizzly,\nzipgateway_cfg: %{\nmanufacturer_id: 0,\nproduct_type: 1,\nproduct_id: 1,\nhardware_version: 1\n}\nThe manufacturer_id will be given to you by Silicon Labs, and will default to 0if not set (this is zipgateway level default).\nThe above fields have no impact on the Grizzly runtime, and are only useful for certification processes.\nWhen running zipgateway binary out side of Grizzly this configuration field is ignored and you will need to pass in the location to your configuration like so:\nzipgateway -c /path/to/zipgateway.cfg\nResources\nZ-Wave Specification Documentation\nZ-Wave Learning Resources\nSpecific Z-Wave product information", "link": "https://github.com/smartrent/grizzly", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "an elixir library for z-wave\ninstallation\ndef deps do\n[\n{:grizzly, \"~> 0.22.7\"}\n]\nend\nhardware requirements\nz-wave bridge controller\nz-wave 500\nz-wave 700\ncompatible system\nnerves compatible system\nzipgateway-env\nsilicon labs zipgateway binary\nthe zipgateway binary allows grizzly to use z-wave over ip or z/ip. using the zipgateway binary provided by silicon labs allows grizzly to support the full range of z-wave features quickly and reliability. some of the more advanced features like s2 security and smart start are already supported in grizzly.\nsee instructions below for compiling the zipgateway binary and/or running locally.\nif you want a quick reference to common uses of grizzly see the cookbook docs.\nbasic usage\ngrizzly exposes a supervisor grizzly.supervisor for the consuming application to add to its supervisor -----> tree !!! . this gives the most flexibility and control over when grizzly's processes start. common ways to start grizzly can look like:\n# all the default options are fine\ngrizzly.supervisor.start_link()\n# using custom hardware where the serial port is different than the default\n# the default serial port is /dev/ttyusb0.\ngrizzly.supervisor.start_link(serial_port: \"/dev/ttys4\")\n# if your system is using zipgateway-env and/or something other than grizzly\n# will start and manage running the zipgateway binary\ngrizzly.supervisor.start_link(run_zipgateway: false)\nthere are other configuration options you can pass to grizzly but the above are most common options. the grizzly.supervisor docs explains all the options in more detail.\nto use a device you have to add it to the z-wave network. this is \"called including a device\" or \"starting an inclusion.\" while most of the grizzly's api is synchronous the process of adding a node is not. so, if you are working from the iex console you can use flush to see the newly add device. here's how this process roughly goes.\niex> grizzly.inclusions.add_node()\n:ok\niex> flush\n{:grizzly, :report, %grizzly.report{\ncommand: %grizzly.zwave.command{\nname: :node_add_status,\nparams: [<node info in here>]\n}\n}}\nto remove a device we have to do an exclusion. z-wave uses the umbrella term \"inclusions\" for both adding a removing a device, but an \"inclusion\" is only about device pairing and \"exclusion\" is only about device removal. the way to remove the device from your network in iex:\niex> grizzly.inclusions.remove_node()\n:ok\niex> flush\n{:grizzly, :report, %grizzly.report{\ncommand: %grizzly.zwave.command{\nname: :node_remove_status,\nparams: [<node info in here>]\n}\n}}\nthere are more details about this process and how to better tie into the grizzly runtime for this events in grizzly.inclusions.\nafter you included a node it will be given a node id that you can use to send z-wave commands to it. say for example we added an on off switch to our network, in z-wave this will be called a binary switch, and it was given the id of 5. turning it off and on would look like this in iex:\niex> grizzly.send_command(5, :switch_binary_set, target_value: :on)\n{:ok, %grizzly.report{}}\niex> grizzly.send_command(5, :switch_binary_set, target_value: :off)\n{:ok, %grizzly.report{}}\nfor more documentation on what grizzly.send_command/4 can return see the grizzly and grizzly.report module documentation.\nsuccessful commands\n{:ok, %grizzly.report{type: :ack_response}} - normally for setting things on a device or changing the device's state\n{:ok, %grizzly.report{type: :command}} - this is normally returned when asking for a device state or about some information about a device or z-wave network. the command be access by the :command field field of the report.\n{:ok, %grizzly.report{type: :queued}} - some devices sleep, so sending a command to it will be queued for some amount of type that can be access in the :queued_delay field. once a device wakes up the calling process will receive the messages in this form: {:grizzly, :report, %grizzly.report{}} where the type can either be :queued_ping or :command. to check if the report you receive was queued you can check the :queued field in the report.\n{:ok, %grizzly.report{type: :timeout}} - the command was sent but for some reason this commanded timed out.\nwhen things go wrong\n{:error, :nack_response} - for when the node is not responding to the command. grizzly has automatic retries, so if you got this message that might mean the node is reachable, your z-wave network is experiencing a of traffic, or the node has recently been hit with a lot of commands and cannot handle anymore at this moment.\n{:error, :including} - the z-wave controller is currently in the inclusion state and the controller cannot send any commands currently\n{:error, :firmware_updating} - the z-wave controller is currently in the process of having it's firmware updated and is not able to send commands\nmore information about grizzly.send_command/4 and the options like timeouts and retries that can be passed to see the grizzly module.\nmore information about reports see the documentation in the grizzly.report module.\nunsolicited messages\nwhen reports are sent from the z-wave network to the controller without the controller asking for a report these are called unsolicited messages. a concrete example of this is when you manually unlock a lock, the controller will receive a message from the device if the associations are setup correctly (see grizzly.node.set_lifeline_association/2 for more information). you can listen for these reports using either grizzly.subscribe_command/1 or grizzly.subscribe_commands/1.\ngrizzly.subscribe_command(:door_lock_operation_report)\n# manually unlock a lock\nflush\n{:grizzly, :report, %grizzly.report{type: :unsolicited}}\nto know what reports a device sends please see the device's user manual as these events will be outlined by the manufacture in the manual.\ncompile and configure zipgateway\nquick and fast running locally\nif you want to run grizzly locally for development and/or learning before going through the challenge of compiling and running in nerves we recommend the zipgateway-env project. this provides a docker container and cli for compiling and running different versions of zipgateway.\nnerves devices (wip)\nfirst download the z/ip gw sdk from silicon labs. you'll need to create an account with them to do this, but the download is free.\nthe default binaries that come with the download will not work by default in nerves system, so you will need to compile the source for your target. the source code can be found in the source directory.\nthis can be tricky and the instructions are a work in progress, so for now please contact us if you any troubles.\nconnecting zipgateway to grizzly\nzipgateway runs as a separate server, accessed over a dtls (udp over ssl) connection. grizzly will automatically start this server. it assumes the executable is in /usr/sbin/zipgateway. if this is not the case, you can specify the actual location with\nconfig :grizzly,\nzipgateway_path: \"\u00abpath\u00bb\"\ngrizzly uses the taptun module to manage the tcp connection: it checks that this is loaded as it starts.\nconfiguring zipgateway\nthe zipgateway binary is passed a configuration file named zipgateway.cfg. this has configuration parameters around networking and setting device specific information. most of these configuration settings are static, so grizzly can handle those for you in a reliable way. however, there are few exposed configuration options to allow some customization around device specific information, logging, and network interface set up.\nsupported configuration fields are:\n:tun_script - a path to the .tun script (default priv dir of grizzly)\n:manufacturer_id: id to set in the version report (default 0)\n:hardware_version - hardware version to set in the version report (default 1)\n:product_id - id to set in the version report (default 1)\n:product_type - id to set in the version report (default 1)\n:serial_log - log file for serial communication. used for debugging. if this option is not set the no logging is done (default none)\nfor the most part if you are using grizzly to run zipgateway the defaults should just work.\nwhen going through certification you will need provide some device specific information:\nconfig :grizzly,\nzipgateway_cfg: %{\nmanufacturer_id: 0,\nproduct_type: 1,\nproduct_id: 1,\nhardware_version: 1\n}\nthe manufacturer_id will be given to you by silicon labs, and will default to 0if not set (this is zipgateway level default).\nthe above fields have no impact on the grizzly runtime, and are only useful for certification processes.\nwhen running zipgateway binary out side of grizzly this configuration field is ignored and you will need to pass in the location to your configuration like so:\nzipgateway -c /path/to/zipgateway.cfg\nresources\nz-wave specification documentation\nz-wave learning resources\nspecific z-wave product information", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000640, "year": null}, {"Unnamed: 0": 666, "autor": 666, "date": null, "content": "FogLAMP\nThis is the FogLAMP project.\nThe open source version of FogLAMP has moved to become part of the Linux Foundation LFedge Project\nWithin the Linux Foundation FogLAMP is now known as Fledge.\nFledge is available in GitHub as the fledge-iot project.\nThe latest version of FogLAMP is still available from Dianomic and has all the latest Fledge features plus extra plugin functionality.\nYour may download FogLAMP or download Fledge packaged binaries from the Dianomic website. These include all available plugins for your chosen architecture.\nDocumentation is available on readthedocs for both Fledge and FogLAMP and includes details of the plugins available for each.\nThis repository is now archieved.\nFogLAMP is an open source platform for the Internet of Things, and an essential component in Fog Computing. It uses a modular microservices architecture including sensor data collection, storage, processing and forwarding to historians, Enterprise systems and Cloud-based services. FogLAMP can run in highly available, stand alone, unattended environments that assume unreliable network connectivity.\nFogLAMP also provides a means of buffering data coming from sensors and forwarding that data onto high level storage systems. It assumes the underlying network layer is not always connected or may not be reliable. Data from sensors may be stored within FogLAMP for a number of days before being purged from the FogLAMP storage. During this time it may be sent to one or more historians and also accessed via a REST API for use by local analytical applications.\nFogLAMP has been designed to run in a Linux environment and makes use of Linux services.\nArchitecture\nFogLAMP is built using a microservices architecture for major component areas, these services consist of:\na Core service responsible for the management of the other services, the external REST API's, scheduling and monitoring of activities.\na South service responsible for the communication between FogLAMP and the sensors/actuators.\na Storage service responsible for the persistance of configuration and metrics and the buffering of sensor data.\nFogLAMP makes extensive use of plugin components in order to increase the flexibility of the implementation:\nSouth plugins are used to allow for the easy expansion of FogLAMP to deal with new South devices and South device connection buses.\nNorth plugins are used to allow for connection to different historians\nDatastore plugins are used to allow FogLAMP to use different storage mechanisms for persisting meta data and the sensor data\nAuthentication provider plugins are used to allow the authentication mechanism to be matched with enterprise requirements or provided internally by FogLAMP.\nThe other paradigm that is used extensively within FogLAMP is the idea of scheduling processes to perform specific operations. The FogLAMP core contains a scheduler which can execute processes based on time schedules or triggered by events. This is used to start processes when an event occurs, such as FogLAMP starting, or based on a time trigger.\nScheduled processes are used to send data from FogLAMP to the historian, to purge data from the FogLAMP data buffer, to gather statistics for historical analysis and perform backups of the FogLAMP environment.\nBuilding FogLAMP\nBuild Prerequisites\nFogLAMP is currently based on C/C++ and Python code. The packages needed to build and run FogLAMP are:\nautoconf\nautomake\navahi-daemon\nbuild-essential\ncmake\ncurl\ng++\nlibtool\nlibboost-dev\nlibboost-system-dev\nlibboost-thread-dev\nlibpq-dev\nlibssl-dev\nlibz-dev\nmake\npostgresql\npython3-pip\npython-dev\npython3-dev\nuuid-dev\nsqlite3\nlibsqlite3-dev\nLinux distributions\nFogLAMP can be built or installed in one of the following Linux distributions :\nUbuntu 16.04 and Ubuntu 18.04\nRaspbian Stretch and Buster\nRed Hat 7.6\nCentOS 7.6\nCoral Mendel\nInstall the prerequisites on Ubuntu\nOn Ubuntu-based Linux distributions the packages can be installed with given requirements.sh or manual apt-get:\napt-get install avahi-daemon curl\napt-get install cmake g++ make build-essential autoconf automake uuid-dev\napt-get install libtool libboost-dev libboost-system-dev libboost-thread-dev libpq-dev libssl-dev libz-dev\napt-get install python-dev python3-dev python3-pip\napt-get install postgresql\napt-get install sqlite3 libsqlite3-dev\nYou may need to use sudo to allow apt-get to install packages dependent upon your access rights.\nInstall the prerequisites on Red Hat/CentOS\nOn Red Hat and CentOS distributions the required packages can be installed automatically with given requirements.sh:\nsudo ./requirements.sh\nYou should run this as a user with sudo access rights.\nBuild\nTo build FogLAMP run the command make in the top level directory. This will compile all the components that need to be compiled and will also create a runable structure of the Python code components of FogLAMP.\nNOTE:\nThe GCC compiler version 5.4 available in Ubuntu 16.04 LTS raises warnings. This is a known bug of the compiler and it can be ignored.\nopenssl toolkit is a requirement if we want to use https based REST client and certificate based authentication.\nOnce the make has completed you can decide to test FogLAMP from your development environment or you can install it.\nTesting FogLAMP from Your Development Environment\nyou can test FogLAMP directly from your Development Environment. All you need to do is to set one environment variable to be able to run FogLAMP from the development tree.\nexport FOGLAMP_ROOT=<basedir>/FogLAMP\nWhere basedir is the base directory into which you cloned the FogLAMP repository.\nFinally, start the FogLAMP core daemon:\n$FOGLAMP_ROOT/scripts/foglamp start\nInstalling FogLAMP\nCreate an installation by executing make install, then set the FOGLAMP_ROOT environment variable specifying the installation path. By default the installation will be placed in /usr/local/foglamp. You may need to execute sudo make install to install FogLAMP where the current user does not have permissions:\nsudo make install\nexport FOGLAMP_ROOT=/usr/local/foglamp\nThe destination may be overriden by setting the variable DESTDIR in the make command line, to a location in which you wish to install FogLAMP. For example, to install FogLAMP in the /opt directory use the command:\nsudo make install DESTDIR=/opt\nexport FOGLAMP_ROOT=/opt/usr/local/foglamp\nUpgrading FogLAMP on Debian based systems\nFogLAMP supports the Kerberos authentication starting from the version 1.7.1 and so the related packages are installed by the script requirements.sh. The krb5-user package prompt a question during the installation process asking for the KDC definition, the packages are installed setting the environment DEBIAN_FRONTEND to avoid this interaction:\n# for Kerberos authentication, avoid interactive questions\nDEBIAN_FRONTEND=noninteractive apt install -yq krb5-user\napt install -y libcurl4-openssl-dev\nThe upgrade of the FogLAMP package should follow the same philosophy, it should be done executing the command:\nsudo DEBIAN_FRONTEND=noninteractive apt -y upgrade\nbefore the upgrade of FogLAMP, SETENV: should be set/added in /etc/sudoers.d/foglamp to allow sudo to support the handling of the environment variables, a sample of the file:\n%sudo ALL=(ALL) NOPASSWD:SETENV: /usr/bin/apt -y update, /usr/bin/apt-get -y install foglamp, /usr/bin/apt -y install /usr/local/foglamp/data/plugins/foglamp*.deb, /usr/bin/apt list, /usr/bin/apt -y install foglamp*, /usr/bin/apt -y upgrade\nExecuting FogLAMP\nFogLAMP is now ready to start. Use the command:\n$FOGLAMP_ROOT/bin/foglamp start\nTo check if FogLAMP is running, use the command:\n$FOGLAMP_ROOT/bin/foglamp status\nThe command returns the status of FogLAMP on the machine it has been executed.\nIf You Use PostgreSQL: Creating the Database Repository\nThis version of FogLAMP relies on SQLite to run. SQLite is embedded into the Storage service, but you may want to use PostgreSQL as a buffer and metadata storage (refer to the documentation on ReadTheDocs for more info. With a version of PostgreSQL installed via apt-get first you need to create a new database user with:\nsudo -u postgres createuser -d <user>\nwhere user is the name of the Linux user that will run FogLAMP. The FogLAMP database user must have createdb privileges (i.e. the -d argument).\nTroubleshooting\nFogLAMP version 1.7.0\n$FOGLAMP_ROOT/data/etc directory ownership\nThe execution of the sudo make install immediately after git clone will create a data/etc directory owned by the root user, it should be owned by the user that will run FogLAMP, to fix it:\nchown -R <user>:<user> $FOGLAMP_ROOT/data\nwhere user is the name of the Linux user that will run FogLAMP.", "link": "https://github.com/foglamp/FogLAMP", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "foglamp\nthis is the foglamp project.\nthe open source version of foglamp has moved to become part of the linux foundation lfedge project\nwithin the linux foundation foglamp is now known as fledge.\nfledge is available in github as the fledge-iot project.\nthe latest version of foglamp is still available from dianomic and has all the latest fledge features plus extra plugin functionality.\nyour may download foglamp or download fledge packaged binaries from the dianomic website. these include all available plugins for your chosen architecture.\ndocumentation is available on readthedocs for both fledge and foglamp and includes details of the plugins available for each.\nthis repository is now archieved.\nfoglamp is an open source platform for the internet of things, and an essential component in fog computing. it uses a modular microservices architecture including sensor data collection, storage, processing and forwarding to historians, enterprise systems and cloud-based services. foglamp can run in highly available, stand alone, unattended environments that assume unreliable network connectivity.\nfoglamp also provides a means of buffering data coming from sensors and forwarding that data onto high level storage systems. it assumes the underlying network layer is not always connected or may not be reliable. data from sensors may be stored within foglamp for a number of days before being purged from the foglamp storage. during this time it may be sent to one or more historians and also accessed via a rest api for use by local analytical applications.\nfoglamp has been designed to run in a linux environment and makes use of linux services.\narchitecture\nfoglamp is built using a microservices architecture for major component areas, these services consist of:\na core service responsible for the management of the other services, the external rest api's, scheduling and monitoring of activities.\na south service responsible for the communication between foglamp and the sensors/actuators.\na storage service responsible for the persistance of configuration and metrics and the buffering of sensor data.\nfoglamp makes extensive use of plugin components in order to increase the flexibility of the implementation:\nsouth plugins are used to allow for the easy expansion of foglamp to deal with new south devices and south device connection buses.\nnorth plugins are used to allow for connection to different historians\ndatastore plugins are used to allow foglamp to use different storage mechanisms for persisting meta data and the sensor data\nauthentication provider plugins are used to allow the authentication mechanism to be matched with enterprise requirements or provided internally by foglamp.\nthe other paradigm that is used extensively within foglamp is the idea of scheduling processes to perform specific operations. the foglamp core contains a scheduler which can execute processes based on time schedules or triggered by events. this is used to start processes when an event occurs, such as foglamp starting, or based on a time trigger.\nscheduled processes are used to send data from foglamp to the historian, to purge data from the foglamp data buffer, to gather statistics for historical analysis and perform backups of the foglamp environment.\nbuilding foglamp\nbuild prerequisites\nfoglamp is currently based on c/c++ and python code. the packages needed to build and run foglamp are:\nautoconf\nautomake\navahi-daemon\nbuild-essential\ncmake\ncurl\ng++\nlibtool\nlibboost-dev\nlibboost-system-dev\nlibboost-thread-dev\nlibpq-dev\nlibssl-dev\nlibz-dev\nmake\npostgresql\npython3-pip\npython-dev\npython3-dev\nuuid-dev\nsqlite3\nlibsqlite3-dev\nlinux distributions\nfoglamp can be built or installed in one of the following linux distributions :\nubuntu 16.04 and ubuntu 18.04\nraspbian stretch and buster\nred hat 7.6\ncentos 7.6\ncoral mendel\ninstall the prerequisites on ubuntu\non ubuntu-based linux distributions the packages can be installed with given requirements.sh or manual apt-get:\napt-get install avahi-daemon curl\napt-get install cmake g++ make build-essential autoconf automake uuid-dev\napt-get install libtool libboost-dev libboost-system-dev libboost-thread-dev libpq-dev libssl-dev libz-dev\napt-get install python-dev python3-dev python3-pip\napt-get install postgresql\napt-get install sqlite3 libsqlite3-dev\nyou may need to use sudo to allow apt-get to install packages dependent upon your access rights.\ninstall the prerequisites on red hat/centos\non red hat and centos distributions the required packages can be installed automatically with given requirements.sh:\nsudo ./requirements.sh\nyou should run this as a user with sudo access rights.\nbuild\nto build foglamp run the command make in the top level directory. this will compile all the components that need to be compiled and will also create a runable structure of the python code components of foglamp.\nnote:\nthe gcc compiler version 5.4 available in ubuntu 16.04 lts raises warnings. this is a known bug of the compiler and it can be ignored.\nopenssl toolkit is a requirement if we want to use https based rest client and certificate based authentication.\nonce the make has completed you can decide to test foglamp from your development environment or you can install it.\ntesting foglamp from your development environment\nyou can test foglamp directly from your development environment. all you need to do is to set one environment variable to be able to run foglamp from the development -----> tree !!! .\nexport foglamp_root=<basedir>/foglamp\nwhere basedir is the base directory into which you cloned the foglamp repository.\nfinally, start the foglamp core daemon:\n$foglamp_root/scripts/foglamp start\ninstalling foglamp\ncreate an installation by executing make install, then set the foglamp_root environment variable specifying the installation path. by default the installation will be placed in /usr/local/foglamp. you may need to execute sudo make install to install foglamp where the current user does not have permissions:\nsudo make install\nexport foglamp_root=/usr/local/foglamp\nthe destination may be overriden by setting the variable destdir in the make command line, to a location in which you wish to install foglamp. for example, to install foglamp in the /opt directory use the command:\nsudo make install destdir=/opt\nexport foglamp_root=/opt/usr/local/foglamp\nupgrading foglamp on debian based systems\nfoglamp supports the kerberos authentication starting from the version 1.7.1 and so the related packages are installed by the script requirements.sh. the krb5-user package prompt a question during the installation process asking for the kdc definition, the packages are installed setting the environment debian_frontend to avoid this interaction:\n# for kerberos authentication, avoid interactive questions\ndebian_frontend=noninteractive apt install -yq krb5-user\napt install -y libcurl4-openssl-dev\nthe upgrade of the foglamp package should follow the same philosophy, it should be done executing the command:\nsudo debian_frontend=noninteractive apt -y upgrade\nbefore the upgrade of foglamp, setenv: should be set/added in /etc/sudoers.d/foglamp to allow sudo to support the handling of the environment variables, a sample of the file:\n%sudo all=(all) nopasswd:setenv: /usr/bin/apt -y update, /usr/bin/apt-get -y install foglamp, /usr/bin/apt -y install /usr/local/foglamp/data/plugins/foglamp*.deb, /usr/bin/apt list, /usr/bin/apt -y install foglamp*, /usr/bin/apt -y upgrade\nexecuting foglamp\nfoglamp is now ready to start. use the command:\n$foglamp_root/bin/foglamp start\nto check if foglamp is running, use the command:\n$foglamp_root/bin/foglamp status\nthe command returns the status of foglamp on the machine it has been executed.\nif you use postgresql: creating the database repository\nthis version of foglamp relies on sqlite to run. sqlite is embedded into the storage service, but you may want to use postgresql as a buffer and metadata storage (refer to the documentation on readthedocs for more info. with a version of postgresql installed via apt-get first you need to create a new database user with:\nsudo -u postgres createuser -d <user>\nwhere user is the name of the linux user that will run foglamp. the foglamp database user must have createdb privileges (i.e. the -d argument).\ntroubleshooting\nfoglamp version 1.7.0\n$foglamp_root/data/etc directory ownership\nthe execution of the sudo make install immediately after git clone will create a data/etc directory owned by the root user, it should be owned by the user that will run foglamp, to fix it:\nchown -r <user>:<user> $foglamp_root/data\nwhere user is the name of the linux user that will run foglamp.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000666, "year": null}, {"Unnamed: 0": 682, "autor": 682, "date": null, "content": "Azure IoT Hub\nAzure IoT Hub extension is now a part of Azure IoT Tools extension pack. We highly recommend installing Azure IoT Tools extension pack, which makes it easy to discover and interact with Azure IoT Hub that power your IoT Edge and device applications. This extension pack can help you:\nDevelop and connect your Azure IoT Applications to Azure. With this extension, you can interact with an Azure IoT Hub, manage connected devices, and enable distributed tracing for your Azure IoT applications.\nDevelop and debug Certifies Azure IoT Devices (including MXChip IoT DevKit, ESP32, Raspberry Pi) to Azure. This extension pack makes it easy to code, build, deploy and debug your IoT applications with popular IoT development boards.\nDevelop and deploy artificial intelligence and your custom logic to Azure IoT Edge. This extension pack makes it easy to code, build, deploy, and debug your IoT Edge applications.\nOverview\nInteract with Azure IoT Hub, IoT Device Management, IoT Edge Management, IoT Hub Device Simulation, IoT Hub Code Generation and IoT Hub Device Provisioning Service.\nDevice Explorer\nThe Wiki page includes a comprehensive getting started guide as well as detailed usage instructions of the following features:\nIoT Hub management\nCreate IoT Hub\nSelect IoT Hub\nCopy IoT Hub Connection String\nGenerate SAS Token for IoT Hub\nDevice management\nList devices\nGet device info\nCreate IoT device\nCreate Edge device\nDelete device\nCopy Device Connection String\nGenerate SAS Token for Device\nModule management\nList Modules\nGet Module Info\nCreate Module\nEdit Module Twin\nInvoke Module Direct Method\nCopy Module Connection String\nDelete Module\nInteract with Azure IoT Hub\nGenerate Code for C#, F#, Go, Java, Node.js, PHP, Python, Ruby or REST API\nSend D2C message to IoT Hub\nMonitor Built-in Event Endpoint\nSend C2D message to device\nReceive C2D message from IoT Hub\nInvoke Device Direct Method\nEdit Device Twin\nManage Azure IoT distributed tracing\nInteract with Azure IoT Edge (Install Azure IoT Edge for more IoT Edge support)\nList Modules\nEdit Module Twin\nCreate deployment for Single Device\nCreate Deployment at Scale\nEndpoints management\nList Built-in and Custom Endpoints\nMonitor Custom Event Hub Endpoint\nPrerequisites\nIn Explorer of VS Code, click \"Azure IoT Hub\" in the bottom left corner.\nClick \"Set IoT Hub Connection String\" in context menu.\nAn input box will pop up, then enter your IoT Hub Connection String (It is one-time configuration, and please make sure it is IoT Hub Connection String not Device Connection String. The format is HostName=<my-hub>.azure-devices.net;SharedAccessKeyName=<my-policy>;SharedAccessKey=<my-policy-key>).\nThe devices list will be shown.\nSign in to Azure\nInstead of copying and pasting to set IoT Hub Connection String, you could sign in to Azure to select IoT Hub from your Azure Subscription.\nClick \"Select IoT Hub\" in context menu.\nIf you have not signed in to Azure, a pop-up will show to let you sign in to Azure.\nAfter you sign in, your Azure Subscription list will be shown, then select an Azure Subscription.\nYour IoT Hub list will be shown, then select an IoT Hub.\nThe devices and endpoints list will be shown.\nDevice Provisioning Service Explorer\nOpen \"Azure\" view on the Activity Bar, and expand \"IOT HUB DEVICE PROVISIONING SERVICE\".\nIf you're not signed in, click \"Sign in to Azure...\" to sign in.\nExpand one subscription to start exploring your device provisioning services.\nCode Generation\nCode Snippets\nTrigger Content\niotSendD2CMessage Send D2C message to IoT Hub\niotMonitorD2CMessage Monitor D2C message for IoT Hub\niotSendC2DMessage Send C2D message to device\niotMonitorC2DMessage Monitor C2D message from IoT Hub\niotCallDirectMethods Send direct methods to device\niotReceiveDirectMethods Receive direct methods from IoT Hub\nAfter code snippet is created, you need to install corresponding npm package (e.g. azure-iot-device-mqtt) to run the code snippet. If you want to 'Run Code' directly, you need to install Code Runner.\nConfiguration\nIoT Hub Consumer Group (default is \"$Default\"):\n{\n\"azure-iot-toolkit.iotHubConsumerGroup\": \"$Default\"\n}\nThe time span (in minutes) of monitoring D2C message before current time (default is 0):\n{\n\"azure-iot-toolkit.monitorD2CBeforeNowInMinutes\": 0\n}\nWhether to show verbose info when monitoring messages (default is false):\n{\n\"azure-iot-toolkit.showVerboseMessage\": false\n}\nWhether to stringify device-to-cloud messages (default is false):\n{\n\"azure-iot-toolkit.iotHubD2CMessageStringify\": false\n}\nWhether to show IoT Hub info when IoT Hub Connection String is not set (default is true):\n{\n\"azure-iot-toolkit.showIoTHubInfo\": true\n}\nWhether to enable auto refresh of tree view (default is false):\n{\n\"azure-iot-toolkit.treeViewAutoRefreshEnable\": false\n}\nTime interval in seconds for tree view auto refresh, auto refresh has to be enabled for it to work. (default is 60):\n{\n\"azure-iot-toolkit.treeViewAutoRefreshIntervalInSeconds\": 60\n}\nResources\nChannel 9 video: Walkthrough of Azure IoT Hub extension\nChannel 9 video: What's new in the IoT Hub extension for VS Code\nCreate an IoT hub using the Azure IoT Tools for Visual Studio Code\nUse Azure IoT Tools to send and receive messages between your device and IoT Hub\nUse Azure IoT Tools for Azure IoT Hub device management\nQuickly build your Azure IoT application with Node.js, Python or REST API\nAzure IoT Hub extension supports C#, Go, Java, Node.js, PHP, Python and Ruby to develop Azure IoT application in VS Code\nUse VS Code as IoT Hub Device Simulator\nUse VS Code to call Azure IoT Hub REST APIs\nCreate and control an IoT device connected to an IoT hub (Node.js)\nCreate and control an IoT device connected to an IoT hub (.NET)\nHandy Tool When You Develop With Azure IoT\nAzure IoT Hub extension for Visual Studio Code generally available for managing Azure IoT Hub and Devices with ease\n\u2764\ufe0f Contributors\nThanks to all the contributors!\nData/Telemetry\nThis project collects usage data and sends it to Microsoft to help improve our products and services. Read our privacy statement to learn more. If you don\u2019t wish to send usage data to Microsoft, you can set the telemetry.enableTelemetry setting to false. Learn more in our FAQ.", "link": "https://github.com/microsoft/vscode-azure-iot-toolkit", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "azure iot hub\nazure iot hub extension is now a part of azure iot tools extension pack. we highly recommend installing azure iot tools extension pack, which makes it easy to discover and interact with azure iot hub that power your iot edge and device applications. this extension pack can help you:\ndevelop and connect your azure iot applications to azure. with this extension, you can interact with an azure iot hub, manage connected devices, and enable distributed tracing for your azure iot applications.\ndevelop and debug certifies azure iot devices (including mxchip iot devkit, esp32, raspberry pi) to azure. this extension pack makes it easy to code, build, deploy and debug your iot applications with popular iot development boards.\ndevelop and deploy artificial intelligence and your custom logic to azure iot edge. this extension pack makes it easy to code, build, deploy, and debug your iot edge applications.\noverview\ninteract with azure iot hub, iot device management, iot edge management, iot hub device simulation, iot hub code generation and iot hub device provisioning service.\ndevice explorer\nthe wiki page includes a comprehensive getting started guide as well as detailed usage instructions of the following features:\niot hub management\ncreate iot hub\nselect iot hub\ncopy iot hub connection string\ngenerate sas token for iot hub\ndevice management\nlist devices\nget device info\ncreate iot device\ncreate edge device\ndelete device\ncopy device connection string\ngenerate sas token for device\nmodule management\nlist modules\nget module info\ncreate module\nedit module twin\ninvoke module direct method\ncopy module connection string\ndelete module\ninteract with azure iot hub\ngenerate code for c#, f#, go, java, node.js, php, python, ruby or rest api\nsend d2c message to iot hub\nmonitor built-in event endpoint\nsend c2d message to device\nreceive c2d message from iot hub\ninvoke device direct method\nedit device twin\nmanage azure iot distributed tracing\ninteract with azure iot edge (install azure iot edge for more iot edge support)\nlist modules\nedit module twin\ncreate deployment for single device\ncreate deployment at scale\nendpoints management\nlist built-in and custom endpoints\nmonitor custom event hub endpoint\nprerequisites\nin explorer of vs code, click \"azure iot hub\" in the bottom left corner.\nclick \"set iot hub connection string\" in context menu.\nan input box will pop up, then enter your iot hub connection string (it is one-time configuration, and please make sure it is iot hub connection string not device connection string. the format is hostname=<my-hub>.azure-devices.net;sharedaccesskeyname=<my-policy>;sharedaccesskey=<my-policy-key>).\nthe devices list will be shown.\nsign in to azure\ninstead of copying and pasting to set iot hub connection string, you could sign in to azure to select iot hub from your azure subscription.\nclick \"select iot hub\" in context menu.\nif you have not signed in to azure, a pop-up will show to let you sign in to azure.\nafter you sign in, your azure subscription list will be shown, then select an azure subscription.\nyour iot hub list will be shown, then select an iot hub.\nthe devices and endpoints list will be shown.\ndevice provisioning service explorer\nopen \"azure\" view on the activity bar, and expand \"iot hub device provisioning service\".\nif you're not signed in, click \"sign in to azure...\" to sign in.\nexpand one subscription to start exploring your device provisioning services.\ncode generation\ncode snippets\ntrigger content\niotsendd2cmessage send d2c message to iot hub\niotmonitord2cmessage monitor d2c message for iot hub\niotsendc2dmessage send c2d message to device\niotmonitorc2dmessage monitor c2d message from iot hub\niotcalldirectmethods send direct methods to device\niotreceivedirectmethods receive direct methods from iot hub\nafter code snippet is created, you need to install corresponding npm package (e.g. azure-iot-device-mqtt) to run the code snippet. if you want to 'run code' directly, you need to install code runner.\nconfiguration\niot hub consumer group (default is \"$default\"):\n{\n\"azure-iot-toolkit.iothubconsumergroup\": \"$default\"\n}\nthe time span (in minutes) of monitoring d2c message before current time (default is 0):\n{\n\"azure-iot-toolkit.monitord2cbeforenowinminutes\": 0\n}\nwhether to show verbose info when monitoring messages (default is false):\n{\n\"azure-iot-toolkit.showverbosemessage\": false\n}\nwhether to stringify device-to-cloud messages (default is false):\n{\n\"azure-iot-toolkit.iothubd2cmessagestringify\": false\n}\nwhether to show iot hub info when iot hub connection string is not set (default is true):\n{\n\"azure-iot-toolkit.showiothubinfo\": true\n}\nwhether to enable auto refresh of -----> tree !!!  view (default is false):\n{\n\"azure-iot-toolkit.treeviewautorefreshenable\": false\n}\ntime interval in seconds for -----> tree !!!  view auto refresh, auto refresh has to be enabled for it to work. (default is 60):\n{\n\"azure-iot-toolkit.treeviewautorefreshintervalinseconds\": 60\n}\nresources\nchannel 9 video: walkthrough of azure iot hub extension\nchannel 9 video: what's new in the iot hub extension for vs code\ncreate an iot hub using the azure iot tools for visual studio code\nuse azure iot tools to send and receive messages between your device and iot hub\nuse azure iot tools for azure iot hub device management\nquickly build your azure iot application with node.js, python or rest api\nazure iot hub extension supports c#, go, java, node.js, php, python and ruby to develop azure iot application in vs code\nuse vs code as iot hub device simulator\nuse vs code to call azure iot hub rest apis\ncreate and control an iot device connected to an iot hub (node.js)\ncreate and control an iot device connected to an iot hub (.net)\nhandy tool when you develop with azure iot\nazure iot hub extension for visual studio code generally available for managing azure iot hub and devices with ease\n\u2764\ufe0f contributors\nthanks to all the contributors!\ndata/telemetry\nthis project collects usage data and sends it to microsoft to help improve our products and services. read our privacy statement to learn more. if you don\u2019t wish to send usage data to microsoft, you can set the telemetry.enabletelemetry setting to false. learn more in our faq.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000682, "year": null}, {"Unnamed: 0": 710, "autor": 710, "date": null, "content": "Simple IoT is collection of building blocks to help you build custom IoT systems quickly, but yet provide full flexibility to customize the system. Many features such as device communication, device update, rules, user/group management, user portal, etc. are needed for every IoT system. This project provides a solid foundation of common features so that you can focus on the specific problem you are solving.\nGuiding principles\nSimple concepts are flexible and scale well.\nThere are more problems to solve than people to solve them, thus it makes sense to collaborate on the common technology pieces.\nThere are a lot of IoT applications that are not Google scale (10-1000 device range).\nThere is significant opportunity in the long tail of IoT, which is our focus.\nThere is value in custom solutions (programming vs drag-n-drop).\nThere is value in running/owning our own platform.\nA single engineer should be able to build and deploy a custom IoT system.\nWe don't need to spend excessive amounts of time on operations. For smaller deployments, we deploy one binary to a cloud server and we are done with operations. We don't need 20 microservices when one monolith will work just fine.\nFor many applications, a couple hours of down time is not the end of the world. Thus a single server that can be quickly rebuilt as needed is adequate and in many cases more reliable than complex systems with many moving parts.\nCore features/requirements:\nRuns in cloud and edge instances.\nConfiguration changes can be made at either cloud, UI, or edge and are synchronized efficiently in any direction.\nEfficient use of network bandwidth for edge systems as most are connected via low cost cellular plans.\nRules can run in cloud or edge devices depending on action required (sending notifications or controlling outputs).\nSystem supports user authentication and grouping users and devices at multiple levels.\nUser interface updates to changes in real time.\nEasy to add custom logic/algorithms by adding processes written in any language that connect to Simple IoT via NATS.\nIoT Systems are inherently distributed, so even though we prefer a monolith for a cloud service, we can't get around the fact that we also need to synchronize data with edge devices and user interfaces.\nSimple IoT is built on simple data structures arranged in a graph that allows for very flexible configurations.\nBecause the core of Simple IoT is designed with flexible data structures, adding functionality and supporting new devices is usually as simple as creating your custom edge device code and modifying the UI to display and configure your device features.\nThough we are focusing on smaller deployments initially, there is no reason Simple IoT can't scale to large systems by swapping out the internal database for MongoDB/Dgraph/InfluxDB/etc.\nSee vision and architecture for addition discussion on these points.\nThis project was developed while building real-world applications and has primarily been driven by these project requirements. This project provides\nan stand-alone application that can be deployed at the edge or in the cloud\npackages for implementing an edge application to run on embedded Linux systems.\nThe Simple IoT project also includes open source gateway firmware and hardware designs.\nDetailed documentation\nExample 1\nThis example (build only tested on Linux and MacOS) shows how to run the server and send data to it:\nBuild Simple Iot or download the latest release:\ninstall Go v1.14 (newer versions will likely work) and node/npm (tested with v12 and v14)\ngit clone https://github.com/simpleiot/simpleiot.git\ncd simpleiot\n. envsetup.sh (note space is required between . and envsetup.sh. Another way to type this is source envsetup.sh. This command populates your terminal session with all the functions defined in envsetup.sh.)\nsiot_setup\nsiot_build\nNow, run the example:\nin one terminal, start server: ./siot\nopen http://localhost:8080\nlogin with user admin@admin.com and password admin\nin another terminal, send some data\nusing HTTP: ./siot -sendPoint \"1823:t1:23.5:temp\"\nusing NATS: ./siot -sendPointNats \"1234:v2:12.5:volt\"\n(the format of the -sendPoint argument is: devId:sensId:value:type)\nin a few seconds, devices should be populated in the web application\nSIOT web interface screenshot\nBelow is a screenshot of the siot web interface with the above data.\nExample 2 (send commands/files to device)\n./siot\nin another terminal, start edge device example: go run cmd/edge/main.go\nin a 3rd terminal:\nsend command to device: ./siot -sendCmd=setTank:150\nsend file to device: ./siot -sendFile=https://raw.githubusercontent.com/simpleiot/simpleiot/master/README.md\nExample 3 (send data with acknowledgments from server)\n./siot -sendPointNats \"1234:v2:12.5:volt\" -natsAck\nExample 4 (send version information to server)\nHardware version information is a Point that encodes the version information in the Text field of a Point.\n./siot -sendPointText \"1234::1:hwVersion\n./siot -sendPointText \"1234::2:osVersion\n./siot -sendPointText \"1234::3:appVersion\nFlexible node view\nInformation is arranged in a flexible node/tree which allows for easy grouping of users, devices, and device attributes.\nEach nodes can be expanded to edit/view attributes\nExtensive support for modbus devices\nSimple IoT can function as either a Modbus TCP/RTU master or client.\nUpstream support\nSimple IoT is designed such that one instance can be run at the edge and connect to another instance in the cloud. The tree in the edge instance is simply mirrored in the upstream tree. Changes at either place are synchronized in real-time. If one device is offline, the changes are synchronized the next time they are connected. See the below video for a demo of this.\nRules and Notifications\nSimple IoT rules can be used to set node values and to trigger notifications.\nConfiguration\nSimple IoT can be configured for basic options such as port numbers, etc.\nAdditionally, command line option help can be viewed by running siot --help.\nDashboard and Graphing\nAlthough Simple IoT provides a rudimentary dashboard and device listing, it does not provide graphs yet. If you need graphs, using InfluxDb + Grafana may be a good interim solution. Contact us if you need help setting this up -- it is relatively simple.\nFeatures\nNote, Simple IoT is under heavy development right now and APIs and database format may change. If you can't find something, it likely got moved to a different package, or renamed -- feel free to ask if you run into problems.\nedit/save device config\ndevice management\ndashboard showing each device and collected parameters\nREST api for devices\nparticle.io support\nboltdb support\nuser authentication\nuser accounts\ngroup support (assign users and devices to a group so users can only see devices they own).\nModbus RTU pkg (both client and server)\nCommand line Modbus utlity\nrules engine (conditions/consequences)\nsms notifications\nmodem/network management\nNATS.io integration (WIP)\nfile transfer over NATs (used for sw updates)\nefficient protocols for cellular data connections (NATs/protobuf)\nModbus RTU support in SIOT\nModbus TCP support in SIOT\nTwilio SMS notifications\ninfluxdb 2.x support\nsynchronization with upstream instances\nemail notifications\nCOAP API for devices\nstore timeseries data in bolt\nesp32 client example\ngraph timeseries data\nWiFi management\nGraphs\nSupport, Community, Contributing, etc.\nPull requests are welcome -- see development for more thoughts on architecture, tooling, etc. Issues are labelled with \"help wanted\" and \"good first issue\" if you would like to contribute to this project.\nFor support or to discuss this project, use one of the following options:\nSimple IoT community forum\n#simpleiot Slack channel is available on gophers.slack.com\nopen a Github issue\nOther resources:\nSimple IoT YouTube channel\nLicense\nApache Version 2.0", "link": "https://github.com/simpleiot/simpleiot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "simple iot is collection of building blocks to help you build custom iot systems quickly, but yet provide full flexibility to customize the system. many features such as device communication, device update, rules, user/group management, user portal, etc. are needed for every iot system. this project provides a solid foundation of common features so that you can focus on the specific problem you are solving.\nguiding principles\nsimple concepts are flexible and scale well.\nthere are more problems to solve than people to solve them, thus it makes sense to collaborate on the common technology pieces.\nthere are a lot of iot applications that are not google scale (10-1000 device range).\nthere is significant opportunity in the long tail of iot, which is our focus.\nthere is value in custom solutions (programming vs drag-n-drop).\nthere is value in running/owning our own platform.\na single engineer should be able to build and deploy a custom iot system.\nwe don't need to spend excessive amounts of time on operations. for smaller deployments, we deploy one binary to a cloud server and we are done with operations. we don't need 20 microservices when one monolith will work just fine.\nfor many applications, a couple hours of down time is not the end of the world. thus a single server that can be quickly rebuilt as needed is adequate and in many cases more reliable than complex systems with many moving parts.\ncore features/requirements:\nruns in cloud and edge instances.\nconfiguration changes can be made at either cloud, ui, or edge and are synchronized efficiently in any direction.\nefficient use of network bandwidth for edge systems as most are connected via low cost cellular plans.\nrules can run in cloud or edge devices depending on action required (sending notifications or controlling outputs).\nsystem supports user authentication and grouping users and devices at multiple levels.\nuser interface updates to changes in real time.\neasy to add custom logic/algorithms by adding processes written in any language that connect to simple iot via nats.\niot systems are inherently distributed, so even though we prefer a monolith for a cloud service, we can't get around the fact that we also need to synchronize data with edge devices and user interfaces.\nsimple iot is built on simple data structures arranged in a graph that allows for very flexible configurations.\nbecause the core of simple iot is designed with flexible data structures, adding functionality and supporting new devices is usually as simple as creating your custom edge device code and modifying the ui to display and configure your device features.\nthough we are focusing on smaller deployments initially, there is no reason simple iot can't scale to large systems by swapping out the internal database for mongodb/dgraph/influxdb/etc.\nsee vision and architecture for addition discussion on these points.\nthis project was developed while building real-world applications and has primarily been driven by these project requirements. this project provides\nan stand-alone application that can be deployed at the edge or in the cloud\npackages for implementing an edge application to run on embedded linux systems.\nthe simple iot project also includes open source gateway firmware and hardware designs.\ndetailed documentation\nexample 1\nthis example (build only tested on linux and macos) shows how to run the server and send data to it:\nbuild simple iot or download the latest release:\ninstall go v1.14 (newer versions will likely work) and node/npm (tested with v12 and v14)\ngit clone https://github.com/simpleiot/simpleiot.git\ncd simpleiot\n. envsetup.sh (note space is required between . and envsetup.sh. another way to type this is source envsetup.sh. this command populates your terminal session with all the functions defined in envsetup.sh.)\nsiot_setup\nsiot_build\nnow, run the example:\nin one terminal, start server: ./siot\nopen http://localhost:8080\nlogin with user admin@admin.com and password admin\nin another terminal, send some data\nusing http: ./siot -sendpoint \"1823:t1:23.5:temp\"\nusing nats: ./siot -sendpointnats \"1234:v2:12.5:volt\"\n(the format of the -sendpoint argument is: devid:sensid:value:type)\nin a few seconds, devices should be populated in the web application\nsiot web interface screenshot\nbelow is a screenshot of the siot web interface with the above data.\nexample 2 (send commands/files to device)\n./siot\nin another terminal, start edge device example: go run cmd/edge/main.go\nin a 3rd terminal:\nsend command to device: ./siot -sendcmd=settank:150\nsend file to device: ./siot -sendfile=https://raw.githubusercontent.com/simpleiot/simpleiot/master/readme.md\nexample 3 (send data with acknowledgments from server)\n./siot -sendpointnats \"1234:v2:12.5:volt\" -natsack\nexample 4 (send version information to server)\nhardware version information is a point that encodes the version information in the text field of a point.\n./siot -sendpointtext \"1234::1:hwversion\n./siot -sendpointtext \"1234::2:osversion\n./siot -sendpointtext \"1234::3:appversion\nflexible node view\ninformation is arranged in a flexible node/-----> tree !!!  which allows for easy grouping of users, devices, and device attributes.\neach nodes can be expanded to edit/view attributes\nextensive support for modbus devices\nsimple iot can function as either a modbus tcp/rtu master or client.\nupstream support\nsimple iot is designed such that one instance can be run at the edge and connect to another instance in the cloud. the tree in the edge instance is simply mirrored in the upstream tree. changes at either place are synchronized in real-time. if one device is offline, the changes are synchronized the next time they are connected. see the below video for a demo of this.\nrules and notifications\nsimple iot rules can be used to set node values and to trigger notifications.\nconfiguration\nsimple iot can be configured for basic options such as port numbers, etc.\nadditionally, command line option help can be viewed by running siot --help.\ndashboard and graphing\nalthough simple iot provides a rudimentary dashboard and device listing, it does not provide graphs yet. if you need graphs, using influxdb + grafana may be a good interim solution. contact us if you need help setting this up -- it is relatively simple.\nfeatures\nnote, simple iot is under heavy development right now and apis and database format may change. if you can't find something, it likely got moved to a different package, or renamed -- feel free to ask if you run into problems.\nedit/save device config\ndevice management\ndashboard showing each device and collected parameters\nrest api for devices\nparticle.io support\nboltdb support\nuser authentication\nuser accounts\ngroup support (assign users and devices to a group so users can only see devices they own).\nmodbus rtu pkg (both client and server)\ncommand line modbus utlity\nrules engine (conditions/consequences)\nsms notifications\nmodem/network management\nnats.io integration (wip)\nfile transfer over nats (used for sw updates)\nefficient protocols for cellular data connections (nats/protobuf)\nmodbus rtu support in siot\nmodbus tcp support in siot\ntwilio sms notifications\ninfluxdb 2.x support\nsynchronization with upstream instances\nemail notifications\ncoap api for devices\nstore timeseries data in bolt\nesp32 client example\ngraph timeseries data\nwifi management\ngraphs\nsupport, community, contributing, etc.\npull requests are welcome -- see development for more thoughts on architecture, tooling, etc. issues are labelled with \"help wanted\" and \"good first issue\" if you would like to contribute to this project.\nfor support or to discuss this project, use one of the following options:\nsimple iot community forum\n#simpleiot slack channel is available on gophers.slack.com\nopen a github issue\nother resources:\nsimple iot youtube channel\nlicense\napache version 2.0", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000710, "year": null}, {"Unnamed: 0": 717, "autor": 717, "date": null, "content": "Bleeper is a library to manage your firmware configurations written in C++ for ESP8266 and ESP32 Arduino Platforms.\nFeatures\nWhy Bleeper\nUsage\nInstallation\nArduino IDE\nPlatformIO IDE for Atom\nFuture Work\nFeatures\nFully customizable hierarchical configuration structure\nGeneric property types\nAutomatic storage with property granularity (EEPROM & SPIFFS)\nWifi & AP connections\nConfiguration interfaces (web panel by default)\nObserve any configuration property change through the observer API\nWhy Bleeper\nIn the scenario of prototyping with hardware devices you will likely end up with a bunch of configuration settings like pin numbers, sensor thresholds, device ids, connection credentials, port numbers, and so many others.\nAs a good programmer you decide to define these configurations in a \"configuration file\" with a lot of #define macros or constants.\nBut... what if you want to change those values? Downloading the firmware each time is tedious. Think about the cases where you have multiple devices to configure or even worst you don't have close physical access to them.\nAt the end you realize that you actually need some sort of \"Configuration Manager\" with high level features like exposing those variables on a web panel (or another type of interface), persisting some of them (usually your Wifi credentials) and so on.\nUsage\nSuppose that you have this configuration:\nThe above tree structure speaks by its own, what's worth to mention here is that we want wifi.ssid and wifi.passwrod to be persistent using the Bleeper storage.\nThe C++ code will look like this:\n#include \"Bleeper.h\"\nclass Config: public RootConfiguration {\npublic:\nstringVar(name, \"Default Device Name\");\nsubconfig(WifiConfig, wifi);\nsubconfig(LedsConfig, leds);\n};\nclass WifiConfig: public Configuration {\npublic:\npersistentStringVar(ssid, \"MySSID\");\npersistentStringVar(password, \"MyPassword\");\n};\nclass LedsConfig: public Configuration {\npublic:\nfloatVar(calibration, 1.5);\nsubconfig(SPIConfig, spi);\n};\nclass SPIConfig: public Configuration {\npublic:\nintVar(speed, 1000000);\n};\nBasically, per each configuration node you have to implement a subclass of Configuration and a RootConfiguration subclass for the especial root node (i.e the top level entry).\nFor a full documentation on how properties are defined read here.\nOnce we completed our configuration structure we can use it like this:\n// Your Config instance\nConfig C;\nvoid loop() {\n// access to your spi speed config\nint speed = C.leds.spi.speed\n}\nNote that all variables are type-safe. You are not accessing to a generic wrapper and casting its type.\nThe final step is to setup the Bleeper singleton instance with your RootConfiguration instance and specify your connections, interfaces, storage and observers.\n#include \"Bleeper.h\"\nclass CalibrationObserver: public ConfigurationObserver {\npublic:\nvoid onConfigurationChanged(const ConfigurationPropertyChange value) {\nSerial.println(\"Configuration \" + value.key + \" changed from \" + value.oldValue + \" to \" + value.newValue);\n}\n};\nConfig C;\nvoid setup() {\nBleeper\n.verbose(115200)\n.configuration\n.set(&C)\n.addObserver(new CalibrationObserver(), {&C.leds.calibration})\n.done()\n.configurationInterface\n.addDefaultWebServer()\n.done()\n.connection\n.setSingleConnectionFromPriorityList({\nnew Wifi(&C.wifi.ssid, &C.wifi.password),\nnew AP() // fallback\n})\n.done()\n.storage\n.setDefault() // EEPROM\n// .set(new SPIFFSStorage()) // SPIFFS\n.done()\n.init();\n}\nvoid loop() {\nBleeper.handle();\n}\nBasically Bleeper exposes four entry points:\nBleeper.configuration\nLets you set your RootConfiguration instance and add observers to changes on it. In this example we are setting the CalibrationObserver instance that will be only notified about changes on the C.leds.calibration property.\nBleeper.configurationInterface\nHere you can add as many ConfigurationInterface instances as you want. Bleeper provides a default web panel when calling addDefaultWebServer.\nBleeper.connection\nUnder connection we can call setMultipleConnections or setSingleConnectionFromPriorityList (in which only one connection will be active) and provide a list of Connection instances. By default the Wifi class will observe changes on the provided credentials and retry the connection accordingly.\nBleeper.storage\nLets you specify the Storage instance to use when saving your persistent variables. Calling setDefault will use the default EEPROM storage automatically. You can also use SPIFFSStorage or create your own instead.\nInstallation\nArduino IDE\nGo to Sketch > Include Library > Manage Libraries...\nSearch for Bleeper and click on Install\nPlatformIO IDE\nGo to your platformio.ini file and add the following lines:\nlib_deps = Bleeper\nlib_ldf_mode = deep\nFuture Work\nAdd support for other boards.\nImprove documentation & examples.\nAdd CI server & tests.\nAuthor\nDiego Ernst", "link": "https://github.com/workilabs/Bleeper", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "bleeper is a library to manage your firmware configurations written in c++ for esp8266 and esp32 arduino platforms.\nfeatures\nwhy bleeper\nusage\ninstallation\narduino ide\nplatformio ide for atom\nfuture work\nfeatures\nfully customizable hierarchical configuration structure\ngeneric property types\nautomatic storage with property granularity (eeprom & spiffs)\nwifi & ap connections\nconfiguration interfaces (web panel by default)\nobserve any configuration property change through the observer api\nwhy bleeper\nin the scenario of prototyping with hardware devices you will likely end up with a bunch of configuration settings like pin numbers, sensor thresholds, device ids, connection credentials, port numbers, and so many others.\nas a good programmer you decide to define these configurations in a \"configuration file\" with a lot of #define macros or constants.\nbut... what if you want to change those values? downloading the firmware each time is tedious. think about the cases where you have multiple devices to configure or even worst you don't have close physical access to them.\nat the end you realize that you actually need some sort of \"configuration manager\" with high level features like exposing those variables on a web panel (or another type of interface), persisting some of them (usually your wifi credentials) and so on.\nusage\nsuppose that you have this configuration:\nthe above -----> tree !!!  structure speaks by its own, what's worth to mention here is that we want wifi.ssid and wifi.passwrod to be persistent using the bleeper storage.\nthe c++ code will look like this:\n#include \"bleeper.h\"\nclass config: public rootconfiguration {\npublic:\nstringvar(name, \"default device name\");\nsubconfig(wificonfig, wifi);\nsubconfig(ledsconfig, leds);\n};\nclass wificonfig: public configuration {\npublic:\npersistentstringvar(ssid, \"myssid\");\npersistentstringvar(password, \"mypassword\");\n};\nclass ledsconfig: public configuration {\npublic:\nfloatvar(calibration, 1.5);\nsubconfig(spiconfig, spi);\n};\nclass spiconfig: public configuration {\npublic:\nintvar(speed, 1000000);\n};\nbasically, per each configuration node you have to implement a subclass of configuration and a rootconfiguration subclass for the especial root node (i.e the top level entry).\nfor a full documentation on how properties are defined read here.\nonce we completed our configuration structure we can use it like this:\n// your config instance\nconfig c;\nvoid loop() {\n// access to your spi speed config\nint speed = c.leds.spi.speed\n}\nnote that all variables are type-safe. you are not accessing to a generic wrapper and casting its type.\nthe final step is to setup the bleeper singleton instance with your rootconfiguration instance and specify your connections, interfaces, storage and observers.\n#include \"bleeper.h\"\nclass calibrationobserver: public configurationobserver {\npublic:\nvoid onconfigurationchanged(const configurationpropertychange value) {\nserial.println(\"configuration \" + value.key + \" changed from \" + value.oldvalue + \" to \" + value.newvalue);\n}\n};\nconfig c;\nvoid setup() {\nbleeper\n.verbose(115200)\n.configuration\n.set(&c)\n.addobserver(new calibrationobserver(), {&c.leds.calibration})\n.done()\n.configurationinterface\n.adddefaultwebserver()\n.done()\n.connection\n.setsingleconnectionfromprioritylist({\nnew wifi(&c.wifi.ssid, &c.wifi.password),\nnew ap() // fallback\n})\n.done()\n.storage\n.setdefault() // eeprom\n// .set(new spiffsstorage()) // spiffs\n.done()\n.init();\n}\nvoid loop() {\nbleeper.handle();\n}\nbasically bleeper exposes four entry points:\nbleeper.configuration\nlets you set your rootconfiguration instance and add observers to changes on it. in this example we are setting the calibrationobserver instance that will be only notified about changes on the c.leds.calibration property.\nbleeper.configurationinterface\nhere you can add as many configurationinterface instances as you want. bleeper provides a default web panel when calling adddefaultwebserver.\nbleeper.connection\nunder connection we can call setmultipleconnections or setsingleconnectionfromprioritylist (in which only one connection will be active) and provide a list of connection instances. by default the wifi class will observe changes on the provided credentials and retry the connection accordingly.\nbleeper.storage\nlets you specify the storage instance to use when saving your persistent variables. calling setdefault will use the default eeprom storage automatically. you can also use spiffsstorage or create your own instead.\ninstallation\narduino ide\ngo to sketch > include library > manage libraries...\nsearch for bleeper and click on install\nplatformio ide\ngo to your platformio.ini file and add the following lines:\nlib_deps = bleeper\nlib_ldf_mode = deep\nfuture work\nadd support for other boards.\nimprove documentation & examples.\nadd ci server & tests.\nauthor\ndiego ernst", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000717, "year": null}, {"Unnamed: 0": 786, "autor": 786, "date": null, "content": "Usage\nInstall dependencies\nruby\nruby-dev\ngem\ngem-dev\ngem rake\ndocker engine\nInstall rebuild CLI\ngem install rbld\nSearch for pre-created environments on Docker Hub\nrbld search\nDeploy environment for Raspberry Pi\nrbld deploy rpi-raspbian:v001\nBuild code for Raspberry Pi\ncd code-location\nrbld run rpi-raspbian:v001 -- make -j8\nDeploy environment for BeagleBoard-X15\nrbld deploy bb-x15:16-05\nBuild code for BeagleBoard-X15\ncd code-location\nrbld run bb-x15:16-05 -- make -j8\nCreate environment for Raspberry Pi\ngit clone git://github.com/raspberrypi/tools.git rpi-tools\nrbld create --base ubuntu:16.04 rpi-raspbian\nrbld modify rpi-raspbian:initial\n>> sudo apt-get update\n>> sudo apt-get install -y make\n>> TOOLCHAIN=gcc-linaro-arm-linux-gnueabihf-raspbian-x64\n>> sudo cp -r rpi-tools/arm-bcm2708/$TOOLCHAIN /\n>> echo export CC=/$TOOLCHAIN/bin/arm-linux-gnueabihf- | sudo tee -a /rebuild/rebuild.rc\n>> exit\nrbld commit rpi-raspbian --tag v001\nProject documentation\nProject WiKi at GitHub: https://github.com/rbld/rebuild/wiki\nLiving Documentation at RelishApp: http://www.relishapp.com/rebuild/rebuild\nRebuild CLI gem\nAvailable at RubyGems: https://rubygems.org/gems/rbld\nRunning tests\nrebuild test suite is based on cucumber/aruba:\nRun bundle to install cucumber, aruba and other dependencies\nRun cucumber [OPTIONS] in the source tree root:\ncucumber to run all tests using binaries from the working copy\ncucmber -p installed to run tests using installed binaries\ncucumber -t ~@slow to exclude slow tests\nUse environment variable registry_type to control registry type used during tests:\nregistry_type=rebuild cucumber ... to use native rebuild registry (default)\nregistry_type=docker cucumber ... to use docker registry\nregistry_type=dockerhub cucumber ... to use Docker Hub (Docker Hub credentials needed)\nRebuild is licensed under the Apache License, Version 2.0.\nSee LICENSE for the full license text.", "link": "https://github.com/rbld/rebuild", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "usage\ninstall dependencies\nruby\nruby-dev\ngem\ngem-dev\ngem rake\ndocker engine\ninstall rebuild cli\ngem install rbld\nsearch for pre-created environments on docker hub\nrbld search\ndeploy environment for raspberry pi\nrbld deploy rpi-raspbian:v001\nbuild code for raspberry pi\ncd code-location\nrbld run rpi-raspbian:v001 -- make -j8\ndeploy environment for beagleboard-x15\nrbld deploy bb-x15:16-05\nbuild code for beagleboard-x15\ncd code-location\nrbld run bb-x15:16-05 -- make -j8\ncreate environment for raspberry pi\ngit clone git://github.com/raspberrypi/tools.git rpi-tools\nrbld create --base ubuntu:16.04 rpi-raspbian\nrbld modify rpi-raspbian:initial\n>> sudo apt-get update\n>> sudo apt-get install -y make\n>> toolchain=gcc-linaro-arm-linux-gnueabihf-raspbian-x64\n>> sudo cp -r rpi-tools/arm-bcm2708/$toolchain /\n>> echo export cc=/$toolchain/bin/arm-linux-gnueabihf- | sudo tee -a /rebuild/rebuild.rc\n>> exit\nrbld commit rpi-raspbian --tag v001\nproject documentation\nproject wiki at github: https://github.com/rbld/rebuild/wiki\nliving documentation at relishapp: http://www.relishapp.com/rebuild/rebuild\nrebuild cli gem\navailable at rubygems: https://rubygems.org/gems/rbld\nrunning tests\nrebuild test suite is based on cucumber/aruba:\nrun bundle to install cucumber, aruba and other dependencies\nrun cucumber [options] in the source -----> tree !!!  root:\ncucumber to run all tests using binaries from the working copy\ncucmber -p installed to run tests using installed binaries\ncucumber -t ~@slow to exclude slow tests\nuse environment variable registry_type to control registry type used during tests:\nregistry_type=rebuild cucumber ... to use native rebuild registry (default)\nregistry_type=docker cucumber ... to use docker registry\nregistry_type=dockerhub cucumber ... to use docker hub (docker hub credentials needed)\nrebuild is licensed under the apache license, version 2.0.\nsee license for the full license text.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000786, "year": null}, {"Unnamed: 0": 937, "autor": 937, "date": null, "content": "ThingFlow\nThingFlow is a (Python3) framework for building IoT event processing dataflows. [1] The goal of this framework is to support the creation of robust IoT systems from reusable components. These systems must account for noisy/missing sensor data, distributed computation, and the need for local (near the data source) processing.\nThe source repository for ThingFlow-python is at https://github.com/mpi-sws-rse/thingflow-python.\nIntroduction\nThe fundamental abstractions in ThingFlow are:\nsensors, which provide a means to sample a changing value representing some quanity in the physical world,\nevent streams, which are push-based sequences of sensor data readings, and\nthings, which are reusable components to generate, transform, or consume the events on these streams.\nThings can have simple, stateless logic (e.g. filter events based on a predicate) or implement more complex, stateful algorithms, such as Kalman filters or machine learning. Using ThingFlow, you describe the flow of data through these things rather than programming low-level behaviors.\nAlthough ThingFlow presents a simple dataflow model to the user, internally it uses an event-driven programming model, building on Python's asyncio module. In addition to being a natural programming model for realtime sensor data, it reduces the potential resource consumption of Ant Events programs. The details of event scheduling are handled by the framework. Separate threads may be used on the \"edges\" of a dataflow, where elements frequently interact with external components that have blocking APIs.\nThingFlow integrates with standard Python data analytics frameworks, including NumPy, Pandas, and scikit-learn. This allows dataflows involving complex elements to be developed and refined offline and then deployed in an IoT environment using the same code base.\nWe call the implementation described here \"ThingFlow-Python\", as it should be possible to port the ideas of ThingFlow to other languages. Currently, one such port exists: \"ThingFlow-MicroPython\". This is a port ThingFlow to MicroPython, a limited version of Python 3 that runs \"bare metal\" on embadded devices. The ThingFlow-MicroPython port is included in the ThingFlow-Python repository under the subdirector micropython. It is documented in a chapter of the documentation.\nExample\nTo give the flavor of ThingFlow, below is a short code snippet for the Raspberry Pi that reads a light sensor and then turns on an LED if the running average of the last five readings is greater than some threshold:\nlux = SensorAsOutputThing(LuxSensor())\nlux.map(lambda e: e.val).running_avg(5).map(lambda v: v > THRESHOLD)\\\n.GpioPinOut()\nscheduler.schedule_periodic(lux, 60.0)\nscheduler.run_forever()\nThe first line instantiates a light sensor object and wraps it in an output thing to handle sampling and progagation of events.\nThe next two lines create a pipeline of things to process the data from the sensor. We call things which have a single input and output filters, as they can be composed to process a stream of events. The map filter extracts the data value from the sensor event, the running_avg filter averages the last five values, and the next map filter converts the value to a a boolean based on the threshold. The GpioPinOut thing is an adapter to the outside world. It turns on the LED based on the value of its input boolean value.\nFinally, the last two lines of the example schedule the sensor to be sampled at a sixty second interval and then start the scheduler's main loop.\nDependencies\nThe ThingFlow proper is self-contained. You do not need any dependencies other than Python 3 (3.4 or later). Specific adapters and sensors may have additional dependencies (e.g. the MQTT adapters depend on MQTT client libraries).\nDocumentation\nDocumentation is hosted online at http://thingflow-python.readthedocs.io.\nThe source tree for the documentation is in the docs subdirectory - it is built using Sphinx. If you have Sphinx installed locally (along with the \"Read the Docs\" theme), you can also build it directly on your machine.\n[1]ThingFlow was originally known as AntEvents.", "link": "https://github.com/mpi-sws-rse/thingflow-python", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "thingflow\nthingflow is a (python3) framework for building iot event processing dataflows. [1] the goal of this framework is to support the creation of robust iot systems from reusable components. these systems must account for noisy/missing sensor data, distributed computation, and the need for local (near the data source) processing.\nthe source repository for thingflow-python is at https://github.com/mpi-sws-rse/thingflow-python.\nintroduction\nthe fundamental abstractions in thingflow are:\nsensors, which provide a means to sample a changing value representing some quanity in the physical world,\nevent streams, which are push-based sequences of sensor data readings, and\nthings, which are reusable components to generate, transform, or consume the events on these streams.\nthings can have simple, stateless logic (e.g. filter events based on a predicate) or implement more complex, stateful algorithms, such as kalman filters or machine learning. using thingflow, you describe the flow of data through these things rather than programming low-level behaviors.\nalthough thingflow presents a simple dataflow model to the user, internally it uses an event-driven programming model, building on python's asyncio module. in addition to being a natural programming model for realtime sensor data, it reduces the potential resource consumption of ant events programs. the details of event scheduling are handled by the framework. separate threads may be used on the \"edges\" of a dataflow, where elements frequently interact with external components that have blocking apis.\nthingflow integrates with standard python data analytics frameworks, including numpy, pandas, and scikit-learn. this allows dataflows involving complex elements to be developed and refined offline and then deployed in an iot environment using the same code base.\nwe call the implementation described here \"thingflow-python\", as it should be possible to port the ideas of thingflow to other languages. currently, one such port exists: \"thingflow-micropython\". this is a port thingflow to micropython, a limited version of python 3 that runs \"bare metal\" on embadded devices. the thingflow-micropython port is included in the thingflow-python repository under the subdirector micropython. it is documented in a chapter of the documentation.\nexample\nto give the flavor of thingflow, below is a short code snippet for the raspberry pi that reads a light sensor and then turns on an led if the running average of the last five readings is greater than some threshold:\nlux = sensorasoutputthing(luxsensor())\nlux.map(lambda e: e.val).running_avg(5).map(lambda v: v > threshold)\\\n.gpiopinout()\nscheduler.schedule_periodic(lux, 60.0)\nscheduler.run_forever()\nthe first line instantiates a light sensor object and wraps it in an output thing to handle sampling and progagation of events.\nthe next two lines create a pipeline of things to process the data from the sensor. we call things which have a single input and output filters, as they can be composed to process a stream of events. the map filter extracts the data value from the sensor event, the running_avg filter averages the last five values, and the next map filter converts the value to a a boolean based on the threshold. the gpiopinout thing is an adapter to the outside world. it turns on the led based on the value of its input boolean value.\nfinally, the last two lines of the example schedule the sensor to be sampled at a sixty second interval and then start the scheduler's main loop.\ndependencies\nthe thingflow proper is self-contained. you do not need any dependencies other than python 3 (3.4 or later). specific adapters and sensors may have additional dependencies (e.g. the mqtt adapters depend on mqtt client libraries).\ndocumentation\ndocumentation is hosted online at http://thingflow-python.readthedocs.io.\nthe source -----> tree !!!  for the documentation is in the docs subdirectory - it is built using sphinx. if you have sphinx installed locally (along with the \"read the docs\" theme), you can also build it directly on your machine.\n[1]thingflow was originally known as antevents.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000937, "year": null}, {"Unnamed: 0": 967, "autor": 967, "date": null, "content": "Syscoin integration/staging tree\nhttps://www.syscoin.org\nCopyright (c) 2009-2014 Bitcoin Developers Copyright (c) 2013-2018 Syscoin Developers\nWhat is Syscoin?\nSyscoin is a merge-minable SHA256 coin which provides an array of useful services which leverage the bitcoin protocol and blockchain technology.\n1 minute block targets, diff retarget each block using KGW(7/98)\nFlexible rewards schedule paying 25% to miners and 75% to masternodes\n888 million total coins\nSHA256 Proof of Work\nFast-response KGW difficulty adjustment algorithm\nMerge mineable with any PoW coin\nMinable either exclusively or via merge-mining\nNetwork service fees burned\nServices include:\nDecentralized Identity reservation, ownership & exchange\nDigital certificate storage, ownership & exchange\nDistributed marketplate & exchange\nDigital Services Provider marketplace & platform\nDigital Asset Creation and Management\nDecentralized Escrow service\nFor more information, as well as an immediately useable, binary version of the Syscoin client sofware, see https://www.syscoin.org.\nLicense\nSyscoin is released under the terms of the MIT license. See COPYING for more information or see http://opensource.org/licenses/MIT.\nDevelopment process\nDevelopers work in their own trees, then submit pull requests when they think their feature or bug fix is ready.\nIf it is a simple/trivial/non-controversial change, then one of the Syscoin development team members simply pulls it.\nIf it is a more complicated or potentially controversial change, then the patch submitter will be asked to start a discussion (if they haven't already) on the mailing list.\nThe patch will be accepted if there is broad consensus that it is a good thing. Developers should expect to rework and resubmit patches if the code doesn't match the project's coding conventions (see doc/coding.txt) or are controversial.\nThe master branch is regularly built and tested, but is not guaranteed to be completely stable. Tags are created regularly to indicate new official, stable release versions of Syscoin.\nTesting\nTesting and code review is the bottleneck for development; we get more pull requests than we can review and test. Please be patient and help out, and remember this is a security-critical project where any mistake might cost people lots of money.\nAutomated Testing\nDevelopers are strongly encouraged to write unit tests for new code, and to submit new unit tests for old code.\nUnit tests for the core code are in src/test/. To compile and run them:\nmake; cd src/test; ./test_syscoin;", "link": "https://github.com/syscoin/syscoin1", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "syscoin integration/staging -----> tree !!! \nhttps://www.syscoin.org\ncopyright (c) 2009-2014 bitcoin developers copyright (c) 2013-2018 syscoin developers\nwhat is syscoin?\nsyscoin is a merge-minable sha256 coin which provides an array of useful services which leverage the bitcoin protocol and blockchain technology.\n1 minute block targets, diff retarget each block using kgw(7/98)\nflexible rewards schedule paying 25% to miners and 75% to masternodes\n888 million total coins\nsha256 proof of work\nfast-response kgw difficulty adjustment algorithm\nmerge mineable with any pow coin\nminable either exclusively or via merge-mining\nnetwork service fees burned\nservices include:\ndecentralized identity reservation, ownership & exchange\ndigital certificate storage, ownership & exchange\ndistributed marketplate & exchange\ndigital services provider marketplace & platform\ndigital asset creation and management\ndecentralized escrow service\nfor more information, as well as an immediately useable, binary version of the syscoin client sofware, see https://www.syscoin.org.\nlicense\nsyscoin is released under the terms of the mit license. see copying for more information or see http://opensource.org/licenses/mit.\ndevelopment process\ndevelopers work in their own trees, then submit pull requests when they think their feature or bug fix is ready.\nif it is a simple/trivial/non-controversial change, then one of the syscoin development team members simply pulls it.\nif it is a more complicated or potentially controversial change, then the patch submitter will be asked to start a discussion (if they haven't already) on the mailing list.\nthe patch will be accepted if there is broad consensus that it is a good thing. developers should expect to rework and resubmit patches if the code doesn't match the project's coding conventions (see doc/coding.txt) or are controversial.\nthe master branch is regularly built and tested, but is not guaranteed to be completely stable. tags are created regularly to indicate new official, stable release versions of syscoin.\ntesting\ntesting and code review is the bottleneck for development; we get more pull requests than we can review and test. please be patient and help out, and remember this is a security-critical project where any mistake might cost people lots of money.\nautomated testing\ndevelopers are strongly encouraged to write unit tests for new code, and to submit new unit tests for old code.\nunit tests for the core code are in src/test/. to compile and run them:\nmake; cd src/test; ./test_syscoin;", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000967, "year": null}, {"Unnamed: 0": 990, "autor": 990, "date": null, "content": "pico-engine\nAn implementation of the pico-engine hosted on node.js\nGetting Started / Installing / Configuration\nSee packages/pico-engine for detailed step-by-step instructions to get started.\nContributing\nThis section is for those who want to contribute to the pico-engine source code. KRL programmers would be better off following the link in the previous section.\nThe pico-engine is made up of several smaller modules. Each with their own documentation and test suite.\nHowever they live in this repository in the packages/ directory (mono-repo style using lerna)\npico-engine - this is the npm package people install and use\npico-engine-core - executes compiled KRL and manages event life-cycle\npico-engine-ui - the default UI of pico-engine\nkrl-stdlib - standard library for KRL\nkrl-compiler - compiles AST into a JavaScript module\nkrl-parser - parses KRL to produce an abstract syntax tree (String -> AST)\nkrl-generator - generates KRL from an AST (AST -> String)\nkrl-editor - in browser editor for KRL\nTo run the pico-engine in development mode do the following:\n$ git clone https://github.com/Picolab/pico-engine.git\n$ cd pico-engine\n$ npm run setup\n$ npm start\nThat will start the server and run the test. npm start is simply an alias for cd packages/pico-engine && npm start\nNOTE about dependencies: generally don't use npm i, rather use npm run setup from the root. lerna will link up the packages so when you make changes in one package, it will be used in others.\nWorking in sub-package\nEach sub-package has it's own tests. And the npm start command is wired to watch for file changes and re-run tests when you make changes. For example, to make changes to the parser:\n$ cd packages/krl-parser/\n$ npm start\nNOTE: When running via npm start the PICO_ENGINE_HOME will default to your current directory i.e. your clone of this repository.\nMaking changes\nUse a branch (or fork) to do your work. When you are ready, create a pull request. That way we can review it before merging it into master.\nThe Pico Labs documentation has a page inviting contributions and giving a step-by-step example, at Pico Engine welcoming your contributions.\nChangelog\nTo view details about versions: CHANGELOG.md\nLicense\nMIT", "link": "https://github.com/Picolab/pico-engine", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "pico-engine\nan implementation of the pico-engine hosted on node.js\ngetting started / installing / configuration\nsee packages/pico-engine for detailed step-by-step instructions to get started.\ncontributing\nthis section is for those who want to contribute to the pico-engine source code. krl programmers would be better off following the link in the previous section.\nthe pico-engine is made up of several smaller modules. each with their own documentation and test suite.\nhowever they live in this repository in the packages/ directory (mono-repo style using lerna)\npico-engine - this is the npm package people install and use\npico-engine-core - executes compiled krl and manages event life-cycle\npico-engine-ui - the default ui of pico-engine\nkrl-stdlib - standard library for krl\nkrl-compiler - compiles ast into a javascript module\nkrl-parser - parses krl to produce an abstract syntax -----> tree !!!  (string -> ast)\nkrl-generator - generates krl from an ast (ast -> string)\nkrl-editor - in browser editor for krl\nto run the pico-engine in development mode do the following:\n$ git clone https://github.com/picolab/pico-engine.git\n$ cd pico-engine\n$ npm run setup\n$ npm start\nthat will start the server and run the test. npm start is simply an alias for cd packages/pico-engine && npm start\nnote about dependencies: generally don't use npm i, rather use npm run setup from the root. lerna will link up the packages so when you make changes in one package, it will be used in others.\nworking in sub-package\neach sub-package has it's own tests. and the npm start command is wired to watch for file changes and re-run tests when you make changes. for example, to make changes to the parser:\n$ cd packages/krl-parser/\n$ npm start\nnote: when running via npm start the pico_engine_home will default to your current directory i.e. your clone of this repository.\nmaking changes\nuse a branch (or fork) to do your work. when you are ready, create a pull request. that way we can review it before merging it into master.\nthe pico labs documentation has a page inviting contributions and giving a step-by-step example, at pico engine welcoming your contributions.\nchangelog\nto view details about versions: changelog.md\nlicense\nmit", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000990, "year": null}, {"Unnamed: 0": 1002, "autor": 1002, "date": null, "content": "IOsonata - makes your I/Os sing\nIOsonata multi-platform multi-architecture optimized software library for fast and easy iot products development\nTurorial blog posts :\nBluetooth Low Energy firmware with a few lines of code\nNordic nRF51 & nRF52 series firmware development with Eclipse\nEclipse IDE installation guide\nAlthough this library supports multiple IDE/Compilers, the preferred IDE is still Eclipse/GCC. GCC is the de facto standard for embedded software development. Eclipse is 100% free and the most flexible IDE. It could be little overwhelming for newbies at first (like any other IDE if you are new to it anyway).\nFor desktop PC version of the library, native compiler and IDE are used. XCode for OSX, Visual Studio for Windows, Eclipse for Linux.\nIDE limiations :\nEclipse & GCC : Full C++ support, full file io support.\nIAR : Full C++ support, no system support for file io. File io only available with semihosting. Bug in IAR : It cannot debug or flash Nordic nRF series using CMSIS-DAP.\nuVision : Requires compiler version 6. Minimal support for file IO. However uVision can be configured to GCC instead.\nCrossWorks : GCC C++ is stripped down to bare bone, no file io support, no atomic support and many others. In order to use full GCC C++, CrossWorks must be configured to use an external compiler.\nSegger Stusio : Stripped down version of CrossWorks. Even less functional. Only supports jlink, cannot be used with any other jtag. SES is not recommended for heavy firmware development.\nRequired installation of external SDK and libraries :\nIn order to compile the IOsonata target libraries these external SDK & lib are required. Follow the instructions below to download and install into appropriate folder locations and naming.\nnRF5_SDK : Nordic nRF5x Bluetooth Low Energy\nnrf5_SDK_Mesh : Nordic nRF5 SDK for Bluetoth Mesh\nICM-20948 Motion_Driver : Create a user at https://invensense.tdk.com/developers/software-downloads/. In the \"Development Kits\" block, download \"DK-20948 SmartMotion eMD 1.1.0\". Unzip the downloaded file and navigate to EMD-Core/sources. Copy the folder Invn to external/Invn as indicated in the folder tree bellow.\nBSEC : Bosch Sensortec Environmental Cluster (BSEC) Software for #BME680 environmental sensor. BSEC is needed for calculating Air Quality Index. Go to https://www.bosch-sensortec.com/bst/products/all_products/bsec at the end of the page. Select checkbox to accept license terms to download. Unzip the the downloaded file. Rename the extracted folder to BSEC and copy the whole folder to external as indicated in the folder tree below.\nLWIP : A Lightweight TCP/IP stack. This library is required for IoT network connectivity over Ethernet, Wifi, LTE, ... Download it via this link https://download.savannah.nongnu.org/releases/lwip/. Rename the extracted folder as lwip and copy it to external.\nIDK-BLYST-NANO : nRF52832 Bluetooth 5.2/Bluetooth Mesh development board with builtin IDAP-M CMSIS-DAP Debug JTag\nBuy : IDK-BLYST-NANO (BLYST Nano development board).\nBuy : BLUEIO-TAG-EVIM (BLYST Nano sensor board).\nNordic Thingy App compatible firmware project\nIOsonata folder structure\nThe way the IOsonata folder is structured is simple. The deeper you go inside the more it is specific to the architecture or platform. The parent folder contains all that is commonly available to the child folder. Which means, source file from child folder can access any source in the upper parent folder but not the other way around. This is the way to keep the abstraction separated from implementation and easier to keep track of things.\n/your_root - Development root directory\n|-- external - Contains downloaded SDKs from silicon vendors\n| |-- nRF5_SDK - Latest Nordic SDK (https://developer.nordicsemi.com)\n| |-- nrf5_SDK_Mesh - Latest Nordic SDK for Mesh (https://www.nordicsemi.com/eng/nordic/Products/nRF5-SDK-for-Mesh/nRF5-SDK-for-Mesh/62377)\n| |---nRF5_SDK_12 - Last version of Nordic SDK12 for nRF51 series\n| |-- BSEC - Bosch Sensortec Environmental Cluster (BSEC) Software (https://www.bosch-sensortec.com/bst/products/all_products/bsec) for #BME680\n| |-- Invn - Invensense SmartMotion Driver (download https://www.invensense.com/developers)\n| | |-- Devices\n| | |...\n| |-- lwip - Lightweight TCP/IP stack (download https://download.savannah.nongnu.org/releases/lwip/)\n| |-- Others as require\n| |...\n| |\n|-- IOsonata - Put IOsonata here\n| |-- include - Generic include common to all platforms\n| | |-- bluetooth - Generic definition for Bluetooth\n| | |-- converters - Generic definition for ADV, DAC, etc...\n| | |-- coredev - Generic definition MCU builtin devices such as i2c, uart, spi, timer, etc...\n| | |-- miscdev - Generic definition for other non categorized devices\n| | |-- sensors - Generic definition for all sort of sensors (environmental, motion, etc...)\n| | |-- usb - Generic definition for USB\n| | |...\n| |-- src - Generic implementation source common to all platforms\n| | |-- bluetooth - Generic source for Bluetooth\n| | |-- converters - Generic source for ADV, DAC, etc...\n| | |-- coredev - Generic source for MCU builtin devices such as i2c, uart, spi, timer, etc...\n| | |-- miscdev - Generic source for other non categorized devices\n| | |-- sensors - Generic source for all sort of sensors (environmental, motion, etc...)\n| | |-- usb - Generic source for USB\n| | |...\n| |\n| |-- ARM - ARM series based MCU\n| | |-- include - Common include for all ARM platform\n| | |-- src - Common source for all ARM platform\n| | |-- DbgConfig - Debugger configuration files.\n| | |-- ldscript - Linker script files\n| | |\n| | |-- Nordic - Nordic Semiconductor based MCU\n| | | |-- nRF51 - nRF51 series MCU\n| | | | |-- include - Common include for this target series\n| | | | |-- src - Common source for this target series\n| | | | |-- lib - IOsonata library for this target\n| | | | | |-- Eclipse - Eclipse project for this lib\n| | | | | |-- IAR - IAR project for this lib\n| | | | | |-- CrossWorks- CrossWorks project for this lib\n| | | | | |...\n| | | | |\n| | | | |-- exemples - Example projects for this target\n| | | | | |-- Blink - Blink example\n| | | | | | |-- src - Source code for this exaple\n| | | | | | |-- Eclipse - Eclipse project for this example\n| | | | | | |-- IAR - IAR project for this example\n| | | | | | |-- CrossWorks- CrossWorks project for this example\n| | | | | | | |...\n| | | | | |-- Many other examples same\n| | | |\n| | | |-- nRF52 - nRF52 serie MCU\n| | | | |-- include - Common include for this target series\n| | | | |-- src - Common source for this target series\n| | | | |-- nRF52832 - Target MCU\n| | | | | |-- lib - IOsonata library for this target\n| | | | | | |-- Eclipse - Eclipse project for this lib\n| | | | | | |-- IAR - IAR project for this lib\n| | | | | | |-- CrossWorks- CrossWorks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - Example projects for this target\n| | | | | | |-- Blink - Blink example\n| | | | | | | |-- src - Source code for this exaple\n| | | | | | | |-- Eclipse - Eclipse project for this example\n| | | | | | | |-- IAR - IAR project for this example\n| | | | | | | |-- CrossWorks- CrossWorks project for this example\n| | | | | | | |...\n| | | | | | |-- Many other examples same\n| | | | | | |\n| | | | |-- nRF52840 - Target MCU\n| | | | | |-- lib - IOsonata library for this target\n| | | | | | |-- Eclipse - Eclipse project for this lib\n| | | | | | |-- IAR - IAR project for this lib\n| | | | | | |-- CrossWorks- CrossWorks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - Example projects for this target\n| | | | | | |-- Blink - Blink example\n| | | | | | | |-- src - Source code for this exaple\n| | | | | | | |-- Eclipse - Eclipse project for this example\n| | | | | | | |-- IAR - IAR project for this example\n| | | | | | | |-- CrossWorks- CrossWorks project for this example\n| | | | | | | |...\n| | | | | | |-- Many other examples same\n| | | |\n| | | |-- nRF53 - nRF53 series MCU\n| | | | |-- include - Common include for this target series\n| | | | |-- src - Common source for this target series\n| | | | |-- nRF5340_App - Target MCU\n| | | | | |-- lib - IOsonata library for this target\n| | | | | | |-- Eclipse - Eclipse project for this lib\n| | | | | | |-- IAR - IAR project for this lib\n| | | | | | |-- CrossWorks- CrossWorks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - Example projects for this target\n| | | | | | |-- Blink - Blink example\n| | | | | | | |-- src - Source code for this exaple\n| | | | | | | |-- Eclipse - Eclipse project for this example\n| | | | | | | |-- IAR - IAR project for this example\n| | | | | | | |-- CrossWorks- CrossWorks project for this example\n| | | | | | | |...\n| | | | | | |-- Many other examples same\n| | | | | | |\n| | | | |\n| | | | |-- nRF5340_Net - Target MCU\n| | | | | |-- lib - IOsonata library for this target\n| | | | | | |-- Eclipse - Eclipse project for this lib\n| | | | | | |-- IAR - IAR project for this lib\n| | | | | | |-- CrossWorks- CrossWorks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - Example projects for this target\n| | | | | | |-- Blink - Blink example\n| | | | | | | |-- src - Source code for this exaple\n| | | | | | | |-- Eclipse - Eclipse project for this example\n| | | | | | | |-- IAR - IAR project for this example\n| | | | | | | |-- CrossWorks- CrossWorks project for this example\n| | | | | | | |...\n| | | | | | |-- Many other examples same\n| | | | | | |\n| | | |\n| | | |-- nRF91 - nRF91 series MCU\n| | | | |-- include - Common include for this target series\n| | | | |-- src - Common source for this target series\n| | | | |-- nRF9160 - Target MCU\n| | | | | |-- lib - IOsonata library for this target\n| | | | | | |-- Eclipse - Eclipse project for this lib\n| | | | | | |-- IAR - IAR project for this lib\n| | | | | | |-- CrossWorks- CrossWorks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - Example projects for this target\n| | | | | | |-- Blink - Blink example\n| | | | | | | |-- src - Source code for this exaple\n| | | | | | | |-- Eclipse - Eclipse project for this example\n| | | | | | | |-- IAR - IAR project for this example\n| | | | | | | |-- CrossWorks- CrossWorks project for this example\n| | | | | | | |...\n| | | | | | |-- Many other examples same\n| | | | | | |\n| | |\n| | |-- NXP - NXP based MCU\n| | | |-- LPC11xx - LPC11xx series MCU\n| | | | |-- include - Common include for this target series\n| | | | |-- src - Common source for this target series\n| | | | |-- LPC11U35 - LPC11U35 target\n| | | | | |-- lib - IOsonata library for this target\n| | | | | | |-- Eclipse - Eclipse project for this lib\n| | | | | | |-- IAR - IAR project for this lib\n| | | | | | |-- CrossWorks- CrossWorks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - Example projects for this target\n| | | | | | |-- Blink - Blink example\n| | | | | | | |-- src - Source code for this exaple\n| | | | | | | |-- Eclipse - Eclipse project for this example\n| | | | | | | |-- IAR - IAR project for this example\n| | | | | | | |-- CrossWorks- CrossWorks project for this example\n| | | | | | | |...\n| | | | | | |-- Many other examples same\n| | | | | | |\n| | | |-- LPC17xx - LPC17xx series MCU\n| | | | |-- include - Common include for this target series\n| | | | |-- src - Common source for this target series\n| | | | |-- LPC176x - LPC176x target\n| | | | | |-- lib - IOsonata library for this target\n| | | | | | |-- Eclipse - Eclipse project for this lib\n| | | | | | |-- IAR - IAR project for this lib\n| | | | | | |-- CrossWorks- CrossWorks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - Example projects for this target\n| | | | | | |-- Blink - Blink example\n| | | | | | | |-- src - Source code for this exaple\n| | | | | | | |-- Eclipse - Eclipse project for this example\n| | | | | | | |-- IAR - IAR project for this example\n| | | | | | | |-- CrossWorks- CrossWorks project for this example\n| | | | | | | |...\n| | | | | | |-- Many other examples same\n| | | | | | |\n| | |\n| | |-- ST - ST based MCU\n| | | |-- STM32F0xx\n| | | |-- STM32F4xx\n| | | |-- STM32L0xx\n| | | |-- STM32L1xx\n| | | |-- STM32L4xx\n| | | | |-- include - Common include for this target series\n| | | | |-- src - Common source for this target series\n| | | | |-- STM32L476 - Target MCU\n| | | | | |-- lib - IOsonata library for this target\n| | | | | | |-- Eclipse - Eclipse project for this lib\n| | | | | | |-- IAR - IAR project for this lib\n| | | | | | |-- CrossWorks- CrossWorks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - Example projects for this target\n| | | | | | |-- Blink - Blink example\n| | | | | | | |-- src - Source code for this exaple\n| | | | | | | |-- Eclipse - Eclipse project for this example\n| | | | | | | |-- IAR - IAR project for this example\n| | | | | | | |-- CrossWorks- CrossWorks project for this example\n| | | | | | | |...\n| | | | | | |-- Many other examples same\n| | | | | | |\n| | |\n| | |-- Other silicon vendors\n| |...\n| |-- Linux\n| | |...\n| |-- OSX\n| | |...\n| |-- Win\n| | |...\n| ...", "link": "https://github.com/IOsonata/IOsonata", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tree", "selectorShort": "tree", "MarkedSent": "iosonata - makes your i/os sing\niosonata multi-platform multi-architecture optimized software library for fast and easy iot products development\nturorial blog posts :\nbluetooth low energy firmware with a few lines of code\nnordic nrf51 & nrf52 series firmware development with eclipse\neclipse ide installation guide\nalthough this library supports multiple ide/compilers, the preferred ide is still eclipse/gcc. gcc is the de facto standard for embedded software development. eclipse is 100% free and the most flexible ide. it could be little overwhelming for newbies at first (like any other ide if you are new to it anyway).\nfor desktop pc version of the library, native compiler and ide are used. xcode for osx, visual studio for windows, eclipse for linux.\nide limiations :\neclipse & gcc : full c++ support, full file io support.\niar : full c++ support, no system support for file io. file io only available with semihosting. bug in iar : it cannot debug or flash nordic nrf series using cmsis-dap.\nuvision : requires compiler version 6. minimal support for file io. however uvision can be configured to gcc instead.\ncrossworks : gcc c++ is stripped down to bare bone, no file io support, no atomic support and many others. in order to use full gcc c++, crossworks must be configured to use an external compiler.\nsegger stusio : stripped down version of crossworks. even less functional. only supports jlink, cannot be used with any other jtag. ses is not recommended for heavy firmware development.\nrequired installation of external sdk and libraries :\nin order to compile the iosonata target libraries these external sdk & lib are required. follow the instructions below to download and install into appropriate folder locations and naming.\nnrf5_sdk : nordic nrf5x bluetooth low energy\nnrf5_sdk_mesh : nordic nrf5 sdk for bluetoth mesh\nicm-20948 motion_driver : create a user at https://invensense.tdk.com/developers/software-downloads/. in the \"development kits\" block, download \"dk-20948 smartmotion emd 1.1.0\". unzip the downloaded file and navigate to emd-core/sources. copy the folder invn to external/invn as indicated in the folder -----> tree !!!  bellow.\nbsec : bosch sensortec environmental cluster (bsec) software for #bme680 environmental sensor. bsec is needed for calculating air quality index. go to https://www.bosch-sensortec.com/bst/products/all_products/bsec at the end of the page. select checkbox to accept license terms to download. unzip the the downloaded file. rename the extracted folder to bsec and copy the whole folder to external as indicated in the folder tree below.\nlwip : a lightweight tcp/ip stack. this library is required for iot network connectivity over ethernet, wifi, lte, ... download it via this link https://download.savannah.nongnu.org/releases/lwip/. rename the extracted folder as lwip and copy it to external.\nidk-blyst-nano : nrf52832 bluetooth 5.2/bluetooth mesh development board with builtin idap-m cmsis-dap debug jtag\nbuy : idk-blyst-nano (blyst nano development board).\nbuy : blueio-tag-evim (blyst nano sensor board).\nnordic thingy app compatible firmware project\niosonata folder structure\nthe way the iosonata folder is structured is simple. the deeper you go inside the more it is specific to the architecture or platform. the parent folder contains all that is commonly available to the child folder. which means, source file from child folder can access any source in the upper parent folder but not the other way around. this is the way to keep the abstraction separated from implementation and easier to keep track of things.\n/your_root - development root directory\n|-- external - contains downloaded sdks from silicon vendors\n| |-- nrf5_sdk - latest nordic sdk (https://developer.nordicsemi.com)\n| |-- nrf5_sdk_mesh - latest nordic sdk for mesh (https://www.nordicsemi.com/eng/nordic/products/nrf5-sdk-for-mesh/nrf5-sdk-for-mesh/62377)\n| |---nrf5_sdk_12 - last version of nordic sdk12 for nrf51 series\n| |-- bsec - bosch sensortec environmental cluster (bsec) software (https://www.bosch-sensortec.com/bst/products/all_products/bsec) for #bme680\n| |-- invn - invensense smartmotion driver (download https://www.invensense.com/developers)\n| | |-- devices\n| | |...\n| |-- lwip - lightweight tcp/ip stack (download https://download.savannah.nongnu.org/releases/lwip/)\n| |-- others as require\n| |...\n| |\n|-- iosonata - put iosonata here\n| |-- include - generic include common to all platforms\n| | |-- bluetooth - generic definition for bluetooth\n| | |-- converters - generic definition for adv, dac, etc...\n| | |-- coredev - generic definition mcu builtin devices such as i2c, uart, spi, timer, etc...\n| | |-- miscdev - generic definition for other non categorized devices\n| | |-- sensors - generic definition for all sort of sensors (environmental, motion, etc...)\n| | |-- usb - generic definition for usb\n| | |...\n| |-- src - generic implementation source common to all platforms\n| | |-- bluetooth - generic source for bluetooth\n| | |-- converters - generic source for adv, dac, etc...\n| | |-- coredev - generic source for mcu builtin devices such as i2c, uart, spi, timer, etc...\n| | |-- miscdev - generic source for other non categorized devices\n| | |-- sensors - generic source for all sort of sensors (environmental, motion, etc...)\n| | |-- usb - generic source for usb\n| | |...\n| |\n| |-- arm - arm series based mcu\n| | |-- include - common include for all arm platform\n| | |-- src - common source for all arm platform\n| | |-- dbgconfig - debugger configuration files.\n| | |-- ldscript - linker script files\n| | |\n| | |-- nordic - nordic semiconductor based mcu\n| | | |-- nrf51 - nrf51 series mcu\n| | | | |-- include - common include for this target series\n| | | | |-- src - common source for this target series\n| | | | |-- lib - iosonata library for this target\n| | | | | |-- eclipse - eclipse project for this lib\n| | | | | |-- iar - iar project for this lib\n| | | | | |-- crossworks- crossworks project for this lib\n| | | | | |...\n| | | | |\n| | | | |-- exemples - example projects for this target\n| | | | | |-- blink - blink example\n| | | | | | |-- src - source code for this exaple\n| | | | | | |-- eclipse - eclipse project for this example\n| | | | | | |-- iar - iar project for this example\n| | | | | | |-- crossworks- crossworks project for this example\n| | | | | | | |...\n| | | | | |-- many other examples same\n| | | |\n| | | |-- nrf52 - nrf52 serie mcu\n| | | | |-- include - common include for this target series\n| | | | |-- src - common source for this target series\n| | | | |-- nrf52832 - target mcu\n| | | | | |-- lib - iosonata library for this target\n| | | | | | |-- eclipse - eclipse project for this lib\n| | | | | | |-- iar - iar project for this lib\n| | | | | | |-- crossworks- crossworks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - example projects for this target\n| | | | | | |-- blink - blink example\n| | | | | | | |-- src - source code for this exaple\n| | | | | | | |-- eclipse - eclipse project for this example\n| | | | | | | |-- iar - iar project for this example\n| | | | | | | |-- crossworks- crossworks project for this example\n| | | | | | | |...\n| | | | | | |-- many other examples same\n| | | | | | |\n| | | | |-- nrf52840 - target mcu\n| | | | | |-- lib - iosonata library for this target\n| | | | | | |-- eclipse - eclipse project for this lib\n| | | | | | |-- iar - iar project for this lib\n| | | | | | |-- crossworks- crossworks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - example projects for this target\n| | | | | | |-- blink - blink example\n| | | | | | | |-- src - source code for this exaple\n| | | | | | | |-- eclipse - eclipse project for this example\n| | | | | | | |-- iar - iar project for this example\n| | | | | | | |-- crossworks- crossworks project for this example\n| | | | | | | |...\n| | | | | | |-- many other examples same\n| | | |\n| | | |-- nrf53 - nrf53 series mcu\n| | | | |-- include - common include for this target series\n| | | | |-- src - common source for this target series\n| | | | |-- nrf5340_app - target mcu\n| | | | | |-- lib - iosonata library for this target\n| | | | | | |-- eclipse - eclipse project for this lib\n| | | | | | |-- iar - iar project for this lib\n| | | | | | |-- crossworks- crossworks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - example projects for this target\n| | | | | | |-- blink - blink example\n| | | | | | | |-- src - source code for this exaple\n| | | | | | | |-- eclipse - eclipse project for this example\n| | | | | | | |-- iar - iar project for this example\n| | | | | | | |-- crossworks- crossworks project for this example\n| | | | | | | |...\n| | | | | | |-- many other examples same\n| | | | | | |\n| | | | |\n| | | | |-- nrf5340_net - target mcu\n| | | | | |-- lib - iosonata library for this target\n| | | | | | |-- eclipse - eclipse project for this lib\n| | | | | | |-- iar - iar project for this lib\n| | | | | | |-- crossworks- crossworks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - example projects for this target\n| | | | | | |-- blink - blink example\n| | | | | | | |-- src - source code for this exaple\n| | | | | | | |-- eclipse - eclipse project for this example\n| | | | | | | |-- iar - iar project for this example\n| | | | | | | |-- crossworks- crossworks project for this example\n| | | | | | | |...\n| | | | | | |-- many other examples same\n| | | | | | |\n| | | |\n| | | |-- nrf91 - nrf91 series mcu\n| | | | |-- include - common include for this target series\n| | | | |-- src - common source for this target series\n| | | | |-- nrf9160 - target mcu\n| | | | | |-- lib - iosonata library for this target\n| | | | | | |-- eclipse - eclipse project for this lib\n| | | | | | |-- iar - iar project for this lib\n| | | | | | |-- crossworks- crossworks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - example projects for this target\n| | | | | | |-- blink - blink example\n| | | | | | | |-- src - source code for this exaple\n| | | | | | | |-- eclipse - eclipse project for this example\n| | | | | | | |-- iar - iar project for this example\n| | | | | | | |-- crossworks- crossworks project for this example\n| | | | | | | |...\n| | | | | | |-- many other examples same\n| | | | | | |\n| | |\n| | |-- nxp - nxp based mcu\n| | | |-- lpc11xx - lpc11xx series mcu\n| | | | |-- include - common include for this target series\n| | | | |-- src - common source for this target series\n| | | | |-- lpc11u35 - lpc11u35 target\n| | | | | |-- lib - iosonata library for this target\n| | | | | | |-- eclipse - eclipse project for this lib\n| | | | | | |-- iar - iar project for this lib\n| | | | | | |-- crossworks- crossworks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - example projects for this target\n| | | | | | |-- blink - blink example\n| | | | | | | |-- src - source code for this exaple\n| | | | | | | |-- eclipse - eclipse project for this example\n| | | | | | | |-- iar - iar project for this example\n| | | | | | | |-- crossworks- crossworks project for this example\n| | | | | | | |...\n| | | | | | |-- many other examples same\n| | | | | | |\n| | | |-- lpc17xx - lpc17xx series mcu\n| | | | |-- include - common include for this target series\n| | | | |-- src - common source for this target series\n| | | | |-- lpc176x - lpc176x target\n| | | | | |-- lib - iosonata library for this target\n| | | | | | |-- eclipse - eclipse project for this lib\n| | | | | | |-- iar - iar project for this lib\n| | | | | | |-- crossworks- crossworks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - example projects for this target\n| | | | | | |-- blink - blink example\n| | | | | | | |-- src - source code for this exaple\n| | | | | | | |-- eclipse - eclipse project for this example\n| | | | | | | |-- iar - iar project for this example\n| | | | | | | |-- crossworks- crossworks project for this example\n| | | | | | | |...\n| | | | | | |-- many other examples same\n| | | | | | |\n| | |\n| | |-- st - st based mcu\n| | | |-- stm32f0xx\n| | | |-- stm32f4xx\n| | | |-- stm32l0xx\n| | | |-- stm32l1xx\n| | | |-- stm32l4xx\n| | | | |-- include - common include for this target series\n| | | | |-- src - common source for this target series\n| | | | |-- stm32l476 - target mcu\n| | | | | |-- lib - iosonata library for this target\n| | | | | | |-- eclipse - eclipse project for this lib\n| | | | | | |-- iar - iar project for this lib\n| | | | | | |-- crossworks- crossworks project for this lib\n| | | | | | |...\n| | | | | |\n| | | | | |-- exemples - example projects for this target\n| | | | | | |-- blink - blink example\n| | | | | | | |-- src - source code for this exaple\n| | | | | | | |-- eclipse - eclipse project for this example\n| | | | | | | |-- iar - iar project for this example\n| | | | | | | |-- crossworks- crossworks project for this example\n| | | | | | | |...\n| | | | | | |-- many other examples same\n| | | | | | |\n| | |\n| | |-- other silicon vendors\n| |...\n| |-- linux\n| | |...\n| |-- osx\n| | |...\n| |-- win\n| | |...\n| ...", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7001002, "year": null}], "name": "treeIot"}