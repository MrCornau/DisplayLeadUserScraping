{"interestingcomments": [{"autor": "R2V0IGEgbGlmZS4", "date": "2019-04-19 07:41:42", "content": "I'm an absolute beginner so bear with me. I'm doing some thought experiments that are getting my brain in a twist and I was hoping someone could explain this to me or point me to a resource that explains it.\n\nLet's say I want to train a neutral network which takes as input the intensity of each pixel of an -----> image !!!  and outputs ~1 if a specific pattern is present in the network and ~0 otherwise. The pattern is small and can appear at any pixel location on the image.\n\nIn my mind, there are two ways this pattern recognition problem could be solved:\n\n* 1) There could just be a giant dense network which effectivity learns the pattern separately for every pixel location that the pattern could be in.\n* 2) There is a subnetwork of neurons that determine whether a pattern is present in a set of pixels that somehow abstracts from pixel location.\n\nTo me, option 1) seems ludicrous. You would have to make sure every pixel location the pattern could be in is represented in the training data. This to me seems like duplicated effort -- you're learning the same thing many times. It also seems prone to local optima. It also doesn't appear to be how real brains work. Once I know what a dog looks like I know what he looks like wherever he is on my retina.\n\nSo in my mind I've concluded 2) is the right way of going about this problem. But then I don't understand how, if at all, it is possible to achieve this technically. I can't see how you could construct a network that can apply a little 'pattern recognition' network for each pixel location -- is this possible?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bewiid/image_pattern_recognition/"}, {"autor": "Stephanehk", "date": "2019-04-19 02:35:47", "content": "I would like to train a convolutional neural network on a series of before and after -----> image !!!  pairs. Ideally, the model would be able to take in 2 new images and detect if they are before and after images or not (assuming there are specific features that differentiate the before and after images). What kind of CNN structure would you recommend for doing so? I am unsure how to train a CNN on image pairs so that the CNN \"learns\" the difference between the images.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/beu521/training_a_cnn_to_find_the_difference_in_images/"}, {"autor": "dankmemelord23", "date": "2019-04-18 21:21:50", "content": "Hi, so I am working on a project where I am coding a neural network that can identify a person based on their handwriting. I'm quite new to python and tensorflow so it's hard for me to catch onto some of the coding syntax.\n\nThe part that I'm having trouble with is converting the -----> image !!!  tensors to numpy arrays for the model to train on. I could convert them directly, but I would not be able to resize the images and make them all grayscale without turning them into a dataset. And even if I have the dataset created, I'm having trouble converting the dataset into a numpy array. Can anyone help me out please? I need to finish this project soon.\n\n&amp;#x200B;\n\n(I'm using the Keras API by the way because it makes things much easier)\n\n&amp;#x200B;\n\nAttached is the code:\n\n&amp;#x200B;\n\n    import os, sys\n    import tensorflow as tf\n    from tensorflow.python.keras.models import Sequential\n    from tensorflow.python.keras.utils import *\n    from tensorflow.python.keras.layers import *\n    from tensorflow.python.keras.layers.advanced_activations import *\n    from tensorflow.python.keras.optimizers import *\n    from tensorflow.python.keras.losses import *\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import pandas as pd\n    import seaborn as sns\n    from math import floor, ceil\n    from pylab import rcParams\n    \n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n    \n    imageFile = tf.constant(['person1-1.jpg', 'person1-2.jpg', 'person1-3.jpg', 'person1-4.jpg',\n    \t\t\t\t\t\t'person2-1.jpg', 'person2-2.jpg', 'person2-3.jpg', 'person2-4.jpg',\n    \t\t\t\t\t\t'person3-1.jpg', 'person3-2.jpg', 'person3-3.jpg', 'person3-4.jpg',\n    \t\t\t\t\t\t'person4-1.jpg', 'person4-2.jpg', 'person4-3.jpg', 'person4-4.jpg',\n    \t\t\t\t\t\t'person5-1.jpg', 'person5-2.jpg', 'person5-3.jpg', 'person5-4.jpg'])\n    testFile = tf.constant(['person1-5.jpg', 'person2-5.jpg', 'person3-5.jpg', 'person4-5.jpg', 'person5-5.jpg'])\n    \n    imageLabels = tf.constant(['person1','person1','person1','person1',\n    \t\t\t\t\t\t'person2','person2','person2','person2',\n    \t\t\t\t\t\t'person3','person3','person3','person4',\n    \t\t\t\t\t\t'person4','person4','person4','person4',\n    \t\t\t\t\t\t'person5','person5','person5','person5'])\n    testLabels = tf.constant(['person1', 'person2', 'person3', 'person4', 'person5'])\n    \n    def _parse(file):\n      image_string = tf.read_file(file)\n      image_decoded = tf.image.decode_jpeg(image_string, channels = 1)\n      image = tf.cast(image_decoded, tf.float32)\n      image_resized = tf.image.resize_images(image, (1290, 560))\n      return image_resized\n    \n    trainImageSet = tf.data.Dataset.from_tensor_slices(imageFile)\n    trainImageSet = trainImageSet.map(_parse)\n    trainImageSet = trainImageSet.batch(4)\n    trainLabelSet = tf.data.Dataset.from_tensor_slices(imageLabels)\n    trainLabelSet = trainImageSet.batch(4)\n    testImageSet = tf.data.Dataset.from_tensor_slices(testFile)\n    testImageSet = testImageSet.map(_parse)\n    testImageSet = testImageSet.batch(4)\n    testLabelSet = tf.data.Dataset.from_tensor_slices(testLabels)\n    testLabelSet = trainImageSet.batch(4)\n    \n    sess = tf.Session()\n    with sess.as_default():\n    \ttrainImages = trainImageSet.eval()\n    \ttrainLabels = trainLabelSet.eval()\n    \ttestImages = testImageSet.eval()\n    \ttestLabels = testLabelSet.eval()\n    \n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = 2, input_shape = (1290, 560, 1), activation = 'relu'))\n    model.add(MaxPooling2D((2, 2), padding = 'same'))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, kernel_size = 2, activation = 'relu'))\n    model.add(MaxPooling2D((2, 2), padding = 'same'))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size = 2, activation = 'relu'))\n    model.add(MaxPooling2D((2, 2), padding = 'same'))\n    model.add(Dropout(0.25))\n    # Final layer - flattening\n    model.add(Flatten())\n    model.add(Dense(64, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation='softmax'))\n    \n    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    fit = model.fit(trainImages, trainLabels, steps_per_epoch = 4, epochs = 2, verbose = 1)\n    score = model.evaluate(testImages, testLabels, verbose = 1)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])", "link": "https://www.reddit.com/r/learnmachinelearning/comments/beqww9/i_need_help_on_my_neural_network_code/"}, {"autor": "jdmg718", "date": "2019-04-18 16:29:17", "content": "Hi there,\n\nLast week I had the opportunity to take part into some sort of hackathon that involved data. I had to make a prediction of sales using several datasets. Albeit it was very motivating for me to apply what I have learned during this last year I felt a bit lost.\n\nI don't have a CS/Statistic/ML/Data background. I am finishing my engineering programme and whereas I like the field of study I am not very motivated by it. It also has some courses related to CS and Statistics but nothing related to CS/ML. Last year I started working on a project that involved ML and used that on an app I have published on the App Store. It consists on a neural network that makes predictions of bike sharing stations availability. It required some data treatment and training the model. That said I know some of the basics and have a ML project in production already.\n\nBack to today, during the days I tried to provide a solution for the hackathon problem I noticed a huge void in how I should approach these kind of problems. I only thought of training a model and making time series predictions using LSTM networks. That is because is the only thing I know in practice to do. The problem might haven't required to use a neural network but I approached it as if it needed that. I tried to find a logic relation between the data provided in the files but I didn't really knew what columns of each dataset were sufficiently relevant for the problem. Are there some resources/courses I could watch/read/study and have a broader -----> picture !!!  on how to tackle this kind of problems? Also learning to interpret the importance of data and how to process it for ML problems would be nice too!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/benlhq/how_to_train_the_mental_aspect_of_ml_and_data/"}, {"autor": "CsSadhu", "date": "2019-04-18 10:16:34", "content": "I want to develop a system where an -----> image !!!  of a person can be compared to other -----> image !!! s in a database and if -----> image !!! s match some output is given. This is for a college project. I want to know what are the topics I have to research in to get this done or are there any API's that can help me do that.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bejukx/help_on_getting_started_with_facial_recognition/"}, {"autor": "leaveAtTen", "date": "2019-04-18 08:06:39", "content": "Hey,\n\nI'm working on implementing a Q-Learning algorithm for a 2 player board game. \n\nhttps://i.redd.it/tq30b5y29zs21.png\n\nI encountered what I think may be a problem. When it comes time to update the Q value with the Bellman equation (above), the last part states that for the maximum expected reward, one must find the highest q value in the new state reached, `s'`, after making action `a`.\n\nHowever, it seems like the I never have q values for state `s'`. I suspect this is because, after reading the q matrix for the board state `s'`, the other player makes a move, and thus the board state changes. Therefore, the board state `s'` is never encountered, thus never evaluated.\n\nI will try to paint a -----> picture !!!  of what I mean. Assume P1 is a random player, and P2 is the learning agent.\n\n1. P1 makes a random move, resulting in state `s`.\n2. P2 evaluates board `s`, finds the best action and takes it, resulting in state `s'`. In the process of updating the Q value, it finds `maxQ'(s', a) = 0`, since the state hasn't been encountered yet.\n3. From `s'`, P1 again makes a random move.\n\nAs you can see, state `s'` is never encountered by P2, since it is a board state that appears only as a result of P2 making a move. Thus the last part of the equation will always result in `0 - current Q value`. \n\nAm I seeing this correctly? Does this affect the learning process? Any input would be appreciated.\n\nThanks.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/beiytd/question_on_qlearning/"}, {"autor": "Conquest-Crown", "date": "2019-04-17 20:21:17", "content": "So I've been trying to, basically, embed images into vectors and make vectors of similar images closer to each other, akin to this [paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf).\n\nThe problem is that training seems to work for a while and the \"resets\" the performance and stays constant. Like [so](https://imgur.com/a/vzqtyCM).\n\nThe problem also seems to be optimizer dependent. That -----> image !!!  was using Momentum Optimizer, but the problem presents itself after just &lt;1000 steps using ADAM, for some reason I ignore.\n\nAny ideas about what may be happening?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/becjtn/help_training_works_but_after_a_while_it_goes/"}, {"autor": "HipsterMcBeardface", "date": "2019-04-17 04:36:39", "content": "I am learning machine learning (duh!) and have started experimenting with a -----> image !!!  classification project. The problem I am encountering is that the script sometimes takes forever (72 minutes yesterday) to run on my Macbook. I am no stranger to pay a few dollars to have this run faster by using AWS/Google etc but I really want the process to be EASY. I checked out AWS (that I already use for other reasons) and just got confused. I also don't know Linux (ssh and such) much at all. \n\nWhich would be the easiest way of getting things going without having to rely on my poor Macbook processor (not even GPU)?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/be3p5x/simplest_way_of_running_your_ml_script_in_the/"}, {"autor": "SoulSkrix", "date": "2019-04-17 01:02:06", "content": "I'm currently working on a project that I don't have much time to complete, as I have been working on collecting data for training my CNN a choice I needed to make became apparent.\n\nBut first let me quickly describe what I've done so far.\n\nI have took some video of an object against a green screen, I have written a program to extract the object from the green screen. The result is a cropped version of the object with a transparent background, unfortunately the green screen reflected a bit on my object leaving a green hue. I have also made a program to randomly throw my object (scaled at random to fit on the -----> image !!!  of varying sizes) onto the backgrounds I have (though I'm finding looking for a dataset for this quite difficult).\n\n1) Is having a background even worth it, can I not just train my CNN on these tiny images that contain nothing but my object and a transparent background. If not, can I not just have random noise as a background since the background is unimportant in any context?\n\n2) If I definitely need backgrounds, do I feed the CNN the whole image, or do I only feed it the region that has my object in it? The whole point of my project is to see how far I can get by artificially inflating my dataset, and having good and bad reasons for some choices would really help me (a) make this project a better success and (b) have some justification for choices which I can write about in my report.\n\nAny help is appreciated, as I have never trained a CNN before and decided to base my final project on it, a bad idea potentially, but I am too far in to change my project now. It would be nice to even achieve a 60% accurate classification rating.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/be1peg/guidance_on_data_choices_to_make_prior_to/"}, {"autor": "-Ulkurz-", "date": "2019-04-16 18:35:28", "content": "I'm very comfortable with working with text/tabular data for machine learning. However, I have never got a chance to work on the computer vision side in terms of -----> image !!!  processing, recognition, object identification, segmentation, etc.\n\nAny recommendation for such a course (which is on the practical side) would be really helpful!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bdxgc8/handson_or_applied_online_courses_for_computer/"}, {"autor": "Kaduo", "date": "2019-04-16 16:14:00", "content": "As a pet project, I am trying to train a neural network to make a [\"querkle\"](http://www.querkles.net/) out of a -----> picture !!! . Its output would be the coordinates of the circles. In order to train the net, the program colors the output querkle and compares the result with the original image, the difference between the two being the loss that the training will try to minimize.\n\nHowever, such a loss function is not differentiable (well, to my knowledge), therefore I can't use gradient descent to fit my model. Is there an alternative way to train such a network ?\n\nFrom what I've read so far, reinforcement learning techniques could work, however there is a lot of literature on the subject and I don't really know where to start, so if you have any pointer don't hesitate ! :)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bdvsjb/can_a_neural_network_be_trained_with_a/"}, {"autor": "zsradu", "date": "2019-04-16 15:51:00", "content": "Hello.\n\nI already know Python would be the best for ML and AI.\nBut my project also involves -----> image !!!  recognition, and I would like to know about the best &amp; easiest language to work for the combination of these 3. Or should I use Python for the first 2 and another language for image recognition and somehow bind them?\n\nThank you!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bdviq1/what_language_to_use_for_my_ml_project/"}, {"autor": "cl567", "date": "2019-04-15 19:53:51", "content": "How hard would it be to send a -----> photo !!!  and have it identify certain objects in the -----> photo !!!  like a name a and also what number or rank it falls under. A better example would be you have a list with the ranks of people in a competition\n\n1. Sam\n2. Ryan\n3. Fred\n\nThe picture would read off sam wins since sam is next to something that says he wins.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bdkm20/would_this_be_hard_to_make/"}, {"autor": "Entsorger", "date": "2019-03-29 23:52:15", "content": "I'm working on understanding VAEs, mostly through video lectures of Stanford cs231n, in particular [lecture 13] https://www.youtube.com/watch?v=5WoItGTWV54) tackles on this topic and I think I have a good theoretical grasp.\n\nHowever, when looking at actual code of implementations, such as [this code] (https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py)  from [this blog] (https://blog.keras.io/building-autoencoders-in-keras.html) of VAEs I see some differences which I can't quite understand.\n\nPlease take a look at this VAE [architecture visualization] (https://imgur.com/a/xK75jxL) from the class, specifically the decoder part. From the way it is presented here I understand that the decoder network outputs mean and covariance for the data *distribution*. To get an actual output (i.e. -----> image !!! ) we need to sample from the distribution that is parametrized by mean and covariance - the outputs of the decoder.\n\nNow if you look at the code from the Keras blog VAE implementation, you will see that there is no such thing. A decoder takes in a sample from latent space and **directly** maps its input (sampled z) to an output (e.g. image), not to parameters of a distribution from which an output is to be sampled. \n\nAm I missing something or does this implementation not correspond to the one presented in the lecture? I've been trying to make sense of it for quite some time now but still can't seem to understand the discrepancy. ", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b74isf/question_on_variational_autoencoders/"}, {"autor": "ApoorvWatsky", "date": "2019-03-28 18:07:50", "content": "So I'm working on lip-reading project based on 3D CNNs and MIRACL-VC1 dataset. Here's a [link](https://www.kaggle.com/apoorvwatsky/miraclvc1) to it. I'm stuck at really crucial part of this project. I can't seem to figure out how should I feed these 4D tensors (num_of_instances, max_seq_length, width, height) into CNNs for training. Here each instance is a sequence of frames which represents a particular phrase/word being said in that sequence. \n\nAlso I'm applying this process to a cropped version of MIRACL-VC1 dataset which I created. This version consists of only the lips extracted from each frame because this is what I want my model to learn from. Then I'm resizing each -----> image !!!  to 90 x 90 size. This is indicated by self.MAX_WIDTH and self.MAX_HEIGHT.\n\nThis is what I'm doing in short to prepare the data:\n\n    for iteration in folder_enum:\n        path = os.path.join(directory, person_id, data_type, word, iteration)\n        # filelist consists of list of images in the current directory\n        filelist = sorted(os.listdir(path + '/'))\n        sequence = []\n\n        for img_name in filelist:\n            if img_name.startswith('color'):\n                image = misc.imread(path + '/' + img_name)\n                image = misc.imresize(image, (self.MAX_WIDTH, self.MAX_HEIGHT))\n                # Appending each image to teh sequence of list\n                sequence.append(image) \n                 # Creating pad array and appending to the list\n                 # This is because I want all the sequence of frames to be of constant size, here 20                                      \n                pad_array = [np.zeros((self.MAX_WIDTH, self.MAX_HEIGHT))]\n                sequence.extend(pad_array * (max_seq_length - len(sequence)))\n                sequence = np.stack(sequence, axis=0)\n\n                if person_id in UNSEEN_TEST_SPLIT:\n                    X_test.append(sequence)\n                    y_test.append(instance_index)\n                elif person_id in UNSEEN_VALIDATION_SPLIT:\n                    X_val.append(sequence)\n                    y_val.append(instance_index)\n                else:\n                    X_train.append(sequence)\n                    y_train.append(instance_index)\n\nSo I do the above process of 3000 total instances(sequence of frames) and create a numpy array of these lists. (Is there a more efficient way of doing this?)\n\n    X_train = np.array(X_train)\n    X_val = np.array(X_val)\n    X_test = np.array(X_test)\n\nOnce done, I save them so that I can load them easily from disk:\n\n    np.save(data_dir+'/X_train', X_train)\n    np.save(data_dir+'/y_train', np.array(y_train))\n    np.save(data_dir+'/X_val', X_val)\n    np.save(data_dir+'/y_val', np.array(y_val))\n    np.save(data_dir+'/X_test', X_test)\n    np.save(data_dir+'/y_test', np.array(y_test))\n\nBut I can't reach there because my kernel dies before it. Most probably the part where I convert these lists into numpy arrays is where this happens. Here's the complete [code](https://www.kaggle.com/apoorvwatsky/starter-miracl-vc1-50761f8a-4-0581f9?scriptVersionId=12191047). \n\nWhere am I going wrong? How should I feed them into CNNs/LSTM keras models once I'm done with this? ", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b6m5pj/how_to_train_a_lip_reading_model_using_cnns_and/"}, {"autor": "ZER_0_NE", "date": "2019-03-28 11:49:03", "content": "Suppose I have a dataset of audio files that I have to use for whale sound classification. I am choosing the strategy of treating it as an -----> image !!!  classification problem by using their corresponding spectrogram (frequency vs time plot) -----> image !!! s. The image shown below shows an example how the whale calls look like in the Label B(B is a species of whale and C stands for negative samples) of the spectrogram.\n\nhttps://i.redd.it/aq2ybjdkjuo21.png\n\nSince the audio files will be of varying length, the pre-processing step would involve padding all the shorter length samples with zero to have a fixed length for all files. So the spectrogram images of all those shorter samples will have the whale call in the beginning (or somewhere) with the majority of the frequency-time area as mere noise from the padding. (The above example divided the audio sample into some frames (to divide them into positive and negative classes) and labelled them as B,C.)\n\nIf we were to use the spectrogram images as such, this would hinder the generalization of our CNN model to a large extent. \n\nOr if we save the output from the pre-processing to .npy format (binary form), I guess this could go unnoticed (or not?). What will be the consequences of saving the images in .npy format and then using in our model\n\nI am not sure whether I am correct with my reasoning or not. Can anyone help me out?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b6ht05/audio_files_and_their_corresponding_spectrograms/"}, {"autor": "formatlar", "date": "2019-03-27 19:46:03", "content": "Introduction Conceptual Modernization on Machine Learning\n\nWe have different prototypes on different source and tools on eco system. There are a lot of different algorithm proposals and implementations on these frameworks. Especially, community focused different frameworks on different algorithms on several frameworks.\n\nWe want to enhance conceptual design in first step. If you can not see big -----> picture !!! , your effort and other valuable resources are wasted and, data is increasing too so fast so that we can not reach this speed using classic tools.\n\nYou can read rest of article from following link\n\n[https://formatlar.com/2019/03/27/introduction-conceptual-modernization-on-machine-learning/](https://formatlar.com/2019/03/27/introduction-conceptual-modernization-on-machine-learning/)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b68rtk/introduction_conceptual_modernization_on_machine/"}, {"autor": "sunny7000", "date": "2019-03-27 18:19:21", "content": "Hi!\n\n&amp;#x200B;\n\nI have a project in which I want to extract from ID card using machine learning. As far as I know the approach for such a task would be to:\n\n1. Crop the ID card from the original -----> image !!! \n\n2. Crop the relevant section of the card for my information (eg DOB)\n\n3. Run OCR on those small focused piece of the original image (perhaps using Tesseract)\n\n&amp;#x200B;\n\nNow I have a clear idea on how to solve 1 and 3, but I wonder how 2 could be solved. My initial idea would be to annotate a data set of ID card with bounding boxes around each piece of information I want to extract. Then I would train a model to detect those bounding boxes using something similar to YOLO.\n\n&amp;#x200B;\n\nI wonder if there is better approach to isolate small pieces of the card that would contains information like name, date of birth etc. What do you guys think?\n\n&amp;#x200B;\n\nIf you could provide advice feedback or advice on how you would solve that problem that would be super helpful.\n\n&amp;#x200B;\n\nNote: I know that it is possible to extract some information using the bar code on some ID card, but for the purpose of my project I want to focus on machine learning.\n\n&amp;#x200B;", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b67ory/id_card_detection/"}, {"autor": "DJYEEZYWORLDPEACE", "date": "2019-03-25 18:40:12", "content": "The challenge of the first task is to recognize handwritten digits using logistic regression. I implemented one vs all classification using scipy's 'optimize.minimize'. The output of my oneVsAll function is a vector which is optimized in regards to the dataset. \nGiven that I have my optimized vector 'all_theta', I now wanted to predict  the digit in a given -----> image !!! . AFAIK I can do that by multiplying 'all_theta' with a given dataset of images of digits and using the result as parameter for my hypothesis (sigmoid function) where I take the max value of every row. So far so good. \nIf I take the sigmoid function away and just multiply the 'all_theta' vector with the dataset, it still works perfectly fine.\nWhy can I omit the sigmoid function call?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b5eja0/question_regarding_week_4_assignment_of_andrew/"}, {"autor": "NoTechBackground", "date": "2019-08-06 16:01:44", "content": "I am following this tutorial on convolution filter visualization. First, I copied the code directly:  [https://keras.io/examples/conv\\_filter\\_visualization/](https://keras.io/examples/conv_filter_visualization/) \n\n&amp;#x200B;\n\nRunning the code as is didn't work (because I have Keras through tensorflow), so I did what I usually do to get Keras to run and that is replace \n\n **from** keras. \n\nwith\n\nfrom tensorflow.contrib.keras.api.keras.\n\n&amp;#x200B;\n\nSo now I have:\n\n&amp;#x200B;\n\nhttps://i.redd.it/pg1a3k27pue31.png\n\nImporting from tensorflow like above usually works. \n\nI got an error on line 13:\n\n&amp;#x200B;\n\nhttps://i.redd.it/45s9afsapue31.png\n\n1) What might you try to figure out why it cannot import save\\_img from preprocessing -----> image !!!  ?\n\n&amp;#x200B;\n\n2) What might you try to google to better understand the problem? I googled 'save\\_img' to figure out what it is but it doesn't look like a standard package\n\n [https://www.google.com/search?q=keras+save\\_img&amp;rlz=1C1GCEA\\_enUS851US851&amp;oq=keras+save\\_img&amp;aqs=chrome..69i57.1607j0j9&amp;sourceid=chrome&amp;ie=UTF-8](https://www.google.com/search?q=keras+save_img&amp;rlz=1C1GCEA_enUS851US851&amp;oq=keras+save_img&amp;aqs=chrome..69i57.1607j0j9&amp;sourceid=chrome&amp;ie=UTF-8)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cmsg6q/keras_convolution_filter_visualization_tutorial/"}, {"autor": "AppleNamu", "date": "2019-08-06 10:14:10", "content": "Hi everyone \n\nI was wondering what it means to use BCE as a loss for supervised -----> image !!!  generation. \n\nFor example, in Keras tutorial, when they introduce autoencoder, they use BCE as the loss and it works fine. However, when you use L1, it also works.\n\nIn that case, i was wondering why advanced supervised image generation papers such as Pix2Pix use L1 instead of BCE. Does one loss have advantage over the other loss when it comes to purely supervised image generation tasks, where the goal is to be as close as to the ground truth image as possible?\n\nAlso, if the image has colour, would it be better to use CCE with 255 as the class?\n\nThank you", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cmoqnt/l1_vs_bce_loss_in_supervised_image_generation/"}, {"autor": "notdheeraj", "date": "2019-08-05 21:40:23", "content": "I don't know if this is the right platform for the question but here goes. I'm working on a binary multi-label classification where each label is 1 or 0, but I'm lacking in data. Most of the data I have only is such that if it's 1 for a label, it's 0 for all the other labels. But I'm expecting test cases with multiple labels in each -----> image !!! . So, how well can the model do in this case ?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cmhfj1/data_imbalance_in_multilabel_image_classification/"}, {"autor": "rapture_inc", "date": "2019-08-05 18:43:45", "content": "Is there any way to train a network for instance segmentation when you have a series of -----> image !!! s and the corresponding mask for each -----> image !!! ?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cmf177/cnn_when_you_have_an_image_and_its_mask/"}, {"autor": "WindowsDOS", "date": "2019-08-03 21:47:57", "content": "Has anyone here been able to successfully recreate the Celebahq dataset from [This GAN paper/code](https://github.com/tkarras/progressive_growing_of_gans) ?\n\nI've tried using the [base celeba dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html), but I've noticed that both the celeba/Anno/ directory from the celeba dataset doesn't match where the nvidia GAN code is expecting it to be (celeba/Img/Anno), and when I move it to the correct location I still have problems with mismatch -----> image !!!  digest values. Specifically I've had an error where the code warns the user to use libjpeg v8d. \n\nI do have libjpeg 8d, but I installed from source because I'm on ubuntu 18.04, and the repositories only go up to 8c.  \nI've also tried ignoring the initial md5 mismatch, but later checks in the code fail.\n\nThe only other difference I can think of is my environment being a docker container as opposed to an anaconda environment like what the nvidia code was written for.\n\n  \nAnyone know what I'm doing wrong? Thanks in advance for the help", "link": "https://www.reddit.com/r/learnmachinelearning/comments/clobs3/celebahq_dataset_recreation_problems/"}, {"autor": "bigDATAbig", "date": "2019-08-03 20:30:30", "content": "So I have a dataset of 6 different dermatology disease -----> picture !!! s along with data of the age, gender, etc other data for each -----> picture !!! .\n\nI want to train a model that combines the image and the categorical/text data to classify it as one of the 6.\n\nMy initial thought is to use ResNet to get a 255x1 size vector for each image, then make 255 features with the value in each entry is the index in the vector. Then I can just add the 5 (let's say) features to get a final input size of 300x1 for each datapoint, which I can then train an LGBM classifier or any other classifier on. Does this sound like it would work?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/clngfy/how_to_combine_image_data_with_metadata_for/"}, {"autor": "rapture_inc", "date": "2019-08-02 19:55:48", "content": "Is there any way to use -----> image !!!  augmentation when you are trying to train a network for instance segmentation? Obviously, the relevant pixels will have changed, so the coordinates would have to be updated too. Is this possible?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cl91t8/coco_dataset_augmentation/"}, {"autor": "epicSaitama", "date": "2019-08-02 17:02:22", "content": "Hi all,\nI'm trying to build a face clustering app where I take in a video, detect faces in that video and extract there embeddings and then cluser faces based on these embeddings. \n\nI'm currently using DBSCAN as it can deal with noise embeddings(outliers). \n\nI'm wondering if this algorithm supports online learning where I dont need to retrain the model on the whole -----> image !!! s embeddings again when a new -----> image !!!  it added to the dataset. \n\nThank you for your time.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cl6t7q/does_dbscan_clustering_algorithm_supports/"}, {"autor": "GinjaTurtles", "date": "2019-08-01 22:53:34", "content": "Is there a way to specify which class is the \"1\" class and which class is the \"0\" class for binary classification in Keras? For example, I want my model to output a \"1\" if it thinks a -----> picture !!!  is an orange and \"0\" if it thinks it's an apple but right now it's outputting 0 for Orange and 1 for Apple. I used flow\\_from\\_directory and I'm wondering if automatically assigns one class as the \"1\" class and the other class as the \"0\" class Thanks for any help!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ckvoet/binary_classification_is_there_a_way_to_specify/"}, {"autor": "Jonno_FTW", "date": "2019-10-17 03:39:16", "content": "I'm doing an -----> image !!!  segmentation problem where this is very high class imbalance. I did a pixel count in the image masks for each class and get the following:\n\n    cls_count = [90506655, 817347, 234573, 10830708, 1413843]\n\nThat is, there are 90506655 instances of the first class (background), 817347 instances of the 2nd class and so on.\n\nDoing: `cls_count.sum() / cls_count` gives `[1., 110.73222878, 85.83577394,   8.35648556, 64.01464307]`. \n\nIf I want to oversample the minority classes (applying augmentations when oversampling), does this mean I need to generated 110 examples of  class 1, 85 samples of class 2 etc.? Would this work or should I weight my loss function as well/instead? Or should I take a different approach?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dj0qv1/how_to_calculate_weighting_for_class_imbalance/"}, {"autor": "BrightTux", "date": "2019-10-16 02:05:39", "content": "  \nHello fellow redditors, \n\nI'm new to tensorflow in general and i'm in the process of creating tensorflow data.Dataset API for public datasets.\n\nI was wondering if it is possible to obtain value of tensors during graph execution. I'm trying to use different decoding method for different -----> image !!!  extensions (ie, tf.io.decode\\_png \\* tf.io.decode\\_jpg)\n\nI would appreciate some guidance.\n\nThank you.\n\n&amp;#x200B;\n\n**Example:**\n\nself.ds\\_paths contains \\[path/to/img1, path/to/img2, ... , path/to/imgN\\]  \nThese images has both png and jpeg format.  \n\n\n`def generator(self):`  \n`samples = self.ds_path`  \n`ds = tf.data.Dataset.from_tensor_slices(samples)`  \n`ds = ds.shuffle(len(samples))`  \n`ds = ds.repeat()`  \n`ds = ds.map(self.process_path,`  \n`num_parallel_calls=tf.data.experimental.AUTOTUNE)`  \n`return self.prepare_for_training(ds, cache=self.cache)`\n\n&amp;#x200B;\n\n  `def process_path(self, file_path):`  \n`label = self.get_label(file_path)`  \n`# load the raw data from the file as a string`  \n`img = tf.io.read_file(file_path)`  \n`img = self.decode_img(img, file_path)`  \n`return img, label`\n\n&amp;#x200B;\n\n  `def decode_img(self, img, file_path):`  \n`# Find out extension of the file`  \n`ext = tf.strings.split(file_path, sep='.')[-1]`  \n`tf.print(ext)`  \n`print(ext)`  \n`if ext == 'jpg':` &lt;&lt; ----- unable to get this value  \n`img = tf.io.decode_jpeg(img, channels=self.channels)`  \n`tf.print('decoding jpg')`  \n`elif ext == 'png':`  \n`img = tf.io.decode_png(img, channels=self.channels)`  \n`tf.print('decoding png')`  \n`else: # fallback` &lt;&lt; ----- Always end up with the fallback  \n`# convert the compressed string to a 3D uint8 tensor`  \n`img = tf.image.decode_image(img, channels=self.channels)`  \n`tf.print('still using old decode method?!!@')`  \n`# Use \\`convert_image_dtype\\` to convert to floats in the [0,1] range.`  \n`img = tf.image.convert_image_dtype(img, tf.float32)`  \n`return img`", "link": "https://www.reddit.com/r/learnmachinelearning/comments/diifdo/tf20_obtaining_value_of_tensor_during_graph/"}, {"autor": "Aradarbel10", "date": "2019-10-15 06:55:06", "content": "Hello,\n\nI want to create a classifier that takes an -----> image !!!  of a Pokemon and outputs its name. I have a folder containing a picture of each pok\u00e9mon. The input images aren't going to be very different from the data set, and by that I mean all pok\u00e9mons are going to be on a white background, so it shouldn't be too complicated to perform. I had a few Ideas for how to do it:\n\n1. Have a CNN with an output for each pok\u00e9mon. This seems too complicated for what I need and also I have only one instance for each pok\u00e9mon.\n2. Color ratios: see how much of each color is in the image and compare it to values in the data set.\n3. Shadow: transform the input image into a b&amp;w shadow (who is that pok\u00e9mon style) and try to see which image of the data set fits the best by scaling, moving, and reflecting.\n\nI am not sure exactly how to implement any of these methods or if they will even work, so I'd love to hear what you say about it. What will be my best option?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/di40g6/how_can_i_create_a_pokemon_classifier/"}, {"autor": "mauistark", "date": "2019-10-14 00:42:43", "content": "Hello everybody. To preface I am brand new to machine learning. I am working on my undergrad capstone project and I was assigned to a project involving ML. Here\u2019s what I am trying to do (note I must be somewhat vague due to NDA): This will be a mobile app developed using Flutter and Dart. I want to present users with a -----> picture !!! . They will either press like or dislike on that photo.  Using this I will train the model to predict whether they will like or dislike other pictures. This approach would require a model for each individual user of the app to learn that user\u2019s preference. I am worried that the maintainability of this would be unrealistic if the application had hundreds or more of users. What do you guys think? Can I have an ML model to learn each user\u2019s preferences? Thank you for any input you may have!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dhj4gw/is_a_model_per_user_feasible/"}, {"autor": "snicksn", "date": "2019-06-30 22:38:54", "content": "My view of ImageDataGenerator (Keras) and its -----> image !!!  augmentation was that it created more -----> image !!! s by transforming the original -----> image !!! s a little. So there would be more training data. But while trying to find how the number of new images are decided, I came to the conclusion that this is not the way it works. Instead the image augmentation randomly transforms images on each epoch, which I guess is good to avoid overfitting. But the number of images trained on is the same. Is that correct?\n\n&amp;#x200B;\n\nThanks", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c7kmz4/imagedatagenerator_iiuc_does_not_create_more_data/"}, {"autor": "vinnivinnivinni", "date": "2019-06-29 19:49:06", "content": "Hello,\n\nI need to do an (approximate) k=1 nearest neighbour search for a dataset of 70000 black and white images with a query time of about 0.25 seconds for a result.\n\nThe images all contain black geometries on white background and look like that. They're all normalized to 244x244 pixels:  \n\n\nhttps://i.redd.it/1f4sr9yomc731.png\n\nI looked at Google AutoML, as I'm just a beginner in python (I'm a webdev), but I'm not sure the *AutoML Vision* is the right way to go, as you can only do labeling with categories that get labled on 100 images per label.\n\nWhat would be the best way to do it?\n\nThe instructions I found were the following:\n\n1. do feature extraction with keras vgg19 on every -----> image !!!  and save it into a file\n2. use an ANN framework (like spotify's [annoy](https://github.com/spotify/annoy)) to generate a model\n3. do the same feature extraction on a sample image and match it with the ANN model\n4. use the returned index to match it with the database and extract the prepared metadata\n\nMaybe someone can give me a hint on how to achieve this. I've been looking at spotify's [annoy](https://github.com/spotify/annoy) But have difficulties even building the model. Maybe this is also just overkill and I should just do a normal cosine similarity search on all 70k?  \n\n\nThanks a lot!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c73pvy/question_approximate_nearest_neighbor_search_on/"}, {"autor": "MenOfUnderstanding2", "date": "2019-06-27 14:56:17", "content": " \n\nJust search on YouTube for the following video, watch both parts 1 and 2 and it will thoroughly prove to\n\nyou exactly what is going on in this seemingly chaotic world and what is soon coming to pass.\n\nSearch for:\n\n&amp;#x200B;\n\nFinal Warning Part 1\n\n&amp;#x200B;\n\nIt is the video that should be at the top of the list, the one with yellow font in the thumbnail -----> picture !!! .", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c66i8l/if_you_care_for_the_truth_and_what_is_soon_coming/"}, {"autor": "Doomb0t1", "date": "2019-06-27 14:47:10", "content": "Hello!\n\nTo start, I'm using Keras, in Spyder 3.3.4.\n\nBasically, I downloaded the VGG16 model, and retrained the last 3 layers to better fit my dataset (classifying custom-machined parts from one another; they are all pretty similar but have enough differences where ML can pick them out). I left it to train overnight yesterday, and then saved the new model to a .h5 file. I did this entire process using pretty much the exact method explained here:  [https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/](https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/)\n\nBasically, my question is here: When I try to load the newly trained model (the code is at the bottom), to test with newly taken images not in either the training\\_set or test\\_set, I get the error \"You are trying to load a weight file containing 3 layers into a model with 16 layers.\" I assume it is coming from the fact that I have not concatenated the new model with the original 16-layer VGG model. However, I do not know how to do so, and this is what I need assistance with.\n\nJust for extra information, my dataset has 5 classes, each of which have 750 images in the training\\_set. The test\\_set shares the same distribution, but with 250 images/item, as opposed to 750. Not really sure if this matters but I figure I may as well give the information anyways.\n\nThanks for the help!\n\n    import keras\n    from keras.applications.vgg16 import VGG16\n    from keras.preprocessing import -----> image !!! \n    from keras.applications.vgg16 import preprocess_input, decode_predictions\n    import numpy as np\n    import cv2\n    import time\n    \n    model = VGG16(weights=\"content/small_last4.h5\") #this is the path to my new model\n    #the old model is /content/vgg16_weights_tf_dim_ordering_tf_kernels.h5 - the original model\n    print('test') # This does not get printed - the program errors on line 18.\n    #I should mention - this code works perfectly fine when I use the original model.\n    \n    video_capture = cv2.VideoCapture(1)\n    if not video_capture.isOpened():\n        raise Exception(\"Could not open video device\")\n    \n    for i in range(0, 100):\n        time.sleep(0.5)\n        ret, frame = video_capture.read()\n        imgPath = 'C:/Users/Doomb0t1/desktop/VGG16/liveTesting/testImage.' + str(i + 1) + '.png'\n        cv2.imwrite(imgPath, frame)\n        img = image.load_img(imgPath, target_size=(64,64)) #note the input size\n        img_arr = np.expand_dims(image.img_to_array(img), axis=0)\n        x = preprocess_input(img_arr)\n        preds = model.predict(x)\n        print('Predicted:', decode_predictions(preds, top=3)[0])\n        #This code block is not particularly useful, but it captures a webcam image\n        #with the intent to check it using the model and determine what item it is.\n    video_capture.release()", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c66ein/loading_newlytrained_model_into_vgg16/"}, {"autor": "ats678", "date": "2019-06-27 08:31:52", "content": "Hello everyone! I have started working on a project I had in my mind for a few weeks. The only problem with it is that to realize it I need a lot of -----> image !!!  datasets to train my models. Is there any way I can make the process of creating a dataset quick/automatic instead of looking manually for every single picture? I\u2019ve tried using beautifulsoup and webscraping but the results are quite far from what I need as I can get just a few pictures. Any advice or even external references would be extremely appreciated!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c6300p/how_to_build_image_datasets_quickly/"}, {"autor": "sunisadeadlylaser", "date": "2019-05-25 20:48:40", "content": "What are general approaches to use an Object Detection model like YOLO trained on 81 classes, to detect presence of a single object class in an -----> image !!! , preferably realtime?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bszf4v/how_to_use_an_object_detection_model_trained_on/"}, {"autor": "Blacky372", "date": "2019-05-24 11:22:03", "content": "Why the fuck does it take literally DAYS to configure a proper ML environment?\n\nI just spent 5 hours trying to install tensorflow with GPU support without success. \n\nI've tried just pip installing tensorflow-gpu. But that doesn't work because it blindly assumes I have exactly cuda 10.0 installed, but on my system it's already cuda 10.1. WHY ISN'T THAT COMPATIBLE??!?\n\nBut ok, sometimes things are a certain way and you just have to deal with it. So manually installing cuda 10.0 should fix it. So I download the cuda 10.0 package and try to pacman -U cuda-10.0.130-2-x86_64.pkg.tar.xz and BOOM, ERROR! Installing cuda 10.0 apparently needs gcc7, but I have gcc8 installed. Again: WHY ISN'T THAT COMPATIBLE??!?\n\nBefore I completely destroy my dev machine, I'll try another way to gpu support. On the [Tensorflow website](https://www.tensorflow.org/install/source) it says the easiest way to get tf with gpu support is using the docker -----> image !!! . So I install docker... but no no no, not that easy. First I also have to install nvidia-docker, which i understand is a way to give docker apps gpu access. But no no no, there is ofc no package for my system, so I need to fetch it from the AUR. So I install pamac to install nvidia-docker, install nvidia-docker and THEN IT DOESN'T FUCKING WORK. \"Unknown runtime specified nvidia.\"\n\nWell... then I'll just have to build TF from source manually. To avoid easy mistakes, I use this [very recent guide](https://mc.ai/build-tensorflow-2-0-from-source-with-gpu-and-tensorrt-supports-on-ubuntu-18-04/) on how to do that. It's for Ubuntu, but most things should be similar. Noo, that also requires an old gcc version. But ok, gotta try it anyways. Aaaaaand next problem. EVEN THOUGH I PROPERLY TOLD IT WHICH CUDA VERSION I HAVE INSTALLED AND WHERE IT IS, THE BUILD SCRIPT CANT FUCKING FIND IT: \"no such package '@local_config_cuda//cuda'\"\n\n    Cuda Configuration Error: None of the libraries match their SONAME: /opt/cuda/lib64/libcublas.so.10.1, /opt/cuda/lib/libcublas.so.10.1\n\nTHESE FILES ARE LITERALLY AT THESE EXACT LOCATIONS! What is the issue?\n\nWhy can't I AT LEAST get a proper error message that you can understand without being actively involved in TFs development? I just want to train some neural nets, not get a degree in cuda programming.\n\n\n\nI've tried a few other guides but none of them work. Countless other people report the same problems.\n\nWhy is it so extremely hard and time-consuming just to set up a development environment? Machine learning is complicated enough by itself. I bet a lot of new people just give up after the first few hours of tinkering, this is so unfortunate. \n\nI have absolutely no problem with doing so research, editing some config files, manually building some tools, but there is a point where ANY motivation I had is just lost, because no matter what I try, there is always some component that is broken. \n\n/rant\n\nMy specs:  \ni7-4770k  \nASRock Z78 Pro3  \nGTX 1050 Ti 4GB  \nManjaro (kde) with Linux 5.1.1", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bsfp45/why_is_ml_software_so_horrible/"}, {"autor": "mersis", "date": "2019-05-23 15:27:39", "content": "I'd like to get started on experimenting with some ML and NN to blend items into existing images / photographs.  \n\nGiven an existing -----> image !!!  and an edited version with some item added to it, ideally I'd end up with a NN that can adjust lighting and shadows to make the item seem part of the -----> image !!! .  \n\nI'm a developer and I have a decent idea how I'd go about trying to implement an algo for this problem by hand, but it seems this could be an ideal problem for a ML solution.  \n\nSince I'm not experienced with ML though I don't really know how to get started and am looking for some guidance.  \nhttps://github.com/luanfujun/deep-painterly-harmonization seems to be almost what I want to do except for the fact that it uses art and not photographs.   \nIs the same approach valid though and I should try and base my experiment on that or is there a better way for my usecase? \n\nThanks a lot for any input!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bs4bcu/blending_items_into_photographs/"}, {"autor": "hiro_ono", "date": "2019-05-23 09:20:34", "content": "This may not be the right place to ask so feel free to delete but:  \n\n\nI've been writing an -----> image !!!  recogntion algorithm. It should be really simple, the images are letters and numbers in squares. I've made a neural network in Keras and it says it's training well (95%+ ).. But when I go to predict what an image is it might as well be totally random.   \ngithub link is here:\n\n [https://github.com/M-Morris-95/Vision](https://github.com/M-Morris-95/Vision)   \n\n\nif anybody can help me out that'd be amazing, I'm sure it's something trivial but I just don't know what", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bs0qqj/convolutional_neural_network_giving_different/"}, {"autor": "Kind_Surprise", "date": "2019-05-22 23:59:30", "content": "I've set up a GAN that works for generating mnist digits, and I am now trying to get it working with cars from cifar10. However, the outputs for cars from cifar10 are usually monochrome and periodically switch to different colors as the generator loss decreases and the discriminator loss increases.\n\n&amp;#x200B;\n\nHere are the generator and discriminator loss graphs when training on mnist:\n\nhttps://i.redd.it/6sxbkcbuouz21.png\n\n&amp;#x200B;\n\nIn contrast, the losses for cifar10 are flat for long periods before suddenly spiking up:\n\nhttps://i.redd.it/b39nnqtxouz21.png\n\nFor cifar10 the GAN generates nearly monochrome -----> image !!! s of varying shades for example:\n\nhttps://i.redd.it/p38s6n70puz21.png\n\nAfter about 10 epochs it starts outputting interesting textures that don't bear any resemblance to the -----> image !!! s:\n\nhttps://i.redd.it/94gt45q4puz21.png\n\nLetting it run for 50 epochs doesn't improve -----> image !!!  quality. The pattern in the loss becomes less apparent, but you can still see the regular spikes at the start of training:\n\nhttps://i.redd.it/3o375ux8puz21.png\n\n[Output from epoch 50](https://i.redd.it/gcc9rwhcpuz21.png)\n\nI've tried messing with the learning rates, activation functions, number of layers, convolutional kernel size, noisy labels, flipped labels, noisy discriminator input and so forth, but nothing seems to work. It seems more likely that there is a larger problem than just incorrect hyperparameters.\n\n&amp;#x200B;\n\nDoes anyone recognize this abnormal pattern in the loss?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/brw6mp/abnormal_loss_curves_when_training_gan_on_cifar10/"}, {"autor": "Laurence-Lin", "date": "2019-05-22 07:35:39", "content": "I'm implementing VGG-16 net, and though I've divide the input pixels by 255, the output of network reaches scale of 1e+22, resulting the loss to explode.\n\nI've check the output of each layer within the network, since my activation function is relu, it won't limit the positive value, then as the layer stacks the output of each layer keep increasing, leading to enormous output.  \n\n\nI've think of solution of this problem: batch normalization, but what if I input a mini-size of batch? What if I want to input a single -----> image !!! ? And also, I've looked for other's implementation of vggnet, they don't seemed to do normalization between hidden layers.  \n\n\nDoes anyone meet similar problem? Thanks for any advice!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/brls2b/my_output_of_network_is_too_large_making_me/"}, {"autor": "imagesegml", "date": "2019-05-21 23:02:41", "content": "Hey guys! I am working on a project right now and a big part of it is this dataset of images that we want to segment into basically part we care about and part we don\u2019t care about. The main problem is the images are all different sizes and we can\u2019t resize them. Is there any model right now that can handle variable size inputs for -----> image !!!  segmentation? To me it doesn\u2019t really seem like that makes sense to be possible but I thought I would ask just in case. If it\u2019s not possible does anyone have any recommendations on what other approaches we can take?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/brh7jb/binary_image_segmentation_on_variable_size_inputs/"}, {"autor": "paswut", "date": "2019-11-23 12:10:55", "content": "Hi, I'm learning deep learning with an -----> image !!!  classification task. I have successfully created a network which can memorize my inputs. However, it's a coin flip for the test set.\n\nI created this network with a few layers and no transfer learning. There are 40 images in each class for the training set and 20 in the test set.\n\nI heard that you should overfit your training data then do hyperparameter tuning to make it perform better on unseen data.\n\nMy questions are... is this expected due to the simplicity of the neural network architecture? For example, if I used a Resnet101 architecture, trained it so it overfit on my training data... that the test data would be above 50%? \n\nNext, I will try to use transfer learning with the same data to see if the test data is above 50%. Another thing to do is data augmentation on the training set to increase the size 10-fold.\n\nAny tips or advice would be appreciated for this task. \n\nThank you.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/e0h3k5/binary_classification_with_simple_cnn_layers_100/"}, {"autor": "VTSAX_Over_Kids", "date": "2019-11-22 15:09:40", "content": "Hey r/LearnMachineLearning!\n\nFirst time poster. \n\nQuestion:\n\nBuild the SVM best linear classifier for the following data set shown (link to -----> picture !!!  below). Show your solutions for w and b. Additional points are given for solving the margin p=2/|w|. Add your SVM decision boundary on the figure below.\n\n\n[SVM Figure](https://imgur.com/gallery/38tqqgy)\n\nAny help is very much appreciated. I\u2019m struggling with this one.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/e028c4/help_with_svm_separable_example/"}, {"autor": "Laxcrom", "date": "2019-11-21 01:15:12", "content": "Guys. I've been given the task of detecting Glaucoma using OCT images but without using any neural net architectures like CNN. Though -----> image !!!  processing approaches like segmentation etc. are allowed to be explored.  I don't work at a medical center so I don't have access to any actual equipment for measurements. Has anyone tried doing this or something similar to it with traditional ML algorithms?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dzblvk/glaucoma_detection_using_oct_images_without/"}, {"autor": "ahmedfgad", "date": "2019-08-01 16:35:20", "content": "This tutorial uses the popular computer vision library [OpenCV](https://heartbeat.fritz.ai/opencv-python-cheat-sheet-from-importing------> image !!! s-to-face-detection-52919da36433) for building an [-----> image !!!  classifier](https://heartbeat.fritz.ai/basics-of------> image !!! -classification-with-pytorch-2f8973c51864) that runs on Android devices.\n\nThe overall process looks like this. First, the color histogram of the hue channel from the HSV color space is extracted from the image dataset. Next, an [artificial neural network](https://heartbeat.fritz.ai/from-y-x-to-building-a-complete-artificial-neural-network-327da18894af) (ANN) is built and trained by such features and then saved for later use in an Android app. An Android Studio project is then created, which imports the Android release of OpenCV. After being imported successfully, the saved trained ANN is loaded for making predictions.\n\nThe tutorial is available here: https://heartbeat.fritz.ai/image-classification-on-android-using-opencv-38a01fce53e9", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ckqqna/image_classification_on_android_using_opencv/"}, {"autor": "Laurence-Lin", "date": "2019-08-01 08:00:37", "content": "I've seen a code online that declare it uses whitening to preprocess the -----> image !!! , but after take a look I found that it's actually doint standardization:\n\n\\[x - mean(x)\\] / std(x),  where x is the pixel value, mean and std is calculated over the whole -----> image !!! .\n\nIn tabular data, standardization scales the different features into similar range, but I don't understand the effect of it works on image data.   \n\n\nHow does standardization means as an processing method to a image?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ckldff/how_could_standardization_extract_important/"}, {"autor": "Zerotool1", "date": "2019-07-31 11:32:23", "content": "[https://console.clouderizer.com/community/details?Tem=d9aa5222-89f7-4d8e-91a3-8fec7ba45fb6&amp;type=public](https://console.clouderizer.com/community/details?Tem=d9aa5222-89f7-4d8e-91a3-8fec7ba45fb6&amp;type=public)\n\nDetectron is a software system developed by Facebook\u2019s AI Research team (FAIR) that \u201cimplements state-of the art object detection algorithms\u201d. It is written in Python and leverages the Caffee2 deep learning framework underneath.\n\nDetectron aims to provide a high quality and industry standard codebase for object detection research. The results it has posted are incredibly accurate. The -----> image !!!  above shows the prediction power of the software. The following object related algorithms are embedded in Detectron:\n\n* Mask R-CNN\n* RetinaNet\n* Faster R-CNN\n* RPN\n* Fast R-CNN\n* R-FCN\n\nAlong with the Python code, FAIR has also released performance baselines for over 70 pre-trained models. Once the model(s) is trained, it can be deployed on the cloud and even on mobile devices.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ck78zm/now_clone_facebooks_ai_team_releases_detectron_in/"}, {"autor": "lonelynobita", "date": "2019-07-31 07:15:30", "content": "Say I have pictures of cats and dog. I train a GAN with pictures of cats.  Can I use the discriminator to classify whether a -----> picture !!!  is a -----> picture !!!  of dog or cat? The idea is the discriminator should classify the picture of dog as fake picture.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ck509l/can_i_use_gan_to_classify_image/"}, {"autor": "Wyvern_king", "date": "2019-07-30 23:20:12", "content": "Hey everyone,\n\nI've built a relatively simple regression CNN on top of ResNet50 in Keras that determines the real world ground truth of an object in the input -----> image !!!  but I want to scale this up to deal with multiple objects and classify the detected objects as well. Two of the well known models I found for this so far are YOLO and multiple box single shot detection (SSD) but they output the x, y pixel values of where the object is in the image instead of where the object is in the real world. \n\nIs it possible to modify the outputs of these models to just be just the real world ground truth of an object and the classification? In my current model the model input is an image and the model output is the real world x and y. \n\nFor reference the video source that would feed into the network is a fixed position camera that should never move in space. \n\nAny advice or help would be greatly appreciated!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cjzw7o/is_it_possible_to_modify_the_output_and_loss/"}, {"autor": "zannyfamily", "date": "2019-07-30 22:58:55", "content": "Hi,\n\nI'm trying to create a binary -----> image !!!  classifier. Images are sorted and are time frame series (but with different number of frames in a series). I'm thinking about creating an ensemble classifier: which will take N images from one series, every image will go through ResNet/other CNN, and the outputs from these networks will feed into FCN.\n\nSo I'm thinking that the approach in PyTorch will look something like this:\n\n    outputs[1] = model_resnet(input[1])\noutputs[2] = model_resnet(input[2])\n...\noutputs[N_frames] = model_resnet(input[N_frames])\n    \n    outputs_final = model_fcn(outputs)\n    \n    loss = criterion(outputs_final, labels)\n    loss.backward()\n\nIs this even feasible? Am I thinking correctly?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cjzm8a/is_this_ensemble_possible/"}, {"autor": "rapture_inc", "date": "2019-07-30 17:45:26", "content": "I need to do some freeform (ie. non-polygonal) -----> image !!!  labeling to be used with an algorithm for semantic segmentation. Is there a recommended (and hopefully free) resource that will take care of exporting label coordinates for you, and that will keep your data private? Thank you.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cjvabz/best_utility_for_semantic_segmentation_image/"}, {"autor": "NormalNoit", "date": "2019-07-30 02:10:15", "content": "I'd like to have an -----> image !!!  converter, capable of looking at a cartoon from one show, and reinterpreting it in another shows style [based on a library of sample -----> image !!! ]. I have an entry level understanding of java. What would I have to learn to be able to do something like this.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cjl5s9/what_i_want_to_do_and_where_would_i_start/"}, {"autor": "EverydayQuestion", "date": "2019-07-29 20:45:21", "content": "I'm looking through this tutorial on creating [facial landmarks](https://www.py-----> image !!! search.com/2017/04/03/facial-landmarks-dlib-opencv-python/), and it mentions that a way of localizing the face in an -----> image !!!  is with [HOG descriptors + LSVM object detector](https://www.py-----> image !!! search.com/2014/11/10/histogram-oriented-gradients-object-detection/). I understand the basics of they work to the extent that:\n\n1) I know that the descriptors are a feature vector containing information about the region-of-interest. In the context of oriented gradients, that means every gradient change is recorded within a histogram (x-axis being the orientation and the y-axis being the magnitude), which is fed into the classifier (in this case the LSVM object detector).\n\n2) I know that Linear SVM is basically an extension to the idea of a Perceptron. The Perceptron uses a hyperplane on a graph to separate binary classifications of plot points. Initially, the hyperplane is placed arbitrarily, but through a user-defined number of iterations, the hyperplane will repeatedly correct itself. It does so whenever a random plot is found to be on the wrong side of a plane, and it will adjust m1,m2, and b in (m1)x + (m2)y - b = 0 by the magnitude of +-learning rate that was set with the sign depending on the relative placement of the plot point. The main difference with the Perceptron and LSVM is that the SVM seeks to define the optimal hyperplane by looking at the extreme cases of both classifications (the data points on both sides where they start to look similar to each other). Two parallel support vector line are put with each touching the closest data points from both classifications, and the hyperplane is set at the average of these two support vectors. Apparently a kernel method can also be applied to the graph such that the transformation allows graphs that previously couldn't be binary classified with a line can now be done so (usually by adding another dimension to the graph).\n\n3) HOG descriptors are extracted from a negative and positive set of the image (and its scaled versions), and the SVM is trained with the negative set via the sliding window technique. When a false positives are found, they are sorted by the confidence (probability that the algorithm believes it to be the object detected), and the SVM is trained again with just these false positives, further filtering and adding the negatives to what the SVM recognizes as negatives, making the overall detection more accurate. Once positive set is processed by the SVM, it is likely that there will be multiple bound boxes that will detect a face. To de-duplicate, a non-maximum sensitization is applied.\n\n&amp;#x200B;\n\nI am confused on how a linear SVM that takes in these visual descriptors describing gradient changes then uses a linear predictor function to determine whether something is a face or not.\n\n&amp;#x200B;\n\nNote: I just started learning about machine learning a few days ago, so please let me know if my knowledge of these specific topics is inaccurate or wrong.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cjh5ay/how_do_histogram_of_oriented_gradients/"}, {"autor": "ajeenkkya", "date": "2019-07-29 18:55:24", "content": "I am using Bag of visual words algorithm to get features of an -----> image !!!  and pass it onto RNN but the problem is that the number of features for every frame of video is different.\n\nAlso, suggest some good techniques to get features of image.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cjfmb4/how_to_use_varying_number_of_nodes_as_input_for/"}, {"autor": "ajeenkkya", "date": "2019-07-29 18:32:30", "content": "I am using Bag of visual words algorithm to get features of an -----> image !!!  and pass it onto RNN but the problem is that the number of features for every frame of video is different.\n\nAlso, suggest some good techniques to get features of image.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cjfayz/how_to_use_varying_number_of_nodes_as_input_for/"}, {"autor": "74throwaway", "date": "2019-07-29 16:55:25", "content": "I have a set of around 10 proprietary images. 3 of them contain a particle defect whereas the rest do not\n\nI was hoping there was a way I could perform data augmentation on the 7 non-defected -----> image !!! s by appending 1+ of the particle defects onto them\n\nI placed some example -----> image !!! s in https://imgur.com/a/Aak1x3W\n\nThe first -----> image !!!  is the example input -----> image !!! , the 2nd is a crop containing the defected particle that I want to append to the 1st one. Ideally, I prefer if there was a way to take that gray particle and make it's background transparent so that when it's appended to the first image, that black background isn't there\n\nI'd like the defected particle to be placed at random locations, such as in the 3rd and 4th images, as well as have rotation, resizing (as in the 5th image), and other transformations applied to it\n\nI've only used `ImageDataGenerator` in Keras to perform augmentation before, but I don't think that will work here because I have the defected particle I want to append\n\nIs there some kind of computer vision, GAN, or deep learning method that can do this? Or would it be easier to just write code using random number generators?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cjdy3g/how_to_perform_image_data_augmentation_with/"}, {"autor": "Dubeyjii", "date": "2019-07-29 10:23:55", "content": "It's a face emotion recognition dataset.\nI have applied Resnet50 on the data , and got 60% accuracy on test data from around ~70 epochs out of 100.\nI changed the last 4 layers and it classifies the data into 8 classes.\nI'm using only -----> image !!! s from the dataset and the first -----> image !!!  of every folder i labelled it 0 for normal and the last 4 -----> image !!! s are labelled as what was emotion given in the txt file in the dataset.\nThere are not much images, only around 1600 images.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cj9ecv/which_pretrained_cnn_model_should_i_use_for_ck/"}, {"autor": "robwoof", "date": "2019-07-29 08:46:31", "content": "Hi everyone. I'm currently trying to get a better -----> picture !!!  of Bayesian Deep Learning. We looked at the topic only briefly this year, especially regarding [modelling uncertainty](https://papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in-bayesian-deep-learning-for-computer-vision) in Computer Vision tasks.\nCan you recommend any paper or manual about the basics of Bayesian Neural Nets? Something that covers the standards (if there are any) of Backprop by Bayes, and anything that is important for the topic. Papers on the application of Bayesian Deep Learning are also welcome, since I'd like to reproduce the results of at least one paper in learning about this.\nThank you!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cj8k6k/papers_on_bayesian_deep_learning/"}, {"autor": "diditi", "date": "2019-10-12 23:37:23", "content": "Hello, \nI've stuck on this problem and feel like there's a major bottleneck in my model.\n\nI'm trying to solve the following problem: given an -----> image !!!  localize (find a bounding box) any of the two object classes present. There can at most be three objects in total in any image, yet I'm only interested in one of the objects. \n\nI've seen leading models of YOLO, R-CNNs and alike, yet since I'm only only interested in one object per image, so I feel like using these architectures would be an overkill. I'm also interested in having as time-efficient model in inference phase as possible, so that's another motivation for not using these approaches.\n\nMy approach is follows: use pretrained CNN on imagenet (I've only tried Mobilenet at this point, yet from the results feel like it should be sufficient), attach global averaging and a few dense layers at the end and output four scalars of the biggest object in the scene (if no object is present, then output a vector of -1s). \n\nHowever, this is failing, and even after few epochs my model either starts overfitting or platoes in validation mse loss. My approach might be hard for the model, I think, as it needs to sort found objects and output the biggest one.\n\nFor context, my dataset consists of 100k images (resolution of 500x400, which I scale to roughly 120x100 with bicubic interpolation (the objects are still identifiable eye-balling them), with around 70k images consisting of only one object, so I feel like there is a big bottleneck in my design.\n\nAny feedback is welcome and appreciated, thanks.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dh2slt/localizing_atleast_one_object_with_two_possible/"}, {"autor": "alex628", "date": "2019-10-12 16:34:57", "content": "I have a portrait I would like to turn into a video as described in this paper \\[Few-Shot Adversarial Learning of Realistic Neural Talking Head Models\\]([https://arxiv.org/pdf/1905.08233.pdf](https://arxiv.org/pdf/1905.08233.pdf)) and on \\[cnet\\]([https://www.cnet.com/news/samsung-ai-deepfake-can-fabricate-a-video-of-you-from-a-single------> photo !!! -mona-lisa-cheapfake-dumbfake/](https://www.cnet.com/news/samsung-ai-deepfake-can-fabricate-a-video-of-you-from-a-single------> photo !!! -mona-lisa-cheapfake-dumbfake/)). \n\n&amp;#x200B;\n\nI am guessing that there are tutorials online on how to do this or something roughly close to this. I am looking to get pointed in the right direction.\n\n&amp;#x200B;\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dgxg0k/question_help_finding_tutorials_on_how_to/"}, {"autor": "inkplay_", "date": "2019-10-11 01:32:20", "content": "For my school's computer club we are having Halloween themed projects. We have these Roombas lying around doing nothing, so I am going to put a raspberry pi on top of the Roomba with a -----> camera !!!  and make it chase people around by detecting their shoes using object detection. Does anyone know where I can get my hands on a trained model like this?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dg7z9g/does_any_one_know_here_i_can_find_a_pertrained/"}, {"autor": "MrJoshiko", "date": "2019-10-09 15:52:44", "content": "Hi,   \nI'm trying to train a YOLO-style network for object detection. I have some images with the objects which I want to detect. I used Amazon's mechanical Turk service to label some of the data, but I'm not really sure what to do with the output.   \n\n\nI have several classes of vehicle which have bounding boxes drawn around them. I also had three people label each -----> image !!! . Quite often the three people disagree on class and the exact location of the boxes also varies somewhat.   \n\n\nI assume there is a (or several) general methods for robustly combining these kinds of data. The kind of logic that I want is:  \n\\-if there is disagreement in the label, flag it for manual inspection. If the disagreement is minor go with a majority vote  \n\\-if the classes are the same average the box centre, width and height.  \n\n\nI assume that people do this sort of thing all of the time, I'm just hitting a block finding an algorithm (or better still a python library) which does this. I've been working on a hacky solution, but it doesn't work well when there are multiple objects of the same class in the same image.  \n\n\nIf anyone has any tips or could point me to a helpful paper I'd be very grateful. Thanks  \n\n\nI hope this is within the scope of the sub.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dfiz8t/combining_multiple_human_bounding_box_estimates/"}, {"autor": "Shameendra", "date": "2019-10-09 14:55:13", "content": "Hi,\n\nSo i am training Yolov2 to detect 9 classes of objects. For that i am using the Darkflow github repo adn Tensorflow as my framework. I followed the instructions from the 'issues' page in the repository. I first took 5 images of each class overfit them and then used these weights to train on my entire dataset. I have a little more than 45k+ -----> image !!! s(thanks to -----> image !!!  augmentation) and about 5k -----> image !!!  for each class. \n\nI cannot unfortunately disclose my dataset but what i can reveal is the objects are all rectangular in shape and can be disinguished from each other by color or by special symbol on the object.\n\nBut i noticed that after 30k steps the the classifer could detect about 1500 images correctly for lets say  'image class 1' while for rest of teh classes it could detect 1500 for each class also. But at 40k steps for 'image class 1', the detection number drops to 1200 while for the rest it goes up.\n\n&amp;#x200B;\n\nAlso the classifier gets detects class 1 wrong among the 1200 detections. Class 1 and class 2 are a little similar in terms of appearance(class 1 is lemon color and has a symbol on it, class 2 is white without any symbol) . So i am guessing it is getting confused because of it?\n\n&amp;#x200B;\n\nI have tried adding more images of class one and class 2, more images of just class 1, and images where class one and class 2 are in the same image but still somehow i get poor detections for class 1. I also tried reducing learning rate from step 30k but it does not seem to work.\n\n&amp;#x200B;\n\nAny suggestions where i am going wrong. Or should i just move on to something better like Yolo v3 or RetinaNet", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dfi65k/training_yolov2darkflow_with_9_classesimages/"}, {"autor": "jfaouzi", "date": "2019-09-11 08:35:07", "content": "Hello everyone,\n\nI have been playing with Recurrent Neural Networks, and I am trying to improve my current model. I have been looking at the attention mechanism, but I am not sure that I understand it correctly.\n\n#### Context\n\nI have longitudinal data, with input vector x_i for i in {1,..., t} and I would like to make a prediction for the target in the near future y_{t+h}.\n\n#### What I have done\n\nI have used RNN and applied a linear layer after the recurrent layer.\n\n#### What I think of doing\n\nI am wondering if it could be useful to use all the previous hidden states (h_i for i in {1,..., t}) instead of the last hidden state only (h_t).\n\n#### My questions\n\nIs attention mechanism relevant in my use case? Most of the examples using Attention that I have seen want to predict a vector (usually a sentence for translation or -----> image !!!  captioning), but in my case I want to predict a single number. I have also read that Attention is really useful for very long sequences, but in my case the sequences are small (t &lt; 10). If Attention could be applied to my use case, do you think that it is relevant?\n\nThanks very much in advance.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d2my9j/attention_mechanism_for_longitudinal_data/"}, {"autor": "NudeJr", "date": "2019-09-10 18:18:53", "content": "I just finished a project using a CNN to identify hand drawn numbers from the MNIST data set. I would like to take it a step further and be able to identify certain -----> image !!! s from a large -----> image !!!  library. Say pictures with dogs from my google photos library. I know with the project I just completed that all the images were the exact same resolution. Does that greatly affect the accuracy of the model? Should I scale all the images to the same res? \n\nSome other questions I have:  \nIs a CNN the best approach for this type of problem? \n\nWhen is too much training data bad? I could easily get a very large amount of images to train with but want to make sure that is fine.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d2bst4/how_important_is_a_constant_image_resolution_when/"}, {"autor": "adpxyz0", "date": "2019-09-10 08:13:15", "content": "Hey,\n\nProblem Statement: To be able to detect faces of specific people with good accuracy and tag those images with the names of the people it contains. \n\nTo do this we have about  40 images person, and 10 classes.\n\nI have been using  Facenet model ( [https://github.com/davidsandberg/facenet](https://github.com/davidsandberg/facenet) ) im getting good results after training the model with the 10 classes &amp; 40 images per class. The current hurdle im facing is : Suppose it suggested with accuracy 40% for an -----> image !!!  containing person of say class A, now we need to add this -----> image !!!  back to the models training dataset and train the model adaptively, so that it  improves the accuracy for this person by taking in more -----> image !!! s and learning from that.\n\nNot sure if I made my problem clear , I could explain more in detail if needed.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d24kc8/image_recognition_model_with_adaptive_learning/"}, {"autor": "AnotherForce", "date": "2019-09-09 15:25:19", "content": "Using  similar agent architectures, should I expect a faster convergence for learning on RAM than learning on -----> image !!!  observations? I'm new to reinforcement learning and therefor do not have a clue.\n\nI  would argue that the size of the observations directly influence the  computation speed, is this correct? Because of this I would expect RAM  observations to speed up convergence of my DDQN implementation, is this a fair assumption?\n\nThanks for your help.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d1sd6e/about_rl_performance_of_openai_retro_gyms_ram_vs/"}, {"autor": "bengya", "date": "2019-05-05 13:43:54", "content": "Hi guys,\nI read several papers and articles where it is suggested that transposed convolution with 2 strides is better than upsampling then convolution. However implementing such model with the transposed convolution resulted in heavy checkboard effect, where the whole generated -----> image !!!  is just a pattern of squares and no learning takes place. How to properly implement it without totally messing up the generation?\nWith the upsampling+convolution I got okay result but I want to improve my model. I am trying to generate images based on the CelebA dataset.\n\nI use keras with tf, later i will attach code but unfortunately I am on mobile now.\n\nThank you for your answers in advance", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bkxukv/transposed_convolution_as_upsampling_in_dcgan/"}, {"autor": "cbstryker", "date": "2019-05-03 22:42:12", "content": "I'm looking for a web application that can be self hosted for -----> image !!! /object labelling. Currently I'm using OpenLabeller and LabelImg, but I would like to be able to have other people work on the dataset without giving them full access. So something that can be self hosted and web based is ideal.\n\nOpenLabeller has the ability to do object inference to assist with the process. So that would be a plus also.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bkehty/web_based_labelling_program/"}, {"autor": "Cbrum11", "date": "2019-05-03 14:58:41", "content": "Hi all,\n\n&amp;#x200B;\n\nI have a fun project I'm working on to help me explore machine learning.  Basically, I've pulled some data and found a high order polynomial that represents the data.  The original idea was to develop some constraints around the coefficients of this polynomial, then create a few thousand, different iterations of the general pattern by randomly incrementing the coefficients.  I could then use openCV and train an -----> image !!!  classifier to look for my pattern in other graphs.\n\n&amp;#x200B;\n\nThe hope was that each coefficient would correspond to an easily identifiable feature in the graph (like the slope of a particular curve, or the length of time the curve stays at a particular apex).  Unfortunately, I learned very quickly that changing the coefficients doesn't actually effect the polynomial in this way.\n\n&amp;#x200B;\n\nFor example.  Here's the original polynomial and data...\n\n&amp;#x200B;\n\n[Original Data](https://i.redd.it/8g6yyevwe0w21.png)\n\nAnd here's graphs that represent incrementing the second coefficient by .001.\n\n&amp;#x200B;\n\n[Increment 2nd coeff by .001](https://i.redd.it/fsi2cfz3f0w21.png)\n\nAnd here's graphs that represent incrementing the third coefficient by .00001\n\n&amp;#x200B;\n\n[Increment 3rd coeff by .00001](https://i.redd.it/a90g6hqaf0w21.png)\n\nSo I'm left scratching my head at how to proceed.  I need a way to keep the general pattern of the curve, but to do things like, make the first slope steeper, raise or lower the apex of the second slope, or squish the distance between the first and second slope.  Am I going about this sort of pattern recognition the right way?\n\n&amp;#x200B;\n\nThanks in advance!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bk9feb/creating_fudge_factos_in_polynomial/"}, {"autor": "Amoney_baconglide", "date": "2019-05-03 10:30:36", "content": "I'm having troubles. Somehow I want to categorize either the text from reciepts or if you can do it with the whole -----> image !!! . The result doesn't have to be perfect I'm writing a report and can come with the conclusion that it doesn't work at al but then I've tested it anyway. I have thought of using KNN and somehow use either the text on the reciept to classify it or the whole picture. I've been searching a lot on internet and don't know if this is possible. Does anyone have any recomendations how i can do this?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bk6wev/help_with_categorising_reciepts/"}, {"autor": "tighter_wires", "date": "2019-05-02 18:35:03", "content": "I have an -----> image !!!  set of variable size that I\u2019d like to train a CNN on, which I assume will get get best result if all -----> image !!! s have the same dimension.\n\nMy first thought was to resize each image to the smallest width and length in the image set. \n\nWhat is considered best practice for image resizing and scaling for CNNs?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bjyfb5/best_practices_for_preparing_an_image_set/"}, {"autor": "74throwaway", "date": "2019-05-02 02:16:27", "content": "I currently work in -----> image !!!  processing using Matlab. I have worked with C++ and CNNs in Python briefly before. From what I understand, most DL jobs fall under the production or research side. In the production roles, C++ is more important, whereas having a PhD or publications and knowing Python/Tensorflow/Keras/Pytorch are more important in the research roles\n\nSince I don't have much work experience or publications/phD, I'm getting it's easier to get hired in a production role? I'm guessing it's easier to get hired at large companies.\n\nSo to get a job at a large company, should I focus on improving my C++? Or use my time to work on projects that demonstrate mastery of DL concepts such as using Variational Autoencoders, GANs, semantic segmentation, Reinforcement Learning, etc?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bjpojv/how_to_get_a_deep_learning_job_in_production_side/"}, {"autor": "thraway14", "date": "2019-05-01 18:36:48", "content": "I have a little experience with -----> image !!!  processing, computer vision, and machine learning. I recently came across how CNNs have been used recently for image segmentation\n\nI'm currently working on a project in which I have a set of very noisy images (around 20 images total) and I want to locate the objects in the images and separate them from the noise/background. \n\nI also have a bunch of images that serve as a \"mask\" in that these images are a sort of blueprint that provide an outline of where the objects should be located.\n\nHere is an example of images: https://imgur.com/a/OVmTu2Q. These images are just a rough outline of what I'm dealing with. The actual images are much noisier than the first image. But the actual masks are noisefree just like the mask in that link\n\nHow should I approach this problem? If 20 images and 20 image masks is not large enough of a training size, should I augment my original set of images (by applying rotations, transformations, etc?)? Or could I use transfer learning? The images I'm dealing with are proprietary so I can't discuss them in detail here. But the objects in them are not people, dogs, cats, airplanes, or other common objects in the CNN examples I've read about. Also, because I want to detect the objects with better accuracy than just a bounding box, semantic segmentation is what I should look into for this project, right?\n\nIf image segmentation is the way to go, which one should I start with assuming I have only basic knowledge of CNNs and Deep Learning? Should I start with UNets?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bjkqqk/use_transfer_learning_and_semantic_segmentation/"}, {"autor": "LavishManatee", "date": "2019-05-01 00:39:42", "content": "  \n\nI want to write a peice of software composed of two smaller pieces in python and Pytorch.\n\nI want it to do the following;\u00a0\n\n1. like the program [PixInsight](https://pixinsight.com/)\u00a0does for astral------> photography !!! , I want it to scan a set of images for pixel matches and align them for stacking to create an HD composite.\n\n2. two types of aberration that are present in these images; a) light reflection and b) reflection of nearby objects (due to high gloss surface).\n\nNot sure which operation should run first, though I am leaning toward aberration removal and then pixel matching to stack and recompose.\n\nMy logic (please correct if in error)\n\nInstead of taking one picture, we take many. I figured out that the light and reflection aberrations shift due to angle of the camera.\u00a0By moving the camera angle around a taking shots from multiple sides the aberration shifts position around the object. This means each picture has roughly 85% of want I want and 15% aberration (which all present the same way), all in different locations. I figure I can pull the clear 85% of each image and align and stack them to remove the aberration.\u00a0\n\nI want the software to become better at doing this over more and more examples.\n\nTraining data? None. Well, let me clarify, I could pull from the internet but the image examples are not uniform (different sizes and resolutions as well as only 1 angle). I talked to one software dev who said I might be able to teach a system the rough estimate of what the aberration looks like and then further refine it later when you have enough data without the aberration. Is this true?\n\nSo far I am learning toward using a convolutional\u00a0or a GAN for this but I am not sure.\u00a0\n\nWhat about OpenCV?\u00a0\n\nMy question are -\u00a0\n\nWhat is the difficulty level of doing something like this?\u00a0\n\nWhat network would you recommend I look into for this?\n\nDo you have any resources you would suggest?\n\nIs [this a good map](https://i.imgur.com/Hk5W3ZD.png) to go off of? If so, what path would you recommend taking?\n\nThanks for taking the time to read and reply!!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bjb0c8/have_a_good_idea_where_to_start_want_to_be_sure/"}, {"autor": "webdevv1", "date": "2019-04-30 19:51:59", "content": "I would like to develop a weapon detection software that analyses a -----> picture !!!  and tells the user if there is a weapon visible in the -----> picture !!! . It should be a command line tool. But I have no idea where to start. I know I need training data as much as possible. The training data must be pictures with different weapons (machine guns, machine pistols, pistols, knives, grenades, ...) from different angles. \n\nI want to know if there's a good tutorial on how to do that. I have absolutely no clue about neural networks, machine learning, deep learning and so on. I know how to develop with python, but that's it.\n\nWould you like to help me?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bj7q8w/weapon_detection_software_picture_analyzer/"}, {"autor": "djkoell", "date": "2019-04-30 13:19:39", "content": "Appreciate any guidance on performing this service.  I'm working on an initiative to take a selfie -----> photo !!!  and determine if it meets requirements for a US Passport -----> photo !!! .  One of the requirements is if the background is a solid white color.  I've done some work using a Mask R-CNN ([https://github.com/matterport/Mask\\_RCNN](https://github.com/matterport/Mask_RCNN)) to detect the person in the foreground and remove the background.  While I think this has capability to offer great service in an app, I would like to launch with a validation service until we can polish this service for GA.  \n\n&amp;#x200B;\n\nCould anyone recommend an approach to take a photo and return a score 0 to 1 based on how busy or much noise is in the background of a Selfie/headshot?\n\n&amp;#x200B;\n\nMuch appreciated!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bj37se/guidance_for_nn_to_score_how_busy_the_background/"}, {"autor": "GhostofBlackSanta", "date": "2019-04-30 05:33:18", "content": "Hi I am playing around with the TensorFlow for Poets project and following YouTube tutorials on how to get it work. Unfortunately, they don't go into detail on **how** it works. Is there a guide for beginners so I can understand how TensorFlow works and how it does -----> image !!!  classification?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bizoid/is_there_an_indepth_guide_on_how_tensorflow_does/"}, {"autor": "Spaceman776", "date": "2019-04-30 03:01:10", "content": "Hi, I am doing an -----> image !!!  classification project using TensorFlow and I was wondering what types are available. I think the code I am follwing (TensorFlow for Poets) is pixel based but I think theres also convolutional layers. Does anyone know where I can get some good basic information on all this?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/biye3h/image_classification_with_tensorflow_types/"}, {"autor": "k3ltis", "date": "2019-09-27 21:31:45", "content": "Hi there,\n\nI am searching for a topic to write a master thesis about and stranded in the broad field of machine learning. I think I am on to something cool but tbh I am lacking of experience to be sure about, what I think is a topic thats hot enough to be called \"a scientific problem waiting to be solved\".\n\nThe main problem: The field is huge. In every direction I looked so far, there is significant research done or going on. And a lot of papers I was reading through are outdated by the next one. It's frustrating. I kindly ask you to have a look at the idea and leave a comment of what you think about it as a state of the art topic:\n\n&amp;#x200B;\n\nIdea:\n\nYou have a set of tags `t1, t2, ...` and a set of documents. As you can see in the -----> image !!!  below (on the left side, marked with `A`), there are connections between those tags and the documents. Imagine a movie (document) that has been assigned a genre (tag) to. **The basic idea is to predict documents based on a given subset of tags.** The tags will come from a NLP module that will extract them from written text.\n\nWhat's the crucial point then?\n\nBoth tags and documents are expendable. On the right side you see that there is another document and additional tags and also new connections between them. **In case the search or result space is changing the already learned prediction should be preserved. There should be no need for learning everything from the beginning on.**\n\nhttps://i.redd.it/3bs62luhc7p31.png\n\nWhat do you think about this? I would particular like to know if this topic is snow from yesteryear...\n\nGreetings  \nThomas", "link": "https://www.reddit.com/r/learnmachinelearning/comments/da6vyb/label_based_prediction_as_thesis_topic/"}, {"autor": "Toko1111", "date": "2019-09-26 15:16:33", "content": "Hello,\n\nI am rather new to machine learning and have only followed an undergraduate class which only focused on the theoretical aspects of ML. This semester I am doing a computer vision project in which we have to segment a mountain -----> image !!!  into different classes. The first task is of course to label all the pictures we have with the different classes.\n\nOne of the person I am working with argues that we can't just have a \"snow\" class, but instead split it into \"sunny snow\" and \"shadowed snow\". It seems a little weird to me, as I believe our Machine Learning algorithm (we'll try multiple, but most likely it'll be a deepnet with CNN) would be robust to detect which are the snow parts, no matter if some are brighter than the others. Please note that in the end, for the purpose of this project, we do not care to differentiate sunny and shadowed snow in the end, and if we made that distinction, the 2 classes would be merged together in the end.\n\nAm I right to think we do not have to go through this process of labeling so precisely the training set ? Thank you for your answers :)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d9l0lh/image_segmentation_choosing_classes/"}, {"autor": "Confused_Electron", "date": "2019-09-25 19:07:01", "content": "Hi all,\n\nI'm a senior undergrad EE student. For the capstone project we're going to design a sort of cat feeder that recognizes cats and dogs and also distinguishes differents cats from each other so that they can have different diets. I'm thinking I need some form of machine learning to identify what the -----> camera !!!  sees is a cat and also to distinguish them from each other and I need some pointers to start learning. I've found [this](https://www.reddit.com/r/MachineLearning/comments/8at30n/d_what_is_the_best_way_of_learning_machine/dx1uilh?utm_source=share&amp;utm_medium=web2x) comment and if it's useful advice for me I can follow it. What do you think?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d97xow/what_should_learn_for_this/"}, {"autor": "terzioo", "date": "2019-09-25 17:52:45", "content": "Hey,\nI\u2019ve been getting into practice with my first few convolutional neural networks and I come up with an idea of a project that aims to detect outdoor ads based on the -----> image !!!  (eg. google street view?).\n\nHowever as I\u2019m a beginner I would like to check your opinions or advice on this idea.\n\nMy major concern is that ads come in various forms and shapes, so training a model and detecting might be hard/impossible with decent accuracy. \n\nAlso, until this point I\u2019ve been training really simple networks, so any advice on direction I should take to make this project possible will be hugely appreciated!\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d96vuz/image_recognition_project_outdoor_ads_detection/"}, {"autor": "ReViZEN", "date": "2019-09-25 10:15:13", "content": "is There a way to give scalar as a input and get input of a -----> image !!!  as numpy array. I am trying to check if machine learning or deep learning can be applied to Fluid Simulations.\n\nVery basic problem I want to test is say fluid flow on a Cylinder.\n\nI want to give input as angle of attack that is the direction of flow it is coming from and I want to get output of an  in numpy array shape which consists of velocities on grid. Is it a good question to solve?\n\nBasically I am thinking of doing some fluid mechanics related problem in Keras with deep learning any Ideas. I just started learning keras  and I completed until 5 chapters of \"deep learning with Python\" book. \n\nSo are there any basic ideas I can explore where I can apply deep learning to some fluid mechanics.\n\nAny help is appreciated.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d918s6/how_to_do_multi_dimensional_regression_problem_in/"}, {"autor": "TheIrrationalRetard", "date": "2019-09-25 09:49:49", "content": "So I have a set of images which I am annotating using labelImg. Its in the PascalVoc format. I have an -----> image !!!  folder and annotation folder. How do I load such dataset of labelled images onto a pytorch model like inception v3. \nHelp with Tensorflow or any other framework will also work. I just wann know how to use such a data. I can't understand any of the google results.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d910wy/how_to_use_annotated_images_made_using_labelimg/"}, {"autor": "tesar-tech", "date": "2019-02-05 21:21:25", "content": "I have created [ZODOC.tech](https://ZODOC.tech) . A site for sharing -----> image !!!  processing and deep learning samples.\n\nSome of them are related to deep learning, like [Classification of hand written digits](https://zodoc.tech/posts/en/classification_of_handwritten_digits) or [Image Classification using alexnet](https://zodoc.tech/posts/en/classify_by_alexnet). Some of them are just basic stuff about image processing, i. e.: [Animation of binary image](https://zodoc.tech/posts/en/animation_of_binary_image_with_variable_threshold) .\n\nCurrently, all samples use matlab code, but plans are to expand it with samples from other frameworks (TF, PyTorch,Caffe, etc..) and languages. \n\nThe project is an open source, available on [GitHub](https://github.com/tesar-tech/zodoc), ready for your ideas or posts. [Here](https://zodoc.tech/about) is some info about contributing.  Feel free to contribute or let me know about your ideas.\n\n&amp;#x200B;\n\n&amp;#x200B;", "link": "https://www.reddit.com/r/learnmachinelearning/comments/aniv8h/project_image_processing_and_deep_learning_samples/"}, {"autor": "XYAtomic", "date": "2019-02-05 14:09:34", "content": "Hi all,\n\n&amp;#x200B;\n\nI'm doing a dissertation project on machine learning. I'm looking for ideas on how to approach the project, as I'm overwhelmed by all the different aspect of ML.\n\n&amp;#x200B;\n\nThe project description:\n\nA passport -----> photo !!!  is used in many official documents such as visa, driver licenses, ID, ... . The photo should conform to several requirements: Neutral face expression, eyes open and look at the camera, full face seen on the camera, neutral background,.... . This validation process is mostly done by manually (I guess), Now I'm looking for a way to automate this by applying machine learning techniques to validate the passport photo. \n\n&amp;#x200B;\n\nWhat I should end up with: \n\n1. Input passport photo\n2. Magical algorithm validates photo.\n3. Output Valid/ Not valid\n\nI'm not looking for an easy way out by using a framework of some sort that does everything for me. I need to understand the underlying process of what is happening step by step. For the project it's not even necessary to make a working prototype, a theoretical explanation will be sufficient.\n\n&amp;#x200B;\n\nLooking forward hearing some of your great ideas! \n\n&amp;#x200B;\n\n\\*\\*Drop the mic\\*\\*", "link": "https://www.reddit.com/r/learnmachinelearning/comments/anefp6/passport_photo_validation/"}, {"autor": "Simusid", "date": "2019-02-05 03:31:00", "content": "It's common practice to pick one of the following 3 methods to normalize an -----> image !!! :\n\n* (x - x.min()) / (x.max() - x.min()) # values from 0 to 1\n* (x - x.min()) / (x.max() - x.min()) - 1 # values from -1 to 1\n* (x - x.mean()) / x.std() # zero mean, std of 1.0\n\nI was helping a friend today with a simple classifier.   He used the first method and appeared to have good initial results.   In 10 epochs he trained to about 95% and validation was just a little below that.   He had a small set of holdout images and those seemed to generalize acceptably.\n\nI commented that I usually use the third method and I thought it might show slightly better training.   We edited his code with that one simple change and found that it did not train at all.  I don't recall the numbers but it was clearly a failure.\n\nI would understand if different methods trained/validated differently and one edged out the other.   But I'm confused why one method would work ok and the other standard method would fail completely.   Is there any intuition about this?   If it matters, the images are [side scan sonar images](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Laevavrakk_%22Aid%22.png/220px-Laevavrakk_%22Aid%22.png) and I think it's fair to say they do not have a high dynamic range.\n", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ana0cy/choice_of_image_normalization/"}, {"autor": "TexSC", "date": "2019-02-05 03:09:10", "content": "I've been following [this guide](https://kingdomakrillic.tumblr.com/post/178254875891/i-figured-out-how-to-get-esrgan-and-sftgan) for getting ESRGAN to work on windows. I had no problems with the guide, and got everything up and running. The results are stunning, but anything larger than the included sample images and I get the following error: \n\n    RuntimeError: CUDA out of memory. Tried to allocate 7.91 GiB (GPU 0; 11.00 GiB total capacity; 2.06 GiB already allocated; 6.71 GiB free; 2.18 MiB cached)\n\nI'm using a 1080ti with 11gb of VRAM, and I was hoping to upscale some 1080p wallpapers. \n\nCan anyone look at [test.py](https://github.com/xinntao/ESRGAN/blob/master/test.py) from their github and let me know which parameters I need to change to allow the larger images? Something like block size? Also, this depends solely on resolution, not -----> image !!!  size on disk, correct?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/an9tgw/how_to_make_esrgan_allow_higher_resolution_images/"}, {"autor": "xHipster", "date": "2019-02-04 15:04:40", "content": "Hi /r/learnmachinelearning, \n\nI've got a working DCGAN, but how do you make the leap towards -----> image !!!  inpainting?\nAfter reading through quite a lot of papers &amp; example codes, it is still unclear for me how this is actually done with a DCGAN.\n\nI've got the feeling that this ia a great example:\nhttps://github.com/saikatbsk/ImageCompletion-DCGAN/blob/master/main.py#L159\nHowever, what's going on from line 159 and beyond? I think think this is were the inpainting is happening. As a (new) pytorch user, it also doesn't help too much that this is written in TF. \n\nAny articles or links to explanatory repositories would be greatly appreciated.  ", "link": "https://www.reddit.com/r/learnmachinelearning/comments/an2hes/how_to_use_a_trained_dcgan_for_image_inpainting/"}, {"autor": "AdrenalDruid08", "date": "2019-02-04 03:29:53", "content": "So, this was the first time I entered an online Machine Learning competition and we were told to build a CNN which performs Object Localisation on a 14 GB -----> image !!!  data set. I had some AWS credits from my student account so I thought of training and testing the model on it but then I was forced to use nano or vim (CLI tools) to code in Python. Since the dataset is so big it's present only on the server, so how do I collaborate with a teammate for the code? For now we used Github; he would commit and push changes and I would pull it on the server. (repeat this till it works?)\n\nDo you guys have better ideas for designing a good workflow? I would love to hear it.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/amxhds/deep_learning_workflow_on_an_aws_server/"}, {"autor": "06darknebula", "date": "2019-02-03 18:12:47", "content": "I want to classify different types of handwritten letters like g and l to determine personality of a person by using graphology.Example:l with loop corresponds to a extrovert and l with no loop corresponds to a introvert.Suggestions for any other -----> image !!!  classification algorithm will be appreciated.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ams5ed/how_do_i_create_dataset_for_convolution_neural/"}, {"autor": "kswiorek", "date": "2019-02-03 17:17:03", "content": "I modified a GAN from [this](https://towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0) example to generate cat pictures.\n\nThis is some of the database:\n\nhttps://i.redd.it/xmqdndwtxde21.jpg\n\nThe generated pictures are pretty good, but I think they could be better, especially that there are apps, which can generate human faces which look like real ones. The problem is that after some time (around 10000 batches) the discriminator starts classifying every generated -----> picture !!!  as real, therefore the generator loss drops to 0 and it doesn't train anymore.\n\n&amp;#x200B;\n\nThese are the generated images:\n\nhttps://i.redd.it/xppdunu0zde21.jpg\n\n&amp;#x200B;\n\nI tried to add while loops wich would train the loosing side untill it stops loosing, but it just starts looping indefinitely.\n\nThis is the code:\n\n    #!/usr/bin/python\n    # -*- coding: utf-8 -*-\n    \n    import numpy as np\n    import time\n    from tensorflow.examples.tutorials.mnist import input_data\n    \n    import os\n    import pickle\n    from keras.models import Sequential\n    from keras.layers import Dense, Activation, Flatten, Reshape\n    from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n    from keras.layers import LeakyReLU, Dropout\n    from keras.layers import BatchNormalization\n    from keras.optimizers import Adam, RMSprop\n    from keras.preprocessing.image import ImageDataGenerator\n    \n    import matplotlib.pyplot as plt\n    \n    batch = 80\n    \n    f = open('log.txt', 'w')\n    \n    \n    class ElapsedTimer(object):\n    \n        def __init__(self):\n            self.start_time = time.time()\n    \n        def elapsed(self, sec):\n            if sec &lt; 60:\n                return str(sec) + ' sec'\n            elif sec &lt; 60 * 60:\n                return str(sec / 60) + ' min'\n            else:\n                return str(sec / (60 * 60)) + ' hr'\n    \n        def elapsed_time(self):\n            f.write('Elapsed: %s ' % self.elapsed(time.time()\n                    - self.start_time))\n            f.write('\\n')\n            print( 'Elapsed: %s ' % self.elapsed(time.time())\n                    - self.start_time)\n    \n    \n    class DCGAN(object):\n    \n        def __init__(\n            self,\n            img_rows=128,\n            img_cols=128,\n            channel=3,\n            ):\n    \n            self.img_rows = img_rows\n            self.img_cols = img_cols\n            self.channel = channel\n            self.D = None  # discriminator\n            self.G = None  # generator\n            self.AM = None  # adversarial model\n            self.DM = None  # discriminator model\n    \n        # (W\u2212F+2P)/S+1\n    \n        def discriminator(self):\n            if self.D:\n                return self.D\n            self.D = Sequential()\n            depth = 64\n            dropout = 0.2\n    \n            # In: 28 x 28 x 1, depth = 1\n            # Out: 14 x 14 x 1, depth=64\n    \n            input_shape = (self.img_rows, self.img_cols, self.channel)\n            self.D.add(Conv2D(depth * 1, 5, strides=2,\n                       input_shape=input_shape, padding='same'))\n            self.D.add(LeakyReLU(alpha=0.2))\n            self.D.add(Dropout(dropout))\n    \n            self.D.add(Conv2D(depth * 2, 5, strides=2, padding='same'))\n            self.D.add(LeakyReLU(alpha=0.2))\n            self.D.add(Dropout(dropout))\n    \n            self.D.add(Conv2D(depth * 4, 5, strides=2, padding='same'))\n            self.D.add(LeakyReLU(alpha=0.2))\n            self.D.add(Dropout(dropout))\n    \n            self.D.add(Conv2D(depth * 4, 5, strides=2, padding='same'))\n            self.D.add(LeakyReLU(alpha=0.2))\n            self.D.add(Dropout(dropout))\n    \n            self.D.add(Conv2D(depth * 8, 5, strides=1, padding='same'))\n            self.D.add(LeakyReLU(alpha=0.2))\n            self.D.add(Dropout(dropout))\n    \n            # Out: 1-dim probability\n    \n            self.D.add(Flatten())\n    \n            self.D.add(Dense(128))\n            self.D.add(Activation('relu'))\n    \n            self.D.add(Dense(32))\n            self.D.add(Activation('relu'))\n    \n            self.D.add(Dense(1))\n            self.D.add(Activation('sigmoid'))\n            self.D.summary()\n            return self.D\n    \n        def generator(self):\n            if self.G:\n                return self.G\n            self.G = Sequential()\n            dropout = 0.2\n            depth = 64 + 64 + 64 + 64\n            dim = 32\n    \n    # In: 100\n            # Out: dim x dim x depth\n    \n            self.G.add(Dense(dim * dim * depth, input_dim=100))\n            self.G.add(BatchNormalization(momentum=0.9))\n            self.G.add(Activation('relu'))\n    \t\t\n            self.G.add(Reshape((dim, dim, depth)))\n            self.G.add(Dropout(dropout))\n    \n            # In: dim x dim x depth\n            # Out: 2*dim x 2*dim x depth/2\n    \n            self.G.add(UpSampling2D())\n            self.G.add(Conv2DTranspose(int(depth / 2), 5, padding='same'))\n            self.G.add(BatchNormalization(momentum=0.9))\n            self.G.add(Activation('relu'))\n    \t\t\n            self.G.add(Conv2DTranspose(int(depth / 2), 5, padding='same'))\n            self.G.add(BatchNormalization(momentum=0.9))\n            self.G.add(Activation('relu'))\n    \n            self.G.add(UpSampling2D())\n            self.G.add(Conv2DTranspose(int(depth / 4), 5, padding='same'))\n            self.G.add(BatchNormalization(momentum=0.9))\n            self.G.add(Activation('relu'))\n    \n            self.G.add(Conv2DTranspose(int(depth / 4), 5, padding='same'))\n            self.G.add(BatchNormalization(momentum=0.9))\n            self.G.add(Activation('relu'))\n    \n            self.G.add(Conv2DTranspose(int(depth / 8), 5, padding='same'))\n            self.G.add(BatchNormalization(momentum=0.9))\n            self.G.add(Activation('relu'))\n    \n            self.G.add(Conv2DTranspose(int(depth / 8), 5, padding='same'))\n            self.G.add(BatchNormalization(momentum=0.9))\n            self.G.add(Activation('relu'))\n    \n            # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n    \n            self.G.add(Conv2DTranspose(3, 5, padding='same'))\n            self.G.add(Activation('sigmoid'))\n            self.G.summary()\n            return self.G\n    \n        def discriminator_model(self):\n            if self.DM:\n                return self.DM\n            optimizer = RMSprop(lr=0.0002, decay=6e-8)\n            self.DM = Sequential()\n            self.DM.add(self.discriminator())\n            self.DM.compile(loss='binary_crossentropy',\n                            optimizer=optimizer, metrics=['accuracy'])\n            return self.DM\n    \n        def adversarial_model(self):\n            if self.AM:\n                return self.AM\n            optimizer = RMSprop(lr=0.0001, decay=3e-8)\n            self.AM = Sequential()\n            self.AM.add(self.generator())\n            self.discriminator().trainable = False\n            self.AM.add(self.discriminator())\n            self.AM.compile(loss='binary_crossentropy',\n                            optimizer=optimizer, metrics=['accuracy'])\n            return self.AM\n    \n    \n    class MNIST_DCGAN(object):\n    \n        a_loss = [1, 1]\n        d_loss = [1, 1]\n    \n        def __init__(self):\n            self.img_rows = 64\n            self.img_cols = 64\n            self.channel = 3\n    \n            self.train_datagen = ImageDataGenerator(rescale=1. / 255,\n                    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n    \n            self.x_train = self.train_datagen.flow_from_directory('cats',\n                    target_size=(128, 128), batch_size=batch,\n                    class_mode=None)\n            self.DCGAN = DCGAN()\n            self.discriminator = self.DCGAN.discriminator_model()\n            self.adversarial = self.DCGAN.adversarial_model()\n            self.generator = self.DCGAN.generator()\n    \n        def train(\n            self,\n            train_steps=2000,\n            batch_size=256,\n            save_interval=0,\n            ):\n    \n            noise_input = None\n            if save_interval &gt; 0:\n                noise_input = np.random.uniform(-1., 1., size=[16, 100])\n            for i in range(train_steps):\n                self.images_train = np.zeros((batch, 128, 128, 3))\n    \n                self.images_train = self.x_train[int(i % 123)]\n    \n                noise = np.random.uniform(-1., 1., size=[batch_size, 100])\n                images_fake = self.generator.predict(noise)\n                x = np.concatenate((self.images_train, images_fake))\n                y = np.ones([2 * batch_size, 1])\n                y[batch_size:, :] = 0\n                test = 1\n                k = 0\n                while self.d_loss[0] &gt; 0.5 and self.a_loss[0] &lt; 0.5 or test \\\n                    == 1:\n                    f.write('training D')\n                    f.write('\\n')\n                    print( 'training D')\n                    self.d_loss = self.discriminator.train_on_batch(x, y)\n                    test = 0\n                    k += 1\n                    if k == 10:\n                        k = 0\n                        break\n    \n                test = 1\n                y = np.ones([batch_size, 1])\n                noise = np.random.uniform(-1., 1., size=[batch_size, 100])\n                while self.a_loss[0] &gt; 0.5 and self.d_loss[0] &lt; 0.5 or test \\\n                    == 1:\n                    f.write('training A')\n                    f.write('\\n')\n                    print( 'training A')\n                    self.a_loss = self.adversarial.train_on_batch(noise, y)\n                    test = 0\n                    k += 1\n                    if k == 10:\n                        k = 0\n                        break\n    \n                log_mesg = '%d: [D loss: %f, acc: %f]' % (i,\n                        self.d_loss[0], self.d_loss[1])\n                log_mesg = '%s  [A loss: %f, acc: %f]' % (log_mesg,\n                        self.a_loss[0], self.a_loss[1])\n                f.write(log_mesg)\n                f.write('\\n')\n                print( log_mesg)\n                if save_interval &gt; 0:\n                    if (i + 1) % save_interval == 0:\n                        os.system('cls')\n                        self.generator.save('generator.p')\n                        self.plot_images(samples=noise_input.shape[0],\n                                noise=noise_input, step=i + 1)\n    \n        def plot_images(\n            self,\n            samples=16,\n            noise=None,\n            step=0,\n            ):\n    \n            filename = 'mnist.png'\n            if noise is None:\n                noise = np.random.uniform(-1., 1., size=[1, 100])\n            else:\n                filename = 'images/mnist_%d.png' % step\n            images = self.generator.predict(noise)\n            image = images[0, :, :, :]\n            fig = plt.figure(frameon=False)\n            ax = plt.Axes(fig, [0., 0., 1., 1.])\n            ax.set_axis_off()\n            fig.add_axes(ax)\n            ax.imshow(image)\n            fig.savefig(filename)\n            plt.close('all')\n    \n    \n    if __name__ == '__main__':\n        mnist_dcgan = MNIST_DCGAN()\n        timer = ElapsedTimer()\n        mnist_dcgan.train(train_steps=20000, batch_size=batch,\n                          save_interval=50)\n        timer.elapsed_time()\n        mnist_dcgan.plot_images()\n        f.close()\n\n&amp;#x200B;", "link": "https://www.reddit.com/r/learnmachinelearning/comments/amrka7/gan_generator_model_winning/"}, {"autor": "PeterThePawn", "date": "2019-02-03 12:40:55", "content": "I have a bunch of images for a dataset which is currently not labeled. I'm looking for a tool which shows me the -----> image !!!  one after another and allows me to label it as X, Y or Z. Then, I want to export the dataset into TensorFlow.  \n\n\nI've looked at a bunch of labeling tools but they all see like overkill. They all have bounding boxes, or complex labeling. I just want classification.\n\n&amp;#x200B;\n\nI was thinking of coding it up myself, but I'm sure there has to be an existing solution...thanks for any advice!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/amp86q/what_tool_do_you_use_to_label_simple/"}, {"autor": "WhyAreYouLikeThatHuh", "date": "2019-02-03 11:01:33", "content": "Hi, I have a question for my project:\n\nI\u00b4m trying to identify mislabeled data, or at least mark them for manual labeling (-----> image !!! -field).\n\nMy plan is to create a filter before the real training occurs in order to get the most out of my model. My approach is what I wanted to present and I would really appreciate if you got any ideas wether this is a good approach or not.\n\nSo basically i want to start by clustering them with Gaussian Mixture-GM (scikit library) based on feature vectors that I get from a neural network (resnet perhaps). From the GM I will attain a probability clouds. Lets say it is 3 classes. If the probability of an image is within one std-deviation (68%) then the image (and all the others withing one std-dev) will be the ground truth for the next stage of the filter. If two clouds are interfering, the probabilty level is increased. That would be in cases when images are really close to each other (maybe if the classes is two different models from same manufacturer with slight differences).\n\nThe next stage of the filter is some kind of ensemble method. Either a bagging or stacking method. The labels (ground truths) are chosen as mentioned in the first stage. The second stage is basically some voting classifier which should give me information about how probable the pictures belongs to each class. Then I could try setting threshold values and the images that does not fulfills the threshold is then marked for manual labeling.\n\nSo my question is: Does this approach make sense? What kind of ensemble method should i pick? Any other tips?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/amomzk/identifying_mislabeled_data_any_tips_comments_on/"}, {"autor": "shubzs-shubham", "date": "2019-02-03 09:47:02", "content": "I am trying to detect cancer in CT scans through -----> image !!!  classification. I've managed to load the CT scans of a patient and prepare the data (loading dicom images and applying a lung mask). Since CT scans are taken as 'slices', my input data is a stack of 2d images. The stack size isn't the same, varies from 30 to 150.\n\nI've never worked with stacks of images that are labelled as a unit (benign or malignant) and am unsure about how I can go about creating a model to predict the same. I'm guessing a 3d kernel is the way to go but it's been a long time since I did anything with AI so I don't remember much. Any help/advice on how I can label + load the data and the model architecture would be great.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/amo8js/classifying_a_stack_of_images_with_pytorch/"}, {"autor": "ILoveToCorrectPeople", "date": "2019-02-02 00:05:04", "content": "I'm trying to learn pyTorch for neural networks, but it doesn't seem to be training properly. I'm using the MNIST data set to test the NN. My training set is a (60000, 784) matrix, which I introduce, row by row, to the NN's input layer (784,). I only trained with about 100 of them at first.  I don't do any convolutions, just a flattened version of the (28,28) images. The output is (10,) where each node represents the confidence in each digit. The target (desired) output is a vector of 9 zeros and one 1 at the index corresponding to the label for the current training -----> image !!! . I'm using MSE for the cost function. I print out the loss during each iteration of training. At first the loss decreases, but then stops dead at 0.1. The reason it's at 0.1, is because the output goes to all zeros as it's training, and so the MSE ends up calculating (0^2 + ... + 1^2 + ... + 0^2)/10 = 0.1.\nThe things that are commented out are other approaches that I've tried that had identical results. This should be very simple and I don't know why its not working. I suspect that the gradients aren't being updated properly, but I can't tell why since I did this just like the many tutorials I watched. HAYLP\n\n    class Net(torch.nn.Module):\n        def __init__(self):\n            super(Net, self).__init__()\n            \n            self.learningRate = 0.1\n            \n            \n            self.l1 = torch.nn.Linear(784,32)\n            self.l2 = torch.nn.Linear(32,16)\n            self.l3 = torch.nn.Linear(16,16)\n            self.l4 = torch.nn.Linear(16,10)\n            \n            self.sigmoid = torch.nn.Sigmoid()\n    \n            self.output = torch.tensor(0)\n            \n            self.optimizer = torch.optim.SGD(self.parameters(), lr=0.01)\n            \n            self.costFunction = torch.nn.MSELoss()\n            self.loss = 0\n            \n        def forward(self, inp):\n            inp = torch.from_numpy(inp) \n            inp = inp.type(torch.float)\n            inp.requires_grad = True\n            \n            inp = self.l1(inp)\n            inp = self.sigmoid(inp)\n            inp = self.l2(inp)\n            inp = self.sigmoid(inp)\n            inp = self.l3(inp)\n            inp = self.sigmoid(inp)\n            inp = self.l4(inp)\n            inp = self.sigmoid(inp)\n            \n            self.output = inp\n            return inp\n        \n        def applyGrad(self):\n            for param in self.parameters():\n    #                 param.data -= (param.grad.data)/(param.grad.data.norm())*self.learningRate\n                    param.data.sub_(param.grad.data*self.learningRate)\n        \n        def train(self, inp, desired):\n            net.forward(inp)\n            self.loss = self.costFunction(self.output, desired)\n            self.loss.backward()\n            self.applyGrad()  \n    #         self.optimizer.step()\n\n..\n\n    def getDesired(label):\n        desired = torch.zeros(10)\n        desired[label] = 1\n        return desired\n\n..\n\n    net = Net()\n    for i,each in enumerate(trainImgPack[:100]):\n        net.train(each, getDesired(trainLab[i]))\n        print(net.loss.item())\n\n\nOUTPUT:\n\n    0.2623\n    0.2546\n    0.2465\n    0.2342\n    0.2044\n    0.2518\n    0.2098\n    ...\n    0.1\n    0.1\n    0.1\n    0.1\n    0.09999\n    0.1\n    0.1\n    0.09999\n    0.09999\n    0.1\n", "link": "https://www.reddit.com/r/learnmachinelearning/comments/am8j0y/the_loss_of_my_neural_network_gets_stuck_at_01_why/"}, {"autor": "A-Walker", "date": "2019-02-01 16:50:53", "content": "Hi all, \n\nI'm building a Convolutional Neural Network and I am currently gathering training data but I've noticed that my data is a little unbalanced. I've done some research and I'm a little unsure if using the images in their current state will make my network unbalanced. I've linked my -----> image !!!  count for each class bellow, my question is, do I limit the usable -----> image !!! s to the lowest amount? Or do I upsample the data in the classes with the lowest count? Thank you in advance!\n\n&amp;#x200B;\n\n|Class|Amount of images|\n|:-|:-|\n|1|2488|\n|2|1909|\n|3|2287|\n|4|1780|\n|5|5110|\n|6|2427|\n|7|908|\n|8|875|\n\n&amp;#x200B;", "link": "https://www.reddit.com/r/learnmachinelearning/comments/am410d/training_data_help/"}, {"autor": "Blammar", "date": "2019-02-01 05:32:09", "content": "Let's assume I have a simple DL network, say based on SRCNN. (I'm specifically interested in single -----> image !!!  superresolution. I'm aware that SRCNN has been superseded with better solutions.) That could consist of say 64 out &lt;- 3 channel x 5x5 in in the first stage, a RELU, 64 out &lt;- 64 x 3 x 3 in and a RELU in the second stage, and 3 out &lt;- 64 x 3 x 3 in in the final stage.\n\nIn the above, the input is the low resolution 3 channel image. And that is the only input.\n\nPresumably the network learns features to do its work.\n\nBut I claim I already know features that should be important. Let's say I compute the gradient angle and strength (i.e., atan2(grad_y, grad_x) and sqrt(grad_x^2 + grad_y^2).) It's reasonable to assume these two numbers are useful in doing superresolution work.\n\nIf the CNN filters are actually attempting to compute something related to the above two numbers (angle, strength), then they have fewer parameters available to do the actual filtering.\n\nSo I thought it would be useful to compute, at each input pixel, the local gradient angle and strength, and also use that as input to the CNN.\n\nOh, that's how to do it. It was helpful to write this out.\n\nBasically, what I should do is add the local rotation and strength as two additional channels to the input image. Voila.\n\nDo you agree that I should just include the two additional channels?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/alysvi/adding_extra_inputs_to_a_cnn_i/"}, {"autor": "Wyvern_king", "date": "2019-07-16 22:43:36", "content": "Hi all, \n\nLike the title says I'm trying to create a basic neural network that takes in an -----> image !!!  and outputs the origin coordinates of a 2D circle in the -----> image !!!  (x, y). I know this can be done without any machine learning but this is just the starting ground for a more complex version of the project that involves determining real world coordinates of objects in an image. \n\nAt the moment I have 10000 512x512x3 training images of a single circle on a white background at random points in the image and associated CSV of the origin points of the cirlce. I was able to convert these into numpy arrays and feed them into some simple convolutional nueral nets from tutorials I had previously followed but I never got an accuracy higher than 50% during training which I always cut short because it was taking forever and not improving. \n\nI know there are plenty of pre-trained networks out there like YOLO that do object identification very well but we're trying to avoid having to manually label thousands of images. Our end goal is also to get real world coordinates of objects (ground truth) which is a bit different than what YOLO outputs. \n\nFor reference I'm using Python and keras with a tensorflow backend and am quite new to machine learning. Any help would be greatly appreciated and sorry for the long post!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ce4ap9/need_advice_with_building_and_training_a_neural/"}, {"autor": "Magniminda", "date": "2019-07-16 09:44:40", "content": " \n\n*In* order to understand the actual power of **machine learning**, you have to consider the characteristics of this technology. There are lots of examples that echo the characteristics of **machine learning** in today\u2019s data-rich world. Here are seven key characteristics of **machine learning** for which companies should prefer it over other technologies.\n\n***1- The ability to perform automated data visualization***\n\n&amp;#x200B;\n\n*A* massive amount of data is being generated by businesses and common people on a regular basis. By visualizing notable relationships in data, businesses can not only make better decisions but build confidence as well. **Machine learning** offers a number of tools that provide rich snippets of data which can be applied to both unstructured and structured data. With the help of user-friendly automated data visualization platforms in **machine learning**, businesses can obtain a wealth of new insights in an effort to increase productivity in their processes.\n\n***2- Automation at its best***\n\n&amp;#x200B;\n\n*One* of the biggest characteristics of **machine learning** is its ability to automate repetitive tasks and thus, increasing productivity. A huge number of organizations are already using **machine learning**\\-powered paperwork and email automation. In the financial sector, for example, a huge number of repetitive, data-heavy and predictable tasks are needed to be performed. Because of this, this sector uses different types of **machine learning** solutions to a great extent. The make accounting tasks faster, more insightful, and more accurate. Some aspects that have been already addressed by **machine learning** include addressing financial queries with the help of chatbots, making predictions, managing expenses, simplifying invoicing, and automating bank reconciliations.\n\n***3- Customer engagement like never before***\n\n&amp;#x200B;\n\n*For* any business, one of the most crucial ways to drive engagement, promote brand loyalty and establish long-lasting customer relationships is by triggering meaningful conversations with its target customer base. **Machine learning** plays a critical role in enabling businesses and brands to spark more valuable conversations in terms of customer engagement. The technology analyzes particular phrases, words, sentences, idioms, and content formats which resonate with certain audience members. You can think of Pinterest which is successfully using **machine learning** to personalize suggestions to its users. It uses the technology to source content in which users will be interested, based on objects which they have pinned already.\n\n***4- The ability to take efficiency to the next level when merged with IoT***\n\n&amp;#x200B;\n\n*Thanks* to the huge hype surrounding the IoT, **machine learning** has experienced a great rise in popularity. IoT is being designated as a strategically significant area by many companies. And many others have launched pilot projects to gauge the potential of IoT in the context of business operations. But attaining financial benefits through IoT isn\u2019t easy. In order to achieve success, companies, which are offering IoT consulting services and platforms, need to clearly determine the areas that will change with the implementation of IoT strategies. Many of these businesses have failed to address it. In this scenario, **machine learning** is probably the best technology that can be used to attain higher levels of efficiency. By merging **machine learning** with IoT, businesses can boost the efficiency of their entire production processes.\n\n***5- The ability to change the mortgage market***\n\n&amp;#x200B;\n\n*It\u2019s* a fact that fostering a positive credit score usually takes discipline, time, and lots of financial planning for a lot of consumers. When it comes to the lenders, the consumer credit score is one of the biggest measures of creditworthiness that involve a number of factors including payment history, total debt, length of credit history etc. But wouldn\u2019t it be great if there is a simplified and better measure? With the help of **machine learning**, lenders can now obtain a more comprehensive consumer -----> picture !!! . They can now predict whether the customer is a low spender or a high spender and understand his/her tipping point of spending. Apart from mortgage lending, financial institutions are using the same techniques for other types of consumer loans.\n\n***6- Accurate data analysis***\n\n&amp;#x200B;\n\n*Traditionally*, data analysis has always been encompassing trial and error method, an approach which becomes impossible when we are working with large and heterogeneous datasets. **Machine learning** comes as the best solution to all these issues by offering effective alternatives to analyzing massive volumes of data. By developing efficient and fast algorithms, as well as, data-driven models for processing of data in real-time, **machine learning** is able to generate accurate analysis and results.\n\n***7- Business intelligence at its best***\n\n&amp;#x200B;\n\n***Machine learning*** characteristics, when merged with big data analytical work, can generate extreme levels of business intelligence with the help of which several different industries are making strategic initiatives. From retail to financial services to healthcare, and many more \u2013 **machine learning** has already become one of the most effective technologies to boost business operations.\n\nWhether you are convinced or not, the above characteristics of **machine learning** have contributed heavily toward making it one of the most crucial technology trends \u2013 it underlies a huge number of things we use these days without even thinking about them.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cduvqk/key_characteristics_of_machine_learning/"}, {"autor": "MidThought_Pause", "date": "2019-07-14 17:43:41", "content": "I've watched a video on Reinforcement learning for python as well as an article about it, and now I'm intrigued in starting a project for it. I want to make a reinforcement learning code that solves Flow Free puzzles. In case you don't know, Flow Free is an app game where you are given a grid that's scattered with pairs of dots with different colors. You have to connect each dot with its respective color 1) without any paths intersecting another, and 2) all boxes in the grid must be occupied. Here's an [example](https://i.imgur.com/xLQXz.jpg). So, I've decided we can make a preliminary array designating 0's for empty boxes and numbers for color dots.\n\n    #####\n    unsolved_grid = [[0, 1, 2, 3, 0],\n                     [0, 0, 0, 4, 0],\n                     [0, 0, 4, 0, 0],\n                     [1, 0, 0, 5, 0],\n                     [2, 0, 5, 3, 0]]\n    #1 is yellow, 2 is blue, 3 is green, 4 is red, 5 is orange\n\nI've realized this project is going to be harder than I thought. Unlike the other path-finding algorithms that were given in the reinforcement learning tutorials that I studied, this is a \"group\" of pathfinders (one for each color), and I also have to warn each color-pathfinder to not interfere with another color-pathfinder. It's basically constraint satisfaction of multiple agents. At this point, I'm not sure if reinforcement is the best method to solve this game. \n\n&amp;#x200B;\n\nEven more [examples of solved ones.](https://faqs.neoseeker.com/Games/Android/flow_free_purple_12x12_10.png) I need to point out something in this -----> image !!! : in the very last -----> image !!!  at the bottom right (puzzle 10), you'll notice that the orange line does a bunch of unnecessary slithering before it connects with the other orange dot. It's because of the second rule that I mentioned above: all boxes must be filled up. This is going to be a problem for my puzzle,  and basically where my plans for the project fall apart. My project already has a lot of challenges, but I have no idea how to implement Hamiltonian path stuff like this. \n\n&amp;#x200B;\n\nSo I have to teach each color pathfinder agent about 3 things:\n\n* They must connect with their other color dot (simple!)\n* They must NOT cross any other pathfinder agent.\n* If the situation necessitates it, and if it's possible, I'll need one of the agents to slither a Hamiltonian path.\n\n&amp;#x200B;\n\nAlso, correct me if I'm wrong, but whenever I give it a new puzzle, isn't that a completely new environment? Doesn't that mean I have to train it all over again, or will the code retain any memory of the strategies that it used in the previous puzzle? I've looked up on the internet to see if anyone has talked about making a solving algorithm for Flow Free, and I found a stack overflow post saying that the puzzle was more appropriate with an SAT solver. I have no idea what an SAT solver is, so let's just focus on reinforcement learning. I'm curious as to whether this game is something possible for reinforcement learning. What irks me about this is that I might have to have multiple pathfinder agents, and these agents have to collaborate (in not intersecting each other, and also ensuring that all boxes are occupied.\n\nThanks.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cd5u56/reinforcement_learning_and_flow_free/"}, {"autor": "DisastrousProgrammer", "date": "2019-07-13 21:09:29", "content": "I'm working on some machine learning projects and every once in a while I get stuck and it takes a while to get unstuck. For anything involving python programming I head on over to /r/slavelabour or /r/ProgrammingTasks and get it done there within an hour. \n\nHowever, there is no such thing for very machine learning specific tasks. Someone mentioned to make it a collaborative, since there's way more value in getting better at a process with a few bucks. I decided to still pay out 5-10$ since it's my project and I'll be benefiting, but here there's no requirement to know exactly how to do it beforehand. \n\n-----\n\n### Introduction \n\nSo for this round, the task using Google Brain's Tensor2Tensor library. \n\nhttps://github.com/tensorflow/tensor2tensor\n\n\n&gt;Tensor2Tensor, or T2T for short, is a library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research. T2T is actively used and maintained by researchers and engineers within the Google Brain team and a community of users\n\n&gt; Features\n\n&gt; Many state of the art and baseline models are built-in and new models can be added easily (open an issue or pull request!).\n\n&gt; Many datasets across modalities - text, audio, -----> image !!!  - available for generation and use, and new ones can be added easily (open an issue or pull request for public datasets!).\n\n&gt; Models can be used with any dataset and input mode (or even multiple); all modality-specific processing (e.g. embedding lookups for text tokens) is done with bottom and top transformations, which are specified per-feature in the model.\n\n&gt; Support for multi-GPU machines and synchronous (1 master, many workers) and asynchronous (independent workers synchronizing through a parameter server) distributed training.\n\n&gt; Easily swap amongst datasets and models by command-line flag with the data generation script t2t-datagen and the training script t2t-trainer.\n\n&gt; Train on Google Cloud ML and Cloud TPUs.\n\nIt is used in industry and was used in the following papers\n\n&gt; Attention Is All You Need\n\n&gt; Depthwise Separable Convolutions for Neural Machine Translation\n\n&gt; One Model To Learn Them All\n\n&gt; Discrete Autoencoders for Sequence Models\n\n&gt; Generating Wikipedia by Summarizing Long Sequences\n\n&gt; Image Transformer\n\n&gt; Training Tips for the Transformer Model\n\n&gt; Self-Attention with Relative Position Representations\n\n&gt; Fast Decoding in Sequence Models using Discrete Latent Variables\n\n&gt; Adafactor: Adaptive Learning Rates with Sublinear Memory Cost\n\n&gt; Universal Transformers\n\n&gt; Attending to Mathematical Language with Transformers\n\n&gt; The Evolved Transformer\n\n&gt; Model-Based Reinforcement Learning for Atari\n\n&gt; VideoFlow: A Flow-Based Generative Model for Video\n\n-----\n\n### Task\n\nThe specific task is we are doing summarization training over a new dataset. They have instructions on how to do summarization training on a few datasets here\n\nhttps://github.com/tensorflow/tensor2tensor#summarization\n\nBut adding a new dataset isn't as straightforward, especially if the new dataset has a different data format\n\nhttps://github.com/tensorflow/tensor2tensor#adding-a-dataset\n\n----\n\n### Participation &amp; Payment\n\nThis is tricky for me to figure out. I initially wanted to pay out 5-10$ to whoever figured out the task. But I was also thinking of accepting whoever wants to participate to join. I was thinking when the task is figured out, anyone who made a contribution no matter how small will get to vote on who gets to have the 5$, and I'll give it to whoever gets the most votes. Or if anyone has any other suggestions lmk.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ccuj6d/anyone_interested_in_learning_use_machine/"}, {"autor": "nisucuk", "date": "2019-07-13 17:02:23", "content": " \n\nI am trying to solve a  multi-label classification problem using pretrained resnet152 .  \nMy training -----> image !!!  have  variable number of labels. There are total of 5528 labels available.I  created train and valid datagenerator with class\\_mode='categorical.'  \nthe result was :  \nFound 5669 validated image filenames belonging to 5528 classes.  \n In the final layer of model creating,  \nmodel.add(Dense(5528,activation='sigmoid').  \nIf I am not wrong, THis  can give variable number of labels.  \nI want to have upto  maximum of 100 labels per image .  I want to know how is it possible?  \nI want to print my labels according to highest order of their probabilities. Please  guide me.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ccrm9w/how_to_solve_this_probelm_of_multi_label/"}, {"autor": "averyconfusedperson", "date": "2019-07-13 14:48:17", "content": "Hello,\n\nI  am very new to ML and I'm just trying to do a personal project for  classifying images. I'm specifically trying build an -----> image !!!  data set for  classifying different mangoes.\n\nIs there any paper, book or other resource that describes best practice for preparing an image data set?\n\nI'm kinda following small guides on online. I was using an approach like this:  \n[https://medium.com/@sangho/how-to-build-a-image-recogniser-using-your-own-dataset-22bb9f806e1d](https://medium.com/@sangho/how-to-build-a-image-recogniser-using-your-own-dataset-22bb9f806e1d)\n\n&amp;#x200B;\n\nThis  is ok for me equipment wise as I only have my phone to take pictures.  And taking video is actually a quick way to capture many images.\n\nI  understand this is probably an over simplified example. But is it  reasonable to use still frames from videos? In this example this person  is using 1 frame every second from a video but I noticed while doing  this myself many frames look almost identical. Would that be a problem?\n\nSome other questions I have:\n\nI  have several types of mangoes and lets say I'm gathering images of one  type. Should I include several images of each individual from different  angles? Or should I try for images of several individuals of the same  type?\n\nShould I be changing the backgrounds of the objects?\n\nI am mostly trying to focus on building a good data set that I can use for testing on different neural nets.\n\n&amp;#x200B;\n\nI asked this over at r/MLQuestions as well.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ccq4wd/what_are_best_practices_for_building_an_image/"}, {"autor": "IRcrazzyyy", "date": "2019-07-12 23:39:44", "content": "I've found a decent amount of articles talking about different methods and techniques for training a model to be able to remove or reconstruct an -----> image !!!  with less noise/grainy-ness but was unsure as to how to get started myself.  \n\nIf it helps, the images I am working with are a set of X-Ray scans that experience a fairly high amount of salt and pepper noise that I would like to remove.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ccietf/looking_for_introtutorial_on_how_to_reduce_noise/"}, {"autor": "ankit603996", "date": "2019-06-25 18:44:06", "content": "Currently, analytics, data science, machine learning, artificial intelligence cover a major portion of a presentation in any company's strategic planning. Be it marketing, finance, supply chain or HR every department consumes analytics in the form of AI and ML. Even after so much of research work, analytics is still a cost center for many of these departments but among all, marketing is actually one of the functions where ML is actually turning department as a profit center.\n\nThere are millions of articles and reports which talk about how companies are planning to leverage AI/ML but all those talks find a place in PPTs and annual reports. For a non-data scientist or fresher, it is still a grey area. Almost all of you have heard some buzz as in data science is helping marketing but how? and which algorithms are actually being used. In this article, I would largely touch upon data science techniques and ML methods that are being implemented through r/Python/SPSS/SAS in daily to daily basis. But before going into details of use cases Lets understand some basics metrics that are required to improve through data science.\n\nBefore that let's understand the focus areas of marketing in a few lines.\n\n1. First of all, we need to understand our products, competitors and markets i.e. SWOT analysis: What and How much and where to sell?\n2. Decide your target customer base: Whom to sell?\n3. Create a communication strategy to reach customers via various communication channels: How to sell?\n4. Analyze Response and convert them into the purchase.\n5. NOW, WHAT? Don't worry Next time target them for another product (cross/up-sell) :)\n\nThis whole journey of a customer is called a funnel where funnel starts from customer identification and ends at final purchase. i.e.\n\n**Product awareness (Communication)** **-----  User Response** \\----- **Lead Generation** \\---- **Lead Evaluation** \\---- **Sell**\n\n&amp;#x200B;\n\n[Marketing Funnel](https://i.redd.it/rkc3nkulqj631.jpg)\n\nAgain coming to the basics, performance/KPI of an overall funnel (i.e. overall funnel ratio) can be defined as\n\nIn terms of cost:  (Final Sales)/(Cost of Acquisition)\n\nIn terms of Conversion ratio :  (Final converted numbers)/(Total customer entered into the funnel )\n\nIf I were analytics head of marketing department I would definitely decompose the funnel, focus upon components of this funnel ratio and understand performance KPIs of each integral stages. As per my understanding, this can be simplified as:\n\n**Overall Funnel Ratio/Overall Performance** = (Performance at stage\\_1) \\* (Performance at stage\\_2)\\*(Performance at stage\\_3)\\*(Performance at stage\\_4)\n\ni.e.\n\n**Funnel Ratio** = (User Response/ Sent Communication Items) \\* (Total Leads/ Total Response) \\* (Qualifying Leads/ Leads)\\*(Conversion /Total Qualifying Leads)\n\nTo Introduce Data Science and Analytics into each stage, we need to understand each funnel ratio in detail because KPIs for each funnel heavily depends upon activities in the funnel.\n\n**STAGE 1:** ***Total user response out of Total Advertisement Units.***\n\nThe very first step of marketing after target base identification is campaigning. The success of the campaign lies in how many users are responding to your campaign. The response is nothing but whether a customer has seen our advertisement or whether he has responded our communication through either view or click.\n\nFurther, advertisement units vary for communication channel such as Total Number of Emailers, Total SMSs, Total facebook Impressions, Total Views in Browser Push Notifications, etc. Hence KPIs for each channel also differ.\n\nFor EMAIL we measure Open Rate, Click Rate; For Browser Notification, we check view rate, click rate; For FB campaign we measure clicks per impressions; For youtube, we check total clicks per view.\n\nIn 2018, The average click-through rate in Google Ads across all industries is 3.17% on the search network and 0.46% on the display network. For EMAIL Open rate across all industries varies from 15- 24% and CTR varies from 1.5-3.25%.\n\nHere how analytics and ML help in the improvement of KPIs:\n\n**Effective Audience Selection :**\n\nProduct Propensity: It is applied once we have identified \"What to Sell\". An ML classification model (Bagging, Boosting or Linear Classifier) helps to identify a hot customer for any product. We can develop an individual binary classification model for all product or We can develop a single multiclass classification model for all products. The output of this model is a probability score for each product against each customer.\n\nRecommendation Engine: It is mostly applied to our existing base customers to promote cross-sell and upsell. We can use association rule mining as well as collaborative filtering to rank products for customers. Ex: Customer A bought product 1 and 2 hence we can also pitch him a product 3.\n\nCLT Value analysis: Customer Lifetime value analysis identifies the total value of a customer that he can bring to the company. It helps a marketer to decide whom he should send promotional offers. This, in turn, reduces the cost of promotions.  We can use either average revenue per month or derive propensity of a customer being alive using Beta-geometric binomial model alternatively gamma-gamma model.\n\n**Effective Channel Selection:** It comes into the -----> picture !!! , once we have identified \" Whom to sell and What to Sell\". An ML classification model helps to derive probability scores (probability to respond) for any customer across all channels. Thus, we can prioritize channels for all customers. Say: for customer A, the probability of response to email is higher than on FB.\n\n**Effective Content Design:** Natural Language Processing serves the best when it comes to content analysis and content design.\n\nAnalysis of Key Components in communication Message: Collect historical data of responded and non-responded users along with communication content. create a\u00a0classification ML model\u00a0(preferably logistic regression) which will provide the important parts of communication content that influence users to the response. Ex: Should we mention the interest rate in the subject line or not?. Sometimes a basic term-frequency analysis can give us a root cause. e.g. how many times long subject lines have increased/decreased Open Rate.\n\nPlacement of Contents in mailers: A basic exploratory analysis on email performance data would be sufficient for the same. Data must contain email response and properties of emails.\n\n**STAGE 2:** ***Total leads out of Total response.***\n\nMostly Leads are captured through \"Fill the forms\", \"Click or Know more\", \"Apply through Chatbots\" OR \"Direct calling\" based on customer footprint. In some cases, his response (say click on notification/view) is counted as a lead but most of the times, this view/click is not enough, his lead is counted only after filling a lead/application form. In many such cases, though people click on an ad, but whenever they are asked to submit a form they back out. Say in an email campaign there are many instances where he/she opens mailer and clicks on mail content but after redirecting to company page he decides not to go further. This is a loss of a lead. In the marketing world, it may be referred to as \"Lead Leakage\" or \"Lead Drop\".\n\nAnalysis of Lead Drop is crucial as it indicates the look-alike feels of our application form or content reliability of arrival page.\n\nHow a data scientist can help here:\n\nLead Propensity Model: A classification ML model can identify potential customers who are likely to submit the lead form. Lead propensity model differs from product propensity models in independent variables selection. Lead propensity model takes arrival page 'look n feel' attributes into model building.\n\nLeads through Chat Bot: Chatbot might be a smart agent but not enough smart till date to understand the mood of the customer. This mood should be captured to make chatbot more smart and interactive. Currently, the best deep learning models which are being used are seq2seq recurrent neural networks.\n\nSeq2seq networks usually contain two LSTM (Long Short term memory): an encoder and a decoder. As the name suggests they take a sequence (context sentence) and produce another sequence (output sentence/machine response). Previous chat history is a feed for LSTM.\n\nForm\\_Analytics: A form requires visitors to enter one of many fields (name, age, city, mobile, salary) as information. Structure of form, misalignment of campaign-content and form-content provokes visitors to drop off the form. With form analytics, we can figure out how many leads are lost from the start of the form till the bottom end of the form i.e. drop of leads through any field w.r.t. previous fields. Although predictive modeling has not gained much scope in form\\_analytics, a/b testing around it works well\n\n**STAGE 3:** ***Total qualifying leads out of Total Submitted leads.***\n\nA marketing Qualified Lead (MQL) is the one who has shown interest voluntarily\u00a0to purchase your product. The concept came into light when unwanted leads were captured just to justify the effectiveness of the campaign. Criteria for MQL depends upon business to business as well as product to product. For E-com MQL may be just a non-duplicate customer-intent for the same product but for loan products MQL covers their CIBIL/Income etc also.\n\nCompanies usually define criteria by themselves for MQL but sometimes they are also unaware which leads can be turned into the final purchase and which leads are worthless to focus. Here data science helps businesses identifying non-measurable behavior of good leads.\n\nLead Potential: A classification ML model (logistic regression) can take attributes like website activities, RFM parameters, etc and predict whether this lead has the potential to convert or not.\n\nFraudulent Leads: Another application of logistic regression here is to detect fraudulent leads. The fraud detection system can be kept offline or it can be integrated into a live production system.\n\nRecommendation Engine: Online commercial sites are now using a recommendation engine to influence non-potential leads to hot leads. Apart from product recommendation Natural language processing with the help of social media provides brand-customer sentiments and influence visitors to get a customer.\n\n**STAGE 4:** ***Total conversions out of Total Qualifying Leads***\n\nProcesses, after MQL identification, are generally taken care of by the operations team. In Loan providers, field representative visit to Qualified lead customers for remaining formalities, same case for Real State and automobiles. For online stores, It is a web developer, who is responsible for a smooth check out procedure.\n\nIntelligent Document Verification: Document NLP is a strong tool but it is in its beginning stage. Its use is very niche though some companies use deep learning to perform image processing for online document verification.\n\n**Conclusion:** A data scientist surely plays a vital role to make this complete funnel as an intelligent and sharp but his number crunching is still not sufficient. He also has to have an in-depth understanding of \"how to do marketing\".", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c5d4sj/game_of_numbers_intellegent_marketing_funnel/"}, {"autor": "NoTechBackground", "date": "2019-06-25 14:34:59", "content": " [https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer](https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer) \n\n&amp;#x200B;\n\n### How can I obtain the output of an intermediate layer?\n\nOne simple way is to create a new Model  \n that will output the layers that you are interested in:\n\n    from keras.models import Model  model = ...  # create the original model  layer_name = 'my_layer' intermediate_layer_model = Model(inputs=model.input,                                  outputs=model.get_layer(layer_name).output) intermediate_output = intermediate_layer_model.predict(data) \n\nAlternatively, you can build a Keras function that will return the output of a certain layer given a certain input, for example:\n\n    from keras import backend as K  # with a Sequential model get_3rd_layer_output = K.function([model.layers[0].input],                                   [model.layers[3].output]) layer_output = get_3rd_layer_output([x])[0] \n\nSimilarly, you could build a Theano and TensorFlow function directly.\n\nNote that if your model has a different behavior in training and testing phase (e.g. if it uses Dropout  \n, BatchNormalization  \n, etc.), you will need to pass the learning phase flag to your function:\n\n    get_3rd_layer_output = K.function([model.layers[0].input, K.learning_phase()],                                   [model.layers[3].output])  # output in test mode = 0 layer_output = get_3rd_layer_output([x, 0])[0]  # output in train mode = 1 layer_output = get_3rd_layer_output([x, 1])[0] \n\n---\n\n1. For the second box with code, doesn't the code need to know what the testing data is or at least have one -----> image !!!  to input to do any intermediate visualization? The first box specifies 'data' to put in, but the second box just uses model.layers\\[0\\].input, and I'm not sure what model.layers\\[0\\].input means. We haven't put in any input, but is the model somehow saving inputs used during training?\n\n&amp;#x200B;\n\n2. If the first box required model.input and .predict(data) , then conceptually, why doesn't the second one? Where are we making up the lacking information?\n\n&amp;#x200B;\n\n3. In the below code, conceptually, what is the \\[0\\] doing and what are the 0 and 1 doing in \\[x, 0\\] and \\[x, 1\\]? Are the 0 and 1 in \\[x, 0\\] and \\[x, 1\\]  implied as booleans? \n\n \n\n    # output in test mode = 0 layer_output = get_3rd_layer_output([x, 0])[0]  # output in train mode = 1 layer_output = get_3rd_layer_output([x, 1])[0]", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c59gp1/why_does_the_function_method_of_obtaining_the/"}, {"autor": "dmdmello", "date": "2019-06-25 13:36:30", "content": " \n\nOverfitting is usually associated with high variance, whereas  underfitting is associated with high bias. But one of my professors at  uni mentioned that overfitting might be caused by high variance and/or  bias. I'm trying to understand how it is possible that it might be  caused by bias. \n\nSomeone pointed me out an example, and I don't know if its correct.  Let's say that we train a model to classify between pictures of old and  young people in a data set where all old people aren't smiling and all  young people are smiling. And then the model, instead of predicting  features that would actually discriminate between young and old, would  learn to classify the two solely by taking into account the presence of a  smile. So, during the test phase, if we where to show the model a  -----> picture !!!  of someone young not smiling, it would predict an old person. Would this case be an overfitting due to high bias? The model not being  able to maintain a more flexible classification zone and take into  account the variance of other features in the data?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c58nys/is_it_possible_to_have_overfitting_due_to_high/"}, {"autor": "chiborevo", "date": "2019-06-24 14:53:48", "content": "What is the best way I can extract the colors or color palette of an -----> image !!! ?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c4p80o/image_colorpalette/"}, {"autor": "Laser_Plasma", "date": "2019-06-24 10:57:01", "content": "Is there an established way of getting the certainty of a model? E.g. for a cat-dog classifier, it'd be able to say it's about 70% sure that the -----> picture !!!  has a cat. \n\nI don't think just looking at the sigmoid output works, it doesn't exactly have an interpretation like this.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c4lnp2/estimating_models_certainty_about_the_output/"}, {"autor": "harsh_sagar", "date": "2019-06-24 06:57:11", "content": "Hi Everyone!\n\nI    am sharing the GitHub link to my project '-----> Image !!!  Classification on  Fashion-MNIST dataset using CNN' . I have tried to write a well  commented code, so that   anyone can learn from it. I have also added  some presentation slides for better understanding.\n\nThe project is done on Fashion-Mnist dataset  which can be downloaded from Kaggle.\n\n[https://github.com/harshgarg27/LastAssignment\\_DeepLeraning\\_CNN\\_Classification](https://github.com/harshgarg27/LastAssignment_DeepLeraning_CNN_Classification)\n\nFeel free to give suggestions and reviews.\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c4jhc8/deep_learning_project/"}, {"autor": "chiborevo", "date": "2019-06-23 03:44:57", "content": "Hi, I want to know how I can suggest or predict a Music Playlist based on mood or -----> image !!!  of a place\n\ni.e:\nsad -&gt; some process to suggest/predict - music playlist\nplace -&gt; some process -&gt; music playlist\n\nis there any algorithm I can use", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c3yre1/suggestionprediction_music_playlist/"}, {"autor": "Laurence-Lin", "date": "2019-06-22 13:46:51", "content": "I'm not sure if it's proper to ask this kind of question, I've change the question if it's inappropriate.\n\n&amp;#x200B;\n\nI've studied mechanical engineering in college and master, and start to learn python during master degree. I found that I'm interesting in ML afterward and start to learn, now I've learned using NN, CNN, LSTM, KNN, logistic regression to do tasks, and I've done some tasks like: -----> image !!!  classification, time series forecasting.   \n\n\nI've searched online and found that to become a data scientist I've to be expert in Big Data, SQL, ML and DL  models, data mining...etc, and I've list the stuff I'm going to learn, and I've found it's really much. \n\n&amp;#x200B;\n\nFor example, I haven't done NLP tasks before, and I found that NLP contains tokenization, stemming, name entity recognition... etc,  a lot kinds of different problem, and I'm afraid if I want to be master of all these problem, it'll cost me too much time until I could find a job.   \n\n\nI know being an ML engineer or AI engineer requires specialization in various ML algorithm, data preprocessing, and database. But I would like to ask is there a list of necessary methods in order to become an ML engineer?  \n\n\nAny advice is appreciated, thanks a lot!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c3pvrc/if_i_want_to_get_an_ml_job_what_is_the_essential/"}, {"autor": "dimark03", "date": "2019-06-21 17:23:11", "content": "I am having a lot of trouble understanding the behaviour of my model and need some help to try figure it out.  \nSuppose this Autoencoder consisting of all convolution layers:\n\n\n    initializer = he_uniform()\n\n    #Input\n    input_tensor_a = Input(shape=(128,128,3))\n\n    #Encoder\n    conv1 = Conv2D(64, kernel_size=7, padding='same', kernel_initializer=initializer)(input_tensor_a)\n    bn1 = BatchNormalization()(conv1)\n    relu1 = Activation('relu')(bn1)\n\n    conv2 = Conv2D(128, kernel_size=3, strides=2, padding='same', kernel_initializer=initializer)(relu1)\n    bn2 = BatchNormalization()(conv2)\n    relu2 = Activation('relu')(bn2)\n\n    ... (two more of those block)\n\n\n    #Decoder\n    ups1 = UpSampling2D(size=(2,2))(relu4)\n    up_conv1 = Conv2D(256, kernel_size=3, padding='same', kernel_initializer=initializer)(ups1)\n    bn5 = BatchNormalization()(up_conv1)\n    relu5 = Activation('relu')(bn5)\n\n    ... (two more of those blocks)\n\n    output = Conv2D(3, kernel_size=7, padding='same', activation='tanh', kernel_initializer=glorot_uniform())(relu7)\n\n\nI know this architecture might not be very good, but I just want to understand the behaviour of it.    \n  \n\nThe following keeps happening:  \n    \n  \nThis is the input Image:  (https://i.imgur.com/d2B9vfJ.png)\n\nThis is the -----> image !!!  after the first 5 epochs:  (https://i.imgur.com/WHKjdxo.png)  \n  \nAnd now after some more epochs:  (https://i.imgur.com/zxoa7zW.png)  \n  \n\nAs you can see the the Model pushes the output -----> image !!!  further and further to a blank -----> image !!!  until at the end it is going to be a full white blank -----> image !!! .  \n  The loss starts off at around 25000 and will decrease very slowly until like 24000 and then is stuck there (which is probably the blank image state)\n  \nI have tried different learning rates, switching bn and relu layer, different loss function than 'mse', with and without kernel_initializer but nothing helps.  \nSo I assume it has to do with the arcitecture, but I dont understand why.  \n  \nIf anyone could give me a good explanation I would be very grateful.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c3dj6z/can_someone_help_me_understand_why_this/"}, {"autor": "FreddyShrimp", "date": "2019-03-14 08:13:49", "content": "I would like to create my own -----> image !!!  classifier in tensorflow.\n\nFor this I would love to have the my\\_images.train.next\\_batch(batch\\_size)  \nin place.\n\nTensorflow provides this for the MNIST dataset, but doens't explain how you can do this for your own images. Can someone push me in the right direction?\n\nI have looked at the [tensorflow documentation on github](https://github.com/tensorflow/tensorflow/blob/7c36309c37b04843030664cdc64aca2bb7d6ecaa/tensorflow/contrib/learn/python/learn/datasets/mnist.py#L160) but I'm not making so much sense out of it right now.\n\nIdeally I'd like to train a network on images of objects, instead of just MNIST digits\n\nThanks for the help!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b0xpxd/create_a_dataset_class_for_own_image_dataset_like/"}, {"autor": "FreddyShrimp", "date": "2019-03-13 20:48:59", "content": "I would like to create my own -----> image !!!  classifier in tensorflow. \n\nFor this I would love to have the `my_images.train.next_batch(batch_size)` in place.\n\nTensorflow provides this for the MNIST dataset, but doens't explain how you can do this for your own images. Can someone push me in the right direction? \n\nI have looked at the [tensorflow documentation on github](https://github.com/tensorflow/tensorflow/blob/7c36309c37b04843030664cdc64aca2bb7d6ecaa/tensorflow/contrib/learn/python/learn/datasets/mnist.py#L160) but I'm not making so much sense out of it right now.\n\n&amp;#x200B;\n\nThanks for the help!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b0r5bs/tensorflow_next_batch_like_mnist_dataset/"}, {"autor": "ganeshdeshmukh", "date": "2019-03-13 07:15:44", "content": "[documentation](https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00)\n\nI can't follow steps in the documentation, I am using tesseract in real-time to recognize OCR printed text/ Optical Character Recognition. \n\nBut I wanted to extend it further to Handwritten character recognition. \n\ncurrently, the new version of Tesseract doesn't recognize HCR. but it says we can do it after training dataset?\n\nI know there are many other ways for the same, but I have to learn Neural-Networks for it, and I would need a faster machine. \n\nmy GitHub repo is \"[https://github.com/ganesh-deshmukh/cvkeyboard](https://github.com/ganesh-deshmukh/cvkeyboard)\"\n\n&amp;#x200B;\n\nI tried using tensorflow, but I can't pass -----> image !!!  correctly so it gave wrong prediction, as this repo '[https://github.com/ganesh-deshmukh/Google-colab-hcr/blob/master/demoHCR.ipynb](https://github.com/ganesh-deshmukh/Google-colab-hcr/blob/master/demoHCR.ipynb)'\n\n&amp;#x200B;\n\nwhat would be a simple approach for same? ", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b0j2oq/requesthow_to_train_tesseract_for_handwriting/"}, {"autor": "-Ulkurz-", "date": "2019-03-12 16:32:40", "content": "I want to learn CNNs. I've very limited idea about neural networks and I want to develop some understanding starting with CNNs, mainly because it's widely used in computer vision. I'd be great to learn by not only understanding the concepts but also working out a practical example (like -----> image !!!  classification). \n\nThere are so many blogs out there, not sure which one covers the topics thoroughly. Any help is appreciated.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b09tl5/how_to_learn_about_cnns_thoroughly/"}, {"autor": "ragnarkar", "date": "2019-03-12 03:04:30", "content": "I'm not sure if this belongs in a Math/Stats subreddit but the context is ML, so here it goes:\n\nSuppose I've trained 2 Machine Learning models for Handwriting Recognition:\n\n- Model 1: recognizes each of the 26 letters of the alphabet (trained on a dataset like EMNIST)\n\n- Model 2: recognizes all possible 2 letter sequences from an -----> image !!!  (i.e. Va, Qu, Ag, etc.)\n\nIs there any way I can combine the two models to make a more accurate prediction using, say, Bayes's theorem?\n\nExample:  Let's say I write the letter \"G\" on a piece of paper then write the letter \"O\" next to the G.  I pass each letter to Model 1.  And I pass the combined 2 letters to Model 2.\n\nFor the first letter, Model 1 will output a 26-dimensional vector indicating the probability that the first letter is each of the 26 letters (with a peak at G hopefully.)  And for the second letter, a peak near O hopefully.\n\nModel 2 will output a 676 dimensional vector, hopefully a peak at \"GO\" although smaller peaks may exist at, say, \"GD\", \"GQ\", etc.\n\nLet P(G) = the probability that the first letter is G\n\nLet P(O) = the probability that the 2nd letter is O\n\nLet P(GO) = the probability that the first letter is G AND the 2nd letter is O.\n\nAccording to Bayes's theorem:\n\nP(G) = P(G | O)*P(O) / P(O | G)\n\nand P(O) = P(O | G)*P(G) / (P | O)\n\nAnd P(G | O)*P(O) = P(O | G)*P(G) = P(GO)\n\nAnd P(G | O) and P(O | G) can be found by looking up the frequency tables found here:\n\nhttp://homepages.math.uic.edu/~leon/mcs425-s08/handouts/char_freq2.pdf\n\nLet's say that Model 1 and Model 2 are fairly accurate, both have an accuracy of about 90% but are not perfect.  Is it possible to use Bayes's rule in this case to combine both of these models in order to make a more accurate prediction, in other words, using Model 2 to (hopefully) glean more new information to help make a more accurate prediction after already making a prediction using Model 1?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b02peh/using_bayesian_thinking_to_combine_the/"}, {"autor": "PetorianBlue", "date": "2019-03-11 16:00:02", "content": "Following Andrew Ng's course, he discusses using convolutions instead of sliding windows.  Conceptually, this makes sense to me, but how do you train the model?\n\nOrdinarily, with a sliding window I can train the model on a batch of positive and negative -----> image !!! s and then when I apply the model, each window is just a instance of this same -----> image !!!  size.  But with the convolutional technique, the input is the entire large image and the output is a tensor of probabilities.\n\nSo for training data, do I have to annotate my large images in this same \"grid-like\" manner?  Do I have to provide the tensor of probabilities for each large image rather than the dataset of individual \"windows\" I already have?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/azv3kp/how_to_train_convolutional_implementation_of/"}, {"autor": "guyi567", "date": "2019-03-09 14:13:57", "content": "Some background: I've finished Andrew Ng's course on Coursera, MIT 6.001x, Michael Nielsen's book on neural networks and deep learning, and I'm really comfortable with Python, I've coded neural networks from scratch as well as Tensorflow for CNN's and -----> image !!!  classification.\n\nFor the most part, I've been learning algorithms on the surface level, just seeing the cost function, hypothesis and coding it. But I want to learn ML on a deeper level now and I have a lot of time on my hand.\n\nAny suggestions for books or other resources?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/az3vs7/i_want_to_learn_ml_on_a_deeper_level_where_do_i/"}, {"autor": "SylwiaOliwia", "date": "2019-11-03 19:00:32", "content": "I've seen several AI competitions (ex. [Humpback Whale Identification Challenge](https://www.kaggle.com/c/whale-categorization-playground), [Planet: Understanding the Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space)), which aim to label animal species/ components of nature. But do you know **any research papers that use images labeled by AI** which prove a hypothesis about the species biology/habitat?\n\nI thought that AI can improve research in animal biology, ex. speed up labeling images from the -----> camera !!!  traps. On the other hand, it's suspicious, that I haven't found any biology research paper using it already.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dr4wru/do_you_know_any_biology_research_papers_that_use/"}, {"autor": "pe-ter06", "date": "2019-11-03 09:57:29", "content": "Hello,\n\nMy GAN is generating very bright red and yellow images and it seems to be producing gibberish. I wanted to show you my architecture so that you can judge whether there are some obvious mistakes to it. I'd appreciate any feedback.\n\n**Generator:**\n\n    nn.ConvTranspose2d(1, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.ConvTranspose2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.ConvTranspose2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.ConvTranspose2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.ConvTranspose2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.ConvTranspose2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.ConvTranspose2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.ConvTranspose2d(128, 3, 5),\n    \n    nn.Tanh()\n\nDiscriminator:\n\n    nn.Conv2d(3, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.Conv2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.Conv2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.Conv2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.Conv2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.Conv2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),\n    \n    nn.Conv2d(128, 128, 5),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(inplace=True),                                    \n    \n    nn.Conv2d(128, 1, 5),\n    \n    (here I flatten the -----> image !!!  on dim=1, where dim=0 is the batch size, dim=1 is the channel size)\n    \n    nn.Linear(1024, 6),\n    nn.Softmax(dim=1)\n\nI seem to be getting very bright red/yellow/white colors. As if the Generator had trouble properly mixing channels in order to achieve realistic colors.\n\nI am unsure what's going on, I'd really appreciate any help.\n\nThank you.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dqycti/could_i_get_your_feedback_on_my_gan_architecture/"}, {"autor": "Scribbio", "date": "2019-11-03 02:09:54", "content": "I would love some additional help understanding the hidden layers of neural networks.\n\nI\u2019ve read that each of the neurons of the hidden layers will relate to various features from the given data set.\n\nDuring and after training, activated neurons combine to form an appropriate output from a given input.\n\nIn the case of -----> image !!!  recognition, these features might be a curve or an edge in a particular region of the -----> image !!! .\n\n*Processing img m3tqvlshndw31...*\n\nSource: [But what is a Neural Network? (3Blue1Brown)](https://www.youtube.com/watch?v=aircAruvnKk&amp;t=570s)\n\nWhat I can\u2019t wrap my head is how those features are distributed \u2013 what exactly is the mechanism (high-level) deciding which features to extract?\n\nIs it just arbitrarily breaking down the images of the data set randomly and spreading it across all the neurons of the hidden layers?\n\nI would therefore suspect that the number of hidden layers is also therefore determined by this process.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dqubfs/how_does_the_distribution_of_features_in_the/"}, {"autor": "b9a4c81f36", "date": "2019-11-02 20:03:08", "content": "I am currently doing semantic segmentation on a medical dataset with the UNet and I have a question regarding the input masks.\n\nI have 3 classes (background, liver, tumour) and these classes are currently labeled as:\nbackground=(0,0,0), liver=(255,0,0) and tumour=(0,0,255). Are these classes labeled correctly or do I have change something?\n\nThe model input is (batch_size, width, height, 3) for the scans and masks\n\nThe model output is a softmax and  returns an -----> image !!!   (width, height, 3)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dqpkit/question_on_mask_for_semantic_segmentation/"}, {"autor": "arjundupa", "date": "2019-11-01 03:55:31", "content": "I have a pre-trained caffe model for scene recognition. I'd like to find an input -----> image !!!  which maximally activates one of the output classes.\n\nThe idea is: start with a randomly initialized input image (noise), feed this into the the pre-trained network, see what the probability distribution with respect to each class is (the output of feeding the this input into the network), and then minimize the loss between this output and the desired output (in this case, the desired output would be the one-hot vector corresponding to which class you're looking for).\n\nI am very new to Caffe -- any ideas / pointers as to how I can go about getting started with this?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dpz4wh/caffe_train_input_with_pretrained_network/"}, {"autor": "xx_stark_xx", "date": "2019-10-31 03:46:47", "content": "I want to extract information from xerox of ID cards.\nHere\u2019s how I have divided it into two parts:\n1. -----> Image !!!  classification to classify the different ID cards,\n2. Information extraction.\n\n\nI want to know what techniques and methods I would need to apply, from very basic to advanced, I want to go step by step. Also, what pre processing is needed? Also, study material i can refer to. \n\nThanks in advance!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dpi3zk/first_image_processing_project/"}, {"autor": "Unchart3disOP", "date": "2019-10-30 19:07:07", "content": "Hello guys,\nI have this idea for a project I want to implement which basically takes an X-Ray -----> image !!!  and classifies which disease this pearson has, I am using the ChexNet architecture for my end-to-end network but I feel like this project would just be abit too small. I was thinking about making a 3D model that would show the shape of the Chest to the user, but I feel like its not really beneficial. I also thought about using image processing to remove any noise and for segmentation and hopefully get more accurate results. What do you guys think I should add for this project. Also a thing to note is It doesnt really matter how hard this project would get, I kinda want to learn as much as I can and an end-to-end neural net would just feel very shallow in terms of the learning experience", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dpb6n4/can_you_help_me_expand_this_project_idea/"}, {"autor": "pe-ter06", "date": "2019-10-30 17:47:45", "content": "In every single post I read people always talk about GANs getting their input from a point in a latent space vector, a latent vector. I have never seen a simple example of implementing it in code and I don't understand this particular terminology. I scouted the web for a while and I feel more stupid than I probably am at this point. Different posts provide different explanations.\n\nI am trying to develop a GAN using two CNNs. Everything was perfectly clear to me until I had to give the generator any input. From what I understand it has to be a point sampled from a Gaussian distribution. How do I represent that in code as input to the Generator though?\n\nCan I just create an -----> image !!!  made up of a Gaussian noise and do a Transpose Convolution on it until it produces some kind of output? Is it supposed to be a single-dimensional array that is passed via a Fully Connected layer? I have no clue how to solve it. Currently I am trying the first option, the input has the shape of (batch\\_size, 1, 32, 32) and this is Transposed into a 32x32 image that is then judged by the discriminator.\n\nAm I doing this right?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dpa34f/question_this_is_something_i_dont_understand/"}, {"autor": "dbx00", "date": "2019-06-08 15:31:33", "content": "I have some limited experience with MLPs and CNNs. I am working on a project where I've used a CNN to classify \"images\" into two classes, 0 and 1. I say \"-----> image !!! s\" as they are not actually -----> image !!! s in the traditional sense, rather we are encoding a string from a limited alphabet, such that each character has a one-hot encoded row in the \"-----> image !!! \". For example, we are using this for a bioinformatics application, so with the alphabet {A, C, G, T} the sequence \"ACGTCCAGCTACTTTACGG\" would be:\n\n&amp;#x200B;\n\nhttps://i.redd.it/8mv0ml7ac5331.png\n\nAll \"images\" are 4x26. I used a CNN to classify pairs of \"images\" (either using two channels, i.e. 2x4x26 or concatenating two representations as 8x46) according to our criteria with good results. The main idea is for the network to learn how 2 sequences interact, so there are particular patterns that make sense. If we want to detect a reverse complement for example, then the network should learn that A-T and G-C pairs are important. For this particular example, if the interaction is high/probable, the assigned label is 1, otherwise 0.\n\n&amp;#x200B;\n\nHowever, now my supervisor wants to go one step further and have a model that is able to generate \"images\" (sequences) that respect the same constraints as the classification problem. To solve this, I looked at Generative Adversarial Networks as the tool to perform the generation, thinking that maybe I could adapt the model from the classification to work as the discriminator. I've looked at the \"simpler\" models such as [DCGAN](https://arxiv.org/abs/1511.06434) and [GAN](https://arxiv.org/abs/1406.2661), with implementations from [https://github.com/eriklindernoren/Keras-GAN](https://github.com/eriklindernoren/Keras-GAN), as I've never studied or used a GAN before.\n\n&amp;#x200B;\n\nSay that we want to generate pairs that are supposed to interact, or with the label 1 from before. I've adapted the DCGAN model to train on our 1-labelled encodings and tried different variations for the discriminator and generator, keeping in mind rules of thumb for stability. However, I can't get the model to learn anything significant. For example, I am trying to make the network learn the simple concept of reverse complement, mentioned above (expectation: learn to produce a pair with high interaction, from noise). Initially the accuracy for the discriminator is low, but after a few thousand epochs it increases drastically (very close to 100%, and the generator loss is huge, which apparently is a good thing, as the two models \"compete\" against each other?). However, the generated samples do not make any sense.\n\n&amp;#x200B;\n\nI suspect that the generator learns the one-hot encoding above - since early generator output is just noise, it probably learns something like \"a single 1 per column is good\", but not the more high level relation between the 1s and 0s. The discriminator probably is able to tell that the early generated outputs are garbage as there are 1s all over the place, but perhaps at some point the generator can match the one-hot encoding and thus the discriminator decides that is not a fake. This would explain the high accuracy, despite the sequences not making sense.\n\n&amp;#x200B;\n\nI am not sure of this is the case or not, or if it makes sense at all (I've just started reading about GANs yesterday). Is there a way to capture the high level features of the dataset? I am not interested in just generating something that looks like a real encoding, I'd like to generate something that follows the encoding but also learns patterns from the original data.\n\n&amp;#x200B;\n\nI was thinking that maybe pretraining the discriminator would be a good idea, because it would then be able to discern between real-looking encodings for both the 0 and 1 classes. However, the pretraining idea seems frowned upon.\n\n&amp;#x200B;\n\nI'd appreciate any ideas and advice. Thanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/by945x/are_gans_applicable_to_this_problem/"}, {"autor": "zimmer550king", "date": "2019-06-08 10:56:32", "content": "I have a strong background in computer vision and I believe if I look at some tutorials that simply show how to set up a CNN in code, I can figure out most of the theory along the way (I have also studied a little bit about neural networks and some introductory theory about how convolutional neural networks work). I Googled and also searched on YouTube but couldn't seem to find a quick tutorial that showed me how to set up a CNN in code. By quick, I obviously don't mean 5 minutes but I simply can't wait for hours of explanation that goes too deep into the idea behind CNN (I am confident I can learn that along the way).\n\nIn short: I am looking for a tutorial that tells me exactly what software to download, how to install it and how to start training an -----> image !!!  classifier straight away. From that basic tutorial, I can work my way to more advanced stuff. But I can't seem to find that basic tutorial. Can anyone here post a link to a tutorial which they believe is beginner friendly to those who have never worked with CNNs before but have a strong Computer Vision background and a somewhat OK understanding of neural networks? Thanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/by6tv4/tutorials_looking_for_a_quick_crash_course_in/"}, {"autor": "redigeur", "date": "2019-06-07 13:15:15", "content": "This might be a very stupid question, but is there any use for a validation set if the test set (+ output) is publicly available?\n\nLet's say you have e.g. an -----> image !!!  data set (like MS COCO) where you can benchmark your model's performance against other people. Would it be a valid approach to validate your model on the test set after each training epoch and then choose the epoch where your model performed best to select your final model?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bxuhh3/is_a_validation_set_always_necessary/"}, {"autor": "ActualRealBuckshot", "date": "2019-06-06 00:46:51", "content": "Dies anybody have any guidance on how to begin learning -----> image !!!  processing? I have a project in mind but have never worked with image data before.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bxaavb/image_processing/"}, {"autor": "mr_meeesix", "date": "2019-06-04 14:16:22", "content": "I have a huge dataset. My usual approach when I deal with such datset is  I split into multiple tiny datasets using numpy archives and use a  generator to deal with them. Are there any other alternatives to this? I  also wanted to incorporate random run time -----> Image !!!  augumentations with  Keras -----> Image !!!  preprocessing module which also is a generator type  function. How do I stream line these two generator processes? The link for the Keras Image augmentation module is below. [https://keras.io/preprocessing/image/](https://keras.io/preprocessing/image/)\n\nMy current data flow generator is as follows:\n\n    def dat_loader(path, batch_size):\n        while True:\n            for dir, subdir, files in os.walk(path):\n                for file in files:\n                    file_path = path + file\n                    archive = np.load(file_path)\n                    img = archive['images']\n                    truth = archive['truth']\n                    del archive\n                    num_batches = len(truth)//batch_size\n                    img = np.array_split(img, num_batches)\n                    truth = np.array_split(truth, num_batches)\n                    while truth:\n                        batch_img = img.pop()\n                        batch_truth = truth.pop()\n                        yield batch_img, batch_truth\n\nDo I perform data augmentation before hand and then use my regular generator function? Is there a workaround for this?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bwp797/how_to_work_with_two_different_generators_while/"}, {"autor": "io_101", "date": "2019-04-13 22:06:52", "content": "I want to build a model for my college website which can detect and tag students based on a group -----> image !!!  of students.\n\nFor example, a teacher clicks a group photo of the students in the class and upload to the website. Using the model, one can update the attendance. \n\nI had previously done a basic dog vs cat classifier using nvidia DIGITS but that was a classifier for images containing  single subjects.  What should be my approach for this problem?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bcvvgb/ml_approach_for_a_group_image_recognition_and/"}, {"autor": "Spaceman776", "date": "2019-04-12 15:21:50", "content": "Hi, I am doing a project for class involving -----> image !!!  classification with TensorFlow. I've been using the \"TensorFlow for Poets\" template for this but I have no idea how it works and the website does not seem to explain it either. As a complete beginner, where would be the best place to start learning how TensorFlow is doing image classification? Thanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bceslm/where_can_i_learn_how_tensorflow_does_image/"}, {"autor": "QuasiEvil", "date": "2019-04-12 02:14:04", "content": "What methods exist out there for doing blind -----> image !!!  classification (if that's even the right thing to call it)? \n\nFor example, I have a bunch of images of nickles, quarters, and dimes and I want my NN to sort the images accordingly. Neither the NN, nor the user, needs to \"know\" what each of these coins are; I just want the model to say \"these all look similar\" and \"these all look similar' and \"those all look similar\"", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bc8bq3/methods_for_blind_image_classification_is_that/"}, {"autor": "Atam55", "date": "2019-12-29 15:44:56", "content": " \n\nWhile I am training my CNN model, the accuracy always gets stuck at around 10%. I am creating an -----> image !!!  classifier using CNN. The loss and accuracy are stuck at one value over the epochs.\n\nThis is the code I have written for the model:\n\n    model = keras.models.Sequential()  \n    model.add(keras.layers.Conv2D(32,(3,3),input_shape = X.shape[1:])) \n    model.add(keras.layers.Activation(\"relu\")) \n    model.add(keras.layers.Conv2D(32,(3,3))) \n    model.add(keras.layers.Activation(\"relu\")) \n    model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))  \n    model.add(keras.layers.Conv2D(64,(3,3))) \n    model.add(keras.layers.Activation(\"relu\")) \n    model.add(keras.layers.Conv2D(64,(3,3))) \n    model.add(keras.layers.Activation(\"relu\")) \n    model.add(keras.layers.MaxPooling2D(pool_size=(2,2))) \n    model.add(keras.layers.Dropout(0.5))  \n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(128)) \n    model.add(keras.layers.Activation(\"softmax\"))  \n    model.add(keras.layers.Dense(128)) \n    model.add(keras.layers.Activation(\"softmax\"))  \n    model.add(keras.layers.Dense(10)) \n    model.add(keras.layers.Activation(\"softmax\"))  \n    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])  \n    history = model.fit(X,y,batch_size=128,epochs = 20, validation_split = 0.2,verbose = 2)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/eh7bhd/accuracy_stuck_at_one_value_while_training_the/"}, {"autor": "nisucuk", "date": "2019-12-28 22:34:32", "content": "I have read several people who have solved this problem using encoder decoder(CNN/LSTM) method. None of them used or mentioned glove  or embedding. however, in most of the -----> image !!!  captioning, I have noticed it being used. I read \"long short term memory \" with python. Is there any link which solves this problem, is (glove or embedding) necessary???", "link": "https://www.reddit.com/r/learnmachinelearning/comments/egxdr3/my_image_contains_varying_number_of_medical/"}, {"autor": "miraksy", "date": "2019-12-28 21:38:16", "content": "Hello guys, \n\nI have been taking some ML/ deep network courses and so far im quite familiar with the algorithms and the logic behind it but i cant manage to get myself togheter to make an end-to-end intermediate/hard project ( like an kaggle competition).\n\nThe problem that i have is coding the preprocessing and data preparation steps of the unstructured data, like images for an CNN. Even tho i know the steps and what i have to do, i can't seem to write good code for this part. \n\nDoes anyone know a good book or course that involves code for -----> image !!!  preprocessing and preparation, i have mostly used keras/tensorflow?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/egwo25/any_recommended_courseguide/"}, {"autor": "hortonhearsadan", "date": "2019-12-28 16:00:52", "content": "At work i've been tasked with building a super quick Anomaly Detector, and the aim is to \\`use machine learning\\` but im not sure how. Lets consider this fake example\n\n&amp;#x200B;\n\nWe get data on, say, street cctv cameras, and each one reports how many cars it can see. The aim is to flag when a -----> camera !!!  claims it can see too many cars.\n\nThe team requesting this want to base its definition of \\`too many\\` on attributes of the camera. So like, the city its in, the type of area (commercial, residential) etc. There are quite a few dimensions of the attributes but not all of them important.\n\n&amp;#x200B;\n\nSo im thinking, just get a the distribution of number of signs for each grouping and then check the reported value against the 99% percentile for that grouping. So \\`Montreal Commercial, and it claims theres 40 cars, however the 99% percentile for Montreal Commercial is 27 so flag it\\`\n\n&amp;#x200B;\n\nDoes it really need to be more complicated than that? Ive tried an angle based  outlier detection model which didn't really work, and an isolation forest didnt really give me anything awesome either.\n\n&amp;#x200B;\n\nWhat am i doing wrong, is there a a good model to use for this?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/egscn5/is_machine_learning_the_right_approach_for_my/"}, {"autor": "logicallyzany", "date": "2019-12-28 04:46:46", "content": "I have a CNN binary classifier I have trained only using images and it achieved an AUROC of .65. I also trained a random forests model using only the \u201cmetadata\u201d for this -----> image !!!  dataset which achieved an AUROC of .71\n\nNow I took the cnn I trained only using the -----> image !!! s and further trained it using now the -----> image !!!  data and \u201cmetadata\u201d which resulted in an AUROC of .94? I feel like this is too good to be true but I can\u2019t immediately where I made a mistake in my code.\n\nThe images here are tissue slides and the \u201cmetadata\u201d are clinical variables for the patient that slide belongs to.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/egmcb4/is_a_huge_boost_in_the_auroc_from_adding_metadata/"}, {"autor": "bobhwantstoknow", "date": "2019-12-27 19:54:04", "content": "Hello,\n\nUsing keras.  I'm putting together a very simple -----> image !!!  de-noising project.  I want to loop through a list of image files, add noise, and fit using the noisy and original image, then repeat with the next image.  Will fitting one image at a time like this cause problems?  Do I first need to combine all the examples into one large set?  I'm hoping to avoid that.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/egfxua/fitting_multiple_individual_sets/"}, {"autor": "_4lexander_", "date": "2019-12-26 19:13:47", "content": "Okay so here's my CNN (simple example from a tutorial) along with some math.\n\nWe've got a dataset of 28\\*28 grayscale -----> image !!! . \n\n1. First layer is a 2D convolution using 32 3x3 kernels. **Running parameter count: 288**\n2. Second layer is 2x2 MaxPool with a 2x2. No extra parameters here. \n3. Third layer is Dense. A 5408x100 matrix. **Running Parameter count: 540988**\n4. Fourth layer is Dense also. A 100x10 matrix. **Running Parameter count: 541988**\n\nThen we're supposed to do stochastic gradient descent ON A 541988 PARAMETER SPACE!\n\nThat feels like a ridiculously big number to me. And this is meant to be the hello world problem of CNNs. Am I missing something fundamental in my understanding how this is meant to work? Or maybe the number is correct but it's not actually a big deal for a computer to crunch?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/efzizw/how_many_parameters_are_being_optimised_over_in_a/"}, {"autor": "roset_ta", "date": "2019-05-20 15:52:05", "content": "Hello everyone, \n\n\nA noob question. Is it possible to give as input to a CNN model images of different sizes? And if yes, how can I concatenate each -----> image !!!  numpy array to one single numpy array? \nI know that before giving the input to the CNN the image input size has to be defined, for example (-1,32,32,3), but what if I have two images of different sizes?\n\n\nThanks a lot", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bqxane/images_of_different_size_as_input_to_cnn/"}, {"autor": "Aerosherm", "date": "2019-05-20 14:02:02", "content": "My friend and I are working on a file sharing platform but we want to build an -----> image !!!  classifier to filter out any illegal pornography. Now we've come to the realisation that there is no way we can (and want to) acquire a dataset to train our model on. So how should we approach this? How do companies like Facebook, and Google approach this problem?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bqvwol/building_an_illegal_pornography_filter_using_ml/"}, {"autor": "granular2", "date": "2019-05-19 19:08:47", "content": "I am trying to do -----> image !!!  classification (by finetuning a pretrained model) and getting nowhere.  I have managed to scrape up about 350 images, but there are 10 classes so I gather I need more. Still though, shouldn't the model just overfit? As it is now, the accuracy (on the training-data) stays around 10%.\n\nI wonder if something is wrong with my setup? Or if the data is incomprihensible? Or some other problem.. \n\nAny advice?  \nThanks", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bqkpek/image_classification_not_learning_keras_on_small/"}, {"autor": "worldrecordusername", "date": "2019-05-19 06:47:24", "content": "Problem statement:\nI have a square boundary made of plastic.I want the program to give the co ordinates of the corners of the boundary.In the input images the square boundary will be the same colour and shape.It will be the same square which will be used in all images.I want to feed in images along with boundary points to make the neural networks learn to find the boundary points of any -----> picture !!!  with the plastic boundary.The plastic boundary will always be in the plane of the image.\nI would like to get materials or links or methods anything which can help with this problem.\nAre their any libraries which i can use to produce the neural network?\nAny help is appreciated.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bqdtcq/how_to_make_a_neural_networks_which_when_given_an/"}, {"autor": "BayesMind", "date": "2019-05-18 17:57:31", "content": "For example, an LSTM has several equations describing it's gates, and states: https://i.stack.imgur.com/aTDpS.png\n\nIn that -----> image !!! , you also see its corresponding digraph.\n\nI would like to algorithmically convert a system of equations into that architecture.\n\nSo, say I have a list of nodes that represent operations (plus, times, linear transform, ...), and a matrix of edges that connect outputs back to inputs, how can I automatically generate a function for computing an input applied through that architecture?\n\nMy problem is close to [tearing](https://sdopt-tearing.readthedocs.io/en/latest/), [decomposition of systems of eqs](http://reliablecomputing.eu/baharev_tearing_survey.pdf), [Minimum Feedback Arc Sets](https://www.mat.univie.ac.at/~neum/ms/minimum_feedback_arc_set.pdf) (and Vertex sets), Maximum Acyclic Subgraphs, Topological Sorting...\n\nThe biggest problem relates to recurrent loops, and how to account for which nodes indicate \"state\" that should be carried into the future.\n\nEven just learning how to mark nodes as state, and remove them so that the graph becomes a DAG that I can sort... that'd solve my problem.\n\n**TLDR**; I want to turn a Graph (Nodes and Edges) into a Neural Net into which I can pass input+states, and get out states+output+loss (i'm not even worried about backprop yet).", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bq6ss6/given_a_system_of_equations_how_can_i_generate/"}, {"autor": "lchtbrn", "date": "2019-05-18 14:59:11", "content": "I have several thousand of images in the format seen in this -----> picture !!!  [https://imgur.com/7yjiW1N](https://imgur.com/7yjiW1N) and I'm looking for a method to convert this into a simple table in which \u2713 = 1, - = 0 and \u2717 = -1. What would be the easiest way to accomplish this? I have Python experience but none in machine learning so far.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bq4vhg/ocr_for_survey_answers_with_special_characters_and/"}, {"autor": "lchtbrn", "date": "2019-05-18 14:09:46", "content": "I have several thousand of images in the format seen in this -----> picture !!!  [https://imgur.com/7yjiW1N](https://imgur.com/7yjiW1N) and I'm looking for a method to convert this into a simple table in which \u2713 = 1, - = 0 and \u2717 = -1.\n\nI tried text recognition software like Adobe without success. Now I'm considering the sklearn Python module. So far I've managed to  load the image into Python and turn it into a numpy array and I uploaded  some correct results and turned it into an array aswell (looks like  this: \\[\\['0', '1', '1'\\], \\['-1', '1', '1'\\], ... , \\['0', '1', '1'\\]\\]  \n) .\n\n    import csv from PIL import Image import numpy im = Image.open(\"training_image.png\") training_data = numpy.array(im) with open('correct_results.csv', 'rb') as f:     correct_results = list(csv.reader(f))\n\nFor what I can see, the sklearn process seems to always go the same way: \n\n    #Import a model:  model=some_model() #train it:  model.fit(training_data,correct_results) #predict:   predicted_results=model.predict(new_input_data)\n\nNow I would like to know, how I can transform this numpy array into a  form that can be used by model.fit, and which model could I use for  this? So far I had no success with my research.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bq4dqy/python_sklearn_ocr_for_survey_answers_with/"}, {"autor": "jr_coyote", "date": "2019-05-18 12:51:05", "content": "Hi,\n\n&amp;#x200B;\n\nIn my dataset, each instance is represented with a gender and frequency. Gender is a categorical variable (M,F) and frequency is a continuous variable that can be any number between \\[0,1\\].  The output is either being successful or failed. Thus, problem is binary prediction task. \n\nI wonder how can I represent my input. \n\n&amp;#x200B;\n\nFor example, If my task was -----> image !!!  classification on MNIST dataset (28x28 pixels -----> image !!! s) , I would use  784 pixel values as input, multiply it with a 784x10 dimensional matrix and apply a softmax to decide which number exist in the input -----> image !!! . However now, I cannot decide how can I represent my input. Any suggestion ?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bq3o6v/how_can_i_perform_a_logistic_regression_on_one/"}, {"autor": "jthat92", "date": "2019-05-18 11:14:05", "content": "Would it work to train a network to count intersections on an -----> image !!!  with a grid on it? I don't want to do it through Computer visions techniques since it seems a bit too hard with my current knowledge.\n\nI was thinking to train with images of grids with the count of the intersections as labels. Would a network at some point recognize the features that the labels are referring to - in this case the intersections in the images?\n\nWould that work or should I use some other Machine Learning technique for that?\n\nI guess I will have to try it out to see how it works, but I thought I could get some valuable opinion from you (experts) on that beforehand.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bq2wiw/count_intersections_on_image_with_neural_network/"}, {"autor": "worldrecordusername", "date": "2019-05-18 10:45:11", "content": "How can I localize a specific object and draw a boundary around it.The object is not a common one.Can anyone provide me any links or material.Or maybe how I could go about this?\nI was thinking of making a neural network which when given an -----> image !!!  outputs the 4 position givingg the corners of a rectangular block which will bound the object .The object i am trying to get a boundary of is a perfect square.Is this possible and how can I move forward? What libraries should I use?Any lectures or tutorials which you can share on how to do this is appreciated.\nThe input images will all contain the object and the object will be the same.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bq2p3o/localizing_specific_object/"}, {"autor": "worldrecordusername", "date": "2019-05-18 07:32:35", "content": "I am trying to segment cloth material which will be bounded by a square base .The base will be same but the cloth material will vary .So i want to create a neural network so that I can input an -----> image !!!  and i will get the output as the corner points of the square.I have images with corner points already known. But how do I go about making the neural network.Is there any library i could use?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bq1eph/detecting_boundary_points/"}, {"autor": "iyaja", "date": "2019-05-18 05:49:45", "content": "Hi everyone. I've been working on a project where I use StyleGAN to generate fake images of characters from Game of Thrones. I wrote an [article](https://blog.nanonets.com/stylegan-got/) that describes that algorithms and methods used, and you can try it out yourself via a [Colab notebook](https://colab.research.google.com/github/iyaja/stylegan-encoder/blob/master/generate_GoT_characters_with_StyleGAN.ipynb#scrollTo=LKzLQp1QIkHd). Here are some of the results:\n\n&amp;#x200B;\n\n*Processing gif qk30sjaxrwy21...*\n\nThese are the resources to follow along:\n\n* Article: [https://blog.nanonets.com/stylegan-got/](https://blog.nanonets.com/stylegan-got/)\n* Colab notebook: [https://colab.research.google.com/github/iyaja/stylegan-encoder/blob/master/generate\\_GoT\\_characters\\_with\\_StyleGAN.ipynb](https://colab.research.google.com/github/iyaja/stylegan-encoder/blob/master/generate_GoT_characters_with_StyleGAN.ipynb#scrollTo=LKzLQp1QIkHd)\n* GitHub repo: [https://github.com/iyaja/stylegan-encoder](https://github.com/iyaja/stylegan-encoder)\n\n&amp;#x200B;\n\nSomething interesting to note: All the results (images and animations) were generated from Nvidia's StyleGAN that was pretrained on the FFHQ dataset, with absolutely no fine-tuning.\n\n&amp;#x200B;\n\nInstead, to make StyleGAN work for Game of Thrones characters, I used another model (credit to [this GitHub repo](https://github.com/iyaja/stylegan-encoder)) that maps images onto StyleGAN's latent space. I gave it -----> image !!! s of Jon, Daenerys, Jaime, etc. and got latent vectors that when fed through StyleGAN, recreate the original -----> image !!! .\n\n&amp;#x200B;\n\nWith the latent vectors for the -----> image !!! s in hand, it's really to modify them in all the ways described in the StyleGAN paper (style mixing, interpolations, etc.) as well as through simple arithmetic in the latent space (such as shifting the latent vector in the \"smiling direction\"). As a bonus, since there's no StyleGAN training involved, all the steps that I just mentioned can be executed extremely fast.\n\n&amp;#x200B;\n\nAlso, stick around to the end of [the article](https://blog.nanonets.com/stylegan-got/) to see a result of character style mixing that might be very interesting to Game of Thrones fans.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bq0a69/how_to_generate_game_of_thrones_characters_using/"}, {"autor": "dgfhgdhg3476234", "date": "2019-05-16 23:35:03", "content": "I\u2019m working on a few side projects that involve deploying ML models to the edge. One of them is a -----> photo !!! -editing app that includes CNN\u2019s for facial recognition, object detection, classification, and style transfer. The other is a NLP app that assists in the writing process by suggesting words and sentence completions..\n\nOnce I have a trained model that\u2019s accurate, it ends up being really slow on one or more mobile devices (usually Android). I\u2019ve read that there are optimizations one can do to speed models up, but I don\u2019t know how. Is there a standard, go-to tool for optimizing models for mobile/edge?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bpjtyx/how_do_you_make_models_run_fast_at_the_edge_mobile/"}, {"autor": "ZER_0_NE", "date": "2019-03-23 21:35:05", "content": "[Previous researchers](https://www.sciencedirect.com/science/article/pii/S0003682X18311241) have used techniques like Denoising using Spectral Subtraction method and calculating Short Time Fourier Transform (STFT) by dividing the audio data into fixed size chunks and then calculating the frame spectrogram for each of these chunks.\n\nThe -----> image !!!  below shows how the author has pre-processed his data by manually extracting the frame and calculating it's spectrogram after applying the above-mentioned methods.\n\nWhat pre-processing techniques exist for such kind of audio data where you need to use the spectrogram images for developing a CNN model, given that all audio files will be of varying length and bit-rates?\n\n\\[!\\[pre-process\\]\\[1\\]\\]\\[1\\]\n\n&amp;#x200B;\n\n  \\[1\\]: [https://i.stack.imgur.com/t6MQw.png](https://i.stack.imgur.com/t6MQw.png)\n\n&amp;#x200B;", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b4ojhv/preprocessing_audio_data_for_whale_sound/"}, {"autor": "Sterben712", "date": "2019-03-22 07:43:08", "content": "I need to do multi-class segmentation 4 class, I have a separate mask for each class, I use a **ResNet-Unet** to solve my problem. But I can't deal with the creation of custom `Dataset` for my problem. Now I decide it is, read a csv file and in `__get_item__` returns a dictionary of form `{'-----> image !!! ': -----> image !!! , 'mask': mask, 'class':class}`. Do I do it and maybe you can do something ? Thanks for the help", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b426cg/how_best_to_do_custom_dataset_for_multiclass/"}, {"autor": "vlanins", "date": "2019-03-20 17:04:19", "content": "I am reading through this paper (https://arxiv.org/abs/1902.08897) and the author makes many references to 'salient' features. \n\nHe states that he \"performed data augmentation using feature extraction algorithms to extract the salient features from the original dataset instead of conventional data augmentation approaches\". Some of the extraction techniques he used are Haar, LBP, and region of -----> image !!!  cropping. \n\nI am unsure what 'salient' features are and how they differ. I did a google search of salient feature extraction and get many papers that reference salient features but haven't see a real definition. \n\nCan anyone point me to a source to where I can better understand salient features and when to use them?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b3eirh/what_are_salient_features/"}, {"autor": "FantasticInjury", "date": "2019-03-20 09:22:24", "content": "Hello,\n\nI'm currently working on a project which involves the need to segment hair from pictures. I looked up at this paper [https://github.com/UmarSpa/HairAnalysis](https://github.com/UmarSpa/HairAnalysis) and I believes it meets my needs. However, when trying to run the demo, it does not work for me.\n\n&amp;#x200B;\n\nI'm working on Mac OSX (no GPU) Mojave, and I did not succeed in installing \"Caffe\". I tried to use a docker as alternative to run the above link, however when I run: docker run --volume=$(pwd):/workspace caffe:cpu \\\\ python ./main.py it does not work and says scikit missing.\n\n&amp;#x200B;\n\nAnd here I'm stuck, I was thinking of modifying the docker -----> image !!!  and add in it **pip install scikit-learn** but I'm not sure how to do it and if it will fix my problem. Here is the docker I'm currently using [https://github.com/floydhub/dl-docker/](https://github.com/floydhub/dl-docker/).\n\n&amp;#x200B;\n\nAny help is appreciated (hoping its the right subreddit). I'm new to machine learning so feel free to tell me if I'm doing everything the wrong way.\n\nThank you!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/b39use/need_help_hair_segmentation_with_python/"}, {"autor": "elisimicr", "date": "2019-11-19 11:59:31", "content": "When I run my CNN (from fast.ai library) \n```learn = cnn_learner(databunch, models.resnet34, metrics=error_rate)```\nit throws this error\n\n    RuntimeError: Given groups=1, weight of size 64 3 7 7, expected input[64, 28, 28, 3] to have 3   channels, but got 28 channels instead\n\nIf I understand right my input is the incorrect format. \n\nMy original input has been shaped to create an -----> image !!!  28px  by 28px. It's grayscale, hence the np.stack(...) to create three channels\n\n    def to_img_shape(data_X, data_y=[]):\n    data_X = np.array(data_X).reshape(-1,28,28)\n    data_X = np.stack((data_X,)*3, axis=-1)\n    data_y = np.array(data_y)\nreturn data_X,data_y\n\ntrain_90_data, train_90_labels = to_img_shape(train_90_data, train_90_labels)\n\ntrain_90_data has a shape of :\n```\n(59949, 28, 28, 3)\n```\n\nCan I manipulate this input for it to be compatible with this architecture? Excuse, my lack of linear algebra knowledge. Am I even understanding this error correctly?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dyjhnx/question_about_reshaping_numpy_array_for_cnn/"}, {"autor": "yash_yennam", "date": "2019-11-19 07:48:35", "content": "I am new to ML with limited experience on small projects using SVM. I have fair knowledge of Python in general and work as Python Developer full time. I tried finding some information online for this project but it is overwhelming and something which may require help from community.\n\nI am looking to start a project in ML with following tasks:\nML program should take a -----> image !!!  file as an input and give output as it's discription according to it's shape ( A line, Triangle, Circle etc) , It's colour (RGB) , and its angle (ex. If it's line, so angle of the line with respect to bottom of screen, if circle : 360 degree, a triangle with angle of edges etc)\n\nQuestions I am stuck with:\n\n1. Which ML library should I use?\n2. How do I deal with finding the angles?\n3. Sources of Train/Test data ( Don't want to waste time on MS Paint)\n4. Can I find links to similar projects if it's already out there. (Please post them if any)\n\nI have not started project yet. Searching for ideas in here and best way to do it.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dyhdi0/ml_to_classify_geometric_shapes_its_colour_and/"}, {"autor": "SecureSolid", "date": "2019-11-19 05:39:28", "content": "&gt;Suppose your target variable is attrition. It's a binary variable - 1 refers to customer attrited and 0 refers to an active customer. In this case, your desired outcome is 1 in attrition since you need to identify customers who are likely to leave.\n\nLet's say you set 0 as an event in the logistic regression:-\n\n* The sign of estimates would be opposite which implies the opposite behavior of variables towards the target variable (as shown in the -----> image !!!  above).\n* Area under the curve (AUC), Concordance and Discordance scores would be precisely the same. No change.\n* Sensitivity and Specificity score would be swapped (see the image below).\n* No change in Information Value (IV) of variables.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dyg70z/how_would_you_determine_your_actions_were/"}, {"autor": "RonaldoSucculent", "date": "2019-11-18 19:38:16", "content": "I'm making a discord bot attached with an -----> image !!!  recognizer but I ran into an issue. I need to classify only one label (for example, the object is x% car). I currently have a CNN that outputs the % correctly, but what I have done was have two lables, one car and one not car, and then train off a dataset of cars with a dataset of random objects in the other.\n\nIs there a better way to do this classification? The class I'm in only does MNIST and CIFAR so I have only had to deal with 10 labels and items inside the dataset.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dy86cc/image_recognition_single_label_classification/"}, {"autor": "TrackLabs", "date": "2019-11-18 13:16:41", "content": "I would like to code a PyTorch -----> image !!!  classifier from scratch. No transfer learning.\n\nI want it to classifiy simple things, like a car, planes, tables, keyboards, etc. the main object.\n\nHow many Images would be good as dataset? \n\nI know there are plenty of datasets to download, so maybe there is a good one I can use for that task?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dy31x0/what_is_a_good_amount_of_data_for_a_pytorch_image/"}, {"autor": "nickbild", "date": "2019-11-18 01:55:16", "content": "Artemis is an eyeglass-mounted device that can be configured to locate a specific type of object, or a person. When the target is found, Artemis will track it with a laser.\n\nHow It Works:\n\nAn eyeglass-mounted -----> camera !!!  streams images to a Jetson AGX Xavier. An SSD300 model is used for object localization within these images. When the object of interest has been found, a laser diode is turned on.\n\nA servo is also mounted on the eyeglasses for X-axis control of the laser. A second servo is mounted on top of the first, at a 90 degree angle, to give Y-axis control. The laser is mounted on the second servo.\n\nImages are thresholded in OpenCV to determine the location of the laser pointer. With the location of the object, and also the laser, now determined it is possible to adjust the servos to place the laser over the object of interest.\n\nFull Details:\n\n[https://github.com/nickbild/artemis](https://github.com/nickbild/artemis)\n\n[https://www.youtube.com/watch?v=zOmJOMlqhAQ](https://www.youtube.com/watch?v=zOmJOMlqhAQ)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dxwefk/artemis_laser_object_tracking/"}, {"autor": "A27_97", "date": "2019-07-22 13:01:10", "content": " I am trying to generate adversarial images for the MNIST data set. I'm not able to figure out where I'm going wrong but I'm pretty sure its a rookie mistake. The main model works fine, but I don't think the gradients are correct, or the gradient is working correctly.\n\nMy understanding of my program is-\n\n* take an -----> image !!!  of a particular digit (2 for example)\n* get the prediction output and store it\n* make a numpy array equal to the size of the -----> image !!! \n* define the target class (4 for example)\n* define epochs (number of iterations), and epsilon(magnifying factor)\n* find the loss gradient wrt to input\n* take sign of loss and add it to the noise\n* multiply noise with epsilon and add it to the original -----> image !!!  (2)\n\nwith each iteration the probability of the target class 4 should be increasing, and 2 should be reducing...but it seems that in my case its not changing. I think the problem is with the loss and gradient, but not sure what exactly is wrong.\n\nThe model that I trained -\n\n`model = Sequential()`\n\n`model.add(Flatten(input_shape=(28, 28)))`\n\n`model.add(Dense(512))`\n\n`model.add(Activation('relu'))`                            \n\n`model.add(Dropout(0.2))`\n\n`model.add(Dense(512))`\n\n`model.add(Activation('relu'))`\n\n`model.add(Dropout(0.2))`\n\n`model.add(Dense(10))`\n\n`model.add(Activation('softmax'))`\n\n&amp;#x200B;\n\n The loop for the adversarial attack - \n\n&amp;#x200B;\n\n`epochs = 20`\n\n`epsilon = 0.01`\n\n`target_class = 4 # cucumber`\n\n`prev_probs = []`\n\n`for i in range(epochs):` \n\n`target = K.one_hot(target_class, 10)`\n\n`loss = -1*K.categorical_crossentropy(target, model.output)`\n\n`grads = K.gradients(loss, model.input)`\n\n`delta = tf.sign(grads[0])`\n\n`x_noise = x_noise + delta`\n\n`x_adv = x_adv + epsilon*delta`\n\n`x_adv =` [`sess.run`](https://sess.run)`(x_adv, feed_dict={model.input:x})`\n\n`preds = model.predict(x_adv)`\n\n`prev_probs.append(preds[0][target_class])`\n\n`if i%1==0:`\n\n`print(i, preds[0][target_class])#, decode_predictions(predictions, top=3)[0])`\n\n&amp;#x200B;\n\n this generates the output - \n\n&amp;#x200B;\n\n`0 1.3663602e-20`\n\n`2 1.3663602e-20`\n\n`3 1.3663602e-20`\n\n`4 1.3663602e-20`\n\n \n\nwhere `1.3663602e-20`is the initial probability of the target class, now this value should be increasing with each iteration if the code was working, but I am unable to figure out what I'm doing wrong.\n\nx\\_adv is the original image of 28,28 size.\n\nthe original prediction is\n\n `[[1.98642525e-15 4.08783875e-11 1.00000000e+00 3.10077613e-16 1.36636020e-20 1.03787735e-16 1.06811939e-14 1.20261394e-16 1.21401262e-16 1.08713405e-24]]`", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cgcwr6/adversarial_attack_on_mnist_data_set_gradient/"}, {"autor": "zimmer550king", "date": "2019-07-22 11:30:38", "content": "Hi. I am new to machine learning. I am taking a course on CNNs from Stanford. I am currently at this lecture (timeslot included to show the part of the lecture I don't understand):  [https://www.youtube.com/watch?v=6wcs6szJWMY&amp;t=37m](https://www.youtube.com/watch?v=6wcs6szJWMY&amp;t=37m) \n\nIn gradient descent, we take the derivative of the loss with respect to the parameters in the previous layer and then we update the parameters in the previous layer using the evaluated gradient. But, what exactly are we doing in gradient ascent? \n\nMy understanding, based on how it is explained in the lecture, is that you push a random (Gaussian) -----> image !!!  through the network. Then you do a backprop and evaluate the gradient for a neuron. Then, you add this gradient value to all pixel values in the image?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cgc17p/how_does_gradient_ascent_work_in_a_convolution/"}, {"autor": "thereallilchief", "date": "2019-07-20 17:03:52", "content": "So I made a [program](https://github.com/andrewsong24/ImageClassificationOOTB) that allows you to easily train a model for multi-class -----> image !!!  classification on your own data sets.\n\nYou can choose between using a custom conv net, which can be created without having to change any code, or just fine-tune a pre-trained VGG16 for quicker results.\n\nUsing custom CNNS could help you experiment with hyper-parameter tuning and different network architectures without having to dive into the code and learn PyTorch\u2019s syntax.\n\nThe pre-trained VGG16 can be used if you don\u2019t really want to make your own model and just want to have a well-performing model on your custom data sets right away.\n\nThe custom conv net uses a config.txt file to generate the model, so you would just alter that to your needs. Also keep in mind that the custom conv net will take more data to train compared to fine-tuning the pre-trained VGG16.\n\nIf you run into any problems or have any suggestions just let me know!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cfo3fs/image_classification_out_of_the_box/"}, {"autor": "dxjustice", "date": "2019-07-20 15:09:51", "content": "I've been reading up on some autoencoder approaches, and am familiar with how convolutional neural networks work. But I'm a bit confused about padding.\n\n&amp;#x200B;\n\nTake the following code for example\n\n&amp;#x200B;\n\n `def conv(self, filters):`\n\n`def block(x):`\n\n`x = Conv2D(filters, kernel_size=5, strides=2, padding='same')(x)`\n\n`x = LeakyReLU(0.1)(x)`\n\n`return x`\n\n`return block`\n\n&amp;#x200B;\n\n`def upscale(self, filters):`\n\n`def block(x):`\n\n`x = Conv2D(filters * 4, kernel_size=3, padding='same')(x)`\n\n`x = LeakyReLU(0.1)(x)`\n\n`x = PixelShuffler()(x)`\n\n`return x`\n\n`return block`\n\n`#Note how no maxpooling after every layer here, we are generating a WARPED -----> image !!! , not a lower dimensional representation first.`\n\n`def Encoder(self):`\n\n`input_ = Input(shape=IMAGE_SHAPE)`\n\n`x = input_`\n\n`x = self.conv(128)(x)`\n\n`x = self.conv(256)(x)`\n\n`x = self.conv(512)(x)`\n\n`x = self.conv(1024)(x)`\n\n`x = Dense(ENCODER_DIM)(Flatten()(x))`\n\n`x = Dense(4 * 4 * 1024)(x)`\n\n`#Passed flattened X input into 2 dense layers, 1024 and 1024*4*4`\n\n`x = Reshape((4, 4, 1024))(x)`\n\n`#Reshapes X into 4,4,1024`\n\n`x = self.upscale(512)(x)`\n\n`return KerasModel(input_, x)`\n\n&amp;#x200B;\n\nPrinting a summary of the model tells me that given a 64x64 image, each convolution layer downsizes it by 2. Fair enough, but given that the padding has been set to \"same\", this should not be possible? Or am I missing something?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cfmtrs/setting_padding_same_in_convolutional_layer_yet/"}, {"autor": "arthomas73", "date": "2019-07-17 20:34:29", "content": "I am building a cnn to determine if a train is in an -----> image !!!  or not.  How many nodes should I have on the final layer? I am considering 2 nodes for \"train\" and \"no train\" with a softmax activation... I am also considering a single node with a sigmoid?\n\n&amp;#x200B;\n\nAny thoughts?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ceiez5/neural_network_classification_final_layer_question/"}, {"autor": "yeetus_deletus", "date": "2019-07-28 20:32:44", "content": "Hi, I am pretty new to ML, but I have a basic understanding of NNs and how to create them with Tensorflow and Keras. I\u2019ve done MNIST and Cifar10 projects and have experimented with -----> image !!!  classification on my own data set. I am interested in creating my own object detection model, and after doing some research I\u2019ve figured out that (correct me if I\u2019m wrong) creating and object detector starts with creating an image classifier and then instead of outputting a class, you begin to process the image more to create boundary boxes and labels. \n\nThe problem is, I don\u2019t really know how to go about doing this, and I\u2019m very inexperienced in general. I have learned how to create models in general but not exactly how to decide on their structures, loss calculations, optimizers, etc. I would appreciate any help with this project, but also please tell me if you think this is too big an undertaking for a beginner. Thanks in advance.\n\nSide note: Am also still being introduced to all the terminology so sorry if I ask a lot of questions.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cj100j/object_detection_help/"}, {"autor": "H3t0N", "date": "2019-07-27 15:07:57", "content": "Heay community whats up, \nmy fellow students and me are building autonomous race cars. This year we did the object detection with yolo on a stereo -----> camera !!! .\n\nNow i want to step up the game a little bit and want to use semantic/instance segmentation that will improve our distance calculation. \n\nMy plan was to use a two step pipeline (yolo-segmentation) like: \n\nDetect objects on on image -&gt; crop the detection box -&gt; do a semantic segmentation on the cropped image \n\nSo i saw that there are multiple papers descriping a softwarearchitecture to realize this in some way. \n\nThe main \"problem\" will be it needs to be fast (like 20 fps on an rtx 20xx) and that my input images will have different dimensions. \nThe input dimensions will be something from 40x50 and smaller. \nI would love to still use yolo for the object detection because its fast and reliable and is testet on our car this year. \n\nI would love to get some informations from you guys where to look or what to read if you have some experience with this.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ciikwp/semanticinstance_segmentation/"}, {"autor": "Stephanehk", "date": "2019-07-26 11:34:08", "content": "I am attempting to train a ball tracking model to recognize images of balls in photos like the one below:\n\n&amp;#x200B;\n\nhttps://i.redd.it/kk2aqxrsvmc31.jpg\n\nThere is already a lot of literature on this topic such as [this paper](https://arxiv.org/pdf/1902.07304.pdf), however, I am confused as to how the models are trained. Suppose I have a dataset of -----> image !!! s like the one above, and for each -----> image !!!  I have the coordinates of the soccer balls position, how would I use that to train a CNN? \n\nWould the input be the image and the output be a bounding box around the ball?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ci1q6k/how_to_train_a_ball_tracking_model/"}, {"autor": "ChiroNika", "date": "2019-07-26 10:38:48", "content": "First off: I've haven't done any -----> image !!!  processing yet and want to dive into this topic. I have an idea for a little artsy project that I want to do and wanted to ask here first which topics I need to research and learn to make this happen. \n\nSo far I only did simple Python Keras/SKLearn stuff but only data classification and regression of existing datasets. \n\nMy little project should be able to do this: I want make something like a deep dream model. I will train it with pictures and music and it should output sequenced visuals that correspond with the music (beatwise for example). Where do I need to start to make something like that happen? What topics do I need to read into? What is the best way to dive into image processing/manipulation and deep dreaming?\n\nThanks for your suggestions!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ci1912/creating_abstract_video_animations_trained_on/"}, {"autor": "matt0319", "date": "2019-07-25 06:05:35", "content": "Sorry if some of this doesn\u2019t make sense as I am brand new to machine learning concepts. I\u2019ve been looking at a bunch of examples for style transfer models, but I was wondering what the best way to go about training a model that uses multiple images as the style reference and not just one. For example it would take the common features of the style references and try its best to apply them to the -----> image !!!  given. This could be used to give images a certain look such as a Polaroid or vintage photo. Thanks :)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/chjtet/style_transfer_with_multiple_images_as_reference/"}, {"autor": "JetFuelCereals", "date": "2019-10-03 14:41:42", "content": "**Dear fellow designers, programmers, students and teachers,**\n\nWe are happy to invite you to our brand new reddit community:  [**r/VisualSchool**](https://www.reddit.com/r/VisualSchool/) . Here you can learn coding, design, marketing, dev ops, security and many other skills. We want to radically improve the online learning experience by providing a visual map of knowledge trough our innovative learning platforms.\n\nHow can we improve our learning platform and help you to learn faster?\n\nLeave us feedback on r/VisualSchool\n\n# Why Visual School?\n\n\u00b7 **Because learning is slow** \u2013 Our current experience learning online is very rough. We are forced to spend lots of time searching for the right material. We are forced to drain lots of energy just to understand the basics.\n\n\u00b7 **Because we lose focus** \u2013 We start learning one thing and then the next few hours we are all over the web trying to put the puzzle together. It\u2019s like going downstairs to dump the trash and returning several hours later after you were attacked by a grizzly bear in Las Vegas.\n\n\u00b7 **Because we are missing know-how** \u2013 On a daily basis we start reading some tutorial and then we find lots of strange unfamiliar concepts. All these gaps in knowledge prevent us from learning fast. Worse they divert our attention away from the main topic.\n\n# How will we learn on Visual School?\n\n\u00b7 **Elastic lessons** \u2013 All the tutorials in Visual School are optimized to be \u201cstretchy\u201d. Depending on how skilled you are you can adjust each part of the lesson to give you more or less content. Users ranging from complete beginners up to experts can consume the same set of tutorials adjusted to their own needs.\n\n\u00b7 **Speed reading** \u2013 All our tutorials will be optimized for speed reading. Our approach is to integrate carefully selected and designed graphics and animations. It will look and feel like a hybrid between text, slideshows and video all optimized for learning fast. The accent is on quality not quantity.\n\n\u00b7 **Learning map** \u2013 Think of it as a subway map. Our aim is to map all the important destinations and focus your attention on what makes the biggest impact in your daily life as a professional. This map will give you awareness of the big -----> picture !!! .\n\n\u00b7 **Learning goals** \u2013 You will be able to setup goals and our platform will help you plan ahead a faster route towards your professional goals. We encourage exploration in all ways and forms, all while maintaining a clear deadline and end-goal.\n\n\u00b7 **Nano Lessons** \u2013 For every new unfamiliar concept you discover in the lesson you will have a mini lesson about it one click away. It will help you focus and stay on track without feeling lost.\n\n# What will Visual School be?\n\n\u00b7 Visual School is the platform where you can study matching your own level of experience\n\n\u00b7 Visual School maintains your focus while studying a certain subject.\n\n\u00b7 Visual School fills in the gaps of knowledge right on the spot.\n\n# Who is the audience for Visual School?\n\n\u00b7 In this current group we invited only profiles that are either strong developers or strong designers. This selection is a good representation of the audience we are targeting. We intend to reach the global market of developers in the early phase. Our first iteration of content will be about programming.\n\nThe ultimate goal of Visual School is to reduce the time spent learning and to increase the time spent coding meaningful projects. Current generation of tutorials does a decent job. The next generation of tutorials will kick ass! We want to lead the way towards this future.\n\nCheers!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dcru1d/join_our_new_subreddit_rvisualschool_it_will_help/"}, {"autor": "Ghjjj4433", "date": "2019-10-02 16:08:20", "content": "I want to train a cnn . Which, for example is trained on pictures of a penguin or dog. And what I want is to build a bot or scrape the web. And I want to use my -----> image !!!  classification as a way of the bot finding matching -----> image !!! s of penguins or dogs. And I want it to send me the url of that site. \n\nCan someone please guide me in how I would approach a problem like this", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dccbqk/i_want_to_create_a_image_classification_model/"}, {"autor": "careertroubleguy", "date": "2019-09-29 17:08:07", "content": "Hi All,\n\n&amp;#x200B;\n\nJust a quick update to my [original post](https://www.reddit.com/r/Python/comments/b97hdk/a_review_of_5_python_deep_learning_computer/) where I started reviewing Computer Vision courses. Felt like this would be highly appreciated here since all are Python-based courses.\n\n&amp;#x200B;\n\n**UPDATE**: I completed two new CV courses:\n\n1. Coursera Andrew Ng course on Convolutional Neural Networks\n2. New Udemy course, this time using PyTorch - [PyTorch for Deep Learning and Computer Vision](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/)\n3. **APOLOGIES**, there was an error in some of the courses (the feedback on two were mixed up, unfortunately) it has since been fixed.\n4. **Some NEWS,** there's going to be an officia[l OpenCV Tutorial](https://www.kickstarter.com/projects/satyamallick/ai-courses-by-opencvorg) coming out soon. Should be one of the best when it's out!\n\n&amp;#x200B;\n\n**TLDR;**\n\n&amp;#x200B;\n\n**WINNER - 3 Way Tie**\n\n1. [**Deep Learning Computer Vision\u2122 CNN, OpenCV, YOLO, SSD &amp; GANs**](https://www.udemy.com/master-deep-learning-computer-visiontm-cnn-ssd-yolo-gans/?couponCode=REDDIT)  **- BEST VALUE**\n2. **Coursera** [**Computer Vision - Convolutional Neural Networks**](https://www.coursera.org/lecture/convolutional-neural-networks/computer-vision-Ob1nR) \\- **BEST EXPLANATIONS**\n3. PyImage's [**Deep Learning for Computer Vision with Python - Practitioner Bundle**](https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/) **- MOST CONTENT**\n\n&amp;#x200B;\n\n|Course Name|Site|Cost|Content|Explanations|Code Quality|Value|Overall Score|\n|:-|:-|:-|:-|:-|:-|:-|:-|\n|[Deep Learning and Computer Vision A-Z\u2122: OpenCV, SSD &amp; GANs](https://www.udemy.com/computer-vision-a-z/)|Udemy - [Hadelin de Ponteves](https://www.udemy.com/computer-vision-a-z/#instructor-1), [Kirill Eremenko](https://www.udemy.com/computer-vision-a-z/#instructor-2), [SuperDataScience Team](https://www.udemy.com/computer-vision-a-z/#instructor-3)|$9.99-199.99\\*|4.5/5|4/5|4.5/5|3.5/5|**3.9**|\n|[Python for Computer Vision with OpenCV and Deep Learning](https://www.udemy.com/python-for-computer-vision-with-opencv-and-deep-learning/)|Udemy - [Jose Portilla](https://www.udemy.com/python-for-computer-vision-with-opencv-and-deep-learning/#instructor-1)|$9.99-199.99\\*|4/5|4/5|4.5/5|4.5/5|**4.3**|\n|[Deep Learning Computer Vision\u2122 CNN, OpenCV, YOLO, SSD &amp; GANs](https://www.udemy.com/master-deep-learning-computer-visiontm-cnn-ssd-yolo-gans/)|Udemy - [Rajeev Ratan](https://www.udemy.com/master-computer-vision-with-opencv-in-python/#instructor-1)|$9.99-199.99\\*|4.8/5|4/5|4.5/5|5/5|**4.6**|\n|[Computer Vision Intro\u2122 OpenCV4 in Python with Deep Learning](https://www.udemy.com/master-computer-vision-with-opencv-in-python/)|Udemy - [Rajeev Ratan](https://www.udemy.com/master-computer-vision-with-opencv-in-python/#instructor-1)|$9.99-199.99\\*|4.3/5|4.3/5|4.5/5|4.5/5|**4.3**|\n|[Deep Learning: Advanced Computer Vision](https://www.udemy.com/advanced-computer-vision/?couponCode=REDDITCV)|Udemy - [Lazy Programmer Inc.](https://www.udemy.com/user/lazy-programmer/)|$9.99-199.99\\*|4/5|4.5/5|4.5/5|4/5|**4.3**|\n|[PyTorch for Deep Learning and Computer Vision](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/)|Udemy - [Rayan Slim](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/#instructor-1), [Jad Slim](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/#instructor-2), [Amer Sharaf](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/#instructor-3), [Sarmad Tanveer](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/#instructor-4)|$9.99-199.99\\*|3.5/5|4.5/5|4.5/5|4/5|**4.2**|\n|[Computer Vision - Convolutional Neural Networks](https://www.coursera.org/lecture/convolutional-neural-networks/computer-vision-Ob1nR)|Coursera - Andrew Ng|7 Days Free, $49/mo|4.4/5|5/5|4.5/5|4.3/5|**4.6**|\n|[Deep Learning for Computer Vision with Python](https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/) \\- PRACTITIONER BUNDLE|PyImage|$295 - use coupon code **reddit** to get 10% off|4.8/5|4.5/5|5/5|4/5|**4.6**|\n|[Deep Learning for Computer Vision with Python - ](https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/)STARTER BUNDLE|PyImage|$145 - use coupon code **reddit** to get 10% off|4.3/5|4/5|5/5|4.5/5|**4.5**|\n|[Deep Learning for Computer Vision with Python - ](https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/)IMAGENET BUNDLE|PyImage|$645 - use coupon code **reddit** to get 10% off|5/5|4.5|5/5|4/5|**4.5**|\n\n\\* Udemy has varying pricing, so course price fluctuates almost daily it seems, but it's rarely ever $199 for long.\n\n\\*\\* That was a sale price (20% off) most times the course doesn't seem to be on sale so the regular price is $295\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n**Summary reviews of each below:**\n\n&amp;#x200B;\n\n[PyTorch for Deep Learning and Computer Vision](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/) by  [Rayan Slim](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/#instructor-1), [Jad Slim](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/#instructor-2), [Amer Sharaf](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/#instructor-3), [Sarmad Tanveer](https://www.udemy.com/pytorch-for-deep-learning-and-computer-vision/#instructor-4)\n\n**Review** \\- This is a very good course. Basic, but well taught and focused well on PyTorch. What I didn't like is that it lacks more advanced content. As such it feels a bit shallow when compared to the other courses. Not bad for beginners though, especially if you're looking to learn PyTorch.\n\n**Pros**:\n\n\\- Very well taught\n\n\\- Basics covered well, lots of time spent on Neural Nets and CNNs\n\n\\- Transfer Learning is well taught\n\n\\- Teaches PyTorch very well\n\n**Cons**:\n\n\\- Only covers the basics and doesn't go into more advanced territory\n\n\\- Lacks cool projects\n\n**Score - 4.2/5**\n\n&amp;#x200B;\n\n[Computer Vision - Convolutional Neural Networks](https://www.coursera.org/lecture/convolutional-neural-networks/computer-vision-Ob1nR) \\- by Andrew Ng\n\n**Review** \\- Excellent Course! I didn't know why I didn't do this sooner! Complex concepts are broken down so well by Andrew Ng. However, it sort of jumps into the complex code a bit quick. Lots of courses tend to do this. It feels like a typical college course where you're taught the theory but not the execution.\n\n**Pros**:\n\n\\- Very well taught! Perhaps the best explanations of any course here.\n\n\\- Covers the key concepts of CNNs, Object Detection very well!\n\n\\- Covers mostly all the key CV topics\n\n**Cons**:\n\n\\- Not a big -----> picture !!!  or big project type course, the code you do is more about understanding the principles rather than doing something impressive.\n\n\\- It's not a course that will teach u to do things, rather it's focused on understanding what you're doing.\n\n\\- Can be expensive since it's $49/mo but if you finish it within that month or even the 7/day trial it's an excellent value.\n\n**Score - 4.5/5**\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[Deep Learning and Computer Vision A-Z\u2122: OpenCV, SSD &amp; GANs](https://www.udemy.com/computer-vision-a-z/) \\-  Created by [Hadelin de Ponteves](https://www.udemy.com/computer-vision-a-z/#instructor-1), [Kirill Eremenko](https://www.udemy.com/computer-vision-a-z/#instructor-2), [SuperDataScience Team](https://www.udemy.com/computer-vision-a-z/#instructor-3)\n\n**Review** \\- **UPDATE**: I initially gave this course a relatively poor review, but I realized I had mistakenly confused some of the content with another [course](https://www.udemy.com/advanced-computer-vision/). This course was very good. The problem I had is that it's not good for actually learning Computer Vision core basics. You'll be able to do a few fun projects after, but it doesn't teach you principles and how to do a lot of this on your own custom projects. Overall though, it's well presented and taught well.\n\n**Pros**:\n\n\\- Good variety of core content\n\n\\- His code works (always a plus since libraries and packages get updated frequently)\n\n\\- Fun projects\n\n**Cons**:\n\n\\- Little core basics as it's more of a cookbook type course. Other courses are like this, but many teach the basics before moving onto a project.\n\n\\- Some fluff and overly long videos. A bit inconsistent in what's taught well and what's skimmed.\n\n**Score - 4.2/5**\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[Python for Computer Vision with OpenCV and Deep Learning](https://www.udemy.com/python-for-computer-vision-with-opencv-and-deep-learning/) \\-  Created by [Jose Portilla](https://www.udemy.com/python-for-computer-vision-with-opencv-and-deep-learning/#instructor-1)\n\nI enjoyed this course quite a bit. It's not a Deep Learning course though, at most he has a basic intro to using Keras, and how to implement CIFAR10 and MNIST, but those things are everywhere. The OpenCV and CV Basics are taught very well! And I like his voice and positivity. He's a good teacher and does it well.\n\n**Pros:**\n\n\\- Covers the basics of OpenCV well\n\n\\- All code works\n\n\\- Has a Deep Learning section for added value\n\n\\- The instructor is upbeat and easy to follow\n\n**Cons:**\n\n\\- The Deep Learning stuff is basic and pretty much fluff to boost the 'value' of this course. It's very basic and can be found elsewhere for free\n\n\\- It doesn't have that many cool projects to do\n\n**Score 4.3/5**\n\n&amp;#x200B;\n\n[Deep Learning Computer Vision\u2122 CNN, OpenCV, YOLO, SSD &amp; GANs](https://www.udemy.com/master-deep-learning-computer-visiontm-cnn-ssd-yolo-gans/?couponCode=REDDIT) \\-  Created by [Rajeev Ratan](https://www.udemy.com/master-computer-vision-with-opencv-in-python/#instructor-1)\n\nI loved this course! It was my go-to reference for doing so many things. The content in this course is insane and he provides a full Virtual Machine with everything pre-installed (useful as all code works perfectly!). The explanations are very good. He doesn't always go into detail, but when he does it's taught quite well. The only issue I have is that I can see beginners sometimes being turned off since he rarely explains the code. He's more like \"here's the code that does this, this line this and this function was built to do this\". If you're a beginner it's understandable you'd be confused. However, the code, content, and number of projects were far more than the other courses, probably even put together (except for the PyImage course, but we'll get there). So to me, it's worth it. It covers all the details of Computer Vision rather than just pieces that look cool.\n\n**UPDATE**: Shortly after I posted the review I noticed Rajeev added some new content regarding using PaperSpace and deploying your CV model on AWS as an API (quite cool!)\n\n**Pros:**\n\n\\- Amazing and detailed content\n\n\\- Excellent theoretical explanations\n\n\\- Shows you how to get the best performance out of a CNN and built a variety of things\n\n\\- Very fun projects!\n\n\\- An enthusiastic teacher who you can tell has a passion for CV\n\n\\- New content always being added it seems!\n\n**Cons:**\n\n\\- Not for absolute beginners, now none of these courses are, but this one goes from easy to relatively hard quickly.\n\n\\- Instructor at times talks too fast and skims explanations of code\n\n\\- Some of the content is text, not video, so I didn't increase the score, but noted it regardless. Not really a con to be perfectly fair.\n\n**Score 4.6/5**\n\n&amp;#x200B;\n\n[Computer Vision Intro\u2122 OpenCV4 in Python with Deep Learning](https://www.udemy.com/master-computer-vision-with-opencv-in-python/?couponCode=REDDIT) \\-  Created by [Rajeev Ratan](https://www.udemy.com/master-computer-vision-with-opencv-in-python/#instructor-1)\n\nThis is the older course of instructor above and it shows, it's been updated quite a bit, but some of the videos aren't the same as the code he provides. That isn't a deal breaker and he does mention it, but it sometimes does make you wonder if was a mistake or intentional. That said, all code is compatible with OpenCV4 which is awesome. Also, the number of projects makes it quite a nice course to get some good practical OpenCV knowledge. A Virtual Machine is also provided (nice touch!). This course has some excellent OpenCV tutorials, fun projects and there is some added Deep Learning stuff so it's quite cool, not as much fluff and good explanations again.\n\n**UPDATE**: Shortly after I posted the review I noticed Rajeev added some new content such as using Caffee models in OpenCV to colorize black and white images and some other object detection stuff, really cool projects but not explained in too much depth, still cool regardless!\n\n**Pros:**\n\n\\- Easy to follow and I feel more of the OpenCV basics were thought\n\n\\- All code works and explanations are on point!\n\n\\- Bonus Deep Learning stuff\n\n\\- Fun Projects\n\n\\- Enthusiast Lecturer\n\n**Cons:**\n\n\\- Audio bad at some times (not much, maybe like 20 mins appears to have been recorded with his laptop mic vs external mic)\n\n\\- The code in the videos is not always the same as the downloadable code he provides\n\n**Score - 4.3/5**\n\n&amp;#x200B;\n\n[Deep Learning: Advanced Computer Vision (Udemy)](https://www.udemy.com/advanced-computer-vision/?couponCode=REDDITCV)  \\- Created by  [Lazy Programmer Inc.](https://www.udemy.com/user/lazy-programmer/)\n\n**UPDATE**: I went back to this course and realized I might have unfairly slammed it. If you want exactly what's offered (look at the syllabus, it's taught really well). But as a standalone CV course, it's lacking.\n\nI enjoyed this course, it doesn't cover very much but it does some of the basics fairly well. What I liked was that it moved relatively slow and spent a while on some details. It goes into good detail about implementing and building the CNN's he teaches. Overall, good course, just not as much wide content as some of the others but still good at what it does!\n\n**Pros:**\n\n\\- Covers a few topics, but covers them well\n\n\\- If you like code-along courses this is for you\n\n\\- Explains Neural Style Transfers and VGG well\n\n**Cons:**\n\n\\- He doesn't step outside a few things, but the things he teaches are taught very well too! So it's not a real con per se\n\n\\- Code along courses are good, but tend to waste a lot of time for me. I get why many people like it, but to me, it slows me down (could just be my impatience)\n\n\\- It lacks a wide variety of projects\n\n**Score - 4.3/5**\n\n**NOTE**: The lazyprogrammer has a second course that seems quite good on GANs and Variational Autoencoders\n\n[https://www.udemy.com/deep-learning-gans-and-variational-autoencoders/?couponCode=REDDITCV](https://www.udemy.com/deep-learning-gans-and-variational-autoencoders/?couponCode=REDDITCV)\n\n&amp;#x200B;\n\n[Deep Learning for Computer Vision with Python - Practitioner Bundle](https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/) \\- Created by [Adrian Rosebrock](https://www.pyimagesearch.com/author/adrian/)\n\n(**NOTE** Adrian provided a 10% Coupon:  **reddit**)\n\nThis is the mother load. Absolute perfect and monster of a course! Now it's expensive compared to the others, but this course teaches almost everything you'll need. I wish the ImageNet Bundle was included at this price, but that module is over $600. This course covers all key areas of Deep Learning in Computer Vision. It does not have any OpenCV (well some, but PIL or imultils are used more often). The videos aren't detailed, you're paying for the detailed textbooks, the videos are pretty much overviews of each chapter. So, yes the course material and code is where the value is, and it's excellent in quality!\n\nThe code isn't always super easy to follow, but he explains almost every line in the book so it's not a complaint, just stating that this isn't a course that's going to be easily accessible to begineers. Also, like some of the others above, it comes with a Virtual Machine with all packages pre-installed.\n\n**UPDATE**: I initially rated the value of this course as 3.5/5 but I'm bumping it 4.1. Adrian and his community will offer to very good help to your research projects etc. So if you're stuck on need advice, it's valuable. Rajeev and Jose will often offer similar support in their Udemy forums, but Adrian's depth and expertise shines if the problem is particularly hard or grounding breaking.\n\n&amp;#x200B;\n\n**Pros:**\n\n\\- Probably the best resources for Practical Deep Learning Computer Vision online\n\n\\- Excellent explanations by a very experienced and passionate teacher\n\n\\- All code is explained nicely\n\n\\- Because of his experience, you know he covers the most relevant and important topics\n\n**Cons:**\n\n\\- Not for beginners, obviously, but it should be noted if you're a beginner you will feel overwhelmed going into this course\n\n\\- Explanations on video are mostly fluff, he doesn't really teach. It's more of an overview of what's covered in the book (which is the real meat of the course)\n\n\\- Expensive!\n\n**Score - 4.5/5**\n\n&amp;#x200B;\n\n**CONCLUSION**\n\n&amp;#x200B;\n\nEven though I initially rated Rajeev's Udemy course the highest, it's only because of the insanely cheap price of $10. It's a great course and I keep coming back to it a lot. That said, when it goes up against Adrian's $300. It can't compete with the detail and explanations offered in Adrian's text. And I don't know how I missed Andrew Ng's Coursera's course, but the theory explanations in that course are best out all so far (Rajeev and Adrian do an excellent job too).\n\n&amp;#x200B;\n\n**NOTE**: I got around to reviewing Adrian's other bundles. I have a friend who purchased the ImageNet Bundle and he lent me the printed text (which has been updated since). But I don't have access to the videos. Here's a quick summary of the PyImage 3 Bundles\n\n* STARTER BUNDLE - Very good value and an excellent resource. Covers all the basics in detail but doesn't get into more advanced and cooler areas of computer vision such as Object Detection and advanced CNNs.\n* PRACTITIONER BUNDLE - Highly recommend you purchase this instead of the Starter Bundle. It's excellent and covers pretty much everything you'd need to know in Computer Vision Deep Learning\n* ImageNet Bundle - It's excellent, but to me not really worth double the price of the Practitioner Bundle. It does have some nice projects and some advanced stuff. I was impressed nevertheless, but in terms of actual theory and knowledge, it's not much new content when compared to Practitioner Bundle.\n\n&amp;#x200B;\n\nIn summary, I'll put it like this. For a $10 Udemy course, Rajeev's course will take you from beginner to a working professional. But to be an expert, you'll need Adrian's (of PyImage) course. Andrew Ng's course will ensure you're understanding key concepts right, it's brilliant in breaking down the theory.\n\n&amp;#x200B;\n\nFeel free to ask me any questions on the above courses.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/daxyda/update_reviews_of_8_python_deep_learning_computer/"}, {"autor": "murphinate", "date": "2019-09-29 16:31:08", "content": "Hi guys, new to the subreddit. I am taking the Udacity course on DL and I am quite enjoying it. The questions I am asking are from [Goodfellow et al's textbook from deeplearningbook.org/contents/prob.html](http://www.deeplearningbook.org/contents/prob.html), which is recommended supplementary material for the course.\n\n**Question 1 - Softplus Useful Properties**\n\nSection 3.10 *Useful Properties of Common Functions* has a subsection on Softplus, particularly a list of softplus functions which are recommended as useful enough to be worth memorizing. Can someone show me some more material as to why these properties are worth memorizing? It helps me to want to memorize something if its usefulness can be made apparent to me.\n\n&amp;#x200B;\n\nhttps://i.redd.it/5uvettjd8kp31.png\n\n**Question 2 - Kullback-Leibler (KL) Divergence vs Cross-entropy**\n\nSection 3.13 *Information Theory* discusses the KL Divergence as an asymmetrical measure of statistical difference. We covered the concept of **cross-entropy** in the Udacity course, and it made sense intuitively at the time. After reading about the KL Divergence, I am now confused. Would cross-entropy still suffer from asymmetry? Why would you use KL Divergence if you could just use cross-entropy? What is the big -----> picture !!!  here? I still understand it as iteratively adjusting weights and bias such that cross-entropy is minimized, and there are many ways to do that, but running operations against cross-entropy is one convenient way to do it? Yet not completely because of asymmetry.\n\n&amp;#x200B;\n\n**Question 3 - Graph Probability Model Representations**\n\nSection 3.14 *Graphical Models* ends by saying these methods are merely ways of **describing** probabilistic relationships and model architecture. Can someone give me an example as to when resorting to a Graph representation of their probabilistic relationships helped them to solve a problem? I want to make sure I understand its value as a tool in the belt.\n\n&amp;#x200B;\n\nThanks guys.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/daxg4l/three_questions_softplus_properties/"}, {"autor": "ransudz", "date": "2019-09-28 20:20:25", "content": "I'm am running ssd_inception_v3_pets sample config on a data set of 200 images of my dog (roughly 4000x4000 pixels and 3MB per -----> photo !!! ). \n\nDuring training, tensor flow first eats up 16GB system ram then 8GB swap and then crashes \n\nSpecs:\nRyzen 1600\nGtx 1060 3GB\n\nIs there anything I can do?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dalatp/tensorflow_crashes_with_low_ram/"}, {"autor": "GoBacksIn", "date": "2019-08-22 09:46:00", "content": "&amp;#x200B;\n\n  I'm using this now. and GPU memory is sufficient.\n\n&amp;#x200B;\n\n    config = tf.ConfigProto() \n    config.gpu_options.allow_growth = True\n    sess = tf.Session (config = config)\n    \n    model = CuDNNLSTM()\n    ...\n\nBut  I have had a lot of errors when I run the program at the same time.  \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nlike \n\n    Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\n\n&amp;#x200B;\n\n    tensorflow.python.framework.errors_impl.InternalError: GPU sync failed\n\nSo,  I wonder if it is the best code to minimize errors when running multiple Python programs at the same time\n\n&amp;#x200B;\n\nmy environment is Python3.6, Windows10 64bit, conda64bit\n  \n\n  \nand CuDNN version is 10.0\n  \n\n  \nbelow is pip list\n  \n\n  \nabsl-py                            0.7.1\n  \nalabaster                          0.7.12\n  \nanaconda-client                    1.7.2\n  \nanaconda-project                   0.8.3\n  \nasn1crypto                         0.24.0\n  \nastor                              0.7.1\n  \nastroid                            2.2.5\n  \nastropy                            3.2.1\n  \natomicwrites                       1.3.0\n  \nattrs                              19.1.0\n  \nBabel                              2.7.0\n  \nbackcall                           0.1.0\n  \nbackports.os                       0.1.1\n  \nbackports.shutil-get-terminal-size 1.0.0\n  \nbeautifulsoup4                     4.8.0\n  \nbitarray                           1.0.1\n  \nbkcharts                           0.2\n  \nbleach                             3.1.0\n  \nbokeh                              1.3.4\n  \nboto                               2.49.0\n  \nBottleneck                         1.2.1\n  \ncertifi                            2019.6.16\n  \ncffi                               1.12.3\n  \nchardet                            3.0.4\n  \nClick                              7.0\n  \ncloudpickle                        1.2.1\n  \nclyent                             1.2.2\n  \ncolorama                           0.4.1\n  \ncomtypes                           1.1.7\n  \ncontextlib2                        0.5.5\n  \ncryptography                       2.7\n  \ncycler                             0.10.0\n  \nCython                             0.29.13\n  \ncytoolz                            0.10.0\n  \ndask                               2.3.0\n  \ndecorator                          4.4.0\n  \ndefusedxml                         0.6.0\n  \ndistributed                        2.3.0\n  \ndocutils                           0.15.2\n  \nentrypoints                        0.3\n  \net-xmlfile                         1.0.1\n  \nfastcache                          1.1.0\n  \nFlask                              1.1.1\n  \nfsspec                             0.4.0\n  \ngast                               0.2.2\n  \ngevent                             1.4.0\n  \ngreenlet                           0.4.15\n  \ngrpcio                             1.20.1\n  \nh5py                               2.9.0\n  \nheapdict                           1.0.0\n  \nhtml5lib                           1.0.1\n  \nidna                               2.8\n  \nimageio                            2.5.0\n  \nimagesize                          1.1.0\n  \nimportlib-metadata                 0.19\n  \nipykernel                          5.1.2\n  \nipython                            7.7.0\n  \nipython-genutils                   0.2.0\n  \nipywidgets                         7.5.1\n  \nisort                              4.3.21\n  \nitsdangerous                       1.1.0\n  \njdcal                              1.4.1\n  \njedi                               0.15.1\n  \nJinja2                             2.10.1\n  \njoblib                             0.13.2\n  \njson5                              0.8.5\n  \njsonschema                         3.0.2\n  \njupyter                            1.0.0\n  \njupyter-client                     5.3.1\n  \njupyter-console                    6.0.0\n  \njupyter-core                       4.5.0\n  \njupyterlab                         1.0.2\n  \njupyterlab-server                  1.0.0\n  \nKeras                              2.2.4\n  \nKeras-Applications                 1.0.7\n  \nKeras-Preprocessing                1.0.9\n  \nkeyring                            18.0.0\n  \nkiwisolver                         1.1.0\n  \nlazy-object-proxy                  1.4.1\n  \nllvmlite                           0.28.0\n  \nlocket                             0.2.0\n  \nlxml                               4.4.1\n  \nMarkdown                           3.1\n  \nMarkupSafe                         1.1.1\n  \nmatplotlib                         3.1.0\n  \nmccabe                             0.6.1\n  \nmenuinst                           1.4.16\n  \nmistune                            0.8.4\n  \nmkl-fft                            1.0.14\n  \nmkl-random                         1.0.2\n  \nmkl-service                        2.0.2\n  \nmock                               3.0.5\n  \nmore-itertools                     7.2.0\n  \nmpmath                             1.1.0\n  \nmsgpack                            0.6.1\n  \nmultipledispatch                   0.6.0\n  \nnbconvert                          5.5.0\n  \nnbformat                           4.4.0\n  \nnetworkx                           2.3\n  \nnltk                               3.4.4\n  \nnose                               1.3.7\n  \nnotebook                           6.0.0\n  \nnumba                              0.43.1\n  \nnumexpr                            2.7.0\n  \nnumpy                              1.16.4\n  \nnumpydoc                           0.9.1\n  \nolefile                            0.46\n  \nopenpyxl                           2.6.2\n  \npackaging                          19.1\n  \npandas                             0.25.0\n  \npandocfilters                      1.4.2\n  \nparso                              0.5.1\n  \npartd                              1.0.0\n  \npath.py                            12.0.1\n  \npathlib2                           2.3.4\n  \npatsy                              0.5.1\n  \npbr                                5.2.0\n  \npep8                               1.7.1\n  \npickleshare                        0.7.5\n  \nPillow                             6.1.0\n  \npip                                19.2.2\n  \npluggy                             0.12.0\n  \nply                                3.11\n  \nprometheus-client                  0.7.1\n  \nprompt-toolkit                     2.0.9\n  \nprotobuf                           3.7.1\n  \npsutil                             5.6.3\n  \npy                                 1.8.0\n  \npycodestyle                        2.5.0\n  \npycosat                            0.6.3\n  \npycparser                          2.19\n  \npycrypto                           2.6.1\n  \npycurl                             7.43.0.3\n  \npyflakes                           2.1.1\n  \nPygments                           2.4.2\n  \npylint                             2.3.1\n  \npyodbc                             4.0.27\n  \npyOpenSSL                          19.0.0\n  \npyparsing                          2.4.2\n  \npyreadline                         2.1\n  \npyrsistent                         0.14.11\n  \nPySocks                            1.7.0\n  \npytest                             5.0.1\n  \npytest-arraydiff                   0.3\n  \npytest-astropy                     0.5.0\n  \npytest-doctestplus                 0.3.0\n  \npytest-openfiles                   0.3.2\n  \npytest-remotedata                  0.3.2\n  \npython-dateutil                    2.8.0\n  \npytz                               2019.2\n  \nPyWavelets                         1.0.3\n  \npywin32                            223\n  \npywinpty                           0.5.5\n  \nPyYAML                             5.1.2\n  \npyzmq                              18.1.0\n  \nQtAwesome                          0.5.7\n  \nqtconsole                          4.5.3\n  \nQtPy                               1.9.0\n  \nrequests                           2.22.0\n  \nrope                               0.14.0\n  \nruamel-yaml                        0.15.46\n  \nscikit------> image !!!                        0.15.0\n  \nscikit-learn                       0.21.2\n  \nscipy                              1.3.1\n  \nseaborn                            0.9.0\n  \nSend2Trash                         1.5.0\n  \nsetuptools                         41.0.1\n  \nsimplegeneric                      0.8.1\n  \nsingledispatch                     3.4.0.3\n  \nsix                                1.12.0\n  \nsnowballstemmer                    1.9.0\n  \nsortedcollections                  1.1.2\n  \nsortedcontainers                   2.1.0\n  \nsoupsieve                          1.9.2\n  \nSphinx                             2.1.2\n  \nsphinxcontrib-applehelp            1.0.1\n  \nsphinxcontrib-devhelp              1.0.1\n  \nsphinxcontrib-htmlhelp             1.0.2\n  \nsphinxcontrib-jsmath               1.0.1\n  \nsphinxcontrib-qthelp               1.0.2\n  \nsphinxcontrib-serializinghtml      1.1.3\n  \nsphinxcontrib-websupport           1.1.2\n  \nspyder                             3.3.6\n  \nspyder-kernels                     0.5.1\n  \nSQLAlchemy                         1.3.7\n  \nstatsmodels                        0.10.1\n  \nsympy                              1.4\n  \ntables                             3.5.2\n  \ntblib                              1.4.0\n  \ntensorboard                        1.13.1\n  \ntensorflow-estimator               1.13.0\n  \ntensorflow-gpu                     1.13.1\n  \ntermcolor                          1.1.0\n  \nterminado                          0.8.2\n  \ntestpath                           0.4.2\n  \ntoolz                              0.10.0\n  \ntornado                            6.0.3\n  \ntraitlets                          4.3.2\n  \ntyped-ast                          1.3.4\n  \nunicodecsv                         0.14.1\n  \nurllib3                            1.24.2\n  \nwcwidth                            0.1.7\n  \nwebencodings                       0.5.1\n  \nWerkzeug                           0.15.5\n  \nwheel                              0.33.4\n  \nwidgetsnbextension                 3.5.1\n  \nwin-inet-pton                      1.1.0\n  \nwin-unicode-console                0.5\n  \nwincertstore                       0.2\n  \nwrapt                              1.11.2\n  \nxlrd                               1.2.0\n  \nXlsxWriter                         1.1.8\n  \nxlwings                            0.15.8\n  \nxlwt                               1.3.0\n  \nzict                               1.0.0\n  \nzipp                               0.5.2", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ctv47g/what_is_the_way_to_minimize_cudnn_error_when/"}, {"autor": "MRK-01", "date": "2019-08-22 05:32:40", "content": "I hope im in the right subreddit to ask this question. I have a data set of lets lets say 92 rows by 12 columns. The matrix represents the water level of each county over than span of 11 years . Each row is an array that contains the county name and its water level for 11 years (so each row is a size 12 array)\n\n[Anyways when i graph this matrix in parallel coordinates using a JavaScript library called d3.js](https://i.redd.it/0d55oh634xe31.jpg). This graph is normalized by the high and low values by the way. In the graph 1.0 is the normalized high and 0 is the low.\n\nThis is good so far but my main objective is to go through this mess and find counties that share a similar trend line. I came up of three ways of doing this but they aren't working as well. Here is my three methods:\n\n\\--------------------------------------------\n\n# 3 METHODS I USED TO FIND PATTERNS:\n\n**1) FINDING PATTERNS BY MANUALLY GOING THROUGH COUNTY TREND LINES:**\n\nFrom the graph above, you can easily identify several similar patterns. Im trying to find as many SIMILAR patterns as possible. I first did it by eye and grouped similar patterns (the results turned out ok but im sure i missed a few counties). obviously, this is not a good way to go about this. Here is the three ways i did it:\n\n**2) USING MY ALGORITHM TO FIND PATTERNS:**\n\nI made a simple algorithm that goes down the rows (goes through each data point of a county) and makes a string for that county that represent the behavior of that county. For example, if a county's line goes up, down, up: it will have a string of \"udu\" (im going to call this the **behavioral string** from now on). Once i have the behavioral string of all counties, i then looped through the rows/counties once again and looked for any other county that has the least common substring of...say 9 (there are 11 years, so the maximum length of the behavioral string is 10 since the initial year is used to measure the first up/down. 9/10 means that at least one year doesn't match) . I then put all of this into a dictionary where the key is the county name and the value is an array that contains the names of all counties that are 9/10 similar to this county.\n\nI though this was a pretty OK algorithm but the results showed a few patterns being there when they shouldn't be there. It was also leaving out many other patterns. I have made a much smaller example that will use this algorithm and the covariance matrix which i will explain below:\n\n**3) USING COVARIANCE MATRIX:**\n\nI was told by a redditor to do this but im still dont understand what this does in my case.\n\n\\--------------------------------------------\n\n# SMALL 5x5 EXAMPLE USING MY ALGORITHM AND COVARIANCE MATRIX:\n\n[So here i made a 5x5 matrix example to test these out:](https://imgur.com/2Ly4qyZ)\n\nThe -----> picture !!!  has 5 patterns (**a,b,c,d,e**). On the top right is a matrix of the graph's data. The middle matrix is me just rotating the matrix to do calculations for the covariance matrix. the 3rd and bottom matrix is the resulting covariance matrix (i used a online covariance matrix calculator).\n\n[This is the results for that 5x5 test](https://imgur.com/atqFRZe). Since there are 5 years, the maximum length of the on the behavior string can be 4. I made it so it will output only 3/4 of similar patterns. On top is me using my algorithm and outputting a matrix where the row arrays only have patterns that has 3 or more lest common substring. below that is the result of the corariance matrix", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ctszfz/how_can_i_finding_similar_patterns_in_rows_of_a/"}, {"autor": "lorenzo_fabbri92", "date": "2019-08-21 03:25:32", "content": "I'm training a CNN (ResNet18 and 34) with Adam and either StepLR or CosineAnnealingLR (LR=0.0001).\n\nI always face the same issue: both the training and validation accuracies plateau at around 9 epochs (see -----> image !!!  below). I switched to ResNet34 because I thought ResNet18 was not enough for this task (Recursion Cellular Image Classification on Kaggle), but the behaviour is the same. Any idea? Should I increase the complexity of the model even more?\n\nhttps://i.redd.it/w7a4hzqj0qh31.png", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ctb3tv/cnn_training_and_validation_accuracies_plateau/"}, {"autor": "SirSourPuss", "date": "2019-08-20 15:15:33", "content": "I'm working on integrating [an implementation of a recurrent visual attention model](https://github.com/kevinzakka/recurrent-visual-attention/) with a video dataset (EPIC Kitchens), and I'm struggling to get this model to run with more than 1 video in a batch at a time.\n\nBackground: the model I am trying to overhaul is as recurrent model that focuses on different parts of MNIST images to classify them. For each -----> image !!!  the model takes a 'glimpse' of the input -----> image !!! , which is essentially a cropped out -----> image !!!  patch, and combines it with the glimpse location to produce the 'hidden state' RNN vector which is then used to choose the location of next -----> image !!!  patch, or to make a prediction about the -----> image !!!  class. Essentially the network behaves more human-like by focusing on different parts of the image based on what it has seen so far.\n\n&amp;#x200B;\n\nI've successfully made the network run on videos from EPIC Kitchens, but the training is incredibly slow. This is because of very slow data loading. I expected training to be quite slow given the video format and the fact that I don't have an SSD (will get one at some point), but it's *too* slow. I need to be able to experiment fairly rapidly. I figured it's largely due to having set batch size to 1, and here is where my current problem comes in. By default PyTorch won't accept batches of variable length video clips, and it will throw an error at data loading. Luckily, PyTorch has a class called [PackedSequence](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.PackedSequence) for 'packing' variable length sequences by padding them with 0s and all of its RNN modules ignore padding so as to be more computationally efficient.\n\nThat's all neat, but I don't use Pytorch's RNN modules and I don't understand how to integrate [PackedSequence](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.PackedSequence) into my model. I'm looking at the documentation for [modules.rnn](https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html) and it's not helping at all (in the definition of forward() for the RNNBase class what does *hx* even stand for?).\n\nDoes anyone here have any experience with integrating PackedSequence into custom RNNs, or with solving this issue in another way?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ct0i4o/pytorchs_packedsequence_and_custom_recurrent/"}, {"autor": "vigbig", "date": "2019-08-20 12:17:55", "content": "I am implementing this via Python using OpenCV.\n\nI  am learning this from scratch and from what I learnt is that I need a  lot of pictures to train the algorithm to recognize one person. Now I  don't know how much is required as many tutorials say more the better ,  and why I ask is I have to make this not for a student but for an entire  class.\n\nSo far I just learnt how to capture a face on -----> camera !!!  using Haar Cascade Classifier, that is it.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/csxskp/i_am_building_a_face_recognition_algorithm_that/"}, {"autor": "avdalim", "date": "2019-08-20 11:48:19", "content": "I want to preprocess Images for a CNN. I have them unsplitted in different folders with the Label as the Folder name.\n\nI need to Import the Pictures, Label ,resize, shuffle and split them and then feed them to a Keras CNN. The books I'm learning with only show already preprocessed -----> Image !!!  datasets, so i have no tutorial.\n\n&amp;#x200B;\n\nI'm using Tensorflow 2 and Keras.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/csxd87/how_do_i_preprocess_images_with_folder_names_as/"}, {"autor": "Rasico2", "date": "2019-09-08 00:12:47", "content": "I'm new machine learning/deep learning and am really just getting started. Apologize if this question was posted before, I'm not sure what terminology to search for. \n\nI'm working with a problem analogous to 1D -----> image !!!  processing. I'm working on what is essentially object detection and localization where if I detect an object I want to determine it's center and bounding box. If there is no object, then I don't care what those quantities are. Therefore I have 3 outputs: a 0/1 indicating an object exists,  object center and object width. I'm getting decent results, but I am working on improving sub-sample accuracy. \n\nIf The object doesn't exist I don't care what the object center and object width are. At the moment I just set those quantities to 0 for data sets where there is no object. However I don't actually care what a model predicts for width/center if the object exists quantity is 0. With the loss function I know of no way to account for don't cares. \n\nOn a related question, I'd also like to train on poorer quality data (think low SNR) where pulling out the precise location is difficult and I expect worse results. Is there a method of rating the data so poor quality data influences the model less during training?\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d13v85/representing_dont_cares_for_neural_networks/"}, {"autor": "sntnmjones", "date": "2019-09-07 18:55:28", "content": "I'm working on my senior project and it is to use opencv to find and report the number of empty parking spots available. The -----> camera !!!  is at an angle so I'm afraid template matching won't work. If I'm going to train a model, but I only care about empty spots, would I also include not empty spots in the training? I don't need to detect nor care if a spot is occupied. Thank you in advance.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d100a8/train_a_model_if_i_only_want_to_find_one_object/"}, {"autor": "rLoper", "date": "2019-09-07 16:05:47", "content": "I am working on my first ML project ( It's more a toying data sat than a project but whatever) and I stumbled across few features that are problematic and I don't know how to deal with them. It is Basement and 2nd floor area in square feets. Like shown on -----> picture !!! , there are some that don't have a 2nd floor but that doesn't mean that they will cost less, there are some houses that have one floor but are good so they cost more. On the other hand, the rest of the houses ( the ones that have the 2nd floor) seem to follow a polynomial pattern. \n\nI have no idea how to deal with this so I am gonna discard the feature for now.\n\n[Scatter plot ](https://i.redd.it/w2li445n37l31.png)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d0xu0h/problem_with_dealing_with_a_feature_in_a_housing/"}, {"autor": "Laope94", "date": "2019-09-07 12:52:50", "content": "So... I am working on this project, which goal is emotion classification from speech. I am sticking to 7 basic emotions as defined by Ekman. While researching, I've came across one very interesting approach - instead extracting numeric features from audio file (e.g. fundamental frequency, formant frequencies, energy...) it uses images in form of spectrograms as input into convolutional neural network. It had surprisingly good result in paper I saw, so I've decided to do my own experiment.\n\nAudio is converted into spectrogram, which looks like this:\n\nhttps://i.redd.it/36f6h9drv5l31.png\n\nI've turned off axis markings, but X axis represents time, Y axis represents frequency (starting on 50 Hz and ending on 4000 Hz. Colour represents intensity - the brighter the colour, the louder given frequency was in given time. Black means that given frequency was not present at all, very bright colour means that it was very loud. \n\nAnd there goes my problem - the biggest problem in emotion recognition is data. There are few publicly accessible databases of emotions usually recorded with actors. I am using Ravdess database which contains 192 audio files for each emotion (50:50 male and female) and only half for neutral emotion, that means I have 1248 spectrograms (btw all of them have same size) and 7 categories and that is of course way too few. My network suffered from overfitting, It reached 95-100% accuracy and extremely small loss basicaly in no time, but validation accuracy would't go over 60%, my best result was about 58%. After spending few days twisting inner structure of network, I've decided to focus on dataset itself instead.\n\nWhat I did is that I took all original images and I added 20% gaussian noise via batch automate in Photoshop. Furthermore, I rotated both original images and images with noise by 90 degrees. \n\n&amp;#x200B;\n\nExample:\n\nThis is original -----> image !!! :\n\n[Original Image](https://i.redd.it/3i3r16ia06l31.png)\n\nAnd these are augmentations derived from it: \n\n[Original -----> image !!!  + gaussian noise](https://i.redd.it/xq02kosf06l31.png)\n\n[Original -----> image !!!  + gaussian noise + 90 degree rotation](https://i.redd.it/qs8g8xsf06l31.png)\n\n[Original -----> image !!!  + 90 degree rotation](https://i.redd.it/fc4ayysf06l31.png)\n\nAnd now I did this - I kept all original images as validation set and all augmentations as training set, therefore I have 3744 images for training and 1248 for validation. Suddenly my network performed very well, I've reached about 97% accuracy and 99% validation accuracy. But I am slightly insecure that despite numbers this might not be right at all. Validation accuracy was much higher during training than accuracy, in first epoch I've reached 70% accuracy and 96% validation accuracy. Let's say this is due dropouts and it's okay. However, what bothers me the most is that original image + rotation is actually the same as original without rotation, or isn't it? I shouldn't have very same images in training set and in validation set. Is this still same image for neural network too? I mean, is my approach to data augmentation valid or good result I've got is caused by the fact that network indeed had same data for training and validation?\n\nIf this is all wrong, how else can I enlarge dataset? I probably want to avoid cropping, zooming and prespective transformations since spectrogram carries information about time and frequency on axises.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d0vlrw/am_i_getting_data_augmentation_right/"}, {"autor": "PartlyShaderly", "date": "2019-09-06 16:10:47", "content": "See, -----> image !!!  I have this data set:\n\n&amp;#x200B;\n\nX    Y   Z\n\n0    1   2018.3.12\n\n1    3   1924.1.4\n\n,     .     ..............\n\n.    .     ...............\n\n4   1    1870.2.1\n\n&amp;#x200B;\n\nI want to train an LSTM that will predict X and Y given the Z. But every LSTM tutorial I read says that train\\_X should be X and Y, and train\\_Y should be Z. I don't understand. This way it's all topsy-turvey, making the other way around: Give X and Y to get Z. But I want to give Z to get X and Y.\n\n&amp;#x200B;\n\nAlso, another question. How can I make time and date into a machine-readable format? Like a float? Thanks again.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d0ipyh/im_very_very_confused_about_time_series_and_lstm/"}, {"autor": "Zenith_N", "date": "2019-09-04 12:43:04", "content": "I have the following specs for a laptop from thinkpad. \n\nPlease let me know if it would be an ideal choice for future proofing personal projects. \n\nObjectives: \n\n**1-Machine Learning / Deep Learning** \n\n**2-Gaming**\n\nPrice: $3400 \n\n* Processor : Intel\u00ae Xeon\u00ae E-2276M with vPro\u2122 (2.80GHz, up to 4.70GHz with Turbo Boost, 6 Cores, 12MB Cache)\n* Operating System : Windows 10 Pro for Workstations 64\n* Operating System Language : Windows 10 Pro for Workstations 64 English\n* Memory : 8GB DDR4 2666MHz\n* First Hard Drive : 256GB Solid State Drive, M.2 PCIe-NVMe, Opal\n* Storage Total Capacity : 256GB\n* Display : 15.6\" FHD (1920 x 1080) IPS, 500 nits, anti-glare with Dolby Vision\u2122 HDR 400\n* Graphic Card : NVIDIA Quadro RTX5000 16GB\n* Fingerprint Reader : Fingerprint Reader\n* Keyboard : Backlit Keyboard with Number Pad - US English\n* -----> Camera !!!  : 720p HD camera with ThinkShutter\n* Pointing Device : Fingerprint\n* TPM Setting : Enabled Discrete TPM2.0\n* Battery : 6 Cell Li-Polymer, 90Wh\n* Power Cord : 230W AC Adapter\n* Wireless : Intel AX200 Wi-Fi 6 802.11AX (2 x 2) &amp; Bluetooth 5.0", "link": "https://www.reddit.com/r/learnmachinelearning/comments/czkcma/please_help_me_choose_a_laptop/"}, {"autor": "gaiaprime27", "date": "2019-09-04 06:08:27", "content": "I'm aware we can run models on Android using tflite but all the examples I've come across involve the input as an -----> image !!!  i.e., -----> image !!!  classification or object detection. The model I'm currently working takes the smartphone sensor data as input for inference. Is it possible to deploy such models on Android with said input? I'm fairly new to ML so pardon if my approach is wrong.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/czgxgi/tensorflow_on_android/"}, {"autor": "chrisvacc", "date": "2019-09-04 00:25:04", "content": "I'm a traditional Data Scientist trying to improve my skillset.\n\nThis paper inspired me:\n\n[Predicting Methylphenidate Response in ADHD Using Machine Learning Approaches](https://www.ncbi.nlm.nih.gov/pubmed/25964505)\n\nI like the idea of just feeding an algorithm a dataset and letting it figure out the predictive utility of each variable, like so. I figure the titanic problem is a good place to start. Any suggestions on where to learn this type of machine learning? I don't need to learn NLP, Speech Recognition, -----> Image !!!  recognition, just yet, so I'd like to start with stuff like that. Suggestions?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/czdccm/whats_the_fastest_way_to_learn_how_to_do_titanic/"}, {"autor": "RedXabier", "date": "2019-09-03 16:56:26", "content": "Hi for my my final year of my undergraduate CS course we have a year long project to do, I want to pick a project that is suitable challenging but definitely achievable for someone like me who is new to ML. I would probably spend the first half of the year learning the relevant theory and maths required (my course is not maths heavy so I\u2019ll have to learn the maths required) as well as making a plan, then the second half actual implementation.\n\nHere are my 2 possible ideas atm:\n- art style transfer using GAN, e.g apply Monet style to given -----> image !!! \n- simple cocktail party problem - separate out two voices from 2 different audio sources (apparently the proper cocktail party problem is currently unsolvable / v tricky but if it\u2019s just 2 audio sources o separate is it a lot simpler?)\n\nAre these viable for my ability? I have just started the Andrew Ng ML course and have experience w Python. I know and was capable w high school level maths but not done any at undergraduate level. A lot of the project workload  is the accompanying detailed report on methodology and such.\n\nThanks for any help!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cz7jbi/are_these_ideas_viable_to_do_for_my_final_cs_uni/"}, {"autor": "Loin1210", "date": "2019-09-03 11:17:21", "content": "Hello everyone, I really a mentor that can guide me in machine learning. I have been stuck for 6 days straight without any progress. I am desperately in need of help for trash detection. I want to make use of machine learning to detect the trash on the ground based on the -----> image !!! . I understand the concept of machine learning but i have no idea how i am suppose to start. I\u2019m reaching the deadline in 2 days, I am hoping someone here can help and guide me. This have been killing my brain so much, i\u2019m starting to panicking. i\u2019m sorry that i have to request help from here.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cz3h38/in_need_of_help_in_understanding_of_machine/"}, {"autor": "laslavinco", "date": "2019-04-29 14:06:21", "content": "So, i wanna start with machine learning. I have tried couple of youtube vids but as you guessed not working for me.\n\nI am mostly looking into theory and practical based explanations . BTW i wanna work mostly with the -----> image !!! s using cv2, like -----> image !!!  classifications and -----> image !!!  restorations and stuff. I am open to all kind of materials i can get my hands on like youtube or books or web articles, anything would do. \n\nThanks a lot :)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bipvbf/suggestions_for_beginner_into_the_ml/"}, {"autor": "tim-hilt", "date": "2019-04-29 08:09:45", "content": "I want to train an -----> image !!! -classifier, that outputs if a pigeon is in the frame or not. I have collected around 700 pictures of pigeons, but now I don't know how I should procede. The way I understand it, when I connect the model to a live feed from a webcam, the application would output the probability for a pigeon being in the frame. For my needs it would suffice to know this probability; I want to trigger an action, whenever the probability is above 0.8 or something around that.\nShould I also include negative examples in my dataset or can the classifier learn without any of that?\nIf so, how should those negative examples look? Should I include images from other birds or just random objects for better results?\nI would want to try the above with Ludwig taking care of the training of the image and then porting the whole thing to tensorflow for comparison. \nLudwig needs a .csv that looks like:\n\nImage, class\nPicture1, pigeon\nPicture2, pigeon\nPicture3, not_a_pigeon\n...", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bimz8w/structuring_dataset_for/"}, {"autor": "ML_hack", "date": "2019-04-28 22:47:51", "content": "Hi there fellow machine learning learners,\n\nI'm looking to use Resnet (probably Resnet50) in my own -----> image !!!  classification project. Do any of you happen to know of a resource that would walk a relative newbie through the process of employing Resnet in Keras + Python? \n\nWould appreciate any assistance you could provide.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bih3zg/using_resnet_in_my_own_image_classification/"}, {"autor": "Spaceman776", "date": "2019-04-28 21:02:28", "content": "Hi, I am going to be presenting a small project involving -----> image !!!  classification using TensorFlow that I worked on to my class. The majority of the presentation, I want to talk about how TensorFlow works and how it is able to classify images. Are there any good resources or lectures out there for something like this? My classmates and I have some very basic knowledge of machine learning (two 50 minute lectures) so I am looking for something that is introductory but informative if possible. Any suggestions?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/big0hq/want_to_give_a_presentation_on_image/"}, {"autor": "s3afroze", "date": "2019-04-27 22:23:30", "content": "Hey guys,\n\nI wanted to train an -----> image !!!  classifier similar to the one show on silicon valley concerning hotdog and not a hotdog. I have done some projects on the side for fun but I am not a professional from any angle. I came across this GitHub:\n\n[https://github.com/kmather73/NotHotdog-Classifier](https://github.com/kmather73/NotHotdog-Classifier)\n\nHe extracted the data from imagenet which is currently down for maintenance.  I wanted to ask given the problem statement where we only care if the image is a hotdog or not, how should the negative instances be collected. The author for the project on GitHub link used categories like \u201cfurniture\u201d, \u201cpeople\u201d and \u201cpets\u201d  but I am curious why use these specific categories and how should someone decide for the number of instances with these categories given a similar problem statement. I know the problem statement will be highly imbalanced which attracted me to the problem statement.\n\n&amp;#x200B;\n\nAny comments will be highly appreciated : )", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bi4don/some_guidance_needed_for_a_passion_project/"}, {"autor": "damnko", "date": "2019-04-25 09:15:46", "content": "Hi, I'm getting into the field of Visual Recognition and was following some tutorials on simple -----> image !!!  classification using pre-trained models.\n\nI've seen two different approaches:\n\n* One simply loads the model, eg. Inception, initialized with the weights generated from training on eg. Imagenet, freezes the conv layers and appends some dense layers to adapt to the specific classification task one's working on.  \nSome references are: [\\[1\\]](https://towardsdatascience.com/keras-transfer-learning-for-beginners-6c9b8b7143e), [\\[2\\]](https://towardsdatascience.com/transfer-learning-for-image-classification-using-keras-c47ccf09c8c8), [\\[3\\]](https://www.kaggle.com/suniliitb96/tutorial-keras-transfer-learning-with-resnet50), [\\[4\\]](https://heartbeat.fritz.ai/how-to-fine-tune-resnet-in-keras-and-use-it-in-an-ios-app-via-core-ml-ee7fd84c1b26)\n* On [this keras blog tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) the process seems more convoluted: runs train/test data through the VGG16 model once and records in two numpy arrays the output from the last activation maps before the fully-connected layers. Then trains a small fully-connected model on top of the stored features (the weights are stored as eg. `mini-fc.h5`). At this point if follows a procedure similar to approach #1 where it freezes the first convolutional layers of VGG16 (initialized with weights from imagenet) and trains only the last conv layers and the fully connected classifier (which is instead initialized with the weights from the previous training part of this approach, `mini-fc.h5`). This final model is then trained.\n\nWhat's the difference/benefits of the two approaches? Are those distinct examples of Transfer Learning vs Fine Tuning? The second one was written in 2016 and I wonder if it's still a valid approach since I've seen it only on that keras blog post.\n\nThanks for your support", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bh6hl8/whats_the_difference_between_these_2_approaches/"}, {"autor": "Laurence-Lin", "date": "2019-04-25 06:31:56", "content": "In LeNet, for example, if I have input -----> image !!!  \\[1, 32, 32, 1\\] and to the first convolution layer which have 6 filters, we have filter size \\[5, 5, 1, 6\\].  \nThe output feature map have size: \\[1, 28, 28, 6\\], this is understandable in theory. But in the tensorflow datatype, this means that the output is one batch of feature map size 28\\*28, which have 6 channels. This 6 channels confuses me, in my opinion the output should be like 6 feature map, with each size 28\\*28.\n\nSecond, if I output the upper feature map \\[1, 28, 28, 6\\] into next convolution layer, I want 16 output feature map, with filter: \\[5, 5, 6, 16\\], output should have size \\[1, 22, 22, 16\\], how is the convolution down? Will the output of each feature map add the convolution of 6 channels together?  \n\n\nThe convolution batch and channel is a hard understanding question to me, hope for detail explanation. Thanks for helping!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bh5ee4/i_have_problems_about_convolution_output_channels/"}, {"autor": "hypo_hibbo", "date": "2019-09-16 15:48:21", "content": "Hi,\n\nI am working on reducing artefacts in medical -----> image !!!  data, using a CNN.\n\nCurrently I am using a loss function, based on MAE and MS SSIM. I had the idea, that it might be worth a try doing the training on the image patches, but calculating the validation loss on whole images.\n\n I am currently doing training and validation on image patches of size 64x64. The training and validation image patches are taken from images of size 150x250 (some are bit bigger, some smaller, because I apply some pre processing to cut off the background that doesn't show interesting content). Training and validation are done on 64X64 images. \n\nTraining on patches and validation on whole images should be something like this:\n\nThe training/weight adjusting part of an epoch should be my standard procedure of iterating randomly over the 64x64 image patches, using them as input for the network, compare them with the artefact free goal image patches via my loss function... etc. \n\nAfter this training steps, the following validation should take place at the end of an epoch:\n\n*1.Take an image from the validation set*\n\n*2. divide it in patches.*\n\n*3. Filter all single patches with the current CNN.*\n\n*4. Merge the patches back together, to reconstruct the old image*\n\n*5. compare goal image with the filtered image with a MAE and MS SSIM based loss metric*\n\nI have no idea, how I could specify, that the special pre and post processing (divide the image for filtering with the network, merge it back together for the loss) should be done for the valdidation step.\n\n&amp;#x200B;\n\nDoes someone know some openly accessible code where something similiar has been done? I haven't found anything like this so far, but I also don't really know good keywords to look for.\n\nI think I really need some inspiration for implementing something like this\n\n&amp;#x200B;\n\nThanks for your help :)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d52ilg/keras_training_loss_on_patches_validation_on/"}, {"autor": "youshouldknowsz", "date": "2019-09-16 10:37:14", "content": "Good evening good sir\n\nI am a newbie with ML, i found this code from fellow redditor parasdahal.\n\nI can make it run with mnist datasets.\n\nHave few questions, i'd really really really appreciate it if someone can help me\n\n[https://github.com/iqbaalmuhmd/CNNnumpy](https://github.com/iqbaalmuhmd/CNNnumpy)\n\n&amp;#x200B;\n\n1. Is it possible to run only test, with our own -----> image !!!  input. Or just random image from mnist dataset\n2. What should i pickle to save the parameters?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d4yubr/convolutional_neural_network_with_numpy_input/"}, {"autor": "LivingPornFree", "date": "2019-09-15 17:29:58", "content": "I'm trying to take two 64x64 -----> image !!! s (one black and white and one color) and covert it into one 64x64 color -----> image !!! . After 4 epochs (which took me almost 36 hours because I don't have the best graphics card), these are the [results that I am getting](https://imgur.com/a/E78kOIF).\n\nYou can see that the output (the second picture) is much lower resolution. I mean, it's still 64 by 64, but it's really blurry. The way I see it, there are two possible explanations here:\n\n1. I messed up my architecture so that the upscaling prevents the model from predicting any more refined images than what I am getting. Or,\n\n2. I just need to train for longer (although this seems unlikely because the validation loss almost completely plateaued and wasn't getting better)\n\nHere is the model.summary() from Keras:\n\n&gt; Layer (type)                    Output Shape         Param #     Connected to\n==================================================================================================\ninput_1 (InputLayer)            (None, 64, 64, 1)    0\n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 64, 64, 3)    0\n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 32, 32, 64)   128         input_1[0][0]\n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 32, 32, 64)   1792        input_2[0][0]\n__________________________________________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_1[0][0]\n__________________________________________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_3[0][0]\n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 64)   0           leaky_re_lu_1[0][0]\n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           leaky_re_lu_3[0][0]\n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 8, 8, 128)    8320        max_pooling2d_1[0][0]\n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 8, 8, 128)    73856       max_pooling2d_3[0][0]\n__________________________________________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)       (None, 8, 8, 128)    0           conv2d_2[0][0]\n__________________________________________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)       (None, 8, 8, 128)    0           conv2d_4[0][0]\n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 128)    0           leaky_re_lu_2[0][0]\n__________________________________________________________________________________________________\nmax_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 128)    0           leaky_re_lu_4[0][0]\n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 4, 4, 256)    0           max_pooling2d_2[0][0]\n                                                                 max_pooling2d_4[0][0]\n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           concatenate_1[0][0]\n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 8, 8, 64)     147520      up_sampling2d_1[0][0]\n__________________________________________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)       (None, 8, 8, 64)     0           conv2d_5[0][0]\n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 8, 8, 64)     0           leaky_re_lu_5[0][0]\n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (None, 32, 32, 64)   0           dropout_1[0][0]\n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 16, 16, 3)    1731        up_sampling2d_2[0][0]\n__________________________________________________________________________________________________\nleaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 3)    0           conv2d_6[0][0]\n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 64, 64, 3)    0           leaky_re_lu_6[0][0]\n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 32, 32, 32)   896         up_sampling2d_3[0][0]\n__________________________________________________________________________________________________\nleaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 32)   0           conv2d_7[0][0]\n__________________________________________________________________________________________________\nup_sampling2d_4 (UpSampling2D)  (None, 128, 128, 32) 0           leaky_re_lu_7[0][0]\n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 64, 64, 3)    867         up_sampling2d_4[0][0]\n==================================================================================================\nTotal params: 235,110\nTrainable params: 235,110\nNon-trainable params: 0\n__________________________________________________________________________________________________\n\nIs this a sub-optimal network architecture? How can I fix it?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d4nkgj/is_my_network_architecture_ideal_for_pix2pix/"}, {"autor": "sicp4lyfe", "date": "2019-09-15 16:35:38", "content": "I've always been turned off by most pedagogy on ML is based around -----> image !!!  stuff. Could not have any less interest in the field but unforunately 100% of all material teaching ML techniques and theory is done via image based applications. Do i just have to put my appetite aside and learn this boring stuff so i can move back to my favourite area (speech analysis)?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d4mtpp/i_hate_the_image_classification_computer_vision/"}, {"autor": "everek123", "date": "2019-09-13 16:29:16", "content": "Hi, I would like to build a model which when given a -----> picture !!!  returns 5 most similar -----> picture !!! s. How could I approach this problem?\n\n&amp;#x200B;\n\nThanks", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d3rri2/finding_most_similar_images_using_neural_networks/"}, {"autor": "zacheism", "date": "2019-09-13 16:09:22", "content": "I know this sounds like a stupid question, but I have a dataset with millions of images and don't know the best way to store them.\n\nThe main issue is that I need to access overlapping subgroups of the images so I can't just zip everything up into one file. And when I each -----> image !!!  on its own, it takes about 24-40x longer (compared to one compressed file of all the -----> image !!! s) to transfer the -----> image !!! s from the bucket to whatever machine I am using -- and that is when the download process is multi-threaded.\n\nThis is the first time I am working with data of this size so I'm wondering if anyone has any tips or ideas as to how I can make the process faster and more efficient.\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d3rhcp/what_is_the_best_way_to_store_a_lot_of_images/"}, {"autor": "Brochenski", "date": "2019-09-13 03:47:33", "content": "Hey all, i'm using a microprocessor with a limited amount of ram to do -----> image !!!  differencing and blob detection. Since i have a limited amount of ram, i'm unable to store the highest resolution picture that my camera is able to take. I have the option of using RGB\\_888, RGB\\_565, and RGB\\_Greyscale. Additionally i have the ability to set the camera resolution from 1600x1200, down to 160x120.\n\nMy biggest desire is to be able to do the blob detection, and im not as concerned about the 'human' quality of the picture. \n\n&amp;#x200B;\n\nCan anyone tell me which one i can reduce the most while still being able to do blob detection effectively?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d3ji2p/blob_detection_priority/"}, {"autor": "DrdDoom", "date": "2019-01-16 09:48:15", "content": "I'm creating a CNN using python Keras to classify images that are only 8x8 pixels, so much smaller than the typical examples I see around. How would you suggest I design this CNN?\n\nTo prevent each layer shrinking the -----> image !!!  until it quickly dissapears,  I've tried using padded 0 Conv2D, only max pooling until nearly the  last step and using both 3x3 and 1x1 conv2D layers .\n\n&amp;#x200B;\n\nAny ideas, suggestions or links to similar projects?\n\nThanks.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/agjlgv/designing_a_cnn_for_tiny_images_8x8_pixels/"}, {"autor": "krtcl", "date": "2019-01-16 05:45:09", "content": "Hello, I just stumbled upon a this interesting [article](https://towardsdatascience.com/the-cold-start-problem-how-to-build-your-machine-learning-portfolio-6718b4ae83e9) about building a data science portfolio. One of the projects discussed is where one candidate decided to attach a -----> camera !!!  to his shopping cart and film shelves and then proceeded to build a model to identify which products needed to be stocked up again.\n\n&amp;#x200B;\n\nIt's a very inspiring approach to take to building a dataset. However, one thing that I am struggling to figure out is how do you think they went about labeling the traing dataset for building the model. Essentially, I am contemplating replicating such an experiment and was wondering how I could possibly go about doing so.\n\n&amp;#x200B;\n\n&amp;#x200B;", "link": "https://www.reddit.com/r/learnmachinelearning/comments/agi2l3/using_deep_learning_to_identify_missing_items_in/"}, {"autor": "BlueMustache", "date": "2019-01-16 03:26:05", "content": "Hi,\nSo I have a use case where I need to be able to trigger the execution of a program, using only an EEG headset. In early tests I was able to take EEG data, set some defined ranges, and get my program to execute about 40% of the time when thinking about a mental -----> image !!! . However, the success rate and processing delay aren't good enough for me. What I can do to improve the processing delay is to read the raw wave data. My TLDR is that I need to get my bootstrapping program to detect me thinking about a mental image with a high success rate, and I think that an application of machine learning would be appropriate for detecting patterns in raw wave data over a time domain. I was considering using an RNN with some sort of reinforcement learning, but I'm not certain. I'm new to machine learning, but willing to learn and read what I have to. Basically my idea was to train the network using the raw EEG data as an input, and hitting a button with my foot to tell it when I am thinking about the mental image. Later on the network would load up the training data, and make a sound when it surmises I'm thinking about my mental image, and I respond whether it's guess was correct or not. My big question is, is an RNN right for this application, and how do I define progress to it? Any resources on anything to this that you can give me would be greatly appreciated. Thank you for the read!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/aggyjt/help_selecting_a_nn_type_for_eeg_analysis/"}, {"autor": "g_surma", "date": "2019-01-14 16:29:20", "content": "&amp;#x200B;\n\nhttps://i.redd.it/50ly0isv0fa21.png\n\n[medium](https://towardsdatascience.com/style-transfer-styling-images-with-convolutional-neural-networks-7d215b58f461)\n\n[github](https://github.com/gsurma/style_transfer)\n\nIn today\u2019s article, we are going to create remarkable style transfer effects. In order to do so, we will have to get a deeper understanding of how Convolutional Neural Networks and its layers work. By the end of this article, you will be able to create a style transfer application that is able to apply a new style to an -----> image !!!  while still preserving its original content.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/afxgxa/style_transfer_styling_images_with_convolutional/"}, {"autor": "Laurence-Lin", "date": "2019-01-14 01:19:12", "content": "In AlexNet, after the first convolution for input -----> image !!! , the output channel has become 48. I'm not really understand for the three channel image convolution computation, is there any clear explanation?   \n\n\nThanks a lot!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/afqes4/during_convolution_for_three_channel_images_why/"}, {"autor": "FontofFortunes", "date": "2019-01-13 18:36:34", "content": "Hey Everyone,\n\nI've been consuming ML / deep learning theory from textbooks, but I'm now moving on to developing software to test out these ideas, including my own.\n\nI came across the Pima Indians example, which has been explored by a number of authors, usually including sample code and the data set. This was perfect to get me started with data sets consisting of a small number of real number features, leading to simple classification (probably the easiest way to start developing?). An example: https://datanonymous.wordpress.com/using-a-neural-network-to-predict-diabetes-in-pima-indians/\n\nI would love to collect similar simple starting point examples (code and dataset provided) from specific disciplines, namely:\n\n1) Audio processing (e.g. input audio files with tags, output classification as young/old, male/female, etc., speech-to-text seems like a future step)\n\n2) -----> Image !!!  processing (e.g. input cat/dog pics, output classification of type, perhaps OCR is even simpler)\n\n3) Text processing (e.g. input text, output classification of tone?)\n\n4) Other disciplines?\n\nMy plan either way is to delve into these from scratch using Python/Keras, but would love a jump start by working with an existing piece of code and probably more important, a known workable dataset, rather than trying to kludge together my own. My hope is to start with reasonably small problems so that I can tinker with my laptop.\n\nAny suggestions, especially specific examples from the disciplines, would be most helpful. Thanks.\n", "link": "https://www.reddit.com/r/learnmachinelearning/comments/afm8gg/what_are_the_best_examples_from_each_domain/"}, {"autor": "tirafesi", "date": "2019-01-30 11:09:35", "content": "I saw [this](https://spinningup.openai.com/en/latest/_images/rl_algorithms_9_15.svg) -----> picture !!!  on OpenAI's blog which I really liked.\n\nOne thing that is confusing me though, is regarding Hierarchical (Deep) Reinforcement Learning. Where in that graph would it fall under?\n\nFor example, Google Brain's [HIRO](https://arxiv.org/pdf/1805.08296.pdf) or OpenAI's [MLSH](https://arxiv.org/pdf/1710.09767.pdf).", "link": "https://www.reddit.com/r/learnmachinelearning/comments/albo03/hierarchical_deep_reinforcement_learning/"}, {"autor": "afartwithnoname", "date": "2019-01-29 18:30:23", "content": "Hello r/learnmachinelearning ! I'm posting here because I'm stuck entering the right shape into a CNN model.\n\nI have a huge dataset of Apple stock of 4 columns: \\[\"Low\", \"High\", \"Open\", \"Close\"\\]. I've reshaped it into matrixes of 12 X 4 and I have 8386 samples. So my x\\_train data has a shape of (8389, 12, 4). My y\\_train data is etiher \\[1,0\\] or \\[0,1\\], depending whether the new price went up or down; this has been classified with keras's one hot encoding tool keras.utils.np\\_utils.to\\_categorical(list(y\\_train))  and its shape is (8386, 2).\n\nLet's go on with the model. I've adapted an -----> image !!!  classifier code and tried to re adapt it to my data. Here's the code:\n\n    from keras import backend as K\n    model = Sequential()\n    model.add(Convolution2D(32, 1, 1, input_shape=(x_train.shape[1], x_train.shape[2])))\n    model.add(Activation('relu'))\n    #model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Convolution2D(32, 1, 1,))\n    model.add(Activation('relu'))\n    #model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Convolution2D(64, 1, 1))\n    model.add(Activation('relu'))\n    #model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Flatten())\n    model.add(Dense(64))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n\nThis didn't work because Convolution2D is expecting an extra dimension. So I reshaped my x\\_data from (8389, 12, 4) to (1,8389, 12, 4) with np.reshape(-1, array.shape\\[0\\], array.shape\\[1\\], array.shape\\[2\\]) and changed the input\\_shape to x\\_train.shape\\[1\\], x\\_train.shape\\[2\\], x\\_train.shape\\[3\\].\n\nThis finally worked, but I'm still not able to run the model.\n\n    model.compile(loss='binary_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    \n    model.fit(x = x_train, y = y_train, nb_epoch=1000, batch_size=32)\n    Output: Error when checking target: expected activation_5 to have shape (1,) but got array with shape (2,)\n\nI feel like this has something to do with my y\\_train data, but I don't understand how am I supposed to even reshape it.\n\nEven if I only run this\n\n    from keras import backend as K\n    model = Sequential()\n    model.add(Convolution2D(32, 1, 1, input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])))\n    model.compile(loss='binary_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['accuracy'])\n    \n    model.fit(x = x_train, y = y_train, nb_epoch=1000, batch_size=32)\n\nI get this error:\n\n    Error when checking target: expected activation_6 to have 4 dimensions, but got array with shape (8389, 2)\n\nCan anyone please help me? Any advice is deeply appreciated, I don't normally ask for help but in I feel like I've exhausted my options and really don't know where to go from here. Thanks in advance guys", "link": "https://www.reddit.com/r/learnmachinelearning/comments/al30bz/shaping_financial_stock_data_into_cnn/"}, {"autor": "stracki", "date": "2019-01-29 15:23:18", "content": " Hi guys,\n\nI want to use -----> image !!!  recognition in the context of search in an -----> image !!!  database (more specifically like \"this picture contains XYZ, here are similar pictures also containing XYZ\"). The application should be lightweight enough to work on a mobile device (like e.g. a Hololens).\n\nI looked for frameworks regarding image recognition and found the following:\n\n* Apache MxNet with Gluon API\n* TensorFlow Slim\n* PyTorch (maybe using fastai)\n* Caffe2\n\nDo you think, one of these would be suited for what I want to achieve? If so, which are specific advantages against the other frameworks. Are there any other recommendations? It should preferably be possible to use the framework with Python, it should be well-documented and it should already come with pre-trained models for image recognition.\n\nAnother possibility that I found, are Cloud services like Azure Computer Vision or Google Cloud Vision. Any opinions on those? Their free plans sounded a bit restricting, but those looked like a good option for an early app prototype.\n\nThanks in advance", "link": "https://www.reddit.com/r/learnmachinelearning/comments/al116k/which_technologiesframeworks_should_i_use_for/"}, {"autor": "dxjustice", "date": "2019-01-26 10:47:19", "content": "Often in tutorials, we observe that classification exercises involving MNIST images versus more complex examples (i.e. cats vs dogs) possess different neural network architectures, often with additional layers. I am aware that these have been chosen arbitrarily for optimal performance, but is there a golden rule for -----> image !!!  complexity and NN structure? A paper publication study on this perhaps?\n\n&amp;#x200B;\n\nSecondly, while it's easy to understand how image classification occurs via NN (filters for features, earlier layers screening for lower level features, with later layers screening for more complex patterns), I'm a bit confused as to how one could do the same for data (if any). Are there any examples?\n\n&amp;#x200B;\n\nThank you in advance", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ajzx5u/two_questions_regarding_the_practical_effects_of/"}, {"autor": "sfhx", "date": "2019-07-08 07:27:17", "content": "I'm a total newbie to ML, and the more I read, the more I understand that a lot of experience is required to choose the right methods and models. Most of what I've read refers to supervised learning, like e.g. -----> image !!!  recognition (from the classical MNIST sample onwards); yet, I'd like to test something more real, and related to unsupervised strategies (essentially, clustering), applying them to true data samples from my research field.\n\nGiving an account of true data would require a long discussion, and would be out of scope. So, I'm introducing here a simple, totally *fake scenario*, whose models are somewhat similar. Given this data model, I'd like to get suggestions about the best ML-based clustering techniques to use about it.\n\nSay we have to inspect a collection of about 100,000 used tickets related to a railway company of the past century. Each ticket is punched in different areas, according to the start and destination station, the number of trains catched in the fare, etc. We do no more know about each fare, its stations, how it connected to others, how the company and its network evolved in time, etc., but we'd like to infer as much as possible from the tickets.\n\nEach ticket has about 20 areas, and from each we can record all the punched areas. Also, tickets are dated, and may show different layouts, colors, etc., while still keeping the same areas.\n\nGiven that a number of factors determine which areas were punched, but we do not know anything in advance, a first desirable task should be finding out similarities and patterns among the punched tickets. So, we need some sort of clustering strategy, examining all the combinations of punched areas across all the tickets. There are a lot of ways in which the tickets could be grouped according to a lot of different features and their combinations, so this looks like a good problem for ML clustering.\n\nIn these terms, each ticket can be described with a fixed set of areas (slots), each being either punched (1) or not (0). If we assign some sort of ID to each area (e.g. letters: A, B, C...), we can list all the observed combinations with their frequency (e.g. A+C+E = 1,346).\n\nThis being the general data model, there are other complications in the distribution of the combinations; for instance, some tickets may split an area into 2 halves, so that we could punch A1 or A2 from what is a unique area A in another type of ticket. Thus, we have a model with even more slots, e.g. A, A1, A2, B, etc., where of course whenever A1 is punched this excludes that A will be ever punched (as it would imply a different type of ticket), and vice-versa. So, some regions are mutually exclusive; yet, we list all of them in a flat model for ML convenience.\n\nAlso, we can add a number of attributes to each ticket besides its date: layout, color, etc. Of course, the more are the groups I partition the tickets in, the more scattered become their distribution, and more confusing their clustering results; so I'll probably need a lot of experiments to get to the right balance, and be able to draw useful information from such metadata.\n\nThe idea is beginning the clustering with a set of maximally aggregated data, where all the attributes are just ignored, and then eventually introduce more and more attributes in each record. In addition to the punched areas combinations, these would give hints for more specialized clustering (e.g. groups might emerge by time, combinations, color...).\n\nGiven this scenario, I tried to have a first look at the data by a trivial algorithmic approach: for instance, I'd like to determine how the combinations are affected by the presence or absence of each single punched area. So, for each single area I collected all the combinations involving it, and calculated the ratios between the frequency of each other punched area and the frequency of the area being examined. I thus get a chart for each area, where the area under exam has frequency 1, and all the other areas a ratio between 0 and 1.\n\nIn this case, I'm directly looking for a specific type of patterns; but given the factors involved and their mutual relationships, further enriched by the addition of other metadata, this is a very limited insight. I suppose that some ML-clustering technique might help in at least provide hints about patterns emerging from data in such ways I could not even imagine at a first thought, so I could formulate hypotheses and test them with specific scenarios. If this is true, could anyone suggest what should I start looking for? Address to specific techniques, learning material, websites, etc. related to similar scenarios are all welcome. Thanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cahylh/newbie_hints_on_clustering_techniques/"}, {"autor": "mtsch11", "date": "2019-07-07 21:02:14", "content": "Hi,\n\nI'm a beginner in machine learning. I currently wanted to create a document scanner, at the beginning using the \"traditional\" way using OpenCV and the computer vision way.\n\nBut then i thought it would maybe be a good example to try and get into ML. I watched a few beginner courses regarding the concept of ML, tensorflow and so on.\n\nMy problem is I can't wrap my head around how I should approach this.\n\nMy requirements are:\n\n* Take an -----> image !!!  as input\n* Find the document\n   * Get the X,Y value where the edges are\n* Either optimize it right there or return the gathered information\n   * Meaning make a perspective transform\n   * Make it to black and white (this would be maybe better suited with a image library)\n\nAlso how should I structure my data to make the training as easy as possible? Also could I use a existing Image Segmentation model?\n\nI would be thankful for pointers into the right direction.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/cabxmi/use_machine_learning_to_scan_documents/"}, {"autor": "toaste_n_beanze", "date": "2019-02-21 13:06:40", "content": "My environment:\n\n* Python 2.7\n* tensorflow and keras\n* Google colab?\n\n\nI have a giant collection of multi-images, i.e. three images stored as one TIFF file, that I've done using numpy arrays and skimage.io.tifffile/ImageCollection. When imported as ndarrays, their dimensions are (3, 300, 300) each.\n\n\nThe individual images are like so:\n[see here](https://i.imgur.com/oDzrBgC.jpg) and [here](https://i.imgur.com/IFCod5A.jpg). As you can see, two of the \"particles\" have moved positions between the first and second -----> image !!! .\n\nMy objective is to train a NN to simply detect whether the \"particles\" have moved in the three image multi-image. The number of particles moved and how much they moved by is for a later date.\n\nI've got a keras/tf environment set up, I have a tagged training set, a validation set, and a larger set of all the multi-images.\n\nI have tried using a basic classifier example as seen in the [TF docs](https://www.tensorflow.org/tutorials/keras/basic_classification) but I can't seem to get it working.\n\nDoes this community have any ideas, suggestions or feedback for my current setup, ideas, the kind of model I should use, or anything that would help me classify these multi-images?\n\nAny help is appreciated.\n\n\n", "link": "https://www.reddit.com/r/learnmachinelearning/comments/at2xnz/what_kind_of_model_should_i_use_to_classify_tiff/"}, {"autor": "idlemang", "date": "2019-02-21 03:41:42", "content": "I am not so clear about the definition of adversarial examples.  Which one is correct? \n\n1) a pair of perturbed features and corrected label. For example, an -----> image !!!  that originally was panda and after adding some perturbation on -----> image !!! s the neural network would think it as cat. But the label is still panda.\n\nor\n\n2) a pair of perturbed features and wrong label. For example, an -----> image !!!  that originally was panda and after adding some perturbation on -----> image !!! s the neural network would think it as cat. But the label is cat now.\n\n&amp;#x200B;\n\nthanks  \n", "link": "https://www.reddit.com/r/learnmachinelearning/comments/asy94z/definition_of_adversarial_examples/"}, {"autor": "ostensibly_work", "date": "2019-02-20 22:44:15", "content": "So here's what I have written so far. You can probably see very quickly where things are going wrong. Please don't judge me too harshly.\n\n    # Adjust -----> image !!!  brightness/contrast and add noise\n    pngs = ['foo.png', 'bar.png', ]\n    contrast_range = (0.9, 1.1)\n    brightness_range = (-0.025, 0.025)\n    noise_range = (0, 5)\n    augmentations_per_image = 5\n\n    with tf.Session() as sess:\n        for png in tqdm(pngs):\n            img = tf.image.decode_png(tf.read_file(png), channels=1)\n            for aug_num in range(augmentations_per_image):\n                # Get the particular augmentation values for this image\n                delta_contrast = random.uniform(*contrast_range)\n                delta_brightness = random.uniform(*brightness_range)\n                delta_noise = random.uniform(*noise_range)\n\n                # Generate the noise\n                noise = tf.random_normal(\n                 shape=tf.shape(img), mean=0.0, stddev=delta_noise\n                )\n                noise = tf.cast(noise, tf.int32)\n\n                # Apply the augmentations\n                new_img = tf.image.adjust_contrast(img, delta_contrast)\n                new_img = tf.image.adjust_brightness(new_img, delta_brightness)\n                new_img = tf.cast(new_img, tf.int32)\n                new_img = tf.add(new_img, noise)\n                new_img = tf.clip_by_value(new_img, 0, 255)\n                new_img = tf.cast(new_img, tf.uint8)\n\n                # Save image\n                new_img = tf.image.encode_png(new_img)\n                filename = png.replace('.png', '_aug_{}.png'.format(aug_num))\n                write_new_png = tf.write_file(filename, new_img)\n                sess.run(write_new_png)\n\nAs you can probably tell, because I keep adding new graph nodes in the session, the program quickly grinds to a halt. From what I understand, I need to move the graph-defining parts outside of the session, and then pass each image through the pipeline, so to speak.\n\nHowever, I'm not really sure how to do that. I tried spinning off the `tf.___` bits into their own functions, but I ran into problems with those functions not being called, or sess.run complaining about return values. I then tried moving all the `new_img` bits outside of the session into the global scope, but then I couldn't figure out how to pass my `img` variable into that, so I kept getting NameErrors.\n\nBasically, I'm just pretty clueless. I haven't really done much with TF, but my coworker left, and there's no one else to do it, so here I am. Can someone point me in the right direction for what I'm trying to do? I'm not asking for you to fix my code, I'd just like to get a sense of how I'm supposed to tackle this problem, and then I can handle the details myself.\n\nThanks, and apologies for the dumb question.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/asuyld/im_attempting_to_augment_data_using_tf_but_ive/"}, {"autor": "Vinceeeent", "date": "2019-02-20 07:49:51", "content": "I'm making a -----> image !!!  caption system and my dataset is the validation since I cannot download the 19GB training set.  So I'm wondering how can I use the caption.json as my caption text\n\nhttps://i.redd.it/u4wjp7dthoh21.png", "link": "https://www.reddit.com/r/learnmachinelearning/comments/aslmsh/how_to_make_the_json_file_of_mscoco_dataset_as/"}, {"autor": "Fjjkordsfv", "date": "2019-02-18 20:42:33", "content": "## Recently,  I started working on cGANs when some issues came up. I am curious about  if it is possible to specify further conditions (aside from the class  labels) on cGANs. I am thinking about to specify pixel values for the  pixels of the outermost column/ row of the generated -----> image !!! , for example  as extra conditions. Have you already heard of such an approach?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/as1sx0/conditional_generative_adversarial_networks/"}, {"autor": "ApoorvWatsky", "date": "2019-02-18 17:36:51", "content": "I'm working on project based on automated lip-reading using CNNs. It is based on this [paper](https://arxiv.org/pdf/1611.01599.pdf). For a given short video clip in which a specific word or phrase is spoken, I want to extract frames and convert it into a 7x7 cluster for testing by model. Here's a [sample](https://i.imgur.com/twHwLYT.jpg) and this is exactly what I want to do.\n\nCurrently I've been able to extract frames from a video. It's nothing  complex. \n\n    def extractImages():\n        count = 0\n        vidcap = cv2.VideoCapture('sample_vid.mp4')\n        success, -----> image !!!  = vidcap.read()\n        success = True\n        while success:\n            cv2.imwrite(f\"frames/frame{count}.jpg\", image)\n            success, image = vidcap.read()\n            count += 1\n\n    if __name__==\"__main__\":\n        extractImages()\n\nHow to form a 7x7 image cluster from these frames? I'm not doing anything complex for now (extracting lips, bgr to grayscale etc). I want to make an image cluster from these frames firstly.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/arzp56/how_to_extract_lips_from_a_sample_video_clip_and/"}, {"autor": "Laurence-Lin", "date": "2019-02-18 00:42:23", "content": "First of all, when I do convolution, do I need to inverse the filter vertically and horizantally before multiplication?  \nSecond, for three channel -----> image !!! , the output neuron get the value for the sum of three channel's product (each channel do simple convolution to the output, then add 3 channel result together), is that right?  \n\n\nI've some problem when studying AlexNet, so I decided to implement a simple convolution myself.    \n\n\nThanks a lot!  \n", "link": "https://www.reddit.com/r/learnmachinelearning/comments/arr7aq/i_have_some_problem_understanding_the_convolution/"}, {"autor": "MasterSama", "date": "2019-02-17 04:07:32", "content": "Hi everyone, of I want to view a specific -----> image !!!  or datasets distribution, how should I go about it? \n\ndoes simply writing something like : \n\n`plt.hist(mydataset.reshape(-1))` \n\ndo the trick? or should I be doing something else? \n\nfor example doing so on cifar10 gave me this plot : \n\nThanks a lot ", "link": "https://www.reddit.com/r/learnmachinelearning/comments/argwzm/how_to_plot_a_datasetimage_distribution_in_python/"}, {"autor": "Spaceman776", "date": "2019-03-08 16:56:59", "content": "Hi, for one of my GPS class we have to do a final project and in two weeks we will be spending a lecture talking about machine learning. I find the concept really interesting so another redditor suggested my project could be something like identifying a location given a satellite -----> image !!!  of it. I tried to clarify, but it seems like he is not an active user so I was wondering if this community could help me with a few questions I have.\n\n  So I am not experienced in ML at all but I know its a developing area of research which is why I am interested. Would a project like this be too complicated for a novice to complete in less than two months? It sounds like a really fascinating idea, but I am also confused on where/how ML plays a role, can someone help me understand it better? Would I just take random satellite images from Google Maps and find a way to process them? Assuming it is doable, do you guys have any tips on a good place to start?\n\n  Thank you for any and all help!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ayshn1/identifying_a_location_given_a_satellite_image_of/"}, {"autor": "aceofpi", "date": "2019-03-06 22:20:35", "content": "Hey r/learnmachinelearning! I\u2019m a 3rd year mechanical engineer and I have a design challenge I\u2019ve been thinking of a solution to. Part of the challenge involves detecting defects created in bottle caps in an assembly line process.\n\nThe errors are pretty visible, but don\u2019t create significant enough geometrical differences for mechanical detection methods to be robust. To me, this sounds like a problem that I could solve with a -----> camera !!!  and some code.\n\nI\u2019m a comp sci minor, but I\u2019ve never tried to make / train neural network before. My understanding is that the code is fairly simple, and that the most important part is the data the network gets trained on. \n\nWhere should I begin with learning how to code something like this? Does this problem sound solvable via machine learning? Thanks so much! ", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ay4tzo/bottle_cap_error_detection/"}, {"autor": "phomb", "date": "2019-03-06 12:38:00", "content": "Hi there,\n\nI want to make a model which takes a small and a big -----> image !!!  as inputs (like a logo and a scanned document) and then detects and locates all occurrences of the small -----> image !!!  in the big one (say, giving out all bounding boxes or coordinates of the logo in the scan).\n\nI know this smells like a Single Shot Detector, but it is distinctly different, since both images are unknown at training time.\n\nAny ideas on how this could be done?\n\nThanks in advance!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/axyddn/how_to_build_a_model_which_detects_counts_and/"}, {"autor": "nanno3000", "date": "2019-09-21 15:30:56", "content": "i have read that gluoncv and openCV use mean value calculation in their preprocessing steps for yolo, as well as changing the -----> image !!!  to be square (e.g. 416x416)  \nCan someone explain to me, or point me to some articles explaining how the resizing in yolo happens? Does it skew aspect ratios, or just crop sides? Does it check whether there is an object before it crops?  \nSince most cameras are not squared, i don't quite understand why this happens, since both scaling and padding the image seem like bad solutions to me (?)\n\nWhen training yolo using darknet there is no mean value calculation (afaik).  Why is it applied to all images that get passed to inference (like in openCV blobFromImages)? Is this something i should do before i feed my CNN the data?  \nIs there a good way to calculate this value beforehand?\n\nThanks for your help", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d7bxxf/yolo_image_preprocessing_in_detail/"}, {"autor": "systemFruad", "date": "2019-09-20 18:55:40", "content": "How do I develop a 100 class -----> image !!!  classification model so that everything outside these 100 classes will have an output of \"others\" class?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d6zeyf/defining_outliers_in_an_image_classification/"}, {"autor": "Hurasuruja", "date": "2019-09-20 18:34:17", "content": "I have a regression problem where the input is a -----> image !!!  and the target is a continuous value 'x' ranging from 0 to 1. The model is resNet50 + a single neuron (with sigmoid activation function) at the top. I have trained the model and it works pretty well. \n\nHowever some of the input images do not contain enough information to predict 'x'. So in order minimize loss the model has learned to predict the 'x' to be \\~0.5 (most of the true 'x' values are around \\~0.5), when this type of \"bad\" image is seen.\n\nThis makes my model pretty much unusable. Is there a common practice to deal with this type of problem?\n\nI could train a different classifier to detect the \"bad\" images, but this would require  lots of labeling, which is infeasible.\n\nI could also try something like described in here:   [https://arxiv.org/abs/1506.02142](https://arxiv.org/abs/1506.02142)  and ignore predictions where the uncertainty is high, but this would require to run the images trough the model several times.\n\nCurrently I am using RMSE as a loss function. Would it be possible to define a custom non-continuous lost function, which would allow the model to 'choose' a constant loss, when this type of \"bad\" image is seen?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d6z4a5/regression_problem_and_confidence/"}, {"autor": "Lackrys", "date": "2019-09-20 01:18:00", "content": "Say I have a trained model, but I want to add to / respecify generic labels like:\n\nperson -&gt; child, adult -&gt; male toddler, elderly woman, etc.\n\nfruit -&gt; apple, banana, strawberry -&gt; golden delicious apple, cavendish banana, etc.\n\ncar -&gt; hatchback, truck, sedan -&gt; 2002 Toyota Highlander, 2006 Honda Odyssey, etc.\n\nCan I add some sort of attribute labels or split generic labels without conflicting with the original generic training? I would like to avoid having to relabel every training -----> image !!!  and retrain from scratch each time.\n\nI obviously can't cover every potential type of an object that comes up. However, it would be nice if the program could at least say \"apple\" with confidence even if it doesn't know what species.\n\nThis is for a school workshop hardware sorter (nuts, bolts, washers, etc.)\n\nI have just started dealing with object recognition training in TensorFlow 1.15 using *labelimg*, faster_rcnn_inception_v2_pets, and the basic *model_main.py*, so I may have the wrong mindset.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d6njtu/tensorflow_object_detection_additional/"}, {"autor": "SirJ_", "date": "2019-09-19 06:53:40", "content": "Hi all! \nCan anyone recommend some good computer vision with python books? I want to learn how to do some -----> image !!!  + video analysis!\n\nAnd any other machine learning books you found helpful! Some descriptions of how they were useful would be great too!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/d6ab83/computer_vision_with_python/"}, {"autor": "Rogerjak", "date": "2019-10-09 10:47:25", "content": "Hey guys, I'm developing a terrain generator that allows authoring using a neural network.   \nI've got some basic results and I am comparing them to a run of the mill algorithm just to gauge people's perception regarding the realism of the structures created.   \n\n\nThe text is in Portuguese but I'll translate and since the tests is visual, there's no need to read all the questions ( they are all the same).\n\n*\"Compara\u00e7\u00e3o de realismo entre resultados de m\u00e9todos generativos\"* : Realism comparison between results of generative methods.  \n*\"Este question\u00e1rio tem como objetivo perceber qual a perce\u00e7\u00e3o dos  utilizadores relativamente ao realismo dos mapas gerados entre estes  dois m\u00e9todos. N\u00e3o existem respostas correctas.\"* : This questionnaire tries to understand the perception of the user regarding the realism of the maps generated by these two algorithms. There are no correct answers.    \n*\"Entre a -----> image !!! m A e B, qual delas representa um terreno mais realista?\"*  : Between -----> image !!!  A and B, which one represents a more realistic terrain?\n\nThere's only two options and the test is visual so it doesn't take long: [https://forms.gle/QDbNbfGUZBvmXd4X6](https://forms.gle/QDbNbfGUZBvmXd4X6)\n\nThanks in advance guys!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dffa4t/master_thesis_questionnaire/"}, {"autor": "TheDeadCrow", "date": "2019-10-07 17:52:34", "content": "I need to do an ALPR aplication where the sensor detects the car then the -----> image !!!  is sent to the cloud and then the adequate processing of identification and OCR must be done remotely. \n\nAnyone knows of any application or service that might help me with this interface to the cloud? I was going to use Azure Machine Learning but I felt it is really lacking when it comes to image recognition. IDK if Azure Cognitive Services has a good price/benefit", "link": "https://www.reddit.com/r/learnmachinelearning/comments/den0gr/computer_vision_in_the_cloud_aplication/"}, {"autor": "thefrenchflo", "date": "2019-10-07 09:58:19", "content": "Hi,\n\nIn order to make my Football Manager game more realistic, I'd like to generate realistic faces for regen players.\n\nI'd like to start from one of the numerous megapacks of existing players faces (like for example the 128.000 faces of [https://www.fmscout.com/a-df11-facepacks-2019.html](https://www.fmscout.com/a-df11-facepacks-2019.html) ), and proceed as follows:\n\n1. select randomly two pictures\n2. blend them to create a convincing hybrid -----> picture !!! \n3. save the result as the new player face\n\nI think this could work perfectly as all the pictures represent the players in the same position, with the same proportions.\n\nWhich method would you use to achieve the most convincing blended faces?\n\nCould you redirect me to the right tutorial / documentation / paper?\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dehbyw/where_can_i_find_an_efficient_face_blending/"}, {"autor": "nopickles_", "date": "2019-10-06 19:37:58", "content": "I was investigating the idea of building a speaker recognition system (who is speaking) and maybe a speech recognition system (what is being said), I didn't find much online but the stuff I did find mostly transformed the audio to a spectogram and used a CNN. My question is, is a spectogram a sure enough way to do this? I mean can't two people have similar spectograms when saying the same exact thing? And are there any other ways than transforming the audio files to -----> image !!!  format?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/de85yl/speaker_recognition_with_deep_learning/"}, {"autor": "rLoper", "date": "2019-10-05 18:34:28", "content": "I am using PCA to reduce my 300+ feature data set to 2 features so I can plot it with matplotlib, but the points in the scatter plot don't look like a cluster at all, they are divided in sort of 2 lines and all lay in the same 2 axises (-----> picture !!!  is down for better understanding) and in the same 7 or so points. \n\nI am quite new to matplotlib so I copied that part of the code from somewhere, but still I am not able to figure out what am I doing wrong.\n\nIf somebody could clear this out, I would be vary grateful!\n\n&amp;#x200B;\n\n[Code](https://i.redd.it/tet3o16znrq31.png)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ddr8vd/i_cant_plot_my_pca_reduced_data/"}, {"autor": "Tmauer", "date": "2019-10-04 20:30:44", "content": "I imagine each are important, but at what point is fps too high to be properly utilized? Same question applies to -----> camera !!!  resolution I presume, what's the best resolution for quick accurate recognition? Or what is too low/high.\n\nTl;dr: What is the lowest you would want for fps and resolution, and if budget wasn't an option what would be the most you'd recommend?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ddd1rc/whats_more_important_for_image_recognition_camera/"}, {"autor": "xHipster", "date": "2019-04-09 12:19:20", "content": "Hi there, \n\nSo i'm currently breaking my brains over how a CNN actually works internally. I did read 'A guide to convolution arithmetic for deep learning'. That's all quite clear, but restricts purely to the convolution arithmetic.\n\nHow does it actually fit together in e.g. PyTorch?\n\nTake this DCGAN generator architecture for example. \n\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n   ConvTranspose2d-1           [-1, 1024, 4, 4]       1,638,400\n         LeakyReLU-2           [-1, 1024, 4, 4]               0\n   ConvTranspose2d-3            [-1, 512, 8, 8]       8,388,608\n         LeakyReLU-4            [-1, 512, 8, 8]               0\n   ConvTranspose2d-5          [-1, 256, 16, 16]       2,097,152\n         LeakyReLU-6          [-1, 256, 16, 16]               0\n   ConvTranspose2d-7            [-1, 1, 32, 32]           4,096\n              Tanh-8            [-1, 1, 32, 32]               0\n================================================================\n(https://prnt.sc/n9jw6v)\n\nHow does this work internally?\n\nIn layer 1, are there 1024 filters each individually performing a convolution on the 100z vector? So there are 1024 kernels with a different learned feature of the 100z vector? Same thing for layer 2: 512 individual filters, each performing a convolution on all the previous 1024 filters?\n\nThe reason i'm asking is because i'm running into a problem where i need to increase the complexity of the CNN. But i'm not sure if i should add more layers or just increase the channels (1 channel is 1 filter?) per layer. For a simple DNN i can imagine what it does, more layers would result in more non-linearity. But for a CNN i'm not sure. \n\nOr if you flip this around, for the discriminator taking a 1x32x32 -----> image !!!  as input:\n\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1          [-1, 128, 16, 16]           2,048\n         LeakyReLU-2          [-1, 128, 16, 16]               0\n            Conv2d-3            [-1, 256, 8, 8]         524,288\n         LeakyReLU-4            [-1, 256, 8, 8]               0\n            Conv2d-5            [-1, 512, 4, 4]       2,097,152\n         LeakyReLU-6            [-1, 512, 4, 4]               0\n            Conv2d-7              [-1, 1, 1, 1]           8,192\n           Sigmoid-8              [-1, 1, 1, 1]               0\n================================================================\n\n(https://prnt.sc/n9jw6v)\n\nLayer 1 (128x16x16) learns low abstractions, e.g. tree's, cars, faces or whatever. While layer 5 has high abstractions, e.g. lines on different angles. If you want to do a better classification on the input image being a face or not a face, would you simply just increase the amount of channels in the current layers? Or add a new layer with ... channels? \n\nSorry for the question being vague, but perhaps there is someone around who understands what i'm asking.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bb7900/n_filters_versus_y_layers_in_cnn_for_usage_in_a/"}, {"autor": "XiPingTing", "date": "2019-04-08 20:21:59", "content": "I have a chess board represented by five 64-bit integers. I've written a minimax chess engine that can play through games against itself, and label each position within a game as either winning or losing. A while ago I wrote an MNIST solver for classifying images of numbers using a labeled data set. Now I want to classify 'images' of chess boards as either 'winning' or 'losing' to replace a hardcoded heuristic. The problem is that my '-----> image !!! ' of a chess board is represented with bits not floating point numbers.\n\n&amp;#x200B;\n\nIs there a common technique for writing a poor man's neural network that performs multiplications and bitwise operations rather than matrix multiplication on floating point numbers? Unpacking integers into float vectors would be the answer if this were not right at a performance bottleneck.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/baymvv/what_techniques_are_there_for_classifying_labeled/"}, {"autor": "masagrator", "date": "2019-04-08 07:23:38", "content": "I have two sets of files - I can bring more than 100k if necessary. One pair contain the same non-compressed -----> image !!! , but they are saved in different ways. What tool would be the best to analyze data to convert one file to the second file? \nOr comparing binary data to image like DDS if it could be easier to do.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/baqs2j/analyzing_two_sets_of_binary_files/"}, {"autor": "spaceape__", "date": "2019-04-08 07:03:23", "content": "Hi,\n\nI\u2019m trying to perform face recognition as multi-class classification on a dataset composed by 10 classes.\nEach class is made of 21 -----> photo !!!  (17 for training and 3 for validation). I\u2019m building a cnn from scratch and, after many model where loss curve didn\u2019t decrease at all, I got [this](https://imgur.com/Ook8U7m) results.\n\nProven that this is a case of overfitting, what can I do to reduce overfitting? I tried adding dropout or using data Augmentation but I had even worse results!\n\nThe architecture of my model is similar to vggnet and I trained it for 30 epochs.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/baqm43/how_to_reduce_overfitting_for_multiclass/"}, {"autor": "hodwill", "date": "2019-04-07 23:45:24", "content": " So I\u2019m currently doing some biometric work in Matlab. I extract HOG features from images for each person and then train a SVM classifier. Then presenting with features of a new -----> image !!!  using predict, it classifies them into one one of the classes ie assigns it to a person. I\u2019m currently thresholding on the hinge binary loss of the class to see whether it\u2019s accepted or not. Some people are left out of training to test the genuine reject rate etc.\n\nTaking a file full of actual labels, predicted labels and results (And knowing which are genuine accepts/genuine rejects etc) I\u2019m creating the ROC curve. (Following the definitions on here [https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5))\n\nAnyway, when plotting my ROC curve there are large jumps in the y direction and the corner is quite rough. Is this because the step between each threshold test is too big? These values range from around 10-8 to 10-2 so I\u2019ve tried to make my steps as small as possible. Or is this because of other reasons? Thanks in advance!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bams0z/roc_curve_rough/"}, {"autor": "victoria-talbert", "date": "2019-04-07 20:43:15", "content": "Hi there,\n\nI am looking for some help next week.\nWe are working on a api that allows our users to upload an -----> image !!!  to our webserver (rootserver, so modules are not an issue).\n\nWe need to find the closest match / nearest neighbor in a set of 30.000 images (static, it won\u2018t change). \n\nWho has some hours to make that happen?\nWould be wonderful to hear from\nYou!\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bakvux/looking_for_help_payed_an_image_has_to_find_its/"}, {"autor": "__sumguy", "date": "2019-04-07 13:10:53", "content": "I trying to implement a Denoising the -----> image !!!  with DCGAN. I am trying to follow this [link](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) .\n\nThe implementation in the above link is trying to generate \"Real Looking Fake images\" from the celeb dataset. I have a doubt in how will i implement DCGAN for denoising images.\n\n1. I would take any image data-set and create a noisy images from the original image using opencv (or some other technique)\n2. The discriminator will discriminate between noisy and original image.\n3. The generator will generate denoised images from the noisy images.\n\nHow will i implement this generator part. In the original [link](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) their dataset has only celeb data unlike my data which consists of original and noisy data. How will i modify the generator such that it takes noisy image and generates denoised image . Help me out if i am not understanding things correctly  I am relatively new to DL and i want this as my project to be done in the next 7 days . Thanks in Advance", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bag2zi/having_trouble_with_a_denoising_image_with_dcgan/"}, {"autor": "nwbie21", "date": "2019-04-07 11:01:21", "content": "I want to compare two similar pictures. Before that I have to denoise the -----> image !!! . OpenCV has image denoising library. But what is the metric to reduce noise?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/baf5wt/how_to_measure_noise_in_an_image_what_is_the/"}, {"autor": "Arkitos", "date": "2019-04-06 18:17:16", "content": "Hey, so I've been in and out of ML over the past year and a half. Have completed Andrew Ng's Coursera ML course and Udacity's Intro to ML course. Also in the middle of a ML course in college.\n\nI have two other ML enthusiasts with me in a group, and we have to submit our idea for our final year project soon.\n\nWe have a good professor that we'd like to mentor us, so it's important to pick and submit an idea soon. The project is supposed to go over the course of approx. 1 year.\n\nSo I'm a little clueless about what kind of ideas to consider. We have to defend our idea religiously as well, even if we don't have a complete -----> picture !!!  yet, we need to show it's feasible.\n\nOur top 3 requirements are:\n- Feasibility of the idea and implementation for ML beginners\n- Innovative (Just enough to be able to brag about ;))\n- Having an answer to \"Why\" we're making it, to better defend the project\n\nCurrently brainstorming with my mates and looking up projects on google, posting here in case someone has any cool ideas :) Thanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/ba78f0/final_year_college_project/"}, {"autor": "MattR0se", "date": "2019-12-09 11:12:33", "content": "I am toying around with -----> image !!!  classification. I found this article [https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/) that is very good, but the size of the data is too much for my PC (takes nearly an hour to compile and train the model) so I decided to tackle something smaller.\n\nI got some images from the Google quick, draw! dataset [https://github.com/googlecreativelab/quickdraw-dataset](https://github.com/googlecreativelab/quickdraw-dataset)\n\nI downloaded the numpy files for cats, dogs, bees, helicopter, octopus and bicycle and converted them to 28x28 jpgs.\n\nI changed the model in the article so that it can fit this multiclass data: [https://pastebin.com/mfvm6KRf](https://pastebin.com/mfvm6KRf)\n\nI changed the input layer's shape to be (28, 28) and the output layer's shape to 6 instead of 2.  I also changed the loss function to \"categorical\\_crossentropy\" and trained for 50 epochs.\n\nI got a reaonable test accuracy of 82%, but when I wanted to predict some random images, I mostly got all zeros as the prediction from this code:\n\n    # load 5 random images and print the output\n    images = []\n    for l in labels.values():\n        folder = f'quickdraw/test/{l}/'\n        images += [folder + f for f in listdir(folder)]\n    shuffle(images)\n    for i in range(10):\n        filename = images.pop(0)\n        plt_img = imread(filename)\n        # plot raw pixel data\n        plt.imshow(plt_img, cmap=\"gray\")\n        plt.show()\n        \n        # classify the image\n        img = load_img(filename, target_size=(28, 28))\n        x = img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        pred = model.predict(x)\n        print(pred)\n    \n    # output:\n    # [[0. 0. 0. 0. 0. 0.]] for all of the images\n\n&amp;#x200B;\n\nDid I make some obvious mistake? Is accuracy even the right metric here?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/e88n6e/problems_with_output_from_keras_cnn/"}, {"autor": "ohdangggg", "date": "2019-12-07 23:40:31", "content": "Sorry if this question is incredibly basic. I feel like there is a  wealth of resources online, but most of them are half-complete or skip over  the details that I want to know.  \n\n\nI am trying to implement LeNet with Pytorch for practice.\n\n[https://pytorch.org/tutorials/beginner/blitz/neural\\_networks\\_tutorial.html](https://www.google.com/url?q=https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html&amp;sa=D&amp;source=hangouts&amp;ust=1575845021900000&amp;usg=AFQjCNH95VMxOOFPsy1MnHOWfIkwEGBIpw)  \n\n\n1. How  come in this examples and many examples online, they define the  convolutional layers and the fc layers in init, but the subsampling and  activation functions in forward?\n2. What is the purpose of using  torch.nn.functional for some functions, and torch.nn for others? For  example, you have convolution with torch.nn ([https://pytorch.org/docs/stable/nn.html#conv1d](https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.html%23conv1d&amp;sa=D&amp;source=hangouts&amp;ust=1575845021900000&amp;usg=AFQjCNESRhEwh2D7R1mrKUsOB_Sjq_sMtQ)) and convolution with torch.nn.functional ([https://pytorch.org/docs/stable/nn.functional.html#conv1d](https://www.google.com/url?q=https://pytorch.org/docs/stable/nn.functional.html%23conv1d&amp;sa=D&amp;source=hangouts&amp;ust=1575845021900000&amp;usg=AFQjCNFT-AvIQAkzvndGfTDAojzc4QwDUA)). Why choose one or the other?\n3. Let's say I want to try different -----> image !!!  sizes, like 28x28 (MNIST). The tutorial recommends I resize MNIST. Is there a way to instead change the values of LeNet? What happens if I don't change them?\n4. What is the purpose of num\\_flat\\_features? If you wanted to flatten the features, couldn't you just do x = x.view(-1, 16\\*5\\*5)?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/e7lw7i/pytorch_implementation_of_lenet_and_other_simple/"}, {"autor": "dondraper36", "date": "2019-12-07 19:01:25", "content": "Let's say we have a regular -----> photo !!!  and three low-light -----> photo !!! s illuminated in different colors. \n\nEach pixel is a three-component vector $q=(R,G,B)$. Then $q\\_k\\^{A}$ is the $k$-th pixel of the regular photo and $q\\_k\\^{B}$ $q\\_k\\^{C}$ $q\\_k\\^{D}$ be the $k$-th pixel of the three low-light versions. \n\n&amp;#x200B;\n\nThe task is to reconstruct the regular photo from the three low-light photos where:\n\n&amp;#x200B;\n\n$q\\_k\\^{A} = F\\^{A}q\\_k\\^{B} + F\\^{C}q\\_k\\^{C} + F\\^{D}q\\_k\\^{D} + q\\_{const}$. Clearly, $F\\^A, F\\^{B}, F\\^{C}$ are $3 \\\\times 3$ matrices and $q\\_{const}$ is a vector. \n\n&amp;#x200B;\n\nThe task is to perform least-squares fit for the 30 components (three matrices and the vector). Specifically, we should minimize:\n\n&amp;#x200B;\n\n$S = \\\\frac{1}{MN}\\\\sum\\\\limits\\_{k=0}\\^{MN-1}{||-q\\_k\\^{A} + F\\^{A}q\\_k\\^{B} + F\\^{C}q\\_k\\^{C} + F\\^{D}q\\_k\\^{D} + q\\_{const}||\\^2}$\n\n&amp;#x200B;\n\nWhat is a proper way to approach this problem? I have implemented linear regression of different types before, but in this case, I am not sure how to proceed.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/e7ia8z/image_reconstruction_using_lowlight_versions/"}, {"autor": "kountryt", "date": "2019-12-06 17:01:05", "content": " If anyone might know of helpful resources or have some input themselves that would be great. I've got two problems that I'm researching possible solutions for.\n\nProblem #1 - -----> Image !!!  classification - The goal is to sort images into likely about 3 categories that are defined by how they relate to the printing industry that I work in. I've attached a crude collage of images just to roughly illustrate the 3 categories that I'm looking to sort images into (these aren't actual examples from training data or anything). I've been researching image classification using machine learning and CNN's so I'm relatively familiar and I can keep reading all the resources out there regarding that general topic. But I'm hoping to find information regarding a kind of classification that's not related to the *subject* of the image, but instead the nature or character of the image. In this case it seems to me that defining the categories would be more about the nature of hues in the image and texture more than a sort of edge detection to identify a subject. And I'm curious how that might affect the necessary approach to creating a model.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nhttps://preview.redd.it/v8kypnaln1341.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=62703c65d1e64dc5f086b802172c85873698ec5d\n\n&amp;#x200B;\n\n Problem #2 - Image segmentation - The goal is to segment images by their prominent colors by first predicting the appropriate number. Just segmenting an image into a color pallet isn't the big issue. There's lot of resources about using k-means clustering (or others) with color data to determine a dominant color pallet. The issue is not knowing the number of buckets ahead of time. I'm tossing around ideas about how to first predict the correct number of color buckets before clustering but none seem great. Any insight or resources would be great.\n\nI'm working with a development team to research these problems and we're not directly in the feild of computer vision or machine learning. But I'm doing tons of reading and just being pointed in the right direction would be hugely helpful. I tried picking the right sub to post this to but if this isn't just let me know.\n\n&amp;#x200B;\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/e71cs7/im_looking_for_any_relevant_info_that_would/"}, {"autor": "Filarius", "date": "2019-12-06 09:30:25", "content": "Some time ago I made app what was able to store data in video so its was possible to use Youtube as \"file storage\".\n\nThere was no actuall purpose on this beside just learn something new and having some fun while trying to make app better.\n\nNow I'm learning how to use neural networks and trying to apply it on same problem - how to store any kind of data inside of video. \n\nGeneral problem definition is:\n\nTake any file from your computer, make video based on file content, upload it to Youtube (or else video hosting website or make livestream on Twitch), download video what was re-encoded by Youtube (that one with same resolution as uploaded video), and basing on video content make file what must be exactly same to original file.\n\nFor me here most hard part is to find some related example, tutorial, or paper. Maybe i do something wrong, but i can't found direct answer.\n\nFrom point where I looking at this problem i have 3 kinds of data. Good quality -----> image !!! , bad quality -----> image !!! , and data what was \"stored\" in both -----> image !!! s. For Decoder NN its obvious how to make training - just take bad image and data. But for Encoder things looks complicated - it need to learn how to make good image so, so if using bad image (made from good one) in Decoder training there will be less percent of wrong answers (and maybe faster training?). Also i do not see best solution to connect Encoder and Decoder in single autoencoder. There  must be video encoder inbetween, what stops of using magic of gradient descent here. \n\nAny idea how to make it best?\n\nRight now I just made middle NN what trained to somehow mimic video encoder behaviour, and and its works on not so \"densy encoding\" with  insignificant  error rate, but I wish to make it much better.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/e6wk8r/video_as_data_storage_using_neural_networks/"}, {"autor": "bananaskywalker", "date": "2019-12-05 14:37:38", "content": "&amp;#x200B;\n\n[Sample Receipt](https://preview.redd.it/wurn0f898t241.jpg?width=675&amp;format=pjpg&amp;auto=webp&amp;s=17461d959269bb97b982f6c221d31a3bbc5dfeb0)\n\n[Another sample receipt](https://preview.redd.it/198c7rpc8t241.jpg?width=675&amp;format=pjpg&amp;auto=webp&amp;s=18678f515c51f4f8c5c554ecf7805638143075f8)\n\nSo my task is to localize the recipt within the -----> image !!! , apply a persective transform, and use \n\n    df = pytesseract.-----> image !!! _to_data()\n\nor something on the lines of what is mentioned [here](https://dzone.com/articles/using-ocr-for-receipt-recognition) to read the text.\n\nThe main issue has been to localize the receipt in the first place.\n\nI though using a simple Canny Edge Detection with a Gaussian Blur to remove the  noise, then using contours to detect the object, isolate it from the image using an AND operation. However, this doesn't produce the right results always.\n\nSo with some googling, I found this:\n\n[First, we recognized the area on the image that contains the full receipt and almost no background. To achieve this, we rotated the image so that text lines are horizontally oriented.](https://dzone.com/articles/using-ocr-for-receipt-recognition)\n\nThe author went on to explain what he did in the comments:\n\n    The algorithm appeared to be slow. It takes several seconds for it to find the angle. But it was much slower before. That's why we've done some optimisation work.\n    \n    First, we rotated a resized copy of the original image. We made it smaller to increase speed. The final rotation was applied to the original (not resized) image only after we got the right angle. Also we made a number of searches. First one was a rough search for the angle of rotation. As a result we found the value of the angle, but it was not really accurate. Second search was more precise and improved the result of the first search. And the third search made the fine tune. \n\nand\n\n    We rotated the image at the specific angles clockwise and counterclockwise. We determined the number of black pixels for every image line angles. Finally, we got the array of black pixels distributed among image lines in accordance with the rotation angle. When the variance was maximum with the chosen slope, the angle turned out to be right.\n    \n    There are some other ways to align documents, but we only applied the one described.\n    \n    \n    If you have some more specific questions, please, leave your email. We\u2019ll take a look and get back to you.\n\nThe first part makes sense.\n\nHowever, in the second explanation, I did not understand what he meant to say.\n\n\\&gt;**for every image line angles.**\n\nWhat does that mean? I believe he meant every line found with a Hough Transform, but then how do I implement that? It seems very tough to implement.\n\nAnother approach was mentioned here:\n\n[https://stackoverflow.com/a/6644246/6941400](https://stackoverflow.com/a/6644246/6941400)\n\nBut I don't get what the algorithm proposed is.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/e6i150/how_do_i_detect_a_receipt_in_an_image_using/"}, {"autor": "Scribbio", "date": "2019-10-28 15:04:18", "content": "Hi all,\n\nI'm currently in the process of making sense of neural networks and how they handle basic -----> image !!!  recognition.\n\nThis question concerns basic vanilla neuron networks, (not convolutional networks - I'm not that far yet!)  \n\nNow, in an image recognition task, each of the input neurons could correspond to a pixel extracted from the image.  \n   \nIn order to perform our various calculations, each of these pixels needs to correspond to a numerical value that help to describe it.  \n   \nThis number then needs to be \"squished\" to a value between 0 and 1.   \n   \nIf the image is in greyscale, these could well reflect the gradient of the pixel. With darker values possessing a value closer to 1.\n\nSimple.\n\nHowever, if the image is in RGB, what is the most adopted practice involved in \u201csquishing\u201d those 3 channels into our single numerical value?\n\nMany thanks for your help!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/doa1w0/what_are_the_inputs_of_a_neural_network_when/"}, {"autor": "rLoper", "date": "2019-10-28 08:30:27", "content": "I am trying to get the hold of seaborn library and I can't get the distplot to show what I desire. Kernel density estimate is off and the bins are not centered around integers. Also there are not any other unique values outer than numbers 3-9. Here's a -----> picture !!! :\n\n![img](cxf8jy46t8v31)", "link": "https://www.reddit.com/r/learnmachinelearning/comments/do60pl/a_question_about_seaborn/"}, {"autor": "glaey", "date": "2019-10-27 21:47:30", "content": "Hi everyone,\nI am working on a -----> image !!!  classifier with few samples (thousands) in six different classes.\nI am planning on using transfer learning on vgg16 in adding my dense layer on top.\nThough my images are currently stored in jpg inside classes directories and I need to divide in two sets (holdout training and test with sklearn). \nI am thinking on creating a hdf5 file for it, but they have different size. Is there a way to store them without resizing or should I do it at this stage?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/dnzkli/store_images_with_different_size/"}, {"autor": "francisco_DANKonia", "date": "2019-07-06 02:27:50", "content": "I'm trying to make a character recognition program and can interpret characters but haven't figured out how to locate them in an -----> image !!! . Does anyone have resources for this in R?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c9ofun/bounding_boxes_in_r/"}, {"autor": "francisco_DANKonia", "date": "2019-07-05 22:21:21", "content": "Hi, I'm working on creating a character recognition program. I managed to create a model that correctly identifies all of my characters, but now I need to be able to locate those characters in an -----> image !!! . Does anyone know a good resource for doing this in R?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c9m288/how_to_tokenize_images_in_r/"}, {"autor": "UniformlyConvergent", "date": "2019-07-05 19:05:55", "content": "So, I was trying to build a SoftMax linear -----> image !!!  classifier (trying to find a matrix W that would classify the -----> image !!! s correctly), and I got stuck with the regularization parameter. After finding my loss function I should add a regularization term to punish the model for complexity (e.g. we want W's entries to have smaller values). According to notes of CS231N, we multiply the regularization term by the sum of the squares  of the matrix's entries. In Python, the pseudocode seems like this:\n\n`Loss = Loss + regularization_term * np.sum(W**2)`\n\nBut, looking at the solutions of other people, I see something like this:\n\n`Loss = Loss + 0.5 * regularization_term * np.sum(W**2)`\n\nWhy do we have 0.5 there?\n\n&amp;#x200B;\n\n**Secondly,** when adding regularization to the gradient, this:\n\n`dW = dW + reg*W`\n\nproduces a smaller error rate than:\n\n`dW = dW + reg*(np.sum(W**2))`\n\nFirst, why do we even have to add regularization term to the gradient? Second, even if we add, why do we add the matrix itself and not the sum of square of its entries?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c9jts6/basic_2_questions_about_the_regularization_term/"}, {"autor": "person4422", "date": "2019-07-05 13:59:19", "content": "I've been given a bunch of images that I've been told I need to classify, but these 'images', in reality, are just points on a 2d plane. These 'images' were even generated by these points. I have access to use the coordinates of the data instead of the images themselves. Would it be better for me to just use the raw data of all the points that created the -----> image !!! s I want to classify or just the -----> image !!!  themselves?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c9g96f/need_advice_on_how_to_approach_an_imagine/"}, {"autor": "vinnivinnivinni", "date": "2019-07-04 18:50:46", "content": "Hello,\n\nI'm doing a reverse -----> image !!!  search within 70k 224x224 -----> image !!! s.   \nI've been working with 20k images until now and seem to reach the RAM limits of Google Colab (and of my PC). How can I predict sets of say 10k images, build a tree until I reach 70 and merge those 7 trees into one? Is this even possible?  \n\n&amp;#x200B;\n\nWhat I'm doing:\n\n1. I flatten all the images into numpy arrays \\[2000, 224, 224, 3\\] (&amp; save it into a h5 on my hard drive)\n2. The I run the prediction \\`imgData\\_feature = model.predict(data, verbose=1)\\`\n3. The I flatten it \\`imgData\\_feature\\_flat = imgData\\_feature.reshape(data.shape\\[0\\], -1)\\`\n4. Build the tree \\`tree = KDTree(imgData\\_feature\\_flat)\\`\n5. And lastly save the tree for later use \\`joblib.dump(tree, 'model20k.pkl', compress=5) \n\n&amp;#x200B;\n\nHow could I do this 7 times with 10k images each and in the end merge the trees or recalculate them, keeping it at 10GB RAM?  \n\n\nThanks!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c967ir/question_how_to_scale_keras_model_prediction/"}, {"autor": "connar_with_a_t", "date": "2019-07-04 00:08:09", "content": "Hi reddit,\n\nx0 and x1 are vectors.\n\nI have a question about understanding the -----> image !!!  under T. Sal Khan had L0 = {T(x0) - t(T(x1) - T(x0)) | 0&lt; t&lt;1} I understand why the points would be connected for t(T(x1) - T(x0)). \n\nHowever I don't understand why the first part T(x0) is there? why are we subtracting t(T(x1) - T(x0)) from T(x0)? Any help is really appreciated. \n\nI have uploaded a screenshot to maybe help make it more clear the example I am referencing.\n\nhttps://i.redd.it/jneordzsh6831.png\n\nI have uploaded a screenshot to maybe help make it more clear the example I am referencing.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c8vo5u/help_understanding_standing_the_image_under_t/"}, {"autor": "jweir136", "date": "2019-07-03 22:21:31", "content": "Hello! I'm currently working on an assignment where I am tasked with creating a model that is able to detect if an -----> image !!!  is a picture of a dog. \n\nThe catch is that the model has to be able to predict if a dog is present OR if a dog is not present. \n\nFrom what I already understand, this is a form of anomaly detection. I have tried creating a deep Convolutional Autoencoder in order to use the loss thresholds to predict the classes. However, the Autoencoder is not really able to learn many useful features for the entire dataset. \n\nI have also tried using a convnet to extract features from an image, and use a one class svm model to classify an image. But at best it is able to only get about an 60% accuracy. \n\nI was wondering is anyone here had any experience with solving a problem like this, and if so what would you recommend?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c8ujq4/best_way_to_do_one_class_classification_with_an/"}, {"autor": "dragomen747180", "date": "2019-07-03 06:14:09", "content": " \n\nforewarning I am out of my element with this idea\n\nI'm  building a lichtenberg machine DIY from a microwave power transformer, i  was wondering if its possible to hook up like an Arduino and a web cam  or some type of -----> camera !!!  and use machine learning to teach the ai lighting  patterns and eventually get it to create its own patterns based off  what i feed it Litchenberg wise. now please don't flame me im not an  expert on anything AI so maybe Arduino isn't the way to go. preferably  would like to do this in Python. if there's any resource or constructive  input id be willing to read.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c8kjy3/discussion_i_have_an_idea_please_read_below/"}, {"autor": "grassshopperrr", "date": "2019-07-03 05:36:24", "content": "I am new to reddit so forgive me if I don't follow the best practises of asking a question.\n\n&amp;#x200B;\n\nTo give some context about me. I have a bachelor's degree ([B.Tech](https://B.Tech).) in Electrical Engineering and now I work as a Data Scientist with 4 years of experience. For a good part of last 4 years I have been working with out a team and this is my first job.   \n\n\nI learned ML by doing a Machine Learning nano degree course on Udacity and Deep Learning specialisation course by Andrew NG on Coursera.\n\n&amp;#x200B;\n\nAt work I had worked on couple of projects (tabular data) where I only used random forest and GBMs. I build an algorithm to extract important phrases from text data. And I worked little bit on Object Detection where I used transfer learning to detect some objects and built an algorithm to detect Dominant Colors from an -----> image !!! . Now I am working on a Rule based question answering chatbot similar to **Insights** in Google Analytics. All these projects I managed to start and push to production on my own. \n\n&amp;#x200B;\n\nBut that's the only thing I have done in last 4 years. I haven't worked on a project outside work and never participated in any Kaggle competitions. Now I want to switch jobs and I don't feel confident about myself as a Data Scientist. \n\nAm I correct in thinking so? \n\nDid I not utilise my last 4 years properly? \n\nCan anyone suggest me a method using which I can practise ML in a structured way? - There is so much to learn and I don't know where to start and how to start.   \n\n\nThanks in advance.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c8k8qv/need_advice_to_improve_my_confidence_levels/"}, {"autor": "Fengax", "date": "2019-07-02 11:11:32", "content": "I have just trained my first CNN network by using the MNIST dataset, it is the most famous handwriting dataset. However, instead of using their testing images, I want to **utilize my own 28x28 testing images.**\n\nThe rationale behind this, is that I want to make a handwriting recognition program, so obviously I need a way to convert traditional -----> image !!!  format to the one-dimensional MNIST format, so that the CNN can read it.\n\nWhat is the best way to accomplish this task?", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c87ypg/best_way_to_convert_traditional_images_into_mnist/"}, {"autor": "Magniminda", "date": "2019-07-02 08:57:59", "content": " \n\n*Today*, more and more organizations are integrating **machine learning** along with **AI** in their products, and in the coming years, this trend is only going to increase.\n\nCompanies of different sizes and from different fields are expanding their capability, intelligence, and speed of human potential through their software. And this makes it the time to grab one of the varied **machine learning jobs**. Here, we\u2019ve consolidated a list of some highly-acclaimed machine learning companies that you can focus upon to get hired.\n\n#### 1- Amazon\n\n&amp;#x200B;\n\n*From* Kindle to Echo to online store \u2013 machine learning is implemented on all [***Amazon*** ](https://www.amazon.com/)consumer services. At Amazon, there\u2019re lots of teams that depend on machine learning \u2013 from Amazon JHIM, Amazon Music, to Alexa Engine, to Customer Service Personalization, etc. With machine learning at its heart, Amazon is certainly one of the best companies that offer a diverse range of **machine learning jobs** to enthusiasts.\n\n#### 2- Google\n\n&amp;#x200B;\n\n*Unquestionably*, [***Google***](https://www.google.com/) is one of the most powerful forces when it comes to implementing machine learning. Over the past few years, the giant has centered its focus on machine learning to enhance Google Language, Visual Processing, Speech Recognition, Search Engine Ranking, [***-----> Image !!!  Processing*** ](https://magnimindacademy.com/image-processing-and-its-future-implications/)etc.\n\nApart from offering healthy pay packets and perks like other top-notch employee-centric firms, Google has something extraordinary on offer \u2013 the availability of extraordinary computing resources.\n\n#### 3- Uber\n\n&amp;#x200B;\n\n*If* you think of [***Uber***](https://en.wikipedia.org/wiki/Uber) as a ride-hailing business, you\u2019re wrong. Its internal teams use a machine learning-as-a-service platform to seamlessly develop, deploy, and operate machine learning solutions at the company\u2019s scale.\n\nIt covers end-to-end machine learning workflow like managing data, evaluating, and deploying models, making and monitoring predictions like estimated time of arrival of your ride. If you\u2019re interested in facing machine learning challenges, try to grab one of the **machine learning jobs** offered by Uber.\n\n#### 4- Facebook\n\n*Machine learning* is used each and every day by users of[ ***Facebook***](https://en.wikipedia.org/wiki/Facebook) without them realizing it. Things like personalized news feed, friend tagging suggestions, friend suggestions, group recommendations, mutual friend analysis, , etc are done through the implementation of machine learning.\n\nIf you\u2019re looking to get hired by a leading company and want to be able to work with top industry experts, Facebook is where you should try to get a job.\n\n#### 5- Apple\n\n&amp;#x200B;\n\n*Siri* has been greatly enhanced by [***Apple*** ](https://www.youtube.com/user/Apple)with the help of machine learning so that it can become more capable than just calling people in your contact list. Now, it can identify someone who emailed you recently but isn\u2019t in your contact list, for instance.\n\nOver the past couple of years, Apple has acquired a number of AI and machine learning startups like Pop Up Archive, SensoMotoric, Lattice.io etc. With iPhone, Apple has certainly covered a long way in the machine learning landscape, and if you want to be a part of its exciting journey in the coming days, it\u2019s the time to grab one of the **machine learning jobs,** at Apple.\n\n#### 6- Feedzai\n\n&amp;#x200B;\n\n*Founded* by university professors, [***Feedzai***](https://feedzai.com/) follows the goal of offering customers a safer and better experience, and providing end-to-end fraud prevention by implementing AI and machine learning. It offers support to brick-and-mortar, as well as online stores, and helps them in acquiring knowledge for every sale. Based on behavioral analysis, it enables analysts to prevent and predict electronic payment loss in real time.\n\nFeedzai\u2019s **machine learning jobs** will let you work with cutting-edge technologies to fight cybercrime in a learning atmosphere.\n\n#### 7- Darktrace\n\n&amp;#x200B;\n\n***AI*** **and machine learning** are used by [***Darktrace***](https://www.darktrace.com/en/) to offer cyber defense systems that impersonate the human immune system by understanding what is normal for all users and devices, modifying its understanding with environmental changes, and finding abnormalities that could uncover security issues.\n\nIf you want to work for a global leader in cybersecurity and feel excited to take up challenges, you should consider applying for any of the **machine learning jobs** offered by Darktrace.\n\n#### 8- IBM Watson\n\n*Apart* from transforming data, data scientists here apply [***machine learning algorithms***](https://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html) for training predictive models and developing intelligent applications that leverage the predictions exhibited by machine learning models. Algorithms are also applied to learn from datasets to develop models that can generate predictions based on those datasets.\n\nIf working for a trusted name in **machine learning** domain is something you look forward to, applying for a job at [***IBM Watson***](https://www.ibm.com/watson) would be a good decision.", "link": "https://www.reddit.com/r/learnmachinelearning/comments/c86wu2/much_soughtafter_companies_for_machine_learning/"}, {"autor": "GotTiredOfMyName", "date": "2019-06-04 09:07:00", "content": "Earlier this year, I stumbled upon [Daniel Shiffman on youtube](https://www.youtube.com/channel/UCvjgXvBlbQiydffZU7m1_aw), and seeing his cool coding challenges, really motivated me to get into learning javascript, (previously i had very basic experience with java and the android sdk). Through that, I saw [genetic algorithm rockets](https://www.youtube.com/watch?v=bGz7mv2vD6g), and [neuroevolution flappy bird](https://www.youtube.com/watch?v=c6y21FkaUqw) challenges, and followed along. And last month I got deep into this subreddit, and machine learning in general. Also, I challenged myself to not use any libraries whatsoever, it lets me also learn about javascript on a much deeper level, and then later I will get to compare what i wrote to the popular libraries to see how i can improve.\n\nAfter about a week of playing around with standard feed-forward networks I made [this version](https://htmlpreview.github.io/?https://github.com/howdoesthisevenwork/neuralnetworktests/blob/master/smartrockets.html) of smart rockets, but they use a 3 layer dense network, their inputs being their own position and rotation, and outputs being their thrust. similarly, I made [this little thing](https://htmlpreview.github.io/?https://raw.githubusercontent.com/howdoesthisevenwork/neuralnetworktests/master/eaters.html) with these dudes who have 3 boxes around them giving the sight. after about 20 generations they get pretty good at hunting for food.\n\nthis is pretty simple, and i ran across recurrent neural networks, and thought that might make the dudes a bit smarter (it didnt) but i did make [a small thing here](https://htmlpreview.github.io/?https://github.com/howdoesthisevenwork/neuralnetworktests/blob/master/word_learner.html) that will memorize the spelling of a word, effectively overtraining on a small piece of data. I'm not 100% sure that what i wrote is perfectly correct, but that was how I checked that it was at least working a bit. That NN cant learn more than about 6-7 letters in sequence (makes sense, its 8 nodes), and also if i increased the timesteps that the backpropagation would go through, my gradients would just go to Infinity or NaN, (learned about vanishing and exploding gradients that way) but that got me reading about LSTMs and how they can improve my rnn.\n\nso I added lstm layers to the network, and now [this one](https://htmlpreview.github.io/?https://github.com/howdoesthisevenwork/neuralnetworktests/blob/master/lstm.html) can learn a lot longer sentences, like the alphabet can be learned in about 100 passes of the string, or \"hello this is a longer sentence\" in about 200. Programming and writing the code for LSTMs really helped me understand the math behind the unit, its actually super clever!\n\nThen I moved onto pictures. Daniel Shiffman did [a coding challenge](https://www.youtube.com/watch?v=KhogNPC24eI) on the mnist database, and there was [a cool video by 3blue1brown](https://www.youtube.com/watch?v=aircAruvnKk) using it, so I decided to start there. I tried to challenge myself by doing it all myself, and I managed to make [this thing here](https://htmlpreview.github.io/?https://github.com/howdoesthisevenwork/neuralnetworktests/blob/master/mnist_with_nn.html). (super proud of myself for figuring out the pixel scaling with an array of pixels on my own which let me make a brush size slider in like 2 lines of code). but this uses a standard dense 3 layer network. My laptop is pretty shit so I cant train it too quickly, but I found that 784-&gt;64(sigmoid)-&gt;16(sigmoid)-&gt;10(softmax) manages to get to about 70% accuracy within 15000 trainings, and if you throw in a relu layer or bump up the node sizes, train it for a few epochs, I got up to 85-90% accuracy on the test samples. But reading online that state of the art networks can do 99.7%+, got me into reading about convolutional networks, and so i challenged myself to make one.\n\nMaking a cnn was pretty tough, gotta say. But I managed to do it, and I learned a lot, and now seeing my phone -----> camera !!!  being able to detect that I'm taking a picture of a cat vs a flower is no longer magic to me. It makes perfect sense. So i tried my new [shitty little cnn on mnist](https://htmlpreview.github.io/?https://github.com/howdoesthisevenwork/neuralnetworktests/blob/master/mnist_with_cnn.html) and a 20 5x5 feature map -&gt; relu -&gt;maxpool -&gt; x4 5x5 feature map -&gt;relu -&gt;maxpool -&gt; 10 dense softmax, gets to 90% accuracy within a couple thousand trainings, much much faster than the regular nn. I didnt really bother with training it too long, again, super shit computer (one picture to backpropagate takes about a full second), and this is single-threaded javascript running matrix multiplication that I wrote, which probably isnt optimized at all, etc..\n\nbut the [same cnn setup](https://htmlpreview.github.io/?https://github.com/howdoesthisevenwork/neuralnetworktests/blob/master/cnn_quickdraw.html) with a dropout layer added can learn 4-6 quick,draw! doodles after only 4-5k trainings to 75% accuracy, so its definitely coded sorta right, or i guess it wouldnt work at all.  also, I have no idea if i programmed the color channel backpropagation properly, i cant really test it properly cause it would take too long, training on the cifar-10 database with this thing took a bit longer than i care to admit and i wanted to try other things.\n\nbut basically after that I learned so much about neural networks, that now when I read a paper or an article about machine learning, I can actually sorta understand the math, and understand the language, the thought process, and can actually take something away from it, rather than just being freaked out by it and not getting it at all.\n\nas far as the library goes, if for some reason anyone wants to use it or look into it, [its here on this github](https://github.com/howdoesthisevenwork/neuralnetworktests) project i set up. (honestly i have no idea how to properly use github, another thing to learn!) but the network is set up like this: (no idea why anyone would set anything up this way, but this is just as many different things in one setup)\n\n    let brain = new NeuralNetwork(1) //setup number of input nodes for a convolutional network, this is how many images (in a 3d array of matricies) should be given at one time, in this case 1. for linear networks, its just an array of numbers for input. \n    brain.addLayer(5, 'conv', {kernel_size: 5})  //output node number, type of layer, config  \n    brain.addLayer(5, 'empty', {activation_fn: 'relu', output_dropout_rate: 0.1}) //empty layers dont apply weights, so can be activation function layers or dropout layers. but these things can also just be added to any layer anyway\n    brain.addLayer(5, 'maxpool', {kernel_size:2}) // for empty and maxpool layers the output should be the same as the input, except for flattening layers\n    brain.addLayer(180, 'maxpool', {kernel_size:2, flatten_layer: true, activation_fn: 'linear'})// here the output would be 5 6x6 matricies flattened, so the output would be 180 nums\n    brain.addLayer(100, 'recurrent', {activation_fn: 'swish', weights_start:'narrow'}) \n    brain.addLayer(50, 'lstm') //lstm units use specific sigmoid and tanh functions.\n    brain.addLayer(5, 'dense', {activation_fn: 'softmax', time_steps: 4}) //etc..\n    brain.config({loss_fn:'cross_entropy', learning_fn: 'SGD'}) //not sure if i called it the right term, but this makes the learning rate go down linearly with the loss \n    brain.init()// runs all the weight setups and stuff\n\nbut the library has dense, lstm, recurrent, convolutional (conv), maxpool, and empty (for relu layer or dropout layer), and config has kernel sizes, time steps, weight and gradient clipping, dropout rates, weight and biases init numbers, (theres a \"calculated\" version which I found in a paper that does a sqrt(6/(in+out)+kernel\\_size\\^2 ) iirc, that i learned about and needed to use in the convolutional networks to stop my gradients from exploding every 30 seconds). I tried to write in a readable way, so you can see in the code the configs you can change, and what methods it has, but again, im totally new to javascript, so i wont be surprised if it ends up in r/badcode or something.\n\nAlso, important note, to try the mnist and quickdraw things i made, youll need to add the sorta trained models to the upload file section. that will take the json file and create the neural network object. If you want to train the networks, youll need to do the same but upload a .csv file with the data, each image separated by newlines, and each line being 785 values long, the first being the label. (if people care enough i could maybe create small csv files and upload them to the github project).\n\nI would recommend anyone starting out with 0 knowledge of machine learning to do the same, and try to make the simple networks on your own from scratch. I now have a much stronger understandings of how machine learning works in practice, but now I can learn and practice more advanced parts of the field, and actually understand what im doing, like why I would want to set up my network in a certain way, or why I would want to have certain hyperparameters in another way, rather than just cause some dude says so. Also, not only that, but now I have a really good grasp on javascript and while I was making this library, I managed to make a few extra little web apps for myself with angular, which make my life and job a bit easier, so the time investment is paying off already.\n\nMy next steps would be to learn about tensorflow, perhaps either starting with tensorflow.js, or perhaps starting to learn python. I really want to explore autoencoders and decoders, and perhaps make a shitty little clone of the sketch-rnn that quickdraw uses. That looks like a fun challenge.\n\nIf anyone here has any cool suggestions with what i should do with this library, or any advice for a beginner like me, or even just regular coding tips, I'd love to hear them all!", "link": "https://www.reddit.com/r/learnmachinelearning/comments/bwmkpn/maybe_this_is_a_bit_basic_for_this_sub_but_i_made/"}], "name": "Subreddit_learnmachinelearning_01_01_2019-30_12_2019"}