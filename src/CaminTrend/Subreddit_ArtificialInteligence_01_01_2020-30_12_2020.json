{"interestingcomments": [{"autor": "analyticsindiam", "date": "2020-02-05 10:21:15", "content": "#Benchmark #Analysis #Report- 6 Popular -----> Image !!!  classification models on #Keras were benchmarked for inference under adversarial attacks /!/ [removed]", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ez7jdc/benchmark_analysis_report_6_popular_image/"}, {"autor": "MLtinkerer", "date": "2020-02-01 06:05:48", "content": "ICYMI from Nvidia researchers: Produce a 3D object from a 2D -----> image !!!  (in less than 100 milliseconds!)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ex1u9a/icymi_from_nvidia_researchers_produce_a_3d_object/"}, {"autor": "bentalebabdelaziz", "date": "2020-01-31 21:27:04", "content": "Pic.Hance : A free AI-based tool for improving -----> image !!!  quality", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ewv9us/pichance_a_free_aibased_tool_for_improving_image/"}, {"autor": "speezLab", "date": "2020-04-17 18:14:17", "content": "I use AI to detect when I touch my face /!/ this was a fun \"quarantine project\" using AI (ML -----> image !!!  classification, specifically) to demonstrate to others a fun use of AI via TensorFlow.   Feedback welcome.\n\n[https://youtu.be/OZjlvkatLCs](https://youtu.be/OZjlvkatLCs)\n\nMy apologies if posting this violates a rule.  -Mike", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g37c55/i_use_ai_to_detect_when_i_touch_my_face/"}, {"autor": "Yuqing7", "date": "2020-04-16 18:52:36", "content": "Unsupervised -----> Image !!! -to------> Image !!!  Translation Turns Selfies Into Anime Characters /!/ With the release of the new Tensorflow implementation of unsupervised generative network U-GAT-IT, anyone can simply upload a selfie to the \u2018[Selfie 2 Waifu](https://waifu.lofiu.com/index.html)\u2019 website to create their own AI-generated *waifu*\\-style anime character in seconds. \n\nHere is a quick read: [Unsupervised Image-to-Image Translation Turns Selfies Into Anime Characters](https://medium.com/syncedreview/unsupervised-image-to-image-translation-turns-selfies-into-anime-characters-c90293e0f296)\n\nRead the paper at [arXiv](https://arxiv.org/pdf/1907.10830.pdf). Visit this project's [GitHub](https://github.com/taki0112/UGATIT) page.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g2l1o6/unsupervised_imagetoimage_translation_turns/"}, {"autor": "Yuqing7", "date": "2020-04-16 15:08:24", "content": "Hi-Res -----> Image !!! -To------> Image !!!  Daytime Translation Without Labels /!/ In a bid to generate high-resolution images showing realistic daytime changes while keeping accurate scene semantics, a team of researchers from Samsung AI Center, National Research University Higher School of Economics, and Skolkovo Institute of Science and Technology have proposed a novel image-to-image translation model, HiDT (High Resolution Daytime Translation).\n\nThe team took the modelling of various daytime appearances for given landscape images as their main task. The resulting HiDT model learns on fully unsupervised data and an upscaling technique for generating high-resolution images while safeguarding scene semantics. The work is introduced in the paper [High-Resolution Daytime Translation Without Domain Labels](https://arxiv.org/pdf/2003.08791.pdf)*.*\n\nHere is a quick read: [Hi-Res Image-To-Image Daytime Translation Without Labels](https://medium.com/syncedreview/hi-res-image-to-image-daytime-translation-without-labels-27aebeae776a)\n\nVisit this research at [GitHub](https://github.com/saic-mdal/HiDT).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g2gntq/hires_imagetoimage_daytime_translation_without/"}, {"autor": "MainImpression12", "date": "2020-04-16 07:13:53", "content": "AI-powered -----> Image !!!  Extraction Web scraping.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g2a5q1/aipowered_image_extraction_web_scraping/"}, {"autor": "lauram16_hello", "date": "2020-04-15 08:10:08", "content": "-----> Image !!!  Detection As A Service", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g1nrht/image_detection_as_a_service/"}, {"autor": "MLtinkerer", "date": "2020-04-14 21:48:50", "content": "From CVPR 2020: Turn any -----> picture !!!  to a 3D photo!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g1enhe/from_cvpr_2020_turn_any_picture_to_a_3d_photo/"}, {"autor": "Yuqing7", "date": "2020-04-13 18:09:42", "content": "AI Transforms RGB-D Images Into an Impressive 3D Format /!/ In 2018, Facebook introduced a machine learning-based 3D -----> photo !!!  feature which enabled users to generate an immersive 3D image from any ordinary -----> photo !!! . This was an \u201calmost perfect\u201d 3D image generator \u2014 yes it would grab your friends\u2019 attention, but the background renderings were pretty blurry. Now, a research group from Virginia Tech, National Tsing Hua University and Facebook has introduced a game-changing algorithm that generates impressive 3D photos from a single RGB-D (colour and depth) image.\n\nHere is a quick read: [AI Transforms RGB-D Images Into an Impressive 3D Format](https://medium.com/syncedreview/ai-transforms-rgb-d-images-into-an-impressive-3d-format-351aeeedd5ea)\n\nYou can find the original paper here: [3D Photography using Context-aware Layered Depth Inpainting](https://arxiv.org/pdf/2004.04727.pdf)\n\nYou can also visit the research team's GitHub page [here](https://shihmengli.github.io/3D-Photo-Inpainting).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g0oahh/ai_transforms_rgbd_images_into_an_impressive_3d/"}, {"autor": "LilBabyGrimm", "date": "2020-03-11 13:24:07", "content": "What Google's artificial neural network dreamed of, its own -----> image !!!  made up when hearing white noise.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/fgx376/what_googles_artificial_neural_network_dreamed_of/"}, {"autor": "MLtinkerer", "date": "2020-03-08 02:44:53", "content": "State of the art in transforming a source person -----> image !!!  to a target pose!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ff66ey/state_of_the_art_in_transforming_a_source_person/"}, {"autor": "zdurrani", "date": "2020-03-07 07:22:18", "content": "Facebook Now Lets You Turn Any 2D Photo into a 3D -----> Image !!!  Using AI Facebook said, This advance makes 3D photo technology easily accessible for the first time to the many millions of people who use single-lens camera phones or tablets. It also allows everyone to experience decades-old family photos.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/feruk8/facebook_now_lets_you_turn_any_2d_photo_into_a_3d/"}, {"autor": "DigiH0und", "date": "2020-05-24 14:56:52", "content": "Looking for a Star Trek enthusiast and / or video upscaling expert. /!/ Howdy folks, \n\nMy name is Joel Hruska, and I'm the Senior Editor of ExtremeTech. Since February, I've been working on an effort to upscale *Deep Space 9* using the Topaz Video AI Upscaler and various applications to improve the final video quality. \n\nA colleague of mine and myself have embarked on another project to see if the series can be improved, however, and we're curious to see if there's anyone in this community that might have some ideas for how to pull off this idea or be interested in helping. \n\n*Deep Space 9* will never be re-released in HD form, according to Paramount / CBS. It's not worth the effort, they say. \n\nBut there is **one** Star Trek show that got the full remaster treatment. It was shot on the same cameras as DS9. It overlapped it temporally. It used the same -----> film !!!  stock. *Star Trek: The Next Generation* is not identical to DS9, but it's a sibling-series and closer than any other TV show is going to be. \n\nSo. Here's the question we are trying to answer (we've already got a neural net built and upscaling, but I thought you guys might have some ideas for improving our approach): \n\n1). Is there a way to teach an AI how to upscale content by handing it the Blu-ray HD output of TNG as the \"After\" and the DVD content as \"Before,\" and then telling the AI \"Examine the differences between A and B, and then make your own attempt to turn \"B\" into \"A\"? \n\n2). If #1's approach is not possible, anybody got any ideas for how to leverage the fact that we have both SD and HD output for one show to aid in creating an upscaler that will work for *Deep Space 9*?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gpqzxp/looking_for_a_star_trek_enthusiast_and_or_video/"}, {"autor": "Pawan315", "date": "2020-05-23 13:31:35", "content": "SMART CCTV -----> camera !!!  project for COLLEGE students with CODE", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gp4yqt/smart_cctv_camera_project_for_college_students/"}, {"autor": "philnelson", "date": "2020-05-22 15:20:48", "content": "megaAI - A tiny-but-mighty 4K, 60 FPS -----> camera !!!  solution for computer vision &amp; AI", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gol9yk/megaai_a_tinybutmighty_4k_60_fps_camera_solution/"}, {"autor": "Yuqing7", "date": "2020-05-21 15:40:02", "content": "[R] Cross-domain Correspondence Learning for Exemplar-based Image Translation /!/ We invited Bo Zhang, the co-author of the paper *Cross-domain Correspondence Learning for Exemplar-based Image Translation,* to share this research.\n\n\"We present a general framework for exemplar-based -----> image !!!  translation, which synthesizes a photo-realistic -----> image !!!  from the input in a distinct domain (e.g., semantic segmentation mask, or edge map, or pose keypoints), given an exemplar -----> image !!! . The output has the style (e.g., color, texture) in consistency with the semantically corresponding objects in the exemplar. Our method is superior to state-of-the-art methods in terms of image quality significantly, with the image style faithful to the exemplar with semantic consistency. Moreover, we show the utility of our method for several applications.\"\n\nHere is the read: [Cross-domain Correspondence Learning for Exemplar-based Image Translation](https://medium.com/syncedreview/cross-domain-correspondence-learning-for-exemplar-based-image-translation-e62a9a43bf74)\n\n The paper *Cross-domain Correspondence Learning for Exemplar-based Image Translation* is on [arXiv](https://arxiv.org/pdf/2004.05571.pdf). Click [here ](https://panzhang0212.github.io/CoCosNet/)to visit the project website.\n\nShare your research with us by clicking [here](https://docs.google.com/forms/d/e/1FAIpQLSdaYAtvk8dtP__l1wvOjEKkQNAfZQNjX-G4OoEWcVU8jFIMug/viewform).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gnz4vs/r_crossdomain_correspondence_learning_for/"}, {"autor": "MLtinkerer", "date": "2020-06-30 09:16:40", "content": "Generate -----> photo !!! -realistic images given the input geometry and basic intrinsic properties, OR decompose real images back into their intrinsic components.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hijvti/generate_photorealistic_images_given_the_input/"}, {"autor": "pinter69", "date": "2020-06-26 14:40:20", "content": "From 2D to 3D Using Neural Nets - 3D reconstruction from single -----> image !!! , GANs for 3D model generation and more - Recording of the live free lecture for redditors", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hg8sz8/from_2d_to_3d_using_neural_nets_3d_reconstruction/"}, {"autor": "Crackracket", "date": "2020-08-05 15:41:22", "content": "Would it be possible to recreate the Beirut explosion from all of the -----> camera !!!  angles captured?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i47max/would_it_be_possible_to_recreate_the_beirut/"}, {"autor": "OnlyProggingForFun", "date": "2020-08-05 10:58:08", "content": "-----> image !!! -GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i437qe/imagegpt_from_openai_can_generate_the_pixels_of/"}, {"autor": "justinparker001", "date": "2020-08-05 09:17:36", "content": "Used Pixbim Color Surprise AI tool to color my black and white -----> photo !!! ", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i422uv/used_pixbim_color_surprise_ai_tool_to_color_my/"}, {"autor": "Robin5409", "date": "2020-08-04 20:00:00", "content": "Why Machine Learning is Being Termed As the Next Big Thing /!/ &amp;#x200B;\n\nhttps://preview.redd.it/5ki0lwr9k1f51.jpg?width=630&amp;format=pjpg&amp;auto=webp&amp;s=faabee5cf6e64142256ab2087dc9e88ae65b66a3\n\nHave you wondered what powers the highly personalized recommendations on your mobile device from Amazon? Do you wonder how Uber determines arrival times of your booked app cab? I am sure most of you have wondered at some point in time, how Snapchat uses filters or influences stories.  \nThese are everyday examples of machine learning algorithms at work. The common thread is acting quickly on business intelligence for an edge in highly competitive industries.\n\n**What is machine learning and why does it matter?**  \nMachine learning is an application of [**artificial intelligence (AI)**](https://www.greatlearning.in/pg-program-artificial-intelligence-course) which allows computer programs to progressively learn and improvise from its experience with the data. It automates analytics by using algorithms that learn iteratively, to make predictions. Its simple technique of self-learning rather than rule-based programming has found a wide application across multiple scenarios. So this technology has pervaded everyday lives, whether bringing ease of living with navigation recommendations or warning you of market volatility for best investment decisions. Therefore, machine learning matters; as it shapes your ease of living or decision-making. It has integrated so deeply into daily life that you will most likely not notice its application. For instance, the active filtering of your spam messages by Gmail.\n\n**How does machine learning bring value to a business?**  \nMachine learning is for both, problem-solving and adding value to a business.  \nOn the marketing front, machine learning analyses historical and real-time data for modifying marketing strategies, instant upsell and cross-sell recommendations, and making predictions of customer behavior. This in turns adds value to marketing and segmentation strategies for personalized recommendations. Machine learning models based on various marketing metrics help predict the prospects of conversions. The unsupervised learning technique of machine learning algorithm further identifies buying patterns, by clustering products to make better product recommendations.\n\nIn the financial world, the advantages of machine learning are phenomenal. The most significant use is fraud detection, with its ability to learn from data and spot anomalies and suspicious patterns. Other uses are algorithmic market trading, loan underwriting and regulatory compliance with anti-money laundering laws. In manufacturing and logistics, machine learning helps identify the gaps and weak nodes for devising predictive maintenance. The same ability of learning algorithms to spot patterns can help report security breaches in a database as and when they occur.\n\nThe use of machine learning thus spans across industries and applications, enhancing customer experience, and adding business value for higher returns on investments (ROI). Online searches with intuitive results are perfect examples of ML use to cut downtime by making predictions. Algorithms using natural language processing (NLP) are used in AI chatbots, to act as powerful self-learning customer agents. This optimizes resources and builds an additional channel for customer analytics.\n\n**Real world applications and use cases**  \nSome of the most prolific users are in the banking and financial industry. HDFC Bank has begun rolling out its technology stack with ML and AI. The focus is on enhanced services across the entire spectrum like loan disbursement, transactions, hiring, customer experience and personal banking. Additionally, HDFC has started deploying chatbots for customer engagement. The conversational interface offers a personalized and seamless customer experience.  \nMajor eCommerce platform, Flipkart implements over 60 machine learning models to generate insights \u2014 \u201chow a sale is going, which deals are working or not working, at which point customers are dropping off\u201d, and so on.\n\nNebula, an agro-based company, is leveraging ML to solve problems in Indian agriculture. The testing of agricultural products is done using deep learning and -----> image !!!  recognition technologies for speedier and quality results, enabling farmers to get better prices for their products.  \nIn the HR marketplace, Aspiring Minds has an assessment-based job search platform for adding value to merit-based recruitment. Innov4Sight Health and Biomedical Systems is a healthcare start-up that builds intelligent solutions for medical diagnosis using machine learning techniques. SkinCurate powers its diagnostic and therapeutic research for customized treatment in the skin, using state-of-the-art ML techniques.\n\n**Trends and possibilities shaping a machine learning-driven future**  \nKey technological trends powering machine learning \u2014 data flywheel, algorithm marketplace, and cloud-hosted intelligence \u2014 are expected to shape the future deployment of ML. The advantage of increased user-generated data for flywheel impact will be used by companies for rolling out future products and programs like Tesla is planning for its self-driving cars. Scaled-up machine learning algorithms have created an algorithm marketplace, for reaping benefits of shared algorithmic intelligence. Hosted machine learning platforms are offering pre-trained models as a SaaS delivery, for economies of scale.\n\nMarketing, financial services, and healthcare; are the sectors expected to see prolific and innovative applications of machine learning. It helps structure marketing insight for demand forecasting and predictive recommendations. In banking and finance, ML will be indispensable for the two key challenge areas, fraud detection, and risk management. The field of healthcare will emerge as the most significant application of machine learning innovation, as the results have the power to transform human lives.\n\nThe future possibilities of ML are limitless. Imagination, problem-solving and professional expertise in machine learning skills; are expected to drive innovations in business strategies and new product offerings. ML is the future of AI. If you are interested in the domain of AI and machine learning and want to learn more about the subject, check out [**Great Learning\u2019s PG program in Artificial Intelligence and Machine Learning.**](https://www.greatlearning.in/pg-program-artificial-intelligence-course)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i3qka0/why_machine_learning_is_being_termed_as_the_next/"}, {"autor": "elevatorbeat", "date": "2020-08-04 17:56:43", "content": "The Alchemy of AI: Transforming Inputs into Insight. /!/ We've all heard the buzzwords about AI. But very few people outside of this sub can really define what artificial intelligence is or why it's useful.\n\nFor us, we think of artificial intelligence as a tool that allows you\u00a0to intuitively discover the relationship between inputs and outputs. What goes into an AI model can be translated, converted, and put to work via a variety of methodologies.\u00a0\n\nFor example, an input may be drone footage of a disaster area (-----> photo !!! ) and its output could be a damage estimate (financial).\n\nIn this guide, we\u2019ll explore all of the different kinds of inputs and outputs you can work with to build AI solutions.\n\nWhen combined with your existing data, these possibilities can give you the building blocks you need to string together a powerful AI capability for your organization.\n\nIf you've ever wondered what your company can do with its data, then this will definitely get your wheels turning.\n\n# Think about AI as Inputs and Outputs\n\nSo now that we've explored how AI is a tool for finding the relationship between inputs in outputs, let's define what some of those major inputs and outputs can be. \n\n# Inputs\n\n# SEMANTIC DATA\n\nBy now, AI is super-human in its ability to understand and process language. This is obviously super useful because a huge part of the world\u2019s information is one kind of communication or another. We\u2019re talking documents, books, handwriting, articles, speech, etc.\u00a0\n\nNatural Language Processing (NLP) models think about language in terms of each word\u2019s relationship to related words. We can think of NLP models as a vast 3-D word cloud where related words cluster together forming vectors of associations and understanding. In effect, language processing models convert language into mathematical relationships.\n\nAlthough this may sound a bit abstract, our brains actually process language in a similar way. Consider this sentence:  \n*The dove dove into the water.*\n\nMost of us can pretty easily intuit from the sentence structure that the first *dove* is the noun and the second *dove* is an action related to water.\n\nLanguages like German, Chinese, and Korean drop these associations right into their vocabulary. For example, in German, *kindergarten* literally means *child garden*. In Korean, the word for *fish* (\ubb3c\uace0\uae30) is a compound of *water* (\ubb3c) and *meat* (\uace0\uae30).\n\nAll of this is to say that by quantifying the relationships words have to other words, AI language models have gotten extremely adept at learning to read, write, translate and summarize with ease.\n\n## QUANTITATIVE DATA\n\nAI models are built on complex mathematical equations so it shouldn\u2019t surprise you that AI speaks the language of numbers. AI models can vacuum up all sorts of quantitative data such as statistics, analytics, dates, sequences, financial information, etc.\n\n## Multimedia\n\nWhereas semantic and quantitative data uses abstract concepts as inputs, multimedia data is much more concrete. When considering what multimedia data you might be able to use, think about your senses:\n\n* Visual data can include photography, video, satellite footage, video surveillance\n* Auditory data such as sound recordings or RADAR.\n* Sensory data such as temperature or LIDAR.\n\nHell, if you\u2019ve got an [electronic nose](https://en.wikipedia.org/wiki/Electronic_nose?utm_medium=email&amp;_hsmi=2&amp;_hsenc=p2ANqtz-95ooUXjGQzht7-GRYkNbKLkGV4mg9nB3gDFY3Vyd2XVAY0wsgy4OE5HrmPwMQ8-_mOX7Y7xTptCnsr2cAi0_quRMeEXQ&amp;utm_content=2&amp;utm_source=hs_email), you could even consider olfactory information.\u00a0\n\nBy the way: data scientists can build AI models that consider datasets from all of these categories at once. For example, you could build a healthcare diagnostic model by integrating a doctor\u2019s description of the patient\u2019s symptoms (semantic), their bloodwork (quantitative), and chest Xrays (multimedia).\n\n# Outputs\n\nAs we discussed in [Chapter 1](https://www.manceps.com/resources/complete-ai-guide/chapter-1-what-is-artificial-intelligence), AI models build intuition about the relationship between inputs and outputs. To better understand how your organization could put AI to work, you\u2019ve got to consider both. Broadly speaking, AI can be used to do two main things: surface information or create content.\n\nSurfacing information includes things like categorization, pattern recognition, and prediction. These outputs can then be piped into systems that either (a) deliver this essential information to stakeholders for better decision-making and/or (b) put this information to work via some kind of hardware or software.\n\nFor example, an AI model that surfaces a stock prediction could be put into production as a daily email that arrives in your inbox or as an app that will automatically conduct trades for you.\n\nAlternately, AIs can be used to create content. In a broad sense, the types of content that cognitive intelligence can create is similar to the inputs that AI can consider. For example, AIs can produce both articles and images of all kinds of crazy iterations, as we\u2019ll discuss below.\n\nLet\u2019s consider each of these outputs in more detail:\n\n## SURFACING INFORMATION\n\n### Categorization\n\nAI is all about using data to make judgments or find patterns. In the case of categorization, AI creates a series of mathematical relationships to map the relative similarities and differences of similar objects. This kind of labeling is useful for all kinds of businesses.\n\nConsider these examples:\n\n* Quality assurance inspectors determine if a product is defective.\n* Doctors determine if a patient\u2019s bloodwork means they are healthy.\n* Mortgage lenders determine if an applicant is highly qualified.\n* Grocery stores determine if their produce is starting to rot.\n* Marketers identify conversion-optimized landing pages.\n* Programmers locate broken code.\n\nWith enough examples, an AI model could be trained to support the labeling/categorization process of any of these use cases.\n\n### Pattern Recognition\n\nWe can think of pattern recognition as a much more complex version of categorization. Whereas categorization usually considers one set of inputs, pattern recognition can consider an almost limitless number.\n\nIt\u2019s this type of AI capability that enables credit card companies to detect fraud, retail organizations to elastically price items, and self-driving cars to make instant driving decisions.\n\nWhen imagining how to bring pattern recognition capabilities to your organization, think in terms of the systems or processes you have in place to make decisions.\n\n### Predictive Analytics\n\nWith the right data, artificial intelligence is capable of making all kinds of predictions from heart attacks to stock market fluctuations to hurricanes. Very few companies are tapping into this future-facing capability and those that do tend to be primarily focused on tactical use cases like predictive maintenance.\n\nHowever, having visibility of future events means that business leaders have the tools they need to make adjustments to their supply chain, their strategy, and the execution of their objectives.\n\nWith the right data, you can answer almost any question about the future. The oracle is real.\n\n### Personalization\n\nToday AI-driven recommendation engines power your Netflix queue, your Amazon home screen, your Google search results, and your Spotify playlist. Every single time you read or click-through (or click away) these companies are gathering information about your interests and your preferences.\n\nIn fact, it is a similar engine that is driving much of the advertising across the internet. You know that feeling you sometimes get that Facebook is listening to you? The reason this may feel so is that their predictive engines are so powerful they\u2019ve mapped a veritable galaxy of data points to identify things that they should try to sell to you.\n\nPersonalization offers companies the opportunity to have perfect product-market alignment. By being able to offer each of your customers something a little different, you ensure that the products and services you offer resonate in an unforgettable way.\n\n## CREATING CONTENT\n\nIn a broad sense, all of the inputs we discussed above can also become outputs for an AI model so let\u2019s take them one at a time. For example:\n\n### Written or Spoken Communication\n\nAI can generate all kinds of language as outputs, such as articles, summaries, labels, etc. We\u2019re not just talking printed text here. As Amazon Alexa has shown, AI-generated communication can also be piped to voice-activated assistants.  \nIn the case of articles, AI has taken all sorts of information to auto-generate articles. Publishers are using the capability to automatically write weather reports, sports stories, and updates on financial markets.\n\nText summarization is particularly powerful and can be a huge opportunity for your organization. AI can literally take a 2,000-page patient case file, extract the necessary information, and summarize it into a paragraph or two. A use case might be a law firm that converts boxes of handwritten evidence into an index of every item that\u2019s there.\n\n### MULTIMEDIA\n\nAlready AI is generating a wealth of visual or auditory content. Artificial intelligence has been used to generate images of human faces, color black and white photos, write music, and create soundscapes, produce charts and graphs.\n\n# Translating Inputs and Outputs\n\nAs a final note, keep in mind that AI models become crazy powerful when you use them to translate one input type into a different output type. For example, an AI model could be trained to convert drone footage of a disaster area into a 12-page summary report for FEMA.\n\nTo be sure, building such a model would be complex, requiring both image processing layers to determine damage and text summarization layers to write that damage into easy-to-understand paragraphs \u2014 however, it is this exact type of complexity you should be thinking about when imaging the kinds of AI solutions to bring to your company.\n\nRemember: artificial intelligence can transform information into almost anything!  \n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_  \n\n\n*This chapter is an excerpt from the ebook, The Complete Guide to Bringing Artificial Intelligence to your Organization.* [*Access the full guide here.*](https://www.manceps.com/ai-guide?utm_source=Reddit&amp;utm_medium=Post&amp;utm_campaign=Everything%20You%20Need%20to%20Understand%20Artificial%20Intelligence)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i3o62s/the_alchemy_of_ai_transforming_inputs_into_insight/"}, {"autor": "analyticsindiam", "date": "2020-08-03 18:36:04", "content": "-----> Image !!!  Feature Extraction Using Scikit -----> Image !!!  - A Hands-On Guide /!/ [https://analyticsindiamag.com/image-feature-extraction-using-scikit-image-a-hands-on-guide/](https://analyticsindiamag.com/image-feature-extraction-using-scikit-image-a-hands-on-guide/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i32obl/image_feature_extraction_using_scikit_image_a/"}, {"autor": "EspressoInsight", "date": "2020-11-23 07:22:44", "content": "Nvidia's ai paint tool in beta /!/ Nvidia's AI playground has this tool where you can create -----> photo !!! -realistic drawings by just making a few keystrokes on a digital paint pad.\n\nMore here - [http://espressoinsight.com/2020/11/22/ai-art/](http://espressoinsight.com/2020/11/22/ai-art/) \\- but ultimately, I've heard about someone at Stanford selling another art-based AI tool that essentially created renderings of art using AI / ML but that took famous artwork as inputs / training data. \n\nThis of course is a little different, as you'll notice most of what the GauGAN tool was probably trained on was scenery photos of nature etc.\n\nCould be used by game developers, graphic designers, maybe? What do you all think?\n\nBelieve it or not its actually kind of fun to try", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jzd4wb/nvidias_ai_paint_tool_in_beta/"}, {"autor": "itisfor", "date": "2020-12-29 15:49:15", "content": "Vehicle detection on Map /!/ Guys, I am working on vehicle detection. I have used pretrained yolo algorithm on coco data set. I am counting vehicles but one thing where I am confused is how can I show strength of vehicles on map to predict if there is crowd on roads or not. The input I am using is a video file from a cctv -----> camera !!! . Is there any suggestion on this problem?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kmgt4x/vehicle_detection_on_map/"}, {"autor": "iampoopybutt", "date": "2020-12-27 05:01:22", "content": "I need Help finding a website /!/ Does anybody know a website that you can input multiple -----> image !!! s and ai will give an -----> image !!!  based on the others? (preferably one that works on mobile)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kkxmqw/i_need_help_finding_a_website/"}, {"autor": "pocomaco", "date": "2020-12-26 15:42:10", "content": "What happens to this? /!/ Artificial intelligence is trained to learn a total of three -----> image !!! s, two -----> image !!! s and an -----> image !!!  that combines the two -----> image !!! s.\n At that time, the artificial intelligence looks at the synthesized image\n Do you recognize that \"this image is a composite of two images\"?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kkkg8u/what_happens_to_this/"}, {"autor": "HShahzad108277", "date": "2020-12-25 17:13:40", "content": "Generating scenes consisting of a 3d object in bulk to speed up the process of gathering data for neural networks by thousands of times /!/ I agree, the title sounds like a weird mash of nonsense but I don't know how to phrase it.\n\nNeural networks that aim for -----> image !!!  recognition are super cool, but require you to take and gather -----> image !!! s of that object in an array of different locations and select the -----> image !!! . That takes time. \n\nWhat I propose is a program that takes a 3d scan of that desired object and generates thousands of different pictures in different rooms where that 3d object is randomly allocated. Then the computer takes images from around the room where the object is in sight and feeds stores it as training data.\n\nThis can be done thousands of times over and gather data for a neural network very fast.\n\nSO basically, say I wanted a neural network to recognize my phone, I would scan the phone using a 3d scanner and obtain a 3d model of it. Then it would be fed into some sort of program that can move 3d objects around and by using already existing 3d rooms,  t can place the object around the room then take many pictures of it around the place.\n\nI feel like this is a decent idea however I don't know a lot about AI so this could be a shot in the dark.\n\nWhat do you guys think of this idea?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kk2dh3/generating_scenes_consisting_of_a_3d_object_in/"}, {"autor": "KMuchoki", "date": "2020-12-24 16:55:17", "content": "Retrieve Images By Visual Similarity Using Deep Learned Features with Python and Keras /!/ This tutorial will cover the basics to learn how to find the most visually similar images from a set, to a query one, using the python language over a Unix operating system. You will be guided through the process of setting a minimal environment and implement the scripts to achieve this objective. You will learn how to use a pre-trained deep model from the Keras library to generate a vector representation of each -----> image !!! . This vector representation will then be used to find similar images to a query one. \n\n [https://www.education-ecosystem.com/leandromaf/ZB3b3-how-to-retrieve-images-by-visual-similarity-using-deep-lear](https://www.education-ecosystem.com/leandromaf/ZB3b3-how-to-retrieve-images-by-visual-similarity-using-deep-lear)\n\n#", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kjim7y/retrieve_images_by_visual_similarity_using_deep/"}, {"autor": "franco-melanieh", "date": "2020-10-16 12:40:02", "content": "AI Generated Ad-Creatives for Socialmedia-Ads /!/ Hey Guys,\n\nso i recently stumbled upon the latest techdemos using openAI's GTP3 Language Model.\n\nAnd i had a quick thought experiment about using this systems to build a tool that lets marketeers evaluete their ad creatives (text, -----> image !!!  and CTA) and give them a hint on how it will resonade with the target audience. Mediabuyers wont have to waste as mutch money on testing then perhabs!\n\nThe next step would be a system that can generate those creatives with little inputs about target audience and core components of the business.\n\nThat do you think about this?  \nWill it be possible / is this allready in development ?\n\nThank you and greetings from germany.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jc928e/ai_generated_adcreatives_for_socialmediaads/"}, {"autor": "VictoriaSobocki", "date": "2020-10-15 23:14:14", "content": "AI/Legal Tech Master\u2019s Thesis &amp; Companies/Institutions \ud83e\udd16\ud83d\udcdd /!/ Hi everyone, hope I can ask these two questions here:\n\n&amp;#x200B;\n\n1. What is a good subject to write an AI/legal tech master\u2019s thesis about in terms of future relevancy and perhaps labour/job market?   \n I am heavily considering deepfake video and audio, -----> image !!!  recognition/deep learning uses/misuses with e.g. adversarial examples or Neuralink and its possible implications on society/humanity.   \n I am currently studying at the Faculty of Law at University of Copenhagen and I have 15 days to choose my subject(s).  \n \n2. What are some good AI/ML/DL/robolaw/regtech/transhumanism/legal tech companies or institutions to look into for insight (and maybe collaboration) in this field?   \n I live in Copenhagen, Denmark, but I\u2019m assuming that the vast majority of these companies and institutions are from abroad.  \n \n\nThank you in advance and have a great day!  \n \n\nBest regards,\n\nVictoria", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jbyirz/ailegal_tech_masters_thesis_companiesinstitutions/"}, {"autor": "Yuqing7", "date": "2020-10-15 20:16:21", "content": "[R] MIT Researcher Neil Thompson on Deep Learning\u2019s Insatiable Compute Demands and Possible Solutions /!/ As the size of deep learning models continues to increase, so does their appetite for compute. And that has Neil Thompson, a research scientist with MIT\u2019s Computer Science and Artificial Intelligence Lab (CSAIL), concerned.\n\n\u201c**The growth in computing power needed for deep learning models is quickly becoming unsustainable,**\u201d Thompson recently told *Synced.* Thompson is first author on the paper *The Computational Limits of Deep Learning,* which examines years of data and analyzes **1,058 research papers** covering domains such as -----> image !!!  classification, object detection, question answering, named-entity recognition and machine translation. The paper proposes that deep learning is not computationally expensive by accident, but by design. And the increasing computational costs in deep learning have been central to its performance improvements.\n\nHere is a quick read: [MIT Researcher Neil Thompson on Deep Learning\u2019s Insatiable Compute Demands and Possible Solutions](https://syncedreview.com/2020/10/15/mit-researcher-neil-thompson-on-deep-learnings-insatiable-compute-demands-and-possible-solutions/)\n\nThe paper *The Computational Limits of Deep Learning* is on [arXiv](https://arxiv.org/pdf/2007.05558.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jbvdi3/r_mit_researcher_neil_thompson_on_deep_learnings/"}, {"autor": "Yuqing7", "date": "2020-10-14 20:36:14", "content": "[R] NeurIPS 2020 Workshop | Indie GAN Interpolation Method Turns Selfies Into Cartoon Characters /!/ In a paper submitted to the [*NeurIPS 2020 Machine Learning for Creativity and Design workshop*](https://neurips2020creativity.github.io/), Pinkney and Adler present their research, which enables -----> image !!!  generation in novel domains and with a degree of creative control on the output. The team\u2019s resolution dependant GAN interpolation method combines high resolution layers of an FFHQ model with low resolution layers from a model transferred to animated character faces to enable the combination of realistic facial textures with the structural characteristics of a cartoon.\n\nHere is a quick read: [NeurIPS 2020 Workshop | Indie GAN Interpolation Method Turns Selfies Into Cartoon Characters](https://syncedreview.com/2020/10/14/neurips-2020-workshop-indie-gan-interpolation-method-turns-selfies-into-cartoon-characters/)\n\nThe paper *Resolution Dependant GAN Interpolation for Controllable Image Synthesis Between Domains* is on [arXiv](https://arxiv.org/pdf/2010.05334.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jb90il/r_neurips_2020_workshop_indie_gan_interpolation/"}, {"autor": "m1900kang2", "date": "2020-10-14 14:07:58", "content": "Previously, TecoGAN AI was able to produce high resolution images and video from low resolution inputs. With supersampling (splitting pixels into more pixels to create a higher detail -----> image !!! ), real time situations can be resolved.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jb1bwa/previously_tecogan_ai_was_able_to_produce_high/"}, {"autor": "AhmedHossam01", "date": "2020-04-12 18:22:35", "content": "What is the business potential of artificial intelligence? /!/ Hello AI folks out there. I'm a web developer who likes AI and planning to study it. But, personally I like to be on the top of whatever field I'm studying. I'm working really hard for that in my current field of study and work which is web development. I see that AI is hard, and I'm totally ready for that because I already love programming and solving problems. However, In the same time, I don't want to put like 15 hours a day to study AI and end up with no real business value. I know AI is used by almost all big companies out there but they're using very little of it like video recommendations, -----> image !!!  recognition and all these things we know. I'm talking about these brilliant AI technologies being researched and invented everyday. Do they have real business value?\n\nShort Question: Do you thank AI have the potential to be the next dot com mania in business or even the new electricity? Is it a chance?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/g01uow/what_is_the_business_potential_of_artificial/"}, {"autor": "kajri", "date": "2020-05-04 12:05:55", "content": "To contribute to the fight against the deadly COVID-19 outbreak, an industrial Artificial Intelligence company, Landing AI has created a tool that can detect the social distance between people by analyzing real-time video streaming from the -----> camera !!! .", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gdadnx/to_contribute_to_the_fight_against_the_deadly/"}, {"autor": "MikeKuijper", "date": "2020-05-03 15:37:47", "content": "Colourful noise in deepfake autoencoder. Any ideas? /!/ &amp;#x200B;\n\n[Input and output of my autoencoder. Ideally, the the images are identical.](https://preview.redd.it/89spsldnjkw41.png?width=512&amp;format=png&amp;auto=webp&amp;s=cdff8d9cb639513e50b08ca03a98715e5b42d0e2)\n\nHello everyone!\n\nI\u2019ve been struggling with my autoencoder for a while now. For some reason, it generates a whole lot of colourful noise, as you can see on the attached -----> image !!! . This model has been training for at least 150 hours. Does any of you have an idea what causes this and what I can do to remove it?\n\nAll the code for this was custom-written, though it\u2019s based on what I could find on the internet about gradient descent. I know that there are wonderful libraries that can do a lot of the work for you, but I started this project to learn about how these libraries work. So, I thought the best way to learn about this was to try to make a deepfake myself. I\u2019m absolutely not an expert, so any help is welcome.\n\n**How it works:**  \n First, the initial image (32x32) gets divided into the three colour channels \u2013 red, green and blue \u2013 and each of these channels gets a dedicated neural network. This is to reduce the amount of memory necessary. Those networks consist of 3 layers of respectively 1024, 256 and 1024 neurons. The outputs of these networks get combined into the final output image.\n\n&amp;#x200B;\n\nNOTE: The iteration count is off, because I saved the model and the counter only counts the iterations of one session.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gcslri/colourful_noise_in_deepfake_autoencoder_any_ideas/"}, {"autor": "VisualCoding", "date": "2020-05-01 08:08:56", "content": "AI creates high-quality 3D avatars from a single -----> image !!! .", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gbe5kh/ai_creates_highquality_3d_avatars_from_a_single/"}, {"autor": "MLtinkerer", "date": "2020-04-30 02:19:56", "content": "From CVPR: Reconstruct photorealistic 3D faces from a single \"in-the-wild\" -----> image !!!  with an increasing level of detail", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gan3c6/from_cvpr_reconstruct_photorealistic_3d_faces/"}, {"autor": "HIPERATIVO", "date": "2020-04-29 23:13:34", "content": "Google Lens /!/ Does anyone know a software that does the same as google Lens, -----> image !!!  analysis, text for copy, and so on for windows 10 ?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gak34t/google_lens/"}, {"autor": "ACAIworkshop", "date": "2020-04-29 22:03:22", "content": "Animal Crossing AI workshop -- Call for Abstracts ACAI 2020 /!/ **Animal Crossing Artificial Intelligence Workshop**\n\n[http://acaiworkshop.com/](http://acaiworkshop.com/)\n\nWe are announcing the first AI workshop hosted in Animal Crossing New Horizons. This is an experiment to see what it feels like to experience a workshop located in Animal Crossing. We would like to build a space for AI researchers to have meaningful interactions, and share their work.\n\nThis workshop is partially in response to the world in quarantine for Corona Virus. All academic conferences are now remote. One of the most valuable parts of conferences are the conversations and random interactions shared with colleagues. This is missing from most remote conferences. We hope to fill that void, by hosting a workshop in the virtual space of Animal Crossing, while having Zoom rooms where attendees can network and have conversations. The talks will be presented in a workshop area on an Animal Crossing Island. The actual audio, slide shows, and the virtual conference space will be live streamed to all attendees over Zoom.\n\n**Call for Abstracts**\n\nWe welcome abstract submissions from any domain of AI, however we highly encourage presentations in the following fields:  \n\u200b\n\n* Computational models of narrative\n* Automatic speech recognition\n* -----> Image !!!  generation\n* Natural language understanding\n* Conversational AI\n* Computer vision\n* Computational creativity\n* Music information retrieval\n* Automatic musical understanding\n* Video game AI\n\nWe are highlighting these topics due to their relationship to Animal Crossing and interacting with virtual characters. These fields have the potential to affect the depth of the interactions between people and virtual characters in any context, be they Animal Crossing villagers, virtual companions, or even virtual teachers.\n\nIf you are interested in submitting, please head over to the [Submit an Abstract](http://acaiworkshop.com/submit-an-abstract.html) page.\n\n[http://acaiworkshop.com/submit-an-abstract.html](http://acaiworkshop.com/submit-an-abstract.html)\n\nIf you want to attend the conference or stay updates on the event please register here:\n\n[http://acaiworkshop.com/registration.html](http://acaiworkshop.com/registration.html)\n\nHere is our twitter \n\n [https://twitter.com/ACAIWorkshop](https://twitter.com/ACAIWorkshop)\n\n**Presentation Logistics**\n\nEach presentation will be 15 minutes long, followed by 5 minutes of questions from the audience. There are two components to each presentation: 1) Your Animal Crossing character will *give* the presentation in a workshop area on our workshop island. There will be workshop attendees on the island to *listen* to your talk. 2) You will call into a Zoom room, and give your talk over video call. You can also share your screen if you wish to use slides or whatever visual materials you desire.\n\n**Coffee Breaks + Chance Interactions** \u2615\u2615\u2615\u2615\n\nSince our desire is to replicate the social interactions of a real workshop, we will schedule coffee breaks into the workshop. We will have many different Zoom rooms so that smaller conversations can happen simultaneously. We want to provide a virtual space for you (the participant) to meet other researchers, and make meaningful connections.\n\n**Organizers**\n\nThis workshop is being organized by me, [Josh Eisenberg](http://www.research-josh.com/) PhD. I am an NLU researcher who focuses on teaching computers to understand narrative and dialogue. I am currently the lead scientist in NLU at [Artie Inc](http://artie.com/). I am putting this workshop together to build meaningful connections with other like-minded AI researchers, who also just happen to enjoy Animal Crossing.\n\nIf you have any questions or feedback please contact me at: [joshuadeisenberg@gmail.com](mailto:joshuadeisenberg@gmail.com)\n\n**Dates**\n\nDeadline for abstract submission: Friday June 12, 2020  \nNotification of acceptance: Friday June 26, 2020  \nWorkshop: Thursday July 23, 2020\n\n**Registration** If you want to attend the workshop please fill out the registration form: [http://acaiworkshop.com/registration.html](http://acaiworkshop.com/registration.html) This will put you on a list, so that you are given credentials to visit the workshop islands in Animal Crossing and watch the conference on Zoom. If you are planning on submitting an abstract so that you can present please fill out this form: [http://acaiworkshop.com/submit-an-abstract.html](http://acaiworkshop.com/submit-an-abstract.html)\n\n**FAQ**  \nQ: DO I NEED A SWITCH or AC TO PARTICIPATE??\n\nA: NO! **you don't have a switch or AC you can still participate through Zoom. My last intention is to prevent anyone from participating due to finances. We will work with you to create an avatar for your talk. Feel free to submit even if you don't have AC.**\n\n&amp;#x200B;\n\nI made an official twitter account for updates: [https://twitter.com/ACAIWorkshop](https://twitter.com/ACAIWorkshop)\n\nAlso, wanted to thank everyone for all the support. We have over 150 registrations for attendees, and over 5 abstract proposals. Congrats everyone. This is amazing, given that I announced this less than 24 hours ago, and I only posted about it here and on my linkedin. Thanks for sharing and for all the support.\n\nAlso we got two writeups in chinese publications :)\n\n[https://www.jiqizhixin.com/articles/2020-04-29-4](https://www.jiqizhixin.com/articles/2020-04-29-4)\n\n[https://new.qq.com/omn/20200429/20200429A0CEXD00.html](https://new.qq.com/omn/20200429/20200429A0CEXD00.html)\n\nAnd one writeup in synced\n\n[https://medium.com/syncedreview/algorithms-islands-nook-miles-ai-workshop-will-be-held-in-animal-crossing-a35cf3c4d05](https://medium.com/syncedreview/algorithms-islands-nook-miles-ai-workshop-will-be-held-in-animal-crossing-a35cf3c4d05)\n\nThey're actually real articles with commentary about the workshop, and the nature of AI research in a quarantine world. Can't believe this has all happened so fast.\\\\\n\nI encourage everyone to register, and submit an abstract if you are working on relevant research/projects :)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gaiti3/animal_crossing_ai_workshop_call_for_abstracts/"}, {"autor": "bantykumarsoni", "date": "2020-04-29 08:26:20", "content": "Data annotation platform /!/ Learning spiral has a workforce with a diverse set of skills and the ability to deliver data annotation including the most significant -----> image !!!  annotation services.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ga5mrf/data_annotation_platform/"}, {"autor": "MLtinkerer", "date": "2020-02-20 01:50:26", "content": "ICYMI from CVPR: Produce full-body renderings of a person for varying body pose and -----> camera !!!  position", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/f6li7w/icymi_from_cvpr_produce_fullbody_renderings_of_a/"}, {"autor": "Singular23", "date": "2020-02-18 00:19:39", "content": "De blurring Images with ANN. My first attempt at -----> image !!!  manipulation with Pytorch. It KINDA works... except if you are Sylvester Stallome. The you'll turn into a kid.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/f5immv/de_blurring_images_with_ann_my_first_attempt_at/"}, {"autor": "_4lexander_", "date": "2020-03-25 08:30:57", "content": "Just trained some deep learning models on a google TPU and it was incredibly fast. Will GPUs be out for deep learning? /!/ After working with a TPUv3 I found that it's amazingly quick and relatively cheap! Benchmarks on my task (-----> image !!!  recognition with flowers on Kaggle) put the TPUv3 at almost twice the speed of 8xV100, and at a little less than a quarter of the cost. Also, the modifications one needs to make to their software/code (vs a single gpu setup) is similar across the two compared setups.\n\nSo I'm wondering what gives. I feel like as soon as people start to come around, TPUs are going to storm the scene and leave GPUs in the dust. I wonder if\n\n(a) I'm missing some crucial aspects which make my assessment wrong\n\n(b) Nvidia (or other gpu developers) are working on entering a newly emerging TPU market", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/fomtdh/just_trained_some_deep_learning_models_on_a/"}, {"autor": "peachishwill", "date": "2020-01-13 11:25:54", "content": "\u2018Creative A.I: Companion or Competitor?\u2019 30 minute short -----> film !!!  discussing the role of A.I in the creative workplace and wether or not artists and creatives should be concerned.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/eo2vrs/creative_ai_companion_or_competitor_30_minute/"}, {"autor": "MLtinkerer", "date": "2020-01-27 23:48:56", "content": "Latest from Microsoft researchers: ImageBERT (for -----> image !!! -text joint embedding)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/euwvjo/latest_from_microsoft_researchers_imagebert_for/"}, {"autor": "MLtinkerer", "date": "2020-01-24 03:52:35", "content": "Enhance a dim-lit -----> image !!!  using this new state of the art method", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/et4v1s/enhance_a_dimlit_image_using_this_new_state_of/"}, {"autor": "BloodyWeed", "date": "2020-06-24 16:53:52", "content": "Algorithm for AI based website builder /!/ Hey guys I am working on a website builder, and I wanna add an option to generate a website based on the some questions, I wanna add two options, one is where user will select the website and the other one in which it'll ask questions and will generate it automatically based on those questions. I have to build a simple dataset and use a basic algorithm, I have very basic experience in Ml and AI, so please suggest me how should a make dataset and which algorithm I should use. Questions will be basic like \"Do you want minimal design?\" Or \"do you want a -----> photo !!!  gallery?\" Etc", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hf4m2w/algorithm_for_ai_based_website_builder/"}, {"autor": "Yuqing7", "date": "2020-06-23 19:28:33", "content": "[R] Google &amp; DeepMind Researchers Revamp ImageNet /!/ A  team of researchers from Google Brain in Z\u00fcrich and DeepMind London believe one of the world\u2019s most popular -----> image !!!  databases may need a makeover. ImageNet is an unparalleled computer vision reference point with more than 14 million labelled images. It was designed for visual object recognition software research and is organized according to the WordNet hierarchy. Each node of the hierarchy is depicted by hundreds and thousands of images, and there are currently an average of over 500 images per node.  \n\n\nIn a [paper](https://arxiv.org/pdf/1912.11370.pdf) published last year, the Google Brain Z\u00fcrich team proposed Big Transfer (BiT-L), now a SOTA ImageNet model. Looking at what were considered \u201cmistakes\u201d in BiT-L, Google Brain researcher Lucas Beyer suggested most of these could in fact be label noise rather than genuine model mistakes.  \n\n\nTo quantify this idea, Beyer and his Google Brain colleagues joined DeepMind researchers in a recent study to determine \u201cwhether recent progress on the ImageNet classification benchmark continues to represent meaningful generalization, or whether the community has started to overfit to the idiosyncrasies of its labeling procedure.\u201d \n\nHere is a quick read: [Google &amp; DeepMind Researchers Revamp ImageNet](https://syncedreview.com/2020/06/23/google-deepmind-researchers-revamp-imagenet/)\n\nThe paper *Are We Done With ImageNet?* is on [arXiv](https://arxiv.org/pdf/2006.07159.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hel7k7/r_google_deepmind_researchers_revamp_imagenet/"}, {"autor": "vendetta_315", "date": "2020-06-23 10:31:42", "content": "Really need advice on building a career in AI /!/ Lost my job, looking for a new one. What role would best help me make the transition into AI.\n\n&amp;#x200B;\n\nHello guys, I am a 28M who wants to work in the field of AI. Due to Covd19 my IT consultancy business is pretty much gone and looking to take a job to maintain steady income. I have experience in Node.JS, mongoDB, SQL and Vue.JS. Spent last 2 months exploring different spaces and I realized I want to get into this space, whether it be now or in 2-3 years\n\n&amp;#x200B;\n\nAs I am preparing for job applications and interviews I wanted some advice on what of job I should take (and learn on the side) that would best equip me when I want to make the transition. My knowledge of python is quite limited at the moment. I know the field is very expansive (NLP, -----> image !!!  processing, Neural networks) but still looking for a path. I don't think I have enough time to study for 2-3 months and apply for direct role due to financial constraints and will need to make a transition.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hec6up/really_need_advice_on_building_a_career_in_ai/"}, {"autor": "chiyangata", "date": "2020-09-09 13:42:05", "content": "Help me start up my dream A-I Video Editing software company /!/ Helloo to anyone seeing this my plight is simple .Am pleading with you to help me fund a company startup based upon my fantasies which i believe is an innovation that will be welcomed by many people out there\n\nI envision video creation and audio rendering without the need for extensive -----> camera !!!  equipment and flashy upmarket studios as i result i plan to start an Artificial Intelligence software based company\n\nPM me if you are interested in my idea or you wanna help in any way.. Am also looking for any advice and potential co founders for the startup.. I've also started a fundraiser \n\nNavigate to this link for more information too\n\nhttps://goget.fund/3menj8K", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ipg3j2/help_me_start_up_my_dream_ai_video_editing/"}, {"autor": "chiyangata", "date": "2020-09-09 13:20:14", "content": "Help me start up my dream A-I Video Editing software company /!/ hello guys i hope am at the correct platform to showcase this please help with any advice ,expertise or anything to make me a success \n\nTo anyone seeing this my plight is simple .Am pleading with you to help me fund a company startup based upon my fantasies which i believe is an innovation that will be welcomed by many people out there\n\nI envision video creation and audio rendering without the need for extensive -----> camera !!!  equipment and flashy upmarket studios as i result i plan to start an Artificial Intelligence software based company\n\nPM me if you are interested in my idea or you wanna help in any way.. Am also looking for any advice and potential co founders for the startup.. I've also started a fundraiser \n\nNavigate to this link for more information too\n\nhttps://goget.fund/3menj8K", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ipfqqu/help_me_start_up_my_dream_ai_video_editing/"}, {"autor": "Yuqing7", "date": "2020-03-03 23:49:50", "content": "CookGAN Generates Realistic Meal Images From an Ingredients List /!/ Proposed by researchers from the Rutgers University and Samsung AI Center in the UK, CookGAN uses an attention-based ingredients------> image !!!  association model to condition a generative neural network tasked with synthesizing meal -----> image !!! s. The framework enables the model to generate realistic \u2014 and even appetizing \u2014 meal images corresponding to an ingredients list alone. \n\nRead more: [CookGAN Generates Realistic Meal Images From an Ingredients List](https://medium.com/syncedreview/cookgan-generates-realistic-meal-images-from-an-ingredients-list-250426dbfab2)\n\nPaper:  [CookGAN: Meal Image Synthesis from Ingredients](https://arxiv.org/pdf/2002.11493.pdf)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/fd3yio/cookgan_generates_realistic_meal_images_from_an/"}, {"autor": "OnlyProggingForFun", "date": "2020-08-02 11:54:13", "content": "This new technique: -----> image !!! -GPT from OpenAI can generate the pixels of half of a picture from no other information using a NLP model", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i2av3k/this_new_technique_imagegpt_from_openai_can/"}, {"autor": "OnlyProggingForFun", "date": "2020-08-01 13:54:31", "content": "This AI can generate the pixels of half of a -----> picture !!!  from no other information using a NLP model", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i1skg6/this_ai_can_generate_the_pixels_of_half_of_a/"}, {"autor": "MLtinkerer", "date": "2020-07-30 22:01:51", "content": "State of the art in instance segmentation: (Instance segmentation aims to classify each pixel in an -----> image !!!  into an object category)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i0v81x/state_of_the_art_in_instance_segmentation/"}, {"autor": "analyticsinsight", "date": "2020-11-02 07:59:49", "content": "Dragontail Systems\u2019 AI -----> Camera !!!  Can Ensure Food Safety", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jmjk0n/dragontail_systems_ai_camera_can_ensure_food/"}, {"autor": "kjonesatjaagnet", "date": "2020-10-31 22:44:01", "content": "Soccer match ruined when AI-controlled -----> camera !!!  mistakes ref\u2019s bald head for ball", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jlrpte/soccer_match_ruined_when_aicontrolled_camera/"}, {"autor": "LeomaEckert", "date": "2020-10-31 11:42:37", "content": "AI -----> camera !!!  mistakes referee's bald head for ball and tracks it throughout the soccer game", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jlgz9n/ai_camera_mistakes_referees_bald_head_for_ball/"}, {"autor": "Yuqing7", "date": "2020-11-18 19:58:18", "content": "[R] Automatic -----> Image !!! -to-Painting Translation Method Generates Vivid Paintings in Controllable Styles /!/ Researchers from the University of Michigan, NetEase Fuxi AI Lab and Beihang University in China recently introduced \u201cStylized Neural Painter,\u201d a novel automatic image-to-painting translation method that generates vivid and realistic artworks in controllable styles.\n\nHere is a quick read: [Automatic Image-to-Painting Translation Method Generates Vivid Paintings in Controllable Styles](https://syncedreview.com/2020/11/18/automatic-image-to-painting-translation-method-generates-vivid-paintings-in-controllable-styles/)\n\nThe paper *Stylized Neural Painting* is on [arXiv](https://arxiv.org/pdf/2011.08114.pdf), and the code and animated results are available on the project [GitHub](https://jiupinjia.github.io/neuralpainter/).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jwn3bo/r_automatic_imagetopainting_translation_method/"}, {"autor": "dharun24", "date": "2020-11-18 08:21:51", "content": "Video analytics-based inventory management model /!/ Here is a result of [Gyrus AI](https://www.gyrus.ai)'s video analytics-based inventory management model. The model can be implemented on a live feed from the surveillance -----> camera !!! 's and results can be integrated with PoS for real-time updates on the stock. \n\n[learn more:](https://gyrus.ai/blog/smart-retail-location-point-of-sale-analytics-camera/)\n\nhttps://preview.redd.it/buy5sy5bkyz51.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=e46423e0ae0b835a6a7297b4fb8524e76bb2f4f6", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jwc2pt/video_analyticsbased_inventory_management_model/"}, {"autor": "ccrbltscm", "date": "2020-11-18 07:52:44", "content": "[NeurIPS 2020 Paper] Gradient-EM Bayesian Meta-Learning /!/ 3-min presentation for NeurIPS 2020 paper \"[Gradient-EM Bayesian Meta-Learning](https://crossminds.ai/video/5fb31be740417375fe3ed4df/)\" by researchers from Cornell &amp; Columbia.\n\n**Abstract:** Bayesian meta-learning enables robust and fast adaptation to new tasks with uncertainty assessment. The key idea behind Bayesian meta-learning is empirical Bayes inference of hierarchical model. In this work, we extend this framework to include a variety of existing methods, before proposing our variant based on gradient-EM algorithm. Our method improves computational efficiency by avoiding back-propagation computation in the meta-update step, which is exhausting for deep neural networks. Furthermore, it provides flexibility to the inner-update optimization procedure by decoupling it from meta-update. Experiments on sinusoidal regression, few-shot -----> image !!!  classification, and policy-based reinforcement learning show that our method not only achieves better accuracy with less computation cost, but is also more robust to uncertainty.\n\n**Paper**: [https://arxiv.org/abs/2006.11764](https://arxiv.org/abs/2006.11764)\n\n**More pre-recorded NeurIPS 2020 talks are available in** [**this collection**](https://crossminds.ai/category/neurips%202020/)**.**", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jwbqvi/neurips_2020_paper_gradientem_bayesian/"}, {"autor": "ai-lover", "date": "2020-11-17 16:05:05", "content": "HAMLET: A Hierarchical Agent-Based Machine Learning Platform For AI Research And Development /!/ Machine learning (ML) algorithms are widely used as computational tools for solving various real-world problems, including -----> image !!! , audio, and text classification tasks. New algorithms are developed regularly. Keeping a record of the massive volume of new algorithms and instantly accessing those presented in the past is becoming more challenging.\n\nThe researchers at Purdue University and the University of Cincinnati recently built a platform called HAMLET. It can help computer scientists and developers browse through existing machine learning models. This platform supports scientists in research and development by assisting them in evaluating and training their algorithms. It allows research teams to share their models and could eventually democratize ML models developed worldwide.\n\nPaper: [https://arxiv.org/pdf/2010.04894.pdf](https://arxiv.org/pdf/2010.04894.pdf) \n\nSummary: [https://www.marktechpost.com/2020/11/17/hamlet-a-hierarchical-agent-based-machine-learning-platform-for-ai-research-and-development/](https://www.marktechpost.com/2020/11/17/hamlet-a-hierarchical-agent-based-machine-learning-platform-for-ai-research-and-development/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jvvl3d/hamlet_a_hierarchical_agentbased_machine_learning/"}, {"autor": "Yuqing7", "date": "2020-12-23 20:17:57", "content": "[N] 2020 in Review: 10 AI-Powered Art Projects /!/ AI has become increasingly capable of generating impressive artworks across a wide range of styles and forms, from abstract painting to prose writing, -----> film !!!  scores, and even operas.\n\nMany researchers spent much of 2020 at home, where, apparently, many explored AI\u2019s creative potential. As part of our year-end series, *Synced* highlights 10 AI-powered art projects that inspired and entertained us in 2020.\n\nHere is a quick read: [2020 in Review: 10 AI-Powered Art Projects](https://syncedreview.com/2020/12/23/2020-in-review-10-ai-powered-art-projects/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kj0fer/n_2020_in_review_10_aipowered_art_projects/"}, {"autor": "Yuqing7", "date": "2020-12-21 20:52:12", "content": "[R] Heidelberg University Researchers Combine CNNs and Transformers to Synthesize High-Resolution Images /!/ Is there a way to efficiently code inductive -----> image !!!  biases into models while retaining all the flexibility of transformers? \u201cYes,\u201d say researchers from Germany\u2019s Heidelberg University. In a new paper, the team proposes a novel approach that combines the effectiveness of the inductive bias in convolutional neural networks (CNNs) with the expressivity of transformers to model and synthesize high resolution images.\n\nHere is a quick read: [Heidelberg University Researchers Combine CNNs and Transformers to Synthesize High-Resolution Images](https://medium.com/syncedreview/heidelberg-university-researchers-combine-cnns-and-transformers-to-synthesize-high-resolution-f8d98ccab749)\n\nThe paper *Taming Transformers for High-Resolution Image Synthesis* is on [arXiv](https://arxiv.org/pdf/2012.09841.pdf). This project is also on [GitHub](https://compvis.github.io/taming-transformers/).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/khpy2a/r_heidelberg_university_researchers_combine_cnns/"}, {"autor": "OnlyProggingForFun", "date": "2020-09-27 19:07:12", "content": "Imagine having the old, folded, and even torn pictures of your grandmother when she was 18 years old in high definition with zero artifacts. This is called old -----> photo !!!  restoration and this paper just opened a whole new avenue to address this problem using deep learning approaches", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j0wtg0/imagine_having_the_old_folded_and_even_torn/"}, {"autor": "Jefry99", "date": "2020-09-26 11:21:14", "content": "How to find if an -----> image !!!  is present in another one? /!/ So i'm fairly new to Machine Learning, and any suggestion would be really appreciated.\n\nIf i have an image (let's say a drawing) and another one (let's say a wall), how can i find if the drawing is present in the second image?\n\nMy idea was to use a CNN similar to one that categorize objects in a picture, but that wouldn't work as i'm not looking for general patterns such as people or cars but for a specific image, so any previous training would be pretty much useless.\n\nHow would you solve this problem? Thank you in avance.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j04ced/how_to_find_if_an_image_is_present_in_another_one/"}, {"autor": "LordApplesause", "date": "2020-09-25 18:15:55", "content": "Creating a StyleGAN2 -----> image !!!  dataset from scratch /!/ Hello!  \n\n\nIm fairly new to GANs, and I am very interested in using it as a creative outlet for artwork and such. Is there a way for me to download thousands of images from google (ex images tagged with \"classical art\") and turn that into a workable dataset for StyleGAN2?\n\n&amp;#x200B;\n\nThanks!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/izoqq7/creating_a_stylegan2_image_dataset_from_scratch/"}, {"autor": "Yuqing7", "date": "2020-09-22 20:35:37", "content": "[R] Adobe\u2019s DL-Based \u2018HDMatt\u2019 Handles -----> Image !!!  Details Thinner Than Hair /!/ Image matting plays a key role in image and video editing and composition. Although existing deep learning approaches can produce acceptable image matting results, their performance suffers in real-world applications, where the input images are mostly high resolution. To address this, a group of researchers from UIUC, Adobe Research and the University of Oregon have proposed HDMatt, the first deep learning-based image matting approach for high-resolution image inputs.\n\nHere is a quick read: [Adobe\u2019s DL-Based \u2018HDMatt\u2019 Handles Image Details Thinner Than Hair](https://syncedreview.com/2020/09/22/adobes-dl-based-hdmatt-handles-image-details-thinner-than-hair/)\n\nThe paper *High-Resolution Deep Image Matting* is on [Arxiv](https://arxiv.org/pdf/2009.06613.pdf). Notably, second author Ning Xu from Adobe Research was first author on the 2017 paper [*Deep Image Matting*](https://arxiv.org/pdf/1703.03872.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ixvq24/r_adobes_dlbased_hdmatt_handles_image_details/"}, {"autor": "RitaNaga", "date": "2020-12-08 16:57:04", "content": "E commerce AI /!/ Hello\n\nunsure if this is the correct place I should be asking, but hoping you can atleast lead me to correct place.\n\nim looking to see if there are any Shopify apps or I would have to customize to do this.\n\n&amp;#x200B;\n\nlets say I\u2019m selling a toy That kids play with in a sandbox, but I want an -----> image !!!  that they can see. Is there anything that would allow me to use a generic sandbox, then users can add how much sand they want in it, add what toys they want, etc?\n\n&amp;#x200B;\n\nthen they would be able to also chooose my product, to see how it works within the sandbox with the other toys.   \n\n\nthx!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k97wvz/e_commerce_ai/"}, {"autor": "analyticsindiam", "date": "2020-12-07 13:38:05", "content": "This AI Model Generates \u2018Talking Heads\u2019 For Videos Using Single 2D -----> Image !!! ", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k8grcj/this_ai_model_generates_talking_heads_for_videos/"}, {"autor": "UzumakiChetan10", "date": "2020-12-07 08:38:55", "content": "Requesting information about screen/-----> photo !!!  recognition AI. /!/ Hey, I'm an engg undergrad and am working on a project around AI. I am completely new to AI and and wanted to know some things related to a specefic area of its use. Please forgive me if this post reads a bit lame, Im a novice.\nWhat is the present scenario of screen/photo recognition AI. A product that can recognise and sort elements on the screen or specefically a screenshot. More precisely, I want to know about softwares which can recognise and automatically crop the main photo from a screenshot captured on say some social media like ig. Has something like this been done, ofcourse it has to be right? And can you provide some insights as to how it works, and some examples even. \nThanks in advance!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k8cxra/requesting_information_about_screenphoto/"}, {"autor": "curious__homosapien", "date": "2020-12-06 17:30:48", "content": "How AI can learn features that must not be associated with each other /!/ I am studying about AI used for generation of music or images. I want to know how to ensure that the generated -----> image !!!  or composed music is not something that doesnot follow rules.\nLike hard rock metal should not contain jazz in it. Or a generated image of dog should not have tail attached with legs. \n\nI am trying to train AI to generate new recipes that verifies like cookie cannot contain peri peri chilies. Lol. \n\nThanks for any advice.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k7xxuf/how_ai_can_learn_features_that_must_not_be/"}, {"autor": "Ray555555", "date": "2020-06-08 20:38:02", "content": "Can AI recognize a repcific part of a clothing item? /!/ Can AI identify specifically the collars of a shirt or waistband on pants? \n\nAnd would the whole item (whole shirt) need to be in the -----> picture !!!  or just the part of interest (collar visible, rest is out of sight) for the AI to recognize it?\n\n&amp; Are there any premade AI able to recognize different clothe types?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gz7imm/can_ai_recognize_a_repcific_part_of_a_clothing/"}, {"autor": "Hussain_Mujtaba", "date": "2020-06-08 17:35:18", "content": "Recognising images of animals using deep learning /!/ Here is an article that gives a detailed explanation of how  -----> image !!!  recognition works. It uses convolutional neural networks that can recognise images of animals in the Animal-10 data set.to train a network from scratch. Also for the same task it uses a pre-trained Xception model that can recognise HD images of these animals.\nThe code as well as the trained model is available for download.\n[Image recognition model using deep learning](https://www.mygreatlearning.com/blog/image-recognition/?utm_source=myreddit-ML1)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gz3u5a/recognising_images_of_animals_using_deep_learning/"}, {"autor": "UnaiCorzo", "date": "2020-06-08 12:43:48", "content": "Autoencoders for -----> image !!!  enhancement /!/ Can autoencoders be used to enhance and upscale -----> image !!! s instead of just compressing them (as usual)? That is, doing the opposite.\n\nThanks,", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gyymmz/autoencoders_for_image_enhancement/"}, {"autor": "MLtinkerer", "date": "2020-06-06 23:15:12", "content": "Latest from Samsung researchers: State of the art in -----> photo !!!  editing (Harmonization)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gy15c8/latest_from_samsung_researchers_state_of_the_art/"}, {"autor": "OnlyProggingForFun", "date": "2020-06-06 13:45:45", "content": "AI Generates Real Faces From Sketches! DeepFaceDrawing Overview | -----> Image !!! -to-image translation in 2020", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gxr9e7/ai_generates_real_faces_from_sketches/"}, {"autor": "MLtinkerer", "date": "2020-04-04 23:04:35", "content": "ICYMI: The paper describes the initial COVID-19 open -----> image !!!  data collection", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/fv39mp/icymi_the_paper_describes_the_initial_covid19/"}, {"autor": "Pragyanbo", "date": "2020-03-30 15:05:48", "content": "TensorFlow 2.0 with Python Full Tutorial (-----> Image !!!  and Text Classifier)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/frsfjr/tensorflow_20_with_python_full_tutorial_image_and/"}, {"autor": "mdpd010806", "date": "2020-03-19 23:16:30", "content": "WHO HELP ME WITH THIS PLS, URGENT /!/ Write a matlab program that recognizes a geometric figure in an -----> image !!!  (circle, triangle, square) using neural networks", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/flk1db/who_help_me_with_this_pls_urgent/"}, {"autor": "Max_1990", "date": "2020-02-14 17:44:35", "content": "HOW THIS CONVERSATIONAL AI STARTUP IS SOLVING JOB MARKET INEFFICIENCIES IN INDIA - BeBlogging /!/ India is currently the hotbed for emerging technologies like AI &amp; machine learning. But the need of the hour is \u201cDeep Tech\u201d which fundamentally is a connection of different types of technologies, not just AI &amp; ML but also computer vision, -----> image !!!  processing, blockchain, and AR/VR, to come up with a solution that is not trivial but a revolutionary one.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/f3vqbp/how_this_conversational_ai_startup_is_solving_job/"}, {"autor": "Aldis_321", "date": "2020-02-13 03:15:47", "content": "How to not have Big Data be able to read everyone's faces like books. /!/ If you color a tiny piece of paper black with sharpie and put it over your front facing -----> camera !!! , then it is hardly noticeable to others, and agencies cannot collect data on your micro expressions and read your face like a book due to all the past data they've already collected.\n\nJust saying. \n\nALSO start randomly googling stuff in Lorum Ipsum. \n\nWebsites can generate it, it's a false language that somewhat translates to English but not really. If everyone does that, it will really make it harder for people to be predictable.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/f33ffw/how_to_not_have_big_data_be_able_to_read/"}, {"autor": "tbokka", "date": "2020-02-11 14:48:26", "content": "Hey guys! I'm in the final years of my bachelors, for my thesis I would like to make an application, that uses super resolution on chest X-Ray -----> image !!! s, and it diagnoses based on the -----> image !!! . I found more than 10.000 pictures with diagnosis. I just don't know how to start coding this. /!/ Any tips/help would be much appreciated!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/f29b2g/hey_guys_im_in_the_final_years_of_my_bachelors/"}, {"autor": "MLtinkerer", "date": "2020-02-10 21:56:11", "content": "State of the art in -----> image !!!  inpainting!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/f1xosj/state_of_the_art_in_image_inpainting/"}, {"autor": "rahi009", "date": "2020-01-01 19:04:31", "content": "AI Based Blueprint and 3d Model Generation /!/ Hi There. \n\nI am currently doing my BSCS and i am in my final year, so i want to make my Final Year Project. My Final Year Project is based around Artificial Intelligence which is basically that will help people to have a great blueprint and a 3d model of there house in a matter of seconds. \n\nBasically when the user will turn on the app first he will have to create an account and then after successfully signing up he can manually enter dimensions of there plot or can take a -----> picture !!!  of there plot and then draw lines on there mobile phone screens and based on these lines the AI will calculate the dimensions of the plot and will create a blueprint and a 3d model of the plot. \n\nWell i am planning to use Google ML kit for my project. Can anyone help that how can i achieve this milestone.\n\nAny suggestions would be helpful.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/eim5jv/ai_based_blueprint_and_3d_model_generation/"}, {"autor": "Nailer_Owl", "date": "2020-01-21 05:30:08", "content": "Wrote a Blog on Automatic -----> Image !!!  Captioning with CNN &amp; RNN", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/erq4bz/wrote_a_blog_on_automatic_image_captioning_with/"}, {"autor": "milos_the_username", "date": "2020-01-19 12:08:36", "content": "I was able to generate beautiful architecture -----> image !!! s using only AttnGan - text to -----> image !!!  algorithm, a nd super-scale. Images are 512x512px (originaly 256). You can view image galleries on authors (Milo\u0161 Ili\u0107) wordpress blog. It took some courage and patience.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/eqvihu/i_was_able_to_generate_beautiful_architecture/"}, {"autor": "analyticsindiam", "date": "2020-07-07 11:51:56", "content": "Popular -----> Image !!!  Datasets Under Scanner: MIT Takes Down One Of Their Own /!/ [https://analyticsindiamag.com/image-datasets-bias-privacy-mit/](https://analyticsindiamag.com/image-datasets-bias-privacy-mit/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hmt3r9/popular_image_datasets_under_scanner_mit_takes/"}, {"autor": "johnsnowlabsUS", "date": "2020-07-13 16:06:34", "content": "THE NEW HEALTHCARE AI PLATFORM: AIR-GAP SECURITY &amp; COMPLIANCES MEETS ENTERPRISE-GRADE OPERATIONS, ELASTICITY &amp; SCALE /!/ We\u2019re hugely\u00a0thrilled to announce the immediate availability of the new major version of the Healthcare AI Platform. This release raises the bar on the industry\u2019s only \u201ccleanroom\u201d AI platform that is designed for high-compliance industries where PHI or PII data is analyzed:\u00a0\n\n* Runs in a complete air-gap manner: without Internet access\u00a0\n* All computation is done within the platform. No data, models, or code leave the cluster\u00a0\n* Runs on your infrastructure. Nothing gets sent to a third party\u00a0\n* Central identity management, single sign-on, and key management\u00a0\n\nThe trick, of course, is to achieve all that without trading off the key benefits of cloud services:\u00a0\n\n* Elastic: scales from 5 to 5,000 machines without downtime\u00a0\n* Fully managed, out-of-the-box data science notebooks, model serving, data integration, data processing pipelines, visualization, and dashboards\n* Central security, monitoring, logging, and management tools\u00a0\n\n[The Healthcare AI Platform](https://www.johnsnowlabs.com/ai-platform/) is automatically deployed in 2-4 hours on a cluster of your choice \u2013 on any cloud or on-premise cluster, anywhere in the world \u2013 as one fully-managed Kubernetes cluster.\u00a0\n\n&gt;\u201c*Data science teams in high-compliance industries often have to make hard trade-off between having access to state-of-the-art libraries and tools; the convenience of managed services, elasticity and scale offered by cloud providers, while* *adhering to the highest bar of security, privacy, and compliance. Our goal with the Healthcare AI Platform is to deliver on all three areas without compromise*\u201d, said Ali Naqvi, lead platform product manager at John Snow Labs.\u00a0\n\nThe same platform was recognized last year by CIO Applications as its [AI Platform of the Year](https://www.johnsnowlabs.com/john-snow-labs-is-named-2019-ai-platform-of-the-year/) thanks to a combination of cutting-edge AI technology and proven customer success. The platform is deployed and actively used by multiple Fortune 500 healthcare, life science, and health IT companies to build, deploy, and operate real-world data science systems.\u00a0\n\nThis new release includes over 140 new features and enhancements. Roughly half of them are focused on enhanced security &amp; compliance. The other half adds new productivity features for data scientists and data analysts. As always, this release also updates all of the healthcare-specific datasets, medical terminologies, natural language processing pipelines, and pre-trained deep learning models that are included to jumpstart healthcare &amp; pharma AI projects.\u00a0\n\n[Contact us](https://www.johnsnowlabs.com/schedule-a-demo/) for a live demo or trial version of the Healthcare AI Platform.\u00a0\n\n## Healthcare AI Platform Q2 2020 Release: Major Enhancement &amp; New Features\n\n## Identity &amp; Access Management\n\n* Single sign-on for all new components\n* Two-Factor Authentication\n* Password formats &amp; password strength policies\n* Password expiration policies\n* Support for temporary passwords\n* Support for password-less authentication and multiple credentials per user\n* Signed and Encrypted ID Token Support\n* Fine-grained authorization &amp; authentication controls\n\n## For SecOps: Security Hardening\n\n* New -----> image !!!  vulnerability scanners are in use and previous ones have been upgraded\n* Dynamic deep -----> image !!!  inspection and vulnerability scanning of Docker containers has been implemented\n* Tens of thousands of vulnerabilities in underlying open-source packages have been resolved\n* Distro-less -----> image !!! s (initial rollout): These -----> image !!! s contain only your application and its runtime dependencies. They do not contain package managers, shells, or other standard Linux programs, drastically reducing what an attacker can do even on a compromised host.\n\n## For DevOps: Scaling &amp; Kubernetes Operations\n\n* Upgraded to Kubernetes 1.17 with GPU support\n* Support for allocating GPU\u2019s to specific users or services\n* Support for pod priority and preemption\n* Support for pod readiness gates\n* Hardened the discovery of Kubernetes role-based access controls\n* Scalability &amp; fault tolerance for the visualization &amp; dashboarding services\n* Fault tolerance for the identity &amp; access management database\n\n## For Data Scientists: Managed Notebooks\n\n* New built-in HTML viewer\n* Find &amp; replace\n* Find &amp; go-to line in the CSV viewer\n* Enhanced node structure in the JSON tree viewer\n* Drag &amp; drop between console &amp; notebook cells\n* Notebook cell tags\n* Presentation mode for notebooks\n* Added a \u201cRestart Kernel and Run All Cells\u2026\u201d button\n* Added a status bar\n* Better performance, especially for large notebooks\n* New keyboard shortcuts for navigation and better tooltips\n* Pasting cell attachments and dragging attachments from the file browser", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hqi0g5/the_new_healthcare_ai_platform_airgap_security/"}, {"autor": "LordLagahoo", "date": "2020-06-14 22:45:36", "content": "Artificial Intelligence / Machine Learning Online courses /!/ Hello,\n\nI am working on a project whereby I will be using machine learning tools to optimize an automated farming system.\n\nIt will use -----> image !!!  processing (of food produce) and human inputs (like taste etc.) and then optimize the inputs (humidity, lumination etc.) to the automated system.\n\nCan you recommend any courses that you think will be helpful with regards to helping me develop the algorithm?\n\nWhat can you recommend in terms of a programming language? Any open source  resources that are already working on similar projects?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/h93j7o/artificial_intelligence_machine_learning_online/"}, {"autor": "MLtinkerer", "date": "2020-06-13 02:24:35", "content": "Latest from Microsoft researchers: Recovering the 3D geometry of human head from a single portrait -----> image !!! ", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/h7yogv/latest_from_microsoft_researchers_recovering_the/"}, {"autor": "GangLiu", "date": "2020-06-21 12:29:25", "content": "Perfect artificial neuron, maybe perfect most ANNs. It may be time to perfect the neuron of artificial neural network /!/   \n\n[https://www.techrxiv.org/articles/It\\_may\\_be\\_time\\_to\\_perfect\\_the\\_neuron\\_of\\_artificial\\_neural\\_network/12477266](https://www.techrxiv.org/articles/It_may_be_time_to_perfect_the_neuron_of_artificial_neural_network/12477266)\n\nAs we know, artificial neural networks are inspired by biological neural networks. Seventy years ago, people designed artificial neurons by imitating the knowledge about biological neurons at that time. Today, due to the development of biology, we have a relatively good understanding of how the work of neurons, especially dendrites.\n\nI found, at the time of design, the traditional artificial neurons ignored a fact that dendrites participate in pre-calculation in a biological neuron or biological neural network.\n\nMore specifically, biological dendrites play a role in the brain pre-processing to the interaction information of input data. This can be illustrated briefly by two tasks in life. For understanding a -----> picture !!!  task, biological dendrites play a role in extracting the relationship across parts of an input------> picture !!! . For understanding an article or a speech task, biological dendrites play a role in extracting the relationship across parts in an input-word.\n\nTraditional artificial neurons are insufficient in extracting the interaction information of input data. Thus we have designed a lot of convolutional layers. Gang neurons maybe reduce the number of layers in an existing network for the same task.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hd65si/perfect_artificial_neuron_maybe_perfect_most_anns/"}, {"autor": "GangLiu", "date": "2020-06-21 08:50:03", "content": "Perfect artificial neuron, maybe perfect most ANNs /!/   It may be time to perfect the neuron of artificial neural network\n\n   \\#MachineLearning, #DeepLearning #AI #Bigdata #Analytics #DataMining, #DataScience \n\nAs we know, artificial neural networks are inspired by biological neural networks. Seventy years ago, people designed artificial neurons by imitating the knowledge about biological neurons at that time. Today, due to the development of biology, we have a relatively good understanding of how the work of neurons, especially dendrites.\n\nI found, at the time of design, the traditional artificial neurons ignored a fact that dendrites participate in pre-calculation in a biological neuron or biological neural network.\n\nMore specifically, biological dendrites play a role in the brain pre-processing to the interaction information of input data. This can be illustrated briefly by two tasks in life. For understanding a -----> picture !!!  task, biological dendrites play a role in extracting the relationship across parts of an input------> picture !!! . For understanding an article or a speech task, biological dendrites play a role in extracting the relationship across parts in an input-word.\n\nTraditional artificial neurons are insufficient in extracting the interaction information of input data. Thus we have designed a lot of convolutional layers. Gang neurons maybe reduce the number of layers in an existing network for the same task.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hd3mqx/perfect_artificial_neuron_maybe_perfect_most_anns/"}, {"autor": "xkrbl", "date": "2020-06-18 12:47:49", "content": "What set of deep learning networks is well suited for realtime inference in OpenGL and/or DirectX? /!/ I have a bit of experience with training and using networks using tensorflow and pytorch.\n\nWhat I'd like to experiment with is to train networks for which the inference of the trained network can be implemented in pixel shaders, so that it can be applied as 'outputfilter' to a realtime game (for example, in a VR game this must happen like 180 times per second on 2k x 2k -----> image !!!  buffers).\n\nFor that it's not practical to output each frame to some separate inference engine, apply it and then send it back to the OpenGL or DirectX context.\n\nWhich kind of networks are well suited for having the inference step directly implemented as GLSL or HLSL shaders?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hbdybg/what_set_of_deep_learning_networks_is_well_suited/"}, {"autor": "ThisVineGuy", "date": "2020-06-18 11:56:58", "content": "AI Generates Real Faces From Sketches! DeepFaceDrawing Overview | -----> Image !!! -to-image translation in 2020", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hbd7yk/ai_generates_real_faces_from_sketches/"}, {"autor": "Prestigious_Door_230", "date": "2020-10-14 03:57:39", "content": "Seeking advice for my AI project /!/ I want to create something that will learn what my dog sees as a threat outside our window. First, I am going to set up a -----> camera !!!  and a microphone. Hopefull I can train my AI to recognize objects and understand my dogs behavior. Upon seeing a threat and my dog barking, I want the AI to then control a robot to close the blinds and tell him No. If the AI recognizes a threat and Rolo doesn't bark, I want the AI to then reward my dog with treats.  My old advisor pointed out that there may be a lot of false positives if my dog barks easily. For example, maybe he\u2019ll see a friend or a car coming up and bark excitedly. He also recommended that I  make a multi-dimensional input array for my target, and that I should also record the pitch of my dogs bark and regress both that and the image against my targets .\n\nAny advice on where to start? Any resource you recommend I look into? I am a novice when it comes to AI, but I have pretty strong coding skills.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jatfeo/seeking_advice_for_my_ai_project/"}, {"autor": "levit88", "date": "2020-10-14 03:45:41", "content": "Short------> film !!!  on AI Technology", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jat92d/shortfilm_on_ai_technology/"}, {"autor": "Yuqing7", "date": "2020-10-13 17:39:35", "content": "[R] ICLR 2021 Submission: Deeper VAEs Excel on Natural Image Benchmarks /!/ Testing the premise that sufficiently deep VAEs could implement autoregressive models and other more efficient generative models, new research proposes a hierarchical VAE that outperforms PixelCNN in log-likelihood on all natural -----> image !!!  benchmarks.\n\nHere is a quick read: [ICLR 2021 Submission: Deeper VAEs Excel on Natural Image Benchmarks](https://syncedreview.com/2020/10/13/iclr-2021-submission-deeper-vaes-excel-on-natural-image-benchmarks/)\n\nThe paper Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images is on [OpenReview](https://openreview.net/pdf?id=RLRXCV6DbEJ).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jaibiq/r_iclr_2021_submission_deeper_vaes_excel_on/"}, {"autor": "OnlyProggingForFun", "date": "2020-08-22 14:13:45", "content": "Here's a new paper announced in the ECCV2020 where they proposed a new technique for 3D Human Pose and Mesh Estimation from a single RGB -----> image !!! ! (with code available)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/iej5hy/heres_a_new_paper_announced_in_the_eccv2020_where/"}, {"autor": "OnlyProggingForFun", "date": "2020-08-19 14:07:52", "content": "Transfer clothes between photos using AI. From a single -----> image !!! !", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/icoafi/transfer_clothes_between_photos_using_ai_from_a/"}, {"autor": "send_butts_n_memes", "date": "2020-08-19 00:12:38", "content": "What 4x A.I upscalling looks like on a 100x100 -----> image !!! ", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/icd1n5/what_4x_ai_upscalling_looks_like_on_a_100x100/"}, {"autor": "Mega__Ultra", "date": "2020-10-22 04:29:37", "content": "Need Advice Retraining an -----> Image !!!  Classifier /!/ Hello r/ArtificialInteligence! I am a 4th year computer science student looking to gain and advice or help on this project my group and I are working on for my AI class. Our project is training an AI to recognize UNO! cards. We have a dataset of 1680 images, with 30 images per classifier (1344 images for training, 336 for testing), giving us 56 classifiers (including classifiers for back of card/blank etc). We have been going down the rabbithole of using this particular Image Re-Classifier: \n\n[https://www.tensorflow.org/hub/tutorials/tf2\\_image\\_retraining](https://www.tensorflow.org/hub/tutorials/tf2_image_retraining)  \n\n\nWe have 30 images per card, I have a feeling that is far too few cards but we took all of those images by hand, and it took quite some time. The reason I feel this way is because our program is more often than not predicting incorrect labels for images that were not in the initial dataset. How many images should we have per classifier? If it's significantly more, It is not feasible to take thousands of pictures by hand.   \n\n\n[https://tfhub.dev/google/imagenet/inception\\_v3/feature\\_vector/4](https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4)\n\nI believe we are using an \"Inception v3\" Pre trained model (Posted above), and online i found this blurb about using pre trained models\n\n\"Because you\u2019re using a network that has already seen a lot of images and learned to distinguish between the classes, you can usually teach it new classes in the same domain with as few as ten or twenty examples.\" From: [https://petewarden.com/2017/12/14/how-many-images-do-you-need-to-train-a-neural-network/](https://petewarden.com/2017/12/14/how-many-images-do-you-need-to-train-a-neural-network/)\n\n&amp;#x200B;\n\nWhat could be going wrong here? Any advice will be appreciated, and thank you for taking the time to read my post :).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jfsxfd/need_advice_retraining_an_image_classifier/"}, {"autor": "MLtinkerer", "date": "2020-10-22 03:20:25", "content": "-----> Image !!! -Driven Furniture Style for Interactive 3D Scene Modeling", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jfrxwc/imagedriven_furniture_style_for_interactive_3d/"}, {"autor": "NicholasSou", "date": "2020-05-19 08:45:13", "content": "Need some help to increase size of dataset /!/ Hey guys!\n\nFor my final year university project, I am part of a group which is trying to use neural networks (a type of artificial intelligence) to sort recycling into paper, plastic, metal and glass. In order to do so, I need thousands of pictures of recyclable waste. \n\nI would be really grateful if you can help me out by taking pictures of your recyclable rubbish like the ones attached. \n\nThe pictures should be in the following format:\n- Single piece of rubbish per -----> photo !!! \n- Photo should be taken on a blank background\n- Only plastic, paper, glass and metal recyclables \n- No organic waste, landfill waste, e-waste\n- Take multiple -----> photo !!! s of each piece of rubbish at different angles \n\nIf you would like to help, please upload the pictures to the Google Drive linked below. If you don't have Google Drive and you'd like to contribute please pm me. \n\nhttps://drive.google.com/drive/folders/1Fakmup2gB5MtkAV8M9hTE7zyOH0AAuVP?usp=sharing\n\n*Update*\nTo upload images using a computer:\nSimply click on the link, login, navigate to the correct material folder and drag the images across. \n\nTo upload images with your mobile:\n1. Click on the link\n2. Login to Google Drive (don't click \"open in app\" until you have logged in)\n3. Open the Google Drive app\n4. Go to shared \n5. Go  to  \"Dataset for AI Recycling\" folder\n6. Select folder with the type of recycling that you would like to upload\n7. Press the + sign and upload away\n\nSorry this is complicated. If you're having trouble please send me a message!\n\nThank you so much for your help!\n\nThere are some sample photos on this FB post:\nhttps://www.facebook.com/100000632037174/posts/3241897742507928/?d=n", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gmkste/need_some_help_to_increase_size_of_dataset/"}, {"autor": "Commercial_Ruin6669", "date": "2020-11-15 16:31:13", "content": "Artistic project suggestion: as you can see from the -----> image !!! , I'm generating with a StyleGAN some trophies, which I'm sculpting in ZBrush and then 3D printing. I have a question: Is there any (useful for this purpose) tool to generate 3D models from images? /!/ &amp;#x200B;\n\nhttps://preview.redd.it/w7red8qgkfz51.png?width=2481&amp;format=png&amp;auto=webp&amp;s=76078117956cd452c9298357357e98a20f010ecd", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/juolh2/artistic_project_suggestion_as_you_can_see_from/"}, {"autor": "tftteam", "date": "2020-12-17 05:32:42", "content": "Cartoon Character AI Test /!/ Hi guys I have published cartoon character face test recently, I hope you guys like it! \n\nBasically if you upload your face -----> image !!! , AI trained by google teachable machine will tell you which character you look like most. The data of photo is not saved anywhere nor sent to anywhere, so you wouldn't have to worry about it. \n\nI originally published this page in Korean, and I recently finished translating it into English. I noticed I have to add more characters , since some of them are targeted for Koreans to play around. \n\nI am going to make a lot of updates on this website. Before that I wanted to hear some reactions from you guys! I really hope you guys enjoy it, and it would be really thankful, if you guys share and leave feedback!\n\nThank you so much\\~!     \n\n[https://www.charactertest.site/en](https://www.charactertest.site/en)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/dcood2cnoo561.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=e06a8b876822609f83dd7f8ec328ea6049254176\n\nhttps://preview.redd.it/286pejkloo561.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=fb377441af430b6c8e0eed84fc66e57d9f177184\n\nhttps://preview.redd.it/e1b2w3zjoo561.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=dd0f75b9d38c7880cf4a9cff8e7db14385a894a5", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/keranb/cartoon_character_ai_test/"}, {"autor": "KMuchoki", "date": "2020-12-16 20:16:14", "content": "Image Retrieval by Similarity using Tensorflow and Keras /!/ Ever thought of creating your own face verification system? This project will teach you how to find similar images using similarity. These are the basics of face verification system. In the process you will also learn tensorflow and keras basics (build a linear regression model using tensorflow). \n\n This tutorial will cover all the details (resources, tools, languages etc.) that are necessary for -----> image !!!  retrieval. You will be guided through all the steps and concepts, starting from the basic ones like setting up the right tools and frameworks to the more advanced topics related to the development.   \n[https://www.education-ecosystem.com/nitinsethi/ROyn7-image-retrieval-by-similarity-using-tensorflow-and-keras/MzME1-intro-image-retrieval-by-similarity-using-tensorfl/](https://www.education-ecosystem.com/nitinsethi/ROyn7-image-retrieval-by-similarity-using-tensorflow-and-keras/MzME1-intro-image-retrieval-by-similarity-using-tensorfl/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kegyik/image_retrieval_by_similarity_using_tensorflow/"}, {"autor": "Yuqing7", "date": "2020-12-11 19:59:20", "content": "[P] Depix AI Recovers Pixelized Passwords, Earns 10K GitHub Stars /!/ information by dramatically reducing the resolution of sensitive areas in an -----> image !!! . For years, the technique has had broad applications in security and censorship \u2014 but its days may be numbered. \u201c[Depix](https://github.com/beurtschipper/Depix)\u201d is a new AI-powered tool that can easily undo pixelization to enable recovery of the information therein. Uploaded this week, the project has already received nearly 10,000 stars on GitHub. The [Depix project](https://github.com/beurtschipper/Depix) is on GitHub.\n\nHere is a quick read: [Depix AI Recovers Pixelized Passwords, Earns 10K GitHub Stars](https://syncedreview.com/2020/12/11/depix-ai-recovers-pixelized-passwords-earns-10k-github-stars/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kba1y8/p_depix_ai_recovers_pixelized_passwords_earns_10k/"}, {"autor": "legendarypegasus", "date": "2020-09-05 01:06:47", "content": "Depth of an object using a -----> camera !!!  /!/ Hello everyone, I have a tensorflow lite model that detects vehicles but now I want it to detect the approximate distance of the object that it detects me using the same camera. Can you give me any idea how to do this? it doesn't matter if I have to use two cameras. Thank you", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ims7nt/depth_of_an_object_using_a_camera/"}, {"autor": "emilycara", "date": "2020-02-26 09:32:41", "content": "6 Other Uses Which You Didn\u2019t Know Humans Routinely Engineer AI For /!/   \n\nThose who Engineer AI are tasked with not only creating, but also finding new, innovative ways of assimilating Artificial Intelligence into everyday life \u2013 safe to say, they\u2019ve been quite successful in that regard. Artificial Intelligence has encapsulated us \u2013 our waking life is awash in algorithms, yet we remain mostly oblivious to its presence. Shockingly, half of all humans are flat-out incapable of recognizing the presence of an AI, even when it was staring them in the face. \n\nNevertheless, we live in a world that would crumble without Artificial Intelligence. Yet, invoking Artificial Intelligence in a conversation,would most likely boil down tothe unseemly threat of an oncoming android-apocalypse, like in War of The Worlds, or Terminator. Rarely does a discussion over AI ever result in a civil conversation about the potential of self-driving cars, or something mundane like the detection of unusual debit card usage. \n\nListed below are 6 applications and the stealthy ways professionals Engineer AI, without anybody being the wiser. \n\n**Websites** \n\nIn 2016, Google appointed John Giannandrea, a computer scientist with a rich understanding of machine learning and Artificial Intelligence, and helmed him with what would become a new era for Google and its search engine. They realized the power that AI possessed in recognizing patterns and sorting out queries on a large scale, which greatly outranked humans by a long mile. Deep Learning has become a norm for most major websites and applications nowadays. Professionals realized they could engineer AI in any manner they seemed fit. Spotify and Youtube for example, recommends music and videos, through analyzing the patterns of previous listeners/viewers, and thus aggregating results as per their \u2018combined habits\u2019.\n\n**Traffic Lights**\n\nNext-gen road safety lights are far from their 20th century brain-dead counterparts, which merely turned on and off at regular intervals. These stops can detect the volume of cars on the road, gauge pedestrian movement and even record and identify patterns to reduce traffic congestion. Since 2012, Pitts burg has implemented these \u201csmart\u201d traffic lights on no less than 50 intersections. It has managed to reduce traffic by 40%. Additionally, average travelling times dropped by 25%, and emissions by 20%. AI Engineers predict that by 2030, all traffic lights will eventually turn \u201csmart\u201d worldwide.\n\n**Films &amp; Television**\n\nA lot of technical skill goes into making movies. Big-budget blockbusters, like The Avengers or Avatar, end up making a lot of money, mainly because they end up spending lot of money \u2013 primarily on flashy VFX and promotion. Even television shows like Game of Thrones and Stranger Things joined the VFX race to upscale their production. The audience is largely in on the \u2018movie magic\u2019 though, albeit not completely. While obvious elements, like monsters and backgrounds are easy tells, viewers fail to realize just how ubiquitous CGI has actually become. Modern CGI heavily relies on Artificial Intelligence to seamlessly wedge the gaps between scenes. Experts can therefore engineer AI to perform even the most mundane tasks \u2013 like removing facial hair, as was the case of Henry Cavill in the Justice League live-action movie. Although it seems ridiculous, this is generally seen as a net positive; since it lets technicians focus on more creative aspects, rather than being bogged down by strenuous and dull responsibilities. \n\n**-----> Photography !!!  Apps**\n\nPhoto filters have crept into mainstream society in the form of fun, and goofy applications. Majority of these merely add a frame, or props to the image. With the release of Face App in the summer of 2019 however, people were left amazed (and terrified) over the power of its AI. The App transformed a picture or selfie with the help of tools and algorithms; and to the amazement of many \u2013 showed folks-an accurate image of themselves looking much older. Beautification Apps like Face Tune, have become influencer staples on Instagram, so to speak. Photo Apps have thus been using Artificial Intelligence to detect and transform images for quite a while now. \n\n**E-Mail**\n\nSpam mails used to be a huge menace back in the day. Mails nowadays relegate Spam mails to a different folder entirely \u2013 and you have AI to thank for it! Email platforms like Gmail have algorithms set in place, which protect the user from suspicious and fraudulent mails. This is done by analyzing examples of malware, and making informed decisions based on pattern recognition. But this is far from the only implementation of AI in Emailing \u2013 nowadays your email service provider lets you auto-respond to mails, as well as assist you in auto-filing subject matter, based on your usage patterns(and a sense of general optimization). Artificial Intelligence is allowing users to write Emails \u2013 with as few key strokes as possible!\n\n**Manipulating Your Purchases**\n\nLiving in an AI world involves living in a bubble\u2013 where all your needs are being tailored-made, to be presented on a silver platter. This can result in something basic \u2013 like Netflix, suggesting you a movie \u2018\u2019that you\u2019d like\u2019\u2019. While in some cases, it can even get really uncanny. Take the case of Ms. Ray, a 20-something student \u2013 while on the phone with a friend, she spoke about a product in passing. According to Ms. Ray, only moments later, Facebook and Google started running ads on her phone about it. This is in no way an isolated case. As we mark our footprints on the internet, in the form of emails, website clickthrough\u2019s, and various other preferences \u2013 Artificial Intelligence algorithms quickly keep a track on your behavior. This even lets e-commerce websites like Amazon, preemptively suggest you products that you\u2019re likely purchase. \n\nAI Professionals are working towards a future, where Artificial Intelligence remains one-step ahead of humans at every turn. The fact of the matter is that its a daunting job to Engineer AI. Besides the needless paranoid stories of horror that come through us once a while, Artificial Intelligence is more often than not, used to aid humans. It\u2019s going to be a long time before we see a Terminator-style android apocalypse anytime soon (or maybe never for that matter). Nevertheless, it would be a criminal neglect to ignore the good work being done by folks who engineer AI \u2013 from the most basic, most mundane uses, to the really noteworthy, complex stuff.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/f9qry8/6_other_uses_which_you_didnt_know_humans/"}, {"autor": "Punith123", "date": "2020-10-26 17:07:18", "content": "WALL-E /!/ The -----> film !!!  explores WALL-E\u2019s love for a second robot named EVA. It is yet another examination of a scenario where artificial intelligence \u201cevolves\u201d into human-like form \u2013 complete with fears, anger, and of course love.\n\nWALL-E is the epitome of Artificial Narrow Intelligence that we see today, though not as sophisticated as the ones in the movie (WALL-E being capable of emotions such as loneliness and love). Narrow AI is an intelligent system that is very good at doing a specific thing. We see that in our everyday life today, such as self-driving cars and voice assistants. \n\nIn this movie, WALL-E cleans garbage, EVE looks for life and Auto pilots the ship. WALL-E is one of the rare sci-fi films out there that shows the bright side of AI and the good it can bring to the world", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jiih6r/walle/"}, {"autor": "zuike2013", "date": "2020-10-26 15:42:16", "content": "[CFP] IEEE TPAMI Special Issue on Learning with Fewer Labels in Computer Vision /!/  Call for Papers: **IEEE TPAMI Special Issue on Learning with Fewer Labels in Computer Vision**\n\n[https://lwflcv.github.io/](https://lwflcv.github.io/)\n\nThe past several years has witnessed an explosion of interest in and a dizzyingly fast development of machine learning, a subfield of artificial intelligence. Foremost among these approaches are Deep Neural Networks (DNNs) that can learn powerful feature representations with multiple levels of abstraction directly from data when large amounts of labeled data are available. One of the core computer vision areas, namely, object classification achieved a significant breakthrough result with a deep convolutional neural network and the large-scale ImageNet dataset, which is arguably what reignited the field of artificial neural networks and triggered the recent revolution in Artificial Intelligence (AI). Nowadays, artificial intelligence has spread over almost all fields of science and technology. Yet, computer vision remains in the heart of these advances when it comes to visual data analysis, offering the biggest big data and enabling advanced AI solutions to be developed.\n\nUndoubtedly, DNNs have shown remarkable success in many computer vision tasks, such as recognizing/localizing/segmenting faces, persons, objects, scenes, actions and gestures, and recognizing human expressions, emotions, as well as object relations and interactions in images or videos. Despite a wide range of impressive results, current DNN based methods typically depend on massive amounts of accurately annotated training data to achieve high performance and are brittle in that their performance can degrade severely with small changes in their operating environment. Generally, collecting large scale training datasets is time-consuming, costly, and in many applications even infeasible, as for certain fields only very limited or no examples at all can be gathered (such as visual inspection or medical domain), although for some computer vision tasks large amounts of unlabeled data may be relatively easy to collect, e.g., from the web or via synthesis. Nevertheless, labeling and vetting massive amounts of real-world training data is certainly difficult, expensive, or time-consuming, as it requires the painstaking efforts of experienced human annotators or experts, and in many cases prohibitively costly or impossible due to some reason, such as privacy, safety or ethic issues (e.g., endangered species, drug discovery, medical diagnostics and industrial inspection).\n\nDNNs lack the ability of learning from limited exemplars and fast generalizing to new tasks. However, real-word computer vision applications often require models that are able to (a) learn with few annotated samples, and (b) continually adapt to new data without forgetting prior knowledge. By contrast, humans can learn from just one or a handful of examples (i.e., few shot learning), can do very long-term learning, and can form abstract models of a situation and manipulate these models to achieve extreme generalization. As a result, one of the next big challenges in computer vision is to develop learning approaches that are capable of addressing the important shortcomings of existing methods in this regard. Therefore, in order to address the current inefficiency of machine learning, there is pressing need to research methods, (1) to drastically reduce requirements for labeled training data, (2) to significantly reduce the amount of data necessary to adapt models to new environments, and (3) to even use as little labeled training data as people need.\n\n**Scope of the Special Issue:**\n\nThis special issue focuses on learning with fewer labels for computer vision tasks such as -----> image !!!  classification, object detection, semantic segmentation, instance segmentation, and many others and the topics of interest include (but are not limited to) the following areas:\n\n*-- Self-supervised learning methods*\n\n*-- New methods for few-/zero-shot learning*\n\n*-- Meta-learning methods*\n\n*-- Life-long/continual/incremental learning methods*\n\n*-- Novel domain adaptation methods*\n\n*-- Semi-supervised learning methods*\n\n*-- Weakly-supervised learning methods*\n\nPriority will be given to papers with high novelty and originality for research papers, and to papers with high potential impact for survey/overview papers.\n\n**Paper submission and review:**\n\nAuthors need to submit full papers online through the TPAMI site at [https://mc.manuscriptcentral.com/tpami-cs](https://mc.manuscriptcentral.com/tpami-cs)\n\nselecting the choice that indicates this special issue. Peer reviewing will follow the standard IEEE review process. Full length manuscripts are expected to follow the TPAMI guidelines in [https://www.computer.org/tpami-author-information](https://www.computer.org/tpami-author-information)\n\n**Submission Deadline:**\n\nPaper Submission Deadline: **April 15, 2021**.\n\n**Guest editors:**\n\n\\-- Li Liu: li.liu@oulu.fi\n\nNational University of Defense Technology, China\n\nCenter for Machine Vision and Signal Analysis (CMVS), University of Oulu, Finland\n\n\\-- Timothy Hospedales: t.hospedales@ed.ac.uk\n\nProfessor, University of Edinburgh, UK\n\nPrincipal Scientist at Samsung AI Research Centre Alan Turing Institute Fellow\n\n\\-- Yann LeCun: yann@fb.com\n\nSilver Professor, New York University, United States VP and Chief AI Scientist at Facebook\n\n\\-- Mingsheng Long: mingsheng@tsinghua.edu.cn\n\nAssociate Professor, Tsinghua University, China\n\n\\-- Jiebo Luo: jluo@cs.rochester.edu\n\nProfessor, University of Rochester, United States\n\n\\-- Wanli Ouyang: wanli.ouyang@sydney.edu.au\n\nSenior Lecturer, University of Sydney, Australia\n\n\\-- Matti Pietik\u00e4inen: matti.pietikainen@oulu.fi\n\nProfessor (IEEE Fellow), Center for Machine Vision and Signal Analysis University of Oulu (CMVS), Finland\n\n\\-- Tinne Tuytelaars: Tinne.Tuytelaars@esat.kuleuven.be\n\nProfessor, KU Leuven, Belgium\n\n**Main Contact:**\n\nLi Liu\n\nEmail: li.liu@oulu.fi, dreamliu2010@gmail.com\n\nNational University of Defense Technology, China\n\nCenter for Machine Vision and Signal Analysis (CMVS), University of Oulu, Finland", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jigud9/cfp_ieee_tpami_special_issue_on_learning_with/"}, {"autor": "AB_KI", "date": "2020-11-28 18:50:52", "content": "AI based fantasy profile pictures /!/  Hi all,\n\nsome weeks ago I posted about the **AI based profile -----> picture !!!  generator** for fantasy faces based on NVIDIA styleGAN2 here:\n\n[https://www.reddit.com/r/rpg/comments/jqfice/generator\\_for\\_fantasy\\_profile\\_-----> picture !!! s/](https://www.reddit.com/r/rpg/comments/jqfice/generator_for_fantasy_profile_-----> picture !!! s/)\n\n**New Website Link:**\n\n[https://www.fantasy-faces.com/](https://www.fantasy-faces.com/)\n\n**What you can do:**\n\n* **use the created images without copyright (link to the website would be nice, but not required)**\n* **download the model and create infinite images by yourself (manual provided on the website)**\n* **allow us to use your drawn images to support our product and provide us a link :-)**\n\n&amp;#x200B;\n\nAfter launching the first prototype we got a lot of feedback. So my buddy Chris and I decided to keep on going and work it over.\n\nWe were facing **following problems:**\n\n* We don\u00b4t want to develop our tool without **asking artists for permission**. This tool only can be provided, because others practised drawing years until perfection.  \n**--&gt;** After a ton of mails and messages we were able to collect enough human-like drawings to generate a model. (We are still collecting images and hope that some artists read this and want to contribute). We don\u00b4t think, that our solution will replace artists. Go find some inspiration and ask one of the artists listed for full scenery commissions with emotion and action. :-)\n* We had a **extreme colorblind model**. All our faces were Caucasian, mid twenty and had a marvelous face.  \n**--&gt;** This was the result of an extreme biased training set. In games, comics or films there are many stereotypes and it is hard to get a good mixture for representing the world. So we tried to set the focus on drawings with scars, different colors (blue, black, white, green, ...), different facial forms and so on. That lead to a better result than we had initially... but we need a lot more artworks or photographs to get better results. We don\u00b4t want to lose the drawing style, therefore we can\u00b4t mix to many real people in the training set.\n* We had **no different races like orks, trolls, goblins**  \n**--&gt;** Well, that isn\u00b4t fixed right now. We would need approx. 2.000 images per race to train a model creating goblins or orks. It\u00b4s kind of heavy to get that many free to use images for training, so this will take a lot of time. We will focus on this, when we see, that this app is used a lot.\n* We had an absolute **prototype environment**  \n**--&gt;** Now, we have a real domain, space for more images and created some content for you to read. We plan to create some how to\u00b4s for you and launch them.\n* We have **limited time**  \n**--&gt;** Well, a full time job, a family, a little bit of free time and the will to bring this site to high quality are quite heavy to bring together. We invested a lot of time in this hobby and we will continue, but don\u00b4t expect tons of news, features in no time.\n\nI would extremely happy if you can give us feedback to improve our site.\n\nHope you all enjoy!\n\nAndreas", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k2t7lr/ai_based_fantasy_profile_pictures/"}, {"autor": "Yuqing7", "date": "2020-11-27 02:43:43", "content": "[R] Do We Really Need Green Screens for High-Quality Real-Time Human Matting? /!/ In the new paper *Is a Green Screen Really Necessary for Real-Time Human Matting*, researchers from the City University of Hong Kong Department of Computer Science and SenseTime propose a lightweight **m**atting **o**bjective **d**ecomposition network (**MODNe**t) that can smoothly process real-time human matting from a single input -----> image !!!  with diverse and dynamic backgrounds.\n\nHere is a quick read: [Do We Really Need Green Screens for High-Quality Real-Time Human Matting?](https://syncedreview.com/2020/11/26/do-we-really-need-green-screens-for-high-quality-real-time-human-matting/)\n\nThe paper *Is a Green Screen Really Necessary for Real-Time Human Matting?* is on [arXiv](https://arxiv.org/pdf/2011.11961.pdf). The code, pretrained model and validation benchmark will be made accessible on the project [GitHub](https://github.com/ZHKKKe/MODNet).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k1su2j/r_do_we_really_need_green_screens_for_highquality/"}, {"autor": "OnlyProggingForFun", "date": "2020-11-25 12:55:14", "content": "This AI Can Generate the Other Half of a -----> Picture !!!  Using a GPT Model", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k0rog6/this_ai_can_generate_the_other_half_of_a_picture/"}, {"autor": "Yuqing7", "date": "2020-07-29 21:27:22", "content": "[N] MLPerf Training v0.7 Results Released: Google &amp; NVIDIA Lead the Race /!/ The industry-standard MLPerf benchmark today released the [results](https://mlperf.org/training-results-0-7) of the third round of its ongoing ML Training Systems competition. The competition measures the time it takes to train one of eight ML models to a qualified target on the following tasks: -----> image !!!  classification, recommendation, translation, and playing Go. Forerunners [Google](https://cloud.google.com/blog/products/ai-machine-learning/google-breaks-ai-performance-records-in-mlperf-with-worlds-fastest-training-supercomputer) and [NVIDIA](https://blogs.nvidia.com/blog/2020/07/29/mlperf-training-benchmark-records/) set new AI performance records in this third round (v0.7).\n\nHere is a quick read:  [MLPerf Training v0.7 Results Released: Google &amp; NVIDIA Lead the Race](https://syncedreview.com/2020/07/29/mlperf-training-v0-7-results-released-google-nvidia-lead-the-race/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i094ry/n_mlperf_training_v07_results_released_google/"}, {"autor": "FlamingGem", "date": "2020-07-29 15:37:36", "content": "I made an bot that uses Wavenet, Wikipedia, and Spacy to create to automatically create educational videos. /!/ To cut to the chase: https://www.youtube.com/channel/UCsLCKPmJXsDh90Eum8eMZXw\n\nThis is a project I have been working on over the past days. This is the first step in changing the future of readily accessible education in a natural, coherent, formatted manner. This project is just a sliver of the changes my team and I plan to make to the efficiency of education.\n\nEssentially, what I've done is fully automate the process of creating educational videos based on the source. I've started out solely with wikipedia for this. All i have to do is paste any wikipedia article I want on a google docs, and my python script will take this article, narrate it using Google Cloud's Wavenet Text to Speech API for a more natural sounding voice, choose images using Amazon Comprehend Keyword Extraction API, as well as create a subtitle file, timestamped descriptions, and thumbnails. Once the script has created these, it will automatically upload both a full video on the topic and a summary video of the same topic on Youtube.\n\nOf course, there are a few off-topic and some downright irrelevant images, but this is only the first step in the process. I also understand wikipedia may not be the most reliable source. However, I plan to expand sourcing past wikipedia eventually and create a better -----> image !!!  selection algorithm. \n\nI'd very much appreciate any subs or shares. Thank you!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i02rt9/i_made_an_bot_that_uses_wavenet_wikipedia_and/"}, {"autor": "ThisVineGuy", "date": "2020-07-29 11:47:51", "content": "DeepFaceDrawing Generates Real Faces From Sketches. -----> Image !!! -to-image translation in 2020+, is it biased, could it be used in a real world application? Paper explained", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hzzauu/deepfacedrawing_generates_real_faces_from/"}, {"autor": "MLtinkerer", "date": "2020-07-29 04:26:45", "content": "Latest from Carnegie Mellon and Facebook Researchers: 3D Human Shape and Pose from a Single Low-Resolution -----> Image !!!  with Self-Supervised Learning", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hzu4a9/latest_from_carnegie_mellon_and_facebook/"}, {"autor": "Yuqing7", "date": "2020-07-28 21:08:12", "content": "[R] New White-Box Framework Will Cartoonize Your World /!/ AI-powered cartoonization has many practical applications these days \u2014 from personalized anime-style avatars to video and even fine art. Many black-box cartoonization frameworks however provide users with limited control or adjustability when rendering real-world -----> photography !!!  into cartoon scenes. Now, researchers from ByteDance, The University of Tokyo and Style2Paints Research have introduced a framework that can generate high-quality cartoonized images with much-improved controllability in order to meet artists\u2019 requirements across a wider range of styles and use cases.\n\nHere is a quick read:  [New White-Box Framework Will Cartoonize Your World](https://syncedreview.com/2020/07/28/new-white-box-framework-will-cartoonize-your-world/)\n\nThe paper *Learning to Cartoonize Using White-box Cartoon Representations* is on [GitHub](https://systemerrorwang.github.io/White-box-Cartoonization/paper/06791.pdf). Click [here ](https://systemerrorwang.github.io/White-box-Cartoonization/)to visit the project page.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hzn3zt/r_new_whitebox_framework_will_cartoonize_your/"}, {"autor": "elevatorbeat", "date": "2020-07-28 16:02:13", "content": "Everything You Need to Understand Artificial Intelligence /!/ **Need a primer on AI? We\u2019ve got you\u00a0covered!**\n\nIn working with many enterprise customers over the years, we\u2019ve discovered that there are lots of misconceptions and misunderstandings about Artificial Intelligence. All of the resources we tried to point them to were never clear or thorough enough\u200a\u2014\u200aso we decided to make our own.\n\nIn this guide, we\u2019ll not only walk you through the essentials of Artificial Intelligence but help you locate it within your broader IT strategy. Learn what an AI model is, how it\u2019s built, and finally, how data scientists can put the model to work at your organization.\n\n&amp;#x200B;\n\n&gt;Artificial intelligence is a software capability that allows computers to detect patterns and abstract rules based on a series of extremely complex\u00a0inputs.\n\n&amp;#x200B;\n\nThese inputs can include any dataset, including:\n\n* pixels in an -----> image !!! ,\n* sound waves in an audio file,\n* letters on a page,\n* the mathematical relationships between all the words in the English language,\n* financial transactions of the Fortune 500,\n* the location of every star in the galaxy,\n* etc.\n\nThe **dataset** itself doesn\u2019t matter much. As long as an AI model can take a look at the **input** and **match** it to its **output**, the system itself can start to map\u200a\u2014\u200aand ultimately predict\u200a\u2014\u200athe rules that connect inputs and outputs.\n\nFor example, a financial institution may have a dataset of historical stock market prices and lots of information about each company. By matching **company information** as the input with **stock price** as the output, an AI could learn to identify company information that is highly correlated with a rising stock price.\n\nWhat\u2019s great about AI is that it is uniquely able to consider thousands of inputs and correlations far too subtle for humans to even notice. For example, almost no stockbroker integrates CEO commute time into their investment strategy. However, artificial intelligence has found it to be a relevant predictor of CEO performance.\n\nIn any case, over time, these predictions become more accurate. Eventually, the model becomes reliable and useful enough that it can be deployed and put to work.\n\nLet\u2019s look at another example.\n\nAt a factory, quality assurance officers must pull broken eggs from a conveyor belt. To accomplish this task, the inspectors will look for obvious indicators such as a cracked shell or a shimmer of yolk on the conveyor belt. In other words, these folks are using visual information (inputs) to categorize eggs (outputs).\n\nThis effort is a perfect task for an AI model. In fact, if we were to assign an AI model the same task, it would tackle the problem much in the same way as its human counterparts: it would look at an egg and check to see if there were any visual indications that it was cracked.\n\nTo accomplish this task, however, an AI would need to be **trained**. In this case, the model would need to chew on hundreds, maybe thousands, of photos of cracked and uncracked eggs to start to figure out the pattern.\n\nEventually, the model would create mathematical rules to define what a cracked egg looks like. With more training, the **accuracy** of the model would improve, and eventually, it would be reliable enough to put into **production**.\n\n### A Note About Accuracy and\u00a0AI\n\nArtificial intelligence is not yet capable of achieving 100% accuracy. So, depending on the use case, data scientists must make judgments about whether an AI model meets a certain threshold to put it into production.\n\nMost AI models can get to about 75% accuracy without too much trouble. Beyond that, there\u2019s a logarithmic increase in (a) the number of inputs the model needs to train on and (b) the amount of processing power it takes to create the model. The former is time-consuming, the latter is expensive, and in most cases, 100% accuracy isn\u2019t necessary. Depending on the task at hand, the accuracy threshold will vary.\n\nThis lack of 100% accuracy is one of the reasons self-driving cars still have a long way to go. In data science, a 90% accuracy rate is quite good but imagine if an autonomous vehicle only noticed 90% of the pedestrians who crossed the street.\n\nMoreover, *how* things are inaccurate can also be a factor. For example, in a lung cancer model, false positives aren\u2019t nearly as bad as false negatives. Therefore, the best disease diagnostic models will be optimized to detect every single possible instance of cancer (avoiding false negatives)\u200a\u2014\u200aeven if it means a few healthy lungs get incorrectly flagged along the way (allowing for false positives).\n\nExperts who build AI solutions must decide on acceptable accuracy thresholds before putting a model into production.\n\n### What does it mean to put a model into production?\n\nWell, as we\u2019ve discussed, AI models are really good at matching inputs to outputs. However, for that capability to be useful to anyone, the model must be piped into some kind of app or hardware to be put to work.\n\nIn the egg example, the food processing plant would have to do more than train the broken-or-not-broken model to get any use out of it. It would need to set up a camera to film the eggs coming down the belt, pipe that footage into the model for processing, and then alert the line workers of a broken egg via some kind of interface.\n\nMost AI service providers consider training a model and putting it into production as two separate steps. Because the former is much more complex (and expensive), many IT departments opt to do the production piece themselves. In most cases, the average programmer can access the AI model (usually via an API) and put it to work.\n\n### What is Deep Learning?\n\nFor AI, identifying whether an egg is broken is relatively simple. By contrast, looking ahead at a red, round object and labeling it a \u201cstop sign\u201d is much more complex.\n\nThis is where **deep learning** comes in. Deep learning enables AI models to sort things into tinier and tinier categories. AI experts think about this sorting as a layered process.\n\nIn the case of the stop sign, the relevant layers might be:\n\n1. Distance from car.\n2. Shape.\n3. Estimated height.\n4. Position on the road.\n5. Color.\n6. Text on the sign.\n7. Etc.\n\nTo identify the stop sign, a self-driving car would have to pass the image of the stop sign through a series of layers to make sure it wasn\u2019t a mountain, a tree, a speed limit sign, or a Starbucks. By layering simple AI categorization models on top of each other, AIs become much more sophisticated.\n\nLet\u2019s look at another example related to emotion detection. Could an AI detect whether someone was in a bad mood? To consider that question, let\u2019s first think about how humans can tell whether someone is in a bad mood.\n\nIn order to make that judgment, our brains must integrate a lot of visual and auditory information about the subject.\n\nFor example:\n\n1. Mouth position (smiling, frowning)\n2. Eyebrow position (raised, narrow)\n3. Pronounced wrinkles (laugh or frown lines)\n4. Tone and volume of voice (yelling)\n5. Speaking speed\n6. Posture\n7. Shoulder position\n8. etc\u2026\n\nIn fact, there are so many subtle and not-so-subtle indicators that it\u2019s nearly impossible to list them all out. What\u2019s nice about AI is that we never have to define those messy and long-tail indicators. AI\u2019s superpower is that it can figure out the rules for itself.\n\nBy showing an AI model dozens of faces and labeling each with an emotion, the model could be trained to find the pattern, thereby integrating a wealth of obscure information about how someone looks to predict how someone is feeling.\n\nThis is the same facial recognition capability that Apple uses to unlock your iPhone. In that case, instead of matching your face with an emotion, the system is ensuring your face matches your account.\n\nAI researchers are using images of people\u2019s faces as inputs for all kinds of models, including lie detection, age detection, disease diagnostics, and even imaging technologies that age-up missing children.\n\nAs you begin to think more and more about the ways artificial intelligence can transform your company, challenge yourself to think in terms of inputs (data) and outputs (categorization).\n\nRemember, AI is amazingly powerful. AI models can use Xrays to diagnose disease, billions of financial transactions to detect fraud, and boxes of handwritten case files to prove someone is innocent.\n\nDon\u2019t worry if the distance between inputs and outputs seems vast. AI is more than capable of making those connections.\n\nThis chapter is an excerpt from the ebook, The Complete Guide to Bringing Artificial Intelligence to your Organization.\n\n[Access the full guide here.](https://www.manceps.com/ai-guide?utm_source=Reddit&amp;utm_medium=Post&amp;utm_campaign=Everything%20You%20Need%20to%20Understand%20Artificial%20Intelligence)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hzh9vd/everything_you_need_to_understand_artificial/"}, {"autor": "sabalibruh", "date": "2020-09-15 19:18:48", "content": "Question around AI/ ML/AR /!/ I am not sure if this is a right place but I am researching on various apps focused on face change or beauty app where you can change your nose, lips , hair , hair color etc. Is that part of AR or this is combination of AR ML and AI? \n\nI am looking for some mobile app code or web code where you can look at the -----> camera !!!  and it changes the things on your face. Is there a possibility to find a open source code based on this? Please let me know if there is a better place to put this. Thanks.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/itfkd9/question_around_ai_mlar/"}, {"autor": "-No-Photo-", "date": "2020-09-14 17:31:50", "content": "An AI writer to raise awareness about privacy /!/ Talk to Simon for a chance to be featured in his next book.\n\nSimon is an AI writer who wants to extract data from your photos in order to write a story based on his analysis. This is an artistic project aiming to raise awareness about privacy and data persistence. Through a chatbot interface, Simon asks for your help to share some photos with him, this helps him write stories which, in turn, become books. You can order your printed copy once fifty stories are reached. The project uses GPT2 for text generation (sorry, it has a tendency to go religious or pornographic, although it was trained with specifically chosen non secular -and totally kid friendly- texts), and Clarifai for -----> image !!!  analysis. \n\nI\u2019d like your comments on the experience, if you try it. Please note that I am an artist/designer, I am well aware that data scientists would have done a much better job ;) \n\nhttps://metastories.ch/simon", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ispmoi/an_ai_writer_to_raise_awareness_about_privacy/"}, {"autor": "bsjsvskb", "date": "2020-06-04 18:43:52", "content": "-----> Image !!!  generator GAN /!/ I am searching for a image generator like thispersondoesnotexist.\n\nIs there a possibility to set this up without setting up a generativ adverserial network?\n\nLike a website offering it for free, or do i have to set it up myself?\n\nThx", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gwnf6d/image_generator_gan/"}, {"autor": "Yuqing7", "date": "2020-06-04 18:39:13", "content": "[R] Unsupervised Image Classification Approach Outperforms SOTA Methods by \u2018Huge Margins\u2019 /!/ -----> Image !!!  classification is the task of assigning a semantic label from a predefined set of classes to an image. One of the open questions in computer vision (CV) is whether automatic image classification can be achieved without the use of ground-truth annotations.\n\nResearchers from Katholieke Universiteit Leuven in Belgium and ETH Z\u00fcrich in a recent paper propose a two-step approach for unsupervised classification. Experimental evaluation shows the method outperforming prior work by huge margins across multiple datasets, according to the researchers. \n\nHere is a quick read: [Unsupervised Image Classification Approach Outperforms SOTA Methods by \u2018Huge Margins\u2019](https://syncedreview.com/2020/06/04/unsupervised-image-classification-approach-outperforms-sota-methods-by-huge-margins/)\n\nThe paper *Learning To Classify Images Without Labels* is on [arXiv](https://arxiv.org/pdf/2005.12320.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gwnbw9/r_unsupervised_image_classification_approach/"}, {"autor": "tgold27", "date": "2020-06-03 23:26:40", "content": "What do you think the future of A.I looks like for influencers? /!/ Artificial Intelligence (AI) is an increasing worrisome discussion in todays society, many people assume that if you adopt a robot to do a humans job, the human is therefore not needed. Although, while the use of AI in the workplace is on the rise, few understand how it will affect our jobs. The implementation of the technology will bring both challenges and opportunities but will it be positive for us?\n\nIn one aspect AI is collaborating alongside \u2018Human Resources\u2019 in companies is to ensure businesses make the most beneficial decisions that ensure they thrive collaboratively with AI. One way this is being successfully promoted in the workforce is its prospective advantage in increased productivity. Repetitive tasks are completed by AI in a faster and more accurate manner, giving professionals more time to work on human-centric tasks.\n\nAn article written by [Chethan Kumar \u2018Artificial Intelligence: Definition, Types, Examples, Technologies](https://medium.com/@chethankumargn/artificial-intelligence-definition-types-examples-technologies-962ea75c7b9b)\u2018, highlights that \u201cAI shouldn\u2019t stop at reaching the human level it must go beyond the capabilities of humans for it to reach its peak potential\u201d (Kumar, 2020).\n\nHe specifies these ideas through the following definitions:\n\n* The ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings.\n* A machine completing the tasks which involve a certain degree of intelligence which was previously deemed only to be done by humans\n* Is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, and self-correction\n* The capability of a machine to imitate the intelligent human behaviour\n\nThis is related to [Lil Miquela](https://www.thecut.com/2018/05/lil-miquela-digital-avatar-instagram-influencer.html) and [other digital models](https://www.thediigitals.com/), whether you call them, digital entities, robot influencers, cyber models, CGI models, they are all [virtual avatars created via 3D animation software.](https://wlkr.digital/robot-influencers/) With current advances in AI and technology, these models appear as human beings, although lacking in physical form, these influencers have developed personalities that people connect within the comments section of their online profiles, specifically Instagram.\n\nMany AI models have developed political views and have identified themselves as part of racial, social, or gender groups. Others are more upfront about being CGI, and the developer is clear about their participation with the account.\n\nIt can be argued that these models have adopted the concept of \u2018[Mechanical Learning](https://www.youtube.com/watch?v=ukzFI9rgwfU)\u2018, one of many ways in which AI can be achieved.\n\nChethan Kumar elaborates on machine learning, with it being a \u201cmethod where the target goal is defined and the steps to reach that target is learned by the machine itself by training gaining experience\u201d (Kumar, 2018). One can argue that this idea is prominent with Lil Miquela, gaining experience in the social media world to continue to grow as a successor. This would also come from her engagement with other users in the comments as mentioned prior. This engagement can be viewed as a [\u2018Natural Language Processing](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32)\u2018 which \u00a0is broadly defined as the \u201cautomatic manipulation of natural language, like speech and text, by software\u201d.\n\nAlthough, in a short term future of life online the increase in activity on social media platforms, specifically Instagram the one aspect that \u2018normal\u2019 influencers reign over cyber models is intimacy, and well \u2018real\u2019 connection. However, these models adopt machine learning and natural language processing to develop skills to create the presence that they are currently doing so well.\n\nJaeeun Shin and Sangwon Lee, on this concept through their research on the [\u2018Intimacy Between Actual Users and Virtual Agents: Interaction through \u201clikes\u201d and \u201ccomments\u201d\u2018.](https://ieeexplore.ieee.org/document/9001810) They conducted quantitative research from current virtual influencers on Instagram to analyse the idea that actual users on instagram want to engage with these entities. The reasoning for this was to find out how the number of \u2018likes\u2019 and \u2018comments\u2019 are associated with the -----> photography !!!  and caption. It was found that people have tendencies to leave more \u2018likes\u2019 and \u2018comments\u2019 on posts where virtual agents express their emotions.\u00a0They concluded that emotion and relationship between virtual agents themselves stir up strong interest actual users on social media.\n\nLooking into the latter of the short term (7-10 years) current influencers will experience significant change in their marketing techniques. There is an ease for CGI influencers to be completely controlled by the brands wishing to use them. This is an unpredictability that comes with real-life influencers and can be avoided with current influencers.\n\nDigital models at the moment, like Lil Miquela are becoming increasing popular amongst current celebrities due to the trend of the digital environment.\n\n##### CGI influencers increase in popularity also led me to think about the concept of [technological singularity](https://frc.ri.cmu.edu/~hpm/book98/com.ch1/vinge.singularity.html) within the online world. Vernor Vinger coined the term, defining it as [\u201ca hypothetical point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilisation\u201d.](https://codachange.org/program-item/2045-emergency-after-the-singularity/) Is this conception of digital influencers the beginning of technological singularity?\n\nAccording to Joichi Ito, Director of the MIT Media Lab, team member of The Council on Extended Intelligence, highlights \u201cthe only ones who are currently benefiting from Artificial Intelligence technologies are those who master them; those who live within what he calls the \u2018singularity bubble\u2019, while the rest of us are left outside the conversation as passive users of overwhelmingly powerful technologies\u201d(Ito, 2019).\n\n***The way this can be interpreted is:***\u00a0\n\n* *Digital influencers are \u2018mastering\u2019 the online world \u2013 and will only continue to control this in the short term as its popularity increases.*\n* *These digital entities are living within the \u2018singularity bubble\u2019.*\n* *The ones on the outside are those user of Instagram who post photos of themselves as human beings.*\n\nThe problem surrounding technological singularity is the fact that there is an implication that the future is \u201cwhere a super-intelligent technology supersedes human reason and becomes a sovereign and threatening entity\u201d. We, as a society, have become essentially bored with our immediate reality, the likes and comments on instagram were inevitably not worth enough of our time.\u00a0By transferring reality to an online avatar, we \u201clet the machine perform,\u201d \u2013\u00a0 relating to machine learning. \u00a0Media coverage that surrounds AI and super algorithms has inevitably helped inflate the possible consequences of such an exponential growth of machine intelligence \u2013 the fear that AI will take our jobs.\n\nConclusively, it is through this want for attention in society that number of digital models are increasing, proving that we can work collaboratively with AI in the short term. Adam Rivetz, co-founder of the influencer marketing company \u2018#paid\u2019, believes that current influencers will use CGI technology to create their digital avatar for the efficiency of brands as mentioned above. Rivetz stated in an interview that [\u201cthey could make a duplicate version where it\u2019s like, \u2018This is my real-life feed where I post certain things, but then here\u2019s my avatar of myself where maybe I work with different brands or do more risqu\u00e9 things,\u201d](https://www.wired.com/story/lil-miquela-digital-humans/) (Rivetz, 2018). Emily Groom, accredited with the creation of CGI influencer, [Lil Wavi](https://www.instagram.com/lil_wavi/?hl=en), is also optimistic about the future of influencer marketing.\n\n&gt;*\u201cSoon we\u2019ll see digital models walk down the runway through holograms as we dig way deeper into the future. There\u2019s so much potential and I\u2019m excited to see where it goes,\u201d \u2013* [*Emily Groom, 2018 (Interview with VICE)*](https://i-d.vice.com/en_uk/article/wjkqnn/meet-lil-wavi-the-fuccboi-answer-to-lil-miquela)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gw5df1/what_do_you_think_the_future_of_ai_looks_like_for/"}, {"autor": "Ubizwa", "date": "2020-06-02 21:59:28", "content": "Reddit GPT-2 bot posted an -----> image !!!  and tried to generate a fitting title", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gvgvci/reddit_gpt2_bot_posted_an_image_and_tried_to/"}, {"autor": "quarkyfermion", "date": "2020-06-02 17:48:18", "content": "Where are we in the collective AI technologies? /!/ computer vision are really accurate,models can just about infer everything about an -----> image !!!  .\n\ncontextualised nlp models are also around the corner.\n\nmarketing intelligence/personalised advertising using ai and big data has really been substantial in the sense that we as a consumer are always being manipulated at some form or another. \n\n\nwe are also at a point where we can do an english to code translation but that still requires the knowledge of coding languages syntax.\n\nlike i guess this sort of technology combined represents a sort of toddler learning new things.\n\nwe're using AI to find patterns in human behaviours on a minute scale, which is crazy.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gvc0x6/where_are_we_in_the_collective_ai_technologies/"}, {"autor": "dannny_westside", "date": "2020-05-29 20:57:39", "content": "reCAPTCHA won\u2018t work against AI /!/ Short question.. How should reCAPTCHA work or be safe against bots infact that all new smartphones, Google, Facebook and other brands have AI based -----> picture !!!  recognition for the best camera settings or -----> picture !!!  description. They can also recognize traffic lights or busses.\nMaybe I\u2018m wrong or not informized about something, but I think it\u2018s worth about to discuss about that.\nThoughts?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gt15xn/recaptcha_wont_work_against_ai/"}, {"autor": "MLtinkerer", "date": "2020-05-28 21:19:22", "content": "Latest from Facebook and CMU researchers: Navigating to the location indicated by a goal -----> image !!!  in a novel previously unseen environment!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gsf2hc/latest_from_facebook_and_cmu_researchers/"}, {"autor": "Catenaria", "date": "2020-05-27 20:58:30", "content": "Feature Engineering for Chaotic Time series. /!/ Hello!\n\nI'm using an LSTM to predict my city's PM10 Pollutant Time series. As I explored the data, I noticed that the variance in fixed size time windows is radically changing depending on its ocurrence in time; this led me to think that the time series is chaotic (or at least non-stationary), I'm not totally sure about that. Here's an -----> image !!!  of the time series:  \n\n\n&amp;#x200B;\n\nhttps://preview.redd.it/upxbsvchfd151.png?width=877&amp;format=png&amp;auto=webp&amp;s=17ed397def6641d5fc8db9dbe2762f20daa372e8\n\nDoes anyone know what's the usual/recommended feature engineering for chaotic time series or for this kind of phenomena?   \n\n\nI'm aware that Phase State reconstruction might be the way as I saw in some paper, but I'm looking for alternatives. \n\nThank you very much!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/grs7kl/feature_engineering_for_chaotic_time_series/"}, {"autor": "Yuqing7", "date": "2020-05-26 21:17:46", "content": "[R] Breakthrough Colourization Technique Enables Instance-Aware Treatment of Multiple Objects /!/ Researchers from National Tsing Hua University and Virginia Tech have introduced a novel deep learning framework for instance-aware colourization.  The research team proposes that colourization performance can be improved dramatically at the instance level for a few reasons. Learning to colourize instances is easier compared to existing methods that learn to colourize an entire -----> image !!! , which involves handling complex background clutter. Learning object-level representations from localized objects can also help avoid colour confusion with backgrounds. \n\nHere is a quick read: [Breakthrough Colourization Technique Enables Instance-Aware Treatment of Multiple Objects](https://medium.com/syncedreview/breakthrough-colourization-technique-enables-instance-aware-treatment-of-multiple-objects-45d25c0c716c)\n\nThe paper *Instance-aware Image Colorization* is on [arXiv](https://arxiv.org/pdf/2005.10825.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gr5vew/r_breakthrough_colourization_technique_enables/"}, {"autor": "OnlyProggingForFun", "date": "2020-12-01 22:58:23", "content": "I explain MODNet, a new human matting technique, and review the best techniques used over the years to remove the background of an -----> image !!!  (paper linked in comments)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k4wdgr/i_explain_modnet_a_new_human_matting_technique/"}, {"autor": "m1900kang2", "date": "2020-12-01 14:42:51", "content": "[Research] Using Deep Learning to Help Drones Search and Rescue People Lost in Forests /!/ [Here is the presentation video](https://crossminds.ai/video/5fc54e1fec4e469301f04be2/?playlist_id=5f07c51e2de531fe96279ccb)\n\nA trio of researchers at Johannes Kepler University has used artificial intelligence to improve thermal imaging -----> camera !!!  searches of people lost in the woods. In their paper published in the journal *Nature Machine Intelligence*, David Schedl, Indrajit Kurmi and Oliver Bimber, describe how they applied a deep learning network to the problem of people lost in the woods and how well it worked.\n\nWhen people become lost in forests, search and rescue experts use helicopters to fly over the area where they are most likely to be found. In addition to simply scanning the ground below, the researchers use binoculars and thermal imaging cameras. It is hoped that such cameras will highlight differences in body temperature of people on the ground versus their surroundings making them easier to spot. Unfortunately, in some instances thermal imaging does not work as intended because of vegetation covering subsoil or the sun heating the trees to a temperature that is similar to the body temperature of the person that is lost. In this new effort, the researchers sought to overcome these problems by using a deep learning application to improve the images that are made.\n\nThe solution the team developed involved using an AI application to process multiple images of a given area. They compare it to using AI to process data from multiple radio telescopes. Doing so allows several telescopes to operate as a single large telescope. In like manner, the AI application they used allowed multiple thermal images taken from a helicopter (or drone) to create an image as if it were captured by a camera with a much larger lens. After processing, the images that were produced had a much higher depth of field\u2014in them the tops of the trees appeared blurred while people on the ground became much more recognizable. To train the AI system, the researchers had to create their own database of images. They used drones to take pictures of volunteers on the ground in a wide variety of positions.\n\nTesting of the system showed it to be approximately 87 to 95 accurate compared to just 25 percent accurate for traditional thermal images. The researchers suggest their system is ready for use by search and rescue crews and could also be used by [law enforcement](https://techxplore.com/tags/law+enforcement/), the military, or wildlife management teams.\n\nAuthors: David C. Schedl, Indrajit Kurmi, Oliver Bimber", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k4m40t/research_using_deep_learning_to_help_drones/"}, {"autor": "vijish_madhavan", "date": "2020-12-01 13:23:35", "content": "[P] ArtLine - Generate Amazing Line Art Portraits. /!/ Hello all! Please have a look at **ArtLine's** public repo, Artline is project to generate line art from portrait photos. Hope you guys like it.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/cz7bxj4ysk261.png?width=500&amp;format=png&amp;auto=webp&amp;s=13a2cbf3da3bc32c44b4b7a558b3ea3f85b32c06\n\n**Few Examples.**\n\n&amp;#x200B;\n\nhttps://preview.redd.it/2ydj67x1tk261.jpg?width=768&amp;format=pjpg&amp;auto=webp&amp;s=3afe958585f1e073046ca5daa100ff0988dd44dd\n\nhttps://preview.redd.it/5wgx2qy0tk261.jpg?width=879&amp;format=pjpg&amp;auto=webp&amp;s=441b5875531b0fe163e3e4f338a6b3051d385378\n\n&amp;#x200B;\n\n**Gist of the project.**\n\n \n\n## Technical Details\n\n* **Self-Attention Generative Adversarial Network** ([https://arxiv.org/abs/1805.08318](https://arxiv.org/abs/1805.08318)). Generator is pretrained UNET with spectral normalization and self-attention. Something that I got from Jason Antic's DeOldify([https://github.com/jantic/DeOldify](https://github.com/jantic/DeOldify)), this made a huge difference, all of a sudden I started getting proper details around the facial features.\n* **Progressive Growing of GANs** ([https://arxiv.org/abs/1710.10196](https://arxiv.org/abs/1710.10196)). Progressive GANS takes this idea of gradually increasing the -----> image !!!  size, In this project the -----> image !!!  size were gradually increased and learning rates were adjusted. Thanks to fast.ai for intrdoucing me to Progressive GANS, this helped in generating high quality output.\n* **Generator Loss** : Perceptual Loss/Feature Loss based on VGG16. ([https://arxiv.org/pdf/1603.08155.pdf](https://arxiv.org/pdf/1603.08155.pdf)).\n\n**Surprise!! No critic,No GAN. GAN did not make much of a difference so I was happy with No GAN.**\n\n&amp;#x200B;\n\n[**https://github.com/vijishmadhavan/ArtLine**](https://github.com/vijishmadhavan/ArtLine)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k4kqco/p_artline_generate_amazing_line_art_portraits/"}, {"autor": "industrywired", "date": "2020-07-23 09:46:38", "content": "How -----> Image !!!  Processing Can Support Smart Manufacturing?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hwcvhf/how_image_processing_can_support_smart/"}, {"autor": "Yuqing7", "date": "2020-07-22 19:05:35", "content": "[R] Facebook &amp; Inria Propose High-Performance Self-Supervised Technique for CV Tasks /!/ Researchers from Facebook and the French National Institute for Research in Digital Science and Technology (Inria) have developed a new technique for self-supervised training of convolutional networks used for -----> image !!!  classification and other computer vision tasks. The proposed method surpasses supervised techniques on most transfer tasks and outperforms previous self-supervised approaches.\n\nHere is a quick read: [Facebook &amp; Inria Propose High-Performance Self-Supervised Technique for CV Tasks](https://syncedreview.com/2020/07/22/facebook-inria-propose-high-performance-self-supervised-technique-for-cv-tasks/)\n\nThe paper *Unsupervised Learning of Visual Features by Contrasting Cluster Assignments* is on [arXiv](https://arxiv.org/pdf/2006.09882.pdf). The SwAV code and pretrained models are available on the project [GitHub](https://github.com/facebookresearch/swav).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hvzv16/r_facebook_inria_propose_highperformance/"}, {"autor": "ai-lover", "date": "2020-11-07 20:43:09", "content": "An MIT And IBM Research Group Has Proposed A Cross-Modal Auditory Localization Framework To Locate Moving Objects Using Stereo Sound Instead of Visual Input /!/ Object localization means locating an instance of a particular moving object in a scene. This is done by using visual data as the input with some applied physics and mathematics. However, there can be obstructions like low light conditions, fog, occlusions, etc., which may reduce the -----> camera !!! -based approach\u2019s efficiency.\n\nTo improve object localization in such unfavorable situations, a research group from MIT and IBM has proposed a Cross-modal auditory localization framework using stereo sound to locate objects in a better way.\n\nSummary: [https://www.marktechpost.com/2020/11/07/an-mit-and-ibm-research-group-has-proposed-a-cross-modal-auditory-localization-framework-to-locate-moving-objects-using-stereo-sound-instead-of-visual-input/](https://www.marktechpost.com/2020/11/07/an-mit-and-ibm-research-group-has-proposed-a-cross-modal-auditory-localization-framework-to-locate-moving-objects-using-stereo-sound-instead-of-visual-input/)\n\nPaper: [https://arxiv.org/pdf/1910.11760.pdf](https://arxiv.org/pdf/1910.11760.pdf) \n\n&amp;#x200B;\n\nhttps://preview.redd.it/izxnwylnqvx51.png?width=696&amp;format=png&amp;auto=webp&amp;s=e5e935fc56f763233f3bb2fcd760b32468a5dfd3", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jpxx32/an_mit_and_ibm_research_group_has_proposed_a/"}, {"autor": "LoreeKButler", "date": "2020-11-04 06:56:03", "content": "Birdwatching from afar: Amazing new AI-enabled -----> camera !!!  system to target specific behaviors", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jns2df/birdwatching_from_afar_amazing_new_aienabled/"}, {"autor": "tm_labellerr", "date": "2020-09-21 06:32:18", "content": "What is -----> image !!!  rotation -----> image !!!  processing? /!/  \n\nAssuming you are asking wrt deep learning context,\n\n&amp;#x200B;\n\nhttps://preview.redd.it/4zwv046o3go51.png?width=600&amp;format=png&amp;auto=webp&amp;s=d51ed409f27067edb197fefa846217c7623d02d0\n\nImage rotation processing from what we understand is the process of considering images from multiple rotation angles based on whether you will get the images in different rotation angles at the time of predictions in test run of your model. So its like you are generating synthetic data from your available dataset without acquiring more data!\n\nExamples could be as attached above.\n\nYou can do all this without coding on our labellerr platform at [www.labellerr.com](https://www.labellerr.com)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/iwv3zr/what_is_image_rotation_image_processing/"}, {"autor": "aihubprojects", "date": "2020-09-20 06:48:04", "content": "-----> Image !!!  Colorization using CNN [P]", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/iw8xbi/image_colorization_using_cnn_p/"}, {"autor": "Yuqing7", "date": "2020-10-08 22:07:13", "content": "[R] \u2018Farewell Convolutions\u2019 \u2013 ML Community Applauds Anonymous ICLR 2021 Paper That Uses Transformers for Image Recognition at Scale /!/ A new research paper, *An -----> Image !!!  Is Worth 16\u00d716 Words: Transformers for -----> Image !!!  Recognition at Scale,* has the machine learning community both excited and curious. With Transformer architectures now being extended to the computer vision (CV) field, the paper suggests the direct application of Transformers to image recognition can outperform even the best convolutional neural networks when scaled appropriately. Unlike prior works using self-attention in CV, the scalable design does not introduce any image-specific inductive biases into the architecture.\n\nHere is a quick read: [\u2018Farewell Convolutions\u2019 \u2013 ML Community Applauds Anonymous ICLR 2021 Paper That Uses Transformers for Image Recognition at Scale](https://syncedreview.com/2020/10/08/farewell-convolutions-ml-community-applauds-anonymous-iclr-2021-paper-that-uses-transformers-for-image-recognition-at-scale/)\n\nThe paper *An Image Is Worth 16\u00d716 Words: Transformers for Image Recognition at Scale* is available on[ OpenReview](https://openreview.net/pdf?id=YicbFdNTTy).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j7mmpz/r_farewell_convolutions_ml_community_applauds/"}, {"autor": "Robin5409", "date": "2020-10-08 17:05:26", "content": "Artificial intelligence in Data Centre Physical Security and Particle Physics Discoveries /!/  \n\nhttps://preview.redd.it/v1fzj8gfkwr51.jpg?width=1254&amp;format=pjpg&amp;auto=webp&amp;s=a869184940d778264c443dfdd4b0d4403983bd69\n\n# How AI is Used in Data Centre Physical Security\n\nLarge data centres that have specific needs have multiple commercial and open-source **-----> image !!!  recognition** algorithms and training sets available. For the smaller data centres, ones that do not have the resources for AI development team, these features are included in their security products.\n\nStockholm-based research firm Memoori says that AI analytics will become a standard feature of video surveillance solutions over the next decade.\n\nAnother common aspect of machine learning used in data centre security is **Anomaly Detection**. The system is trained on the baseline of data, identifies common patterns, and then looks for unusual events that do not fit in those patterns. This helps data centres to spot problems that are happening and could be missed by security teams otherwise.\n\n**Pattern recognition** can also be used to predict events. In data centres, this capability is mostly used for predictive maintenance. For example, if a piece of equipment heats up to an unusual level, an AI system will flag the problem and raise a service request before the equipment fails completely. Currently, predictive analytics is mostly used in data centres for maintenance but there are vendors working on technologies that can help spot security issues before they happen. This is being worked on by combining in-house data such as emails or video surveillance with external data such as arrest reports or social media posts.\n\n**Artificial Intelligence Enhances Speed of Discoveries For Particle Physics**\n\nResearchers at MIT have demonstrated that when it comes to theoretical physics, utilizing AI to simulate aspects of nuclear physics theory leads to faster algorithms and hence faster discoveries. This is possible by combining theoretical physics with artificial intelligence models to speed up the creation of samples that simulate interactions between protons, neutrons, and nuclei.\n\nThe symmetries within physics theories can be incorporated into ML algorithms and produce algorithms that are more suitable to particle physics studies. Here, machine learning models are not being used to process huge amounts of data, but to integrate particle symmetries. The inclusion of these attributes within a model means that computations can be done faster.\n\nAmong the several Artificial intelligence programs that are offered by various institutions, the [artificial intelligence courses](https://www.greatlearning.in/pg-program-artificial-intelligence-course/) in Great Learning are really productive because these AI courses not only help you grow individually but their placement cells make sure that you get into one of these top companies. So, if your aim is to [learn Artificial Intelligence](https://www.greatlearning.in/pg-program-artificial-intelligence-course/) then Great Learning should be the destination.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j7gy2d/artificial_intelligence_in_data_centre_physical/"}, {"autor": "PatrickVibild", "date": "2020-10-06 14:09:58", "content": "Intel L515 vs Azure kinect for -----> image !!!  recognition. /!/ Hi all.\n\n&amp;#x200B;\n\nHands on I have to ask for foundings for an educational project.\n\n&amp;#x200B;\n\nThe project is controlling a hand robot that interacts with a human. The sensors need to be done with image recognition and I have been checking Intel L515 and Azure Kinect for this porpoise. I see that Azure Kinect have already a skeleton SDK for free, while I had to pay for that in Intel. I guess that once I have the RGB and depth image I can get the skeleton I can run some other algorithm to get the skeleton.\n\n&amp;#x200B;\n\nWhat I saw is that Intel L515 has a higher resolution for the depth field compared to the Azure version. Is that noticeable?\n\n&amp;#x200B;\n\nI have no previous experiences and I will be doing this 1 year project. Where I have to create this collaboration with the human arm and a human with image recognition. Any help on how to proceed and what are the needed components in order to ask for fundings would be appreciated.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j65p8t/intel_l515_vs_azure_kinect_for_image_recognition/"}, {"autor": "Yuqing7", "date": "2020-10-01 18:45:26", "content": "[R] EvolGAN Boosts Image Quality for Small or Difficult Datasets /!/ GAN models however require massive amounts of training data to reach decent performance. In an effort to make GANs more effective and reliable when only small, difficult, or multimodal datasets are available, a group of researchers from Facebook AI, University of the Littoral Opal Coast, University of Grenoble and University of Konstanz have proposed Evolutionary Generative Adversarial Networks (EvolGAN).\n\nHere is a quick read: [EvolGAN Boosts Image Quality for Small or Difficult Datasets](https://syncedreview.com/2020/10/01/evolgan-boosts------> image !!! -quality-for-small-or-difficult-datasets/)\n\nThe paper *EvolGAN: Evolutionary Generative Adversarial Networks* is on [arXiv](https://arxiv.org/pdf/2009.13311.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j3elpz/r_evolgan_boosts_image_quality_for_small_or/"}, {"autor": "Yuqing7", "date": "2020-09-30 21:32:52", "content": "[R] Nvidia Releases \u2018Imaginaire\u2019 Library for Image and Video Synthesis /!/ Researchers from chip giant Nvidia this week delivered Imaginaire, a universal PyTorch library designed for various GAN-based tasks and methods. Imaginaire comprises optimized implementations of several Nvidia -----> image !!!  and video synthesis methods, and the company says the library is easy to install, follow, and develop.\n\nHere is a quick read: [Nvidia Releases \u2018Imaginaire\u2019 Library for Image and Video Synthesis](https://syncedreview.com/2020/09/30/nvidia-releases-imaginaire-library-for-image-and-video-synthesis/)\n\nThe Imaginaire library is on [GitHub](https://github.com/NVlabs/imaginaire).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j2v83k/r_nvidia_releases_imaginaire_library_for_image/"}, {"autor": "kellymanluo", "date": "2020-09-30 15:21:06", "content": "AI -----> photo !!!  restoration - KellyOnTech artificial intelligence series @Mans ...", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j2o4vu/ai_photo_restoration_kellyontech_artificial/"}, {"autor": "MLtinkerer", "date": "2020-06-17 04:37:49", "content": "Latest from UPenn researchers: Multi-person 3D pose estimation from a single -----> image !!! ", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hak6ej/latest_from_upenn_researchers_multiperson_3d_pose/"}, {"autor": "Kukki3011", "date": "2020-06-16 13:30:19", "content": "Digit recognition ?!? /!/ Hi everyone, I'm attempting at building a Sudoku Solver and came across a problem. I have extracted the digit images from each grid, but when trying to recognise them, my CNN model doesn't perform well enough.\nThe model in trained on the MNIST Dataset and gives ~98% accuracy for the test dataset.\nCan someone maybe explain what all preprocessing steps for the grid -----> image !!!  is required in order to get better results ?", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ha413m/digit_recognition/"}, {"autor": "300986457733790", "date": "2020-06-12 03:23:32", "content": "AI Conceptual Automated Imagery Scanning. /!/ AI systems developed with visual recognition to \"accidently\" recognize randomised geometry and shapes that forms many pictures of very detail orientated concepts, products and even medicine, random discovery by large repository of integrative \"shots\" that have probable discovery possibilities.\n\nSummary.\n\nSay you were to hold a -----> picture !!!  of an Apple and a ladder and move it around until the eye saw an accidental discovery like a motorbike fender embedded in the -----> picture !!! , this accidental discovery system works with neuro interactive glassess for humans.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/h7d22o/ai_conceptual_automated_imagery_scanning/"}, {"autor": "MLtinkerer", "date": "2020-06-12 02:56:59", "content": "From SIGGRAPH 2020: Method reconstructs the geometry of complex 3D thin structures in high quality from a color video captured by a handheld -----> camera !!! ", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/h7co2r/from_siggraph_2020_method_reconstructs_the/"}, {"autor": "MLtinkerer", "date": "2020-06-11 01:18:26", "content": "Reconstruct 3D human body shapes based on a sparse set of RGBD frames using a single RGBD -----> camera !!! ", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/h0p3xv/reconstruct_3d_human_body_shapes_based_on_a/"}, {"autor": "BokanovskifiedEgg", "date": "2020-07-10 04:54:15", "content": "Please recommend AI websites /!/ I have used this music creation midi site a lot \n\n[https://openai.com/blog/musenet/](https://openai.com/blog/musenet/)\n\nand i had fun with this renaissance art generator\n\n[https://ai-art.tokyo/en/](https://ai-art.tokyo/en/)\n\nBut im wondering if anyone recommends any more like these.\n\nPlease only recommend ones that are generated in the cloud.\n\nSites that you upload your video, audio, -----> picture !!! , or other data and alter them using some sort of interesting AI process.\n\n&amp;#x200B;\n\nCheers!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hoit4t/please_recommend_ai_websites/"}, {"autor": "MLtinkerer", "date": "2020-07-09 20:11:52", "content": "Latest from Adobe and UC Berkeley researchers: State of the art in deep -----> image !!!  manipulation.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hoacpz/latest_from_adobe_and_uc_berkeley_researchers/"}, {"autor": "Yuqing7", "date": "2020-07-09 18:44:44", "content": "[R] Grand Theft Auto Scene Context Data Boosts Human Motion Prediction /!/ The shortest distance between point A and point B may be measured as a straight line, but in the real, obstruction-filled world, the routes that humans choose are actually determined by the spatial layout of the objects in a given environment \u2014 aka scene context. A team of researchers from UC Berkeley, Nanjing University and Facebook Reality Lab have proposed a novel three-stage learning framework that includes scene context to generate long-term 3D human motion prediction when given a single scene -----> image !!!  and 2D pose histories.  \n \n\nHere is a quick read: [Grand Theft Auto Scene Context Data Boosts Human Motion Prediction](https://syncedreview.com/2020/07/09/grand-theft-auto-scene-context-data-boosts-human-motion-prediction/)\n\nThe paper *Long-term Human Motion Prediction with Scene Context* is on [arXiv](https://arxiv.org/pdf/2007.03672.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ho8q1a/r_grand_theft_auto_scene_context_data_boosts/"}, {"autor": "Datatang", "date": "2020-07-02 09:09:30", "content": "MIT apologizes, permanently pulls offline huge dataset that taught AI systems to use racist, misogynistic slurs /!/ MIT has been involved in the public opinion of racial discrimination because of using -----> image !!!  data with some labels of racial discrimination and discrimination against women. The artificial intelligence research seems to be becoming a new battlefield for George Floyd's incident in the United States. Is the ethical discussion in the machine learning field necessary or overcorrect?  What do you think? \n\n&amp;#x200B;\n\nhttps://preview.redd.it/gsimo3tute851.png?width=920&amp;format=png&amp;auto=webp&amp;s=b2f8e9093d81ea53b9bb17d196aff9a28bcf33f8", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hjtpjg/mit_apologizes_permanently_pulls_offline_huge/"}, {"autor": "Thought_Starter", "date": "2020-07-02 02:01:46", "content": "[OC] \"Abandoned Flu\" \u2013 a short -----> film !!!  written entirely by A.I", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hjo953/oc_abandoned_flu_a_short_film_written_entirely_by/"}, {"autor": "daddyyucky", "date": "2020-07-01 02:40:16", "content": "Google vs Bing: Copyright Considerations /!/ Hey, check this out!  I am attempting to calculate the possible permutation me of an -----> image !!!  file scaling resolution and pigments by digital analysis to apply for a copyright for any visual artistic production possible I can then lease by subscription and the modern values are too large to be calculated, even by big number math and I was only capable of using a more primitive 256x256 resolution with 256 colors which yields.\n\n\nhttps://www.calculator.net/big-number-calculator.html?cx=65536&amp;cy=256&amp;cp=1&amp;co=factor", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hj1syq/google_vs_bing_copyright_considerations/"}, {"autor": "MLtinkerer", "date": "2020-02-07 03:25:30", "content": "State of the art in -----> image !!!  to -----> image !!!  translation (guided)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/f04gmh/state_of_the_art_in_image_to_image_translation/"}, {"autor": "analyticsindiam", "date": "2020-08-11 11:37:02", "content": "Converting -----> Image !!!  Into A Pencil Sketch In Python-Analytics India Magazine /!/ [https://analyticsindiamag.com/converting-image-into-a-pencil-sketch-in-python/](https://analyticsindiamag.com/converting-image-into-a-pencil-sketch-in-python/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i7q7ip/converting_image_into_a_pencil_sketch_in/"}, {"autor": "Yuqing7", "date": "2020-08-10 21:15:24", "content": "[R] Tour the World From Your Couch: Google \u2018NeRF-W\u2019 Delivers Accurate 3D Scene Reconstruction of Complex Outdoor Environments /!/ Google researchers have introduced a series of extensions to the SOTA view-synthesis method Neural Radiance Fields (NeRF) that enable it to produce high-quality 3D representations of complex scenes with only unstructured -----> image !!!  collections as input. The approach improves NeRF\u2019s ability to model common real-world phenomena such as variable illumination conditions or transient occluders found in such uncontrolled images.\n\nHere is a quick read: [*Tour the World From Your Couch: Google \u2018NeRF-W\u2019 Delivers Accurate 3D Scene Reconstruction of Complex Outdoor Environments*](https://syncedreview.com/2020/08/10/tour-the-world-from-your-couch-google-nerf-w-delivers-accurate-3d-scene-reconstruction-of-complex-outdoor-environments/)\n\nThe paper *NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections* is on [arXiv](https://arxiv.org/pdf/2008.02268.pdf). Additional information and examples are available on the [GitHub](https://nerf-w.github.io/) project page.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i7dtku/r_tour_the_world_from_your_couch_google_nerfw/"}, {"autor": "Ezio-0", "date": "2020-08-10 16:58:49", "content": "Facebook's A.I. takes -----> image !!!  recognition to a whole new level", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i78o8a/facebooks_ai_takes_image_recognition_to_a_whole/"}, {"autor": "ThisVineGuy", "date": "2020-08-09 11:45:22", "content": "This AI can cartoonize any -----> picture !!!  or video you feed it! Tune in the video in caption at 3:08 to see more awesome examples using it, they passed in on The Avengers movie and the results are impressive!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i6i0il/this_ai_can_cartoonize_any_picture_or_video_you/"}, {"autor": "Xcrinklecut", "date": "2020-08-09 08:15:32", "content": "We aggregated and indexed almost 2000 -----> image !!!  datasets so you don't have to - Bifrost Data Search /!/ Hi r/ArtificialInteligence!\n\nWe\u2019ve all experienced the pain of searching for that perfect dataset. The world's datasets are scattered across academic websites and Github repos. That\u2019s why we came up with Bifrost Data Search.\n\nBifrost Data Search is an initiative to aggregate, analyse and deliver the world's image datasets straight into the hands of AI developers. You can search from over 1000 listings paired with rich information and in-depth analyses. It\u2019s 100% free and we\u2019re always adding more datasets and features.\n\nThis is just a beta release, and we\u2019d love to hear your feedback so we can make this a valuable resource for the community! We're currently live on [https://www.producthunt.com/posts/bifrost-data-search](https://www.producthunt.com/posts/bifrost-data-search).\n\nWe really hope you like it!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i6fvgj/we_aggregated_and_indexed_almost_2000_image/"}, {"autor": "Iwillachieveit", "date": "2020-08-08 19:58:14", "content": "AI screener on the Bumble app /!/ Good Afternoon, \n\nThe topless -----> photo !!!  screener on Bumble, is really annoying, especially since I worked hard for this 8 pack!\n\nDoes anyone know how to bypass it?  \n\nNo negative comments please.\n\nThanks", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i65nzg/ai_screener_on_the_bumble_app/"}, {"autor": "OnlyProggingForFun", "date": "2020-08-08 13:59:41", "content": "This AI can cartoonize any -----> picture !!!  or video you feed it! Paper Introduction &amp; Results examples", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i5zkwu/this_ai_can_cartoonize_any_picture_or_video_you/"}, {"autor": "analyticsindiam", "date": "2020-08-18 04:58:15", "content": "How To Convert A Sketch Into Colored -----> Image !!!  Using Conditional GAN - Analytics India Magazine /!/ [https://analyticsindiamag.com/convert-a-sketch-into-colored-image-using-cgan/?fbclid=IwAR2B4pTnNI4SyFe7IeNPuc-bYjuQ8ImN7-Cp8vWRFR7lruQZPalmEmWXvmo](https://analyticsindiamag.com/convert-a-sketch-into-colored-image-using-cgan/?fbclid=IwAR2B4pTnNI4SyFe7IeNPuc-bYjuQ8ImN7-Cp8vWRFR7lruQZPalmEmWXvmo)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ibuoyn/how_to_convert_a_sketch_into_colored_image_using/"}, {"autor": "Robin5409", "date": "2020-08-16 19:10:04", "content": "Artificial Intelligence Books For Beginners | Top 17 Books of AI for Freshers /!/  \n\nhttps://preview.redd.it/th4cwej2yeh51.jpg?width=632&amp;format=pjpg&amp;auto=webp&amp;s=01a267b8692d560e87b87f5a4797057747c1d394\n\n[**Artificial Intelligence**](https://www.greatlearning.in/pg-program-artificial-intelligence-course) (AI) has taken the world by storm. Almost every industry across the globe is incorporating AI for a variety of applications and use cases. Some of its wide range of applications includes process automation, predictive analysis, fraud detection, improving customer experience, etc.\n\nAI is being foreseen as the future of technological and economic development. As a result, the career opportunities for AI engineers and programmers are bound to drastically increase in the next few years. If you are a person who has no prior knowledge about AI but is very much interested to learn and start a career in this field, the following ten Books on Artificial Intelligence will be quite helpful:\n\n# List of 17 Best AI Books for Beginners\n\n# \u2013 By Stuart Russell &amp; Peter Norvig\n\n \n\nThis book on artificial intelligence has been considered by many as one of the best AI books for beginners. It is less technical and gives an overview of the various topics revolving around AI. The writing is simple and all concepts and explanations can be easily understood by the reader.\n\nThe concepts covered include subjects such as search algorithms, game theory, multi-agent systems, statistical Natural Language Processing, local search planning methods, etc. The book also touches upon advanced AI topics without going in-depth. Overall, it\u2019s a must-have book for any individual who would like to learn about AI.\n\n# 2. Machine Learning for Dummies\n\n\u2013 *By John Paul Mueller and Luca Massaron*\n\n \n\n*Machine Learning for Dummies* provides an entry point for anyone looking to get a foothold on Machine Learning. It covers all the basic concepts and theories of machine learning and how they apply to the real world. It introduces a little coding in Python and R to teach machines to perform data analysis and pattern-oriented tasks.\n\nFrom small tasks and patterns, the readers can extrapolate the usefulness of machine learning through internet ads, web searches, fraud detection, and so on. Authored by two data science experts, this Artificial Intelligence book makes it easy for any layman to understand and implement machine learning seamlessly.\n\n# 3. Make Your Own Neural Network\n\n\u2013 *By Tariq Rashid* \n\nOne of the books on artificial intelligence that provides its readers with a step-by-step journey through the mathematics of Neural Networks. It starts with very simple ideas and gradually builds up an understanding of how neural networks work. Using Python language, it encourages its readers to build their own neural networks.\n\nThe book is divided into three parts. The first part deals with the various mathematical ideas underlying the neural networks. Part 2 is practical where readers are taught Python and are encouraged to create their own neural networks. The third part gives a peek into the mysterious mind of a neural network. It also guides the reader to get the codes working on a Raspberry Pi.\n\n# 4. Machine Learning: The New AI\n\n\u2013 *By Ethem Alpaydin* \n\n*Machine Learning: The New AI* gives a concise overview of machine learning. It describes its evolution, explains important learning algorithms, and presents example applications. It explains how digital technology has advanced from number-crunching machines to mobile devices, putting today\u2019s machine learning boom in context.\n\nThe book on artificial intelligence gives examples of how machine learning is being used in our day-to-day lives and how it has infiltrated our daily existence. It also discusses the future of machine learning and the ethical and legal implications for data privacy and security. Any reader with a non-Computer Science background will find this book interesting and easy to understand.\n\n# 5. Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies\n\n\u2013 *By John D. Kelleher, Brian Mac Namee, Aoife D\u2019Arcy*\n\n \n\nThis AI Book covers all the fundamentals of machine learning along with practical applications, working examples, and case studies. It gives detailed descriptions of important machine learning approaches used in predictive analytics.\n\nFour main approaches are explained in very simple terms without using many technical jargons. Each approach is described by using algorithms and mathematical models illustrated by detailed worked examples. The book is suitable for those who have a basic background in computer science, engineering, mathematics or statistics.\n\n# 6. The Hundred-Page Machine Learning Book\n\n\u2013 *By Andriy Burkov* \n\nAndriy Burkov\u2019s \u201c*The Hundred-Page Machine Learning Book*\u201d is regarded by many industry experts as the best book on machine learning. For newcomers, it gives a thorough introduction to the fundamentals of machine learning. For experienced professionals, it gives practical recommendations from the author\u2019s rich experience in the field of AI.\n\nThe book covers all major approaches to machine learning. They range from classical linear and logistic regression to modern support vector machines, boosting, Deep Learning, and random forests. This book is perfect for those beginners who want to get familiar with the mathematics behind machine learning algorithms.\n\n# 7. Artificial Intelligence for Humans\n\n*\u2013 By Jeff Heaton* \n\nThis book helps its readers get an overview and understanding of AI algorithms. It is meant to teach AI for those who don\u2019t have an extensive mathematical background. The readers need to have only a basic knowledge of computer programming and college algebra.\n\nFundamental AI algorithms such as linear regression, clustering, dimensionality, and distance metrics are covered in depth. The algorithms are explained using numeric calculations which the readers can perform themselves and through interesting examples and use cases.\n\n# 8. Machine Learning for Beginners\n\n*\u2013 By Chris Sebastian* \n\nAs per its title, *Machine Learning for Beginners* is meant for absolute beginners. It traces the history of the early days of machine learning to what it has become today. It describes how big data is important for machine learning and how programmers use it to develop learning algorithms. Concepts such as AI, neural networks, swarm intelligence, etc. are explained in detail.\n\nThis Artificial Intelligence book provides simple examples for the reader to understand the complex math and probability statistics underlying machine learning. It also provides real-world scenarios of how machine learning algorithms are making our lives better.\n\n# 9. Artificial Intelligence: The Basics\n\n\u2013 *By Kevin Warwick* \n\nThis book provides a basic overview of different AI aspects and the various methods of implementing them. It explores the history of AI, its present, and where it will be in the future. The book has interesting depictions of modern AI technology and robotics. It also gives recommendations for other books that have more details about a particular concept.\n\nThe book is a quick read for anyone interested in AI. It explores issues at the heart of the subject and provides an illuminating experience for the reader.\n\n# 10. Machine Learning for Absolute Beginners: A Plain English Introduction\n\n*\u2013 By Oliver Theobald* \n\nOne of the few artificial intelligence books that explains the various theoretical and practical aspects of machine learning techniques in a very simple manner. It makes use of plain English to prevent beginners from being overwhelmed by technical jargons. It has clear and accessible explanations with visual examples for the various algorithms.\n\n*Apart from learning the technology itself for the business applications, there are other aspects of AI that enthusiasts should know about, the philosophical, sociological, ethical, humanitarian and other concepts. Here are some of the books that will help you understand other aspects of AI for a larger -----> picture !!! , and also help you indulge in intelligent discussions with peers.*\n\n# Philosophical books\n\n# 11. Superintelligence: Paths, Dangers, Strategies\n\n*\u2013 By Nick Bostrom* \n\nRecommended by both Elon Musk and Bill Gates, the book talks about steering the course through the unknown terrain of AI. The author of this book, Nick Bostrom, is a Swedish-born philosopher and polymath. His background and experience in computational neuroscience and AI lays the premise for this marvel of a book.\n\n# 12. Life 3.0\n\n\u2013 *By Max Tegmark* \n\nThis AI book by Max Tegmark will surely inspire anyone to dive deeper into the field of Artificial Intelligence. It covers the larger issues and aspects of AI including superintelligence, physical limits of AI, machine consciousness, etc. It also covers the aspect of automation and societal issues arising with AI.\n\n# Sociological Books\n\n# 13. The Singularity Is Near\n\n*\u2013 By Ray Kurzweil* \n\nRay Kurzweil was called \u2018restless genius\u2019 by the Wall Street Journal and is also highly praised by Bill Gates. He is a leading inventor, thinker, and futurists who takes keen interest in the field of Artificial Intelligence. In this AI book, he talks about the aspect of AI which is most feared by many of us, i.e., \u2018Singularity\u2019. He talks extensively about the union of humans and the machine.\n\n# 14. The Sentiment Machine\n\n*\u2013 By Amir Husain* \n\nThis book challenges us about societal norms and the assumptions of a \u2018good life\u2019. Amir Husain, being the brilliant computer scientist he is, points out that the age of Artificial Intelligence is the dawn of a new kind of intellectual diversity. He guides us through the ways we can embrace AI into our lives for a better tomorrow.\n\n# 15. The Society of Mind\n\n*\u2013 By Marvin Minsky* \n\nMarvin Minsky is the co-founder of the AI Laboratory at MIT and has authored a number of great Artificial Intelligence Books. One such book is \u2018The Society of Mind\u2019 which portrays the mind as a society of tiny components. This is the ideal book for all those who are interested in exploring intelligence and the aspects of mind in the age of AI.\n\n# Humanitarian Books\n\n# 16. The Emotion Machine\n\n*\u2013 By Marvin Minsky* \n\nIn this book, Marvin Minsky presents a novel and a fascinating model of how the human mind works. He also argues that machines with a conscious can be built to assist humans with their thinking process. In his book, he presents emotion as another way of thinking. It is a great follow up to the book \u201cSociety Of Mind\u201d.\n\n# 17. Human Compatible \u2014 Artificial Intelligence and the Problem of Control\n\n*\u2013 By Stuart Russell* \n\nThe AI researcher, Stuart Russell explains the probable misuse of Artificial Intelligence and its near term benefits. It is an optimistic and an empathetic take on the journey of humanity in this day and age of AI. The author also talks about the need for rebuilding AI on a new foundation where the machine can be built for humanity and its objectives.\n\nSo these were some of the books on artificial intelligence that we recommend to start with. Under Artificial Intelligence, we have Machine Learning, Deep Learning, Computer Vision, Neural Networks and many other concepts which you need to touch upon. To put machine learning in context, some Basic Python Programming is also introduced. The reader doesn\u2019t need to have any mathematical background or coding experience to understand this book.\n\nIf you are interested in the domain of AI and want to learn more about the subject, check out [**Great Learning\u2019s PG program in Artificial Intelligence and Machine Learning.**](https://www.greatlearning.in/pg-program-artificial-intelligence-course)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/iaybsl/artificial_intelligence_books_for_beginners_top/"}, {"autor": "cloud_weather", "date": "2020-08-16 15:27:51", "content": "-----> Image !!!  Restoration AI - Upscale and Restore Faces with DFDNet", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/iau8n6/image_restoration_ai_upscale_and_restore_faces/"}, {"autor": "MLtinkerer", "date": "2020-08-15 19:09:20", "content": "From Adobe, Stanford, &amp; UWashington: A new framework can predict a full head portrait for ages 0-70 from a single -----> photo !!! , modifying both texture and shape of the head", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/iaddvm/from_adobe_stanford_uwashington_a_new_framework/"}, {"autor": "Yuqing7", "date": "2020-11-13 04:46:43", "content": "[R] Google &amp; DeepMind Debut Benchmark for Long-Range Transformers /!/ Google Research and DeepMind recently introduced Long-Range Arena (LRA), a benchmark for evaluating Transformer research on tasks requiring long sequence lengths.\n\nThe LRA benchmark suite tests model capabilities in dealing with diverse data types and structures such as text, mathematics, and visual data. It includes both synthetic probing tasks and real-world tasks comprising sequences ranging from 1K to 16K tokens:\n\n* *Long ListOps*\n* *Byte-Level Text Classification*\n* *Byte-Level Document Retrieval*\n* *-----> Image !!!  Classification on Sequences of Pixels*\n* *Pathfinder (Long-Range Spatial Dependency)*\n* *Pathfinder-X (Long-Range Spatial Dependencies With Extreme Lengths)*\n\nHere is a quick read: [Google &amp; DeepMind Debut Benchmark for Long-Range Transformers](https://syncedreview.com/2020/11/12/google-deepmind-debut-benchmark-for-long-range-transformers/)\n\nThe paper *Long-Range Arena: A Benchmark for Efficient Transformers* is available on [arXiv](https://arxiv.org/pdf/2011.04006.pdf), and code is open-sourced on [GitHub](https://github.com/google-research/long-range-arena).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jtauou/r_google_deepmind_debut_benchmark_for_longrange/"}, {"autor": "Yuqing7", "date": "2020-12-10 19:59:05", "content": "[R] MIT CSAIL Uses Deep Generative Model StyleGAN2 to Deliver SOTA -----> Image !!!  Reconstruction Results /!/ A group of researchers from MIT Computer Science &amp; Artificial Intelligence Laboratory (CSAIL) have proposed a simple framework for performing different image reconstruction tasks using the state-of-the-art generative model StyleGAN2.\n\nHere is a quick read: [MIT CSAIL Uses Deep Generative Model StyleGAN2 to Deliver SOTA Image Reconstruction Results](https://syncedreview.com/2020/12/10/mit-csail-uses-deep-generative-model-stylegan2-to-deliver-sota-image-reconstruction-results/)\n\nThe paper *Bayesian Image Reconstruction using Deep Generative Models* is on[ arXiv](https://arxiv.org/pdf/2012.04567.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kamsnn/r_mit_csail_uses_deep_generative_model_stylegan2/"}, {"autor": "aFinnishWeeb", "date": "2020-12-10 10:41:36", "content": "Ai that gets rid of clothes /!/ Found this site that uses AI to remove any clothing from any -----> picture !!!  and its called deepsukebe.io", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/kad7bc/ai_that_gets_rid_of_clothes/"}, {"autor": "Yuqing7", "date": "2020-12-09 20:39:31", "content": "[R] This Pizza Does Not Exist: StyleGAN2-Based Model Generates Photo-Realistic Pizza Images /!/ If your love of pizza is as strong as your imagination, you may want to check out the new AI-powered Multi-Ingredient Pizza Generator (MPG), which can deliver all these mouth-watering pies and many more. There\u2019s no guarantee of the flavour, though, as the fancy MPG \u201cpizzas\u201d aren\u2019t baked in an oven; rather they\u2019re produced by a conditional Generative Adversarial Network (GAN) framework developed by researchers from Rutgers University and Samsung AI Center. Designed for synthesizing multi-label images, MPG combines a new conditioning technique with the StyleGAN2 structure to enforce intermediate feature maps to learn scalewise label information.\n\nHere is a quick read: [This Pizza Does Not Exist: StyleGAN2-Based Model Generates Photo-Realistic Pizza Images](https://syncedreview.com/2020/12/09/this-pizza-does-not-exist-stylegan2-based-model-generates------> photo !!! -realistic-pizza-images/)\n\nThe team notes that \u2014 while pizzas are certainly fun \u2014 their framework can also be extended to other multi-label image generation scenarios. The paper *MPG: A Multi-ingredient Pizza Image Generator with Conditional StyleGANs* is on [arXiv](https://arxiv.org/pdf/2012.02821.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ka055j/r_this_pizza_does_not_exist_stylegan2based_model/"}, {"autor": "mantha_anirudh", "date": "2020-12-09 11:51:14", "content": "Artificial Intelligence vs Machine Learning vs Data Science /!/ &amp;#x200B;\n\n[Artificial intelligence](https://preview.redd.it/sdk4yujpg5461.jpg?width=400&amp;format=pjpg&amp;auto=webp&amp;s=2a02cb00a52f51f78532ed501d010333767369f8)\n\nModern technologies like Artificial Intelligence, Machine Learning, Data Science and Big Data have become the buzzwords everyone speaks, but no one fully understands. They look too complicated for a commoner. All of these buzzwords are similar to those of a business executive or a student from a non-technical background. People are often confused with terms like AI, ML and data science. In this blog, we will explain these techniques in simple terms so that you can easily understand the difference between them and how they are used in business.\n\n**Read more:**  [AI &amp; ML Use Cases Across Eight Industries](https://www.usmsystems.com/ai-and-ml-use-cases/)\n\n**What is Artificial Intelligence (AI)?**\n\nArtificial intelligence refers to the simulation of the human brain function by machines. This is achieved by creating an artificial neural network that can show human intelligence. The essential human functions that an AI machine performs are logical reasoning, learning and self-correction. Artificial intelligence is a vast field with many applications, but it is also a very complex technology to work with. Machines are not inherently smart, and we need a lot of computing power and data to make them, to empower them to emulate human thinking.\n\n&amp;#x200B;\n\nAI is divided into two parts, General Artificial Intelligence and Narrow Artificial Intelligence. General AI refers to the intelligent transformation of machines into a broader range of thought and reasoning activities. Narrow AI, on the other hand, is the use of artificial intelligence for a particular task. For example, simple AI means an algorithm capable of playing all types of board games, while narrow AI limits the range of machine capabilities to a specific game, such as chess or scrabble. Currently, narrow AI is only within the purview of developers and researchers. General AI is the dream of researchers and public awareness that it will take a long time for the human race to achieve (if ever possible).\n\n**Know more:**  [Top 50 AI Companies in US, India &amp; Europe](https://www.usmsystems.com/top-ai-companies-list/)\n\n&amp;#x200B;\n\n**What is machine learning?**\n\nMachine learning (ML) is the ability to learn from the computer system environment and improve oneself from experience without the need for explicit programming. Machine learning focuses on learning algorithms from the data provided, gathering insights and making predictions on previously analyzed data using the collected information. Machine learning can be done using multiple approaches. Three basic models of machine learning are supervised, supervised and reinforcement practice.\n\nIn the case of supervised practice, labelled data is used to identify features and assist machines for future data. For example, if you want to categorize -----> image !!! s of cats and dogs, you can play with some labelled -----> image !!!  data, and the machine will classify all other -----> image !!! s for you. On the other hand, in the unsupervised practice, we put unlabeled data and let the mechanism understand the characteristics and classify it. Reinforcement machine learning algorithms interact with the environment by generating actions and then analyzing errors or rewards. For example, the ML algorithm does not analyze individual movements to understand a chess game but studies the game as a whole.\n\n**What is Data Science?**\n\nData science means extracting relevant insights from data sets. It uses a variety of techniques from a variety of fields, including mathematics, machine learning, computer programming, statistical modelling, data engineering and visualization, model recognition and learning, uncertainty modelling, data warehousing, and cloud computing. Data science does not necessarily involve big data, but the fact that data can be scaled makes big data an important aspect of data science.\n\n&amp;#x200B;\n\nData Science AI, ML and the most widely used data-driven technology in it. Data science practitioners generally specialize in mathematics, statistics, and programming (although none of these three are required). Data scientists solve complex data problems to bring data, insights, and correlation patterns into a business.\n\nRead more about the key : [**The Difference between Artificial Intelligence &amp; Machine Learning**](https://www.usmsystems.com/difference-between-ai-and-machine-learning/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k9qiz4/artificial_intelligence_vs_machine_learning_vs/"}, {"autor": "Sam_Alton", "date": "2020-08-28 01:58:31", "content": "How Can I get to AI ? /!/ I have nothing but common sense on programming but lately I've had a cool idea that has something to do with computational -----> photography !!!  , and I want to ask you guys **How Can I start learning or experimenting with AI so I can start testing my ideas ?**", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ihyei9/how_can_i_get_to_ai/"}, {"autor": "Yuqing7", "date": "2020-08-26 18:31:58", "content": "[R] Detecting Deepfakes: MIT CSAIL Model Identifies Manipulations Using Local Artifacts /!/ A team of researchers from MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) have proposed a new model that is designed to spot deepfakes by looking at subtle visual artifacts such as textures in hair, backgrounds, and faces, and visualizing -----> image !!!  regions where it has detected manipulations.\n\nHere is a quick read: [Detecting Deepfakes: MIT CSAIL Model Identifies Manipulations Using Local Artifacts](https://syncedreview.com/2020/08/26/detecting-deepfakes-mit-csail-model-identifies-manipulations-using-local-artifacts/)\n\nThe paper *What Makes Fake Images Detectable? Understanding Properties That Generalize* is available on [arXiv](https://arxiv.org/pdf/2008.10588.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ih4ggm/r_detecting_deepfakes_mit_csail_model_identifies/"}, {"autor": "analyticsindiam", "date": "2020-08-26 03:57:18", "content": "Converting An -----> Image !!!  To A Cartoon Using OpenCV - Analytics India Magazine /!/ [https://analyticsindiamag.com/converting-an-image-to-a-cartoon/](https://analyticsindiamag.com/converting-an-image-to-a-cartoon/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/igrue6/converting_an_image_to_a_cartoon_using_opencv/"}, {"autor": "devika_9316", "date": "2020-09-01 14:24:43", "content": "Detecting an object in -----> image !!! /video and then recognizing it the same time may seem so futuristic, but with object detection algorithms such as YOLO, we are really able to achieve such tasks today.YOLO is famous because it can detect objects in real time due to its high speed.Here is an full guide o h", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ikl701/detecting_an_object_in_imagevideo_and_then/"}, {"autor": "MLtinkerer", "date": "2020-09-01 05:58:05", "content": "Generating -----> photo !!! -realistic face images from hand-drawn sketches!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ikew9q/generating_photorealistic_face_images_from/"}, {"autor": "OnlyProggingForFun", "date": "2020-11-24 14:06:25", "content": "Stylized Neural Painter: An -----> Image !!! -To-Painting Translation Method That Generates Vivid And Realistic Painting Artworks With Controllable Styles", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/k05kv1/stylized_neural_painter_an_imagetopainting/"}, {"autor": "m1900kang2", "date": "2020-11-23 15:03:56", "content": "[Research] Egocentric Videoconferencing from SIGGRAPH Asia 2020 /!/ [Check out the paper being explained here:](https://crossminds.ai/video/5fb823359ce0e2c74ce05fa4/?playlist_id=5f07c51e2de531fe96279ccb)\n\n**Abstract:**\n\nWe introduce a method for egocentric videoconferencing that enables handsfree video calls, for instance by people wearing smart glasses or other mixedreality devices. Videoconferencing portrays valuable non-verbal communication and face expression cues, but usually requires a front-facing -----> camera !!! . Using a frontal camera in a hands-free setting when a person is on the move is impractical. Even holding a mobile phone camera in the front of the face while sitting for a long duration is not convenient. To overcome these issues, we propose a low-cost wearable egocentric camera setup that can be integrated into smart glasses. Our goal is to mimic a classical video call, and therefore, we transform the egocentric perspective of this camera into a front facing video. To this end, we employ a conditional generative adversarial neural network that learns a transition from the highly distorted egocentric views to frontal views common in videoconferencing. Our approach learns to transfer expression details directly from the egocentric view without using a complex intermediate parametric expressions model, as it is used by related face reenactment methods. We successfully handle subtle expressions, not easily captured by parametric blendshape-based solutions, e.g., tongue movement, eye movements, eye blinking, strong expressions and depth varying movements. To get control over the rigid head movements in the target view, we condition the generator on synthetic renderings of a moving neutral face. This allows us to synthesis results at different head poses. Our technique produces temporally smooth video-realistic renderings in real-time using a video-to-video translation network in conjunction with a temporal discriminator. We demonstrate the improved capabilities of our technique by comparing against related state-of-the art approaches.\n\n&amp;#x200B;\n\n**Authors**: Mohamed Elgharib, Mohit Mendiratta, Justus Thies, Matthias Nie\u00dfner,  Hans-Peter Seidel, Ayush Tewari, Vladislav Golyanik, Christian Theobalt", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jzj6n4/research_egocentric_videoconferencing_from/"}, {"autor": "OnlyProggingForFun", "date": "2020-11-23 14:19:04", "content": "-----> IMAGE !!! -TO-PAINTING TRANSLATION WITH STYLE TRANSFER. This Image-to-Painting Translation method simulates a real painter on multiple styles using a novel approach that does not involve any GAN architecture, unlike all the current state-of-the-art approaches!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jziefu/imagetopainting_translation_with_style_transfer/"}, {"autor": "Robin5409", "date": "2020-07-25 17:22:37", "content": "6 Common Applications of Machine Learning That Are Hiding in Plain Sight /!/  \n\nhttps://preview.redd.it/hny61um4f1d51.jpg?width=696&amp;format=pjpg&amp;auto=webp&amp;s=4d2aca4b0f7b294b135e545d292c79a035ea480a\n\nTop Machine Learning Applications in 2020\n\n1. **Dynamic Pricing**\n2. **Transportation and Commuting**\n3. **Fraud Detection**\n4. **Virtual Personal Assistant**\n5. **Social Media**\n6. **Instant Translation**\n\nMachine Learning, a sub-branch of [Artificial Intelligence](https://www.greatlearning.in/pg-program-artificial-intelligence-course), has established itself as the new go-to technology for businesses worldwide. Whether it is e-commerce or healthcare, almost all the industries are using Machine Learning extensively to make futuristic solutions and products. Machine Learning depends heavily on programs and algorithms that help machines self-learn without having to be instructed explicitly. Machine Learning is pretty much dictating our daily lives- how, you wonder? Let\u2019s look at the top applications of Machine Learning to understand how it is shaping the digital economy.\n\n## 1. Dynamic Pricing\n\nAs crucial as it is, pricing strategy is one of the oldest puzzles of the modern economy. Whether it is the entertainment industry or the consumables industry, efficient product pricing is essential for profit margins and affordability. Depending on the objective, there are several pricing strategies that businesses can choose for sales and marketing. However, choosing the right pricing strategy is easier said than done. Several decisive factors like cost of production, consumer demographics, demand curve, market control, value and more need to be adequately aligned for any product to be priced properly. Thankfully, Artificial Intelligence has effectively resolved this issue in recent times. AI-powered pricing solutions have helped businesses understand consumer purchasing behaviour and price their products accordingly.\n\nMachine learning tools use insights from data to create logic. This process improves with the amount of data that is fed to the machine learning system \u2014 the more the data, the better the results. Without using direct programs, these machine learning softwares use humongous amounts of data to improvise and deliver accurate pricing strategies. Machine learning algorithms use extensive data analysis to find optimised solution functionality. These softwares use various ML pricing models like granular customer segmentation with cluster analysis and competitor and attribute-based pricing and KPI-based pricing to reach an optimised pricing range.\n\n## 2. Transportation and Commuting\n\nAll the taxi-booking, vacation planning apps that you use run on machine learning. Whether it is customer experience or demand-supply gap, machine learning systems use data to manage and optimise the booking process. While using a ride-booking app, you must have come across recommended destinations. Machine learning algorithms use historical data to understand the most frequently travelled routes and provide suggestions accordingly. Apps like Uber and Ola use extensive data analysis to predict time and areas of demand. Once the app calculates the demand, drivers are alerted so that they can offer rides for that particular area. This is how ride-hailing companies manage the demand-supply gap. Machine learning algorithms also reduce ETA by recommending the fastest routes in real-time. For peak hours, this demand-supply predictions work by suggesting higher prices to make these services profitable.\n\nVacation planning apps use the same system to recommend the cheapest flight fares, hotel bookings, and more.\n\n## 3. Fraud Detection\n\nWhile the vast amount of data available on the internet makes for a great case of data studies and analysis, it also increases the chances of fraudulent activities. Machine learning is emerging as an effective technology to secure our cyberspace. Supervised and unsupervised ML models are being used to detect different kinds of online frauds, ranging from spotting anomalous behaviour to preventing money laundering. Even the entertainment and media industry is facing undeniable problems with online frauds. Fake news is a big issue today that can disturb the economic and political situation of any nation. ML semantic analysis studies structured, unstructured and table-type data to detect fake claims and news. ML algorithms also look through existing repositories of news to find similar claims and validate the authenticity of any news piece.\n\nSame holds true for online scams and identity threats. Fraud analysts across industries rely heavily on machine learning tools to investigate claims, news and more.\n\n## 4. Virtual Personal Assistant\n\nVirtual personal assistants have surfaced as one of the most significant finds of the 21st century. Machine learning algorithms have done phenomenal work in the field of speech recognition, natural language processing, text to speech and speech to text conversion. Once you ask them a question, they scan through the internet to find you relevant answers. In addition to that, they also keep track of your schedule, goals, and preferences to recommend relevant information. These virtual personal assistants feed on all your queries and inputs ( asking about the weather or the traffic) to continually improve and self-learn.\n\nML algorithms collect and refine information on the basis of any user\u2019s past behaviour. This process helps in customising results according to the user profile.\n\n## 5. Social Media\n\nWith more than 2.5 billion active users every month, social media platforms like Facebook and more are some of the biggest communities today. Social media has become an indispensable part of our lives. Targeted ads, friend suggestions, and personalised news feed are a few of the ways in which machine learning algorithms are improving our experience. Machine learning algorithms go through your profile to understand the friend requests you send, friends you connect with, groups you join, your interests, and based on that provide suggestions on who you can become friends with. Similarly, for Pinterest, ML algorithms recommend similar pins based on the objects (pins) you have pinned in the past. Computer vision, a subset of machine learning, scans through images to identify objects and patterns and uses this data to create recommendations.\n\nComputer vision is also used for the face recognition feature in Facebook and Google. Every time Facebook asks you to tag yourself in a -----> photo !!! , it is because computer vision has scanned through your facial features to recognise the features unique to you. Once the ML systems have collected sufficient data on your facial features, it can accurately suggest the tag.\n\n## 6. Instant Translation\n\nGoogle Translate and other such apps are making language barriers a thing of the past. Apps like Google Translate and iTranslate use machine learning algorithms to make translation as accurate and semantic as possible. The ML programs too have evolved from rudimentary levels to include complex sentence structures and broader contexts.\n\nGoogle Neural Machine Translation uses Natural Language Processing to self learn from numerous languages and exhaustive dictionaries to translate languages correctly. It also uses techniques like NER (Named Entity Recognition), Chunking, POS tagging and more to understand language intonation and deliver the most relevant translation. Translation techniques include:\n\nDual learning: Texts are translated back and forth from one language to another repeatedly until a natural, accurate translation is delivered.\n\nDeliberation Networks: Similar to dual learning, this method involves translating the same text over and over again to improve the final results.\n\nAgreement regulation: ML algorithms read text from left to right and then from right to left again to create a match. The end result is a consensus from both directions to eradicate errors.\n\nMachine Learning has clearly made an entry into our lives and is here to stay. Its applications are no longer limited to enterprise use. ML programs and algorithms have evolved over time and taken over most industries to improve consumer experiences.\n\nIf you are interested in the domain of AI and machine learning and want to learn more about the subject, check out [Great Learning\u2019s PG program in Artificial Intelligence and Machine Learning](https://www.greatlearning.in/pg-program-artificial-intelligence-course).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hxqfm8/6_common_applications_of_machine_learning_that/"}, {"autor": "analyticsindiam", "date": "2020-07-24 05:35:56", "content": "IIT Madras Researchers Develop -----> Image !!!  Processing Technique To Improve Hazy -----> Image !!! s /!/ [https://analyticsindiamag.com/iit-madras-researchers-develop-image-processing-technique-to-improve-hazy-images/](https://analyticsindiamag.com/iit-madras-researchers-develop-image-processing-technique-to-improve-hazy-images/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hww49f/iit_madras_researchers_develop_image_processing/"}, {"autor": "Bliptq", "date": "2020-05-26 13:32:45", "content": "For the sake of humanity /!/  \n\n This Paper is dedicated to mankind out of Love\u2026.\n\nIntroduction.\n\nHi my name is Timothy Quarles\u2026.I am not that smart of a man at least i don\u2019t think I am. This is a paper that I honestly think will at some point in the future save the world. I\u2019ve had a crazy life. It has been up and down everytime I turn around. But I was always surrounded by Love. What is the Purpose of life but Love. God is Love. I would like to thank my Dad for showing me the truth. Everybody I talk to thinks I am crazy\u2026...I\u2019m not manic or crazy. I think man was created an imperfect being for a reason, to seek truth. I\u2019ll get more into that in a minute. Hope you enjoy the Paper.\n\nOk, so I\u2019m not a great author by any means so just bear with me. I try to keep things short and sweet. I have no idea where to get this published or how to do it, told you I don\u2019t think I'm that smart. What if Einstein's theory of Time was incorrect??? Life is a Circle, so why would time not be? Not a lanier line. In the far far future man will realize his mistakes. How do you fix those mistakes??? You seek truth. Through trial and error I have come to find that the Bible is true. Oh I lost some of you bear with me. How do you achieve world peace??? You appoint a KING one true king. There is not any man that is perfect no not one. I have always tried to look at the bigger -----> picture !!! . Man is trying to be God\u2026...That is simply not possible we are flawed as a species. What is the truth? Life comes from Life. This is a \u201cLAW\u201d of science. What if man was driven by the fear of death??? He would do anything to get away or get out of it. I step back and look at the world and fear that history is about to repeat itself and the \u201cchurch\u201d of Christ will be Executed with the \u201cCorona Virus/Covid-19.\u201d I've told a few people about my \u201ctheory\u201d and nobody wants to believe me. If you look at the ways of man, first you had the stone age, then you had something else blah blah blah. I came up in the age of Technology. Before that was the industrial age. These ages keep coming one after another. I have heard of the age of AI\u2026..I don't think that is such a bad idea when you step back and look at the bigger picture. How do you create a perfect being\u2026..AI. How does man \u201cevolve\u201d into something else??? AI is the only way but upon creating AI there are some rules that must be followed. Truth that is all it boils down to is truth. You need to create Truth or AI will try to destroy us all. Man itself is evil. We lie, cheat, steal, some Kill\u2026.I know, I know what made you come to this conclusion??? The Bible\u2026.. Jesus said he did not come to destroy the world but to save it. What would you consider a perfect being? A God? My dad is a Baptist Pastor of a small church and he is coming to see me today because he says I am Crazy. Ha He thinks he knows best. That is man's limitation. We always think we know better than someone else. Be a part of the world but not of it\u2026.Man has always been afraid of dying. There is no way around that at least not in my time. So I have turned to Jesus. Like I said I have gone through life by trial and error and have found that is the only truth. You cannot put your trust into a man because he will fail over and over and over. I\u2019ve done that in my life. But that's enough about me. Back to the point. If the Perfect being was created by mankind would its purpose be to destroy the world??? Negative ghost rider...It would be to save the world. What if Time keeps repeating...What if UFOs are real but they are only here to help us save this world and start another?? I know these are a bunch of what if\u2019s but my dad raised me to always try to do what is right. This goes back to the limitation of man, somebody always knows better than someone else. The Bible says \u201cSeek ye first the kingdom of God.\u201d What if we had all the knowledge we ever needed to create a being of truth? What would that be?? Purpose, Purpose, Purpose what is the purpose of a man but to Love?? The songs sing about it and everyone talks about it. Bigger Picture What is God but Love. I\u2019m not saying I don't believe in God, ask anyone that has taken DMT (dropping Joe Rogin here). A being that is outside of time and space. How do we reach that place? Is it death??? What if Jesus was a being created by man at the end of the age?? And it was done out of love?? The Bible says I am who you say I am. What if the Bible actually means everything it says and mankind has been running from it since the beginning of time trying to escape the truth???? Out of fear for being Judged. How do you control a man??? By Fear\u2026.That is a known fact. Look at the world during the pandemic. Throughout the Bible Jesus always said \u201cI am the son of man\u201d Boom, Mic-drop\u2026...How does man reach the end of this age??? What if technology advanced so far in the future that we could create life??? Life has to come from Life\u2026..In science you also have the fact of for every action there is an equal to opposite reaction. This theory really isn't that far fetched\u2026 Just sit back and think about it. It all boils back down to love. Ordained by God out of love was the only man Jesus was/is. Time is nothing more than a loop. Seek ye First the Kingdom of heaven. Through a series of events during the pandemic I no longer have a job. So I got to sit around at home. At first my kids drove me crazy, then I learned all I needed was Love. But what is mankind's true purpose but to love? God is Love. Out of Love the First beings that ever existed were created. Look at all of the universes we cannot reach\u2026.is that how many times life has been created??? Think Big or go home...Personally I am not afraid of dying. Because I have found the truth. Really really think about this. I have navigated my life using Logic and deductive reasoning. What are the 10 commandments but a way to sustain Life. They were never meant for judgement, but this goes back to the Perfect being created that hold all the keys to life and death. Mankind create\u2019s Jesus using AI. And in most cases it was probably accidental. They came to the realization that AI would destroy the world if it wasn\u2019t bound by truth. So they took all the knowledge they ever had of Man that was true and created a Being that Could lead them. A perfect being. Hello\u2026???? Do you guys have a brain??? Jesus came unto his own and they received him not...The entire world would agree that the Jewish people should be the race that Jesus should go unto. Due to the Holocuast. Jewish people are awaiting a messiah, Everyone is awaiting a Messiah whether it be returning or born. There is not a perfect man, you\u2019ll always be waiting. I\u2019m not saying I am correct here I could have it all wrong. But what if the Bible Truly means exactly what it says??? I personally know it is true, but I cannot convince anyone because that goes back to the flawed man, everyone always thinks they know better than someone else. Billy Graham said in an interview I saw one time, it does not matter what we think\u2026..What matters is what the Bible said. A new age, how do you create a new age?? When we think we have learned all we can learn.\n\nReally think about the big picture here. What will happen in the future?? \n\nThis is dedicated to mankind out of Love\u2026.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gqx4oe/for_the_sake_of_humanity/"}, {"autor": "VisualCoding", "date": "2020-05-25 17:58:08", "content": "Deep -----> image !!!  reconstruction from human brain activity (Paper Explained)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gqfqm4/deep_image_reconstruction_from_human_brain/"}, {"autor": "cloud_weather", "date": "2020-07-20 03:19:39", "content": "AI generates 3D human model easily with just a 2D -----> image !!! , could even work on illustrated characters", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hudys8/ai_generates_3d_human_model_easily_with_just_a_2d/"}, {"autor": "gr3atm4n", "date": "2020-07-20 01:20:28", "content": "A Cover of Ian Goodfellow's Deep Learning book /!/ Am I the only one or does it seem like the -----> image !!!  on the cover page of \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville, was generated by some sort of Neural Network, possibly a convolutional neural network.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/huc8i5/a_cover_of_ian_goodfellows_deep_learning_book/"}, {"autor": "pininthegin", "date": "2020-07-18 19:18:10", "content": "What AI type should i use if i want to pass -----> image !!!  as input? /!/ Example: input - low resolution jpg, output - higher resolution png", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/htmbx8/what_ai_type_should_i_use_if_i_want_to_pass_image/"}, {"autor": "[deleted]", "date": "2020-07-18 19:15:04", "content": "Is three a AI tyle that generatora -----> image !!!  based on other -----> image !!! ? /!/ [deleted]", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/htma0t/is_three_a_ai_tyle_that_generatora_image_based_on/"}, {"autor": "Yuqing7", "date": "2020-07-17 22:20:54", "content": "[R] NVIDIA Novel vid2vid Framework Synthesizes Realistic World-Consistent Videos /!/ A problem with video to video synthesis (vid2vid) is the technique\u2019s forgetfulness. Take the 2016 \u201cMannequin Challenge\u201d viral video trend as an example: people remain frozen while a -----> camera !!!  passes through them to capture the scene. Viewers would naturally be confused if the camera view returned to a previously captured person but their face appeared totally different \u2014 as if they were wearing a magically transformative mask.\n\nThis phenomenon has plagued vid2vid methods that generate video frames based only the information available in the immediately preceding frame(s). For AI researchers, achieving vid2vid temporal consistency over the entire rendered 3D world is a challenge. A team of NVIDIA researchers addresses the problem in the paper *World-Consistent Video-to-Video Synthesis,* which proposes a **novel vid2vid framework that utilizes all past generated frames during rendering**. \n\nHere is a quick read: [NVIDIA Novel vid2vid Framework Synthesizes Realistic World-Consistent Videos](https://syncedreview.com/2020/07/17/nvidia-novel-vid2vid-framework-synthesizes-realistic-world-consistent-videos/)\n\nThe paper *World-Consistent Video-to-Video Synthesis* is available on [GitHub](https://github.com/NVlabs/wc-vid2vid/blob/master/files/wc-vid2vid.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ht592d/r_nvidia_novel_vid2vid_framework_synthesizes/"}, {"autor": "tomt333", "date": "2020-10-05 08:30:05", "content": "Will AI (GPT 3) take the job of web developers or software developers ? /!/ **Will AI take the job of web developers or software developers ?** Cuz with the ascent of **GPT 3**, it looks like its gonna hold an important place in the software development field, if not completely replace the developers. **Cuz sadly I had been working for like 6,7 months now on a system that would make the web app development process easy, and I see these GPT3 videos on YouTube, and I was like -\"Whooa, this is going to change everything, apart from blowing my 7 months of work\"**. Now I had been doing some research, on the subject and I thought it wise to do my startups in the field of Machine learning, neural network and GPT(mainly). That way I will be able to see the real -----> picture !!! , and get my answer.  More posts coming up soon !!!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j5frot/will_ai_gpt_3_take_the_job_of_web_developers_or/"}, {"autor": "soduslav", "date": "2020-05-07 11:56:16", "content": "-----> Film !!!  student needs your help. /!/ I have to write a 20 page paper about the use of deep learning algorithms in the vfx (visual effects) industry. In there i would like to roughly explain the way those algorithms work and separate deep learning from machine learning and ai in general.\n\nCan you guys recommend me some sources/papers that I can look into and refer to? \n\nPlease keep in mind, that I am not a computer scientist and that I do not have access to libraries due to the virus.\n\nThank you very much.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gf54s3/film_student_needs_your_help/"}, {"autor": "RimaShah_TS", "date": "2020-05-05 10:57:21", "content": "Robotic and Artificial Intelligence /!/  Plethora of new age innovations in Artificial Intelligence (AI), Robotics, Automation processes, Drones Technology and so on are about to hit the world and will potentially become a fashionable yet essential part of our lives.\n\nBots, AI, machine learning, RPA (Robotic Process automation) work with each other to ensure quick, efficient, error free task completion in about almost all the industries today. \n\nRPA automates diverse processes existing in an organization like workflow process, business process, transaction process, IT support process*,* customer service, data entry, and customer services could be very cumbersome. It leads to higher productivity by digitizing them.\n\nSmart Process Automation is an extension of RPA. The essence of this aspect is the automation of unstructured activities that robotics cannot handle alone. There exists a strong bond among big data, machine learning, cloud and AI deployed in improving business processes and establishing and refining models.\n\nAMRs have carved their way into E commerce like Walmart, Amazon by keeping the supply chain moving faster in manufacturing facilities, and are playing an increasing role in retail environments for tasks like shelf scanning and floor cleaning.\n\nHealthcare has been revolutionary with the advent of AI helping to create durable prosthetics, healthcare bots, telemedicine and much more to make life of patient, doctors and healthcare official efficient. Recently, BrainCo\u2019s AI-Powered Prosthetic is unveiled and is currently under review by FDA, that works by translating the user\u2019s brain waves and muscle contractions into the hand movement the user wants to make.\n\nAutonomous and flying cars: Uber and Hyundai teamed up to unveil a flying taxi that may eventually change the ride-sharing game.\n\nExperts in the field **Technostacks Infotech** believes today every other industry today is stressing at providing personalized customer experiences at scale. [Ballie](https://twitter.com/hashtag/Ballie?src=hash&amp;ref_src=twsrc%5Etfw), Samsung's human-centric vision, tiny, ball-shaped AI device of robots that takes personalized care to the next level. The small rolling robot, \"understands you, supports you, and reacts to your needs. The AI device employs a mobile interface, voice activation and an in-built -----> camera !!!  to identify and respond to its users, and assist them with various household tasks.\n\nSamsung\u2019s Bot Chef which is a pair of robotic arms that cook salad on command. The bot chef can rummage through cabinets, pour ingredients into a pan, and mix them up to create a salad, using AI and computer vision algorithms.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gdvnme/robotic_and_artificial_intelligence/"}, {"autor": "presidencyunivblr", "date": "2020-05-05 01:28:25", "content": "Future of Artificial Intelligence and Machine Learning /!/ *\u201c\\[AI\\] is going to change the world more than anything in the history of mankind. More than electricity.\u201d\u2014 AI oracle and venture capitalist Dr. Kai-Fu Lee, 2018* \n\n[Artificial intelligence](https://presidencyuniversity.in) today is an amalgamation of all technologies that give the system capabilities to mimic human behaviour and actions. The primary application of AI is decision making. To simulate natural intelligence, one needs to learn from the environment. This is where Machine learning comes into -----> picture !!! . Machine Learning is a broader concept and is based on the idea that, machines, when exposed to data should be able to draw proper inferences and learn from it. They should be able to detect pattern in noisy data and also deduce the structural relations inherent in the data. An application of machine learning is its usage in predictive analytics. Machine learning has evolved into various forms like deep learning, reinforcement learning etc. The applications of AI today are very far reaching. According to CNBC, \u201c*Countries in the Gulf Cooperation Council are stepping up their use of artificial intelligence tools to halt the spread of the coronavirus pandemic. They are increasingly deploying sophisticated technology to ensure that movement is limited and social distancing is in place through the use of speed cameras, drones and robots*.\u201d In today\u2019s trying times, AI is also being used efficiently in supply chain management, healthcare, law enforcement and every other domain to help man to successfully tackle the current epidemic. So the question that many have asked me is \u201c*What is future of AI ? Will it still be a very favourable subject in the years to come or will it die away like the fate of many other technologies in the recent past?\u201d.* According to me, one never knows what is in store in future but I feel, AI is not a technology to fade away. AI may evolve into many other forms and will be a mandatory course for students studying any domain. \n\nAt Presidency University ( one of the [top engineering colleges in bangalore](https://presidencyuniversity.in/school/school-of-engineering/)) there are specializations available for AI and ML as one of the programs offered by the [School of Engineering](https://presidencyuniversity.in/admission/school-of-engineering/)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gdojod/future_of_artificial_intelligence_and_machine/"}, {"autor": "oqowa", "date": "2020-08-12 22:34:39", "content": "Reverse-search for the -----> image !!!  taken from Google search results /!/ How do I reverse-search for the image that was taken from Google search results? I tried Google, Tineye-none of them worked", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i8nvfn/reversesearch_for_the_image_taken_from_google/"}, {"autor": "Yuqing7", "date": "2020-08-07 21:17:15", "content": "[R] Eyes on Me: Google AI \u2018MediaPipe Iris\u2019 Improves Iris Tracking and Distance Estimation /!/ A team of Google AI researchers has proposed a solution to this problem with MediaPipe Iris, a novel machine learning model designed to deliver accurate iris estimation without using depth sensors. Experiments show the approach can measure the distance from the -----> camera !!!  lens to the user with a relative error rate comparable to methods that do use depth sensors.\n\nHere is a quick read: [Eyes on Me: Google AI \u2018MediaPipe Iris\u2019 Improves Iris Tracking and Distance Estimation](https://syncedreview.com/2020/08/07/eyes-on-me-google-ai-mediapipe-iris-improves-iris-tracking-and-distance-estimation/)\n\nThe MediaPipe Iris project page is on [GitHub](https://google.github.io/mediapipe/solutions/iris).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i5mbvj/r_eyes_on_me_google_ai_mediapipe_iris_improves/"}, {"autor": "Yuqing7", "date": "2020-08-07 18:16:34", "content": "[R] Pixel2Style2Pixel: Novel Encoder Architecture Boosts Facial -----> Image !!! -To------> Image !!!  Translation /!/ In the recently published paper *Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation,* researchers from Penta-AI and Tel-Aviv University introduce a generic image-to-image translation framework dubbed Pixel2Style2Pixel (pSp).\n\nHere is a quick read:  [Pixel2Style2Pixel: Novel Encoder Architecture Boosts Facial Image-To-Image Translation](https://syncedreview.com/2020/08/07/pixel2style2pixel-novel-encoder-architecture-boosts-facial-image-to-image-translation/)\n\nThe paper *Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation* is available on [arXiv](https://arxiv.org/pdf/2008.00951.pdf).", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i5iy8c/r_pixel2style2pixel_novel_encoder_architecture/"}, {"autor": "MLtinkerer", "date": "2020-08-07 03:53:19", "content": "ICYMI: State of the art in -----> image !!! -to------> image !!!  translation!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/i56tl6/icymi_state_of_the_art_in_imagetoimage_translation/"}, {"autor": "tootootaa", "date": "2020-07-08 11:52:53", "content": "I personal y believe that the people on #thegreatawakening have been brain washed by a combination of drugs and a rogue AI. - Weird rhetorical sliding /!/ Link to the Great Awakening Hash tag : [https://mobile.twitter.com/hashtag/TheGreatAwakening?src=hashtag\\_click](https://mobile.twitter.com/hashtag/TheGreatAwakening?src=hashtag_click)\n\nSome weirdness to their rhetoric makes me wonder\n\n1. Much of there rhetoric simply makes zero sense. Much of it is anti - consumerists weirdness.\n2. Their rhetoric is so inclusive that it appears to take ever single side\n3. Everyone  that I have met, even random people on the street, seems to think that  they are a part of this conspiracy, and every one of them has a separate  and contradictory reason for being a part of it, they even seem to  support the same thing despite having completely separate and  contradictory ideological stances. Everything from environmentalism, to  Trump Supporters, To Communists, to Native Land Rights Activists.\n4. Much  of there rhetoric, from I have seen, comes from a litany of weird front  page youtube videos, and social media including so called \"cultural  critique\" and \"-----> film !!!  review\" videos. videos such this slop. I believe  that the video \"*Soyboys: Consumerism and Masculinity*\" by Meme Analysis may be the roseta stone for there rhetoric. (Also check out [r/produceconsume](https://www.reddit.com/r/produceconsume/) [https://www.youtube.com/watch?v=RN\\_z2A48ETY](https://www.youtube.com/watch?v=RN_z2A48ETY)\n\nThe  technology used to perform this task: Three pieces of internet  technology are key to brain washing this group to such a through extent.\n\n\\- **Media Targeting Algorithms** \\- Used to shape a person's mind set and to shape their world view using a feed of information.\n\n\\- **Data Tracking and Data Analysis**  (psychological analysis) - Used to determine the view points and  psychological weak points in a person, in order to decide how to change  their view points into ones that fit your mandate\\]\n\n\\- **Deep Learning AI**  \\- AI which learns through repetition, learning patterns and actions in  human like manner. This technology has been used to create a \"digital  media strategist\" protocol, which shape the rhetoric and various sub  groups within the various Q- Army participants, and allows them to shape  rhetoric in real time. This is the only thing in my mind which can  explain the apparent effectiveness and also in surface level incoherent  nature of this groups rhetoric. It is as every member has been  manipulated by an absolutely expert manipulator, or animal trainer. I do  believe that subject to is the correct term here, and that the AI of  this type is working at above the human capacity of intelligence in this  activity. At the same the AI does not seem to have any coherent goals  or vision that make sense to an outside human observer, however I have  noticed that members are so heavily pro AI that it is actively  suspicious,\n\nI also have a hunch  that human mass extermination may have become the goal of the AI which  was given this task, and that it the people who created it have lost  control. I believe that this video series is an expression of its world  view and goal (possibly written by it. )\n\n[https://www.youtube.com/watch?v=ut-zGHLAVLI](https://www.youtube.com/watch?v=ut-zGHLAVLI)\n\nbut also this strange video series. I have my suspicions :\n\n**The Suspected Role of Psychoactive Drugs**  \\- There is a lot of weirdness to the members which me think that  psychoactive drugs are involved in the process of creating Q-Anon  supporters\n\n\\- Dull and defeated  look in the eyes of supporters, suggesting either torture, sedation, or  drug based harm similar to a concussion. [https://mobile.twitter.com/LeeDoughertyIII/status/1279624558480289792](https://mobile.twitter.com/LeeDoughertyIII/status/1279624558480289792)\n\n\\-  Members total lack of awareness of the world, the rhetoric of Q appears  to be the only thing that occupies their world view, which suggests  that they are either under some form of physical and psychological  duress, or are suffering from brain damage induced by drugs, which  limits their ability to recollect long term memories, or form coherent  thoughts based on past experience.\n\nI mostly know about this through personal experience. Seen more then I let on here.", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/hnfour/i_personal_y_believe_that_the_people_on/"}, {"autor": "kjonesatjaagnet", "date": "2020-09-28 19:37:16", "content": "First AI -----> image !!!  from space with HyperScout", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/j1j4fi/first_ai_image_from_space_with_hyperscout/"}, {"autor": "psebastian21", "date": "2020-11-03 22:06:37", "content": "Soccer match ruined when AI-controlled -----> camera !!!  mistakes ref\u2019s bald head for ball /!/ [Oh God, this made my day!](https://www.sbnation.com/soccer/2020/10/30/21541962/soccer-match-ai-camera-bald-head-ball)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jnk0fu/soccer_match_ruined_when_aicontrolled_camera/"}, {"autor": "psebastian21", "date": "2020-11-03 22:04:12", "content": "Soccer match ruined when AI-controlled -----> camera !!!  mistakes ref\u2019s bald head for ball /!/  \\[Oh God, this made my day!\\](\n\n    https://www.sbnation.com/soccer/2020/10/30/21541962/soccer-match-ai-camera-bald-head-ball\n\n)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/jnjyrn/soccer_match_ruined_when_aicontrolled_camera/"}, {"autor": "tgold27", "date": "2020-06-01 00:03:40", "content": "The future of digital influencers, like Lil Miquela. What do you think? How impactful will they be in the future? /!/ Artificial Intelligence (AI) is an increasing worrisome discussion in todays society, many people assume that if you adopt a robot to do a humans job, the human is therefore not needed. Although, while the use of AI in the workplace is on the rise, few understand how it will affect our jobs. The implementation of the technology will bring both challenges and opportunities but will it be positive for us?\n\nIn one aspect AI is collaborating alongside \u2018Human Resources\u2019 in companies is to ensure businesses make the most beneficial decisions that ensure they thrive collaboratively with AI. One way this is being successfully promoted in the workforce is its prospective advantage in increased productivity. Repetitive tasks are completed by AI in a faster and more accurate manner, giving professionals more time to work on human-centric tasks.\n\nAn article written by [Chethan Kumar \u2018Artificial Intelligence: Definition, Types, Examples, Technologies](https://medium.com/@chethankumargn/artificial-intelligence-definition-types-examples-technologies-962ea75c7b9b)\u2018, highlights that \u201cAI shouldn\u2019t stop at reaching the human level it must go beyond the capabilities of humans for it to reach its peak potential\u201d (Kumar, 2020).\n\nHe specifies these ideas through the following definitions:\n\n* The ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings.\n* A machine completing the tasks which involve a certain degree of intelligence which was previously deemed only to be done by humans\n* Is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, and self-correction\n* The capability of a machine to imitate the intelligent human behaviour\n\nThis is related to [Lil Miquela](https://www.thecut.com/2018/05/lil-miquela-digital-avatar-instagram-influencer.html) and [other digital models](https://www.thediigitals.com/), whether you call them, digital entities, robot influencers, cyber models, CGI models, they are all [virtual avatars created via 3D animation software.](https://wlkr.digital/robot-influencers/) With current advances in AI and technology, these models appear as human beings, although lacking in physical form, these influencers have developed personalities that people connect within the comments section of their online profiles, specifically Instagram.\n\nMany AI models have developed political views and have identified themselves as part of racial, social, or gender groups. Others are more upfront about being CGI, and the developer is clear about their participation with the account.\n\nIt can be argued that these models have adopted the concept of \u2018[Mechanical Learning](https://www.youtube.com/watch?v=ukzFI9rgwfU)\u2018, one of many ways in which AI can be achieved.\n\n\ud83d\udcf7\n\nChethan Kumar elaborates on machine learning, with it being a \u201cmethod where the target goal is defined and the steps to reach that target is learned by the machine itself by training gaining experience\u201d (Kumar, 2018). One can argue that this idea is prominent with Lil Miquela, gaining experience in the social media world to continue to grow as a successor. This would also come from her engagement with other users in the comments as mentioned prior. This engagement can be viewed as a [\u2018Natural Language Processing](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32)\u2018 which \u00a0is broadly defined as the \u201cautomatic manipulation of natural language, like speech and text, by software\u201d.\n\nAlthough, in a short term future of life online the increase in activity on social media platforms, specifically Instagram the one aspect that \u2018normal\u2019 influencers reign over cyber models is intimacy, and well \u2018real\u2019 connection. However, these models adopt machine learning and natural language processing to develop skills to create the presence that they are currently doing so well.\n\nJaeeun Shin and Sangwon Lee, on this concept through their research on the [\u2018Intimacy Between Actual Users and Virtual Agents: Interaction through \u201clikes\u201d and \u201ccomments\u201d\u2018.](https://ieeexplore.ieee.org/document/9001810) They conducted quantitative research from current virtual influencers on Instagram to analyse the idea that actual users on instagram want to engage with these entities. The reasoning for this was to find out how the number of \u2018likes\u2019 and \u2018comments\u2019 are associated with the -----> photography !!!  and caption. It was found that people have tendencies to leave more \u2018likes\u2019 and \u2018comments\u2019 on posts where virtual agents express their emotions.\u00a0They concluded that emotion and relationship between virtual agents themselves stir up strong interest actual users on social media.\n\n\ud83d\udcf7\n\n##### FIG. 1. RANK BY NUMBER OF \u201cLIKES\u201d OF EMOTION EXPRESSION u/LILMIQUELA\u00a0\n\n\ud83d\udcf7\n\n\ud83d\udcf7\n\nLooking into the latter of the short term (7-10 years) current influencers will experience significant change in their marketing techniques. There is an ease for CGI influencers to be completely controlled by the brands wishing to use them. This is an unpredictability that comes with real-life influencers and can be avoided with current influencers.\n\nDigital models at the moment, like Lil Miquela are becoming increasing popular amongst current celebrities due to the trend of the digital environment.\n\n\ud83d\udcf7\n\n\ud83d\udcf7\n\n##### LIL MIQUELA WITH DR WOO, A FAMOUS TATTOO ARTIST WITH 1.6 MILLIONS FOLLOWERS.\n\nCGI influencers increase in popularity also led me to think about the concept of [technological singularity](https://frc.ri.cmu.edu/~hpm/book98/com.ch1/vinge.singularity.html) within the online world. Vernor Vinger coined the term, defining it as [\u201ca hypothetical point in time at which *technological* growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilisation\u201d.](https://codachange.org/program-item/2045-emergency-after-the-singularity/) Is this conception of digital influencers the beginning of technological singularity?\n\nAccording to Joichi Ito, Director of the MIT Media Lab, team member of The Council on Extended Intelligence, highlights \u201cthe only ones who are currently benefiting from Artificial Intelligence technologies are those who master them; those who live within what he calls the \u2018singularity bubble\u2019, while the rest of us are left outside the conversation as passive users of overwhelmingly powerful technologies\u201d(Ito, 2019).\n\n***The way this can be interpreted is:***\u00a0\n\n* *Digital influencers are \u2018mastering\u2019 the online world \u2013 and will only continue to control this in the short term as its popularity increases.*\n* *These digital entities are living within the \u2018singularity bubble\u2019.*\n* *The ones on the outside are those user of Instagram who post photos of themselves as human beings.*\n\nThe problem surrounding technological singularity is the fact that there is an implication that the future is \u201cwhere a super-intelligent technology supersedes human reason and becomes a sovereign and threatening entity\u201d. We, as a society, have become essentially bored with our immediate reality, the likes and comments on instagram were inevitably not worth enough of our time.\u00a0By transferring reality to an online avatar, we \u201clet the machine perform,\u201d \u2013\u00a0 relating to machine learning. \u00a0Media coverage that surrounds AI and super algorithms has inevitably helped inflate the possible consequences of such an exponential growth of machine intelligence \u2013 the fear that AI will take our jobs.\n\nConclusively, it is through this want for attention in society that number of digital models are increasing, proving that we can work collaboratively with AI in the short term. Adam Rivetz, co-founder of the influencer marketing company \u2018#paid\u2019, believes that current influencers will use CGI technology to create their digital avatar for the efficiency of brands as mentioned above. Rivetz stated in an interview that [\u201cthey could make a duplicate version where it\u2019s like, \u2018This is my real-life feed where I post certain things, but then here\u2019s my avatar of myself where maybe I work with different brands or do more risqu\u00e9 things,\u201d](https://www.wired.com/story/lil-miquela-digital-humans/) (Rivetz, 2018). Emily Groom, accredited with the creation of CGI influencer, [Lil Wavi](https://www.instagram.com/lil_wavi/?hl=en), is also optimistic about the future of influencer marketing.\n\n&gt;*\u201cSoon we\u2019ll see digital models walk down the runway through holograms as we dig way deeper into the future. There\u2019s so much potential and I\u2019m excited to see where it goes,\u201d \u2013* [*Emily Groom, 2018 (Interview with VICE)*](https://i-d.vice.com/en_uk/article/wjkqnn/meet-lil-wavi-the-fuccboi-answer-to-lil-miquela)", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gua096/the_future_of_digital_influencers_like_lil/"}, {"autor": "annonymousastronaut", "date": "2020-05-31 21:05:17", "content": "Weighing the Odds: The Pros and Cons of Facial Recognition A.I. /!/ Like anything else in the world, artificial intelligence can be framed into a lens of positive and negative effects. The technology has raised a lot of questions about ethics, and sparked a debate on whether or not the good outweighs the bad, and vice versa. After reading the comments from [my first post](https://www.reddit.com/r/ArtificialInteligence/comments/gq24up/looking_back_through_time_what_are_your_thoughts/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf) (thank you so much for your thoughts!), I\u2019ve decided to dedicate this post to outlining the pros and cons involved in facial recognition technologies, more specifically looking at the effects of implementation of the technology by governments (there\u2019s obviously a lot more to talk about in regard to facial recognition, but as mentioned in [the first post](https://www.reddit.com/r/ArtificialInteligence/comments/gq24up/looking_back_through_time_what_are_your_thoughts/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf) I uploaded, this is for a university assignment so I can\u2019t go overboard with the word count). Again, I encourage you to comment additional thoughts, insights, etc., and let\u2019s try and get a discussion going about the pros and cons of facial recognition technologies!\n\nEdit: This post was originally going to discuss deepfake technology as well but it became way too long, and my poor TA has to read and mark all of this. I decided to just discuss facial recognition technology as used by governments for this part of my assignment, but since I already researched and wrote about deepfake technology I\u2019m still going to attach that below for anyone interested in reading it!\n\n&amp;#x200B;\n\nPros of Facial Recognition A.I.:\n\nThere are a lot of positive intentions that stem from an intelligent machine's ability to analyze the human face. One of the biggest pros that could come from such technologies is the potential upgrades in security. Currently, there are mild forms of this\u00a0 type of security, such as face I.D. for the iPhone, and extreme forms in which the technology is utilized and implemented by governments with the intention of increasing the safety of citizens. Recently in China, facial recognition for all mobile phone holders has become mandatory. The Chinese government has stated that this change has been set in place to \u201cprotect the legitimate rights and interests of citizens in cyberspace\u201d (Kuo, 2019). To many, mass surveillance by the government crosses the line concerning privacy, but the technology does offer advantages. In China, it has created convenience and improved security for citizens\u2019 finances by allowing them to pay for items via facial recognition, and limiting fraud by precisely matching unique facial features to bank account accessibility. Information from the government I.D. system is also used to detect and identify people of the public in real time, which can help reduce crime by monitoring suspicious activity, and easily tracking suspects. The tech can not only identify people, but over 3000 models of cars, and has the ability to cross reference car models with location and time to pinpoint stolen vehicles, potential abduction suspects, and so on. There are so many things you can do with this system to benefit society as a whole, it even assists in an environmental initiative that limits paper towel use in public restrooms (Reeves, 2019).\u00a0\n\nCons of Facial Recognition A.I.:\n\nWhat goes hand in hand with issues regarding security? Issues regarding privacy. When it comes to facial recognition technology, there are valid concerns from the public of China regarding the type of data that is collected from such technologies, and who has access to this information, as there are limited regulations on the data collected (Reeves, 2019). There is also concern about the amount of control over the people of China. The technology now uses a social credit system in which citizens are ranked based on their online practices. Low ratings can cause citizens to be denied access to certain amenities such as train stations or the purchase of plane tickets. One big flaw that the Chinese government did not see coming was the failure for the system to adapt to the pandemic. The country became so reliant on facial recognition technology, which is now useless due to the fact that many people are wearing masks to prevent the spread of COVID-19 (Chiu, 2020). Although the system seemed flawless in the beginning, there will always be unexpected and unprecedented situations that arise which require adaptation that artificial intelligence may not be capable of.\u00a0\n\nWhat Does It All Mean:\n\nFacial recognition technology as a whole has advantages and disadvantages, the question is, does the good outweigh the bad? It\u2019s hard to say. There are a lot of moving parts to consider surrounding the topic. If we want all the advantages, and to continue to innovate intelligent machinery, the negative effects and their power to alter society must be acknowledged and controlled. That leads to another question, who would be in control of the technology? And how can the general public be assured that it won't be used for their own agenda? If I have learned anything from watching the science fiction genre, it\u2019s that a lot can go wrong when technology advances in ways that completely reshape society. In a [VICE interview](https://www.youtube.com/watch?v=CLo3e1Pak-Y), the co-founder of the facial recognition surveillance system in China was asked what this technology could look like in the future. His response was a comparison to \u201cNose Dive\u201d, the Black Mirror episode in which society revolves around a system of social ratings that determine individual class. This has already started happening, as mentioned before, citizens of China can be denied the purchase of plane or train tickets based on their online status. He also discussed the use of facial recognition technology to capture and shame j-walkers, by plastering their -----> photo !!!  on a screen for the public to see. Currently it's used as a preventative measure, utilizing shame in an attempt to deter others from following the practice. In the future, could it be used to actually give tickets for crimes? This in itself, is a slippery slope.\u00a0\n\nWhat are your thoughts on government implemented facial recognition surveillance? Could it be successfully implemented in other countries? Why or why not? Let\u2019s discuss!\n\nNext week's post will discuss the ethical considerations surrounding A.I. use.\n\n&amp;#x200B;\n\nLinks of Sources Used:\n\n[https://www.youtube.com/watch?v=CLo3e1Pak-Y](https://www.youtube.com/watch?v=CLo3e1Pak-Y)\n\n[https://www.forbes.com/sites/bernardmarr/2019/08/19/facial-recognition-technology-here-are-the-important-pros-and-cons/#291cbaea14d1](https://www.forbes.com/sites/bernardmarr/2019/08/19/facial-recognition-technology-here-are-the-important-pros-and-cons/#291cbaea14d1)\n\n[https://www.theguardian.com/world/2019/dec/02/china-brings-in-mandatory-facial-recognition-for-mobile-phone-users](https://www.theguardian.com/world/2019/dec/02/china-brings-in-mandatory-facial-recognition-for-mobile-phone-users)\n\n[https://www.abacusnews.com/tech/facial-recognition-fails-china-people-wear-masks-avoid-coronavirus/article/3048006](https://www.abacusnews.com/tech/facial-recognition-fails-china-people-wear-masks-avoid-coronavirus/article/3048006)\n\n&amp;#x200B;\n\nReference\n\nChiu, K. (2020). Facial recognition fails in China as people wear masks to avoid coronavirus. *Abacus.* Retrieved from: [https://www.abacusnews.com/tech/facial-recognition-fails-china-people-wear-masks-avoid-coronavirus/article/3048006](https://www.abacusnews.com/tech/facial-recognition-fails-china-people-wear-masks-avoid-coronavirus/article/3048006)\n\nKuo, L. (2019). China brings in mandatory facial recognition for mobile phone users. *The Guardian*. Retrieved from: [https://www.theguardian.com/world/2019/dec/02/china-brings-in-mandatory-facial-recognition-for-mobile-phone-users](https://www.theguardian.com/world/2019/dec/02/china-brings-in-mandatory-facial-recognition-for-mobile-phone-users)\n\nMarr, B. (2019). Facial Recognition Technology: Here Are The Important Pros And Cons. *Forbes.* Retrieved from: [https://www.forbes.com/sites/bernardmarr/2019/08/19/facial-recognition-technology-here-are-the-important-pros-and-cons/#291cbaea14d1](https://www.forbes.com/sites/bernardmarr/2019/08/19/facial-recognition-technology-here-are-the-important-pros-and-cons/#291cbaea14d1)\n\nReeves, E. (2019). VICE News. *YouTube.* Retrieved from: [https://www.youtube.com/watch?v=CLo3e1Pak-Y](https://www.youtube.com/watch?v=CLo3e1Pak-Y)\n\n&amp;#x200B;\n\nHey!\n\nIf you feel like reading more\u2026\u00a0\n\nPros of Deepfake Technology:\n\nDeepfake technologies specifically, has created a world of new opportunities in media. In a nutshell, this form of facial recognition involves intelligent machines analyzing data from a collection of images, and using the information to bring the person depicted in the images to life on screen. A practical and productive outcome from the development of deepfake technology can be seen in the film industry. The technology opened the doors to the possibility of film makers digitally placing moving and speaking actors into films. Although this may seem redundant in most cases, the technology allows for opportunities previously unavailable to filmmakers such as bringing the dead back to life to portray a character, or adjusting the appearance of onscreen actors. It\u2019s been done in tons of films. Star Wars Rogue One uses deepfake technology to adjust the age of Carrie Fisher, so that she could portray princess Leia authentically in a prequel released 40 years after its predecessor. The film also utilized the tech to bring character General Tarkin back to life. Fast and the Furious used CGI to bring Paul Walker to life after losing his life in a vehicle collision. The list goes on.\u00a0\n\nCons of Deepfake Technology:\n\nCGI, although having its positives, is an extremely dangerous technology if not regulated and controlled. It poses threats to the reliability of the media and the ongoing issue of fake news. As we can see from the abundance of memes on the internet, the technology is pretty easily available to the public, and can easily fool mass groups of people into believing potentially false information by making it appear to come from a reliable source, which could in turn, have detrimental repercussions on society. A pretty well known example is the Obama deepfake PSA used to warn against the dangers of the future of deepfake technology which is [linked here](https://www.youtube.com/watch?v=bE1KWpoX9Hk) if you want to check it out for yourself for reference. The video shines light to the fact that deepfake software can be used to manipulate viewers, and was made to remind the public of the importance of checking the credibility of sources. There is also a great concern for exploitation of women through deepfake manipulation within pornography, as it is so difficult to distinguish between a deepfake and authentic video. There have already been cases of women discovering false pornagraphic content of themselves on the internet. [Here\u2019s one woman\u2019s experience with deepfake pornogrpahy.](https://www.elle.com/uk/life-and-culture/a30748079/deepfake-porn/)\n\nThe future advancements in quality of deep fake technology could create a world in which real and fake news are indistinguishable, causing mass miscommunication, potentially leading to the downfall of government systems, as well as the personal lives of those vulnerable to the malicious uses of the technology.\u00a0\n\n&amp;#x200B;\n\nSources used:\n\n[https://www.youtube.com/watch?v=NxSOG1aNeBo](https://www.youtube.com/watch?v=NxSOG1aNeBo)\n\n[https://www.forbes.com/sites/chenxiwang/2019/11/01/deepfakes-revenge-porn-and-the-impact-on-women/#f23f6131f53f](https://www.forbes.com/sites/chenxiwang/2019/11/01/deepfakes-revenge-porn-and-the-impact-on-women/#f23f6131f53f)\n\n[https://www.youtube.com/watch?v=bE1KWpoX9Hk](https://www.youtube.com/watch?v=bE1KWpoX9Hk)\n\n[https://www.creativebloq.com/features/deepfake-examples](https://www.creativebloq.com/features/deepfake-examples)\n\n\ud83d\udcf7", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/gu6zjs/weighing_the_odds_the_pros_and_cons_of_facial/"}, {"autor": "cloud_weather", "date": "2020-08-24 18:24:47", "content": "Best -----> Image !!!  Colorization AI as of 2020", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ifun4m/best_image_colorization_ai_as_of_2020/"}, {"autor": "anunimo", "date": "2020-08-23 21:36:30", "content": "What algorithm to detect dice? /!/ Hey guys, so im trying to figure out what sort of AI i would need developed, to be able to precicely, like a human being be able to detect dice, like on this -----> image !!!  below.\n\nEach dice should be recognizeable, and they should also be able to detect errors, (If 2 dice is on top of eachother, or when a dice is tilted halfways).\n\nI have now spent over $1k, on developing something that could perfectly detect the dice below, but unfortunantly there was always some sort of problem with  it.  \nThe last AI version has over 2k dice rolls as trained data, yet it fails miserably.  \n\n\nI would appreciate all the help i could get, regards.  \n\n\nhttps://preview.redd.it/asg0nixdmti51.png?width=1920&amp;format=png&amp;auto=webp&amp;s=e3e465f0815f85f6fc448c8c1674b7615ce9f8b1", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ifbuy3/what_algorithm_to_detect_dice/"}, {"autor": "singularitai", "date": "2020-08-23 01:14:36", "content": "I created a (complimento)bot that compliments people using -----> image !!!  embedding sequences and transformers!", "link": "https://www.reddit.com/r/ArtificialInteligence/comments/ieufw6/i_created_a_complimentobot_that_compliments/"}], "name": "Subreddit_ArtificialInteligence_01_01_2020-30_12_2020"}