{"interestingcomments": [{"autor": "bwllc", "date": "2018-01-17 09:44:04", "content": "Incremental construction of neural networks? /!/ Hi folks!\n\nI have a fair amount of experience with machine learning.  I tried neural networks over a decade ago when nothing much could be accomplished with them, and now I'm coming back.\n\nThe last time that I walked this road, I was intrigued with the cascade correlation network topology that was devised by Scott Fahlman in the 1990's.  His idea was essentially to start with just one output neuron (per output), and to add just one neuron at a time.  Every time that training reached a plateau, the weights of the active neuron would be frozen, then a new neuron would be added.  The new neuron could accept input from every data input, plus the outputs of all the existing neurons.\n\nThere are effectively no layers in the cascade correlation architecture.  The architecture could definitely speed up early training compared to other approaches of that time.  A cascade could also get stuck in local minima, perhaps more easily than other architectures.  I'm not sure whether that was conclusively proven to be a weakness of the approach.\n\nToday, the idea of not using layers in a neural network is unthinkable.  We have much more computing power, especially if we leverage parallel processing, which really only helps if you use layers.  Still...\n\nUsing modern methods (TensorFlow and a GPU, plus whatever high-level Python API I can eventually master), I'm currently working on a complex project that resembles -----> image !!!  segmentation.  It requires hours per iteration.  I have some simple, 3- or 4-layer models that get a piece of my desired result.  Every time that I add more data, or more layers, things slow down.  And as I watch my models train, I can see that the bigger models effectively recapitulate the learning trajectory of the smaller models.  As I explore larger and larger networks, it appears that I'm reinventing the wheel many times.\n\nAvoiding this repetition is something that the cascade correlation architecture was especially good at doing.  So I have been searching for any information that suggests that there is an analogous way to handle convolutional network layers.\n\nCan I initialize a larger model with the weights of a successful smaller one?  Should I?  Is this standard practice, or do people just grind through the whole process from scratch every time?  I have read about transfer learning, but it appears that this refers to readjusting the weights in a given network to improve results on a different data set from the data on which the network was initially trained.  It doesn't seem to refer to wrapping a larger untrained model around a smaller, trained core, which is what I'm suggesting.\n\nCan I build a model which incrementally adds convolutional layers, Fahlman style, with each new layer accepting inputs plus the outputs of all previously-defined layers?  Should I?  I realize that would break the pipelined nature of a typical convolutional data path, but I might have enough GPU memory to handle that situation.  I've seen GoogLeNet, and the Inception module.  The data paths in that architecture are not strictly pipelined.  So I know that it's formally possible to do what I'm suggesting, I just wonder whether it's advisable.\n\nIf anyone has any references or ideas they can share, I would appreciate it.  Thanks!\n", "link": "https://www.reddit.com/r/neuralnetworks/comments/7qzxl7/incremental_construction_of_neural_networks/"}, {"autor": "CuriousCesarr", "date": "2018-01-14 10:39:32", "content": "Unknown details for softmax /!/ Hello everyone.\n  \nI'll try to keep it short and simple: I'm using a feedforward NN for -----> image !!!  recognition (I know that CNNs tend to be better, but I saw that the classical ones could also do the job). My main issue is that I can't apply softmax to the final layer for classification since the inputs are too high and vary too much. My input is a 50x50 image; I convert it to a 2500 element array of values 0-1 and then give it to the network. My network has the structure 2500-764-332-3 (since I have 3 categories that I'm trying to find). I use ReLU as an activation function on all layers and softmax only on the final layer. Before applying softmax, I normalize the inputs by subtracting the largest value from all of them.\n  \nMy issue is that after following all these steps, the values that come into the softmax are still huge (ex: 9.5 mil, 9.2 mil, 8.8 mil) and they remain huge even after normalization. I don't think my implementation is wrong since the input for any one neuron on the second layer will be anywhere between 0-2500 (0-1 inputs, first layer has 2500 neurons); so the 3rd layer will be even larger. Is there a rule or something that I'm unaware of?\n  \nThank you in advance and I wish you all a nice day.", "link": "https://www.reddit.com/r/neuralnetworks/comments/7qb7vo/unknown_details_for_softmax/"}, {"autor": "DiscoverAI", "date": "2018-01-06 17:25:04", "content": "Want to learn how to make your own Convolutional Neural Network for ACCURATE -----> IMAGE !!!  CLASSIFYING? Check this video out, and if you enjoy it, make sure to subscribe. :)", "link": "https://www.reddit.com/r/neuralnetworks/comments/7okios/want_to_learn_how_to_make_your_own_convolutional/"}, {"autor": "JScheinpheld", "date": "2018-01-05 23:31:31", "content": "Fake -----> image !!! s, deep learning and medical -----> image !!!  segmentation - new lit review 17Q4", "link": "https://www.reddit.com/r/neuralnetworks/comments/7ofb91/fake_images_deep_learning_and_medical_image/"}, {"autor": "doorwindowtable", "date": "2018-01-02 16:33:16", "content": "Classifying types of changes between two images with a neural network /!/ I'm a newbie so I'll try to provide as much information as I can, but please bear with me as I stumble through the explanation of my problem. Basically, I have a lot of -----> image !!!  pairs that are from different time stamps. These images are basically just blobs that go through some transformation over time and the image pair is from two-time stamps of this transformation. What I am trying to do is classify types of changes. For now, I just need a binary classification. Although I may change this in the future, but that would mean changing my labels so obviously that is far off. I've been reading up a lot about NN but I can't seem to find anything close to what I'm trying to do. Any direction would be greatly appreciated. ", "link": "https://www.reddit.com/r/neuralnetworks/comments/7nnh6e/classifying_types_of_changes_between_two_images/"}, {"autor": "champloo11", "date": "2018-07-01 01:36:45", "content": "Techniques for using known metadata about -----> image !!! s to improve a retrained -----> image !!!  recognition model? /!/ Recently, I've built a model with ~97.5% identification accuracy by shamelessly stealing retraining techniques used in tutorials like Tensorflow For Poets for retraining a mobilenet. In validation, different categories of images with highly varying levels of accuracy. I'm hoping to improve the accuracy using information I already have about the contents of the image based on improved accuracy I see building customized models.\n\nThe images I am classifying are fairly consistent, and I have loads of structured metadata prior to classification detailing what will be in the image, but not about what needs to be classified. The \"generalized\" model appears to have segments of images with significantly higher classification accuracy than others (segmented based on the aforementioned metadata). If I build one-off models specifically for each segment, I'm able to get poorly performing segments of images (sub 90%) consistently above 97%.\n\nHowever, building one-off models is \n1) fairly cumbersome as I have to build a process to build/retrain the models. and\n2) The outputted models are each above 10MB and I have hundreds/thousands of possible segments.\n\nAre there common patterns for adding known metadata into the feature vectors, or retraining models with metadata to improve training accuracy? I'm an software engineer by trade, and my google-foo is failing me in this regard as I don't think I know the right terminology.\n\nCheers", "link": "https://www.reddit.com/r/neuralnetworks/comments/8v6m0s/techniques_for_using_known_metadata_about_images/"}, {"autor": "Zigguraut", "date": "2018-06-21 00:41:01", "content": "Activity Detector and Labeller /!/ The idea of this is to create a kind of automated security monitoring software which works very similar to an -----> image !!!  detector, but, detects the action the object in the -----> image !!!  is taking. Here is an example.\n\nThere is inputs for for layer of images. The first image has maybe over 4050 inputs to represent an image, hue, and brightness. After the first frame, you have another 4050 inputs for the next image. Each activity that you can think of can probably be labeled in under a second, so you could cut down the number of inputs by depending on 15 frames. This equals 4050x15 inputs. Only the first layer of inputs for the current image being processed should care about image detection. The other layers are trained to detect how to label the differences between images over time. This means that an image detection like neural network is trained to process 15 frames at the same time in order to get an idea of what happened and time stamps the activity of interest, such as somebody getting into a car crash or stealing something from a store. Pretty interesting yes? You could set up cameras all over the player which have been trained to recognize certain types of activity and instead of sitting around behind a monitor watching the cameras all night, you can sleep like a baby. If the cameras witness something like someone trying to break or sneak into a house, a wild animal trying to hurt people, or anything else like that, it could be set up to alarm whoever needs to be alarmed.\n\nWhat do you guys think?", "link": "https://www.reddit.com/r/neuralnetworks/comments/8snj3f/activity_detector_and_labeller/"}, {"autor": "_beeb", "date": "2018-06-09 08:14:46", "content": "Removing hard subtitles from video /!/ Hey all!\n\nI haven't played with nn in a while but I would like to get back into it, especially now that a lot of tools are available for us to use.\n\nI think it would be a cool project to train a deep learning model to hide hard subtitles from video files.\n\nFirst of all, have you heard of something similar yet?\n\nGenerating training data should be easy, take a normal video file without subtitles, download the corresponding subtitles and generate a file with subtitles hard embedded into the images. The first one is the output, the latter the input.\n\nThe algorithm could be optimized to only look at the part of the -----> image !!!  where subtitles are expected (lower quarter or so). Might it be a good idea to also use audio data in this or would it be overkill? The idea is that a subtitle is usually linked with an audio input (but not always).\n\nLastly, any recommendation on a method that has proven to work for similar tasks?\n\nThanks a lot! ", "link": "https://www.reddit.com/r/neuralnetworks/comments/8preq3/removing_hard_subtitles_from_video/"}, {"autor": "MartinKardis", "date": "2018-07-09 16:21:31", "content": "Would it be possible/make sense to apply machine learning to rendering? /!/ Just a \"shower thought\". I'm a programmer, but I've never done anything related to neural networks. I was wondering if it would be possible to teach an AI to render a scene. The learning process seems more-or-less straightforward, with raw scene files and traditionally rendered results as input.\n\nI was wondering whether it could be possible, and if it would have any benefits (maybe smaller files, as AI'd need less info to produce a realistic -----> image !!! , or maybe \"infinite\" resolution and poly-count, as it would predict how the -----> image !!!  should look like).", "link": "https://www.reddit.com/r/neuralnetworks/comments/8xd856/would_it_be_possiblemake_sense_to_apply_machine/"}, {"autor": "rennytech", "date": "2018-07-04 08:29:01", "content": "Wine vs Sparkling Wine: A Neural Network -----> image !!!  classification explained", "link": "https://www.reddit.com/r/neuralnetworks/comments/8w02s4/wine_vs_sparkling_wine_a_neural_network_image/"}, {"autor": "ronith_sinha", "date": "2018-09-06 17:26:26", "content": "Counting people in an -----> image !!!  of a dense crowd. /!/ What are some good approaches that I can use to count the no. of people in a crowd. Tracking each person individually is obviously not an option. Any good approaches or some references to research papers would be very helpful.", "link": "https://www.reddit.com/r/neuralnetworks/comments/9dkv74/counting_people_in_an_image_of_a_dense_crowd/"}, {"autor": "akgoel", "date": "2018-09-06 15:20:25", "content": "-----> Image !!!  tampering detection paper: Does anybody have a link to the code? /!/ Paper: [Learning Rich Features for Image Manipulation Detection](https://arxiv.org/pdf/1805.04953.pdf)\n\nDoes anybody know if the code for this is released by the authors publicly, and where to download it from?", "link": "https://www.reddit.com/r/neuralnetworks/comments/9djmw5/image_tampering_detection_paper_does_anybody_have/"}, {"autor": "mikinoqwert2", "date": "2018-08-08 16:48:49", "content": "Few activation functions handling various problems - neural networks /!/ Please, explain me, how a few activation functions in neural networks can handle so many problems? I know some basics theory behind ANN, but I can't get what in common have sigmoid function etc. with for example -----> picture !!!  classification?", "link": "https://www.reddit.com/r/neuralnetworks/comments/95nq3b/few_activation_functions_handling_various/"}, {"autor": "keghn", "date": "2018-10-01 13:28:13", "content": "Gun-spotting -----> camera !!!  can take the next step realtime and alert authorities", "link": "https://www.reddit.com/r/neuralnetworks/comments/9kgbew/gunspotting_camera_can_take_the_next_step/"}, {"autor": "mulaned", "date": "2018-09-19 05:22:18", "content": "Doing a Heirohlypics(of sort) project, need some advice and tips. /!/ I'm doing a project that is involved with some sort of Heiroglyphics, so basically they're going to be like objects that'll soon be recognized as their corresponding words. I want to get the framework down so I'm looking for tips to do this. I'm new to Machine Learning so I still dont know a lot. I'm thinking of using a Convoluted Neural Networks since it'll be accepting an -----> image !!!  as an input. For Object Detection I'm thinking of using sliding windows after the image has been convoluted to identify the heiroglyphs. Should it be 2 separate networks, one for the detection and one for the transliteration?\n\nWould there be any need to max pool the image while training?\n\nAlso, any image segmentation methods better than sliding window?\n\n&amp;#x200B;", "link": "https://www.reddit.com/r/neuralnetworks/comments/9h2enb/doing_a_heirohlypicsof_sort_project_need_some/"}, {"autor": "Aradarbel10", "date": "2018-09-14 19:49:15", "content": "Understanding Convolutional Layers /!/ Hello,\n\nI am learning ml now, and I wrote some simple neural networks, one of them was softmax regression for the mnist dataset. I have about 90% correct predictions. I know that I can improve it in theory by using convNets, but I am not quite sure about something. I know lots in this field from book, arcticles, and videos, but I really want to get right into the programming.\n\nWhen I feed a convNet with an -----> image !!! , first thing happens is the convolutional layer. using some features, I can get a list of filtered images. Because I am using mnist (1 channel - grayscale) the input will be 2 dimentional, and the next layer will be 3 dimentional. After that I can apply relu and max pooling for example, and here comes my question: how should I apply the filters? 1 for each Image, so the next layer will be also 3 dimentional? or apply all the features to all the images from the previous layer, and get a new dimention with each convolution layer, so in theory it could get to a lot higher dimentions?\n\nI will be happy to have links for good explenations you know, or get some help from the experts here ;D\n\nAnyways, Any help will be appriciated,\n\nArad.", "link": "https://www.reddit.com/r/neuralnetworks/comments/9fv6ze/understanding_convolutional_layers/"}, {"autor": "PM_ME_cutefish", "date": "2018-11-20 11:21:42", "content": "Detect illegal pattern in adult content videos /!/ Hello guys!\n\n&amp;#x200B;\n\nFirst please notice that this is a serious post even though the subject might sound weird.\n\nTo introduce myself, I work in a company that basically offer some streaming and downloading platform for adult content.\n\nI was recently introduced to a new kind of product which work like this:\n\n\\- A \"seller\" upload content (lets focus on -----> photo !!! /video) on our website\n\n\\- A \"buyer\" can download the content by paying\n\n&amp;#x200B;\n\nNow here is where my job starts: As the content is on OUR website, we are responsible for the content of it. So if for example someone uploads a video in which we see anything that could be illegal (drug, rape, pedophilia...), we are responsible for it. Therefore, we need to monitor the content of every product that is uploaded on our website.\n\n&amp;#x200B;\n\nNow here is where I need your help: I have a theoretical knowledge of machine learning and neural network and it's a field I am really interested in and I really want to learn, so i'd have 2 questions:\n\n&amp;#x200B;\n\n1- Regardless of my profile, would it be possible to have an artificial intelligence that could detect on video undesirable things such as blood, extreme violence and anything you don't want to see on a video?\n\n2- How hard would it be for me, that has not much practical experience in this, to build this?\n\n&amp;#x200B;\n\nMany thanks for your time guys!", "link": "https://www.reddit.com/r/neuralnetworks/comments/9yrb7x/detect_illegal_pattern_in_adult_content_videos/"}, {"autor": "bkmnsk", "date": "2018-11-09 12:10:13", "content": "CV tool for turning video stream from -----> camera !!!  into structured data in real-time /!/ Hi there!\n\nOur team make a tool for developers, based on computer vision algorithms, that helps to extract useful information from video stream in real-time and integrate it into apps without expertise in machine learning.\n\nThere are three simple steps to get started. Install the program on your computer, connect the camera and choose what you want to see. That's it. Live video stream from camera will be processed locally on your computer by AI models. Result will be time series data in JSON format, which developer can integrate into his application.\n\nAs for now the tool is on the development stage. You can see a demonstration of the tool on the [website](https://heyml.com/vision).\nWe need your opinion and recommendations for improvement. We are open to discussion :)", "link": "https://www.reddit.com/r/neuralnetworks/comments/9vjwnr/cv_tool_for_turning_video_stream_from_camera_into/"}, {"autor": "pocketMAD", "date": "2018-11-07 00:33:14", "content": "What is the difference between YOLO, Single Shot Detectors, MobileNet, Darknet, and Darkflow? /!/ I'm trying to use an SSD for my robotics club. From researching, I see these terms thrown around all the time. I'd like it if someone could clarify what they are.\n\nHere's what I believe is true:\nSSD is a CV algorithm that uses those cell grid and bounding boxes stuff.\nYOLO is a trained model using the SSD algorithm\nDarkflow is an -----> image !!!  database (I think?)\n\nThat's all I got so far. Correct me on anything I'm incorrect on. :) ", "link": "https://www.reddit.com/r/neuralnetworks/comments/9uu8xf/what_is_the_difference_between_yolo_single_shot/"}, {"autor": "Autoradiograph", "date": "2018-11-02 23:54:32", "content": "How reasonable would it be to run a NN on a Raspberry Pi to detect people in photos taken with a night vision Pi Cam? /!/ I'm thinking about working on a very low power person-detection security -----> camera !!!  for a van RV. It would have a camera that's on all the time, taking pictures as rapidly as it can classify them, and if it detects a person close to the van from some length of time, it could alert me.\n\nDoes that seem possible?\n\nI don't really know jack about neural networks, but I'm a software engineer, so I'm sure I could learn.\n\n(Training could obviously be done on a real PC.)", "link": "https://www.reddit.com/r/neuralnetworks/comments/9tphf4/how_reasonable_would_it_be_to_run_a_nn_on_a/"}, {"autor": "aashwin93", "date": "2018-11-26 12:44:46", "content": "Experience with Deep Fashion dataset /!/ Hey guys,\n\nI'd like to know if any of you have used the DeepFashion dataset for classification/-----> image !!!  ranking . Its a major pain the ass to preprocess and would love to hear some of your inputs regarding the same.\n\n Also, what other Fashion/Apparel datasets have you come across/used/recommend?\n\n&amp;#x200B;", "link": "https://www.reddit.com/r/neuralnetworks/comments/a0j0yj/experience_with_deep_fashion_dataset/"}, {"autor": "pahvikahvi", "date": "2018-04-10 07:21:40", "content": "Made my first neural network AI! /!/ Inspired by mari/o i got interested in Neural Networks. I had a vague idea of what they are doing, but i wanted to know how to make one. I watched a couple videos and read alot about how they work in general and about different thinks that make them learn such as back propagation. It was amazing how it made so much sense and seemed less like magic, so i thought i could make a self learning number recognition neural network AI with no tutorials, and finally got it completed!\nRight now it can only be used for recognizing if the -----> image !!!  is of an 8 or a 9. It is fed 30 pictures of 30x30 images, and should output percentages, of what it believes the number is. It doesn't do exactly that. Instead, it says that the possibility that the image is of the number it isn't is around 50, and it says that the possibility that the image is of the number that it is, is pretty random, but for some reason never around 50.\nSo basically, it doesn't show the right percentage, but it does know what number is in the picture, and the information is easily deciphered.", "link": "https://www.reddit.com/r/neuralnetworks/comments/8b5svn/made_my_first_neural_network_ai/"}, {"autor": "overwhelmed_dev", "date": "2018-05-25 00:34:33", "content": "Assistance de-blurring -----> photo !!!  with CNN? /!/ Hello /r/neuralnetworks! An odd question to throw out to this subreddit.  \n\n\nFulham v Aston Villa this weekend is one of the biggest football games of the year, and Fulham\u2019s manager posted this image of his team\u2019s confidential pre\\-match report on Twitter:  \n\n\n[https://twitter.com/Jokanovic/status/997207217618243584](https://twitter.com/Jokanovic/status/997207217618243584)  \n\n\nI\u2019m curious if anyone here knows whether a CNN for deblurring, such as the one below, might be able to declassify any of the hidden text? Does anyone have some tools to take a stab at it?  \n\n\n[http://www.fit.vutbr.cz/\\~ihradis/CNN\\-Deblur/](http://www.fit.vutbr.cz/~ihradis/CNN-Deblur/)  \n\n\nHere are some higher\\-res versions of the original image:  \n\n\n[https://imgur.com/a/P0B3lFO](https://imgur.com/a/P0B3lFO)  \n[https://imgur.com/a/g6YRZs3](https://imgur.com/a/g6YRZs3)", "link": "https://www.reddit.com/r/neuralnetworks/comments/8lxmq3/assistance_deblurring_photo_with_cnn/"}, {"autor": "mrmola", "date": "2018-05-21 02:44:48", "content": "-----> Image !!!  stuff /!/ So I installed [this](https://github.com/solivr/tf-crnn) thing off of github for picture to text machine learning, and I installed all the dependencies but when I run it for training it says this:\n`/home/mrmola/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nTraceback (most recent call last):\n  File \"train.py\", line 14, in &lt;module&gt;\n    from src.model import crnn_fn\nImportError: No module named src.model`\nSo I go to the src directory. I run model.py because I figured that would fix the problem and I get:\n`  File \"model.py\", line 25\n    def deep_cnn(input_imgs: tf.Tensor, is_training: bool, summaries: bool=True) -&gt; tf.Tensor:\n                           ^\nSyntaxError: invalid syntax`\nHelp?", "link": "https://www.reddit.com/r/neuralnetworks/comments/8kxmyc/image_stuff/"}, {"autor": "iwantinternetplease", "date": "2018-03-05 04:07:30", "content": "Train A Network With Large Amounts of Data? /!/ A hypothetical neural net has 800 inputs and 1 output. Then 1024 of them are put together to create a list of 1s and 0s. Maybe it is creating an -----> image !!!  based on 800 conditions. How do I train it quickly? I don't want to write out that many conditions. Is there a quick, pythonic way to do this in python? ", "link": "https://www.reddit.com/r/neuralnetworks/comments/8239br/train_a_network_with_large_amounts_of_data/"}, {"autor": "neurointerventional", "date": "2018-02-27 02:29:45", "content": "Question about Neural Network for Medical Imaging /!/ Hi, I am a medical student interested in applying machine learning to medical research to improve patient outcomes. For neural networks such as this one\n\n&gt;[3D Deep Learning for Multi-modal Imaging-Guided Survival Time Prediction of Brain Tumor Patients]\n(http://www.unc.edu/%7Eeadeli/publications/Dong_MICCAI2016.pdf)\n\ndoes the neural network produce results that we can understand or at least translate into concepts usable by e.g. a radiologist looking at a similar -----> image !!! ? Or does it output a raw value like \"You are expected to live 5.77 years,\" and for a new scan you would have to run it through the network to get a new prediction? Could a network built differently provide the kind of output I'm looking for e.g. MRI characteristic X is associated with 5.77 years greater survival? \n\nThanks!", "link": "https://www.reddit.com/r/neuralnetworks/comments/80iupp/question_about_neural_network_for_medical_imaging/"}], "name": "Subreddit_neuralnetworks_01_01_2018-30_12_2018"}